2019-10-29 00:29:43,630 Training Epoch [1/40] Iter[0/312]		Loss: 5.4851
2019-10-29 00:29:43,759 Training Epoch [1/40] Iter[1/312]		Loss: 4.5686
2019-10-29 00:29:43,882 Training Epoch [1/40] Iter[2/312]		Loss: 4.2128
2019-10-29 00:29:44,004 Training Epoch [1/40] Iter[3/312]		Loss: 3.8764
2019-10-29 00:29:44,124 Training Epoch [1/40] Iter[4/312]		Loss: 3.5263
2019-10-29 00:29:44,247 Training Epoch [1/40] Iter[5/312]		Loss: 3.4112
2019-10-29 00:29:44,367 Training Epoch [1/40] Iter[6/312]		Loss: 3.3837
2019-10-29 00:29:44,488 Training Epoch [1/40] Iter[7/312]		Loss: 3.3085
2019-10-29 00:29:44,608 Training Epoch [1/40] Iter[8/312]		Loss: 3.2079
2019-10-29 00:29:44,729 Training Epoch [1/40] Iter[9/312]		Loss: 3.1478
2019-10-29 00:29:44,850 Training Epoch [1/40] Iter[10/312]		Loss: 3.0994
2019-10-29 00:29:44,972 Training Epoch [1/40] Iter[11/312]		Loss: 3.0701
2019-10-29 00:29:45,093 Training Epoch [1/40] Iter[12/312]		Loss: 3.0329
2019-10-29 00:29:45,214 Training Epoch [1/40] Iter[13/312]		Loss: 2.9662
2019-10-29 00:29:45,336 Training Epoch [1/40] Iter[14/312]		Loss: 2.9501
2019-10-29 00:29:45,458 Training Epoch [1/40] Iter[15/312]		Loss: 2.9209
2019-10-29 00:29:45,579 Training Epoch [1/40] Iter[16/312]		Loss: 2.8761
2019-10-29 00:29:45,705 Training Epoch [1/40] Iter[17/312]		Loss: 2.8603
2019-10-29 00:29:45,827 Training Epoch [1/40] Iter[18/312]		Loss: 2.8516
2019-10-29 00:29:45,948 Training Epoch [1/40] Iter[19/312]		Loss: 2.8372
2019-10-29 00:29:46,069 Training Epoch [1/40] Iter[20/312]		Loss: 2.8290
2019-10-29 00:29:46,191 Training Epoch [1/40] Iter[21/312]		Loss: 2.7947
2019-10-29 00:29:46,313 Training Epoch [1/40] Iter[22/312]		Loss: 2.7726
2019-10-29 00:29:46,434 Training Epoch [1/40] Iter[23/312]		Loss: 2.7477
2019-10-29 00:29:46,556 Training Epoch [1/40] Iter[24/312]		Loss: 2.7011
2019-10-29 00:29:46,678 Training Epoch [1/40] Iter[25/312]		Loss: 2.6951
2019-10-29 00:29:46,799 Training Epoch [1/40] Iter[26/312]		Loss: 2.6831
2019-10-29 00:29:46,921 Training Epoch [1/40] Iter[27/312]		Loss: 2.6829
2019-10-29 00:29:47,042 Training Epoch [1/40] Iter[28/312]		Loss: 2.6825
2019-10-29 00:29:47,163 Training Epoch [1/40] Iter[29/312]		Loss: 2.6773
2019-10-29 00:29:47,285 Training Epoch [1/40] Iter[30/312]		Loss: 2.6491
2019-10-29 00:29:47,406 Training Epoch [1/40] Iter[31/312]		Loss: 2.6424
2019-10-29 00:29:47,528 Training Epoch [1/40] Iter[32/312]		Loss: 2.6384
2019-10-29 00:29:47,649 Training Epoch [1/40] Iter[33/312]		Loss: 2.6293
2019-10-29 00:29:47,770 Training Epoch [1/40] Iter[34/312]		Loss: 2.6249
2019-10-29 00:29:47,891 Training Epoch [1/40] Iter[35/312]		Loss: 2.6196
2019-10-29 00:29:48,012 Training Epoch [1/40] Iter[36/312]		Loss: 2.6046
2019-10-29 00:29:48,133 Training Epoch [1/40] Iter[37/312]		Loss: 2.6030
2019-10-29 00:29:48,256 Training Epoch [1/40] Iter[38/312]		Loss: 2.6113
2019-10-29 00:29:48,377 Training Epoch [1/40] Iter[39/312]		Loss: 2.6091
2019-10-29 00:29:48,499 Training Epoch [1/40] Iter[40/312]		Loss: 2.6156
2019-10-29 00:29:48,620 Training Epoch [1/40] Iter[41/312]		Loss: 2.6063
2019-10-29 00:29:48,742 Training Epoch [1/40] Iter[42/312]		Loss: 2.5950
2019-10-29 00:29:48,864 Training Epoch [1/40] Iter[43/312]		Loss: 2.5816
2019-10-29 00:29:48,985 Training Epoch [1/40] Iter[44/312]		Loss: 2.5727
2019-10-29 00:29:49,107 Training Epoch [1/40] Iter[45/312]		Loss: 2.5679
2019-10-29 00:29:49,228 Training Epoch [1/40] Iter[46/312]		Loss: 2.5641
2019-10-29 00:29:49,350 Training Epoch [1/40] Iter[47/312]		Loss: 2.5647
2019-10-29 00:29:49,472 Training Epoch [1/40] Iter[48/312]		Loss: 2.5653
2019-10-29 00:29:49,593 Training Epoch [1/40] Iter[49/312]		Loss: 2.5540
2019-10-29 00:29:49,714 Training Epoch [1/40] Iter[50/312]		Loss: 2.5480
2019-10-29 00:29:49,835 Training Epoch [1/40] Iter[51/312]		Loss: 2.5371
2019-10-29 00:29:49,956 Training Epoch [1/40] Iter[52/312]		Loss: 2.5307
2019-10-29 00:29:50,077 Training Epoch [1/40] Iter[53/312]		Loss: 2.5279
2019-10-29 00:29:50,199 Training Epoch [1/40] Iter[54/312]		Loss: 2.5301
2019-10-29 00:29:50,320 Training Epoch [1/40] Iter[55/312]		Loss: 2.5276
2019-10-29 00:29:50,441 Training Epoch [1/40] Iter[56/312]		Loss: 2.5254
2019-10-29 00:29:50,562 Training Epoch [1/40] Iter[57/312]		Loss: 2.5256
2019-10-29 00:29:50,684 Training Epoch [1/40] Iter[58/312]		Loss: 2.5215
2019-10-29 00:29:50,806 Training Epoch [1/40] Iter[59/312]		Loss: 2.5203
2019-10-29 00:29:50,927 Training Epoch [1/40] Iter[60/312]		Loss: 2.5156
2019-10-29 00:29:51,049 Training Epoch [1/40] Iter[61/312]		Loss: 2.5127
2019-10-29 00:29:51,171 Training Epoch [1/40] Iter[62/312]		Loss: 2.5058
2019-10-29 00:29:51,292 Training Epoch [1/40] Iter[63/312]		Loss: 2.5029
2019-10-29 00:29:51,414 Training Epoch [1/40] Iter[64/312]		Loss: 2.5032
2019-10-29 00:29:51,536 Training Epoch [1/40] Iter[65/312]		Loss: 2.4942
2019-10-29 00:29:51,657 Training Epoch [1/40] Iter[66/312]		Loss: 2.4918
2019-10-29 00:29:51,779 Training Epoch [1/40] Iter[67/312]		Loss: 2.4881
2019-10-29 00:29:51,900 Training Epoch [1/40] Iter[68/312]		Loss: 2.4834
2019-10-29 00:29:52,022 Training Epoch [1/40] Iter[69/312]		Loss: 2.4807
2019-10-29 00:29:52,143 Training Epoch [1/40] Iter[70/312]		Loss: 2.4774
2019-10-29 00:29:52,265 Training Epoch [1/40] Iter[71/312]		Loss: 2.4735
2019-10-29 00:29:52,386 Training Epoch [1/40] Iter[72/312]		Loss: 2.4693
2019-10-29 00:29:52,508 Training Epoch [1/40] Iter[73/312]		Loss: 2.4659
2019-10-29 00:29:52,629 Training Epoch [1/40] Iter[74/312]		Loss: 2.4628
2019-10-29 00:29:52,750 Training Epoch [1/40] Iter[75/312]		Loss: 2.4613
2019-10-29 00:29:52,871 Training Epoch [1/40] Iter[76/312]		Loss: 2.4596
2019-10-29 00:29:52,992 Training Epoch [1/40] Iter[77/312]		Loss: 2.4659
2019-10-29 00:29:53,113 Training Epoch [1/40] Iter[78/312]		Loss: 2.4619
2019-10-29 00:29:53,234 Training Epoch [1/40] Iter[79/312]		Loss: 2.4567
2019-10-29 00:29:53,356 Training Epoch [1/40] Iter[80/312]		Loss: 2.4544
2019-10-29 00:29:53,477 Training Epoch [1/40] Iter[81/312]		Loss: 2.4511
2019-10-29 00:29:53,599 Training Epoch [1/40] Iter[82/312]		Loss: 2.4472
2019-10-29 00:29:53,720 Training Epoch [1/40] Iter[83/312]		Loss: 2.4401
2019-10-29 00:29:53,841 Training Epoch [1/40] Iter[84/312]		Loss: 2.4366
2019-10-29 00:29:53,962 Training Epoch [1/40] Iter[85/312]		Loss: 2.4334
2019-10-29 00:29:54,084 Training Epoch [1/40] Iter[86/312]		Loss: 2.4365
2019-10-29 00:29:54,205 Training Epoch [1/40] Iter[87/312]		Loss: 2.4286
2019-10-29 00:29:54,326 Training Epoch [1/40] Iter[88/312]		Loss: 2.4250
2019-10-29 00:29:54,454 Training Epoch [1/40] Iter[89/312]		Loss: 2.4245
2019-10-29 00:29:54,575 Training Epoch [1/40] Iter[90/312]		Loss: 2.4186
2019-10-29 00:29:54,696 Training Epoch [1/40] Iter[91/312]		Loss: 2.4161
2019-10-29 00:29:54,817 Training Epoch [1/40] Iter[92/312]		Loss: 2.4153
2019-10-29 00:29:54,939 Training Epoch [1/40] Iter[93/312]		Loss: 2.4154
2019-10-29 00:29:55,060 Training Epoch [1/40] Iter[94/312]		Loss: 2.4116
2019-10-29 00:29:55,182 Training Epoch [1/40] Iter[95/312]		Loss: 2.4102
2019-10-29 00:29:55,304 Training Epoch [1/40] Iter[96/312]		Loss: 2.4110
2019-10-29 00:29:55,426 Training Epoch [1/40] Iter[97/312]		Loss: 2.4037
2019-10-29 00:29:55,547 Training Epoch [1/40] Iter[98/312]		Loss: 2.3993
2019-10-29 00:29:55,668 Training Epoch [1/40] Iter[99/312]		Loss: 2.3939
2019-10-29 00:29:55,795 Training Epoch [1/40] Iter[100/312]		Loss: 2.3915
2019-10-29 00:29:55,916 Training Epoch [1/40] Iter[101/312]		Loss: 2.3860
2019-10-29 00:29:56,038 Training Epoch [1/40] Iter[102/312]		Loss: 2.3752
2019-10-29 00:29:56,159 Training Epoch [1/40] Iter[103/312]		Loss: 2.3722
2019-10-29 00:29:56,281 Training Epoch [1/40] Iter[104/312]		Loss: 2.3643
2019-10-29 00:29:56,402 Training Epoch [1/40] Iter[105/312]		Loss: 2.3571
2019-10-29 00:29:56,523 Training Epoch [1/40] Iter[106/312]		Loss: 2.3511
2019-10-29 00:29:56,645 Training Epoch [1/40] Iter[107/312]		Loss: 2.3427
2019-10-29 00:29:56,766 Training Epoch [1/40] Iter[108/312]		Loss: 2.3363
2019-10-29 00:29:56,887 Training Epoch [1/40] Iter[109/312]		Loss: 2.3297
2019-10-29 00:29:57,009 Training Epoch [1/40] Iter[110/312]		Loss: 2.3222
2019-10-29 00:29:57,130 Training Epoch [1/40] Iter[111/312]		Loss: 2.3127
2019-10-29 00:29:57,251 Training Epoch [1/40] Iter[112/312]		Loss: 2.3037
2019-10-29 00:29:57,373 Training Epoch [1/40] Iter[113/312]		Loss: 2.2939
2019-10-29 00:29:57,495 Training Epoch [1/40] Iter[114/312]		Loss: 2.2839
2019-10-29 00:29:57,616 Training Epoch [1/40] Iter[115/312]		Loss: 2.2762
2019-10-29 00:29:57,737 Training Epoch [1/40] Iter[116/312]		Loss: 2.2677
2019-10-29 00:29:57,858 Training Epoch [1/40] Iter[117/312]		Loss: 2.2600
2019-10-29 00:29:57,979 Training Epoch [1/40] Iter[118/312]		Loss: 2.2525
2019-10-29 00:29:58,100 Training Epoch [1/40] Iter[119/312]		Loss: 2.2430
2019-10-29 00:29:58,221 Training Epoch [1/40] Iter[120/312]		Loss: 2.2344
2019-10-29 00:29:58,343 Training Epoch [1/40] Iter[121/312]		Loss: 2.2236
2019-10-29 00:29:58,464 Training Epoch [1/40] Iter[122/312]		Loss: 2.2167
2019-10-29 00:29:58,585 Training Epoch [1/40] Iter[123/312]		Loss: 2.2124
2019-10-29 00:29:58,706 Training Epoch [1/40] Iter[124/312]		Loss: 2.2024
2019-10-29 00:29:58,827 Training Epoch [1/40] Iter[125/312]		Loss: 2.1940
2019-10-29 00:29:58,948 Training Epoch [1/40] Iter[126/312]		Loss: 2.1882
2019-10-29 00:29:59,070 Training Epoch [1/40] Iter[127/312]		Loss: 2.1800
2019-10-29 00:29:59,191 Training Epoch [1/40] Iter[128/312]		Loss: 2.1725
2019-10-29 00:29:59,313 Training Epoch [1/40] Iter[129/312]		Loss: 2.1645
2019-10-29 00:29:59,435 Training Epoch [1/40] Iter[130/312]		Loss: 2.1571
2019-10-29 00:29:59,556 Training Epoch [1/40] Iter[131/312]		Loss: 2.1480
2019-10-29 00:29:59,677 Training Epoch [1/40] Iter[132/312]		Loss: 2.1406
2019-10-29 00:29:59,798 Training Epoch [1/40] Iter[133/312]		Loss: 2.1337
2019-10-29 00:29:59,919 Training Epoch [1/40] Iter[134/312]		Loss: 2.1251
2019-10-29 00:30:00,041 Training Epoch [1/40] Iter[135/312]		Loss: 2.1207
2019-10-29 00:30:00,162 Training Epoch [1/40] Iter[136/312]		Loss: 2.1132
2019-10-29 00:30:00,284 Training Epoch [1/40] Iter[137/312]		Loss: 2.1069
2019-10-29 00:30:00,406 Training Epoch [1/40] Iter[138/312]		Loss: 2.0989
2019-10-29 00:30:00,528 Training Epoch [1/40] Iter[139/312]		Loss: 2.0925
2019-10-29 00:30:00,649 Training Epoch [1/40] Iter[140/312]		Loss: 2.0864
2019-10-29 00:30:00,770 Training Epoch [1/40] Iter[141/312]		Loss: 2.0808
2019-10-29 00:30:00,892 Training Epoch [1/40] Iter[142/312]		Loss: 2.0737
2019-10-29 00:30:01,013 Training Epoch [1/40] Iter[143/312]		Loss: 2.0669
2019-10-29 00:30:01,134 Training Epoch [1/40] Iter[144/312]		Loss: 2.0611
2019-10-29 00:30:01,256 Training Epoch [1/40] Iter[145/312]		Loss: 2.0525
2019-10-29 00:30:01,377 Training Epoch [1/40] Iter[146/312]		Loss: 2.0465
2019-10-29 00:30:01,499 Training Epoch [1/40] Iter[147/312]		Loss: 2.0408
2019-10-29 00:30:01,620 Training Epoch [1/40] Iter[148/312]		Loss: 2.0360
2019-10-29 00:30:01,741 Training Epoch [1/40] Iter[149/312]		Loss: 2.0327
2019-10-29 00:30:01,862 Training Epoch [1/40] Iter[150/312]		Loss: 2.0264
2019-10-29 00:30:01,984 Training Epoch [1/40] Iter[151/312]		Loss: 2.0216
2019-10-29 00:30:02,105 Training Epoch [1/40] Iter[152/312]		Loss: 2.0144
2019-10-29 00:30:02,226 Training Epoch [1/40] Iter[153/312]		Loss: 2.0085
2019-10-29 00:30:02,348 Training Epoch [1/40] Iter[154/312]		Loss: 2.0019
2019-10-29 00:30:02,470 Training Epoch [1/40] Iter[155/312]		Loss: 1.9969
2019-10-29 00:30:02,592 Training Epoch [1/40] Iter[156/312]		Loss: 1.9929
2019-10-29 00:30:02,713 Training Epoch [1/40] Iter[157/312]		Loss: 1.9870
2019-10-29 00:30:02,834 Training Epoch [1/40] Iter[158/312]		Loss: 1.9818
2019-10-29 00:30:02,955 Training Epoch [1/40] Iter[159/312]		Loss: 1.9758
2019-10-29 00:30:03,077 Training Epoch [1/40] Iter[160/312]		Loss: 1.9701
2019-10-29 00:30:03,198 Training Epoch [1/40] Iter[161/312]		Loss: 1.9642
2019-10-29 00:30:03,319 Training Epoch [1/40] Iter[162/312]		Loss: 1.9591
2019-10-29 00:30:03,441 Training Epoch [1/40] Iter[163/312]		Loss: 1.9519
2019-10-29 00:30:03,562 Training Epoch [1/40] Iter[164/312]		Loss: 1.9465
2019-10-29 00:30:03,684 Training Epoch [1/40] Iter[165/312]		Loss: 1.9417
2019-10-29 00:30:03,806 Training Epoch [1/40] Iter[166/312]		Loss: 1.9367
2019-10-29 00:30:03,927 Training Epoch [1/40] Iter[167/312]		Loss: 1.9308
2019-10-29 00:30:04,048 Training Epoch [1/40] Iter[168/312]		Loss: 1.9248
2019-10-29 00:30:04,169 Training Epoch [1/40] Iter[169/312]		Loss: 1.9192
2019-10-29 00:30:04,291 Training Epoch [1/40] Iter[170/312]		Loss: 1.9125
2019-10-29 00:30:04,413 Training Epoch [1/40] Iter[171/312]		Loss: 1.9067
2019-10-29 00:30:04,534 Training Epoch [1/40] Iter[172/312]		Loss: 1.9003
2019-10-29 00:30:04,655 Training Epoch [1/40] Iter[173/312]		Loss: 1.8949
2019-10-29 00:30:04,776 Training Epoch [1/40] Iter[174/312]		Loss: 1.8899
2019-10-29 00:30:04,897 Training Epoch [1/40] Iter[175/312]		Loss: 1.8865
2019-10-29 00:30:05,019 Training Epoch [1/40] Iter[176/312]		Loss: 1.8823
2019-10-29 00:30:05,140 Training Epoch [1/40] Iter[177/312]		Loss: 1.8774
2019-10-29 00:30:05,262 Training Epoch [1/40] Iter[178/312]		Loss: 1.8723
2019-10-29 00:30:05,384 Training Epoch [1/40] Iter[179/312]		Loss: 1.8681
2019-10-29 00:30:05,505 Training Epoch [1/40] Iter[180/312]		Loss: 1.8642
2019-10-29 00:30:05,627 Training Epoch [1/40] Iter[181/312]		Loss: 1.8591
2019-10-29 00:30:05,748 Training Epoch [1/40] Iter[182/312]		Loss: 1.8537
2019-10-29 00:30:05,870 Training Epoch [1/40] Iter[183/312]		Loss: 1.8495
2019-10-29 00:30:05,991 Training Epoch [1/40] Iter[184/312]		Loss: 1.8441
2019-10-29 00:30:06,113 Training Epoch [1/40] Iter[185/312]		Loss: 1.8399
2019-10-29 00:30:06,235 Training Epoch [1/40] Iter[186/312]		Loss: 1.8366
2019-10-29 00:30:06,356 Training Epoch [1/40] Iter[187/312]		Loss: 1.8320
2019-10-29 00:30:06,477 Training Epoch [1/40] Iter[188/312]		Loss: 1.8282
2019-10-29 00:30:06,599 Training Epoch [1/40] Iter[189/312]		Loss: 1.8236
2019-10-29 00:30:06,720 Training Epoch [1/40] Iter[190/312]		Loss: 1.8201
2019-10-29 00:30:06,841 Training Epoch [1/40] Iter[191/312]		Loss: 1.8167
2019-10-29 00:30:06,962 Training Epoch [1/40] Iter[192/312]		Loss: 1.8131
2019-10-29 00:30:07,083 Training Epoch [1/40] Iter[193/312]		Loss: 1.8097
2019-10-29 00:30:07,204 Training Epoch [1/40] Iter[194/312]		Loss: 1.8057
2019-10-29 00:30:07,325 Training Epoch [1/40] Iter[195/312]		Loss: 1.8021
2019-10-29 00:30:07,446 Training Epoch [1/40] Iter[196/312]		Loss: 1.7976
2019-10-29 00:30:07,567 Training Epoch [1/40] Iter[197/312]		Loss: 1.7941
2019-10-29 00:30:07,689 Training Epoch [1/40] Iter[198/312]		Loss: 1.7912
2019-10-29 00:30:07,810 Training Epoch [1/40] Iter[199/312]		Loss: 1.7858
2019-10-29 00:30:07,930 Training Epoch [1/40] Iter[200/312]		Loss: 1.7810
2019-10-29 00:30:08,051 Training Epoch [1/40] Iter[201/312]		Loss: 1.7771
2019-10-29 00:30:08,172 Training Epoch [1/40] Iter[202/312]		Loss: 1.7724
2019-10-29 00:30:08,294 Training Epoch [1/40] Iter[203/312]		Loss: 1.7690
2019-10-29 00:30:08,415 Training Epoch [1/40] Iter[204/312]		Loss: 1.7648
2019-10-29 00:30:08,537 Training Epoch [1/40] Iter[205/312]		Loss: 1.7608
2019-10-29 00:30:08,659 Training Epoch [1/40] Iter[206/312]		Loss: 1.7574
2019-10-29 00:30:08,780 Training Epoch [1/40] Iter[207/312]		Loss: 1.7541
2019-10-29 00:30:08,902 Training Epoch [1/40] Iter[208/312]		Loss: 1.7501
2019-10-29 00:30:09,023 Training Epoch [1/40] Iter[209/312]		Loss: 1.7470
2019-10-29 00:30:09,144 Training Epoch [1/40] Iter[210/312]		Loss: 1.7423
2019-10-29 00:30:09,265 Training Epoch [1/40] Iter[211/312]		Loss: 1.7390
2019-10-29 00:30:09,387 Training Epoch [1/40] Iter[212/312]		Loss: 1.7362
2019-10-29 00:30:09,509 Training Epoch [1/40] Iter[213/312]		Loss: 1.7315
2019-10-29 00:30:09,631 Training Epoch [1/40] Iter[214/312]		Loss: 1.7280
2019-10-29 00:30:09,752 Training Epoch [1/40] Iter[215/312]		Loss: 1.7239
2019-10-29 00:30:09,874 Training Epoch [1/40] Iter[216/312]		Loss: 1.7203
2019-10-29 00:30:09,995 Training Epoch [1/40] Iter[217/312]		Loss: 1.7172
2019-10-29 00:30:10,117 Training Epoch [1/40] Iter[218/312]		Loss: 1.7142
2019-10-29 00:30:10,238 Training Epoch [1/40] Iter[219/312]		Loss: 1.7115
2019-10-29 00:30:10,360 Training Epoch [1/40] Iter[220/312]		Loss: 1.7076
2019-10-29 00:30:10,481 Training Epoch [1/40] Iter[221/312]		Loss: 1.7054
2019-10-29 00:30:10,603 Training Epoch [1/40] Iter[222/312]		Loss: 1.7020
2019-10-29 00:30:10,725 Training Epoch [1/40] Iter[223/312]		Loss: 1.6984
2019-10-29 00:30:10,846 Training Epoch [1/40] Iter[224/312]		Loss: 1.6936
2019-10-29 00:30:10,967 Training Epoch [1/40] Iter[225/312]		Loss: 1.6900
2019-10-29 00:30:11,088 Training Epoch [1/40] Iter[226/312]		Loss: 1.6861
2019-10-29 00:30:11,210 Training Epoch [1/40] Iter[227/312]		Loss: 1.6832
2019-10-29 00:30:11,332 Training Epoch [1/40] Iter[228/312]		Loss: 1.6800
2019-10-29 00:30:11,454 Training Epoch [1/40] Iter[229/312]		Loss: 1.6780
2019-10-29 00:30:11,576 Training Epoch [1/40] Iter[230/312]		Loss: 1.6743
2019-10-29 00:30:11,697 Training Epoch [1/40] Iter[231/312]		Loss: 1.6715
2019-10-29 00:30:11,819 Training Epoch [1/40] Iter[232/312]		Loss: 1.6684
2019-10-29 00:30:11,941 Training Epoch [1/40] Iter[233/312]		Loss: 1.6648
2019-10-29 00:30:12,062 Training Epoch [1/40] Iter[234/312]		Loss: 1.6622
2019-10-29 00:30:12,184 Training Epoch [1/40] Iter[235/312]		Loss: 1.6587
2019-10-29 00:30:12,306 Training Epoch [1/40] Iter[236/312]		Loss: 1.6576
2019-10-29 00:30:12,428 Training Epoch [1/40] Iter[237/312]		Loss: 1.6550
2019-10-29 00:30:12,549 Training Epoch [1/40] Iter[238/312]		Loss: 1.6528
2019-10-29 00:30:12,670 Training Epoch [1/40] Iter[239/312]		Loss: 1.6496
2019-10-29 00:30:12,792 Training Epoch [1/40] Iter[240/312]		Loss: 1.6472
2019-10-29 00:30:12,913 Training Epoch [1/40] Iter[241/312]		Loss: 1.6444
2019-10-29 00:30:13,035 Training Epoch [1/40] Iter[242/312]		Loss: 1.6410
2019-10-29 00:30:13,156 Training Epoch [1/40] Iter[243/312]		Loss: 1.6382
2019-10-29 00:30:13,279 Training Epoch [1/40] Iter[244/312]		Loss: 1.6350
2019-10-29 00:30:13,400 Training Epoch [1/40] Iter[245/312]		Loss: 1.6321
2019-10-29 00:30:13,522 Training Epoch [1/40] Iter[246/312]		Loss: 1.6291
2019-10-29 00:30:13,643 Training Epoch [1/40] Iter[247/312]		Loss: 1.6270
2019-10-29 00:30:13,765 Training Epoch [1/40] Iter[248/312]		Loss: 1.6237
2019-10-29 00:30:13,886 Training Epoch [1/40] Iter[249/312]		Loss: 1.6207
2019-10-29 00:30:14,008 Training Epoch [1/40] Iter[250/312]		Loss: 1.6176
2019-10-29 00:30:14,129 Training Epoch [1/40] Iter[251/312]		Loss: 1.6152
2019-10-29 00:30:14,250 Training Epoch [1/40] Iter[252/312]		Loss: 1.6119
2019-10-29 00:30:14,371 Training Epoch [1/40] Iter[253/312]		Loss: 1.6095
2019-10-29 00:30:14,493 Training Epoch [1/40] Iter[254/312]		Loss: 1.6059
2019-10-29 00:30:14,614 Training Epoch [1/40] Iter[255/312]		Loss: 1.6034
2019-10-29 00:30:14,735 Training Epoch [1/40] Iter[256/312]		Loss: 1.6010
2019-10-29 00:30:14,856 Training Epoch [1/40] Iter[257/312]		Loss: 1.5982
2019-10-29 00:30:14,978 Training Epoch [1/40] Iter[258/312]		Loss: 1.5961
2019-10-29 00:30:15,099 Training Epoch [1/40] Iter[259/312]		Loss: 1.5933
2019-10-29 00:30:15,220 Training Epoch [1/40] Iter[260/312]		Loss: 1.5904
2019-10-29 00:30:15,342 Training Epoch [1/40] Iter[261/312]		Loss: 1.5876
2019-10-29 00:30:15,463 Training Epoch [1/40] Iter[262/312]		Loss: 1.5849
2019-10-29 00:30:15,584 Training Epoch [1/40] Iter[263/312]		Loss: 1.5828
2019-10-29 00:30:15,706 Training Epoch [1/40] Iter[264/312]		Loss: 1.5802
2019-10-29 00:30:15,827 Training Epoch [1/40] Iter[265/312]		Loss: 1.5779
2019-10-29 00:30:15,948 Training Epoch [1/40] Iter[266/312]		Loss: 1.5759
2019-10-29 00:30:16,069 Training Epoch [1/40] Iter[267/312]		Loss: 1.5727
2019-10-29 00:30:16,190 Training Epoch [1/40] Iter[268/312]		Loss: 1.5703
2019-10-29 00:30:16,311 Training Epoch [1/40] Iter[269/312]		Loss: 1.5686
2019-10-29 00:30:16,433 Training Epoch [1/40] Iter[270/312]		Loss: 1.5656
2019-10-29 00:30:16,554 Training Epoch [1/40] Iter[271/312]		Loss: 1.5640
2019-10-29 00:30:16,675 Training Epoch [1/40] Iter[272/312]		Loss: 1.5613
2019-10-29 00:30:16,796 Training Epoch [1/40] Iter[273/312]		Loss: 1.5579
2019-10-29 00:30:16,917 Training Epoch [1/40] Iter[274/312]		Loss: 1.5553
2019-10-29 00:30:17,038 Training Epoch [1/40] Iter[275/312]		Loss: 1.5522
2019-10-29 00:30:17,159 Training Epoch [1/40] Iter[276/312]		Loss: 1.5502
2019-10-29 00:30:17,281 Training Epoch [1/40] Iter[277/312]		Loss: 1.5480
2019-10-29 00:30:17,403 Training Epoch [1/40] Iter[278/312]		Loss: 1.5465
2019-10-29 00:30:17,524 Training Epoch [1/40] Iter[279/312]		Loss: 1.5442
2019-10-29 00:30:17,645 Training Epoch [1/40] Iter[280/312]		Loss: 1.5416
2019-10-29 00:30:17,767 Training Epoch [1/40] Iter[281/312]		Loss: 1.5397
2019-10-29 00:30:17,888 Training Epoch [1/40] Iter[282/312]		Loss: 1.5375
2019-10-29 00:30:18,010 Training Epoch [1/40] Iter[283/312]		Loss: 1.5349
2019-10-29 00:30:18,131 Training Epoch [1/40] Iter[284/312]		Loss: 1.5320
2019-10-29 00:30:18,253 Training Epoch [1/40] Iter[285/312]		Loss: 1.5300
2019-10-29 00:30:18,375 Training Epoch [1/40] Iter[286/312]		Loss: 1.5279
2019-10-29 00:30:18,496 Training Epoch [1/40] Iter[287/312]		Loss: 1.5258
2019-10-29 00:30:18,618 Training Epoch [1/40] Iter[288/312]		Loss: 1.5232
2019-10-29 00:30:18,740 Training Epoch [1/40] Iter[289/312]		Loss: 1.5214
2019-10-29 00:30:18,861 Training Epoch [1/40] Iter[290/312]		Loss: 1.5189
2019-10-29 00:30:18,982 Training Epoch [1/40] Iter[291/312]		Loss: 1.5180
2019-10-29 00:30:19,103 Training Epoch [1/40] Iter[292/312]		Loss: 1.5155
2019-10-29 00:30:19,224 Training Epoch [1/40] Iter[293/312]		Loss: 1.5129
2019-10-29 00:30:19,345 Training Epoch [1/40] Iter[294/312]		Loss: 1.5102
2019-10-29 00:30:19,466 Training Epoch [1/40] Iter[295/312]		Loss: 1.5079
2019-10-29 00:30:19,587 Training Epoch [1/40] Iter[296/312]		Loss: 1.5062
2019-10-29 00:30:19,708 Training Epoch [1/40] Iter[297/312]		Loss: 1.5038
2019-10-29 00:30:19,830 Training Epoch [1/40] Iter[298/312]		Loss: 1.5023
2019-10-29 00:30:19,951 Training Epoch [1/40] Iter[299/312]		Loss: 1.5005
2019-10-29 00:30:20,072 Training Epoch [1/40] Iter[300/312]		Loss: 1.4996
2019-10-29 00:30:20,193 Training Epoch [1/40] Iter[301/312]		Loss: 1.4979
2019-10-29 00:30:20,314 Training Epoch [1/40] Iter[302/312]		Loss: 1.4966
2019-10-29 00:30:20,435 Training Epoch [1/40] Iter[303/312]		Loss: 1.4947
2019-10-29 00:30:20,557 Training Epoch [1/40] Iter[304/312]		Loss: 1.4925
2019-10-29 00:30:20,678 Training Epoch [1/40] Iter[305/312]		Loss: 1.4900
2019-10-29 00:30:20,799 Training Epoch [1/40] Iter[306/312]		Loss: 1.4880
2019-10-29 00:30:20,919 Training Epoch [1/40] Iter[307/312]		Loss: 1.4865
2019-10-29 00:30:21,040 Training Epoch [1/40] Iter[308/312]		Loss: 1.4848
2019-10-29 00:30:21,161 Training Epoch [1/40] Iter[309/312]		Loss: 1.4822
2019-10-29 00:30:21,282 Training Epoch [1/40] Iter[310/312]		Loss: 1.4810
2019-10-29 00:30:21,403 Training Epoch [1/40] Iter[311/312]		Loss: 1.4796
2019-10-29 00:30:21,463 Training Epoch [1/40] Iter[312/312]		Loss: 1.4785
2019-10-29 00:30:21,709 Testing Epoch [1/40] Iter[0/62]		Loss: 1.6028
2019-10-29 00:30:21,764 Testing Epoch [1/40] Iter[1/62]		Loss: 1.5792
2019-10-29 00:30:21,801 Testing Epoch [1/40] Iter[2/62]		Loss: 1.4983
2019-10-29 00:30:21,833 Testing Epoch [1/40] Iter[3/62]		Loss: 1.5120
2019-10-29 00:30:21,866 Testing Epoch [1/40] Iter[4/62]		Loss: 1.5400
2019-10-29 00:30:21,897 Testing Epoch [1/40] Iter[5/62]		Loss: 1.4796
2019-10-29 00:30:21,927 Testing Epoch [1/40] Iter[6/62]		Loss: 1.4595
2019-10-29 00:30:21,962 Testing Epoch [1/40] Iter[7/62]		Loss: 1.3959
2019-10-29 00:30:21,992 Testing Epoch [1/40] Iter[8/62]		Loss: 1.4412
2019-10-29 00:30:22,023 Testing Epoch [1/40] Iter[9/62]		Loss: 1.4599
2019-10-29 00:30:22,058 Testing Epoch [1/40] Iter[10/62]		Loss: 1.5123
2019-10-29 00:30:22,089 Testing Epoch [1/40] Iter[11/62]		Loss: 1.5562
2019-10-29 00:30:22,120 Testing Epoch [1/40] Iter[12/62]		Loss: 1.5672
2019-10-29 00:30:22,154 Testing Epoch [1/40] Iter[13/62]		Loss: 1.5991
2019-10-29 00:30:22,185 Testing Epoch [1/40] Iter[14/62]		Loss: 1.6055
2019-10-29 00:30:22,216 Testing Epoch [1/40] Iter[15/62]		Loss: 1.6180
2019-10-29 00:30:22,250 Testing Epoch [1/40] Iter[16/62]		Loss: 1.6137
2019-10-29 00:30:22,281 Testing Epoch [1/40] Iter[17/62]		Loss: 1.6245
2019-10-29 00:30:22,312 Testing Epoch [1/40] Iter[18/62]		Loss: 1.6136
2019-10-29 00:30:22,349 Testing Epoch [1/40] Iter[19/62]		Loss: 1.6136
2019-10-29 00:30:22,380 Testing Epoch [1/40] Iter[20/62]		Loss: 1.6116
2019-10-29 00:30:22,411 Testing Epoch [1/40] Iter[21/62]		Loss: 1.5894
2019-10-29 00:30:22,442 Testing Epoch [1/40] Iter[22/62]		Loss: 1.6119
2019-10-29 00:30:22,472 Testing Epoch [1/40] Iter[23/62]		Loss: 1.6219
2019-10-29 00:30:22,503 Testing Epoch [1/40] Iter[24/62]		Loss: 1.6344
2019-10-29 00:30:22,533 Testing Epoch [1/40] Iter[25/62]		Loss: 1.6377
2019-10-29 00:30:22,564 Testing Epoch [1/40] Iter[26/62]		Loss: 1.6282
2019-10-29 00:30:22,595 Testing Epoch [1/40] Iter[27/62]		Loss: 1.6805
2019-10-29 00:30:22,626 Testing Epoch [1/40] Iter[28/62]		Loss: 1.6691
2019-10-29 00:30:22,656 Testing Epoch [1/40] Iter[29/62]		Loss: 1.6662
2019-10-29 00:30:22,687 Testing Epoch [1/40] Iter[30/62]		Loss: 1.6827
2019-10-29 00:30:22,718 Testing Epoch [1/40] Iter[31/62]		Loss: 1.6811
2019-10-29 00:30:22,748 Testing Epoch [1/40] Iter[32/62]		Loss: 1.6746
2019-10-29 00:30:22,779 Testing Epoch [1/40] Iter[33/62]		Loss: 1.6748
2019-10-29 00:30:22,810 Testing Epoch [1/40] Iter[34/62]		Loss: 1.6792
2019-10-29 00:30:22,841 Testing Epoch [1/40] Iter[35/62]		Loss: 1.6744
2019-10-29 00:30:22,871 Testing Epoch [1/40] Iter[36/62]		Loss: 1.6757
2019-10-29 00:30:22,902 Testing Epoch [1/40] Iter[37/62]		Loss: 1.6773
2019-10-29 00:30:22,933 Testing Epoch [1/40] Iter[38/62]		Loss: 1.6664
2019-10-29 00:30:22,963 Testing Epoch [1/40] Iter[39/62]		Loss: 1.6642
2019-10-29 00:30:22,994 Testing Epoch [1/40] Iter[40/62]		Loss: 1.6656
2019-10-29 00:30:23,025 Testing Epoch [1/40] Iter[41/62]		Loss: 1.6571
2019-10-29 00:30:23,056 Testing Epoch [1/40] Iter[42/62]		Loss: 1.6507
2019-10-29 00:30:23,086 Testing Epoch [1/40] Iter[43/62]		Loss: 1.6697
2019-10-29 00:30:23,117 Testing Epoch [1/40] Iter[44/62]		Loss: 1.6801
2019-10-29 00:30:23,148 Testing Epoch [1/40] Iter[45/62]		Loss: 1.6775
2019-10-29 00:30:23,179 Testing Epoch [1/40] Iter[46/62]		Loss: 1.6792
2019-10-29 00:30:23,209 Testing Epoch [1/40] Iter[47/62]		Loss: 1.6870
2019-10-29 00:30:23,240 Testing Epoch [1/40] Iter[48/62]		Loss: 1.6914
2019-10-29 00:30:23,271 Testing Epoch [1/40] Iter[49/62]		Loss: 1.6874
2019-10-29 00:30:23,302 Testing Epoch [1/40] Iter[50/62]		Loss: 1.6806
2019-10-29 00:30:23,333 Testing Epoch [1/40] Iter[51/62]		Loss: 1.6745
2019-10-29 00:30:23,364 Testing Epoch [1/40] Iter[52/62]		Loss: 1.6710
2019-10-29 00:30:23,394 Testing Epoch [1/40] Iter[53/62]		Loss: 1.6721
2019-10-29 00:30:23,425 Testing Epoch [1/40] Iter[54/62]		Loss: 1.6701
2019-10-29 00:30:23,455 Testing Epoch [1/40] Iter[55/62]		Loss: 1.6689
2019-10-29 00:30:23,486 Testing Epoch [1/40] Iter[56/62]		Loss: 1.6741
2019-10-29 00:30:23,516 Testing Epoch [1/40] Iter[57/62]		Loss: 1.6821
2019-10-29 00:30:23,546 Testing Epoch [1/40] Iter[58/62]		Loss: 1.6782
2019-10-29 00:30:23,577 Testing Epoch [1/40] Iter[59/62]		Loss: 1.6771
2019-10-29 00:30:23,607 Testing Epoch [1/40] Iter[60/62]		Loss: 1.6720
2019-10-29 00:30:23,637 Testing Epoch [1/40] Iter[61/62]		Loss: 1.6827
2019-10-29 00:30:23,655 Testing Epoch [1/40] Iter[62/62]		Loss: 1.6721
2019-10-29 00:30:23,718 Saving the Model
2019-10-29 00:30:23,985 Training Epoch [2/40] Iter[0/312]		Loss: 0.9086
2019-10-29 00:30:24,117 Training Epoch [2/40] Iter[1/312]		Loss: 1.0161
2019-10-29 00:30:24,238 Training Epoch [2/40] Iter[2/312]		Loss: 0.9994
2019-10-29 00:30:24,359 Training Epoch [2/40] Iter[3/312]		Loss: 0.8887
2019-10-29 00:30:24,480 Training Epoch [2/40] Iter[4/312]		Loss: 0.9620
2019-10-29 00:30:24,601 Training Epoch [2/40] Iter[5/312]		Loss: 1.0116
2019-10-29 00:30:24,722 Training Epoch [2/40] Iter[6/312]		Loss: 1.0484
2019-10-29 00:30:24,842 Training Epoch [2/40] Iter[7/312]		Loss: 1.0365
2019-10-29 00:30:24,962 Training Epoch [2/40] Iter[8/312]		Loss: 1.0619
2019-10-29 00:30:25,083 Training Epoch [2/40] Iter[9/312]		Loss: 1.0453
2019-10-29 00:30:25,204 Training Epoch [2/40] Iter[10/312]		Loss: 1.0448
2019-10-29 00:30:25,326 Training Epoch [2/40] Iter[11/312]		Loss: 1.0315
2019-10-29 00:30:25,447 Training Epoch [2/40] Iter[12/312]		Loss: 1.0476
2019-10-29 00:30:25,568 Training Epoch [2/40] Iter[13/312]		Loss: 1.0457
2019-10-29 00:30:25,689 Training Epoch [2/40] Iter[14/312]		Loss: 1.0472
2019-10-29 00:30:25,810 Training Epoch [2/40] Iter[15/312]		Loss: 1.0420
2019-10-29 00:30:25,932 Training Epoch [2/40] Iter[16/312]		Loss: 1.0400
2019-10-29 00:30:26,064 Training Epoch [2/40] Iter[17/312]		Loss: 1.0478
2019-10-29 00:30:26,188 Training Epoch [2/40] Iter[18/312]		Loss: 1.0360
2019-10-29 00:30:26,310 Training Epoch [2/40] Iter[19/312]		Loss: 1.0417
2019-10-29 00:30:26,431 Training Epoch [2/40] Iter[20/312]		Loss: 1.0438
2019-10-29 00:30:26,552 Training Epoch [2/40] Iter[21/312]		Loss: 1.0328
2019-10-29 00:30:26,674 Training Epoch [2/40] Iter[22/312]		Loss: 1.0301
2019-10-29 00:30:26,795 Training Epoch [2/40] Iter[23/312]		Loss: 1.0194
2019-10-29 00:30:26,917 Training Epoch [2/40] Iter[24/312]		Loss: 1.0188
2019-10-29 00:30:27,038 Training Epoch [2/40] Iter[25/312]		Loss: 1.0178
2019-10-29 00:30:27,160 Training Epoch [2/40] Iter[26/312]		Loss: 1.0106
2019-10-29 00:30:27,281 Training Epoch [2/40] Iter[27/312]		Loss: 1.0166
2019-10-29 00:30:27,403 Training Epoch [2/40] Iter[28/312]		Loss: 1.0092
2019-10-29 00:30:27,524 Training Epoch [2/40] Iter[29/312]		Loss: 1.0057
2019-10-29 00:30:27,645 Training Epoch [2/40] Iter[30/312]		Loss: 1.0114
2019-10-29 00:30:27,766 Training Epoch [2/40] Iter[31/312]		Loss: 1.0114
2019-10-29 00:30:27,888 Training Epoch [2/40] Iter[32/312]		Loss: 1.0129
2019-10-29 00:30:28,009 Training Epoch [2/40] Iter[33/312]		Loss: 1.0138
2019-10-29 00:30:28,130 Training Epoch [2/40] Iter[34/312]		Loss: 1.0134
2019-10-29 00:30:28,251 Training Epoch [2/40] Iter[35/312]		Loss: 1.0073
2019-10-29 00:30:28,373 Training Epoch [2/40] Iter[36/312]		Loss: 1.0048
2019-10-29 00:30:28,494 Training Epoch [2/40] Iter[37/312]		Loss: 0.9973
2019-10-29 00:30:28,615 Training Epoch [2/40] Iter[38/312]		Loss: 0.9934
2019-10-29 00:30:28,736 Training Epoch [2/40] Iter[39/312]		Loss: 1.0025
2019-10-29 00:30:28,858 Training Epoch [2/40] Iter[40/312]		Loss: 0.9993
2019-10-29 00:30:28,980 Training Epoch [2/40] Iter[41/312]		Loss: 1.0021
2019-10-29 00:30:29,104 Training Epoch [2/40] Iter[42/312]		Loss: 1.0004
2019-10-29 00:30:29,226 Training Epoch [2/40] Iter[43/312]		Loss: 1.0020
2019-10-29 00:30:29,348 Training Epoch [2/40] Iter[44/312]		Loss: 0.9991
2019-10-29 00:30:29,469 Training Epoch [2/40] Iter[45/312]		Loss: 0.9960
2019-10-29 00:30:29,591 Training Epoch [2/40] Iter[46/312]		Loss: 0.9970
2019-10-29 00:30:29,712 Training Epoch [2/40] Iter[47/312]		Loss: 0.9964
2019-10-29 00:30:29,834 Training Epoch [2/40] Iter[48/312]		Loss: 0.9950
2019-10-29 00:30:29,955 Training Epoch [2/40] Iter[49/312]		Loss: 0.9934
2019-10-29 00:30:30,080 Training Epoch [2/40] Iter[50/312]		Loss: 0.9921
2019-10-29 00:30:30,201 Training Epoch [2/40] Iter[51/312]		Loss: 0.9886
2019-10-29 00:30:30,323 Training Epoch [2/40] Iter[52/312]		Loss: 0.9869
2019-10-29 00:30:30,445 Training Epoch [2/40] Iter[53/312]		Loss: 0.9817
2019-10-29 00:30:30,567 Training Epoch [2/40] Iter[54/312]		Loss: 0.9776
2019-10-29 00:30:30,688 Training Epoch [2/40] Iter[55/312]		Loss: 0.9746
2019-10-29 00:30:30,810 Training Epoch [2/40] Iter[56/312]		Loss: 0.9734
2019-10-29 00:30:30,931 Training Epoch [2/40] Iter[57/312]		Loss: 0.9731
2019-10-29 00:30:31,052 Training Epoch [2/40] Iter[58/312]		Loss: 0.9709
2019-10-29 00:30:31,174 Training Epoch [2/40] Iter[59/312]		Loss: 0.9676
2019-10-29 00:30:31,295 Training Epoch [2/40] Iter[60/312]		Loss: 0.9633
2019-10-29 00:30:31,416 Training Epoch [2/40] Iter[61/312]		Loss: 0.9609
2019-10-29 00:30:31,538 Training Epoch [2/40] Iter[62/312]		Loss: 0.9570
2019-10-29 00:30:31,659 Training Epoch [2/40] Iter[63/312]		Loss: 0.9549
2019-10-29 00:30:31,781 Training Epoch [2/40] Iter[64/312]		Loss: 0.9535
2019-10-29 00:30:31,902 Training Epoch [2/40] Iter[65/312]		Loss: 0.9506
2019-10-29 00:30:32,023 Training Epoch [2/40] Iter[66/312]		Loss: 0.9467
2019-10-29 00:30:32,144 Training Epoch [2/40] Iter[67/312]		Loss: 0.9452
2019-10-29 00:30:32,266 Training Epoch [2/40] Iter[68/312]		Loss: 0.9442
2019-10-29 00:30:32,388 Training Epoch [2/40] Iter[69/312]		Loss: 0.9416
2019-10-29 00:30:32,509 Training Epoch [2/40] Iter[70/312]		Loss: 0.9394
2019-10-29 00:30:32,631 Training Epoch [2/40] Iter[71/312]		Loss: 0.9372
2019-10-29 00:30:32,752 Training Epoch [2/40] Iter[72/312]		Loss: 0.9364
2019-10-29 00:30:32,873 Training Epoch [2/40] Iter[73/312]		Loss: 0.9346
2019-10-29 00:30:32,994 Training Epoch [2/40] Iter[74/312]		Loss: 0.9346
2019-10-29 00:30:33,116 Training Epoch [2/40] Iter[75/312]		Loss: 0.9324
2019-10-29 00:30:33,237 Training Epoch [2/40] Iter[76/312]		Loss: 0.9350
2019-10-29 00:30:33,359 Training Epoch [2/40] Iter[77/312]		Loss: 0.9323
2019-10-29 00:30:33,480 Training Epoch [2/40] Iter[78/312]		Loss: 0.9316
2019-10-29 00:30:33,601 Training Epoch [2/40] Iter[79/312]		Loss: 0.9290
2019-10-29 00:30:33,722 Training Epoch [2/40] Iter[80/312]		Loss: 0.9277
2019-10-29 00:30:33,843 Training Epoch [2/40] Iter[81/312]		Loss: 0.9267
2019-10-29 00:30:33,964 Training Epoch [2/40] Iter[82/312]		Loss: 0.9237
2019-10-29 00:30:34,085 Training Epoch [2/40] Iter[83/312]		Loss: 0.9203
2019-10-29 00:30:34,207 Training Epoch [2/40] Iter[84/312]		Loss: 0.9215
2019-10-29 00:30:34,329 Training Epoch [2/40] Iter[85/312]		Loss: 0.9197
2019-10-29 00:30:34,451 Training Epoch [2/40] Iter[86/312]		Loss: 0.9174
2019-10-29 00:30:34,572 Training Epoch [2/40] Iter[87/312]		Loss: 0.9160
2019-10-29 00:30:34,693 Training Epoch [2/40] Iter[88/312]		Loss: 0.9152
2019-10-29 00:30:34,815 Training Epoch [2/40] Iter[89/312]		Loss: 0.9146
2019-10-29 00:30:34,936 Training Epoch [2/40] Iter[90/312]		Loss: 0.9153
2019-10-29 00:30:35,057 Training Epoch [2/40] Iter[91/312]		Loss: 0.9162
2019-10-29 00:30:35,179 Training Epoch [2/40] Iter[92/312]		Loss: 0.9156
2019-10-29 00:30:35,301 Training Epoch [2/40] Iter[93/312]		Loss: 0.9132
2019-10-29 00:30:35,424 Training Epoch [2/40] Iter[94/312]		Loss: 0.9106
2019-10-29 00:30:35,545 Training Epoch [2/40] Iter[95/312]		Loss: 0.9086
2019-10-29 00:30:35,667 Training Epoch [2/40] Iter[96/312]		Loss: 0.9077
2019-10-29 00:30:35,789 Training Epoch [2/40] Iter[97/312]		Loss: 0.9064
2019-10-29 00:30:35,912 Training Epoch [2/40] Iter[98/312]		Loss: 0.9097
2019-10-29 00:30:36,034 Training Epoch [2/40] Iter[99/312]		Loss: 0.9071
2019-10-29 00:30:36,155 Training Epoch [2/40] Iter[100/312]		Loss: 0.9063
2019-10-29 00:30:36,276 Training Epoch [2/40] Iter[101/312]		Loss: 0.9051
2019-10-29 00:30:36,398 Training Epoch [2/40] Iter[102/312]		Loss: 0.9035
2019-10-29 00:30:36,519 Training Epoch [2/40] Iter[103/312]		Loss: 0.9028
2019-10-29 00:30:36,641 Training Epoch [2/40] Iter[104/312]		Loss: 0.9011
2019-10-29 00:30:36,762 Training Epoch [2/40] Iter[105/312]		Loss: 0.8994
2019-10-29 00:30:36,883 Training Epoch [2/40] Iter[106/312]		Loss: 0.8992
2019-10-29 00:30:37,004 Training Epoch [2/40] Iter[107/312]		Loss: 0.8994
2019-10-29 00:30:37,125 Training Epoch [2/40] Iter[108/312]		Loss: 0.8992
2019-10-29 00:30:37,247 Training Epoch [2/40] Iter[109/312]		Loss: 0.8978
2019-10-29 00:30:37,369 Training Epoch [2/40] Iter[110/312]		Loss: 0.8970
2019-10-29 00:30:37,491 Training Epoch [2/40] Iter[111/312]		Loss: 0.8969
2019-10-29 00:30:37,612 Training Epoch [2/40] Iter[112/312]		Loss: 0.8949
2019-10-29 00:30:37,734 Training Epoch [2/40] Iter[113/312]		Loss: 0.8937
2019-10-29 00:30:37,855 Training Epoch [2/40] Iter[114/312]		Loss: 0.8924
2019-10-29 00:30:37,976 Training Epoch [2/40] Iter[115/312]		Loss: 0.8917
2019-10-29 00:30:38,098 Training Epoch [2/40] Iter[116/312]		Loss: 0.8938
2019-10-29 00:30:38,219 Training Epoch [2/40] Iter[117/312]		Loss: 0.8928
2019-10-29 00:30:38,340 Training Epoch [2/40] Iter[118/312]		Loss: 0.8911
2019-10-29 00:30:38,462 Training Epoch [2/40] Iter[119/312]		Loss: 0.8904
2019-10-29 00:30:38,584 Training Epoch [2/40] Iter[120/312]		Loss: 0.8898
2019-10-29 00:30:38,706 Training Epoch [2/40] Iter[121/312]		Loss: 0.8905
2019-10-29 00:30:38,828 Training Epoch [2/40] Iter[122/312]		Loss: 0.8926
2019-10-29 00:30:38,949 Training Epoch [2/40] Iter[123/312]		Loss: 0.8930
2019-10-29 00:30:39,071 Training Epoch [2/40] Iter[124/312]		Loss: 0.8923
2019-10-29 00:30:39,192 Training Epoch [2/40] Iter[125/312]		Loss: 0.8928
2019-10-29 00:30:39,313 Training Epoch [2/40] Iter[126/312]		Loss: 0.8934
2019-10-29 00:30:39,435 Training Epoch [2/40] Iter[127/312]		Loss: 0.8919
2019-10-29 00:30:39,557 Training Epoch [2/40] Iter[128/312]		Loss: 0.8914
2019-10-29 00:30:39,679 Training Epoch [2/40] Iter[129/312]		Loss: 0.8917
2019-10-29 00:30:39,800 Training Epoch [2/40] Iter[130/312]		Loss: 0.8926
2019-10-29 00:30:39,921 Training Epoch [2/40] Iter[131/312]		Loss: 0.8948
2019-10-29 00:30:40,043 Training Epoch [2/40] Iter[132/312]		Loss: 0.8946
2019-10-29 00:30:40,164 Training Epoch [2/40] Iter[133/312]		Loss: 0.8930
2019-10-29 00:30:40,286 Training Epoch [2/40] Iter[134/312]		Loss: 0.8930
2019-10-29 00:30:40,408 Training Epoch [2/40] Iter[135/312]		Loss: 0.8932
2019-10-29 00:30:40,529 Training Epoch [2/40] Iter[136/312]		Loss: 0.8929
2019-10-29 00:30:40,650 Training Epoch [2/40] Iter[137/312]		Loss: 0.8922
2019-10-29 00:30:40,771 Training Epoch [2/40] Iter[138/312]		Loss: 0.8914
2019-10-29 00:30:40,893 Training Epoch [2/40] Iter[139/312]		Loss: 0.8910
2019-10-29 00:30:41,014 Training Epoch [2/40] Iter[140/312]		Loss: 0.8928
2019-10-29 00:30:41,135 Training Epoch [2/40] Iter[141/312]		Loss: 0.8919
2019-10-29 00:30:41,257 Training Epoch [2/40] Iter[142/312]		Loss: 0.8917
2019-10-29 00:30:41,378 Training Epoch [2/40] Iter[143/312]		Loss: 0.8908
2019-10-29 00:30:41,500 Training Epoch [2/40] Iter[144/312]		Loss: 0.8902
2019-10-29 00:30:41,621 Training Epoch [2/40] Iter[145/312]		Loss: 0.8880
2019-10-29 00:30:41,743 Training Epoch [2/40] Iter[146/312]		Loss: 0.8890
2019-10-29 00:30:41,865 Training Epoch [2/40] Iter[147/312]		Loss: 0.8880
2019-10-29 00:30:41,986 Training Epoch [2/40] Iter[148/312]		Loss: 0.8862
2019-10-29 00:30:42,107 Training Epoch [2/40] Iter[149/312]		Loss: 0.8871
2019-10-29 00:30:42,228 Training Epoch [2/40] Iter[150/312]		Loss: 0.8872
2019-10-29 00:30:42,350 Training Epoch [2/40] Iter[151/312]		Loss: 0.8869
2019-10-29 00:30:42,476 Training Epoch [2/40] Iter[152/312]		Loss: 0.8871
2019-10-29 00:30:42,598 Training Epoch [2/40] Iter[153/312]		Loss: 0.8882
2019-10-29 00:30:42,719 Training Epoch [2/40] Iter[154/312]		Loss: 0.8870
2019-10-29 00:30:42,841 Training Epoch [2/40] Iter[155/312]		Loss: 0.8870
2019-10-29 00:30:42,962 Training Epoch [2/40] Iter[156/312]		Loss: 0.8860
2019-10-29 00:30:43,084 Training Epoch [2/40] Iter[157/312]		Loss: 0.8860
2019-10-29 00:30:43,206 Training Epoch [2/40] Iter[158/312]		Loss: 0.8867
2019-10-29 00:30:43,327 Training Epoch [2/40] Iter[159/312]		Loss: 0.8878
2019-10-29 00:30:43,449 Training Epoch [2/40] Iter[160/312]		Loss: 0.8876
2019-10-29 00:30:43,570 Training Epoch [2/40] Iter[161/312]		Loss: 0.8885
2019-10-29 00:30:43,692 Training Epoch [2/40] Iter[162/312]		Loss: 0.8885
2019-10-29 00:30:43,814 Training Epoch [2/40] Iter[163/312]		Loss: 0.8874
2019-10-29 00:30:43,935 Training Epoch [2/40] Iter[164/312]		Loss: 0.8862
2019-10-29 00:30:44,057 Training Epoch [2/40] Iter[165/312]		Loss: 0.8869
2019-10-29 00:30:44,179 Training Epoch [2/40] Iter[166/312]		Loss: 0.8868
2019-10-29 00:30:44,301 Training Epoch [2/40] Iter[167/312]		Loss: 0.8868
2019-10-29 00:30:44,423 Training Epoch [2/40] Iter[168/312]		Loss: 0.8866
2019-10-29 00:30:44,544 Training Epoch [2/40] Iter[169/312]		Loss: 0.8862
2019-10-29 00:30:44,666 Training Epoch [2/40] Iter[170/312]		Loss: 0.8874
2019-10-29 00:30:44,787 Training Epoch [2/40] Iter[171/312]		Loss: 0.8872
2019-10-29 00:30:44,908 Training Epoch [2/40] Iter[172/312]		Loss: 0.8879
2019-10-29 00:30:45,030 Training Epoch [2/40] Iter[173/312]		Loss: 0.8868
2019-10-29 00:30:45,151 Training Epoch [2/40] Iter[174/312]		Loss: 0.8858
2019-10-29 00:30:45,272 Training Epoch [2/40] Iter[175/312]		Loss: 0.8851
2019-10-29 00:30:45,393 Training Epoch [2/40] Iter[176/312]		Loss: 0.8851
2019-10-29 00:30:45,515 Training Epoch [2/40] Iter[177/312]		Loss: 0.8832
2019-10-29 00:30:45,636 Training Epoch [2/40] Iter[178/312]		Loss: 0.8813
2019-10-29 00:30:45,757 Training Epoch [2/40] Iter[179/312]		Loss: 0.8818
2019-10-29 00:30:45,879 Training Epoch [2/40] Iter[180/312]		Loss: 0.8817
2019-10-29 00:30:46,000 Training Epoch [2/40] Iter[181/312]		Loss: 0.8809
2019-10-29 00:30:46,122 Training Epoch [2/40] Iter[182/312]		Loss: 0.8810
2019-10-29 00:30:46,244 Training Epoch [2/40] Iter[183/312]		Loss: 0.8809
2019-10-29 00:30:46,365 Training Epoch [2/40] Iter[184/312]		Loss: 0.8808
2019-10-29 00:30:46,486 Training Epoch [2/40] Iter[185/312]		Loss: 0.8806
2019-10-29 00:30:46,607 Training Epoch [2/40] Iter[186/312]		Loss: 0.8811
2019-10-29 00:30:46,729 Training Epoch [2/40] Iter[187/312]		Loss: 0.8823
2019-10-29 00:30:46,850 Training Epoch [2/40] Iter[188/312]		Loss: 0.8819
2019-10-29 00:30:46,971 Training Epoch [2/40] Iter[189/312]		Loss: 0.8826
2019-10-29 00:30:47,093 Training Epoch [2/40] Iter[190/312]		Loss: 0.8818
2019-10-29 00:30:47,215 Training Epoch [2/40] Iter[191/312]		Loss: 0.8816
2019-10-29 00:30:47,336 Training Epoch [2/40] Iter[192/312]		Loss: 0.8815
2019-10-29 00:30:47,458 Training Epoch [2/40] Iter[193/312]		Loss: 0.8811
2019-10-29 00:30:47,579 Training Epoch [2/40] Iter[194/312]		Loss: 0.8812
2019-10-29 00:30:47,701 Training Epoch [2/40] Iter[195/312]		Loss: 0.8808
2019-10-29 00:30:47,822 Training Epoch [2/40] Iter[196/312]		Loss: 0.8811
2019-10-29 00:30:47,943 Training Epoch [2/40] Iter[197/312]		Loss: 0.8805
2019-10-29 00:30:48,065 Training Epoch [2/40] Iter[198/312]		Loss: 0.8802
2019-10-29 00:30:48,186 Training Epoch [2/40] Iter[199/312]		Loss: 0.8787
2019-10-29 00:30:48,308 Training Epoch [2/40] Iter[200/312]		Loss: 0.8784
2019-10-29 00:30:48,429 Training Epoch [2/40] Iter[201/312]		Loss: 0.8772
2019-10-29 00:30:48,551 Training Epoch [2/40] Iter[202/312]		Loss: 0.8772
2019-10-29 00:30:48,672 Training Epoch [2/40] Iter[203/312]		Loss: 0.8777
2019-10-29 00:30:48,793 Training Epoch [2/40] Iter[204/312]		Loss: 0.8765
2019-10-29 00:30:48,914 Training Epoch [2/40] Iter[205/312]		Loss: 0.8765
2019-10-29 00:30:49,035 Training Epoch [2/40] Iter[206/312]		Loss: 0.8770
2019-10-29 00:30:49,156 Training Epoch [2/40] Iter[207/312]		Loss: 0.8775
2019-10-29 00:30:49,278 Training Epoch [2/40] Iter[208/312]		Loss: 0.8777
2019-10-29 00:30:49,399 Training Epoch [2/40] Iter[209/312]		Loss: 0.8775
2019-10-29 00:30:49,521 Training Epoch [2/40] Iter[210/312]		Loss: 0.8772
2019-10-29 00:30:49,642 Training Epoch [2/40] Iter[211/312]		Loss: 0.8781
2019-10-29 00:30:49,763 Training Epoch [2/40] Iter[212/312]		Loss: 0.8777
2019-10-29 00:30:49,884 Training Epoch [2/40] Iter[213/312]		Loss: 0.8777
2019-10-29 00:30:50,005 Training Epoch [2/40] Iter[214/312]		Loss: 0.8770
2019-10-29 00:30:50,126 Training Epoch [2/40] Iter[215/312]		Loss: 0.8777
2019-10-29 00:30:50,247 Training Epoch [2/40] Iter[216/312]		Loss: 0.8771
2019-10-29 00:30:50,368 Training Epoch [2/40] Iter[217/312]		Loss: 0.8766
2019-10-29 00:30:50,489 Training Epoch [2/40] Iter[218/312]		Loss: 0.8767
2019-10-29 00:30:50,611 Training Epoch [2/40] Iter[219/312]		Loss: 0.8768
2019-10-29 00:30:50,732 Training Epoch [2/40] Iter[220/312]		Loss: 0.8774
2019-10-29 00:30:50,853 Training Epoch [2/40] Iter[221/312]		Loss: 0.8765
2019-10-29 00:30:50,975 Training Epoch [2/40] Iter[222/312]		Loss: 0.8762
2019-10-29 00:30:51,097 Training Epoch [2/40] Iter[223/312]		Loss: 0.8755
2019-10-29 00:30:51,218 Training Epoch [2/40] Iter[224/312]		Loss: 0.8757
2019-10-29 00:30:51,340 Training Epoch [2/40] Iter[225/312]		Loss: 0.8755
2019-10-29 00:30:51,462 Training Epoch [2/40] Iter[226/312]		Loss: 0.8751
2019-10-29 00:30:51,583 Training Epoch [2/40] Iter[227/312]		Loss: 0.8747
2019-10-29 00:30:51,704 Training Epoch [2/40] Iter[228/312]		Loss: 0.8754
2019-10-29 00:30:51,826 Training Epoch [2/40] Iter[229/312]		Loss: 0.8750
2019-10-29 00:30:51,948 Training Epoch [2/40] Iter[230/312]		Loss: 0.8748
2019-10-29 00:30:52,070 Training Epoch [2/40] Iter[231/312]		Loss: 0.8738
2019-10-29 00:30:52,192 Training Epoch [2/40] Iter[232/312]		Loss: 0.8725
2019-10-29 00:30:52,313 Training Epoch [2/40] Iter[233/312]		Loss: 0.8724
2019-10-29 00:30:52,435 Training Epoch [2/40] Iter[234/312]		Loss: 0.8718
2019-10-29 00:30:52,557 Training Epoch [2/40] Iter[235/312]		Loss: 0.8703
2019-10-29 00:30:52,678 Training Epoch [2/40] Iter[236/312]		Loss: 0.8707
2019-10-29 00:30:52,799 Training Epoch [2/40] Iter[237/312]		Loss: 0.8702
2019-10-29 00:30:52,920 Training Epoch [2/40] Iter[238/312]		Loss: 0.8699
2019-10-29 00:30:53,041 Training Epoch [2/40] Iter[239/312]		Loss: 0.8699
2019-10-29 00:30:53,162 Training Epoch [2/40] Iter[240/312]		Loss: 0.8694
2019-10-29 00:30:53,283 Training Epoch [2/40] Iter[241/312]		Loss: 0.8690
2019-10-29 00:30:53,405 Training Epoch [2/40] Iter[242/312]		Loss: 0.8686
2019-10-29 00:30:53,525 Training Epoch [2/40] Iter[243/312]		Loss: 0.8681
2019-10-29 00:30:53,647 Training Epoch [2/40] Iter[244/312]		Loss: 0.8677
2019-10-29 00:30:53,768 Training Epoch [2/40] Iter[245/312]		Loss: 0.8668
2019-10-29 00:30:53,889 Training Epoch [2/40] Iter[246/312]		Loss: 0.8665
2019-10-29 00:30:54,010 Training Epoch [2/40] Iter[247/312]		Loss: 0.8669
2019-10-29 00:30:54,132 Training Epoch [2/40] Iter[248/312]		Loss: 0.8670
2019-10-29 00:30:54,254 Training Epoch [2/40] Iter[249/312]		Loss: 0.8670
2019-10-29 00:30:54,375 Training Epoch [2/40] Iter[250/312]		Loss: 0.8661
2019-10-29 00:30:54,497 Training Epoch [2/40] Iter[251/312]		Loss: 0.8662
2019-10-29 00:30:54,618 Training Epoch [2/40] Iter[252/312]		Loss: 0.8668
2019-10-29 00:30:54,740 Training Epoch [2/40] Iter[253/312]		Loss: 0.8671
2019-10-29 00:30:54,861 Training Epoch [2/40] Iter[254/312]		Loss: 0.8678
2019-10-29 00:30:54,983 Training Epoch [2/40] Iter[255/312]		Loss: 0.8675
2019-10-29 00:30:55,104 Training Epoch [2/40] Iter[256/312]		Loss: 0.8664
2019-10-29 00:30:55,226 Training Epoch [2/40] Iter[257/312]		Loss: 0.8657
2019-10-29 00:30:55,348 Training Epoch [2/40] Iter[258/312]		Loss: 0.8655
2019-10-29 00:30:55,470 Training Epoch [2/40] Iter[259/312]		Loss: 0.8657
2019-10-29 00:30:55,592 Training Epoch [2/40] Iter[260/312]		Loss: 0.8656
2019-10-29 00:30:55,713 Training Epoch [2/40] Iter[261/312]		Loss: 0.8648
2019-10-29 00:30:55,835 Training Epoch [2/40] Iter[262/312]		Loss: 0.8650
2019-10-29 00:30:55,956 Training Epoch [2/40] Iter[263/312]		Loss: 0.8644
2019-10-29 00:30:56,077 Training Epoch [2/40] Iter[264/312]		Loss: 0.8638
2019-10-29 00:30:56,199 Training Epoch [2/40] Iter[265/312]		Loss: 0.8626
2019-10-29 00:30:56,320 Training Epoch [2/40] Iter[266/312]		Loss: 0.8624
2019-10-29 00:30:56,442 Training Epoch [2/40] Iter[267/312]		Loss: 0.8621
2019-10-29 00:30:56,563 Training Epoch [2/40] Iter[268/312]		Loss: 0.8616
2019-10-29 00:30:56,685 Training Epoch [2/40] Iter[269/312]		Loss: 0.8611
2019-10-29 00:30:56,806 Training Epoch [2/40] Iter[270/312]		Loss: 0.8611
2019-10-29 00:30:56,927 Training Epoch [2/40] Iter[271/312]		Loss: 0.8610
2019-10-29 00:30:57,049 Training Epoch [2/40] Iter[272/312]		Loss: 0.8614
2019-10-29 00:30:57,171 Training Epoch [2/40] Iter[273/312]		Loss: 0.8614
2019-10-29 00:30:57,293 Training Epoch [2/40] Iter[274/312]		Loss: 0.8613
2019-10-29 00:30:57,415 Training Epoch [2/40] Iter[275/312]		Loss: 0.8610
2019-10-29 00:30:57,537 Training Epoch [2/40] Iter[276/312]		Loss: 0.8609
2019-10-29 00:30:57,658 Training Epoch [2/40] Iter[277/312]		Loss: 0.8608
2019-10-29 00:30:57,779 Training Epoch [2/40] Iter[278/312]		Loss: 0.8604
2019-10-29 00:30:57,901 Training Epoch [2/40] Iter[279/312]		Loss: 0.8603
2019-10-29 00:30:58,022 Training Epoch [2/40] Iter[280/312]		Loss: 0.8603
2019-10-29 00:30:58,143 Training Epoch [2/40] Iter[281/312]		Loss: 0.8598
2019-10-29 00:30:58,264 Training Epoch [2/40] Iter[282/312]		Loss: 0.8594
2019-10-29 00:30:58,385 Training Epoch [2/40] Iter[283/312]		Loss: 0.8592
2019-10-29 00:30:58,506 Training Epoch [2/40] Iter[284/312]		Loss: 0.8585
2019-10-29 00:30:58,627 Training Epoch [2/40] Iter[285/312]		Loss: 0.8580
2019-10-29 00:30:58,748 Training Epoch [2/40] Iter[286/312]		Loss: 0.8579
2019-10-29 00:30:58,869 Training Epoch [2/40] Iter[287/312]		Loss: 0.8574
2019-10-29 00:30:58,990 Training Epoch [2/40] Iter[288/312]		Loss: 0.8571
2019-10-29 00:30:59,111 Training Epoch [2/40] Iter[289/312]		Loss: 0.8566
2019-10-29 00:30:59,232 Training Epoch [2/40] Iter[290/312]		Loss: 0.8566
2019-10-29 00:30:59,354 Training Epoch [2/40] Iter[291/312]		Loss: 0.8559
2019-10-29 00:30:59,475 Training Epoch [2/40] Iter[292/312]		Loss: 0.8557
2019-10-29 00:30:59,597 Training Epoch [2/40] Iter[293/312]		Loss: 0.8558
2019-10-29 00:30:59,718 Training Epoch [2/40] Iter[294/312]		Loss: 0.8553
2019-10-29 00:30:59,840 Training Epoch [2/40] Iter[295/312]		Loss: 0.8548
2019-10-29 00:30:59,961 Training Epoch [2/40] Iter[296/312]		Loss: 0.8537
2019-10-29 00:31:00,083 Training Epoch [2/40] Iter[297/312]		Loss: 0.8533
2019-10-29 00:31:00,204 Training Epoch [2/40] Iter[298/312]		Loss: 0.8529
2019-10-29 00:31:00,326 Training Epoch [2/40] Iter[299/312]		Loss: 0.8529
2019-10-29 00:31:00,447 Training Epoch [2/40] Iter[300/312]		Loss: 0.8529
2019-10-29 00:31:00,569 Training Epoch [2/40] Iter[301/312]		Loss: 0.8525
2019-10-29 00:31:00,691 Training Epoch [2/40] Iter[302/312]		Loss: 0.8522
2019-10-29 00:31:00,813 Training Epoch [2/40] Iter[303/312]		Loss: 0.8517
2019-10-29 00:31:00,934 Training Epoch [2/40] Iter[304/312]		Loss: 0.8514
2019-10-29 00:31:01,055 Training Epoch [2/40] Iter[305/312]		Loss: 0.8514
2019-10-29 00:31:01,175 Training Epoch [2/40] Iter[306/312]		Loss: 0.8502
2019-10-29 00:31:01,296 Training Epoch [2/40] Iter[307/312]		Loss: 0.8495
2019-10-29 00:31:01,417 Training Epoch [2/40] Iter[308/312]		Loss: 0.8494
2019-10-29 00:31:01,538 Training Epoch [2/40] Iter[309/312]		Loss: 0.8489
2019-10-29 00:31:01,658 Training Epoch [2/40] Iter[310/312]		Loss: 0.8487
2019-10-29 00:31:01,779 Training Epoch [2/40] Iter[311/312]		Loss: 0.8488
2019-10-29 00:31:01,840 Training Epoch [2/40] Iter[312/312]		Loss: 0.8482
2019-10-29 00:31:02,097 Testing Epoch [2/40] Iter[0/62]		Loss: 1.8935
2019-10-29 00:31:02,127 Testing Epoch [2/40] Iter[1/62]		Loss: 1.7733
2019-10-29 00:31:02,175 Testing Epoch [2/40] Iter[2/62]		Loss: 1.7289
2019-10-29 00:31:02,210 Testing Epoch [2/40] Iter[3/62]		Loss: 1.7292
2019-10-29 00:31:02,240 Testing Epoch [2/40] Iter[4/62]		Loss: 1.7308
2019-10-29 00:31:02,270 Testing Epoch [2/40] Iter[5/62]		Loss: 1.6965
2019-10-29 00:31:02,301 Testing Epoch [2/40] Iter[6/62]		Loss: 1.7098
2019-10-29 00:31:02,332 Testing Epoch [2/40] Iter[7/62]		Loss: 1.6572
2019-10-29 00:31:02,363 Testing Epoch [2/40] Iter[8/62]		Loss: 1.6478
2019-10-29 00:31:02,393 Testing Epoch [2/40] Iter[9/62]		Loss: 1.6659
2019-10-29 00:31:02,424 Testing Epoch [2/40] Iter[10/62]		Loss: 1.6680
2019-10-29 00:31:02,455 Testing Epoch [2/40] Iter[11/62]		Loss: 1.6884
2019-10-29 00:31:02,485 Testing Epoch [2/40] Iter[12/62]		Loss: 1.7099
2019-10-29 00:31:02,516 Testing Epoch [2/40] Iter[13/62]		Loss: 1.7321
2019-10-29 00:31:02,547 Testing Epoch [2/40] Iter[14/62]		Loss: 1.7308
2019-10-29 00:31:02,578 Testing Epoch [2/40] Iter[15/62]		Loss: 1.7544
2019-10-29 00:31:02,609 Testing Epoch [2/40] Iter[16/62]		Loss: 1.7475
2019-10-29 00:31:02,640 Testing Epoch [2/40] Iter[17/62]		Loss: 1.7577
2019-10-29 00:31:02,671 Testing Epoch [2/40] Iter[18/62]		Loss: 1.7373
2019-10-29 00:31:02,702 Testing Epoch [2/40] Iter[19/62]		Loss: 1.7462
2019-10-29 00:31:02,733 Testing Epoch [2/40] Iter[20/62]		Loss: 1.7468
2019-10-29 00:31:02,763 Testing Epoch [2/40] Iter[21/62]		Loss: 1.7354
2019-10-29 00:31:02,794 Testing Epoch [2/40] Iter[22/62]		Loss: 1.7548
2019-10-29 00:31:02,825 Testing Epoch [2/40] Iter[23/62]		Loss: 1.7744
2019-10-29 00:31:02,856 Testing Epoch [2/40] Iter[24/62]		Loss: 1.7949
2019-10-29 00:31:02,886 Testing Epoch [2/40] Iter[25/62]		Loss: 1.7994
2019-10-29 00:31:02,917 Testing Epoch [2/40] Iter[26/62]		Loss: 1.7898
2019-10-29 00:31:02,947 Testing Epoch [2/40] Iter[27/62]		Loss: 1.8175
2019-10-29 00:31:02,978 Testing Epoch [2/40] Iter[28/62]		Loss: 1.8139
2019-10-29 00:31:03,009 Testing Epoch [2/40] Iter[29/62]		Loss: 1.8042
2019-10-29 00:31:03,040 Testing Epoch [2/40] Iter[30/62]		Loss: 1.8256
2019-10-29 00:31:03,071 Testing Epoch [2/40] Iter[31/62]		Loss: 1.8297
2019-10-29 00:31:03,101 Testing Epoch [2/40] Iter[32/62]		Loss: 1.8213
2019-10-29 00:31:03,132 Testing Epoch [2/40] Iter[33/62]		Loss: 1.8252
2019-10-29 00:31:03,163 Testing Epoch [2/40] Iter[34/62]		Loss: 1.8219
2019-10-29 00:31:03,194 Testing Epoch [2/40] Iter[35/62]		Loss: 1.8193
2019-10-29 00:31:03,225 Testing Epoch [2/40] Iter[36/62]		Loss: 1.8233
2019-10-29 00:31:03,256 Testing Epoch [2/40] Iter[37/62]		Loss: 1.8212
2019-10-29 00:31:03,286 Testing Epoch [2/40] Iter[38/62]		Loss: 1.8122
2019-10-29 00:31:03,317 Testing Epoch [2/40] Iter[39/62]		Loss: 1.8054
2019-10-29 00:31:03,348 Testing Epoch [2/40] Iter[40/62]		Loss: 1.8073
2019-10-29 00:31:03,379 Testing Epoch [2/40] Iter[41/62]		Loss: 1.7934
2019-10-29 00:31:03,409 Testing Epoch [2/40] Iter[42/62]		Loss: 1.7897
2019-10-29 00:31:03,440 Testing Epoch [2/40] Iter[43/62]		Loss: 1.8061
2019-10-29 00:31:03,471 Testing Epoch [2/40] Iter[44/62]		Loss: 1.8029
2019-10-29 00:31:03,502 Testing Epoch [2/40] Iter[45/62]		Loss: 1.8063
2019-10-29 00:31:03,533 Testing Epoch [2/40] Iter[46/62]		Loss: 1.8019
2019-10-29 00:31:03,563 Testing Epoch [2/40] Iter[47/62]		Loss: 1.8038
2019-10-29 00:31:03,594 Testing Epoch [2/40] Iter[48/62]		Loss: 1.8088
2019-10-29 00:31:03,625 Testing Epoch [2/40] Iter[49/62]		Loss: 1.8038
2019-10-29 00:31:03,656 Testing Epoch [2/40] Iter[50/62]		Loss: 1.8006
2019-10-29 00:31:03,686 Testing Epoch [2/40] Iter[51/62]		Loss: 1.7969
2019-10-29 00:31:03,717 Testing Epoch [2/40] Iter[52/62]		Loss: 1.8010
2019-10-29 00:31:03,748 Testing Epoch [2/40] Iter[53/62]		Loss: 1.8047
2019-10-29 00:31:03,779 Testing Epoch [2/40] Iter[54/62]		Loss: 1.8032
2019-10-29 00:31:03,810 Testing Epoch [2/40] Iter[55/62]		Loss: 1.8016
2019-10-29 00:31:03,841 Testing Epoch [2/40] Iter[56/62]		Loss: 1.8050
2019-10-29 00:31:03,871 Testing Epoch [2/40] Iter[57/62]		Loss: 1.8104
2019-10-29 00:31:03,902 Testing Epoch [2/40] Iter[58/62]		Loss: 1.8129
2019-10-29 00:31:03,932 Testing Epoch [2/40] Iter[59/62]		Loss: 1.8150
2019-10-29 00:31:03,963 Testing Epoch [2/40] Iter[60/62]		Loss: 1.8146
2019-10-29 00:31:03,993 Testing Epoch [2/40] Iter[61/62]		Loss: 1.8175
2019-10-29 00:31:04,011 Testing Epoch [2/40] Iter[62/62]		Loss: 1.8159
2019-10-29 00:31:04,365 Training Epoch [3/40] Iter[0/312]		Loss: 0.8018
2019-10-29 00:31:04,486 Training Epoch [3/40] Iter[1/312]		Loss: 0.8864
2019-10-29 00:31:04,607 Training Epoch [3/40] Iter[2/312]		Loss: 0.9172
2019-10-29 00:31:04,729 Training Epoch [3/40] Iter[3/312]		Loss: 0.8856
2019-10-29 00:31:04,852 Training Epoch [3/40] Iter[4/312]		Loss: 0.8333
2019-10-29 00:31:04,972 Training Epoch [3/40] Iter[5/312]		Loss: 0.8079
2019-10-29 00:31:05,092 Training Epoch [3/40] Iter[6/312]		Loss: 0.8475
2019-10-29 00:31:05,213 Training Epoch [3/40] Iter[7/312]		Loss: 0.8582
2019-10-29 00:31:05,334 Training Epoch [3/40] Iter[8/312]		Loss: 0.8893
2019-10-29 00:31:05,456 Training Epoch [3/40] Iter[9/312]		Loss: 0.9165
2019-10-29 00:31:05,577 Training Epoch [3/40] Iter[10/312]		Loss: 0.9106
2019-10-29 00:31:05,698 Training Epoch [3/40] Iter[11/312]		Loss: 0.8906
2019-10-29 00:31:05,819 Training Epoch [3/40] Iter[12/312]		Loss: 0.8939
2019-10-29 00:31:05,941 Training Epoch [3/40] Iter[13/312]		Loss: 0.8853
2019-10-29 00:31:06,062 Training Epoch [3/40] Iter[14/312]		Loss: 0.8827
2019-10-29 00:31:06,184 Training Epoch [3/40] Iter[15/312]		Loss: 0.8760
2019-10-29 00:31:06,306 Training Epoch [3/40] Iter[16/312]		Loss: 0.8736
2019-10-29 00:31:06,427 Training Epoch [3/40] Iter[17/312]		Loss: 0.8618
2019-10-29 00:31:06,548 Training Epoch [3/40] Iter[18/312]		Loss: 0.8537
2019-10-29 00:31:06,669 Training Epoch [3/40] Iter[19/312]		Loss: 0.8520
2019-10-29 00:31:06,790 Training Epoch [3/40] Iter[20/312]		Loss: 0.8556
2019-10-29 00:31:06,911 Training Epoch [3/40] Iter[21/312]		Loss: 0.8520
2019-10-29 00:31:07,033 Training Epoch [3/40] Iter[22/312]		Loss: 0.8485
2019-10-29 00:31:07,154 Training Epoch [3/40] Iter[23/312]		Loss: 0.8501
2019-10-29 00:31:07,275 Training Epoch [3/40] Iter[24/312]		Loss: 0.8390
2019-10-29 00:31:07,397 Training Epoch [3/40] Iter[25/312]		Loss: 0.8387
2019-10-29 00:31:07,517 Training Epoch [3/40] Iter[26/312]		Loss: 0.8306
2019-10-29 00:31:07,638 Training Epoch [3/40] Iter[27/312]		Loss: 0.8241
2019-10-29 00:31:07,758 Training Epoch [3/40] Iter[28/312]		Loss: 0.8201
2019-10-29 00:31:07,880 Training Epoch [3/40] Iter[29/312]		Loss: 0.8181
2019-10-29 00:31:08,001 Training Epoch [3/40] Iter[30/312]		Loss: 0.8204
2019-10-29 00:31:08,123 Training Epoch [3/40] Iter[31/312]		Loss: 0.8166
2019-10-29 00:31:08,244 Training Epoch [3/40] Iter[32/312]		Loss: 0.8126
2019-10-29 00:31:08,366 Training Epoch [3/40] Iter[33/312]		Loss: 0.8085
2019-10-29 00:31:08,488 Training Epoch [3/40] Iter[34/312]		Loss: 0.8083
2019-10-29 00:31:08,609 Training Epoch [3/40] Iter[35/312]		Loss: 0.8151
2019-10-29 00:31:08,730 Training Epoch [3/40] Iter[36/312]		Loss: 0.8152
2019-10-29 00:31:08,852 Training Epoch [3/40] Iter[37/312]		Loss: 0.8083
2019-10-29 00:31:08,973 Training Epoch [3/40] Iter[38/312]		Loss: 0.7985
2019-10-29 00:31:09,095 Training Epoch [3/40] Iter[39/312]		Loss: 0.7933
2019-10-29 00:31:09,217 Training Epoch [3/40] Iter[40/312]		Loss: 0.7862
2019-10-29 00:31:09,338 Training Epoch [3/40] Iter[41/312]		Loss: 0.7831
2019-10-29 00:31:09,460 Training Epoch [3/40] Iter[42/312]		Loss: 0.7819
2019-10-29 00:31:09,581 Training Epoch [3/40] Iter[43/312]		Loss: 0.7766
2019-10-29 00:31:09,703 Training Epoch [3/40] Iter[44/312]		Loss: 0.7763
2019-10-29 00:31:09,823 Training Epoch [3/40] Iter[45/312]		Loss: 0.7698
2019-10-29 00:31:09,945 Training Epoch [3/40] Iter[46/312]		Loss: 0.7677
2019-10-29 00:31:10,066 Training Epoch [3/40] Iter[47/312]		Loss: 0.7654
2019-10-29 00:31:10,187 Training Epoch [3/40] Iter[48/312]		Loss: 0.7645
2019-10-29 00:31:10,308 Training Epoch [3/40] Iter[49/312]		Loss: 0.7602
2019-10-29 00:31:10,429 Training Epoch [3/40] Iter[50/312]		Loss: 0.7567
2019-10-29 00:31:10,551 Training Epoch [3/40] Iter[51/312]		Loss: 0.7532
2019-10-29 00:31:10,672 Training Epoch [3/40] Iter[52/312]		Loss: 0.7522
2019-10-29 00:31:10,794 Training Epoch [3/40] Iter[53/312]		Loss: 0.7470
2019-10-29 00:31:10,915 Training Epoch [3/40] Iter[54/312]		Loss: 0.7420
2019-10-29 00:31:11,036 Training Epoch [3/40] Iter[55/312]		Loss: 0.7402
2019-10-29 00:31:11,157 Training Epoch [3/40] Iter[56/312]		Loss: 0.7393
2019-10-29 00:31:11,280 Training Epoch [3/40] Iter[57/312]		Loss: 0.7375
2019-10-29 00:31:11,402 Training Epoch [3/40] Iter[58/312]		Loss: 0.7388
2019-10-29 00:31:11,523 Training Epoch [3/40] Iter[59/312]		Loss: 0.7397
2019-10-29 00:31:11,644 Training Epoch [3/40] Iter[60/312]		Loss: 0.7430
2019-10-29 00:31:11,765 Training Epoch [3/40] Iter[61/312]		Loss: 0.7428
2019-10-29 00:31:11,887 Training Epoch [3/40] Iter[62/312]		Loss: 0.7433
2019-10-29 00:31:12,009 Training Epoch [3/40] Iter[63/312]		Loss: 0.7394
2019-10-29 00:31:12,131 Training Epoch [3/40] Iter[64/312]		Loss: 0.7381
2019-10-29 00:31:12,252 Training Epoch [3/40] Iter[65/312]		Loss: 0.7356
2019-10-29 00:31:12,374 Training Epoch [3/40] Iter[66/312]		Loss: 0.7328
2019-10-29 00:31:12,496 Training Epoch [3/40] Iter[67/312]		Loss: 0.7312
2019-10-29 00:31:12,618 Training Epoch [3/40] Iter[68/312]		Loss: 0.7314
2019-10-29 00:31:12,740 Training Epoch [3/40] Iter[69/312]		Loss: 0.7283
2019-10-29 00:31:12,861 Training Epoch [3/40] Iter[70/312]		Loss: 0.7279
2019-10-29 00:31:12,983 Training Epoch [3/40] Iter[71/312]		Loss: 0.7264
2019-10-29 00:31:13,104 Training Epoch [3/40] Iter[72/312]		Loss: 0.7250
2019-10-29 00:31:13,226 Training Epoch [3/40] Iter[73/312]		Loss: 0.7232
2019-10-29 00:31:13,347 Training Epoch [3/40] Iter[74/312]		Loss: 0.7229
2019-10-29 00:31:13,469 Training Epoch [3/40] Iter[75/312]		Loss: 0.7198
2019-10-29 00:31:13,591 Training Epoch [3/40] Iter[76/312]		Loss: 0.7185
2019-10-29 00:31:13,713 Training Epoch [3/40] Iter[77/312]		Loss: 0.7161
2019-10-29 00:31:13,834 Training Epoch [3/40] Iter[78/312]		Loss: 0.7151
2019-10-29 00:31:13,955 Training Epoch [3/40] Iter[79/312]		Loss: 0.7164
2019-10-29 00:31:14,077 Training Epoch [3/40] Iter[80/312]		Loss: 0.7165
2019-10-29 00:31:14,199 Training Epoch [3/40] Iter[81/312]		Loss: 0.7142
2019-10-29 00:31:14,321 Training Epoch [3/40] Iter[82/312]		Loss: 0.7137
2019-10-29 00:31:14,443 Training Epoch [3/40] Iter[83/312]		Loss: 0.7122
2019-10-29 00:31:14,565 Training Epoch [3/40] Iter[84/312]		Loss: 0.7125
2019-10-29 00:31:14,687 Training Epoch [3/40] Iter[85/312]		Loss: 0.7127
2019-10-29 00:31:14,809 Training Epoch [3/40] Iter[86/312]		Loss: 0.7133
2019-10-29 00:31:14,930 Training Epoch [3/40] Iter[87/312]		Loss: 0.7103
2019-10-29 00:31:15,052 Training Epoch [3/40] Iter[88/312]		Loss: 0.7106
2019-10-29 00:31:15,173 Training Epoch [3/40] Iter[89/312]		Loss: 0.7087
2019-10-29 00:31:15,295 Training Epoch [3/40] Iter[90/312]		Loss: 0.7108
2019-10-29 00:31:15,417 Training Epoch [3/40] Iter[91/312]		Loss: 0.7123
2019-10-29 00:31:15,537 Training Epoch [3/40] Iter[92/312]		Loss: 0.7108
2019-10-29 00:31:15,659 Training Epoch [3/40] Iter[93/312]		Loss: 0.7096
2019-10-29 00:31:15,780 Training Epoch [3/40] Iter[94/312]		Loss: 0.7079
2019-10-29 00:31:15,901 Training Epoch [3/40] Iter[95/312]		Loss: 0.7061
2019-10-29 00:31:16,022 Training Epoch [3/40] Iter[96/312]		Loss: 0.7054
2019-10-29 00:31:16,144 Training Epoch [3/40] Iter[97/312]		Loss: 0.7044
2019-10-29 00:31:16,265 Training Epoch [3/40] Iter[98/312]		Loss: 0.7032
2019-10-29 00:31:16,386 Training Epoch [3/40] Iter[99/312]		Loss: 0.7039
2019-10-29 00:31:16,508 Training Epoch [3/40] Iter[100/312]		Loss: 0.7031
2019-10-29 00:31:16,630 Training Epoch [3/40] Iter[101/312]		Loss: 0.7010
2019-10-29 00:31:16,751 Training Epoch [3/40] Iter[102/312]		Loss: 0.6993
2019-10-29 00:31:16,873 Training Epoch [3/40] Iter[103/312]		Loss: 0.6979
2019-10-29 00:31:16,995 Training Epoch [3/40] Iter[104/312]		Loss: 0.6957
2019-10-29 00:31:17,116 Training Epoch [3/40] Iter[105/312]		Loss: 0.6935
2019-10-29 00:31:17,238 Training Epoch [3/40] Iter[106/312]		Loss: 0.6921
2019-10-29 00:31:17,359 Training Epoch [3/40] Iter[107/312]		Loss: 0.6935
2019-10-29 00:31:17,481 Training Epoch [3/40] Iter[108/312]		Loss: 0.6919
2019-10-29 00:31:17,603 Training Epoch [3/40] Iter[109/312]		Loss: 0.6921
2019-10-29 00:31:17,725 Training Epoch [3/40] Iter[110/312]		Loss: 0.6909
2019-10-29 00:31:17,847 Training Epoch [3/40] Iter[111/312]		Loss: 0.6913
2019-10-29 00:31:17,968 Training Epoch [3/40] Iter[112/312]		Loss: 0.6914
2019-10-29 00:31:18,089 Training Epoch [3/40] Iter[113/312]		Loss: 0.6904
2019-10-29 00:31:18,211 Training Epoch [3/40] Iter[114/312]		Loss: 0.6905
2019-10-29 00:31:18,333 Training Epoch [3/40] Iter[115/312]		Loss: 0.6903
2019-10-29 00:31:18,455 Training Epoch [3/40] Iter[116/312]		Loss: 0.6890
2019-10-29 00:31:18,576 Training Epoch [3/40] Iter[117/312]		Loss: 0.6885
2019-10-29 00:31:18,697 Training Epoch [3/40] Iter[118/312]		Loss: 0.6885
2019-10-29 00:31:18,818 Training Epoch [3/40] Iter[119/312]		Loss: 0.6891
2019-10-29 00:31:18,939 Training Epoch [3/40] Iter[120/312]		Loss: 0.6891
2019-10-29 00:31:19,061 Training Epoch [3/40] Iter[121/312]		Loss: 0.6880
2019-10-29 00:31:19,182 Training Epoch [3/40] Iter[122/312]		Loss: 0.6882
2019-10-29 00:31:19,304 Training Epoch [3/40] Iter[123/312]		Loss: 0.6871
2019-10-29 00:31:19,425 Training Epoch [3/40] Iter[124/312]		Loss: 0.6875
2019-10-29 00:31:19,546 Training Epoch [3/40] Iter[125/312]		Loss: 0.6880
2019-10-29 00:31:19,668 Training Epoch [3/40] Iter[126/312]		Loss: 0.6871
2019-10-29 00:31:19,789 Training Epoch [3/40] Iter[127/312]		Loss: 0.6864
2019-10-29 00:31:19,910 Training Epoch [3/40] Iter[128/312]		Loss: 0.6867
2019-10-29 00:31:20,032 Training Epoch [3/40] Iter[129/312]		Loss: 0.6853
2019-10-29 00:31:20,154 Training Epoch [3/40] Iter[130/312]		Loss: 0.6855
2019-10-29 00:31:20,276 Training Epoch [3/40] Iter[131/312]		Loss: 0.6851
2019-10-29 00:31:20,397 Training Epoch [3/40] Iter[132/312]		Loss: 0.6858
2019-10-29 00:31:20,519 Training Epoch [3/40] Iter[133/312]		Loss: 0.6859
2019-10-29 00:31:20,640 Training Epoch [3/40] Iter[134/312]		Loss: 0.6872
2019-10-29 00:31:20,762 Training Epoch [3/40] Iter[135/312]		Loss: 0.6869
2019-10-29 00:31:20,883 Training Epoch [3/40] Iter[136/312]		Loss: 0.6853
2019-10-29 00:31:21,005 Training Epoch [3/40] Iter[137/312]		Loss: 0.6851
2019-10-29 00:31:21,126 Training Epoch [3/40] Iter[138/312]		Loss: 0.6866
2019-10-29 00:31:21,248 Training Epoch [3/40] Iter[139/312]		Loss: 0.6859
2019-10-29 00:31:21,370 Training Epoch [3/40] Iter[140/312]		Loss: 0.6855
2019-10-29 00:31:21,492 Training Epoch [3/40] Iter[141/312]		Loss: 0.6855
2019-10-29 00:31:21,613 Training Epoch [3/40] Iter[142/312]		Loss: 0.6856
2019-10-29 00:31:21,735 Training Epoch [3/40] Iter[143/312]		Loss: 0.6842
2019-10-29 00:31:21,856 Training Epoch [3/40] Iter[144/312]		Loss: 0.6825
2019-10-29 00:31:21,977 Training Epoch [3/40] Iter[145/312]		Loss: 0.6819
2019-10-29 00:31:22,099 Training Epoch [3/40] Iter[146/312]		Loss: 0.6814
2019-10-29 00:31:22,220 Training Epoch [3/40] Iter[147/312]		Loss: 0.6807
2019-10-29 00:31:22,341 Training Epoch [3/40] Iter[148/312]		Loss: 0.6795
2019-10-29 00:31:22,463 Training Epoch [3/40] Iter[149/312]		Loss: 0.6784
2019-10-29 00:31:22,584 Training Epoch [3/40] Iter[150/312]		Loss: 0.6777
2019-10-29 00:31:22,705 Training Epoch [3/40] Iter[151/312]		Loss: 0.6781
2019-10-29 00:31:22,827 Training Epoch [3/40] Iter[152/312]		Loss: 0.6770
2019-10-29 00:31:22,948 Training Epoch [3/40] Iter[153/312]		Loss: 0.6772
2019-10-29 00:31:23,070 Training Epoch [3/40] Iter[154/312]		Loss: 0.6767
2019-10-29 00:31:23,192 Training Epoch [3/40] Iter[155/312]		Loss: 0.6761
2019-10-29 00:31:23,313 Training Epoch [3/40] Iter[156/312]		Loss: 0.6760
2019-10-29 00:31:23,435 Training Epoch [3/40] Iter[157/312]		Loss: 0.6754
2019-10-29 00:31:23,557 Training Epoch [3/40] Iter[158/312]		Loss: 0.6757
2019-10-29 00:31:23,679 Training Epoch [3/40] Iter[159/312]		Loss: 0.6763
2019-10-29 00:31:23,800 Training Epoch [3/40] Iter[160/312]		Loss: 0.6753
2019-10-29 00:31:23,922 Training Epoch [3/40] Iter[161/312]		Loss: 0.6744
2019-10-29 00:31:24,043 Training Epoch [3/40] Iter[162/312]		Loss: 0.6749
2019-10-29 00:31:24,164 Training Epoch [3/40] Iter[163/312]		Loss: 0.6739
2019-10-29 00:31:24,286 Training Epoch [3/40] Iter[164/312]		Loss: 0.6733
2019-10-29 00:31:24,407 Training Epoch [3/40] Iter[165/312]		Loss: 0.6727
2019-10-29 00:31:24,528 Training Epoch [3/40] Iter[166/312]		Loss: 0.6716
2019-10-29 00:31:24,650 Training Epoch [3/40] Iter[167/312]		Loss: 0.6707
2019-10-29 00:31:24,771 Training Epoch [3/40] Iter[168/312]		Loss: 0.6704
2019-10-29 00:31:24,892 Training Epoch [3/40] Iter[169/312]		Loss: 0.6709
2019-10-29 00:31:25,014 Training Epoch [3/40] Iter[170/312]		Loss: 0.6705
2019-10-29 00:31:25,141 Training Epoch [3/40] Iter[171/312]		Loss: 0.6695
2019-10-29 00:31:25,263 Training Epoch [3/40] Iter[172/312]		Loss: 0.6698
2019-10-29 00:31:25,385 Training Epoch [3/40] Iter[173/312]		Loss: 0.6693
2019-10-29 00:31:25,506 Training Epoch [3/40] Iter[174/312]		Loss: 0.6688
2019-10-29 00:31:25,628 Training Epoch [3/40] Iter[175/312]		Loss: 0.6685
2019-10-29 00:31:25,749 Training Epoch [3/40] Iter[176/312]		Loss: 0.6673
2019-10-29 00:31:25,871 Training Epoch [3/40] Iter[177/312]		Loss: 0.6665
2019-10-29 00:31:25,993 Training Epoch [3/40] Iter[178/312]		Loss: 0.6659
2019-10-29 00:31:26,116 Training Epoch [3/40] Iter[179/312]		Loss: 0.6665
2019-10-29 00:31:26,238 Training Epoch [3/40] Iter[180/312]		Loss: 0.6660
2019-10-29 00:31:26,359 Training Epoch [3/40] Iter[181/312]		Loss: 0.6655
2019-10-29 00:31:26,481 Training Epoch [3/40] Iter[182/312]		Loss: 0.6655
2019-10-29 00:31:26,603 Training Epoch [3/40] Iter[183/312]		Loss: 0.6658
2019-10-29 00:31:26,724 Training Epoch [3/40] Iter[184/312]		Loss: 0.6644
2019-10-29 00:31:26,846 Training Epoch [3/40] Iter[185/312]		Loss: 0.6653
2019-10-29 00:31:26,967 Training Epoch [3/40] Iter[186/312]		Loss: 0.6659
2019-10-29 00:31:27,089 Training Epoch [3/40] Iter[187/312]		Loss: 0.6652
2019-10-29 00:31:27,210 Training Epoch [3/40] Iter[188/312]		Loss: 0.6655
2019-10-29 00:31:27,332 Training Epoch [3/40] Iter[189/312]		Loss: 0.6650
2019-10-29 00:31:27,453 Training Epoch [3/40] Iter[190/312]		Loss: 0.6647
2019-10-29 00:31:27,574 Training Epoch [3/40] Iter[191/312]		Loss: 0.6651
2019-10-29 00:31:27,696 Training Epoch [3/40] Iter[192/312]		Loss: 0.6649
2019-10-29 00:31:27,817 Training Epoch [3/40] Iter[193/312]		Loss: 0.6653
2019-10-29 00:31:27,939 Training Epoch [3/40] Iter[194/312]		Loss: 0.6657
2019-10-29 00:31:28,060 Training Epoch [3/40] Iter[195/312]		Loss: 0.6661
2019-10-29 00:31:28,181 Training Epoch [3/40] Iter[196/312]		Loss: 0.6646
2019-10-29 00:31:28,305 Training Epoch [3/40] Iter[197/312]		Loss: 0.6639
2019-10-29 00:31:28,426 Training Epoch [3/40] Iter[198/312]		Loss: 0.6640
2019-10-29 00:31:28,548 Training Epoch [3/40] Iter[199/312]		Loss: 0.6631
2019-10-29 00:31:28,670 Training Epoch [3/40] Iter[200/312]		Loss: 0.6617
2019-10-29 00:31:28,791 Training Epoch [3/40] Iter[201/312]		Loss: 0.6608
2019-10-29 00:31:28,913 Training Epoch [3/40] Iter[202/312]		Loss: 0.6599
2019-10-29 00:31:29,034 Training Epoch [3/40] Iter[203/312]		Loss: 0.6593
2019-10-29 00:31:29,156 Training Epoch [3/40] Iter[204/312]		Loss: 0.6585
2019-10-29 00:31:29,278 Training Epoch [3/40] Iter[205/312]		Loss: 0.6579
2019-10-29 00:31:29,399 Training Epoch [3/40] Iter[206/312]		Loss: 0.6576
2019-10-29 00:31:29,521 Training Epoch [3/40] Iter[207/312]		Loss: 0.6569
2019-10-29 00:31:29,642 Training Epoch [3/40] Iter[208/312]		Loss: 0.6562
2019-10-29 00:31:29,764 Training Epoch [3/40] Iter[209/312]		Loss: 0.6550
2019-10-29 00:31:29,886 Training Epoch [3/40] Iter[210/312]		Loss: 0.6550
2019-10-29 00:31:30,008 Training Epoch [3/40] Iter[211/312]		Loss: 0.6550
2019-10-29 00:31:30,129 Training Epoch [3/40] Iter[212/312]		Loss: 0.6539
2019-10-29 00:31:30,251 Training Epoch [3/40] Iter[213/312]		Loss: 0.6539
2019-10-29 00:31:30,372 Training Epoch [3/40] Iter[214/312]		Loss: 0.6536
2019-10-29 00:31:30,494 Training Epoch [3/40] Iter[215/312]		Loss: 0.6531
2019-10-29 00:31:30,615 Training Epoch [3/40] Iter[216/312]		Loss: 0.6525
2019-10-29 00:31:30,737 Training Epoch [3/40] Iter[217/312]		Loss: 0.6513
2019-10-29 00:31:30,858 Training Epoch [3/40] Iter[218/312]		Loss: 0.6512
2019-10-29 00:31:30,979 Training Epoch [3/40] Iter[219/312]		Loss: 0.6508
2019-10-29 00:31:31,100 Training Epoch [3/40] Iter[220/312]		Loss: 0.6512
2019-10-29 00:31:31,222 Training Epoch [3/40] Iter[221/312]		Loss: 0.6509
2019-10-29 00:31:31,344 Training Epoch [3/40] Iter[222/312]		Loss: 0.6501
2019-10-29 00:31:31,466 Training Epoch [3/40] Iter[223/312]		Loss: 0.6496
2019-10-29 00:31:31,587 Training Epoch [3/40] Iter[224/312]		Loss: 0.6497
2019-10-29 00:31:31,709 Training Epoch [3/40] Iter[225/312]		Loss: 0.6485
2019-10-29 00:31:31,831 Training Epoch [3/40] Iter[226/312]		Loss: 0.6474
2019-10-29 00:31:31,952 Training Epoch [3/40] Iter[227/312]		Loss: 0.6473
2019-10-29 00:31:32,074 Training Epoch [3/40] Iter[228/312]		Loss: 0.6464
2019-10-29 00:31:32,196 Training Epoch [3/40] Iter[229/312]		Loss: 0.6462
2019-10-29 00:31:32,317 Training Epoch [3/40] Iter[230/312]		Loss: 0.6460
2019-10-29 00:31:32,438 Training Epoch [3/40] Iter[231/312]		Loss: 0.6460
2019-10-29 00:31:32,559 Training Epoch [3/40] Iter[232/312]		Loss: 0.6451
2019-10-29 00:31:32,680 Training Epoch [3/40] Iter[233/312]		Loss: 0.6444
2019-10-29 00:31:32,801 Training Epoch [3/40] Iter[234/312]		Loss: 0.6437
2019-10-29 00:31:32,922 Training Epoch [3/40] Iter[235/312]		Loss: 0.6429
2019-10-29 00:31:33,044 Training Epoch [3/40] Iter[236/312]		Loss: 0.6424
2019-10-29 00:31:33,165 Training Epoch [3/40] Iter[237/312]		Loss: 0.6425
2019-10-29 00:31:33,286 Training Epoch [3/40] Iter[238/312]		Loss: 0.6419
2019-10-29 00:31:33,408 Training Epoch [3/40] Iter[239/312]		Loss: 0.6412
2019-10-29 00:31:33,529 Training Epoch [3/40] Iter[240/312]		Loss: 0.6411
2019-10-29 00:31:33,650 Training Epoch [3/40] Iter[241/312]		Loss: 0.6403
2019-10-29 00:31:33,771 Training Epoch [3/40] Iter[242/312]		Loss: 0.6406
2019-10-29 00:31:33,893 Training Epoch [3/40] Iter[243/312]		Loss: 0.6405
2019-10-29 00:31:34,014 Training Epoch [3/40] Iter[244/312]		Loss: 0.6397
2019-10-29 00:31:34,136 Training Epoch [3/40] Iter[245/312]		Loss: 0.6390
2019-10-29 00:31:34,258 Training Epoch [3/40] Iter[246/312]		Loss: 0.6385
2019-10-29 00:31:34,380 Training Epoch [3/40] Iter[247/312]		Loss: 0.6381
2019-10-29 00:31:34,501 Training Epoch [3/40] Iter[248/312]		Loss: 0.6379
2019-10-29 00:31:34,623 Training Epoch [3/40] Iter[249/312]		Loss: 0.6377
2019-10-29 00:31:34,744 Training Epoch [3/40] Iter[250/312]		Loss: 0.6374
2019-10-29 00:31:34,866 Training Epoch [3/40] Iter[251/312]		Loss: 0.6367
2019-10-29 00:31:34,988 Training Epoch [3/40] Iter[252/312]		Loss: 0.6364
2019-10-29 00:31:35,110 Training Epoch [3/40] Iter[253/312]		Loss: 0.6359
2019-10-29 00:31:35,231 Training Epoch [3/40] Iter[254/312]		Loss: 0.6351
2019-10-29 00:31:35,353 Training Epoch [3/40] Iter[255/312]		Loss: 0.6344
2019-10-29 00:31:35,475 Training Epoch [3/40] Iter[256/312]		Loss: 0.6343
2019-10-29 00:31:35,596 Training Epoch [3/40] Iter[257/312]		Loss: 0.6339
2019-10-29 00:31:35,718 Training Epoch [3/40] Iter[258/312]		Loss: 0.6331
2019-10-29 00:31:35,839 Training Epoch [3/40] Iter[259/312]		Loss: 0.6329
2019-10-29 00:31:35,960 Training Epoch [3/40] Iter[260/312]		Loss: 0.6326
2019-10-29 00:31:36,081 Training Epoch [3/40] Iter[261/312]		Loss: 0.6326
2019-10-29 00:31:36,202 Training Epoch [3/40] Iter[262/312]		Loss: 0.6322
2019-10-29 00:31:36,324 Training Epoch [3/40] Iter[263/312]		Loss: 0.6321
2019-10-29 00:31:36,445 Training Epoch [3/40] Iter[264/312]		Loss: 0.6326
2019-10-29 00:31:36,567 Training Epoch [3/40] Iter[265/312]		Loss: 0.6323
2019-10-29 00:31:36,689 Training Epoch [3/40] Iter[266/312]		Loss: 0.6316
2019-10-29 00:31:36,810 Training Epoch [3/40] Iter[267/312]		Loss: 0.6320
2019-10-29 00:31:36,931 Training Epoch [3/40] Iter[268/312]		Loss: 0.6317
2019-10-29 00:31:37,053 Training Epoch [3/40] Iter[269/312]		Loss: 0.6307
2019-10-29 00:31:37,175 Training Epoch [3/40] Iter[270/312]		Loss: 0.6308
2019-10-29 00:31:37,297 Training Epoch [3/40] Iter[271/312]		Loss: 0.6310
2019-10-29 00:31:37,419 Training Epoch [3/40] Iter[272/312]		Loss: 0.6302
2019-10-29 00:31:37,540 Training Epoch [3/40] Iter[273/312]		Loss: 0.6296
2019-10-29 00:31:37,661 Training Epoch [3/40] Iter[274/312]		Loss: 0.6293
2019-10-29 00:31:37,783 Training Epoch [3/40] Iter[275/312]		Loss: 0.6294
2019-10-29 00:31:37,905 Training Epoch [3/40] Iter[276/312]		Loss: 0.6301
2019-10-29 00:31:38,026 Training Epoch [3/40] Iter[277/312]		Loss: 0.6300
2019-10-29 00:31:38,148 Training Epoch [3/40] Iter[278/312]		Loss: 0.6294
2019-10-29 00:31:38,269 Training Epoch [3/40] Iter[279/312]		Loss: 0.6289
2019-10-29 00:31:38,391 Training Epoch [3/40] Iter[280/312]		Loss: 0.6283
2019-10-29 00:31:38,513 Training Epoch [3/40] Iter[281/312]		Loss: 0.6282
2019-10-29 00:31:38,635 Training Epoch [3/40] Iter[282/312]		Loss: 0.6282
2019-10-29 00:31:38,757 Training Epoch [3/40] Iter[283/312]		Loss: 0.6280
2019-10-29 00:31:38,878 Training Epoch [3/40] Iter[284/312]		Loss: 0.6273
2019-10-29 00:31:39,000 Training Epoch [3/40] Iter[285/312]		Loss: 0.6269
2019-10-29 00:31:39,121 Training Epoch [3/40] Iter[286/312]		Loss: 0.6270
2019-10-29 00:31:39,243 Training Epoch [3/40] Iter[287/312]		Loss: 0.6266
2019-10-29 00:31:39,364 Training Epoch [3/40] Iter[288/312]		Loss: 0.6266
2019-10-29 00:31:39,486 Training Epoch [3/40] Iter[289/312]		Loss: 0.6265
2019-10-29 00:31:39,607 Training Epoch [3/40] Iter[290/312]		Loss: 0.6260
2019-10-29 00:31:39,729 Training Epoch [3/40] Iter[291/312]		Loss: 0.6256
2019-10-29 00:31:39,850 Training Epoch [3/40] Iter[292/312]		Loss: 0.6254
2019-10-29 00:31:39,972 Training Epoch [3/40] Iter[293/312]		Loss: 0.6258
2019-10-29 00:31:40,093 Training Epoch [3/40] Iter[294/312]		Loss: 0.6256
2019-10-29 00:31:40,215 Training Epoch [3/40] Iter[295/312]		Loss: 0.6253
2019-10-29 00:31:40,336 Training Epoch [3/40] Iter[296/312]		Loss: 0.6247
2019-10-29 00:31:40,458 Training Epoch [3/40] Iter[297/312]		Loss: 0.6247
2019-10-29 00:31:40,579 Training Epoch [3/40] Iter[298/312]		Loss: 0.6249
2019-10-29 00:31:40,701 Training Epoch [3/40] Iter[299/312]		Loss: 0.6247
2019-10-29 00:31:40,823 Training Epoch [3/40] Iter[300/312]		Loss: 0.6242
2019-10-29 00:31:40,944 Training Epoch [3/40] Iter[301/312]		Loss: 0.6237
2019-10-29 00:31:41,066 Training Epoch [3/40] Iter[302/312]		Loss: 0.6232
2019-10-29 00:31:41,187 Training Epoch [3/40] Iter[303/312]		Loss: 0.6231
2019-10-29 00:31:41,309 Training Epoch [3/40] Iter[304/312]		Loss: 0.6229
2019-10-29 00:31:41,429 Training Epoch [3/40] Iter[305/312]		Loss: 0.6223
2019-10-29 00:31:41,550 Training Epoch [3/40] Iter[306/312]		Loss: 0.6220
2019-10-29 00:31:41,670 Training Epoch [3/40] Iter[307/312]		Loss: 0.6224
2019-10-29 00:31:41,791 Training Epoch [3/40] Iter[308/312]		Loss: 0.6220
2019-10-29 00:31:41,911 Training Epoch [3/40] Iter[309/312]		Loss: 0.6215
2019-10-29 00:31:42,032 Training Epoch [3/40] Iter[310/312]		Loss: 0.6210
2019-10-29 00:31:42,152 Training Epoch [3/40] Iter[311/312]		Loss: 0.6205
2019-10-29 00:31:42,212 Training Epoch [3/40] Iter[312/312]		Loss: 0.6197
2019-10-29 00:31:42,463 Testing Epoch [3/40] Iter[0/62]		Loss: 0.5127
2019-10-29 00:31:42,505 Testing Epoch [3/40] Iter[1/62]		Loss: 0.4934
2019-10-29 00:31:42,545 Testing Epoch [3/40] Iter[2/62]		Loss: 0.4752
2019-10-29 00:31:42,637 Testing Epoch [3/40] Iter[3/62]		Loss: 0.4706
2019-10-29 00:31:42,667 Testing Epoch [3/40] Iter[4/62]		Loss: 0.4756
2019-10-29 00:31:42,698 Testing Epoch [3/40] Iter[5/62]		Loss: 0.4612
2019-10-29 00:31:42,741 Testing Epoch [3/40] Iter[6/62]		Loss: 0.4608
2019-10-29 00:31:42,776 Testing Epoch [3/40] Iter[7/62]		Loss: 0.4670
2019-10-29 00:31:42,806 Testing Epoch [3/40] Iter[8/62]		Loss: 0.4725
2019-10-29 00:31:42,836 Testing Epoch [3/40] Iter[9/62]		Loss: 0.4661
2019-10-29 00:31:42,880 Testing Epoch [3/40] Iter[10/62]		Loss: 0.4661
2019-10-29 00:31:42,911 Testing Epoch [3/40] Iter[11/62]		Loss: 0.4671
2019-10-29 00:31:42,942 Testing Epoch [3/40] Iter[12/62]		Loss: 0.4687
2019-10-29 00:31:42,975 Testing Epoch [3/40] Iter[13/62]		Loss: 0.4651
2019-10-29 00:31:43,006 Testing Epoch [3/40] Iter[14/62]		Loss: 0.4932
2019-10-29 00:31:43,038 Testing Epoch [3/40] Iter[15/62]		Loss: 0.4960
2019-10-29 00:31:43,070 Testing Epoch [3/40] Iter[16/62]		Loss: 0.4938
2019-10-29 00:31:43,100 Testing Epoch [3/40] Iter[17/62]		Loss: 0.4877
2019-10-29 00:31:43,134 Testing Epoch [3/40] Iter[18/62]		Loss: 0.4829
2019-10-29 00:31:43,165 Testing Epoch [3/40] Iter[19/62]		Loss: 0.4818
2019-10-29 00:31:43,196 Testing Epoch [3/40] Iter[20/62]		Loss: 0.4899
2019-10-29 00:31:43,233 Testing Epoch [3/40] Iter[21/62]		Loss: 0.4938
2019-10-29 00:31:43,265 Testing Epoch [3/40] Iter[22/62]		Loss: 0.5031
2019-10-29 00:31:43,295 Testing Epoch [3/40] Iter[23/62]		Loss: 0.5044
2019-10-29 00:31:43,327 Testing Epoch [3/40] Iter[24/62]		Loss: 0.5051
2019-10-29 00:31:43,358 Testing Epoch [3/40] Iter[25/62]		Loss: 0.5044
2019-10-29 00:31:43,389 Testing Epoch [3/40] Iter[26/62]		Loss: 0.5032
2019-10-29 00:31:43,420 Testing Epoch [3/40] Iter[27/62]		Loss: 0.5162
2019-10-29 00:31:43,451 Testing Epoch [3/40] Iter[28/62]		Loss: 0.5137
2019-10-29 00:31:43,481 Testing Epoch [3/40] Iter[29/62]		Loss: 0.5151
2019-10-29 00:31:43,512 Testing Epoch [3/40] Iter[30/62]		Loss: 0.5134
2019-10-29 00:31:43,544 Testing Epoch [3/40] Iter[31/62]		Loss: 0.5132
2019-10-29 00:31:43,575 Testing Epoch [3/40] Iter[32/62]		Loss: 0.5148
2019-10-29 00:31:43,606 Testing Epoch [3/40] Iter[33/62]		Loss: 0.5123
2019-10-29 00:31:43,637 Testing Epoch [3/40] Iter[34/62]		Loss: 0.5160
2019-10-29 00:31:43,668 Testing Epoch [3/40] Iter[35/62]		Loss: 0.5160
2019-10-29 00:31:43,699 Testing Epoch [3/40] Iter[36/62]		Loss: 0.5103
2019-10-29 00:31:43,731 Testing Epoch [3/40] Iter[37/62]		Loss: 0.5105
2019-10-29 00:31:43,762 Testing Epoch [3/40] Iter[38/62]		Loss: 0.5105
2019-10-29 00:31:43,793 Testing Epoch [3/40] Iter[39/62]		Loss: 0.5113
2019-10-29 00:31:43,824 Testing Epoch [3/40] Iter[40/62]		Loss: 0.5143
2019-10-29 00:31:43,855 Testing Epoch [3/40] Iter[41/62]		Loss: 0.5146
2019-10-29 00:31:43,886 Testing Epoch [3/40] Iter[42/62]		Loss: 0.5113
2019-10-29 00:31:43,917 Testing Epoch [3/40] Iter[43/62]		Loss: 0.5128
2019-10-29 00:31:43,948 Testing Epoch [3/40] Iter[44/62]		Loss: 0.5109
2019-10-29 00:31:43,979 Testing Epoch [3/40] Iter[45/62]		Loss: 0.5127
2019-10-29 00:31:44,010 Testing Epoch [3/40] Iter[46/62]		Loss: 0.5129
2019-10-29 00:31:44,041 Testing Epoch [3/40] Iter[47/62]		Loss: 0.5167
2019-10-29 00:31:44,072 Testing Epoch [3/40] Iter[48/62]		Loss: 0.5145
2019-10-29 00:31:44,103 Testing Epoch [3/40] Iter[49/62]		Loss: 0.5170
2019-10-29 00:31:44,134 Testing Epoch [3/40] Iter[50/62]		Loss: 0.5157
2019-10-29 00:31:44,165 Testing Epoch [3/40] Iter[51/62]		Loss: 0.5168
2019-10-29 00:31:44,196 Testing Epoch [3/40] Iter[52/62]		Loss: 0.5163
2019-10-29 00:31:44,226 Testing Epoch [3/40] Iter[53/62]		Loss: 0.5165
2019-10-29 00:31:44,257 Testing Epoch [3/40] Iter[54/62]		Loss: 0.5151
2019-10-29 00:31:44,288 Testing Epoch [3/40] Iter[55/62]		Loss: 0.5144
2019-10-29 00:31:44,318 Testing Epoch [3/40] Iter[56/62]		Loss: 0.5146
2019-10-29 00:31:44,349 Testing Epoch [3/40] Iter[57/62]		Loss: 0.5162
2019-10-29 00:31:44,379 Testing Epoch [3/40] Iter[58/62]		Loss: 0.5135
2019-10-29 00:31:44,409 Testing Epoch [3/40] Iter[59/62]		Loss: 0.5135
2019-10-29 00:31:44,440 Testing Epoch [3/40] Iter[60/62]		Loss: 0.5128
2019-10-29 00:31:44,470 Testing Epoch [3/40] Iter[61/62]		Loss: 0.5136
2019-10-29 00:31:44,487 Testing Epoch [3/40] Iter[62/62]		Loss: 0.5167
2019-10-29 00:31:44,555 Saving the Model
2019-10-29 00:31:44,871 Training Epoch [4/40] Iter[0/312]		Loss: 0.5260
2019-10-29 00:31:45,032 Training Epoch [4/40] Iter[1/312]		Loss: 0.5926
2019-10-29 00:31:45,155 Training Epoch [4/40] Iter[2/312]		Loss: 0.5394
2019-10-29 00:31:45,279 Training Epoch [4/40] Iter[3/312]		Loss: 0.5297
2019-10-29 00:31:45,399 Training Epoch [4/40] Iter[4/312]		Loss: 0.5460
2019-10-29 00:31:45,520 Training Epoch [4/40] Iter[5/312]		Loss: 0.5560
2019-10-29 00:31:45,641 Training Epoch [4/40] Iter[6/312]		Loss: 0.5513
2019-10-29 00:31:45,763 Training Epoch [4/40] Iter[7/312]		Loss: 0.5538
2019-10-29 00:31:45,883 Training Epoch [4/40] Iter[8/312]		Loss: 0.5692
2019-10-29 00:31:46,005 Training Epoch [4/40] Iter[9/312]		Loss: 0.5635
2019-10-29 00:31:46,126 Training Epoch [4/40] Iter[10/312]		Loss: 0.5679
2019-10-29 00:31:46,248 Training Epoch [4/40] Iter[11/312]		Loss: 0.5746
2019-10-29 00:31:46,370 Training Epoch [4/40] Iter[12/312]		Loss: 0.5840
2019-10-29 00:31:46,491 Training Epoch [4/40] Iter[13/312]		Loss: 0.5775
2019-10-29 00:31:46,613 Training Epoch [4/40] Iter[14/312]		Loss: 0.5814
2019-10-29 00:31:46,734 Training Epoch [4/40] Iter[15/312]		Loss: 0.5756
2019-10-29 00:31:46,856 Training Epoch [4/40] Iter[16/312]		Loss: 0.5758
2019-10-29 00:31:46,977 Training Epoch [4/40] Iter[17/312]		Loss: 0.5827
2019-10-29 00:31:47,099 Training Epoch [4/40] Iter[18/312]		Loss: 0.5899
2019-10-29 00:31:47,220 Training Epoch [4/40] Iter[19/312]		Loss: 0.5890
2019-10-29 00:31:47,342 Training Epoch [4/40] Iter[20/312]		Loss: 0.5889
2019-10-29 00:31:47,464 Training Epoch [4/40] Iter[21/312]		Loss: 0.5861
2019-10-29 00:31:47,585 Training Epoch [4/40] Iter[22/312]		Loss: 0.5828
2019-10-29 00:31:47,706 Training Epoch [4/40] Iter[23/312]		Loss: 0.5747
2019-10-29 00:31:47,828 Training Epoch [4/40] Iter[24/312]		Loss: 0.5758
2019-10-29 00:31:47,950 Training Epoch [4/40] Iter[25/312]		Loss: 0.5677
2019-10-29 00:31:48,071 Training Epoch [4/40] Iter[26/312]		Loss: 0.5620
2019-10-29 00:31:48,193 Training Epoch [4/40] Iter[27/312]		Loss: 0.5617
2019-10-29 00:31:48,314 Training Epoch [4/40] Iter[28/312]		Loss: 0.5587
2019-10-29 00:31:48,440 Training Epoch [4/40] Iter[29/312]		Loss: 0.5525
2019-10-29 00:31:48,562 Training Epoch [4/40] Iter[30/312]		Loss: 0.5477
2019-10-29 00:31:48,685 Training Epoch [4/40] Iter[31/312]		Loss: 0.5421
2019-10-29 00:31:48,806 Training Epoch [4/40] Iter[32/312]		Loss: 0.5434
2019-10-29 00:31:48,928 Training Epoch [4/40] Iter[33/312]		Loss: 0.5419
2019-10-29 00:31:49,049 Training Epoch [4/40] Iter[34/312]		Loss: 0.5358
2019-10-29 00:31:49,171 Training Epoch [4/40] Iter[35/312]		Loss: 0.5359
2019-10-29 00:31:49,292 Training Epoch [4/40] Iter[36/312]		Loss: 0.5377
2019-10-29 00:31:49,414 Training Epoch [4/40] Iter[37/312]		Loss: 0.5420
2019-10-29 00:31:49,536 Training Epoch [4/40] Iter[38/312]		Loss: 0.5432
2019-10-29 00:31:49,658 Training Epoch [4/40] Iter[39/312]		Loss: 0.5443
2019-10-29 00:31:49,779 Training Epoch [4/40] Iter[40/312]		Loss: 0.5448
2019-10-29 00:31:49,900 Training Epoch [4/40] Iter[41/312]		Loss: 0.5436
2019-10-29 00:31:50,021 Training Epoch [4/40] Iter[42/312]		Loss: 0.5403
2019-10-29 00:31:50,142 Training Epoch [4/40] Iter[43/312]		Loss: 0.5446
2019-10-29 00:31:50,263 Training Epoch [4/40] Iter[44/312]		Loss: 0.5426
2019-10-29 00:31:50,385 Training Epoch [4/40] Iter[45/312]		Loss: 0.5445
2019-10-29 00:31:50,506 Training Epoch [4/40] Iter[46/312]		Loss: 0.5419
2019-10-29 00:31:50,627 Training Epoch [4/40] Iter[47/312]		Loss: 0.5418
2019-10-29 00:31:50,749 Training Epoch [4/40] Iter[48/312]		Loss: 0.5417
2019-10-29 00:31:50,870 Training Epoch [4/40] Iter[49/312]		Loss: 0.5397
2019-10-29 00:31:50,991 Training Epoch [4/40] Iter[50/312]		Loss: 0.5388
2019-10-29 00:31:51,113 Training Epoch [4/40] Iter[51/312]		Loss: 0.5396
2019-10-29 00:31:51,235 Training Epoch [4/40] Iter[52/312]		Loss: 0.5369
2019-10-29 00:31:51,357 Training Epoch [4/40] Iter[53/312]		Loss: 0.5373
2019-10-29 00:31:51,479 Training Epoch [4/40] Iter[54/312]		Loss: 0.5360
2019-10-29 00:31:51,600 Training Epoch [4/40] Iter[55/312]		Loss: 0.5342
2019-10-29 00:31:51,721 Training Epoch [4/40] Iter[56/312]		Loss: 0.5314
2019-10-29 00:31:51,843 Training Epoch [4/40] Iter[57/312]		Loss: 0.5304
2019-10-29 00:31:51,965 Training Epoch [4/40] Iter[58/312]		Loss: 0.5302
2019-10-29 00:31:52,087 Training Epoch [4/40] Iter[59/312]		Loss: 0.5290
2019-10-29 00:31:52,209 Training Epoch [4/40] Iter[60/312]		Loss: 0.5256
2019-10-29 00:31:52,331 Training Epoch [4/40] Iter[61/312]		Loss: 0.5263
2019-10-29 00:31:52,453 Training Epoch [4/40] Iter[62/312]		Loss: 0.5222
2019-10-29 00:31:52,575 Training Epoch [4/40] Iter[63/312]		Loss: 0.5213
2019-10-29 00:31:52,697 Training Epoch [4/40] Iter[64/312]		Loss: 0.5227
2019-10-29 00:31:52,818 Training Epoch [4/40] Iter[65/312]		Loss: 0.5194
2019-10-29 00:31:52,940 Training Epoch [4/40] Iter[66/312]		Loss: 0.5191
2019-10-29 00:31:53,061 Training Epoch [4/40] Iter[67/312]		Loss: 0.5163
2019-10-29 00:31:53,182 Training Epoch [4/40] Iter[68/312]		Loss: 0.5159
2019-10-29 00:31:53,304 Training Epoch [4/40] Iter[69/312]		Loss: 0.5169
2019-10-29 00:31:53,426 Training Epoch [4/40] Iter[70/312]		Loss: 0.5171
2019-10-29 00:31:53,548 Training Epoch [4/40] Iter[71/312]		Loss: 0.5162
2019-10-29 00:31:53,670 Training Epoch [4/40] Iter[72/312]		Loss: 0.5168
2019-10-29 00:31:53,791 Training Epoch [4/40] Iter[73/312]		Loss: 0.5165
2019-10-29 00:31:53,913 Training Epoch [4/40] Iter[74/312]		Loss: 0.5169
2019-10-29 00:31:54,034 Training Epoch [4/40] Iter[75/312]		Loss: 0.5164
2019-10-29 00:31:54,156 Training Epoch [4/40] Iter[76/312]		Loss: 0.5141
2019-10-29 00:31:54,278 Training Epoch [4/40] Iter[77/312]		Loss: 0.5143
2019-10-29 00:31:54,400 Training Epoch [4/40] Iter[78/312]		Loss: 0.5129
2019-10-29 00:31:54,522 Training Epoch [4/40] Iter[79/312]		Loss: 0.5108
2019-10-29 00:31:54,643 Training Epoch [4/40] Iter[80/312]		Loss: 0.5121
2019-10-29 00:31:54,765 Training Epoch [4/40] Iter[81/312]		Loss: 0.5110
2019-10-29 00:31:54,887 Training Epoch [4/40] Iter[82/312]		Loss: 0.5111
2019-10-29 00:31:55,009 Training Epoch [4/40] Iter[83/312]		Loss: 0.5085
2019-10-29 00:31:55,131 Training Epoch [4/40] Iter[84/312]		Loss: 0.5085
2019-10-29 00:31:55,253 Training Epoch [4/40] Iter[85/312]		Loss: 0.5072
2019-10-29 00:31:55,375 Training Epoch [4/40] Iter[86/312]		Loss: 0.5071
2019-10-29 00:31:55,497 Training Epoch [4/40] Iter[87/312]		Loss: 0.5087
2019-10-29 00:31:55,619 Training Epoch [4/40] Iter[88/312]		Loss: 0.5075
2019-10-29 00:31:55,741 Training Epoch [4/40] Iter[89/312]		Loss: 0.5069
2019-10-29 00:31:55,863 Training Epoch [4/40] Iter[90/312]		Loss: 0.5063
2019-10-29 00:31:55,985 Training Epoch [4/40] Iter[91/312]		Loss: 0.5039
2019-10-29 00:31:56,106 Training Epoch [4/40] Iter[92/312]		Loss: 0.5035
2019-10-29 00:31:56,228 Training Epoch [4/40] Iter[93/312]		Loss: 0.5022
2019-10-29 00:31:56,350 Training Epoch [4/40] Iter[94/312]		Loss: 0.5007
2019-10-29 00:31:56,472 Training Epoch [4/40] Iter[95/312]		Loss: 0.5017
2019-10-29 00:31:56,594 Training Epoch [4/40] Iter[96/312]		Loss: 0.5013
2019-10-29 00:31:56,716 Training Epoch [4/40] Iter[97/312]		Loss: 0.4993
2019-10-29 00:31:56,838 Training Epoch [4/40] Iter[98/312]		Loss: 0.5003
2019-10-29 00:31:56,960 Training Epoch [4/40] Iter[99/312]		Loss: 0.5018
2019-10-29 00:31:57,081 Training Epoch [4/40] Iter[100/312]		Loss: 0.5015
2019-10-29 00:31:57,203 Training Epoch [4/40] Iter[101/312]		Loss: 0.5018
2019-10-29 00:31:57,324 Training Epoch [4/40] Iter[102/312]		Loss: 0.5013
2019-10-29 00:31:57,446 Training Epoch [4/40] Iter[103/312]		Loss: 0.5004
2019-10-29 00:31:57,568 Training Epoch [4/40] Iter[104/312]		Loss: 0.5006
2019-10-29 00:31:57,689 Training Epoch [4/40] Iter[105/312]		Loss: 0.4998
2019-10-29 00:31:57,811 Training Epoch [4/40] Iter[106/312]		Loss: 0.4981
2019-10-29 00:31:57,932 Training Epoch [4/40] Iter[107/312]		Loss: 0.4997
2019-10-29 00:31:58,054 Training Epoch [4/40] Iter[108/312]		Loss: 0.5002
2019-10-29 00:31:58,175 Training Epoch [4/40] Iter[109/312]		Loss: 0.5025
2019-10-29 00:31:58,297 Training Epoch [4/40] Iter[110/312]		Loss: 0.5056
2019-10-29 00:31:58,419 Training Epoch [4/40] Iter[111/312]		Loss: 0.5068
2019-10-29 00:31:58,540 Training Epoch [4/40] Iter[112/312]		Loss: 0.5075
2019-10-29 00:31:58,661 Training Epoch [4/40] Iter[113/312]		Loss: 0.5073
2019-10-29 00:31:58,782 Training Epoch [4/40] Iter[114/312]		Loss: 0.5078
2019-10-29 00:31:58,903 Training Epoch [4/40] Iter[115/312]		Loss: 0.5069
2019-10-29 00:31:59,025 Training Epoch [4/40] Iter[116/312]		Loss: 0.5068
2019-10-29 00:31:59,146 Training Epoch [4/40] Iter[117/312]		Loss: 0.5078
2019-10-29 00:31:59,268 Training Epoch [4/40] Iter[118/312]		Loss: 0.5083
2019-10-29 00:31:59,390 Training Epoch [4/40] Iter[119/312]		Loss: 0.5080
2019-10-29 00:31:59,511 Training Epoch [4/40] Iter[120/312]		Loss: 0.5067
2019-10-29 00:31:59,633 Training Epoch [4/40] Iter[121/312]		Loss: 0.5063
2019-10-29 00:31:59,754 Training Epoch [4/40] Iter[122/312]		Loss: 0.5057
2019-10-29 00:31:59,875 Training Epoch [4/40] Iter[123/312]		Loss: 0.5057
2019-10-29 00:31:59,997 Training Epoch [4/40] Iter[124/312]		Loss: 0.5065
2019-10-29 00:32:00,119 Training Epoch [4/40] Iter[125/312]		Loss: 0.5055
2019-10-29 00:32:00,240 Training Epoch [4/40] Iter[126/312]		Loss: 0.5065
2019-10-29 00:32:00,362 Training Epoch [4/40] Iter[127/312]		Loss: 0.5074
2019-10-29 00:32:00,484 Training Epoch [4/40] Iter[128/312]		Loss: 0.5067
2019-10-29 00:32:00,606 Training Epoch [4/40] Iter[129/312]		Loss: 0.5063
2019-10-29 00:32:00,728 Training Epoch [4/40] Iter[130/312]		Loss: 0.5066
2019-10-29 00:32:00,850 Training Epoch [4/40] Iter[131/312]		Loss: 0.5059
2019-10-29 00:32:00,972 Training Epoch [4/40] Iter[132/312]		Loss: 0.5052
2019-10-29 00:32:01,094 Training Epoch [4/40] Iter[133/312]		Loss: 0.5057
2019-10-29 00:32:01,215 Training Epoch [4/40] Iter[134/312]		Loss: 0.5051
2019-10-29 00:32:01,337 Training Epoch [4/40] Iter[135/312]		Loss: 0.5050
2019-10-29 00:32:01,459 Training Epoch [4/40] Iter[136/312]		Loss: 0.5043
2019-10-29 00:32:01,580 Training Epoch [4/40] Iter[137/312]		Loss: 0.5039
2019-10-29 00:32:01,702 Training Epoch [4/40] Iter[138/312]		Loss: 0.5048
2019-10-29 00:32:01,823 Training Epoch [4/40] Iter[139/312]		Loss: 0.5042
2019-10-29 00:32:01,945 Training Epoch [4/40] Iter[140/312]		Loss: 0.5040
2019-10-29 00:32:02,066 Training Epoch [4/40] Iter[141/312]		Loss: 0.5053
2019-10-29 00:32:02,187 Training Epoch [4/40] Iter[142/312]		Loss: 0.5054
2019-10-29 00:32:02,309 Training Epoch [4/40] Iter[143/312]		Loss: 0.5061
2019-10-29 00:32:02,431 Training Epoch [4/40] Iter[144/312]		Loss: 0.5070
2019-10-29 00:32:02,552 Training Epoch [4/40] Iter[145/312]		Loss: 0.5064
2019-10-29 00:32:02,673 Training Epoch [4/40] Iter[146/312]		Loss: 0.5060
2019-10-29 00:32:02,795 Training Epoch [4/40] Iter[147/312]		Loss: 0.5050
2019-10-29 00:32:02,917 Training Epoch [4/40] Iter[148/312]		Loss: 0.5056
2019-10-29 00:32:03,039 Training Epoch [4/40] Iter[149/312]		Loss: 0.5054
2019-10-29 00:32:03,160 Training Epoch [4/40] Iter[150/312]		Loss: 0.5046
2019-10-29 00:32:03,282 Training Epoch [4/40] Iter[151/312]		Loss: 0.5045
2019-10-29 00:32:03,404 Training Epoch [4/40] Iter[152/312]		Loss: 0.5054
2019-10-29 00:32:03,526 Training Epoch [4/40] Iter[153/312]		Loss: 0.5048
2019-10-29 00:32:03,648 Training Epoch [4/40] Iter[154/312]		Loss: 0.5040
2019-10-29 00:32:03,769 Training Epoch [4/40] Iter[155/312]		Loss: 0.5042
2019-10-29 00:32:03,891 Training Epoch [4/40] Iter[156/312]		Loss: 0.5040
2019-10-29 00:32:04,012 Training Epoch [4/40] Iter[157/312]		Loss: 0.5044
2019-10-29 00:32:04,134 Training Epoch [4/40] Iter[158/312]		Loss: 0.5045
2019-10-29 00:32:04,256 Training Epoch [4/40] Iter[159/312]		Loss: 0.5041
2019-10-29 00:32:04,378 Training Epoch [4/40] Iter[160/312]		Loss: 0.5035
2019-10-29 00:32:04,499 Training Epoch [4/40] Iter[161/312]		Loss: 0.5040
2019-10-29 00:32:04,621 Training Epoch [4/40] Iter[162/312]		Loss: 0.5041
2019-10-29 00:32:04,742 Training Epoch [4/40] Iter[163/312]		Loss: 0.5045
2019-10-29 00:32:04,864 Training Epoch [4/40] Iter[164/312]		Loss: 0.5054
2019-10-29 00:32:04,986 Training Epoch [4/40] Iter[165/312]		Loss: 0.5053
2019-10-29 00:32:05,108 Training Epoch [4/40] Iter[166/312]		Loss: 0.5048
2019-10-29 00:32:05,232 Training Epoch [4/40] Iter[167/312]		Loss: 0.5047
2019-10-29 00:32:05,354 Training Epoch [4/40] Iter[168/312]		Loss: 0.5045
2019-10-29 00:32:05,476 Training Epoch [4/40] Iter[169/312]		Loss: 0.5036
2019-10-29 00:32:05,597 Training Epoch [4/40] Iter[170/312]		Loss: 0.5033
2019-10-29 00:32:05,719 Training Epoch [4/40] Iter[171/312]		Loss: 0.5025
2019-10-29 00:32:05,840 Training Epoch [4/40] Iter[172/312]		Loss: 0.5016
2019-10-29 00:32:05,962 Training Epoch [4/40] Iter[173/312]		Loss: 0.5008
2019-10-29 00:32:06,083 Training Epoch [4/40] Iter[174/312]		Loss: 0.5002
2019-10-29 00:32:06,205 Training Epoch [4/40] Iter[175/312]		Loss: 0.5002
2019-10-29 00:32:06,327 Training Epoch [4/40] Iter[176/312]		Loss: 0.4999
2019-10-29 00:32:06,449 Training Epoch [4/40] Iter[177/312]		Loss: 0.4993
2019-10-29 00:32:06,570 Training Epoch [4/40] Iter[178/312]		Loss: 0.4991
2019-10-29 00:32:06,692 Training Epoch [4/40] Iter[179/312]		Loss: 0.4997
2019-10-29 00:32:06,813 Training Epoch [4/40] Iter[180/312]		Loss: 0.4992
2019-10-29 00:32:06,934 Training Epoch [4/40] Iter[181/312]		Loss: 0.4989
2019-10-29 00:32:07,055 Training Epoch [4/40] Iter[182/312]		Loss: 0.4989
2019-10-29 00:32:07,176 Training Epoch [4/40] Iter[183/312]		Loss: 0.4986
2019-10-29 00:32:07,298 Training Epoch [4/40] Iter[184/312]		Loss: 0.4982
2019-10-29 00:32:07,419 Training Epoch [4/40] Iter[185/312]		Loss: 0.4977
2019-10-29 00:32:07,540 Training Epoch [4/40] Iter[186/312]		Loss: 0.4976
2019-10-29 00:32:07,661 Training Epoch [4/40] Iter[187/312]		Loss: 0.4973
2019-10-29 00:32:07,782 Training Epoch [4/40] Iter[188/312]		Loss: 0.4965
2019-10-29 00:32:07,903 Training Epoch [4/40] Iter[189/312]		Loss: 0.4959
2019-10-29 00:32:08,024 Training Epoch [4/40] Iter[190/312]		Loss: 0.4970
2019-10-29 00:32:08,147 Training Epoch [4/40] Iter[191/312]		Loss: 0.4963
2019-10-29 00:32:08,268 Training Epoch [4/40] Iter[192/312]		Loss: 0.4955
2019-10-29 00:32:08,390 Training Epoch [4/40] Iter[193/312]		Loss: 0.4955
2019-10-29 00:32:08,512 Training Epoch [4/40] Iter[194/312]		Loss: 0.4945
2019-10-29 00:32:08,634 Training Epoch [4/40] Iter[195/312]		Loss: 0.4936
2019-10-29 00:32:08,755 Training Epoch [4/40] Iter[196/312]		Loss: 0.4924
2019-10-29 00:32:08,877 Training Epoch [4/40] Iter[197/312]		Loss: 0.4915
2019-10-29 00:32:08,998 Training Epoch [4/40] Iter[198/312]		Loss: 0.4903
2019-10-29 00:32:09,120 Training Epoch [4/40] Iter[199/312]		Loss: 0.4896
2019-10-29 00:32:09,242 Training Epoch [4/40] Iter[200/312]		Loss: 0.4887
2019-10-29 00:32:09,364 Training Epoch [4/40] Iter[201/312]		Loss: 0.4881
2019-10-29 00:32:09,487 Training Epoch [4/40] Iter[202/312]		Loss: 0.4876
2019-10-29 00:32:09,609 Training Epoch [4/40] Iter[203/312]		Loss: 0.4871
2019-10-29 00:32:09,731 Training Epoch [4/40] Iter[204/312]		Loss: 0.4863
2019-10-29 00:32:09,852 Training Epoch [4/40] Iter[205/312]		Loss: 0.4863
2019-10-29 00:32:09,974 Training Epoch [4/40] Iter[206/312]		Loss: 0.4868
2019-10-29 00:32:10,095 Training Epoch [4/40] Iter[207/312]		Loss: 0.4863
2019-10-29 00:32:10,217 Training Epoch [4/40] Iter[208/312]		Loss: 0.4864
2019-10-29 00:32:10,338 Training Epoch [4/40] Iter[209/312]		Loss: 0.4869
2019-10-29 00:32:10,460 Training Epoch [4/40] Iter[210/312]		Loss: 0.4866
2019-10-29 00:32:10,581 Training Epoch [4/40] Iter[211/312]		Loss: 0.4862
2019-10-29 00:32:10,702 Training Epoch [4/40] Iter[212/312]		Loss: 0.4856
2019-10-29 00:32:10,824 Training Epoch [4/40] Iter[213/312]		Loss: 0.4849
2019-10-29 00:32:10,945 Training Epoch [4/40] Iter[214/312]		Loss: 0.4848
2019-10-29 00:32:11,067 Training Epoch [4/40] Iter[215/312]		Loss: 0.4845
2019-10-29 00:32:11,188 Training Epoch [4/40] Iter[216/312]		Loss: 0.4841
2019-10-29 00:32:11,310 Training Epoch [4/40] Iter[217/312]		Loss: 0.4838
2019-10-29 00:32:11,431 Training Epoch [4/40] Iter[218/312]		Loss: 0.4840
2019-10-29 00:32:11,553 Training Epoch [4/40] Iter[219/312]		Loss: 0.4840
2019-10-29 00:32:11,675 Training Epoch [4/40] Iter[220/312]		Loss: 0.4840
2019-10-29 00:32:11,796 Training Epoch [4/40] Iter[221/312]		Loss: 0.4840
2019-10-29 00:32:11,918 Training Epoch [4/40] Iter[222/312]		Loss: 0.4841
2019-10-29 00:32:12,040 Training Epoch [4/40] Iter[223/312]		Loss: 0.4840
2019-10-29 00:32:12,161 Training Epoch [4/40] Iter[224/312]		Loss: 0.4833
2019-10-29 00:32:12,282 Training Epoch [4/40] Iter[225/312]		Loss: 0.4837
2019-10-29 00:32:12,404 Training Epoch [4/40] Iter[226/312]		Loss: 0.4833
2019-10-29 00:32:12,526 Training Epoch [4/40] Iter[227/312]		Loss: 0.4828
2019-10-29 00:32:12,648 Training Epoch [4/40] Iter[228/312]		Loss: 0.4832
2019-10-29 00:32:12,770 Training Epoch [4/40] Iter[229/312]		Loss: 0.4831
2019-10-29 00:32:12,892 Training Epoch [4/40] Iter[230/312]		Loss: 0.4832
2019-10-29 00:32:13,013 Training Epoch [4/40] Iter[231/312]		Loss: 0.4829
2019-10-29 00:32:13,135 Training Epoch [4/40] Iter[232/312]		Loss: 0.4826
2019-10-29 00:32:13,257 Training Epoch [4/40] Iter[233/312]		Loss: 0.4827
2019-10-29 00:32:13,379 Training Epoch [4/40] Iter[234/312]		Loss: 0.4824
2019-10-29 00:32:13,500 Training Epoch [4/40] Iter[235/312]		Loss: 0.4819
2019-10-29 00:32:13,622 Training Epoch [4/40] Iter[236/312]		Loss: 0.4810
2019-10-29 00:32:13,743 Training Epoch [4/40] Iter[237/312]		Loss: 0.4808
2019-10-29 00:32:13,865 Training Epoch [4/40] Iter[238/312]		Loss: 0.4810
2019-10-29 00:32:13,986 Training Epoch [4/40] Iter[239/312]		Loss: 0.4807
2019-10-29 00:32:14,108 Training Epoch [4/40] Iter[240/312]		Loss: 0.4801
2019-10-29 00:32:14,230 Training Epoch [4/40] Iter[241/312]		Loss: 0.4795
2019-10-29 00:32:14,351 Training Epoch [4/40] Iter[242/312]		Loss: 0.4791
2019-10-29 00:32:14,473 Training Epoch [4/40] Iter[243/312]		Loss: 0.4792
2019-10-29 00:32:14,594 Training Epoch [4/40] Iter[244/312]		Loss: 0.4789
2019-10-29 00:32:14,716 Training Epoch [4/40] Iter[245/312]		Loss: 0.4792
2019-10-29 00:32:14,837 Training Epoch [4/40] Iter[246/312]		Loss: 0.4788
2019-10-29 00:32:14,959 Training Epoch [4/40] Iter[247/312]		Loss: 0.4785
2019-10-29 00:32:15,081 Training Epoch [4/40] Iter[248/312]		Loss: 0.4785
2019-10-29 00:32:15,202 Training Epoch [4/40] Iter[249/312]		Loss: 0.4786
2019-10-29 00:32:15,323 Training Epoch [4/40] Iter[250/312]		Loss: 0.4789
2019-10-29 00:32:15,445 Training Epoch [4/40] Iter[251/312]		Loss: 0.4791
2019-10-29 00:32:15,567 Training Epoch [4/40] Iter[252/312]		Loss: 0.4795
2019-10-29 00:32:15,688 Training Epoch [4/40] Iter[253/312]		Loss: 0.4800
2019-10-29 00:32:15,810 Training Epoch [4/40] Iter[254/312]		Loss: 0.4801
2019-10-29 00:32:15,931 Training Epoch [4/40] Iter[255/312]		Loss: 0.4801
2019-10-29 00:32:16,055 Training Epoch [4/40] Iter[256/312]		Loss: 0.4799
2019-10-29 00:32:16,177 Training Epoch [4/40] Iter[257/312]		Loss: 0.4795
2019-10-29 00:32:16,298 Training Epoch [4/40] Iter[258/312]		Loss: 0.4787
2019-10-29 00:32:16,420 Training Epoch [4/40] Iter[259/312]		Loss: 0.4786
2019-10-29 00:32:16,541 Training Epoch [4/40] Iter[260/312]		Loss: 0.4783
2019-10-29 00:32:16,663 Training Epoch [4/40] Iter[261/312]		Loss: 0.4783
2019-10-29 00:32:16,784 Training Epoch [4/40] Iter[262/312]		Loss: 0.4779
2019-10-29 00:32:16,906 Training Epoch [4/40] Iter[263/312]		Loss: 0.4773
2019-10-29 00:32:17,028 Training Epoch [4/40] Iter[264/312]		Loss: 0.4771
2019-10-29 00:32:17,150 Training Epoch [4/40] Iter[265/312]		Loss: 0.4764
2019-10-29 00:32:17,271 Training Epoch [4/40] Iter[266/312]		Loss: 0.4770
2019-10-29 00:32:17,393 Training Epoch [4/40] Iter[267/312]		Loss: 0.4769
2019-10-29 00:32:17,515 Training Epoch [4/40] Iter[268/312]		Loss: 0.4771
2019-10-29 00:32:17,637 Training Epoch [4/40] Iter[269/312]		Loss: 0.4771
2019-10-29 00:32:17,759 Training Epoch [4/40] Iter[270/312]		Loss: 0.4770
2019-10-29 00:32:17,881 Training Epoch [4/40] Iter[271/312]		Loss: 0.4768
2019-10-29 00:32:18,003 Training Epoch [4/40] Iter[272/312]		Loss: 0.4764
2019-10-29 00:32:18,125 Training Epoch [4/40] Iter[273/312]		Loss: 0.4760
2019-10-29 00:32:18,247 Training Epoch [4/40] Iter[274/312]		Loss: 0.4763
2019-10-29 00:32:18,369 Training Epoch [4/40] Iter[275/312]		Loss: 0.4776
2019-10-29 00:32:18,490 Training Epoch [4/40] Iter[276/312]		Loss: 0.4777
2019-10-29 00:32:18,611 Training Epoch [4/40] Iter[277/312]		Loss: 0.4771
2019-10-29 00:32:18,733 Training Epoch [4/40] Iter[278/312]		Loss: 0.4764
2019-10-29 00:32:18,854 Training Epoch [4/40] Iter[279/312]		Loss: 0.4766
2019-10-29 00:32:18,976 Training Epoch [4/40] Iter[280/312]		Loss: 0.4761
2019-10-29 00:32:19,098 Training Epoch [4/40] Iter[281/312]		Loss: 0.4759
2019-10-29 00:32:19,219 Training Epoch [4/40] Iter[282/312]		Loss: 0.4760
2019-10-29 00:32:19,341 Training Epoch [4/40] Iter[283/312]		Loss: 0.4762
2019-10-29 00:32:19,462 Training Epoch [4/40] Iter[284/312]		Loss: 0.4762
2019-10-29 00:32:19,583 Training Epoch [4/40] Iter[285/312]		Loss: 0.4762
2019-10-29 00:32:19,705 Training Epoch [4/40] Iter[286/312]		Loss: 0.4762
2019-10-29 00:32:19,827 Training Epoch [4/40] Iter[287/312]		Loss: 0.4768
2019-10-29 00:32:19,949 Training Epoch [4/40] Iter[288/312]		Loss: 0.4766
2019-10-29 00:32:20,071 Training Epoch [4/40] Iter[289/312]		Loss: 0.4767
2019-10-29 00:32:20,193 Training Epoch [4/40] Iter[290/312]		Loss: 0.4771
2019-10-29 00:32:20,314 Training Epoch [4/40] Iter[291/312]		Loss: 0.4770
2019-10-29 00:32:20,436 Training Epoch [4/40] Iter[292/312]		Loss: 0.4770
2019-10-29 00:32:20,557 Training Epoch [4/40] Iter[293/312]		Loss: 0.4773
2019-10-29 00:32:20,679 Training Epoch [4/40] Iter[294/312]		Loss: 0.4773
2019-10-29 00:32:20,800 Training Epoch [4/40] Iter[295/312]		Loss: 0.4772
2019-10-29 00:32:20,922 Training Epoch [4/40] Iter[296/312]		Loss: 0.4772
2019-10-29 00:32:21,044 Training Epoch [4/40] Iter[297/312]		Loss: 0.4771
2019-10-29 00:32:21,165 Training Epoch [4/40] Iter[298/312]		Loss: 0.4770
2019-10-29 00:32:21,287 Training Epoch [4/40] Iter[299/312]		Loss: 0.4766
2019-10-29 00:32:21,409 Training Epoch [4/40] Iter[300/312]		Loss: 0.4764
2019-10-29 00:32:21,530 Training Epoch [4/40] Iter[301/312]		Loss: 0.4766
2019-10-29 00:32:21,652 Training Epoch [4/40] Iter[302/312]		Loss: 0.4768
2019-10-29 00:32:21,773 Training Epoch [4/40] Iter[303/312]		Loss: 0.4768
2019-10-29 00:32:21,894 Training Epoch [4/40] Iter[304/312]		Loss: 0.4765
2019-10-29 00:32:22,015 Training Epoch [4/40] Iter[305/312]		Loss: 0.4764
2019-10-29 00:32:22,136 Training Epoch [4/40] Iter[306/312]		Loss: 0.4766
2019-10-29 00:32:22,257 Training Epoch [4/40] Iter[307/312]		Loss: 0.4767
2019-10-29 00:32:22,377 Training Epoch [4/40] Iter[308/312]		Loss: 0.4766
2019-10-29 00:32:22,498 Training Epoch [4/40] Iter[309/312]		Loss: 0.4764
2019-10-29 00:32:22,619 Training Epoch [4/40] Iter[310/312]		Loss: 0.4766
2019-10-29 00:32:22,740 Training Epoch [4/40] Iter[311/312]		Loss: 0.4766
2019-10-29 00:32:22,801 Training Epoch [4/40] Iter[312/312]		Loss: 0.4761
2019-10-29 00:32:23,198 Testing Epoch [4/40] Iter[0/62]		Loss: 0.4088
2019-10-29 00:32:23,240 Testing Epoch [4/40] Iter[1/62]		Loss: 0.4052
2019-10-29 00:32:23,274 Testing Epoch [4/40] Iter[2/62]		Loss: 0.3926
2019-10-29 00:32:23,304 Testing Epoch [4/40] Iter[3/62]		Loss: 0.3985
2019-10-29 00:32:23,338 Testing Epoch [4/40] Iter[4/62]		Loss: 0.4068
2019-10-29 00:32:23,368 Testing Epoch [4/40] Iter[5/62]		Loss: 0.3986
2019-10-29 00:32:23,401 Testing Epoch [4/40] Iter[6/62]		Loss: 0.4027
2019-10-29 00:32:23,434 Testing Epoch [4/40] Iter[7/62]		Loss: 0.3997
2019-10-29 00:32:23,465 Testing Epoch [4/40] Iter[8/62]		Loss: 0.3941
2019-10-29 00:32:23,496 Testing Epoch [4/40] Iter[9/62]		Loss: 0.3936
2019-10-29 00:32:23,530 Testing Epoch [4/40] Iter[10/62]		Loss: 0.3895
2019-10-29 00:32:23,560 Testing Epoch [4/40] Iter[11/62]		Loss: 0.4002
2019-10-29 00:32:23,591 Testing Epoch [4/40] Iter[12/62]		Loss: 0.4010
2019-10-29 00:32:23,626 Testing Epoch [4/40] Iter[13/62]		Loss: 0.4024
2019-10-29 00:32:23,657 Testing Epoch [4/40] Iter[14/62]		Loss: 0.4195
2019-10-29 00:32:23,688 Testing Epoch [4/40] Iter[15/62]		Loss: 0.4251
2019-10-29 00:32:23,722 Testing Epoch [4/40] Iter[16/62]		Loss: 0.4227
2019-10-29 00:32:23,752 Testing Epoch [4/40] Iter[17/62]		Loss: 0.4230
2019-10-29 00:32:23,783 Testing Epoch [4/40] Iter[18/62]		Loss: 0.4192
2019-10-29 00:32:23,818 Testing Epoch [4/40] Iter[19/62]		Loss: 0.4140
2019-10-29 00:32:23,850 Testing Epoch [4/40] Iter[20/62]		Loss: 0.4149
2019-10-29 00:32:23,880 Testing Epoch [4/40] Iter[21/62]		Loss: 0.4123
2019-10-29 00:32:23,911 Testing Epoch [4/40] Iter[22/62]		Loss: 0.4165
2019-10-29 00:32:23,942 Testing Epoch [4/40] Iter[23/62]		Loss: 0.4156
2019-10-29 00:32:23,972 Testing Epoch [4/40] Iter[24/62]		Loss: 0.4217
2019-10-29 00:32:24,003 Testing Epoch [4/40] Iter[25/62]		Loss: 0.4189
2019-10-29 00:32:24,033 Testing Epoch [4/40] Iter[26/62]		Loss: 0.4193
2019-10-29 00:32:24,064 Testing Epoch [4/40] Iter[27/62]		Loss: 0.4310
2019-10-29 00:32:24,094 Testing Epoch [4/40] Iter[28/62]		Loss: 0.4314
2019-10-29 00:32:24,125 Testing Epoch [4/40] Iter[29/62]		Loss: 0.4310
2019-10-29 00:32:24,156 Testing Epoch [4/40] Iter[30/62]		Loss: 0.4305
2019-10-29 00:32:24,187 Testing Epoch [4/40] Iter[31/62]		Loss: 0.4292
2019-10-29 00:32:24,217 Testing Epoch [4/40] Iter[32/62]		Loss: 0.4327
2019-10-29 00:32:24,248 Testing Epoch [4/40] Iter[33/62]		Loss: 0.4326
2019-10-29 00:32:24,279 Testing Epoch [4/40] Iter[34/62]		Loss: 0.4321
2019-10-29 00:32:24,310 Testing Epoch [4/40] Iter[35/62]		Loss: 0.4338
2019-10-29 00:32:24,341 Testing Epoch [4/40] Iter[36/62]		Loss: 0.4326
2019-10-29 00:32:24,371 Testing Epoch [4/40] Iter[37/62]		Loss: 0.4329
2019-10-29 00:32:24,402 Testing Epoch [4/40] Iter[38/62]		Loss: 0.4321
2019-10-29 00:32:24,433 Testing Epoch [4/40] Iter[39/62]		Loss: 0.4322
2019-10-29 00:32:24,464 Testing Epoch [4/40] Iter[40/62]		Loss: 0.4337
2019-10-29 00:32:24,494 Testing Epoch [4/40] Iter[41/62]		Loss: 0.4336
2019-10-29 00:32:24,525 Testing Epoch [4/40] Iter[42/62]		Loss: 0.4316
2019-10-29 00:32:24,556 Testing Epoch [4/40] Iter[43/62]		Loss: 0.4327
2019-10-29 00:32:24,586 Testing Epoch [4/40] Iter[44/62]		Loss: 0.4326
2019-10-29 00:32:24,617 Testing Epoch [4/40] Iter[45/62]		Loss: 0.4325
2019-10-29 00:32:24,648 Testing Epoch [4/40] Iter[46/62]		Loss: 0.4328
2019-10-29 00:32:24,679 Testing Epoch [4/40] Iter[47/62]		Loss: 0.4360
2019-10-29 00:32:24,710 Testing Epoch [4/40] Iter[48/62]		Loss: 0.4341
2019-10-29 00:32:24,740 Testing Epoch [4/40] Iter[49/62]		Loss: 0.4339
2019-10-29 00:32:24,771 Testing Epoch [4/40] Iter[50/62]		Loss: 0.4323
2019-10-29 00:32:24,802 Testing Epoch [4/40] Iter[51/62]		Loss: 0.4318
2019-10-29 00:32:24,833 Testing Epoch [4/40] Iter[52/62]		Loss: 0.4311
2019-10-29 00:32:24,866 Testing Epoch [4/40] Iter[53/62]		Loss: 0.4302
2019-10-29 00:32:24,897 Testing Epoch [4/40] Iter[54/62]		Loss: 0.4301
2019-10-29 00:32:24,927 Testing Epoch [4/40] Iter[55/62]		Loss: 0.4307
2019-10-29 00:32:24,958 Testing Epoch [4/40] Iter[56/62]		Loss: 0.4322
2019-10-29 00:32:24,988 Testing Epoch [4/40] Iter[57/62]		Loss: 0.4343
2019-10-29 00:32:25,019 Testing Epoch [4/40] Iter[58/62]		Loss: 0.4326
2019-10-29 00:32:25,049 Testing Epoch [4/40] Iter[59/62]		Loss: 0.4325
2019-10-29 00:32:25,079 Testing Epoch [4/40] Iter[60/62]		Loss: 0.4324
2019-10-29 00:32:25,109 Testing Epoch [4/40] Iter[61/62]		Loss: 0.4330
2019-10-29 00:32:25,126 Testing Epoch [4/40] Iter[62/62]		Loss: 0.4344
2019-10-29 00:32:25,193 Saving the Model
2019-10-29 00:32:25,633 Training Epoch [5/40] Iter[0/312]		Loss: 0.3586
2019-10-29 00:32:25,753 Training Epoch [5/40] Iter[1/312]		Loss: 0.4991
2019-10-29 00:32:25,875 Training Epoch [5/40] Iter[2/312]		Loss: 0.4795
2019-10-29 00:32:25,996 Training Epoch [5/40] Iter[3/312]		Loss: 0.4763
2019-10-29 00:32:26,118 Training Epoch [5/40] Iter[4/312]		Loss: 0.5159
2019-10-29 00:32:26,240 Training Epoch [5/40] Iter[5/312]		Loss: 0.5397
2019-10-29 00:32:26,363 Training Epoch [5/40] Iter[6/312]		Loss: 0.5196
2019-10-29 00:32:26,483 Training Epoch [5/40] Iter[7/312]		Loss: 0.5121
2019-10-29 00:32:26,604 Training Epoch [5/40] Iter[8/312]		Loss: 0.5196
2019-10-29 00:32:26,725 Training Epoch [5/40] Iter[9/312]		Loss: 0.5094
2019-10-29 00:32:26,847 Training Epoch [5/40] Iter[10/312]		Loss: 0.5079
2019-10-29 00:32:26,969 Training Epoch [5/40] Iter[11/312]		Loss: 0.4921
2019-10-29 00:32:27,090 Training Epoch [5/40] Iter[12/312]		Loss: 0.4815
2019-10-29 00:32:27,212 Training Epoch [5/40] Iter[13/312]		Loss: 0.4734
2019-10-29 00:32:27,333 Training Epoch [5/40] Iter[14/312]		Loss: 0.4684
2019-10-29 00:32:27,455 Training Epoch [5/40] Iter[15/312]		Loss: 0.4796
2019-10-29 00:32:27,576 Training Epoch [5/40] Iter[16/312]		Loss: 0.4856
2019-10-29 00:32:27,698 Training Epoch [5/40] Iter[17/312]		Loss: 0.4805
2019-10-29 00:32:27,819 Training Epoch [5/40] Iter[18/312]		Loss: 0.4812
2019-10-29 00:32:27,940 Training Epoch [5/40] Iter[19/312]		Loss: 0.4784
2019-10-29 00:32:28,061 Training Epoch [5/40] Iter[20/312]		Loss: 0.4822
2019-10-29 00:32:28,183 Training Epoch [5/40] Iter[21/312]		Loss: 0.4868
2019-10-29 00:32:28,304 Training Epoch [5/40] Iter[22/312]		Loss: 0.4825
2019-10-29 00:32:28,425 Training Epoch [5/40] Iter[23/312]		Loss: 0.4839
2019-10-29 00:32:28,547 Training Epoch [5/40] Iter[24/312]		Loss: 0.4800
2019-10-29 00:32:28,669 Training Epoch [5/40] Iter[25/312]		Loss: 0.4818
2019-10-29 00:32:28,790 Training Epoch [5/40] Iter[26/312]		Loss: 0.4827
2019-10-29 00:32:28,911 Training Epoch [5/40] Iter[27/312]		Loss: 0.4844
2019-10-29 00:32:29,033 Training Epoch [5/40] Iter[28/312]		Loss: 0.4802
2019-10-29 00:32:29,154 Training Epoch [5/40] Iter[29/312]		Loss: 0.4800
2019-10-29 00:32:29,276 Training Epoch [5/40] Iter[30/312]		Loss: 0.4820
2019-10-29 00:32:29,398 Training Epoch [5/40] Iter[31/312]		Loss: 0.4814
2019-10-29 00:32:29,519 Training Epoch [5/40] Iter[32/312]		Loss: 0.4799
2019-10-29 00:32:29,640 Training Epoch [5/40] Iter[33/312]		Loss: 0.4769
2019-10-29 00:32:29,762 Training Epoch [5/40] Iter[34/312]		Loss: 0.4753
2019-10-29 00:32:29,884 Training Epoch [5/40] Iter[35/312]		Loss: 0.4698
2019-10-29 00:32:30,006 Training Epoch [5/40] Iter[36/312]		Loss: 0.4686
2019-10-29 00:32:30,127 Training Epoch [5/40] Iter[37/312]		Loss: 0.4738
2019-10-29 00:32:30,249 Training Epoch [5/40] Iter[38/312]		Loss: 0.4748
2019-10-29 00:32:30,372 Training Epoch [5/40] Iter[39/312]		Loss: 0.4712
2019-10-29 00:32:30,493 Training Epoch [5/40] Iter[40/312]		Loss: 0.4684
2019-10-29 00:32:30,616 Training Epoch [5/40] Iter[41/312]		Loss: 0.4657
2019-10-29 00:32:30,738 Training Epoch [5/40] Iter[42/312]		Loss: 0.4640
2019-10-29 00:32:30,864 Training Epoch [5/40] Iter[43/312]		Loss: 0.4613
2019-10-29 00:32:30,985 Training Epoch [5/40] Iter[44/312]		Loss: 0.4642
2019-10-29 00:32:31,107 Training Epoch [5/40] Iter[45/312]		Loss: 0.4609
2019-10-29 00:32:31,228 Training Epoch [5/40] Iter[46/312]		Loss: 0.4626
2019-10-29 00:32:31,350 Training Epoch [5/40] Iter[47/312]		Loss: 0.4615
2019-10-29 00:32:31,471 Training Epoch [5/40] Iter[48/312]		Loss: 0.4598
2019-10-29 00:32:31,592 Training Epoch [5/40] Iter[49/312]		Loss: 0.4583
2019-10-29 00:32:31,713 Training Epoch [5/40] Iter[50/312]		Loss: 0.4562
2019-10-29 00:32:31,835 Training Epoch [5/40] Iter[51/312]		Loss: 0.4553
2019-10-29 00:32:31,956 Training Epoch [5/40] Iter[52/312]		Loss: 0.4528
2019-10-29 00:32:32,078 Training Epoch [5/40] Iter[53/312]		Loss: 0.4511
2019-10-29 00:32:32,200 Training Epoch [5/40] Iter[54/312]		Loss: 0.4495
2019-10-29 00:32:32,321 Training Epoch [5/40] Iter[55/312]		Loss: 0.4509
2019-10-29 00:32:32,443 Training Epoch [5/40] Iter[56/312]		Loss: 0.4486
2019-10-29 00:32:32,564 Training Epoch [5/40] Iter[57/312]		Loss: 0.4485
2019-10-29 00:32:32,686 Training Epoch [5/40] Iter[58/312]		Loss: 0.4491
2019-10-29 00:32:32,807 Training Epoch [5/40] Iter[59/312]		Loss: 0.4489
2019-10-29 00:32:32,928 Training Epoch [5/40] Iter[60/312]		Loss: 0.4484
2019-10-29 00:32:33,052 Training Epoch [5/40] Iter[61/312]		Loss: 0.4463
2019-10-29 00:32:33,173 Training Epoch [5/40] Iter[62/312]		Loss: 0.4453
2019-10-29 00:32:33,295 Training Epoch [5/40] Iter[63/312]		Loss: 0.4451
2019-10-29 00:32:33,416 Training Epoch [5/40] Iter[64/312]		Loss: 0.4454
2019-10-29 00:32:33,537 Training Epoch [5/40] Iter[65/312]		Loss: 0.4443
2019-10-29 00:32:33,658 Training Epoch [5/40] Iter[66/312]		Loss: 0.4443
2019-10-29 00:32:33,779 Training Epoch [5/40] Iter[67/312]		Loss: 0.4428
2019-10-29 00:32:33,901 Training Epoch [5/40] Iter[68/312]		Loss: 0.4442
2019-10-29 00:32:34,022 Training Epoch [5/40] Iter[69/312]		Loss: 0.4457
2019-10-29 00:32:34,143 Training Epoch [5/40] Iter[70/312]		Loss: 0.4466
2019-10-29 00:32:34,265 Training Epoch [5/40] Iter[71/312]		Loss: 0.4444
2019-10-29 00:32:34,387 Training Epoch [5/40] Iter[72/312]		Loss: 0.4438
2019-10-29 00:32:34,509 Training Epoch [5/40] Iter[73/312]		Loss: 0.4430
2019-10-29 00:32:34,631 Training Epoch [5/40] Iter[74/312]		Loss: 0.4446
2019-10-29 00:32:34,753 Training Epoch [5/40] Iter[75/312]		Loss: 0.4446
2019-10-29 00:32:34,875 Training Epoch [5/40] Iter[76/312]		Loss: 0.4432
2019-10-29 00:32:34,997 Training Epoch [5/40] Iter[77/312]		Loss: 0.4418
2019-10-29 00:32:35,119 Training Epoch [5/40] Iter[78/312]		Loss: 0.4426
2019-10-29 00:32:35,242 Training Epoch [5/40] Iter[79/312]		Loss: 0.4421
2019-10-29 00:32:35,365 Training Epoch [5/40] Iter[80/312]		Loss: 0.4425
2019-10-29 00:32:35,487 Training Epoch [5/40] Iter[81/312]		Loss: 0.4413
2019-10-29 00:32:35,609 Training Epoch [5/40] Iter[82/312]		Loss: 0.4406
2019-10-29 00:32:35,731 Training Epoch [5/40] Iter[83/312]		Loss: 0.4398
2019-10-29 00:32:35,852 Training Epoch [5/40] Iter[84/312]		Loss: 0.4415
2019-10-29 00:32:35,974 Training Epoch [5/40] Iter[85/312]		Loss: 0.4405
2019-10-29 00:32:36,096 Training Epoch [5/40] Iter[86/312]		Loss: 0.4417
2019-10-29 00:32:36,218 Training Epoch [5/40] Iter[87/312]		Loss: 0.4412
2019-10-29 00:32:36,339 Training Epoch [5/40] Iter[88/312]		Loss: 0.4410
2019-10-29 00:32:36,461 Training Epoch [5/40] Iter[89/312]		Loss: 0.4411
2019-10-29 00:32:36,583 Training Epoch [5/40] Iter[90/312]		Loss: 0.4392
2019-10-29 00:32:36,705 Training Epoch [5/40] Iter[91/312]		Loss: 0.4379
2019-10-29 00:32:36,827 Training Epoch [5/40] Iter[92/312]		Loss: 0.4374
2019-10-29 00:32:36,948 Training Epoch [5/40] Iter[93/312]		Loss: 0.4362
2019-10-29 00:32:37,070 Training Epoch [5/40] Iter[94/312]		Loss: 0.4366
2019-10-29 00:32:37,192 Training Epoch [5/40] Iter[95/312]		Loss: 0.4348
2019-10-29 00:32:37,315 Training Epoch [5/40] Iter[96/312]		Loss: 0.4330
2019-10-29 00:32:37,437 Training Epoch [5/40] Iter[97/312]		Loss: 0.4315
2019-10-29 00:32:37,559 Training Epoch [5/40] Iter[98/312]		Loss: 0.4306
2019-10-29 00:32:37,681 Training Epoch [5/40] Iter[99/312]		Loss: 0.4304
2019-10-29 00:32:37,802 Training Epoch [5/40] Iter[100/312]		Loss: 0.4289
2019-10-29 00:32:37,924 Training Epoch [5/40] Iter[101/312]		Loss: 0.4276
2019-10-29 00:32:38,046 Training Epoch [5/40] Iter[102/312]		Loss: 0.4268
2019-10-29 00:32:38,168 Training Epoch [5/40] Iter[103/312]		Loss: 0.4257
2019-10-29 00:32:38,290 Training Epoch [5/40] Iter[104/312]		Loss: 0.4259
2019-10-29 00:32:38,412 Training Epoch [5/40] Iter[105/312]		Loss: 0.4249
2019-10-29 00:32:38,534 Training Epoch [5/40] Iter[106/312]		Loss: 0.4245
2019-10-29 00:32:38,656 Training Epoch [5/40] Iter[107/312]		Loss: 0.4243
2019-10-29 00:32:38,778 Training Epoch [5/40] Iter[108/312]		Loss: 0.4235
2019-10-29 00:32:38,899 Training Epoch [5/40] Iter[109/312]		Loss: 0.4233
2019-10-29 00:32:39,021 Training Epoch [5/40] Iter[110/312]		Loss: 0.4233
2019-10-29 00:32:39,143 Training Epoch [5/40] Iter[111/312]		Loss: 0.4225
2019-10-29 00:32:39,264 Training Epoch [5/40] Iter[112/312]		Loss: 0.4222
2019-10-29 00:32:39,386 Training Epoch [5/40] Iter[113/312]		Loss: 0.4220
2019-10-29 00:32:39,509 Training Epoch [5/40] Iter[114/312]		Loss: 0.4219
2019-10-29 00:32:39,630 Training Epoch [5/40] Iter[115/312]		Loss: 0.4223
2019-10-29 00:32:39,752 Training Epoch [5/40] Iter[116/312]		Loss: 0.4223
2019-10-29 00:32:39,873 Training Epoch [5/40] Iter[117/312]		Loss: 0.4211
2019-10-29 00:32:39,995 Training Epoch [5/40] Iter[118/312]		Loss: 0.4214
2019-10-29 00:32:40,117 Training Epoch [5/40] Iter[119/312]		Loss: 0.4204
2019-10-29 00:32:40,239 Training Epoch [5/40] Iter[120/312]		Loss: 0.4192
2019-10-29 00:32:40,361 Training Epoch [5/40] Iter[121/312]		Loss: 0.4190
2019-10-29 00:32:40,483 Training Epoch [5/40] Iter[122/312]		Loss: 0.4178
2019-10-29 00:32:40,605 Training Epoch [5/40] Iter[123/312]		Loss: 0.4181
2019-10-29 00:32:40,727 Training Epoch [5/40] Iter[124/312]		Loss: 0.4183
2019-10-29 00:32:40,849 Training Epoch [5/40] Iter[125/312]		Loss: 0.4186
2019-10-29 00:32:40,971 Training Epoch [5/40] Iter[126/312]		Loss: 0.4176
2019-10-29 00:32:41,093 Training Epoch [5/40] Iter[127/312]		Loss: 0.4164
2019-10-29 00:32:41,215 Training Epoch [5/40] Iter[128/312]		Loss: 0.4152
2019-10-29 00:32:41,337 Training Epoch [5/40] Iter[129/312]		Loss: 0.4148
2019-10-29 00:32:41,458 Training Epoch [5/40] Iter[130/312]		Loss: 0.4153
2019-10-29 00:32:41,580 Training Epoch [5/40] Iter[131/312]		Loss: 0.4145
2019-10-29 00:32:41,701 Training Epoch [5/40] Iter[132/312]		Loss: 0.4143
2019-10-29 00:32:41,823 Training Epoch [5/40] Iter[133/312]		Loss: 0.4135
2019-10-29 00:32:41,944 Training Epoch [5/40] Iter[134/312]		Loss: 0.4142
2019-10-29 00:32:42,066 Training Epoch [5/40] Iter[135/312]		Loss: 0.4138
2019-10-29 00:32:42,188 Training Epoch [5/40] Iter[136/312]		Loss: 0.4130
2019-10-29 00:32:42,309 Training Epoch [5/40] Iter[137/312]		Loss: 0.4127
2019-10-29 00:32:42,431 Training Epoch [5/40] Iter[138/312]		Loss: 0.4122
2019-10-29 00:32:42,553 Training Epoch [5/40] Iter[139/312]		Loss: 0.4124
2019-10-29 00:32:42,675 Training Epoch [5/40] Iter[140/312]		Loss: 0.4128
2019-10-29 00:32:42,797 Training Epoch [5/40] Iter[141/312]		Loss: 0.4131
2019-10-29 00:32:42,919 Training Epoch [5/40] Iter[142/312]		Loss: 0.4132
2019-10-29 00:32:43,041 Training Epoch [5/40] Iter[143/312]		Loss: 0.4128
2019-10-29 00:32:43,163 Training Epoch [5/40] Iter[144/312]		Loss: 0.4125
2019-10-29 00:32:43,285 Training Epoch [5/40] Iter[145/312]		Loss: 0.4132
2019-10-29 00:32:43,408 Training Epoch [5/40] Iter[146/312]		Loss: 0.4129
2019-10-29 00:32:43,530 Training Epoch [5/40] Iter[147/312]		Loss: 0.4127
2019-10-29 00:32:43,652 Training Epoch [5/40] Iter[148/312]		Loss: 0.4124
2019-10-29 00:32:43,774 Training Epoch [5/40] Iter[149/312]		Loss: 0.4117
2019-10-29 00:32:43,896 Training Epoch [5/40] Iter[150/312]		Loss: 0.4119
2019-10-29 00:32:44,018 Training Epoch [5/40] Iter[151/312]		Loss: 0.4119
2019-10-29 00:32:44,140 Training Epoch [5/40] Iter[152/312]		Loss: 0.4123
2019-10-29 00:32:44,261 Training Epoch [5/40] Iter[153/312]		Loss: 0.4114
2019-10-29 00:32:44,383 Training Epoch [5/40] Iter[154/312]		Loss: 0.4102
2019-10-29 00:32:44,505 Training Epoch [5/40] Iter[155/312]		Loss: 0.4096
2019-10-29 00:32:44,626 Training Epoch [5/40] Iter[156/312]		Loss: 0.4097
2019-10-29 00:32:44,747 Training Epoch [5/40] Iter[157/312]		Loss: 0.4094
2019-10-29 00:32:44,868 Training Epoch [5/40] Iter[158/312]		Loss: 0.4087
2019-10-29 00:32:44,989 Training Epoch [5/40] Iter[159/312]		Loss: 0.4084
2019-10-29 00:32:45,111 Training Epoch [5/40] Iter[160/312]		Loss: 0.4094
2019-10-29 00:32:45,232 Training Epoch [5/40] Iter[161/312]		Loss: 0.4089
2019-10-29 00:32:45,354 Training Epoch [5/40] Iter[162/312]		Loss: 0.4091
2019-10-29 00:32:45,475 Training Epoch [5/40] Iter[163/312]		Loss: 0.4088
2019-10-29 00:32:45,596 Training Epoch [5/40] Iter[164/312]		Loss: 0.4087
2019-10-29 00:32:45,718 Training Epoch [5/40] Iter[165/312]		Loss: 0.4086
2019-10-29 00:32:45,840 Training Epoch [5/40] Iter[166/312]		Loss: 0.4089
2019-10-29 00:32:45,962 Training Epoch [5/40] Iter[167/312]		Loss: 0.4081
2019-10-29 00:32:46,084 Training Epoch [5/40] Iter[168/312]		Loss: 0.4076
2019-10-29 00:32:46,206 Training Epoch [5/40] Iter[169/312]		Loss: 0.4077
2019-10-29 00:32:46,327 Training Epoch [5/40] Iter[170/312]		Loss: 0.4073
2019-10-29 00:32:46,449 Training Epoch [5/40] Iter[171/312]		Loss: 0.4070
2019-10-29 00:32:46,570 Training Epoch [5/40] Iter[172/312]		Loss: 0.4063
2019-10-29 00:32:46,691 Training Epoch [5/40] Iter[173/312]		Loss: 0.4061
2019-10-29 00:32:46,813 Training Epoch [5/40] Iter[174/312]		Loss: 0.4057
2019-10-29 00:32:46,934 Training Epoch [5/40] Iter[175/312]		Loss: 0.4054
2019-10-29 00:32:47,056 Training Epoch [5/40] Iter[176/312]		Loss: 0.4049
2019-10-29 00:32:47,178 Training Epoch [5/40] Iter[177/312]		Loss: 0.4049
2019-10-29 00:32:47,299 Training Epoch [5/40] Iter[178/312]		Loss: 0.4047
2019-10-29 00:32:47,421 Training Epoch [5/40] Iter[179/312]		Loss: 0.4045
2019-10-29 00:32:47,542 Training Epoch [5/40] Iter[180/312]		Loss: 0.4040
2019-10-29 00:32:47,664 Training Epoch [5/40] Iter[181/312]		Loss: 0.4039
2019-10-29 00:32:47,785 Training Epoch [5/40] Iter[182/312]		Loss: 0.4036
2019-10-29 00:32:47,907 Training Epoch [5/40] Iter[183/312]		Loss: 0.4046
2019-10-29 00:32:48,029 Training Epoch [5/40] Iter[184/312]		Loss: 0.4047
2019-10-29 00:32:48,151 Training Epoch [5/40] Iter[185/312]		Loss: 0.4044
2019-10-29 00:32:48,273 Training Epoch [5/40] Iter[186/312]		Loss: 0.4057
2019-10-29 00:32:48,395 Training Epoch [5/40] Iter[187/312]		Loss: 0.4057
2019-10-29 00:32:48,516 Training Epoch [5/40] Iter[188/312]		Loss: 0.4061
2019-10-29 00:32:48,638 Training Epoch [5/40] Iter[189/312]		Loss: 0.4065
2019-10-29 00:32:48,759 Training Epoch [5/40] Iter[190/312]		Loss: 0.4069
2019-10-29 00:32:48,881 Training Epoch [5/40] Iter[191/312]		Loss: 0.4070
2019-10-29 00:32:49,002 Training Epoch [5/40] Iter[192/312]		Loss: 0.4075
2019-10-29 00:32:49,124 Training Epoch [5/40] Iter[193/312]		Loss: 0.4078
2019-10-29 00:32:49,246 Training Epoch [5/40] Iter[194/312]		Loss: 0.4075
2019-10-29 00:32:49,367 Training Epoch [5/40] Iter[195/312]		Loss: 0.4080
2019-10-29 00:32:49,489 Training Epoch [5/40] Iter[196/312]		Loss: 0.4075
2019-10-29 00:32:49,610 Training Epoch [5/40] Iter[197/312]		Loss: 0.4075
2019-10-29 00:32:49,732 Training Epoch [5/40] Iter[198/312]		Loss: 0.4066
2019-10-29 00:32:49,853 Training Epoch [5/40] Iter[199/312]		Loss: 0.4059
2019-10-29 00:32:49,974 Training Epoch [5/40] Iter[200/312]		Loss: 0.4062
2019-10-29 00:32:50,095 Training Epoch [5/40] Iter[201/312]		Loss: 0.4065
2019-10-29 00:32:50,216 Training Epoch [5/40] Iter[202/312]		Loss: 0.4061
2019-10-29 00:32:50,337 Training Epoch [5/40] Iter[203/312]		Loss: 0.4053
2019-10-29 00:32:50,458 Training Epoch [5/40] Iter[204/312]		Loss: 0.4045
2019-10-29 00:32:50,579 Training Epoch [5/40] Iter[205/312]		Loss: 0.4040
2019-10-29 00:32:50,700 Training Epoch [5/40] Iter[206/312]		Loss: 0.4037
2019-10-29 00:32:50,821 Training Epoch [5/40] Iter[207/312]		Loss: 0.4037
2019-10-29 00:32:50,943 Training Epoch [5/40] Iter[208/312]		Loss: 0.4039
2019-10-29 00:32:51,064 Training Epoch [5/40] Iter[209/312]		Loss: 0.4033
2019-10-29 00:32:51,186 Training Epoch [5/40] Iter[210/312]		Loss: 0.4028
2019-10-29 00:32:51,307 Training Epoch [5/40] Iter[211/312]		Loss: 0.4025
2019-10-29 00:32:51,429 Training Epoch [5/40] Iter[212/312]		Loss: 0.4026
2019-10-29 00:32:51,551 Training Epoch [5/40] Iter[213/312]		Loss: 0.4025
2019-10-29 00:32:51,672 Training Epoch [5/40] Iter[214/312]		Loss: 0.4021
2019-10-29 00:32:51,794 Training Epoch [5/40] Iter[215/312]		Loss: 0.4013
2019-10-29 00:32:51,915 Training Epoch [5/40] Iter[216/312]		Loss: 0.4012
2019-10-29 00:32:52,037 Training Epoch [5/40] Iter[217/312]		Loss: 0.4012
2019-10-29 00:32:52,159 Training Epoch [5/40] Iter[218/312]		Loss: 0.4009
2019-10-29 00:32:52,281 Training Epoch [5/40] Iter[219/312]		Loss: 0.4004
2019-10-29 00:32:52,403 Training Epoch [5/40] Iter[220/312]		Loss: 0.4004
2019-10-29 00:32:52,524 Training Epoch [5/40] Iter[221/312]		Loss: 0.4000
2019-10-29 00:32:52,646 Training Epoch [5/40] Iter[222/312]		Loss: 0.3996
2019-10-29 00:32:52,767 Training Epoch [5/40] Iter[223/312]		Loss: 0.3999
2019-10-29 00:32:52,888 Training Epoch [5/40] Iter[224/312]		Loss: 0.3998
2019-10-29 00:32:53,009 Training Epoch [5/40] Iter[225/312]		Loss: 0.3996
2019-10-29 00:32:53,131 Training Epoch [5/40] Iter[226/312]		Loss: 0.3998
2019-10-29 00:32:53,252 Training Epoch [5/40] Iter[227/312]		Loss: 0.4005
2019-10-29 00:32:53,374 Training Epoch [5/40] Iter[228/312]		Loss: 0.3997
2019-10-29 00:32:53,495 Training Epoch [5/40] Iter[229/312]		Loss: 0.3990
2019-10-29 00:32:53,616 Training Epoch [5/40] Iter[230/312]		Loss: 0.3987
2019-10-29 00:32:53,738 Training Epoch [5/40] Iter[231/312]		Loss: 0.3985
2019-10-29 00:32:53,859 Training Epoch [5/40] Iter[232/312]		Loss: 0.3980
2019-10-29 00:32:53,981 Training Epoch [5/40] Iter[233/312]		Loss: 0.3985
2019-10-29 00:32:54,102 Training Epoch [5/40] Iter[234/312]		Loss: 0.3982
2019-10-29 00:32:54,224 Training Epoch [5/40] Iter[235/312]		Loss: 0.3981
2019-10-29 00:32:54,346 Training Epoch [5/40] Iter[236/312]		Loss: 0.3979
2019-10-29 00:32:54,467 Training Epoch [5/40] Iter[237/312]		Loss: 0.3977
2019-10-29 00:32:54,588 Training Epoch [5/40] Iter[238/312]		Loss: 0.3978
2019-10-29 00:32:54,711 Training Epoch [5/40] Iter[239/312]		Loss: 0.3981
2019-10-29 00:32:54,833 Training Epoch [5/40] Iter[240/312]		Loss: 0.3976
2019-10-29 00:32:54,954 Training Epoch [5/40] Iter[241/312]		Loss: 0.3973
2019-10-29 00:32:55,076 Training Epoch [5/40] Iter[242/312]		Loss: 0.3977
2019-10-29 00:32:55,198 Training Epoch [5/40] Iter[243/312]		Loss: 0.3980
2019-10-29 00:32:55,319 Training Epoch [5/40] Iter[244/312]		Loss: 0.3977
2019-10-29 00:32:55,441 Training Epoch [5/40] Iter[245/312]		Loss: 0.3974
2019-10-29 00:32:55,563 Training Epoch [5/40] Iter[246/312]		Loss: 0.3974
2019-10-29 00:32:55,685 Training Epoch [5/40] Iter[247/312]		Loss: 0.3972
2019-10-29 00:32:55,806 Training Epoch [5/40] Iter[248/312]		Loss: 0.3974
2019-10-29 00:32:55,927 Training Epoch [5/40] Iter[249/312]		Loss: 0.3971
2019-10-29 00:32:56,049 Training Epoch [5/40] Iter[250/312]		Loss: 0.3972
2019-10-29 00:32:56,171 Training Epoch [5/40] Iter[251/312]		Loss: 0.3967
2019-10-29 00:32:56,297 Training Epoch [5/40] Iter[252/312]		Loss: 0.3968
2019-10-29 00:32:56,419 Training Epoch [5/40] Iter[253/312]		Loss: 0.3964
2019-10-29 00:32:56,540 Training Epoch [5/40] Iter[254/312]		Loss: 0.3959
2019-10-29 00:32:56,662 Training Epoch [5/40] Iter[255/312]		Loss: 0.3958
2019-10-29 00:32:56,783 Training Epoch [5/40] Iter[256/312]		Loss: 0.3959
2019-10-29 00:32:56,904 Training Epoch [5/40] Iter[257/312]		Loss: 0.3957
2019-10-29 00:32:57,026 Training Epoch [5/40] Iter[258/312]		Loss: 0.3960
2019-10-29 00:32:57,147 Training Epoch [5/40] Iter[259/312]		Loss: 0.3959
2019-10-29 00:32:57,269 Training Epoch [5/40] Iter[260/312]		Loss: 0.3958
2019-10-29 00:32:57,390 Training Epoch [5/40] Iter[261/312]		Loss: 0.3954
2019-10-29 00:32:57,512 Training Epoch [5/40] Iter[262/312]		Loss: 0.3958
2019-10-29 00:32:57,633 Training Epoch [5/40] Iter[263/312]		Loss: 0.3953
2019-10-29 00:32:57,755 Training Epoch [5/40] Iter[264/312]		Loss: 0.3951
2019-10-29 00:32:57,876 Training Epoch [5/40] Iter[265/312]		Loss: 0.3950
2019-10-29 00:32:57,998 Training Epoch [5/40] Iter[266/312]		Loss: 0.3949
2019-10-29 00:32:58,119 Training Epoch [5/40] Iter[267/312]		Loss: 0.3951
2019-10-29 00:32:58,240 Training Epoch [5/40] Iter[268/312]		Loss: 0.3950
2019-10-29 00:32:58,362 Training Epoch [5/40] Iter[269/312]		Loss: 0.3949
2019-10-29 00:32:58,483 Training Epoch [5/40] Iter[270/312]		Loss: 0.3945
2019-10-29 00:32:58,605 Training Epoch [5/40] Iter[271/312]		Loss: 0.3942
2019-10-29 00:32:58,726 Training Epoch [5/40] Iter[272/312]		Loss: 0.3944
2019-10-29 00:32:58,847 Training Epoch [5/40] Iter[273/312]		Loss: 0.3947
2019-10-29 00:32:58,968 Training Epoch [5/40] Iter[274/312]		Loss: 0.3946
2019-10-29 00:32:59,089 Training Epoch [5/40] Iter[275/312]		Loss: 0.3948
2019-10-29 00:32:59,210 Training Epoch [5/40] Iter[276/312]		Loss: 0.3948
2019-10-29 00:32:59,331 Training Epoch [5/40] Iter[277/312]		Loss: 0.3949
2019-10-29 00:32:59,452 Training Epoch [5/40] Iter[278/312]		Loss: 0.3944
2019-10-29 00:32:59,574 Training Epoch [5/40] Iter[279/312]		Loss: 0.3946
2019-10-29 00:32:59,695 Training Epoch [5/40] Iter[280/312]		Loss: 0.3944
2019-10-29 00:32:59,816 Training Epoch [5/40] Iter[281/312]		Loss: 0.3945
2019-10-29 00:32:59,937 Training Epoch [5/40] Iter[282/312]		Loss: 0.3944
2019-10-29 00:33:00,058 Training Epoch [5/40] Iter[283/312]		Loss: 0.3945
2019-10-29 00:33:00,180 Training Epoch [5/40] Iter[284/312]		Loss: 0.3940
2019-10-29 00:33:00,301 Training Epoch [5/40] Iter[285/312]		Loss: 0.3938
2019-10-29 00:33:00,423 Training Epoch [5/40] Iter[286/312]		Loss: 0.3935
2019-10-29 00:33:00,545 Training Epoch [5/40] Iter[287/312]		Loss: 0.3938
2019-10-29 00:33:00,666 Training Epoch [5/40] Iter[288/312]		Loss: 0.3939
2019-10-29 00:33:00,788 Training Epoch [5/40] Iter[289/312]		Loss: 0.3933
2019-10-29 00:33:00,909 Training Epoch [5/40] Iter[290/312]		Loss: 0.3930
2019-10-29 00:33:01,031 Training Epoch [5/40] Iter[291/312]		Loss: 0.3928
2019-10-29 00:33:01,156 Training Epoch [5/40] Iter[292/312]		Loss: 0.3926
2019-10-29 00:33:01,278 Training Epoch [5/40] Iter[293/312]		Loss: 0.3922
2019-10-29 00:33:01,400 Training Epoch [5/40] Iter[294/312]		Loss: 0.3919
2019-10-29 00:33:01,522 Training Epoch [5/40] Iter[295/312]		Loss: 0.3917
2019-10-29 00:33:01,644 Training Epoch [5/40] Iter[296/312]		Loss: 0.3914
2019-10-29 00:33:01,766 Training Epoch [5/40] Iter[297/312]		Loss: 0.3913
2019-10-29 00:33:01,888 Training Epoch [5/40] Iter[298/312]		Loss: 0.3909
2019-10-29 00:33:02,009 Training Epoch [5/40] Iter[299/312]		Loss: 0.3907
2019-10-29 00:33:02,131 Training Epoch [5/40] Iter[300/312]		Loss: 0.3904
2019-10-29 00:33:02,257 Training Epoch [5/40] Iter[301/312]		Loss: 0.3901
2019-10-29 00:33:02,378 Training Epoch [5/40] Iter[302/312]		Loss: 0.3895
2019-10-29 00:33:02,500 Training Epoch [5/40] Iter[303/312]		Loss: 0.3893
2019-10-29 00:33:02,621 Training Epoch [5/40] Iter[304/312]		Loss: 0.3893
2019-10-29 00:33:02,742 Training Epoch [5/40] Iter[305/312]		Loss: 0.3893
2019-10-29 00:33:02,862 Training Epoch [5/40] Iter[306/312]		Loss: 0.3893
2019-10-29 00:33:02,983 Training Epoch [5/40] Iter[307/312]		Loss: 0.3891
2019-10-29 00:33:03,103 Training Epoch [5/40] Iter[308/312]		Loss: 0.3889
2019-10-29 00:33:03,224 Training Epoch [5/40] Iter[309/312]		Loss: 0.3887
2019-10-29 00:33:03,345 Training Epoch [5/40] Iter[310/312]		Loss: 0.3885
2019-10-29 00:33:03,466 Training Epoch [5/40] Iter[311/312]		Loss: 0.3887
2019-10-29 00:33:03,526 Training Epoch [5/40] Iter[312/312]		Loss: 0.3886
2019-10-29 00:33:03,915 Testing Epoch [5/40] Iter[0/62]		Loss: 0.7111
2019-10-29 00:33:03,958 Testing Epoch [5/40] Iter[1/62]		Loss: 0.8033
2019-10-29 00:33:03,988 Testing Epoch [5/40] Iter[2/62]		Loss: 0.7770
2019-10-29 00:33:04,022 Testing Epoch [5/40] Iter[3/62]		Loss: 0.7738
2019-10-29 00:33:04,053 Testing Epoch [5/40] Iter[4/62]		Loss: 0.7619
2019-10-29 00:33:04,086 Testing Epoch [5/40] Iter[5/62]		Loss: 0.7749
2019-10-29 00:33:04,117 Testing Epoch [5/40] Iter[6/62]		Loss: 0.8055
2019-10-29 00:33:04,149 Testing Epoch [5/40] Iter[7/62]		Loss: 0.8066
2019-10-29 00:33:04,182 Testing Epoch [5/40] Iter[8/62]		Loss: 0.8001
2019-10-29 00:33:04,213 Testing Epoch [5/40] Iter[9/62]		Loss: 0.8075
2019-10-29 00:33:04,244 Testing Epoch [5/40] Iter[10/62]		Loss: 0.7955
2019-10-29 00:33:04,278 Testing Epoch [5/40] Iter[11/62]		Loss: 0.8342
2019-10-29 00:33:04,309 Testing Epoch [5/40] Iter[12/62]		Loss: 0.8344
2019-10-29 00:33:04,340 Testing Epoch [5/40] Iter[13/62]		Loss: 0.8499
2019-10-29 00:33:04,377 Testing Epoch [5/40] Iter[14/62]		Loss: 0.8545
2019-10-29 00:33:04,408 Testing Epoch [5/40] Iter[15/62]		Loss: 0.8604
2019-10-29 00:33:04,439 Testing Epoch [5/40] Iter[16/62]		Loss: 0.8432
2019-10-29 00:33:04,470 Testing Epoch [5/40] Iter[17/62]		Loss: 0.8537
2019-10-29 00:33:04,501 Testing Epoch [5/40] Iter[18/62]		Loss: 0.8336
2019-10-29 00:33:04,532 Testing Epoch [5/40] Iter[19/62]		Loss: 0.8304
2019-10-29 00:33:04,563 Testing Epoch [5/40] Iter[20/62]		Loss: 0.8272
2019-10-29 00:33:04,594 Testing Epoch [5/40] Iter[21/62]		Loss: 0.8144
2019-10-29 00:33:04,625 Testing Epoch [5/40] Iter[22/62]		Loss: 0.8115
2019-10-29 00:33:04,656 Testing Epoch [5/40] Iter[23/62]		Loss: 0.8075
2019-10-29 00:33:04,687 Testing Epoch [5/40] Iter[24/62]		Loss: 0.8064
2019-10-29 00:33:04,718 Testing Epoch [5/40] Iter[25/62]		Loss: 0.8050
2019-10-29 00:33:04,749 Testing Epoch [5/40] Iter[26/62]		Loss: 0.8044
2019-10-29 00:33:04,780 Testing Epoch [5/40] Iter[27/62]		Loss: 0.8215
2019-10-29 00:33:04,812 Testing Epoch [5/40] Iter[28/62]		Loss: 0.8276
2019-10-29 00:33:04,843 Testing Epoch [5/40] Iter[29/62]		Loss: 0.8248
2019-10-29 00:33:04,874 Testing Epoch [5/40] Iter[30/62]		Loss: 0.8301
2019-10-29 00:33:04,905 Testing Epoch [5/40] Iter[31/62]		Loss: 0.8265
2019-10-29 00:33:04,936 Testing Epoch [5/40] Iter[32/62]		Loss: 0.8243
2019-10-29 00:33:04,967 Testing Epoch [5/40] Iter[33/62]		Loss: 0.8263
2019-10-29 00:33:04,998 Testing Epoch [5/40] Iter[34/62]		Loss: 0.8247
2019-10-29 00:33:05,029 Testing Epoch [5/40] Iter[35/62]		Loss: 0.8224
2019-10-29 00:33:05,060 Testing Epoch [5/40] Iter[36/62]		Loss: 0.8217
2019-10-29 00:33:05,090 Testing Epoch [5/40] Iter[37/62]		Loss: 0.8183
2019-10-29 00:33:05,121 Testing Epoch [5/40] Iter[38/62]		Loss: 0.8196
2019-10-29 00:33:05,152 Testing Epoch [5/40] Iter[39/62]		Loss: 0.8198
2019-10-29 00:33:05,183 Testing Epoch [5/40] Iter[40/62]		Loss: 0.8245
2019-10-29 00:33:05,214 Testing Epoch [5/40] Iter[41/62]		Loss: 0.8271
2019-10-29 00:33:05,245 Testing Epoch [5/40] Iter[42/62]		Loss: 0.8263
2019-10-29 00:33:05,276 Testing Epoch [5/40] Iter[43/62]		Loss: 0.8283
2019-10-29 00:33:05,307 Testing Epoch [5/40] Iter[44/62]		Loss: 0.8302
2019-10-29 00:33:05,341 Testing Epoch [5/40] Iter[45/62]		Loss: 0.8270
2019-10-29 00:33:05,372 Testing Epoch [5/40] Iter[46/62]		Loss: 0.8285
2019-10-29 00:33:05,403 Testing Epoch [5/40] Iter[47/62]		Loss: 0.8324
2019-10-29 00:33:05,434 Testing Epoch [5/40] Iter[48/62]		Loss: 0.8338
2019-10-29 00:33:05,464 Testing Epoch [5/40] Iter[49/62]		Loss: 0.8294
2019-10-29 00:33:05,495 Testing Epoch [5/40] Iter[50/62]		Loss: 0.8270
2019-10-29 00:33:05,526 Testing Epoch [5/40] Iter[51/62]		Loss: 0.8254
2019-10-29 00:33:05,557 Testing Epoch [5/40] Iter[52/62]		Loss: 0.8222
2019-10-29 00:33:05,588 Testing Epoch [5/40] Iter[53/62]		Loss: 0.8220
2019-10-29 00:33:05,619 Testing Epoch [5/40] Iter[54/62]		Loss: 0.8188
2019-10-29 00:33:05,649 Testing Epoch [5/40] Iter[55/62]		Loss: 0.8180
2019-10-29 00:33:05,680 Testing Epoch [5/40] Iter[56/62]		Loss: 0.8217
2019-10-29 00:33:05,711 Testing Epoch [5/40] Iter[57/62]		Loss: 0.8260
2019-10-29 00:33:05,741 Testing Epoch [5/40] Iter[58/62]		Loss: 0.8247
2019-10-29 00:33:05,772 Testing Epoch [5/40] Iter[59/62]		Loss: 0.8235
2019-10-29 00:33:05,802 Testing Epoch [5/40] Iter[60/62]		Loss: 0.8224
2019-10-29 00:33:05,833 Testing Epoch [5/40] Iter[61/62]		Loss: 0.8279
2019-10-29 00:33:05,850 Testing Epoch [5/40] Iter[62/62]		Loss: 0.8242
2019-10-29 00:33:06,368 Training Epoch [6/40] Iter[0/312]		Loss: 0.4153
2019-10-29 00:33:06,489 Training Epoch [6/40] Iter[1/312]		Loss: 0.5393
2019-10-29 00:33:06,610 Training Epoch [6/40] Iter[2/312]		Loss: 0.5171
2019-10-29 00:33:06,732 Training Epoch [6/40] Iter[3/312]		Loss: 0.4792
2019-10-29 00:33:06,856 Training Epoch [6/40] Iter[4/312]		Loss: 0.4664
2019-10-29 00:33:06,976 Training Epoch [6/40] Iter[5/312]		Loss: 0.4690
2019-10-29 00:33:07,096 Training Epoch [6/40] Iter[6/312]		Loss: 0.4703
2019-10-29 00:33:07,217 Training Epoch [6/40] Iter[7/312]		Loss: 0.4710
2019-10-29 00:33:07,339 Training Epoch [6/40] Iter[8/312]		Loss: 0.4713
2019-10-29 00:33:07,465 Training Epoch [6/40] Iter[9/312]		Loss: 0.4687
2019-10-29 00:33:07,586 Training Epoch [6/40] Iter[10/312]		Loss: 0.4533
2019-10-29 00:33:07,707 Training Epoch [6/40] Iter[11/312]		Loss: 0.4384
2019-10-29 00:33:07,828 Training Epoch [6/40] Iter[12/312]		Loss: 0.4375
2019-10-29 00:33:07,949 Training Epoch [6/40] Iter[13/312]		Loss: 0.4426
2019-10-29 00:33:08,070 Training Epoch [6/40] Iter[14/312]		Loss: 0.4463
2019-10-29 00:33:08,191 Training Epoch [6/40] Iter[15/312]		Loss: 0.4399
2019-10-29 00:33:08,312 Training Epoch [6/40] Iter[16/312]		Loss: 0.4332
2019-10-29 00:33:08,433 Training Epoch [6/40] Iter[17/312]		Loss: 0.4340
2019-10-29 00:33:08,554 Training Epoch [6/40] Iter[18/312]		Loss: 0.4299
2019-10-29 00:33:08,676 Training Epoch [6/40] Iter[19/312]		Loss: 0.4314
2019-10-29 00:33:08,797 Training Epoch [6/40] Iter[20/312]		Loss: 0.4278
2019-10-29 00:33:08,919 Training Epoch [6/40] Iter[21/312]		Loss: 0.4258
2019-10-29 00:33:09,040 Training Epoch [6/40] Iter[22/312]		Loss: 0.4275
2019-10-29 00:33:09,162 Training Epoch [6/40] Iter[23/312]		Loss: 0.4300
2019-10-29 00:33:09,284 Training Epoch [6/40] Iter[24/312]		Loss: 0.4280
2019-10-29 00:33:09,406 Training Epoch [6/40] Iter[25/312]		Loss: 0.4272
2019-10-29 00:33:09,527 Training Epoch [6/40] Iter[26/312]		Loss: 0.4248
2019-10-29 00:33:09,649 Training Epoch [6/40] Iter[27/312]		Loss: 0.4260
2019-10-29 00:33:09,771 Training Epoch [6/40] Iter[28/312]		Loss: 0.4232
2019-10-29 00:33:09,892 Training Epoch [6/40] Iter[29/312]		Loss: 0.4179
2019-10-29 00:33:10,014 Training Epoch [6/40] Iter[30/312]		Loss: 0.4189
2019-10-29 00:33:10,136 Training Epoch [6/40] Iter[31/312]		Loss: 0.4140
2019-10-29 00:33:10,258 Training Epoch [6/40] Iter[32/312]		Loss: 0.4120
2019-10-29 00:33:10,380 Training Epoch [6/40] Iter[33/312]		Loss: 0.4153
2019-10-29 00:33:10,502 Training Epoch [6/40] Iter[34/312]		Loss: 0.4148
2019-10-29 00:33:10,623 Training Epoch [6/40] Iter[35/312]		Loss: 0.4154
2019-10-29 00:33:10,745 Training Epoch [6/40] Iter[36/312]		Loss: 0.4142
2019-10-29 00:33:10,866 Training Epoch [6/40] Iter[37/312]		Loss: 0.4132
2019-10-29 00:33:10,987 Training Epoch [6/40] Iter[38/312]		Loss: 0.4107
2019-10-29 00:33:11,112 Training Epoch [6/40] Iter[39/312]		Loss: 0.4077
2019-10-29 00:33:11,233 Training Epoch [6/40] Iter[40/312]		Loss: 0.4092
2019-10-29 00:33:11,356 Training Epoch [6/40] Iter[41/312]		Loss: 0.4064
2019-10-29 00:33:11,477 Training Epoch [6/40] Iter[42/312]		Loss: 0.4054
2019-10-29 00:33:11,598 Training Epoch [6/40] Iter[43/312]		Loss: 0.4014
2019-10-29 00:33:11,720 Training Epoch [6/40] Iter[44/312]		Loss: 0.4006
2019-10-29 00:33:11,842 Training Epoch [6/40] Iter[45/312]		Loss: 0.3974
2019-10-29 00:33:11,963 Training Epoch [6/40] Iter[46/312]		Loss: 0.3962
2019-10-29 00:33:12,084 Training Epoch [6/40] Iter[47/312]		Loss: 0.3930
2019-10-29 00:33:12,212 Training Epoch [6/40] Iter[48/312]		Loss: 0.3910
2019-10-29 00:33:12,336 Training Epoch [6/40] Iter[49/312]		Loss: 0.3906
2019-10-29 00:33:12,460 Training Epoch [6/40] Iter[50/312]		Loss: 0.3883
2019-10-29 00:33:12,581 Training Epoch [6/40] Iter[51/312]		Loss: 0.3879
2019-10-29 00:33:12,702 Training Epoch [6/40] Iter[52/312]		Loss: 0.3875
2019-10-29 00:33:12,828 Training Epoch [6/40] Iter[53/312]		Loss: 0.3914
2019-10-29 00:33:12,952 Training Epoch [6/40] Iter[54/312]		Loss: 0.3917
2019-10-29 00:33:13,073 Training Epoch [6/40] Iter[55/312]		Loss: 0.3902
2019-10-29 00:33:13,195 Training Epoch [6/40] Iter[56/312]		Loss: 0.3887
2019-10-29 00:33:13,320 Training Epoch [6/40] Iter[57/312]		Loss: 0.3898
2019-10-29 00:33:13,445 Training Epoch [6/40] Iter[58/312]		Loss: 0.3893
2019-10-29 00:33:13,566 Training Epoch [6/40] Iter[59/312]		Loss: 0.3873
2019-10-29 00:33:13,688 Training Epoch [6/40] Iter[60/312]		Loss: 0.3869
2019-10-29 00:33:13,812 Training Epoch [6/40] Iter[61/312]		Loss: 0.3843
2019-10-29 00:33:13,936 Training Epoch [6/40] Iter[62/312]		Loss: 0.3825
2019-10-29 00:33:14,058 Training Epoch [6/40] Iter[63/312]		Loss: 0.3814
2019-10-29 00:33:14,179 Training Epoch [6/40] Iter[64/312]		Loss: 0.3818
2019-10-29 00:33:14,304 Training Epoch [6/40] Iter[65/312]		Loss: 0.3818
2019-10-29 00:33:14,428 Training Epoch [6/40] Iter[66/312]		Loss: 0.3831
2019-10-29 00:33:14,549 Training Epoch [6/40] Iter[67/312]		Loss: 0.3832
2019-10-29 00:33:14,670 Training Epoch [6/40] Iter[68/312]		Loss: 0.3817
2019-10-29 00:33:14,796 Training Epoch [6/40] Iter[69/312]		Loss: 0.3813
2019-10-29 00:33:14,920 Training Epoch [6/40] Iter[70/312]		Loss: 0.3828
2019-10-29 00:33:15,041 Training Epoch [6/40] Iter[71/312]		Loss: 0.3828
2019-10-29 00:33:15,163 Training Epoch [6/40] Iter[72/312]		Loss: 0.3818
2019-10-29 00:33:15,288 Training Epoch [6/40] Iter[73/312]		Loss: 0.3807
2019-10-29 00:33:15,412 Training Epoch [6/40] Iter[74/312]		Loss: 0.3808
2019-10-29 00:33:15,534 Training Epoch [6/40] Iter[75/312]		Loss: 0.3797
2019-10-29 00:33:15,655 Training Epoch [6/40] Iter[76/312]		Loss: 0.3777
2019-10-29 00:33:15,777 Training Epoch [6/40] Iter[77/312]		Loss: 0.3769
2019-10-29 00:33:15,899 Training Epoch [6/40] Iter[78/312]		Loss: 0.3762
2019-10-29 00:33:16,020 Training Epoch [6/40] Iter[79/312]		Loss: 0.3752
2019-10-29 00:33:16,142 Training Epoch [6/40] Iter[80/312]		Loss: 0.3760
2019-10-29 00:33:16,262 Training Epoch [6/40] Iter[81/312]		Loss: 0.3762
2019-10-29 00:33:16,383 Training Epoch [6/40] Iter[82/312]		Loss: 0.3762
2019-10-29 00:33:16,505 Training Epoch [6/40] Iter[83/312]		Loss: 0.3748
2019-10-29 00:33:16,626 Training Epoch [6/40] Iter[84/312]		Loss: 0.3743
2019-10-29 00:33:16,747 Training Epoch [6/40] Iter[85/312]		Loss: 0.3745
2019-10-29 00:33:16,869 Training Epoch [6/40] Iter[86/312]		Loss: 0.3741
2019-10-29 00:33:16,990 Training Epoch [6/40] Iter[87/312]		Loss: 0.3736
2019-10-29 00:33:17,112 Training Epoch [6/40] Iter[88/312]		Loss: 0.3728
2019-10-29 00:33:17,233 Training Epoch [6/40] Iter[89/312]		Loss: 0.3725
2019-10-29 00:33:17,355 Training Epoch [6/40] Iter[90/312]		Loss: 0.3707
2019-10-29 00:33:17,477 Training Epoch [6/40] Iter[91/312]		Loss: 0.3710
2019-10-29 00:33:17,598 Training Epoch [6/40] Iter[92/312]		Loss: 0.3715
2019-10-29 00:33:17,720 Training Epoch [6/40] Iter[93/312]		Loss: 0.3709
2019-10-29 00:33:17,842 Training Epoch [6/40] Iter[94/312]		Loss: 0.3708
2019-10-29 00:33:17,963 Training Epoch [6/40] Iter[95/312]		Loss: 0.3699
2019-10-29 00:33:18,085 Training Epoch [6/40] Iter[96/312]		Loss: 0.3709
2019-10-29 00:33:18,207 Training Epoch [6/40] Iter[97/312]		Loss: 0.3702
2019-10-29 00:33:18,329 Training Epoch [6/40] Iter[98/312]		Loss: 0.3693
2019-10-29 00:33:18,450 Training Epoch [6/40] Iter[99/312]		Loss: 0.3686
2019-10-29 00:33:18,572 Training Epoch [6/40] Iter[100/312]		Loss: 0.3682
2019-10-29 00:33:18,693 Training Epoch [6/40] Iter[101/312]		Loss: 0.3682
2019-10-29 00:33:18,816 Training Epoch [6/40] Iter[102/312]		Loss: 0.3677
2019-10-29 00:33:18,937 Training Epoch [6/40] Iter[103/312]		Loss: 0.3670
2019-10-29 00:33:19,059 Training Epoch [6/40] Iter[104/312]		Loss: 0.3659
2019-10-29 00:33:19,180 Training Epoch [6/40] Iter[105/312]		Loss: 0.3654
2019-10-29 00:33:19,301 Training Epoch [6/40] Iter[106/312]		Loss: 0.3642
2019-10-29 00:33:19,423 Training Epoch [6/40] Iter[107/312]		Loss: 0.3632
2019-10-29 00:33:19,544 Training Epoch [6/40] Iter[108/312]		Loss: 0.3629
2019-10-29 00:33:19,666 Training Epoch [6/40] Iter[109/312]		Loss: 0.3620
2019-10-29 00:33:19,787 Training Epoch [6/40] Iter[110/312]		Loss: 0.3609
2019-10-29 00:33:19,909 Training Epoch [6/40] Iter[111/312]		Loss: 0.3610
2019-10-29 00:33:20,030 Training Epoch [6/40] Iter[112/312]		Loss: 0.3605
2019-10-29 00:33:20,151 Training Epoch [6/40] Iter[113/312]		Loss: 0.3615
2019-10-29 00:33:20,273 Training Epoch [6/40] Iter[114/312]		Loss: 0.3607
2019-10-29 00:33:20,394 Training Epoch [6/40] Iter[115/312]		Loss: 0.3607
2019-10-29 00:33:20,516 Training Epoch [6/40] Iter[116/312]		Loss: 0.3602
2019-10-29 00:33:20,637 Training Epoch [6/40] Iter[117/312]		Loss: 0.3600
2019-10-29 00:33:20,759 Training Epoch [6/40] Iter[118/312]		Loss: 0.3600
2019-10-29 00:33:20,881 Training Epoch [6/40] Iter[119/312]		Loss: 0.3598
2019-10-29 00:33:21,002 Training Epoch [6/40] Iter[120/312]		Loss: 0.3590
2019-10-29 00:33:21,124 Training Epoch [6/40] Iter[121/312]		Loss: 0.3578
2019-10-29 00:33:21,245 Training Epoch [6/40] Iter[122/312]		Loss: 0.3577
2019-10-29 00:33:21,367 Training Epoch [6/40] Iter[123/312]		Loss: 0.3570
2019-10-29 00:33:21,489 Training Epoch [6/40] Iter[124/312]		Loss: 0.3560
2019-10-29 00:33:21,611 Training Epoch [6/40] Iter[125/312]		Loss: 0.3563
2019-10-29 00:33:21,732 Training Epoch [6/40] Iter[126/312]		Loss: 0.3562
2019-10-29 00:33:21,854 Training Epoch [6/40] Iter[127/312]		Loss: 0.3557
2019-10-29 00:33:21,976 Training Epoch [6/40] Iter[128/312]		Loss: 0.3558
2019-10-29 00:33:22,098 Training Epoch [6/40] Iter[129/312]		Loss: 0.3554
2019-10-29 00:33:22,219 Training Epoch [6/40] Iter[130/312]		Loss: 0.3556
2019-10-29 00:33:22,341 Training Epoch [6/40] Iter[131/312]		Loss: 0.3550
2019-10-29 00:33:22,462 Training Epoch [6/40] Iter[132/312]		Loss: 0.3550
2019-10-29 00:33:22,584 Training Epoch [6/40] Iter[133/312]		Loss: 0.3542
2019-10-29 00:33:22,705 Training Epoch [6/40] Iter[134/312]		Loss: 0.3547
2019-10-29 00:33:22,827 Training Epoch [6/40] Iter[135/312]		Loss: 0.3550
2019-10-29 00:33:22,949 Training Epoch [6/40] Iter[136/312]		Loss: 0.3552
2019-10-29 00:33:23,070 Training Epoch [6/40] Iter[137/312]		Loss: 0.3561
2019-10-29 00:33:23,192 Training Epoch [6/40] Iter[138/312]		Loss: 0.3570
2019-10-29 00:33:23,313 Training Epoch [6/40] Iter[139/312]		Loss: 0.3560
2019-10-29 00:33:23,435 Training Epoch [6/40] Iter[140/312]		Loss: 0.3560
2019-10-29 00:33:23,556 Training Epoch [6/40] Iter[141/312]		Loss: 0.3558
2019-10-29 00:33:23,678 Training Epoch [6/40] Iter[142/312]		Loss: 0.3552
2019-10-29 00:33:23,799 Training Epoch [6/40] Iter[143/312]		Loss: 0.3553
2019-10-29 00:33:23,921 Training Epoch [6/40] Iter[144/312]		Loss: 0.3549
2019-10-29 00:33:24,042 Training Epoch [6/40] Iter[145/312]		Loss: 0.3544
2019-10-29 00:33:24,164 Training Epoch [6/40] Iter[146/312]		Loss: 0.3548
2019-10-29 00:33:24,285 Training Epoch [6/40] Iter[147/312]		Loss: 0.3545
2019-10-29 00:33:24,407 Training Epoch [6/40] Iter[148/312]		Loss: 0.3544
2019-10-29 00:33:24,529 Training Epoch [6/40] Iter[149/312]		Loss: 0.3541
2019-10-29 00:33:24,651 Training Epoch [6/40] Iter[150/312]		Loss: 0.3539
2019-10-29 00:33:24,772 Training Epoch [6/40] Iter[151/312]		Loss: 0.3534
2019-10-29 00:33:24,893 Training Epoch [6/40] Iter[152/312]		Loss: 0.3537
2019-10-29 00:33:25,014 Training Epoch [6/40] Iter[153/312]		Loss: 0.3533
2019-10-29 00:33:25,136 Training Epoch [6/40] Iter[154/312]		Loss: 0.3541
2019-10-29 00:33:25,257 Training Epoch [6/40] Iter[155/312]		Loss: 0.3545
2019-10-29 00:33:25,378 Training Epoch [6/40] Iter[156/312]		Loss: 0.3538
2019-10-29 00:33:25,500 Training Epoch [6/40] Iter[157/312]		Loss: 0.3544
2019-10-29 00:33:25,621 Training Epoch [6/40] Iter[158/312]		Loss: 0.3554
2019-10-29 00:33:25,742 Training Epoch [6/40] Iter[159/312]		Loss: 0.3562
2019-10-29 00:33:25,864 Training Epoch [6/40] Iter[160/312]		Loss: 0.3564
2019-10-29 00:33:25,986 Training Epoch [6/40] Iter[161/312]		Loss: 0.3561
2019-10-29 00:33:26,108 Training Epoch [6/40] Iter[162/312]		Loss: 0.3559
2019-10-29 00:33:26,230 Training Epoch [6/40] Iter[163/312]		Loss: 0.3559
2019-10-29 00:33:26,351 Training Epoch [6/40] Iter[164/312]		Loss: 0.3565
2019-10-29 00:33:26,473 Training Epoch [6/40] Iter[165/312]		Loss: 0.3565
2019-10-29 00:33:26,594 Training Epoch [6/40] Iter[166/312]		Loss: 0.3566
2019-10-29 00:33:26,716 Training Epoch [6/40] Iter[167/312]		Loss: 0.3568
2019-10-29 00:33:26,837 Training Epoch [6/40] Iter[168/312]		Loss: 0.3578
2019-10-29 00:33:26,959 Training Epoch [6/40] Iter[169/312]		Loss: 0.3583
2019-10-29 00:33:27,081 Training Epoch [6/40] Iter[170/312]		Loss: 0.3577
2019-10-29 00:33:27,203 Training Epoch [6/40] Iter[171/312]		Loss: 0.3575
2019-10-29 00:33:27,326 Training Epoch [6/40] Iter[172/312]		Loss: 0.3573
2019-10-29 00:33:27,448 Training Epoch [6/40] Iter[173/312]		Loss: 0.3570
2019-10-29 00:33:27,570 Training Epoch [6/40] Iter[174/312]		Loss: 0.3570
2019-10-29 00:33:27,691 Training Epoch [6/40] Iter[175/312]		Loss: 0.3574
2019-10-29 00:33:27,812 Training Epoch [6/40] Iter[176/312]		Loss: 0.3578
2019-10-29 00:33:27,934 Training Epoch [6/40] Iter[177/312]		Loss: 0.3585
2019-10-29 00:33:28,055 Training Epoch [6/40] Iter[178/312]		Loss: 0.3582
2019-10-29 00:33:28,176 Training Epoch [6/40] Iter[179/312]		Loss: 0.3579
2019-10-29 00:33:28,298 Training Epoch [6/40] Iter[180/312]		Loss: 0.3571
2019-10-29 00:33:28,419 Training Epoch [6/40] Iter[181/312]		Loss: 0.3569
2019-10-29 00:33:28,540 Training Epoch [6/40] Iter[182/312]		Loss: 0.3572
2019-10-29 00:33:28,662 Training Epoch [6/40] Iter[183/312]		Loss: 0.3566
2019-10-29 00:33:28,783 Training Epoch [6/40] Iter[184/312]		Loss: 0.3562
2019-10-29 00:33:28,904 Training Epoch [6/40] Iter[185/312]		Loss: 0.3556
2019-10-29 00:33:29,026 Training Epoch [6/40] Iter[186/312]		Loss: 0.3553
2019-10-29 00:33:29,148 Training Epoch [6/40] Iter[187/312]		Loss: 0.3553
2019-10-29 00:33:29,270 Training Epoch [6/40] Iter[188/312]		Loss: 0.3554
2019-10-29 00:33:29,392 Training Epoch [6/40] Iter[189/312]		Loss: 0.3554
2019-10-29 00:33:29,513 Training Epoch [6/40] Iter[190/312]		Loss: 0.3553
2019-10-29 00:33:29,634 Training Epoch [6/40] Iter[191/312]		Loss: 0.3557
2019-10-29 00:33:29,756 Training Epoch [6/40] Iter[192/312]		Loss: 0.3556
2019-10-29 00:33:29,878 Training Epoch [6/40] Iter[193/312]		Loss: 0.3560
2019-10-29 00:33:30,000 Training Epoch [6/40] Iter[194/312]		Loss: 0.3564
2019-10-29 00:33:30,121 Training Epoch [6/40] Iter[195/312]		Loss: 0.3565
2019-10-29 00:33:30,243 Training Epoch [6/40] Iter[196/312]		Loss: 0.3567
2019-10-29 00:33:30,365 Training Epoch [6/40] Iter[197/312]		Loss: 0.3566
2019-10-29 00:33:30,486 Training Epoch [6/40] Iter[198/312]		Loss: 0.3568
2019-10-29 00:33:30,609 Training Epoch [6/40] Iter[199/312]		Loss: 0.3565
2019-10-29 00:33:30,731 Training Epoch [6/40] Iter[200/312]		Loss: 0.3568
2019-10-29 00:33:30,852 Training Epoch [6/40] Iter[201/312]		Loss: 0.3566
2019-10-29 00:33:30,973 Training Epoch [6/40] Iter[202/312]		Loss: 0.3569
2019-10-29 00:33:31,095 Training Epoch [6/40] Iter[203/312]		Loss: 0.3570
2019-10-29 00:33:31,216 Training Epoch [6/40] Iter[204/312]		Loss: 0.3574
2019-10-29 00:33:31,338 Training Epoch [6/40] Iter[205/312]		Loss: 0.3573
2019-10-29 00:33:31,459 Training Epoch [6/40] Iter[206/312]		Loss: 0.3573
2019-10-29 00:33:31,580 Training Epoch [6/40] Iter[207/312]		Loss: 0.3574
2019-10-29 00:33:31,702 Training Epoch [6/40] Iter[208/312]		Loss: 0.3577
2019-10-29 00:33:31,823 Training Epoch [6/40] Iter[209/312]		Loss: 0.3576
2019-10-29 00:33:31,945 Training Epoch [6/40] Iter[210/312]		Loss: 0.3573
2019-10-29 00:33:32,066 Training Epoch [6/40] Iter[211/312]		Loss: 0.3568
2019-10-29 00:33:32,187 Training Epoch [6/40] Iter[212/312]		Loss: 0.3570
2019-10-29 00:33:32,308 Training Epoch [6/40] Iter[213/312]		Loss: 0.3571
2019-10-29 00:33:32,431 Training Epoch [6/40] Iter[214/312]		Loss: 0.3570
2019-10-29 00:33:32,553 Training Epoch [6/40] Iter[215/312]		Loss: 0.3578
2019-10-29 00:33:32,674 Training Epoch [6/40] Iter[216/312]		Loss: 0.3574
2019-10-29 00:33:32,796 Training Epoch [6/40] Iter[217/312]		Loss: 0.3572
2019-10-29 00:33:32,917 Training Epoch [6/40] Iter[218/312]		Loss: 0.3566
2019-10-29 00:33:33,039 Training Epoch [6/40] Iter[219/312]		Loss: 0.3560
2019-10-29 00:33:33,160 Training Epoch [6/40] Iter[220/312]		Loss: 0.3559
2019-10-29 00:33:33,282 Training Epoch [6/40] Iter[221/312]		Loss: 0.3556
2019-10-29 00:33:33,403 Training Epoch [6/40] Iter[222/312]		Loss: 0.3553
2019-10-29 00:33:33,524 Training Epoch [6/40] Iter[223/312]		Loss: 0.3555
2019-10-29 00:33:33,645 Training Epoch [6/40] Iter[224/312]		Loss: 0.3553
2019-10-29 00:33:33,766 Training Epoch [6/40] Iter[225/312]		Loss: 0.3553
2019-10-29 00:33:33,887 Training Epoch [6/40] Iter[226/312]		Loss: 0.3553
2019-10-29 00:33:34,008 Training Epoch [6/40] Iter[227/312]		Loss: 0.3554
2019-10-29 00:33:34,130 Training Epoch [6/40] Iter[228/312]		Loss: 0.3556
2019-10-29 00:33:34,251 Training Epoch [6/40] Iter[229/312]		Loss: 0.3556
2019-10-29 00:33:34,373 Training Epoch [6/40] Iter[230/312]		Loss: 0.3551
2019-10-29 00:33:34,494 Training Epoch [6/40] Iter[231/312]		Loss: 0.3554
2019-10-29 00:33:34,616 Training Epoch [6/40] Iter[232/312]		Loss: 0.3555
2019-10-29 00:33:34,737 Training Epoch [6/40] Iter[233/312]		Loss: 0.3551
2019-10-29 00:33:34,859 Training Epoch [6/40] Iter[234/312]		Loss: 0.3547
2019-10-29 00:33:34,980 Training Epoch [6/40] Iter[235/312]		Loss: 0.3543
2019-10-29 00:33:35,102 Training Epoch [6/40] Iter[236/312]		Loss: 0.3538
2019-10-29 00:33:35,223 Training Epoch [6/40] Iter[237/312]		Loss: 0.3533
2019-10-29 00:33:35,345 Training Epoch [6/40] Iter[238/312]		Loss: 0.3533
2019-10-29 00:33:35,466 Training Epoch [6/40] Iter[239/312]		Loss: 0.3531
2019-10-29 00:33:35,588 Training Epoch [6/40] Iter[240/312]		Loss: 0.3528
2019-10-29 00:33:35,710 Training Epoch [6/40] Iter[241/312]		Loss: 0.3521
2019-10-29 00:33:35,832 Training Epoch [6/40] Iter[242/312]		Loss: 0.3517
2019-10-29 00:33:35,954 Training Epoch [6/40] Iter[243/312]		Loss: 0.3513
2019-10-29 00:33:36,076 Training Epoch [6/40] Iter[244/312]		Loss: 0.3508
2019-10-29 00:33:36,197 Training Epoch [6/40] Iter[245/312]		Loss: 0.3505
2019-10-29 00:33:36,319 Training Epoch [6/40] Iter[246/312]		Loss: 0.3500
2019-10-29 00:33:36,440 Training Epoch [6/40] Iter[247/312]		Loss: 0.3497
2019-10-29 00:33:36,561 Training Epoch [6/40] Iter[248/312]		Loss: 0.3492
2019-10-29 00:33:36,683 Training Epoch [6/40] Iter[249/312]		Loss: 0.3487
2019-10-29 00:33:36,804 Training Epoch [6/40] Iter[250/312]		Loss: 0.3481
2019-10-29 00:33:36,926 Training Epoch [6/40] Iter[251/312]		Loss: 0.3482
2019-10-29 00:33:37,047 Training Epoch [6/40] Iter[252/312]		Loss: 0.3486
2019-10-29 00:33:37,169 Training Epoch [6/40] Iter[253/312]		Loss: 0.3484
2019-10-29 00:33:37,290 Training Epoch [6/40] Iter[254/312]		Loss: 0.3482
2019-10-29 00:33:37,412 Training Epoch [6/40] Iter[255/312]		Loss: 0.3479
2019-10-29 00:33:37,534 Training Epoch [6/40] Iter[256/312]		Loss: 0.3475
2019-10-29 00:33:37,655 Training Epoch [6/40] Iter[257/312]		Loss: 0.3471
2019-10-29 00:33:37,777 Training Epoch [6/40] Iter[258/312]		Loss: 0.3473
2019-10-29 00:33:37,899 Training Epoch [6/40] Iter[259/312]		Loss: 0.3466
2019-10-29 00:33:38,020 Training Epoch [6/40] Iter[260/312]		Loss: 0.3467
2019-10-29 00:33:38,143 Training Epoch [6/40] Iter[261/312]		Loss: 0.3464
2019-10-29 00:33:38,265 Training Epoch [6/40] Iter[262/312]		Loss: 0.3463
2019-10-29 00:33:38,387 Training Epoch [6/40] Iter[263/312]		Loss: 0.3459
2019-10-29 00:33:38,508 Training Epoch [6/40] Iter[264/312]		Loss: 0.3459
2019-10-29 00:33:38,629 Training Epoch [6/40] Iter[265/312]		Loss: 0.3457
2019-10-29 00:33:38,751 Training Epoch [6/40] Iter[266/312]		Loss: 0.3456
2019-10-29 00:33:38,872 Training Epoch [6/40] Iter[267/312]		Loss: 0.3457
2019-10-29 00:33:38,994 Training Epoch [6/40] Iter[268/312]		Loss: 0.3453
2019-10-29 00:33:39,116 Training Epoch [6/40] Iter[269/312]		Loss: 0.3452
2019-10-29 00:33:39,238 Training Epoch [6/40] Iter[270/312]		Loss: 0.3448
2019-10-29 00:33:39,359 Training Epoch [6/40] Iter[271/312]		Loss: 0.3446
2019-10-29 00:33:39,481 Training Epoch [6/40] Iter[272/312]		Loss: 0.3443
2019-10-29 00:33:39,603 Training Epoch [6/40] Iter[273/312]		Loss: 0.3444
2019-10-29 00:33:39,725 Training Epoch [6/40] Iter[274/312]		Loss: 0.3441
2019-10-29 00:33:39,846 Training Epoch [6/40] Iter[275/312]		Loss: 0.3442
2019-10-29 00:33:39,968 Training Epoch [6/40] Iter[276/312]		Loss: 0.3441
2019-10-29 00:33:40,089 Training Epoch [6/40] Iter[277/312]		Loss: 0.3440
2019-10-29 00:33:40,211 Training Epoch [6/40] Iter[278/312]		Loss: 0.3439
2019-10-29 00:33:40,332 Training Epoch [6/40] Iter[279/312]		Loss: 0.3438
2019-10-29 00:33:40,454 Training Epoch [6/40] Iter[280/312]		Loss: 0.3438
2019-10-29 00:33:40,575 Training Epoch [6/40] Iter[281/312]		Loss: 0.3435
2019-10-29 00:33:40,697 Training Epoch [6/40] Iter[282/312]		Loss: 0.3430
2019-10-29 00:33:40,819 Training Epoch [6/40] Iter[283/312]		Loss: 0.3429
2019-10-29 00:33:40,940 Training Epoch [6/40] Iter[284/312]		Loss: 0.3433
2019-10-29 00:33:41,062 Training Epoch [6/40] Iter[285/312]		Loss: 0.3431
2019-10-29 00:33:41,183 Training Epoch [6/40] Iter[286/312]		Loss: 0.3430
2019-10-29 00:33:41,305 Training Epoch [6/40] Iter[287/312]		Loss: 0.3427
2019-10-29 00:33:41,426 Training Epoch [6/40] Iter[288/312]		Loss: 0.3428
2019-10-29 00:33:41,548 Training Epoch [6/40] Iter[289/312]		Loss: 0.3431
2019-10-29 00:33:41,669 Training Epoch [6/40] Iter[290/312]		Loss: 0.3430
2019-10-29 00:33:41,790 Training Epoch [6/40] Iter[291/312]		Loss: 0.3429
2019-10-29 00:33:41,911 Training Epoch [6/40] Iter[292/312]		Loss: 0.3427
2019-10-29 00:33:42,032 Training Epoch [6/40] Iter[293/312]		Loss: 0.3424
2019-10-29 00:33:42,153 Training Epoch [6/40] Iter[294/312]		Loss: 0.3424
2019-10-29 00:33:42,275 Training Epoch [6/40] Iter[295/312]		Loss: 0.3424
2019-10-29 00:33:42,396 Training Epoch [6/40] Iter[296/312]		Loss: 0.3422
2019-10-29 00:33:42,517 Training Epoch [6/40] Iter[297/312]		Loss: 0.3419
2019-10-29 00:33:42,638 Training Epoch [6/40] Iter[298/312]		Loss: 0.3417
2019-10-29 00:33:42,759 Training Epoch [6/40] Iter[299/312]		Loss: 0.3412
2019-10-29 00:33:42,880 Training Epoch [6/40] Iter[300/312]		Loss: 0.3416
2019-10-29 00:33:43,002 Training Epoch [6/40] Iter[301/312]		Loss: 0.3415
2019-10-29 00:33:43,124 Training Epoch [6/40] Iter[302/312]		Loss: 0.3415
2019-10-29 00:33:43,245 Training Epoch [6/40] Iter[303/312]		Loss: 0.3416
2019-10-29 00:33:43,367 Training Epoch [6/40] Iter[304/312]		Loss: 0.3413
2019-10-29 00:33:43,488 Training Epoch [6/40] Iter[305/312]		Loss: 0.3414
2019-10-29 00:33:43,610 Training Epoch [6/40] Iter[306/312]		Loss: 0.3417
2019-10-29 00:33:43,731 Training Epoch [6/40] Iter[307/312]		Loss: 0.3418
2019-10-29 00:33:43,851 Training Epoch [6/40] Iter[308/312]		Loss: 0.3419
2019-10-29 00:33:43,972 Training Epoch [6/40] Iter[309/312]		Loss: 0.3417
2019-10-29 00:33:44,093 Training Epoch [6/40] Iter[310/312]		Loss: 0.3416
2019-10-29 00:33:44,215 Training Epoch [6/40] Iter[311/312]		Loss: 0.3415
2019-10-29 00:33:44,276 Training Epoch [6/40] Iter[312/312]		Loss: 0.3424
2019-10-29 00:33:44,650 Testing Epoch [6/40] Iter[0/62]		Loss: 0.3776
2019-10-29 00:33:44,684 Testing Epoch [6/40] Iter[1/62]		Loss: 0.3686
2019-10-29 00:33:44,732 Testing Epoch [6/40] Iter[2/62]		Loss: 0.3718
2019-10-29 00:33:44,774 Testing Epoch [6/40] Iter[3/62]		Loss: 0.3753
2019-10-29 00:33:44,804 Testing Epoch [6/40] Iter[4/62]		Loss: 0.3747
2019-10-29 00:33:44,834 Testing Epoch [6/40] Iter[5/62]		Loss: 0.3632
2019-10-29 00:33:44,865 Testing Epoch [6/40] Iter[6/62]		Loss: 0.3622
2019-10-29 00:33:44,895 Testing Epoch [6/40] Iter[7/62]		Loss: 0.3611
2019-10-29 00:33:44,925 Testing Epoch [6/40] Iter[8/62]		Loss: 0.3638
2019-10-29 00:33:44,955 Testing Epoch [6/40] Iter[9/62]		Loss: 0.3619
2019-10-29 00:33:44,986 Testing Epoch [6/40] Iter[10/62]		Loss: 0.3568
2019-10-29 00:33:45,017 Testing Epoch [6/40] Iter[11/62]		Loss: 0.3624
2019-10-29 00:33:45,047 Testing Epoch [6/40] Iter[12/62]		Loss: 0.3647
2019-10-29 00:33:45,078 Testing Epoch [6/40] Iter[13/62]		Loss: 0.3647
2019-10-29 00:33:45,109 Testing Epoch [6/40] Iter[14/62]		Loss: 0.3815
2019-10-29 00:33:45,140 Testing Epoch [6/40] Iter[15/62]		Loss: 0.3817
2019-10-29 00:33:45,171 Testing Epoch [6/40] Iter[16/62]		Loss: 0.3776
2019-10-29 00:33:45,202 Testing Epoch [6/40] Iter[17/62]		Loss: 0.3725
2019-10-29 00:33:45,233 Testing Epoch [6/40] Iter[18/62]		Loss: 0.3674
2019-10-29 00:33:45,263 Testing Epoch [6/40] Iter[19/62]		Loss: 0.3650
2019-10-29 00:33:45,294 Testing Epoch [6/40] Iter[20/62]		Loss: 0.3660
2019-10-29 00:33:45,325 Testing Epoch [6/40] Iter[21/62]		Loss: 0.3659
2019-10-29 00:33:45,357 Testing Epoch [6/40] Iter[22/62]		Loss: 0.3695
2019-10-29 00:33:45,388 Testing Epoch [6/40] Iter[23/62]		Loss: 0.3655
2019-10-29 00:33:45,418 Testing Epoch [6/40] Iter[24/62]		Loss: 0.3704
2019-10-29 00:33:45,449 Testing Epoch [6/40] Iter[25/62]		Loss: 0.3680
2019-10-29 00:33:45,480 Testing Epoch [6/40] Iter[26/62]		Loss: 0.3664
2019-10-29 00:33:45,511 Testing Epoch [6/40] Iter[27/62]		Loss: 0.3750
2019-10-29 00:33:45,542 Testing Epoch [6/40] Iter[28/62]		Loss: 0.3779
2019-10-29 00:33:45,572 Testing Epoch [6/40] Iter[29/62]		Loss: 0.3774
2019-10-29 00:33:45,603 Testing Epoch [6/40] Iter[30/62]		Loss: 0.3767
2019-10-29 00:33:45,634 Testing Epoch [6/40] Iter[31/62]		Loss: 0.3774
2019-10-29 00:33:45,665 Testing Epoch [6/40] Iter[32/62]		Loss: 0.3793
2019-10-29 00:33:45,696 Testing Epoch [6/40] Iter[33/62]		Loss: 0.3767
2019-10-29 00:33:45,727 Testing Epoch [6/40] Iter[34/62]		Loss: 0.3780
2019-10-29 00:33:45,759 Testing Epoch [6/40] Iter[35/62]		Loss: 0.3781
2019-10-29 00:33:45,790 Testing Epoch [6/40] Iter[36/62]		Loss: 0.3783
2019-10-29 00:33:45,820 Testing Epoch [6/40] Iter[37/62]		Loss: 0.3787
2019-10-29 00:33:45,851 Testing Epoch [6/40] Iter[38/62]		Loss: 0.3786
2019-10-29 00:33:45,882 Testing Epoch [6/40] Iter[39/62]		Loss: 0.3802
2019-10-29 00:33:45,913 Testing Epoch [6/40] Iter[40/62]		Loss: 0.3824
2019-10-29 00:33:45,944 Testing Epoch [6/40] Iter[41/62]		Loss: 0.3840
2019-10-29 00:33:45,975 Testing Epoch [6/40] Iter[42/62]		Loss: 0.3819
2019-10-29 00:33:46,005 Testing Epoch [6/40] Iter[43/62]		Loss: 0.3809
2019-10-29 00:33:46,036 Testing Epoch [6/40] Iter[44/62]		Loss: 0.3782
2019-10-29 00:33:46,067 Testing Epoch [6/40] Iter[45/62]		Loss: 0.3777
2019-10-29 00:33:46,098 Testing Epoch [6/40] Iter[46/62]		Loss: 0.3781
2019-10-29 00:33:46,129 Testing Epoch [6/40] Iter[47/62]		Loss: 0.3820
2019-10-29 00:33:46,160 Testing Epoch [6/40] Iter[48/62]		Loss: 0.3797
2019-10-29 00:33:46,191 Testing Epoch [6/40] Iter[49/62]		Loss: 0.3816
2019-10-29 00:33:46,222 Testing Epoch [6/40] Iter[50/62]		Loss: 0.3810
2019-10-29 00:33:46,252 Testing Epoch [6/40] Iter[51/62]		Loss: 0.3807
2019-10-29 00:33:46,283 Testing Epoch [6/40] Iter[52/62]		Loss: 0.3792
2019-10-29 00:33:46,314 Testing Epoch [6/40] Iter[53/62]		Loss: 0.3782
2019-10-29 00:33:46,346 Testing Epoch [6/40] Iter[54/62]		Loss: 0.3762
2019-10-29 00:33:46,376 Testing Epoch [6/40] Iter[55/62]		Loss: 0.3761
2019-10-29 00:33:46,406 Testing Epoch [6/40] Iter[56/62]		Loss: 0.3758
2019-10-29 00:33:46,437 Testing Epoch [6/40] Iter[57/62]		Loss: 0.3781
2019-10-29 00:33:46,467 Testing Epoch [6/40] Iter[58/62]		Loss: 0.3774
2019-10-29 00:33:46,497 Testing Epoch [6/40] Iter[59/62]		Loss: 0.3782
2019-10-29 00:33:46,527 Testing Epoch [6/40] Iter[60/62]		Loss: 0.3768
2019-10-29 00:33:46,557 Testing Epoch [6/40] Iter[61/62]		Loss: 0.3763
2019-10-29 00:33:46,574 Testing Epoch [6/40] Iter[62/62]		Loss: 0.3782
2019-10-29 00:33:46,638 Saving the Model
2019-10-29 00:33:47,056 Training Epoch [7/40] Iter[0/312]		Loss: 0.2236
2019-10-29 00:33:47,177 Training Epoch [7/40] Iter[1/312]		Loss: 0.3825
2019-10-29 00:33:47,299 Training Epoch [7/40] Iter[2/312]		Loss: 0.4034
2019-10-29 00:33:47,423 Training Epoch [7/40] Iter[3/312]		Loss: 0.4154
2019-10-29 00:33:47,543 Training Epoch [7/40] Iter[4/312]		Loss: 0.4405
2019-10-29 00:33:47,664 Training Epoch [7/40] Iter[5/312]		Loss: 0.4480
2019-10-29 00:33:47,784 Training Epoch [7/40] Iter[6/312]		Loss: 0.4520
2019-10-29 00:33:47,906 Training Epoch [7/40] Iter[7/312]		Loss: 0.4415
2019-10-29 00:33:48,027 Training Epoch [7/40] Iter[8/312]		Loss: 0.4495
2019-10-29 00:33:48,148 Training Epoch [7/40] Iter[9/312]		Loss: 0.4361
2019-10-29 00:33:48,270 Training Epoch [7/40] Iter[10/312]		Loss: 0.4316
2019-10-29 00:33:48,392 Training Epoch [7/40] Iter[11/312]		Loss: 0.4259
2019-10-29 00:33:48,514 Training Epoch [7/40] Iter[12/312]		Loss: 0.4269
2019-10-29 00:33:48,635 Training Epoch [7/40] Iter[13/312]		Loss: 0.4221
2019-10-29 00:33:48,756 Training Epoch [7/40] Iter[14/312]		Loss: 0.4158
2019-10-29 00:33:48,878 Training Epoch [7/40] Iter[15/312]		Loss: 0.4113
2019-10-29 00:33:49,000 Training Epoch [7/40] Iter[16/312]		Loss: 0.4032
2019-10-29 00:33:49,126 Training Epoch [7/40] Iter[17/312]		Loss: 0.4005
2019-10-29 00:33:49,247 Training Epoch [7/40] Iter[18/312]		Loss: 0.4166
2019-10-29 00:33:49,369 Training Epoch [7/40] Iter[19/312]		Loss: 0.4142
2019-10-29 00:33:49,491 Training Epoch [7/40] Iter[20/312]		Loss: 0.4104
2019-10-29 00:33:49,612 Training Epoch [7/40] Iter[21/312]		Loss: 0.4082
2019-10-29 00:33:49,733 Training Epoch [7/40] Iter[22/312]		Loss: 0.4102
2019-10-29 00:33:49,855 Training Epoch [7/40] Iter[23/312]		Loss: 0.4106
2019-10-29 00:33:49,976 Training Epoch [7/40] Iter[24/312]		Loss: 0.4046
2019-10-29 00:33:50,097 Training Epoch [7/40] Iter[25/312]		Loss: 0.4014
2019-10-29 00:33:50,219 Training Epoch [7/40] Iter[26/312]		Loss: 0.3975
2019-10-29 00:33:50,340 Training Epoch [7/40] Iter[27/312]		Loss: 0.3896
2019-10-29 00:33:50,462 Training Epoch [7/40] Iter[28/312]		Loss: 0.3883
2019-10-29 00:33:50,583 Training Epoch [7/40] Iter[29/312]		Loss: 0.3851
2019-10-29 00:33:50,703 Training Epoch [7/40] Iter[30/312]		Loss: 0.3811
2019-10-29 00:33:50,825 Training Epoch [7/40] Iter[31/312]		Loss: 0.3789
2019-10-29 00:33:50,946 Training Epoch [7/40] Iter[32/312]		Loss: 0.3774
2019-10-29 00:33:51,067 Training Epoch [7/40] Iter[33/312]		Loss: 0.3736
2019-10-29 00:33:51,188 Training Epoch [7/40] Iter[34/312]		Loss: 0.3721
2019-10-29 00:33:51,310 Training Epoch [7/40] Iter[35/312]		Loss: 0.3712
2019-10-29 00:33:51,431 Training Epoch [7/40] Iter[36/312]		Loss: 0.3682
2019-10-29 00:33:51,552 Training Epoch [7/40] Iter[37/312]		Loss: 0.3642
2019-10-29 00:33:51,674 Training Epoch [7/40] Iter[38/312]		Loss: 0.3615
2019-10-29 00:33:51,800 Training Epoch [7/40] Iter[39/312]		Loss: 0.3585
2019-10-29 00:33:51,928 Training Epoch [7/40] Iter[40/312]		Loss: 0.3597
2019-10-29 00:33:52,052 Training Epoch [7/40] Iter[41/312]		Loss: 0.3572
2019-10-29 00:33:52,174 Training Epoch [7/40] Iter[42/312]		Loss: 0.3569
2019-10-29 00:33:52,295 Training Epoch [7/40] Iter[43/312]		Loss: 0.3581
2019-10-29 00:33:52,417 Training Epoch [7/40] Iter[44/312]		Loss: 0.3548
2019-10-29 00:33:52,538 Training Epoch [7/40] Iter[45/312]		Loss: 0.3548
2019-10-29 00:33:52,660 Training Epoch [7/40] Iter[46/312]		Loss: 0.3535
2019-10-29 00:33:52,782 Training Epoch [7/40] Iter[47/312]		Loss: 0.3519
2019-10-29 00:33:52,905 Training Epoch [7/40] Iter[48/312]		Loss: 0.3512
2019-10-29 00:33:53,027 Training Epoch [7/40] Iter[49/312]		Loss: 0.3496
2019-10-29 00:33:53,149 Training Epoch [7/40] Iter[50/312]		Loss: 0.3496
2019-10-29 00:33:53,270 Training Epoch [7/40] Iter[51/312]		Loss: 0.3472
2019-10-29 00:33:53,392 Training Epoch [7/40] Iter[52/312]		Loss: 0.3446
2019-10-29 00:33:53,516 Training Epoch [7/40] Iter[53/312]		Loss: 0.3424
2019-10-29 00:33:53,638 Training Epoch [7/40] Iter[54/312]		Loss: 0.3393
2019-10-29 00:33:53,759 Training Epoch [7/40] Iter[55/312]		Loss: 0.3384
2019-10-29 00:33:53,881 Training Epoch [7/40] Iter[56/312]		Loss: 0.3401
2019-10-29 00:33:54,002 Training Epoch [7/40] Iter[57/312]		Loss: 0.3406
2019-10-29 00:33:54,124 Training Epoch [7/40] Iter[58/312]		Loss: 0.3408
2019-10-29 00:33:54,245 Training Epoch [7/40] Iter[59/312]		Loss: 0.3409
2019-10-29 00:33:54,368 Training Epoch [7/40] Iter[60/312]		Loss: 0.3395
2019-10-29 00:33:54,490 Training Epoch [7/40] Iter[61/312]		Loss: 0.3372
2019-10-29 00:33:54,611 Training Epoch [7/40] Iter[62/312]		Loss: 0.3359
2019-10-29 00:33:54,732 Training Epoch [7/40] Iter[63/312]		Loss: 0.3339
2019-10-29 00:33:54,854 Training Epoch [7/40] Iter[64/312]		Loss: 0.3331
2019-10-29 00:33:54,976 Training Epoch [7/40] Iter[65/312]		Loss: 0.3313
2019-10-29 00:33:55,098 Training Epoch [7/40] Iter[66/312]		Loss: 0.3311
2019-10-29 00:33:55,220 Training Epoch [7/40] Iter[67/312]		Loss: 0.3300
2019-10-29 00:33:55,341 Training Epoch [7/40] Iter[68/312]		Loss: 0.3292
2019-10-29 00:33:55,463 Training Epoch [7/40] Iter[69/312]		Loss: 0.3306
2019-10-29 00:33:55,584 Training Epoch [7/40] Iter[70/312]		Loss: 0.3312
2019-10-29 00:33:55,706 Training Epoch [7/40] Iter[71/312]		Loss: 0.3308
2019-10-29 00:33:55,827 Training Epoch [7/40] Iter[72/312]		Loss: 0.3327
2019-10-29 00:33:55,949 Training Epoch [7/40] Iter[73/312]		Loss: 0.3318
2019-10-29 00:33:56,070 Training Epoch [7/40] Iter[74/312]		Loss: 0.3315
2019-10-29 00:33:56,192 Training Epoch [7/40] Iter[75/312]		Loss: 0.3307
2019-10-29 00:33:56,314 Training Epoch [7/40] Iter[76/312]		Loss: 0.3308
2019-10-29 00:33:56,436 Training Epoch [7/40] Iter[77/312]		Loss: 0.3305
2019-10-29 00:33:56,557 Training Epoch [7/40] Iter[78/312]		Loss: 0.3309
2019-10-29 00:33:56,679 Training Epoch [7/40] Iter[79/312]		Loss: 0.3320
2019-10-29 00:33:56,800 Training Epoch [7/40] Iter[80/312]		Loss: 0.3318
2019-10-29 00:33:56,922 Training Epoch [7/40] Iter[81/312]		Loss: 0.3319
2019-10-29 00:33:57,043 Training Epoch [7/40] Iter[82/312]		Loss: 0.3327
2019-10-29 00:33:57,164 Training Epoch [7/40] Iter[83/312]		Loss: 0.3328
2019-10-29 00:33:57,286 Training Epoch [7/40] Iter[84/312]		Loss: 0.3321
2019-10-29 00:33:57,407 Training Epoch [7/40] Iter[85/312]		Loss: 0.3315
2019-10-29 00:33:57,529 Training Epoch [7/40] Iter[86/312]		Loss: 0.3309
2019-10-29 00:33:57,650 Training Epoch [7/40] Iter[87/312]		Loss: 0.3301
2019-10-29 00:33:57,772 Training Epoch [7/40] Iter[88/312]		Loss: 0.3301
2019-10-29 00:33:57,893 Training Epoch [7/40] Iter[89/312]		Loss: 0.3300
2019-10-29 00:33:58,015 Training Epoch [7/40] Iter[90/312]		Loss: 0.3295
2019-10-29 00:33:58,137 Training Epoch [7/40] Iter[91/312]		Loss: 0.3292
2019-10-29 00:33:58,259 Training Epoch [7/40] Iter[92/312]		Loss: 0.3279
2019-10-29 00:33:58,380 Training Epoch [7/40] Iter[93/312]		Loss: 0.3288
2019-10-29 00:33:58,502 Training Epoch [7/40] Iter[94/312]		Loss: 0.3291
2019-10-29 00:33:58,623 Training Epoch [7/40] Iter[95/312]		Loss: 0.3306
2019-10-29 00:33:58,744 Training Epoch [7/40] Iter[96/312]		Loss: 0.3303
2019-10-29 00:33:58,866 Training Epoch [7/40] Iter[97/312]		Loss: 0.3296
2019-10-29 00:33:58,987 Training Epoch [7/40] Iter[98/312]		Loss: 0.3298
2019-10-29 00:33:59,107 Training Epoch [7/40] Iter[99/312]		Loss: 0.3294
2019-10-29 00:33:59,229 Training Epoch [7/40] Iter[100/312]		Loss: 0.3284
2019-10-29 00:33:59,350 Training Epoch [7/40] Iter[101/312]		Loss: 0.3289
2019-10-29 00:33:59,472 Training Epoch [7/40] Iter[102/312]		Loss: 0.3285
2019-10-29 00:33:59,593 Training Epoch [7/40] Iter[103/312]		Loss: 0.3275
2019-10-29 00:33:59,714 Training Epoch [7/40] Iter[104/312]		Loss: 0.3277
2019-10-29 00:33:59,836 Training Epoch [7/40] Iter[105/312]		Loss: 0.3276
2019-10-29 00:33:59,957 Training Epoch [7/40] Iter[106/312]		Loss: 0.3270
2019-10-29 00:34:00,079 Training Epoch [7/40] Iter[107/312]		Loss: 0.3265
2019-10-29 00:34:00,200 Training Epoch [7/40] Iter[108/312]		Loss: 0.3261
2019-10-29 00:34:00,322 Training Epoch [7/40] Iter[109/312]		Loss: 0.3263
2019-10-29 00:34:00,444 Training Epoch [7/40] Iter[110/312]		Loss: 0.3261
2019-10-29 00:34:00,566 Training Epoch [7/40] Iter[111/312]		Loss: 0.3258
2019-10-29 00:34:00,688 Training Epoch [7/40] Iter[112/312]		Loss: 0.3261
2019-10-29 00:34:00,809 Training Epoch [7/40] Iter[113/312]		Loss: 0.3257
2019-10-29 00:34:00,931 Training Epoch [7/40] Iter[114/312]		Loss: 0.3249
2019-10-29 00:34:01,053 Training Epoch [7/40] Iter[115/312]		Loss: 0.3236
2019-10-29 00:34:01,174 Training Epoch [7/40] Iter[116/312]		Loss: 0.3228
2019-10-29 00:34:01,296 Training Epoch [7/40] Iter[117/312]		Loss: 0.3222
2019-10-29 00:34:01,418 Training Epoch [7/40] Iter[118/312]		Loss: 0.3218
2019-10-29 00:34:01,540 Training Epoch [7/40] Iter[119/312]		Loss: 0.3223
2019-10-29 00:34:01,662 Training Epoch [7/40] Iter[120/312]		Loss: 0.3222
2019-10-29 00:34:01,783 Training Epoch [7/40] Iter[121/312]		Loss: 0.3216
2019-10-29 00:34:01,904 Training Epoch [7/40] Iter[122/312]		Loss: 0.3211
2019-10-29 00:34:02,025 Training Epoch [7/40] Iter[123/312]		Loss: 0.3223
2019-10-29 00:34:02,146 Training Epoch [7/40] Iter[124/312]		Loss: 0.3229
2019-10-29 00:34:02,268 Training Epoch [7/40] Iter[125/312]		Loss: 0.3221
2019-10-29 00:34:02,389 Training Epoch [7/40] Iter[126/312]		Loss: 0.3220
2019-10-29 00:34:02,510 Training Epoch [7/40] Iter[127/312]		Loss: 0.3221
2019-10-29 00:34:02,631 Training Epoch [7/40] Iter[128/312]		Loss: 0.3217
2019-10-29 00:34:02,752 Training Epoch [7/40] Iter[129/312]		Loss: 0.3215
2019-10-29 00:34:02,874 Training Epoch [7/40] Iter[130/312]		Loss: 0.3205
2019-10-29 00:34:02,995 Training Epoch [7/40] Iter[131/312]		Loss: 0.3212
2019-10-29 00:34:03,116 Training Epoch [7/40] Iter[132/312]		Loss: 0.3216
2019-10-29 00:34:03,239 Training Epoch [7/40] Iter[133/312]		Loss: 0.3214
2019-10-29 00:34:03,360 Training Epoch [7/40] Iter[134/312]		Loss: 0.3210
2019-10-29 00:34:03,482 Training Epoch [7/40] Iter[135/312]		Loss: 0.3200
2019-10-29 00:34:03,604 Training Epoch [7/40] Iter[136/312]		Loss: 0.3196
2019-10-29 00:34:03,725 Training Epoch [7/40] Iter[137/312]		Loss: 0.3195
2019-10-29 00:34:03,846 Training Epoch [7/40] Iter[138/312]		Loss: 0.3201
2019-10-29 00:34:03,967 Training Epoch [7/40] Iter[139/312]		Loss: 0.3197
2019-10-29 00:34:04,088 Training Epoch [7/40] Iter[140/312]		Loss: 0.3192
2019-10-29 00:34:04,209 Training Epoch [7/40] Iter[141/312]		Loss: 0.3198
2019-10-29 00:34:04,331 Training Epoch [7/40] Iter[142/312]		Loss: 0.3190
2019-10-29 00:34:04,453 Training Epoch [7/40] Iter[143/312]		Loss: 0.3190
2019-10-29 00:34:04,574 Training Epoch [7/40] Iter[144/312]		Loss: 0.3192
2019-10-29 00:34:04,696 Training Epoch [7/40] Iter[145/312]		Loss: 0.3190
2019-10-29 00:34:04,817 Training Epoch [7/40] Iter[146/312]		Loss: 0.3189
2019-10-29 00:34:04,939 Training Epoch [7/40] Iter[147/312]		Loss: 0.3187
2019-10-29 00:34:05,061 Training Epoch [7/40] Iter[148/312]		Loss: 0.3182
2019-10-29 00:34:05,183 Training Epoch [7/40] Iter[149/312]		Loss: 0.3182
2019-10-29 00:34:05,304 Training Epoch [7/40] Iter[150/312]		Loss: 0.3182
2019-10-29 00:34:05,426 Training Epoch [7/40] Iter[151/312]		Loss: 0.3179
2019-10-29 00:34:05,548 Training Epoch [7/40] Iter[152/312]		Loss: 0.3181
2019-10-29 00:34:05,669 Training Epoch [7/40] Iter[153/312]		Loss: 0.3175
2019-10-29 00:34:05,791 Training Epoch [7/40] Iter[154/312]		Loss: 0.3171
2019-10-29 00:34:05,913 Training Epoch [7/40] Iter[155/312]		Loss: 0.3167
2019-10-29 00:34:06,035 Training Epoch [7/40] Iter[156/312]		Loss: 0.3163
2019-10-29 00:34:06,156 Training Epoch [7/40] Iter[157/312]		Loss: 0.3162
2019-10-29 00:34:06,277 Training Epoch [7/40] Iter[158/312]		Loss: 0.3164
2019-10-29 00:34:06,399 Training Epoch [7/40] Iter[159/312]		Loss: 0.3163
2019-10-29 00:34:06,520 Training Epoch [7/40] Iter[160/312]		Loss: 0.3158
2019-10-29 00:34:06,641 Training Epoch [7/40] Iter[161/312]		Loss: 0.3154
2019-10-29 00:34:06,762 Training Epoch [7/40] Iter[162/312]		Loss: 0.3160
2019-10-29 00:34:06,884 Training Epoch [7/40] Iter[163/312]		Loss: 0.3164
2019-10-29 00:34:07,005 Training Epoch [7/40] Iter[164/312]		Loss: 0.3162
2019-10-29 00:34:07,127 Training Epoch [7/40] Iter[165/312]		Loss: 0.3159
2019-10-29 00:34:07,249 Training Epoch [7/40] Iter[166/312]		Loss: 0.3156
2019-10-29 00:34:07,370 Training Epoch [7/40] Iter[167/312]		Loss: 0.3155
2019-10-29 00:34:07,492 Training Epoch [7/40] Iter[168/312]		Loss: 0.3151
2019-10-29 00:34:07,613 Training Epoch [7/40] Iter[169/312]		Loss: 0.3154
2019-10-29 00:34:07,735 Training Epoch [7/40] Iter[170/312]		Loss: 0.3154
2019-10-29 00:34:07,856 Training Epoch [7/40] Iter[171/312]		Loss: 0.3151
2019-10-29 00:34:07,976 Training Epoch [7/40] Iter[172/312]		Loss: 0.3148
2019-10-29 00:34:08,098 Training Epoch [7/40] Iter[173/312]		Loss: 0.3149
2019-10-29 00:34:08,219 Training Epoch [7/40] Iter[174/312]		Loss: 0.3161
2019-10-29 00:34:08,341 Training Epoch [7/40] Iter[175/312]		Loss: 0.3160
2019-10-29 00:34:08,462 Training Epoch [7/40] Iter[176/312]		Loss: 0.3159
2019-10-29 00:34:08,583 Training Epoch [7/40] Iter[177/312]		Loss: 0.3156
2019-10-29 00:34:08,704 Training Epoch [7/40] Iter[178/312]		Loss: 0.3157
2019-10-29 00:34:08,825 Training Epoch [7/40] Iter[179/312]		Loss: 0.3159
2019-10-29 00:34:08,946 Training Epoch [7/40] Iter[180/312]		Loss: 0.3156
2019-10-29 00:34:09,067 Training Epoch [7/40] Iter[181/312]		Loss: 0.3155
2019-10-29 00:34:09,188 Training Epoch [7/40] Iter[182/312]		Loss: 0.3152
2019-10-29 00:34:09,309 Training Epoch [7/40] Iter[183/312]		Loss: 0.3150
2019-10-29 00:34:09,431 Training Epoch [7/40] Iter[184/312]		Loss: 0.3147
2019-10-29 00:34:09,552 Training Epoch [7/40] Iter[185/312]		Loss: 0.3153
2019-10-29 00:34:09,673 Training Epoch [7/40] Iter[186/312]		Loss: 0.3154
2019-10-29 00:34:09,795 Training Epoch [7/40] Iter[187/312]		Loss: 0.3151
2019-10-29 00:34:09,916 Training Epoch [7/40] Iter[188/312]		Loss: 0.3151
2019-10-29 00:34:10,038 Training Epoch [7/40] Iter[189/312]		Loss: 0.3149
2019-10-29 00:34:10,160 Training Epoch [7/40] Iter[190/312]		Loss: 0.3156
2019-10-29 00:34:10,281 Training Epoch [7/40] Iter[191/312]		Loss: 0.3158
2019-10-29 00:34:10,403 Training Epoch [7/40] Iter[192/312]		Loss: 0.3152
2019-10-29 00:34:10,524 Training Epoch [7/40] Iter[193/312]		Loss: 0.3153
2019-10-29 00:34:10,645 Training Epoch [7/40] Iter[194/312]		Loss: 0.3155
2019-10-29 00:34:10,767 Training Epoch [7/40] Iter[195/312]		Loss: 0.3160
2019-10-29 00:34:10,889 Training Epoch [7/40] Iter[196/312]		Loss: 0.3159
2019-10-29 00:34:11,011 Training Epoch [7/40] Iter[197/312]		Loss: 0.3157
2019-10-29 00:34:11,133 Training Epoch [7/40] Iter[198/312]		Loss: 0.3158
2019-10-29 00:34:11,255 Training Epoch [7/40] Iter[199/312]		Loss: 0.3157
2019-10-29 00:34:11,377 Training Epoch [7/40] Iter[200/312]		Loss: 0.3157
2019-10-29 00:34:11,498 Training Epoch [7/40] Iter[201/312]		Loss: 0.3155
2019-10-29 00:34:11,619 Training Epoch [7/40] Iter[202/312]		Loss: 0.3153
2019-10-29 00:34:11,741 Training Epoch [7/40] Iter[203/312]		Loss: 0.3148
2019-10-29 00:34:11,862 Training Epoch [7/40] Iter[204/312]		Loss: 0.3145
2019-10-29 00:34:11,983 Training Epoch [7/40] Iter[205/312]		Loss: 0.3149
2019-10-29 00:34:12,105 Training Epoch [7/40] Iter[206/312]		Loss: 0.3147
2019-10-29 00:34:12,226 Training Epoch [7/40] Iter[207/312]		Loss: 0.3145
2019-10-29 00:34:12,348 Training Epoch [7/40] Iter[208/312]		Loss: 0.3142
2019-10-29 00:34:12,469 Training Epoch [7/40] Iter[209/312]		Loss: 0.3140
2019-10-29 00:34:12,590 Training Epoch [7/40] Iter[210/312]		Loss: 0.3139
2019-10-29 00:34:12,712 Training Epoch [7/40] Iter[211/312]		Loss: 0.3135
2019-10-29 00:34:12,834 Training Epoch [7/40] Iter[212/312]		Loss: 0.3129
2019-10-29 00:34:12,955 Training Epoch [7/40] Iter[213/312]		Loss: 0.3126
2019-10-29 00:34:13,076 Training Epoch [7/40] Iter[214/312]		Loss: 0.3121
2019-10-29 00:34:13,198 Training Epoch [7/40] Iter[215/312]		Loss: 0.3122
2019-10-29 00:34:13,326 Training Epoch [7/40] Iter[216/312]		Loss: 0.3122
2019-10-29 00:34:13,447 Training Epoch [7/40] Iter[217/312]		Loss: 0.3117
2019-10-29 00:34:13,569 Training Epoch [7/40] Iter[218/312]		Loss: 0.3120
2019-10-29 00:34:13,691 Training Epoch [7/40] Iter[219/312]		Loss: 0.3119
2019-10-29 00:34:13,813 Training Epoch [7/40] Iter[220/312]		Loss: 0.3114
2019-10-29 00:34:13,934 Training Epoch [7/40] Iter[221/312]		Loss: 0.3112
2019-10-29 00:34:14,055 Training Epoch [7/40] Iter[222/312]		Loss: 0.3110
2019-10-29 00:34:14,177 Training Epoch [7/40] Iter[223/312]		Loss: 0.3111
2019-10-29 00:34:14,299 Training Epoch [7/40] Iter[224/312]		Loss: 0.3108
2019-10-29 00:34:14,420 Training Epoch [7/40] Iter[225/312]		Loss: 0.3107
2019-10-29 00:34:14,542 Training Epoch [7/40] Iter[226/312]		Loss: 0.3107
2019-10-29 00:34:14,663 Training Epoch [7/40] Iter[227/312]		Loss: 0.3107
2019-10-29 00:34:14,784 Training Epoch [7/40] Iter[228/312]		Loss: 0.3104
2019-10-29 00:34:14,906 Training Epoch [7/40] Iter[229/312]		Loss: 0.3103
2019-10-29 00:34:15,028 Training Epoch [7/40] Iter[230/312]		Loss: 0.3101
2019-10-29 00:34:15,149 Training Epoch [7/40] Iter[231/312]		Loss: 0.3095
2019-10-29 00:34:15,271 Training Epoch [7/40] Iter[232/312]		Loss: 0.3092
2019-10-29 00:34:15,392 Training Epoch [7/40] Iter[233/312]		Loss: 0.3094
2019-10-29 00:34:15,514 Training Epoch [7/40] Iter[234/312]		Loss: 0.3091
2019-10-29 00:34:15,635 Training Epoch [7/40] Iter[235/312]		Loss: 0.3098
2019-10-29 00:34:15,757 Training Epoch [7/40] Iter[236/312]		Loss: 0.3100
2019-10-29 00:34:15,878 Training Epoch [7/40] Iter[237/312]		Loss: 0.3105
2019-10-29 00:34:16,000 Training Epoch [7/40] Iter[238/312]		Loss: 0.3106
2019-10-29 00:34:16,121 Training Epoch [7/40] Iter[239/312]		Loss: 0.3110
2019-10-29 00:34:16,243 Training Epoch [7/40] Iter[240/312]		Loss: 0.3108
2019-10-29 00:34:16,365 Training Epoch [7/40] Iter[241/312]		Loss: 0.3106
2019-10-29 00:34:16,487 Training Epoch [7/40] Iter[242/312]		Loss: 0.3106
2019-10-29 00:34:16,608 Training Epoch [7/40] Iter[243/312]		Loss: 0.3108
2019-10-29 00:34:16,730 Training Epoch [7/40] Iter[244/312]		Loss: 0.3108
2019-10-29 00:34:16,852 Training Epoch [7/40] Iter[245/312]		Loss: 0.3104
2019-10-29 00:34:16,973 Training Epoch [7/40] Iter[246/312]		Loss: 0.3104
2019-10-29 00:34:17,094 Training Epoch [7/40] Iter[247/312]		Loss: 0.3107
2019-10-29 00:34:17,215 Training Epoch [7/40] Iter[248/312]		Loss: 0.3108
2019-10-29 00:34:17,336 Training Epoch [7/40] Iter[249/312]		Loss: 0.3105
2019-10-29 00:34:17,458 Training Epoch [7/40] Iter[250/312]		Loss: 0.3107
2019-10-29 00:34:17,578 Training Epoch [7/40] Iter[251/312]		Loss: 0.3103
2019-10-29 00:34:17,699 Training Epoch [7/40] Iter[252/312]		Loss: 0.3107
2019-10-29 00:34:17,820 Training Epoch [7/40] Iter[253/312]		Loss: 0.3109
2019-10-29 00:34:17,941 Training Epoch [7/40] Iter[254/312]		Loss: 0.3110
2019-10-29 00:34:18,062 Training Epoch [7/40] Iter[255/312]		Loss: 0.3109
2019-10-29 00:34:18,184 Training Epoch [7/40] Iter[256/312]		Loss: 0.3110
2019-10-29 00:34:18,305 Training Epoch [7/40] Iter[257/312]		Loss: 0.3105
2019-10-29 00:34:18,427 Training Epoch [7/40] Iter[258/312]		Loss: 0.3105
2019-10-29 00:34:18,548 Training Epoch [7/40] Iter[259/312]		Loss: 0.3104
2019-10-29 00:34:18,670 Training Epoch [7/40] Iter[260/312]		Loss: 0.3106
2019-10-29 00:34:18,792 Training Epoch [7/40] Iter[261/312]		Loss: 0.3107
2019-10-29 00:34:18,914 Training Epoch [7/40] Iter[262/312]		Loss: 0.3110
2019-10-29 00:34:19,035 Training Epoch [7/40] Iter[263/312]		Loss: 0.3113
2019-10-29 00:34:19,157 Training Epoch [7/40] Iter[264/312]		Loss: 0.3113
2019-10-29 00:34:19,278 Training Epoch [7/40] Iter[265/312]		Loss: 0.3113
2019-10-29 00:34:19,400 Training Epoch [7/40] Iter[266/312]		Loss: 0.3113
2019-10-29 00:34:19,522 Training Epoch [7/40] Iter[267/312]		Loss: 0.3110
2019-10-29 00:34:19,643 Training Epoch [7/40] Iter[268/312]		Loss: 0.3110
2019-10-29 00:34:19,765 Training Epoch [7/40] Iter[269/312]		Loss: 0.3111
2019-10-29 00:34:19,886 Training Epoch [7/40] Iter[270/312]		Loss: 0.3109
2019-10-29 00:34:20,008 Training Epoch [7/40] Iter[271/312]		Loss: 0.3107
2019-10-29 00:34:20,129 Training Epoch [7/40] Iter[272/312]		Loss: 0.3107
2019-10-29 00:34:20,251 Training Epoch [7/40] Iter[273/312]		Loss: 0.3104
2019-10-29 00:34:20,372 Training Epoch [7/40] Iter[274/312]		Loss: 0.3104
2019-10-29 00:34:20,494 Training Epoch [7/40] Iter[275/312]		Loss: 0.3103
2019-10-29 00:34:20,615 Training Epoch [7/40] Iter[276/312]		Loss: 0.3102
2019-10-29 00:34:20,737 Training Epoch [7/40] Iter[277/312]		Loss: 0.3100
2019-10-29 00:34:20,858 Training Epoch [7/40] Iter[278/312]		Loss: 0.3101
2019-10-29 00:34:20,980 Training Epoch [7/40] Iter[279/312]		Loss: 0.3100
2019-10-29 00:34:21,101 Training Epoch [7/40] Iter[280/312]		Loss: 0.3102
2019-10-29 00:34:21,223 Training Epoch [7/40] Iter[281/312]		Loss: 0.3099
2019-10-29 00:34:21,344 Training Epoch [7/40] Iter[282/312]		Loss: 0.3101
2019-10-29 00:34:21,466 Training Epoch [7/40] Iter[283/312]		Loss: 0.3099
2019-10-29 00:34:21,587 Training Epoch [7/40] Iter[284/312]		Loss: 0.3102
2019-10-29 00:34:21,709 Training Epoch [7/40] Iter[285/312]		Loss: 0.3102
2019-10-29 00:34:21,831 Training Epoch [7/40] Iter[286/312]		Loss: 0.3101
2019-10-29 00:34:21,952 Training Epoch [7/40] Iter[287/312]		Loss: 0.3100
2019-10-29 00:34:22,073 Training Epoch [7/40] Iter[288/312]		Loss: 0.3096
2019-10-29 00:34:22,194 Training Epoch [7/40] Iter[289/312]		Loss: 0.3094
2019-10-29 00:34:22,316 Training Epoch [7/40] Iter[290/312]		Loss: 0.3099
2019-10-29 00:34:22,437 Training Epoch [7/40] Iter[291/312]		Loss: 0.3097
2019-10-29 00:34:22,559 Training Epoch [7/40] Iter[292/312]		Loss: 0.3097
2019-10-29 00:34:22,680 Training Epoch [7/40] Iter[293/312]		Loss: 0.3095
2019-10-29 00:34:22,801 Training Epoch [7/40] Iter[294/312]		Loss: 0.3097
2019-10-29 00:34:22,923 Training Epoch [7/40] Iter[295/312]		Loss: 0.3095
2019-10-29 00:34:23,045 Training Epoch [7/40] Iter[296/312]		Loss: 0.3094
2019-10-29 00:34:23,167 Training Epoch [7/40] Iter[297/312]		Loss: 0.3093
2019-10-29 00:34:23,289 Training Epoch [7/40] Iter[298/312]		Loss: 0.3090
2019-10-29 00:34:23,410 Training Epoch [7/40] Iter[299/312]		Loss: 0.3093
2019-10-29 00:34:23,532 Training Epoch [7/40] Iter[300/312]		Loss: 0.3093
2019-10-29 00:34:23,653 Training Epoch [7/40] Iter[301/312]		Loss: 0.3090
2019-10-29 00:34:23,775 Training Epoch [7/40] Iter[302/312]		Loss: 0.3090
2019-10-29 00:34:23,896 Training Epoch [7/40] Iter[303/312]		Loss: 0.3089
2019-10-29 00:34:24,019 Training Epoch [7/40] Iter[304/312]		Loss: 0.3091
2019-10-29 00:34:24,140 Training Epoch [7/40] Iter[305/312]		Loss: 0.3093
2019-10-29 00:34:24,260 Training Epoch [7/40] Iter[306/312]		Loss: 0.3092
2019-10-29 00:34:24,381 Training Epoch [7/40] Iter[307/312]		Loss: 0.3096
2019-10-29 00:34:24,502 Training Epoch [7/40] Iter[308/312]		Loss: 0.3092
2019-10-29 00:34:24,623 Training Epoch [7/40] Iter[309/312]		Loss: 0.3091
2019-10-29 00:34:24,744 Training Epoch [7/40] Iter[310/312]		Loss: 0.3089
2019-10-29 00:34:24,864 Training Epoch [7/40] Iter[311/312]		Loss: 0.3089
2019-10-29 00:34:24,925 Training Epoch [7/40] Iter[312/312]		Loss: 0.3086
2019-10-29 00:34:25,306 Testing Epoch [7/40] Iter[0/62]		Loss: 0.2991
2019-10-29 00:34:25,345 Testing Epoch [7/40] Iter[1/62]		Loss: 0.3061
2019-10-29 00:34:25,382 Testing Epoch [7/40] Iter[2/62]		Loss: 0.2956
2019-10-29 00:34:25,415 Testing Epoch [7/40] Iter[3/62]		Loss: 0.3020
2019-10-29 00:34:25,450 Testing Epoch [7/40] Iter[4/62]		Loss: 0.2989
2019-10-29 00:34:25,480 Testing Epoch [7/40] Iter[5/62]		Loss: 0.2929
2019-10-29 00:34:25,509 Testing Epoch [7/40] Iter[6/62]		Loss: 0.2948
2019-10-29 00:34:25,542 Testing Epoch [7/40] Iter[7/62]		Loss: 0.2954
2019-10-29 00:34:25,572 Testing Epoch [7/40] Iter[8/62]		Loss: 0.2927
2019-10-29 00:34:25,603 Testing Epoch [7/40] Iter[9/62]		Loss: 0.2921
2019-10-29 00:34:25,638 Testing Epoch [7/40] Iter[10/62]		Loss: 0.2877
2019-10-29 00:34:25,669 Testing Epoch [7/40] Iter[11/62]		Loss: 0.2943
2019-10-29 00:34:25,699 Testing Epoch [7/40] Iter[12/62]		Loss: 0.2959
2019-10-29 00:34:25,734 Testing Epoch [7/40] Iter[13/62]		Loss: 0.2989
2019-10-29 00:34:25,765 Testing Epoch [7/40] Iter[14/62]		Loss: 0.3151
2019-10-29 00:34:25,796 Testing Epoch [7/40] Iter[15/62]		Loss: 0.3177
2019-10-29 00:34:25,830 Testing Epoch [7/40] Iter[16/62]		Loss: 0.3135
2019-10-29 00:34:25,860 Testing Epoch [7/40] Iter[17/62]		Loss: 0.3117
2019-10-29 00:34:25,891 Testing Epoch [7/40] Iter[18/62]		Loss: 0.3079
2019-10-29 00:34:25,926 Testing Epoch [7/40] Iter[19/62]		Loss: 0.3057
2019-10-29 00:34:25,956 Testing Epoch [7/40] Iter[20/62]		Loss: 0.3066
2019-10-29 00:34:25,987 Testing Epoch [7/40] Iter[21/62]		Loss: 0.3069
2019-10-29 00:34:26,022 Testing Epoch [7/40] Iter[22/62]		Loss: 0.3077
2019-10-29 00:34:26,054 Testing Epoch [7/40] Iter[23/62]		Loss: 0.3060
2019-10-29 00:34:26,086 Testing Epoch [7/40] Iter[24/62]		Loss: 0.3084
2019-10-29 00:34:26,116 Testing Epoch [7/40] Iter[25/62]		Loss: 0.3049
2019-10-29 00:34:26,147 Testing Epoch [7/40] Iter[26/62]		Loss: 0.3021
2019-10-29 00:34:26,182 Testing Epoch [7/40] Iter[27/62]		Loss: 0.3111
2019-10-29 00:34:26,212 Testing Epoch [7/40] Iter[28/62]		Loss: 0.3114
2019-10-29 00:34:26,243 Testing Epoch [7/40] Iter[29/62]		Loss: 0.3129
2019-10-29 00:34:26,278 Testing Epoch [7/40] Iter[30/62]		Loss: 0.3149
2019-10-29 00:34:26,308 Testing Epoch [7/40] Iter[31/62]		Loss: 0.3152
2019-10-29 00:34:26,339 Testing Epoch [7/40] Iter[32/62]		Loss: 0.3149
2019-10-29 00:34:26,374 Testing Epoch [7/40] Iter[33/62]		Loss: 0.3139
2019-10-29 00:34:26,404 Testing Epoch [7/40] Iter[34/62]		Loss: 0.3145
2019-10-29 00:34:26,435 Testing Epoch [7/40] Iter[35/62]		Loss: 0.3154
2019-10-29 00:34:26,470 Testing Epoch [7/40] Iter[36/62]		Loss: 0.3141
2019-10-29 00:34:26,500 Testing Epoch [7/40] Iter[37/62]		Loss: 0.3146
2019-10-29 00:34:26,531 Testing Epoch [7/40] Iter[38/62]		Loss: 0.3146
2019-10-29 00:34:26,562 Testing Epoch [7/40] Iter[39/62]		Loss: 0.3151
2019-10-29 00:34:26,592 Testing Epoch [7/40] Iter[40/62]		Loss: 0.3185
2019-10-29 00:34:26,623 Testing Epoch [7/40] Iter[41/62]		Loss: 0.3208
2019-10-29 00:34:26,653 Testing Epoch [7/40] Iter[42/62]		Loss: 0.3191
2019-10-29 00:34:26,684 Testing Epoch [7/40] Iter[43/62]		Loss: 0.3198
2019-10-29 00:34:26,715 Testing Epoch [7/40] Iter[44/62]		Loss: 0.3176
2019-10-29 00:34:26,745 Testing Epoch [7/40] Iter[45/62]		Loss: 0.3169
2019-10-29 00:34:26,777 Testing Epoch [7/40] Iter[46/62]		Loss: 0.3176
2019-10-29 00:34:26,808 Testing Epoch [7/40] Iter[47/62]		Loss: 0.3224
2019-10-29 00:34:26,839 Testing Epoch [7/40] Iter[48/62]		Loss: 0.3208
2019-10-29 00:34:26,870 Testing Epoch [7/40] Iter[49/62]		Loss: 0.3203
2019-10-29 00:34:26,900 Testing Epoch [7/40] Iter[50/62]		Loss: 0.3197
2019-10-29 00:34:26,931 Testing Epoch [7/40] Iter[51/62]		Loss: 0.3191
2019-10-29 00:34:26,962 Testing Epoch [7/40] Iter[52/62]		Loss: 0.3165
2019-10-29 00:34:26,993 Testing Epoch [7/40] Iter[53/62]		Loss: 0.3169
2019-10-29 00:34:27,023 Testing Epoch [7/40] Iter[54/62]		Loss: 0.3155
2019-10-29 00:34:27,054 Testing Epoch [7/40] Iter[55/62]		Loss: 0.3148
2019-10-29 00:34:27,084 Testing Epoch [7/40] Iter[56/62]		Loss: 0.3152
2019-10-29 00:34:27,114 Testing Epoch [7/40] Iter[57/62]		Loss: 0.3157
2019-10-29 00:34:27,144 Testing Epoch [7/40] Iter[58/62]		Loss: 0.3146
2019-10-29 00:34:27,174 Testing Epoch [7/40] Iter[59/62]		Loss: 0.3154
2019-10-29 00:34:27,205 Testing Epoch [7/40] Iter[60/62]		Loss: 0.3149
2019-10-29 00:34:27,235 Testing Epoch [7/40] Iter[61/62]		Loss: 0.3148
2019-10-29 00:34:27,252 Testing Epoch [7/40] Iter[62/62]		Loss: 0.3140
2019-10-29 00:34:27,320 Saving the Model
2019-10-29 00:34:27,753 Training Epoch [8/40] Iter[0/312]		Loss: 0.2923
2019-10-29 00:34:27,875 Training Epoch [8/40] Iter[1/312]		Loss: 0.4249
2019-10-29 00:34:27,996 Training Epoch [8/40] Iter[2/312]		Loss: 0.4117
2019-10-29 00:34:28,118 Training Epoch [8/40] Iter[3/312]		Loss: 0.4347
2019-10-29 00:34:28,241 Training Epoch [8/40] Iter[4/312]		Loss: 0.4258
2019-10-29 00:34:28,361 Training Epoch [8/40] Iter[5/312]		Loss: 0.3925
2019-10-29 00:34:28,482 Training Epoch [8/40] Iter[6/312]		Loss: 0.3726
2019-10-29 00:34:28,604 Training Epoch [8/40] Iter[7/312]		Loss: 0.3731
2019-10-29 00:34:28,725 Training Epoch [8/40] Iter[8/312]		Loss: 0.3811
2019-10-29 00:34:28,847 Training Epoch [8/40] Iter[9/312]		Loss: 0.3877
2019-10-29 00:34:28,968 Training Epoch [8/40] Iter[10/312]		Loss: 0.3899
2019-10-29 00:34:29,090 Training Epoch [8/40] Iter[11/312]		Loss: 0.3765
2019-10-29 00:34:29,212 Training Epoch [8/40] Iter[12/312]		Loss: 0.3704
2019-10-29 00:34:29,333 Training Epoch [8/40] Iter[13/312]		Loss: 0.3660
2019-10-29 00:34:29,455 Training Epoch [8/40] Iter[14/312]		Loss: 0.3616
2019-10-29 00:34:29,576 Training Epoch [8/40] Iter[15/312]		Loss: 0.3621
2019-10-29 00:34:29,697 Training Epoch [8/40] Iter[16/312]		Loss: 0.3647
2019-10-29 00:34:29,819 Training Epoch [8/40] Iter[17/312]		Loss: 0.3619
2019-10-29 00:34:29,940 Training Epoch [8/40] Iter[18/312]		Loss: 0.3621
2019-10-29 00:34:30,061 Training Epoch [8/40] Iter[19/312]		Loss: 0.3584
2019-10-29 00:34:30,183 Training Epoch [8/40] Iter[20/312]		Loss: 0.3628
2019-10-29 00:34:30,304 Training Epoch [8/40] Iter[21/312]		Loss: 0.3606
2019-10-29 00:34:30,426 Training Epoch [8/40] Iter[22/312]		Loss: 0.3602
2019-10-29 00:34:30,548 Training Epoch [8/40] Iter[23/312]		Loss: 0.3592
2019-10-29 00:34:30,669 Training Epoch [8/40] Iter[24/312]		Loss: 0.3586
2019-10-29 00:34:30,791 Training Epoch [8/40] Iter[25/312]		Loss: 0.3567
2019-10-29 00:34:30,912 Training Epoch [8/40] Iter[26/312]		Loss: 0.3572
2019-10-29 00:34:31,034 Training Epoch [8/40] Iter[27/312]		Loss: 0.3555
2019-10-29 00:34:31,155 Training Epoch [8/40] Iter[28/312]		Loss: 0.3506
2019-10-29 00:34:31,276 Training Epoch [8/40] Iter[29/312]		Loss: 0.3496
2019-10-29 00:34:31,398 Training Epoch [8/40] Iter[30/312]		Loss: 0.3473
2019-10-29 00:34:31,520 Training Epoch [8/40] Iter[31/312]		Loss: 0.3462
2019-10-29 00:34:31,641 Training Epoch [8/40] Iter[32/312]		Loss: 0.3453
2019-10-29 00:34:31,762 Training Epoch [8/40] Iter[33/312]		Loss: 0.3438
2019-10-29 00:34:31,884 Training Epoch [8/40] Iter[34/312]		Loss: 0.3436
2019-10-29 00:34:32,005 Training Epoch [8/40] Iter[35/312]		Loss: 0.3414
2019-10-29 00:34:32,127 Training Epoch [8/40] Iter[36/312]		Loss: 0.3398
2019-10-29 00:34:32,249 Training Epoch [8/40] Iter[37/312]		Loss: 0.3388
2019-10-29 00:34:32,371 Training Epoch [8/40] Iter[38/312]		Loss: 0.3362
2019-10-29 00:34:32,493 Training Epoch [8/40] Iter[39/312]		Loss: 0.3334
2019-10-29 00:34:32,614 Training Epoch [8/40] Iter[40/312]		Loss: 0.3322
2019-10-29 00:34:32,736 Training Epoch [8/40] Iter[41/312]		Loss: 0.3318
2019-10-29 00:34:32,857 Training Epoch [8/40] Iter[42/312]		Loss: 0.3285
2019-10-29 00:34:32,979 Training Epoch [8/40] Iter[43/312]		Loss: 0.3330
2019-10-29 00:34:33,100 Training Epoch [8/40] Iter[44/312]		Loss: 0.3317
2019-10-29 00:34:33,222 Training Epoch [8/40] Iter[45/312]		Loss: 0.3299
2019-10-29 00:34:33,344 Training Epoch [8/40] Iter[46/312]		Loss: 0.3281
2019-10-29 00:34:33,465 Training Epoch [8/40] Iter[47/312]		Loss: 0.3271
2019-10-29 00:34:33,588 Training Epoch [8/40] Iter[48/312]		Loss: 0.3246
2019-10-29 00:34:33,712 Training Epoch [8/40] Iter[49/312]		Loss: 0.3223
2019-10-29 00:34:33,833 Training Epoch [8/40] Iter[50/312]		Loss: 0.3204
2019-10-29 00:34:33,955 Training Epoch [8/40] Iter[51/312]		Loss: 0.3206
2019-10-29 00:34:34,080 Training Epoch [8/40] Iter[52/312]		Loss: 0.3185
2019-10-29 00:34:34,204 Training Epoch [8/40] Iter[53/312]		Loss: 0.3169
2019-10-29 00:34:34,326 Training Epoch [8/40] Iter[54/312]		Loss: 0.3147
2019-10-29 00:34:34,447 Training Epoch [8/40] Iter[55/312]		Loss: 0.3150
2019-10-29 00:34:34,572 Training Epoch [8/40] Iter[56/312]		Loss: 0.3160
2019-10-29 00:34:34,696 Training Epoch [8/40] Iter[57/312]		Loss: 0.3154
2019-10-29 00:34:34,818 Training Epoch [8/40] Iter[58/312]		Loss: 0.3149
2019-10-29 00:34:34,939 Training Epoch [8/40] Iter[59/312]		Loss: 0.3144
2019-10-29 00:34:35,064 Training Epoch [8/40] Iter[60/312]		Loss: 0.3133
2019-10-29 00:34:35,188 Training Epoch [8/40] Iter[61/312]		Loss: 0.3123
2019-10-29 00:34:35,309 Training Epoch [8/40] Iter[62/312]		Loss: 0.3122
2019-10-29 00:34:35,430 Training Epoch [8/40] Iter[63/312]		Loss: 0.3116
2019-10-29 00:34:35,556 Training Epoch [8/40] Iter[64/312]		Loss: 0.3099
2019-10-29 00:34:35,680 Training Epoch [8/40] Iter[65/312]		Loss: 0.3102
2019-10-29 00:34:35,802 Training Epoch [8/40] Iter[66/312]		Loss: 0.3103
2019-10-29 00:34:35,923 Training Epoch [8/40] Iter[67/312]		Loss: 0.3093
2019-10-29 00:34:36,044 Training Epoch [8/40] Iter[68/312]		Loss: 0.3087
2019-10-29 00:34:36,168 Training Epoch [8/40] Iter[69/312]		Loss: 0.3073
2019-10-29 00:34:36,290 Training Epoch [8/40] Iter[70/312]		Loss: 0.3066
2019-10-29 00:34:36,412 Training Epoch [8/40] Iter[71/312]		Loss: 0.3079
2019-10-29 00:34:36,536 Training Epoch [8/40] Iter[72/312]		Loss: 0.3066
2019-10-29 00:34:36,664 Training Epoch [8/40] Iter[73/312]		Loss: 0.3047
2019-10-29 00:34:36,788 Training Epoch [8/40] Iter[74/312]		Loss: 0.3032
2019-10-29 00:34:36,910 Training Epoch [8/40] Iter[75/312]		Loss: 0.3022
2019-10-29 00:34:37,031 Training Epoch [8/40] Iter[76/312]		Loss: 0.3018
2019-10-29 00:34:37,153 Training Epoch [8/40] Iter[77/312]		Loss: 0.3009
2019-10-29 00:34:37,275 Training Epoch [8/40] Iter[78/312]		Loss: 0.3013
2019-10-29 00:34:37,397 Training Epoch [8/40] Iter[79/312]		Loss: 0.3013
2019-10-29 00:34:37,518 Training Epoch [8/40] Iter[80/312]		Loss: 0.3008
2019-10-29 00:34:37,640 Training Epoch [8/40] Iter[81/312]		Loss: 0.3000
2019-10-29 00:34:37,761 Training Epoch [8/40] Iter[82/312]		Loss: 0.3008
2019-10-29 00:34:37,882 Training Epoch [8/40] Iter[83/312]		Loss: 0.2994
2019-10-29 00:34:38,003 Training Epoch [8/40] Iter[84/312]		Loss: 0.2977
2019-10-29 00:34:38,125 Training Epoch [8/40] Iter[85/312]		Loss: 0.2969
2019-10-29 00:34:38,247 Training Epoch [8/40] Iter[86/312]		Loss: 0.2964
2019-10-29 00:34:38,368 Training Epoch [8/40] Iter[87/312]		Loss: 0.2956
2019-10-29 00:34:38,490 Training Epoch [8/40] Iter[88/312]		Loss: 0.2962
2019-10-29 00:34:38,612 Training Epoch [8/40] Iter[89/312]		Loss: 0.2965
2019-10-29 00:34:38,734 Training Epoch [8/40] Iter[90/312]		Loss: 0.2970
2019-10-29 00:34:38,855 Training Epoch [8/40] Iter[91/312]		Loss: 0.2971
2019-10-29 00:34:38,977 Training Epoch [8/40] Iter[92/312]		Loss: 0.2964
2019-10-29 00:34:39,098 Training Epoch [8/40] Iter[93/312]		Loss: 0.2957
2019-10-29 00:34:39,226 Training Epoch [8/40] Iter[94/312]		Loss: 0.2962
2019-10-29 00:34:39,348 Training Epoch [8/40] Iter[95/312]		Loss: 0.2966
2019-10-29 00:34:39,470 Training Epoch [8/40] Iter[96/312]		Loss: 0.2970
2019-10-29 00:34:39,591 Training Epoch [8/40] Iter[97/312]		Loss: 0.2962
2019-10-29 00:34:39,713 Training Epoch [8/40] Iter[98/312]		Loss: 0.2965
2019-10-29 00:34:39,833 Training Epoch [8/40] Iter[99/312]		Loss: 0.2966
2019-10-29 00:34:39,955 Training Epoch [8/40] Iter[100/312]		Loss: 0.2967
2019-10-29 00:34:40,077 Training Epoch [8/40] Iter[101/312]		Loss: 0.2968
2019-10-29 00:34:40,198 Training Epoch [8/40] Iter[102/312]		Loss: 0.2970
2019-10-29 00:34:40,320 Training Epoch [8/40] Iter[103/312]		Loss: 0.2966
2019-10-29 00:34:40,441 Training Epoch [8/40] Iter[104/312]		Loss: 0.2978
2019-10-29 00:34:40,563 Training Epoch [8/40] Iter[105/312]		Loss: 0.2971
2019-10-29 00:34:40,688 Training Epoch [8/40] Iter[106/312]		Loss: 0.2967
2019-10-29 00:34:40,810 Training Epoch [8/40] Iter[107/312]		Loss: 0.2961
2019-10-29 00:34:40,932 Training Epoch [8/40] Iter[108/312]		Loss: 0.2958
2019-10-29 00:34:41,053 Training Epoch [8/40] Iter[109/312]		Loss: 0.2952
2019-10-29 00:34:41,175 Training Epoch [8/40] Iter[110/312]		Loss: 0.2944
2019-10-29 00:34:41,296 Training Epoch [8/40] Iter[111/312]		Loss: 0.2949
2019-10-29 00:34:41,418 Training Epoch [8/40] Iter[112/312]		Loss: 0.2945
2019-10-29 00:34:41,539 Training Epoch [8/40] Iter[113/312]		Loss: 0.2954
2019-10-29 00:34:41,660 Training Epoch [8/40] Iter[114/312]		Loss: 0.2965
2019-10-29 00:34:41,782 Training Epoch [8/40] Iter[115/312]		Loss: 0.2970
2019-10-29 00:34:41,903 Training Epoch [8/40] Iter[116/312]		Loss: 0.2964
2019-10-29 00:34:42,025 Training Epoch [8/40] Iter[117/312]		Loss: 0.2972
2019-10-29 00:34:42,147 Training Epoch [8/40] Iter[118/312]		Loss: 0.2980
2019-10-29 00:34:42,268 Training Epoch [8/40] Iter[119/312]		Loss: 0.2987
2019-10-29 00:34:42,390 Training Epoch [8/40] Iter[120/312]		Loss: 0.2983
2019-10-29 00:34:42,511 Training Epoch [8/40] Iter[121/312]		Loss: 0.2986
2019-10-29 00:34:42,633 Training Epoch [8/40] Iter[122/312]		Loss: 0.2988
2019-10-29 00:34:42,754 Training Epoch [8/40] Iter[123/312]		Loss: 0.2993
2019-10-29 00:34:42,876 Training Epoch [8/40] Iter[124/312]		Loss: 0.2993
2019-10-29 00:34:42,997 Training Epoch [8/40] Iter[125/312]		Loss: 0.2991
2019-10-29 00:34:43,119 Training Epoch [8/40] Iter[126/312]		Loss: 0.2981
2019-10-29 00:34:43,241 Training Epoch [8/40] Iter[127/312]		Loss: 0.2981
2019-10-29 00:34:43,363 Training Epoch [8/40] Iter[128/312]		Loss: 0.2982
2019-10-29 00:34:43,484 Training Epoch [8/40] Iter[129/312]		Loss: 0.2977
2019-10-29 00:34:43,605 Training Epoch [8/40] Iter[130/312]		Loss: 0.2973
2019-10-29 00:34:43,727 Training Epoch [8/40] Iter[131/312]		Loss: 0.2968
2019-10-29 00:34:43,848 Training Epoch [8/40] Iter[132/312]		Loss: 0.2963
2019-10-29 00:34:43,970 Training Epoch [8/40] Iter[133/312]		Loss: 0.2962
2019-10-29 00:34:44,091 Training Epoch [8/40] Iter[134/312]		Loss: 0.2954
2019-10-29 00:34:44,217 Training Epoch [8/40] Iter[135/312]		Loss: 0.2947
2019-10-29 00:34:44,338 Training Epoch [8/40] Iter[136/312]		Loss: 0.2951
2019-10-29 00:34:44,460 Training Epoch [8/40] Iter[137/312]		Loss: 0.2948
2019-10-29 00:34:44,581 Training Epoch [8/40] Iter[138/312]		Loss: 0.2947
2019-10-29 00:34:44,703 Training Epoch [8/40] Iter[139/312]		Loss: 0.2941
2019-10-29 00:34:44,825 Training Epoch [8/40] Iter[140/312]		Loss: 0.2945
2019-10-29 00:34:44,946 Training Epoch [8/40] Iter[141/312]		Loss: 0.2944
2019-10-29 00:34:45,068 Training Epoch [8/40] Iter[142/312]		Loss: 0.2945
2019-10-29 00:34:45,190 Training Epoch [8/40] Iter[143/312]		Loss: 0.2936
2019-10-29 00:34:45,312 Training Epoch [8/40] Iter[144/312]		Loss: 0.2930
2019-10-29 00:34:45,433 Training Epoch [8/40] Iter[145/312]		Loss: 0.2935
2019-10-29 00:34:45,554 Training Epoch [8/40] Iter[146/312]		Loss: 0.2934
2019-10-29 00:34:45,676 Training Epoch [8/40] Iter[147/312]		Loss: 0.2928
2019-10-29 00:34:45,798 Training Epoch [8/40] Iter[148/312]		Loss: 0.2930
2019-10-29 00:34:45,920 Training Epoch [8/40] Iter[149/312]		Loss: 0.2924
2019-10-29 00:34:46,042 Training Epoch [8/40] Iter[150/312]		Loss: 0.2923
2019-10-29 00:34:46,163 Training Epoch [8/40] Iter[151/312]		Loss: 0.2921
2019-10-29 00:34:46,284 Training Epoch [8/40] Iter[152/312]		Loss: 0.2915
2019-10-29 00:34:46,406 Training Epoch [8/40] Iter[153/312]		Loss: 0.2913
2019-10-29 00:34:46,527 Training Epoch [8/40] Iter[154/312]		Loss: 0.2910
2019-10-29 00:34:46,649 Training Epoch [8/40] Iter[155/312]		Loss: 0.2905
2019-10-29 00:34:46,770 Training Epoch [8/40] Iter[156/312]		Loss: 0.2905
2019-10-29 00:34:46,891 Training Epoch [8/40] Iter[157/312]		Loss: 0.2908
2019-10-29 00:34:47,013 Training Epoch [8/40] Iter[158/312]		Loss: 0.2906
2019-10-29 00:34:47,134 Training Epoch [8/40] Iter[159/312]		Loss: 0.2907
2019-10-29 00:34:47,256 Training Epoch [8/40] Iter[160/312]		Loss: 0.2900
2019-10-29 00:34:47,377 Training Epoch [8/40] Iter[161/312]		Loss: 0.2898
2019-10-29 00:34:47,499 Training Epoch [8/40] Iter[162/312]		Loss: 0.2900
2019-10-29 00:34:47,620 Training Epoch [8/40] Iter[163/312]		Loss: 0.2899
2019-10-29 00:34:47,742 Training Epoch [8/40] Iter[164/312]		Loss: 0.2895
2019-10-29 00:34:47,863 Training Epoch [8/40] Iter[165/312]		Loss: 0.2899
2019-10-29 00:34:47,985 Training Epoch [8/40] Iter[166/312]		Loss: 0.2901
2019-10-29 00:34:48,107 Training Epoch [8/40] Iter[167/312]		Loss: 0.2901
2019-10-29 00:34:48,228 Training Epoch [8/40] Iter[168/312]		Loss: 0.2897
2019-10-29 00:34:48,349 Training Epoch [8/40] Iter[169/312]		Loss: 0.2891
2019-10-29 00:34:48,471 Training Epoch [8/40] Iter[170/312]		Loss: 0.2889
2019-10-29 00:34:48,592 Training Epoch [8/40] Iter[171/312]		Loss: 0.2886
2019-10-29 00:34:48,714 Training Epoch [8/40] Iter[172/312]		Loss: 0.2884
2019-10-29 00:34:48,835 Training Epoch [8/40] Iter[173/312]		Loss: 0.2885
2019-10-29 00:34:48,956 Training Epoch [8/40] Iter[174/312]		Loss: 0.2883
2019-10-29 00:34:49,078 Training Epoch [8/40] Iter[175/312]		Loss: 0.2884
2019-10-29 00:34:49,199 Training Epoch [8/40] Iter[176/312]		Loss: 0.2884
2019-10-29 00:34:49,322 Training Epoch [8/40] Iter[177/312]		Loss: 0.2885
2019-10-29 00:34:49,444 Training Epoch [8/40] Iter[178/312]		Loss: 0.2885
2019-10-29 00:34:49,565 Training Epoch [8/40] Iter[179/312]		Loss: 0.2888
2019-10-29 00:34:49,686 Training Epoch [8/40] Iter[180/312]		Loss: 0.2886
2019-10-29 00:34:49,808 Training Epoch [8/40] Iter[181/312]		Loss: 0.2883
2019-10-29 00:34:49,930 Training Epoch [8/40] Iter[182/312]		Loss: 0.2891
2019-10-29 00:34:50,051 Training Epoch [8/40] Iter[183/312]		Loss: 0.2894
2019-10-29 00:34:50,173 Training Epoch [8/40] Iter[184/312]		Loss: 0.2896
2019-10-29 00:34:50,295 Training Epoch [8/40] Iter[185/312]		Loss: 0.2899
2019-10-29 00:34:50,416 Training Epoch [8/40] Iter[186/312]		Loss: 0.2900
2019-10-29 00:34:50,538 Training Epoch [8/40] Iter[187/312]		Loss: 0.2895
2019-10-29 00:34:50,659 Training Epoch [8/40] Iter[188/312]		Loss: 0.2891
2019-10-29 00:34:50,781 Training Epoch [8/40] Iter[189/312]		Loss: 0.2885
2019-10-29 00:34:50,902 Training Epoch [8/40] Iter[190/312]		Loss: 0.2885
2019-10-29 00:34:51,023 Training Epoch [8/40] Iter[191/312]		Loss: 0.2880
2019-10-29 00:34:51,145 Training Epoch [8/40] Iter[192/312]		Loss: 0.2881
2019-10-29 00:34:51,266 Training Epoch [8/40] Iter[193/312]		Loss: 0.2888
2019-10-29 00:34:51,388 Training Epoch [8/40] Iter[194/312]		Loss: 0.2885
2019-10-29 00:34:51,510 Training Epoch [8/40] Iter[195/312]		Loss: 0.2885
2019-10-29 00:34:51,631 Training Epoch [8/40] Iter[196/312]		Loss: 0.2888
2019-10-29 00:34:51,753 Training Epoch [8/40] Iter[197/312]		Loss: 0.2891
2019-10-29 00:34:51,873 Training Epoch [8/40] Iter[198/312]		Loss: 0.2888
2019-10-29 00:34:51,995 Training Epoch [8/40] Iter[199/312]		Loss: 0.2892
2019-10-29 00:34:52,116 Training Epoch [8/40] Iter[200/312]		Loss: 0.2888
2019-10-29 00:34:52,237 Training Epoch [8/40] Iter[201/312]		Loss: 0.2887
2019-10-29 00:34:52,358 Training Epoch [8/40] Iter[202/312]		Loss: 0.2889
2019-10-29 00:34:52,479 Training Epoch [8/40] Iter[203/312]		Loss: 0.2885
2019-10-29 00:34:52,601 Training Epoch [8/40] Iter[204/312]		Loss: 0.2883
2019-10-29 00:34:52,722 Training Epoch [8/40] Iter[205/312]		Loss: 0.2880
2019-10-29 00:34:52,843 Training Epoch [8/40] Iter[206/312]		Loss: 0.2879
2019-10-29 00:34:52,964 Training Epoch [8/40] Iter[207/312]		Loss: 0.2876
2019-10-29 00:34:53,085 Training Epoch [8/40] Iter[208/312]		Loss: 0.2873
2019-10-29 00:34:53,207 Training Epoch [8/40] Iter[209/312]		Loss: 0.2868
2019-10-29 00:34:53,328 Training Epoch [8/40] Iter[210/312]		Loss: 0.2870
2019-10-29 00:34:53,449 Training Epoch [8/40] Iter[211/312]		Loss: 0.2870
2019-10-29 00:34:53,571 Training Epoch [8/40] Iter[212/312]		Loss: 0.2867
2019-10-29 00:34:53,698 Training Epoch [8/40] Iter[213/312]		Loss: 0.2867
2019-10-29 00:34:53,819 Training Epoch [8/40] Iter[214/312]		Loss: 0.2864
2019-10-29 00:34:53,940 Training Epoch [8/40] Iter[215/312]		Loss: 0.2865
2019-10-29 00:34:54,062 Training Epoch [8/40] Iter[216/312]		Loss: 0.2869
2019-10-29 00:34:54,183 Training Epoch [8/40] Iter[217/312]		Loss: 0.2868
2019-10-29 00:34:54,305 Training Epoch [8/40] Iter[218/312]		Loss: 0.2863
2019-10-29 00:34:54,428 Training Epoch [8/40] Iter[219/312]		Loss: 0.2866
2019-10-29 00:34:54,549 Training Epoch [8/40] Iter[220/312]		Loss: 0.2866
2019-10-29 00:34:54,671 Training Epoch [8/40] Iter[221/312]		Loss: 0.2867
2019-10-29 00:34:54,793 Training Epoch [8/40] Iter[222/312]		Loss: 0.2868
2019-10-29 00:34:54,914 Training Epoch [8/40] Iter[223/312]		Loss: 0.2873
2019-10-29 00:34:55,036 Training Epoch [8/40] Iter[224/312]		Loss: 0.2870
2019-10-29 00:34:55,157 Training Epoch [8/40] Iter[225/312]		Loss: 0.2867
2019-10-29 00:34:55,279 Training Epoch [8/40] Iter[226/312]		Loss: 0.2865
2019-10-29 00:34:55,400 Training Epoch [8/40] Iter[227/312]		Loss: 0.2863
2019-10-29 00:34:55,521 Training Epoch [8/40] Iter[228/312]		Loss: 0.2858
2019-10-29 00:34:55,643 Training Epoch [8/40] Iter[229/312]		Loss: 0.2856
2019-10-29 00:34:55,764 Training Epoch [8/40] Iter[230/312]		Loss: 0.2854
2019-10-29 00:34:55,885 Training Epoch [8/40] Iter[231/312]		Loss: 0.2859
2019-10-29 00:34:56,007 Training Epoch [8/40] Iter[232/312]		Loss: 0.2856
2019-10-29 00:34:56,128 Training Epoch [8/40] Iter[233/312]		Loss: 0.2853
2019-10-29 00:34:56,250 Training Epoch [8/40] Iter[234/312]		Loss: 0.2860
2019-10-29 00:34:56,371 Training Epoch [8/40] Iter[235/312]		Loss: 0.2864
2019-10-29 00:34:56,492 Training Epoch [8/40] Iter[236/312]		Loss: 0.2858
2019-10-29 00:34:56,614 Training Epoch [8/40] Iter[237/312]		Loss: 0.2857
2019-10-29 00:34:56,736 Training Epoch [8/40] Iter[238/312]		Loss: 0.2862
2019-10-29 00:34:56,857 Training Epoch [8/40] Iter[239/312]		Loss: 0.2861
2019-10-29 00:34:56,979 Training Epoch [8/40] Iter[240/312]		Loss: 0.2862
2019-10-29 00:34:57,100 Training Epoch [8/40] Iter[241/312]		Loss: 0.2860
2019-10-29 00:34:57,222 Training Epoch [8/40] Iter[242/312]		Loss: 0.2865
2019-10-29 00:34:57,344 Training Epoch [8/40] Iter[243/312]		Loss: 0.2867
2019-10-29 00:34:57,466 Training Epoch [8/40] Iter[244/312]		Loss: 0.2866
2019-10-29 00:34:57,588 Training Epoch [8/40] Iter[245/312]		Loss: 0.2867
2019-10-29 00:34:57,709 Training Epoch [8/40] Iter[246/312]		Loss: 0.2868
2019-10-29 00:34:57,831 Training Epoch [8/40] Iter[247/312]		Loss: 0.2867
2019-10-29 00:34:57,953 Training Epoch [8/40] Iter[248/312]		Loss: 0.2864
2019-10-29 00:34:58,075 Training Epoch [8/40] Iter[249/312]		Loss: 0.2861
2019-10-29 00:34:58,197 Training Epoch [8/40] Iter[250/312]		Loss: 0.2860
2019-10-29 00:34:58,318 Training Epoch [8/40] Iter[251/312]		Loss: 0.2859
2019-10-29 00:34:58,440 Training Epoch [8/40] Iter[252/312]		Loss: 0.2861
2019-10-29 00:34:58,561 Training Epoch [8/40] Iter[253/312]		Loss: 0.2860
2019-10-29 00:34:58,683 Training Epoch [8/40] Iter[254/312]		Loss: 0.2863
2019-10-29 00:34:58,804 Training Epoch [8/40] Iter[255/312]		Loss: 0.2862
2019-10-29 00:34:58,926 Training Epoch [8/40] Iter[256/312]		Loss: 0.2865
2019-10-29 00:34:59,047 Training Epoch [8/40] Iter[257/312]		Loss: 0.2868
2019-10-29 00:34:59,169 Training Epoch [8/40] Iter[258/312]		Loss: 0.2870
2019-10-29 00:34:59,290 Training Epoch [8/40] Iter[259/312]		Loss: 0.2870
2019-10-29 00:34:59,413 Training Epoch [8/40] Iter[260/312]		Loss: 0.2871
2019-10-29 00:34:59,535 Training Epoch [8/40] Iter[261/312]		Loss: 0.2870
2019-10-29 00:34:59,656 Training Epoch [8/40] Iter[262/312]		Loss: 0.2868
2019-10-29 00:34:59,778 Training Epoch [8/40] Iter[263/312]		Loss: 0.2866
2019-10-29 00:34:59,899 Training Epoch [8/40] Iter[264/312]		Loss: 0.2870
2019-10-29 00:35:00,021 Training Epoch [8/40] Iter[265/312]		Loss: 0.2870
2019-10-29 00:35:00,145 Training Epoch [8/40] Iter[266/312]		Loss: 0.2869
2019-10-29 00:35:00,267 Training Epoch [8/40] Iter[267/312]		Loss: 0.2868
2019-10-29 00:35:00,389 Training Epoch [8/40] Iter[268/312]		Loss: 0.2873
2019-10-29 00:35:00,510 Training Epoch [8/40] Iter[269/312]		Loss: 0.2874
2019-10-29 00:35:00,631 Training Epoch [8/40] Iter[270/312]		Loss: 0.2874
2019-10-29 00:35:00,752 Training Epoch [8/40] Iter[271/312]		Loss: 0.2872
2019-10-29 00:35:00,874 Training Epoch [8/40] Iter[272/312]		Loss: 0.2870
2019-10-29 00:35:00,995 Training Epoch [8/40] Iter[273/312]		Loss: 0.2870
2019-10-29 00:35:01,116 Training Epoch [8/40] Iter[274/312]		Loss: 0.2870
2019-10-29 00:35:01,238 Training Epoch [8/40] Iter[275/312]		Loss: 0.2871
2019-10-29 00:35:01,359 Training Epoch [8/40] Iter[276/312]		Loss: 0.2871
2019-10-29 00:35:01,481 Training Epoch [8/40] Iter[277/312]		Loss: 0.2870
2019-10-29 00:35:01,602 Training Epoch [8/40] Iter[278/312]		Loss: 0.2869
2019-10-29 00:35:01,723 Training Epoch [8/40] Iter[279/312]		Loss: 0.2869
2019-10-29 00:35:01,845 Training Epoch [8/40] Iter[280/312]		Loss: 0.2867
2019-10-29 00:35:01,967 Training Epoch [8/40] Iter[281/312]		Loss: 0.2867
2019-10-29 00:35:02,088 Training Epoch [8/40] Iter[282/312]		Loss: 0.2871
2019-10-29 00:35:02,210 Training Epoch [8/40] Iter[283/312]		Loss: 0.2876
2019-10-29 00:35:02,332 Training Epoch [8/40] Iter[284/312]		Loss: 0.2877
2019-10-29 00:35:02,453 Training Epoch [8/40] Iter[285/312]		Loss: 0.2880
2019-10-29 00:35:02,575 Training Epoch [8/40] Iter[286/312]		Loss: 0.2878
2019-10-29 00:35:02,696 Training Epoch [8/40] Iter[287/312]		Loss: 0.2880
2019-10-29 00:35:02,818 Training Epoch [8/40] Iter[288/312]		Loss: 0.2883
2019-10-29 00:35:02,940 Training Epoch [8/40] Iter[289/312]		Loss: 0.2882
2019-10-29 00:35:03,061 Training Epoch [8/40] Iter[290/312]		Loss: 0.2881
2019-10-29 00:35:03,183 Training Epoch [8/40] Iter[291/312]		Loss: 0.2881
2019-10-29 00:35:03,304 Training Epoch [8/40] Iter[292/312]		Loss: 0.2880
2019-10-29 00:35:03,427 Training Epoch [8/40] Iter[293/312]		Loss: 0.2882
2019-10-29 00:35:03,548 Training Epoch [8/40] Iter[294/312]		Loss: 0.2886
2019-10-29 00:35:03,669 Training Epoch [8/40] Iter[295/312]		Loss: 0.2884
2019-10-29 00:35:03,790 Training Epoch [8/40] Iter[296/312]		Loss: 0.2883
2019-10-29 00:35:03,912 Training Epoch [8/40] Iter[297/312]		Loss: 0.2882
2019-10-29 00:35:04,033 Training Epoch [8/40] Iter[298/312]		Loss: 0.2879
2019-10-29 00:35:04,154 Training Epoch [8/40] Iter[299/312]		Loss: 0.2877
2019-10-29 00:35:04,276 Training Epoch [8/40] Iter[300/312]		Loss: 0.2875
2019-10-29 00:35:04,397 Training Epoch [8/40] Iter[301/312]		Loss: 0.2873
2019-10-29 00:35:04,518 Training Epoch [8/40] Iter[302/312]		Loss: 0.2871
2019-10-29 00:35:04,639 Training Epoch [8/40] Iter[303/312]		Loss: 0.2871
2019-10-29 00:35:04,761 Training Epoch [8/40] Iter[304/312]		Loss: 0.2872
2019-10-29 00:35:04,881 Training Epoch [8/40] Iter[305/312]		Loss: 0.2873
2019-10-29 00:35:05,002 Training Epoch [8/40] Iter[306/312]		Loss: 0.2874
2019-10-29 00:35:05,124 Training Epoch [8/40] Iter[307/312]		Loss: 0.2871
2019-10-29 00:35:05,245 Training Epoch [8/40] Iter[308/312]		Loss: 0.2868
2019-10-29 00:35:05,366 Training Epoch [8/40] Iter[309/312]		Loss: 0.2872
2019-10-29 00:35:05,487 Training Epoch [8/40] Iter[310/312]		Loss: 0.2870
2019-10-29 00:35:05,608 Training Epoch [8/40] Iter[311/312]		Loss: 0.2872
2019-10-29 00:35:05,669 Training Epoch [8/40] Iter[312/312]		Loss: 0.2871
2019-10-29 00:35:06,084 Testing Epoch [8/40] Iter[0/62]		Loss: 0.3059
2019-10-29 00:35:06,122 Testing Epoch [8/40] Iter[1/62]		Loss: 0.2900
2019-10-29 00:35:06,152 Testing Epoch [8/40] Iter[2/62]		Loss: 0.2849
2019-10-29 00:35:06,183 Testing Epoch [8/40] Iter[3/62]		Loss: 0.2822
2019-10-29 00:35:06,215 Testing Epoch [8/40] Iter[4/62]		Loss: 0.2751
2019-10-29 00:35:06,245 Testing Epoch [8/40] Iter[5/62]		Loss: 0.2661
2019-10-29 00:35:06,275 Testing Epoch [8/40] Iter[6/62]		Loss: 0.2615
2019-10-29 00:35:06,305 Testing Epoch [8/40] Iter[7/62]		Loss: 0.2643
2019-10-29 00:35:06,337 Testing Epoch [8/40] Iter[8/62]		Loss: 0.2733
2019-10-29 00:35:06,368 Testing Epoch [8/40] Iter[9/62]		Loss: 0.2690
2019-10-29 00:35:06,399 Testing Epoch [8/40] Iter[10/62]		Loss: 0.2663
2019-10-29 00:35:06,430 Testing Epoch [8/40] Iter[11/62]		Loss: 0.2725
2019-10-29 00:35:06,461 Testing Epoch [8/40] Iter[12/62]		Loss: 0.2717
2019-10-29 00:35:06,492 Testing Epoch [8/40] Iter[13/62]		Loss: 0.2759
2019-10-29 00:35:06,523 Testing Epoch [8/40] Iter[14/62]		Loss: 0.2953
2019-10-29 00:35:06,554 Testing Epoch [8/40] Iter[15/62]		Loss: 0.2952
2019-10-29 00:35:06,584 Testing Epoch [8/40] Iter[16/62]		Loss: 0.2937
2019-10-29 00:35:06,615 Testing Epoch [8/40] Iter[17/62]		Loss: 0.2900
2019-10-29 00:35:06,646 Testing Epoch [8/40] Iter[18/62]		Loss: 0.2862
2019-10-29 00:35:06,677 Testing Epoch [8/40] Iter[19/62]		Loss: 0.2849
2019-10-29 00:35:06,708 Testing Epoch [8/40] Iter[20/62]		Loss: 0.2888
2019-10-29 00:35:06,739 Testing Epoch [8/40] Iter[21/62]		Loss: 0.2896
2019-10-29 00:35:06,769 Testing Epoch [8/40] Iter[22/62]		Loss: 0.2921
2019-10-29 00:35:06,800 Testing Epoch [8/40] Iter[23/62]		Loss: 0.2915
2019-10-29 00:35:06,831 Testing Epoch [8/40] Iter[24/62]		Loss: 0.2948
2019-10-29 00:35:06,862 Testing Epoch [8/40] Iter[25/62]		Loss: 0.2928
2019-10-29 00:35:06,893 Testing Epoch [8/40] Iter[26/62]		Loss: 0.2927
2019-10-29 00:35:06,924 Testing Epoch [8/40] Iter[27/62]		Loss: 0.2999
2019-10-29 00:35:06,955 Testing Epoch [8/40] Iter[28/62]		Loss: 0.3023
2019-10-29 00:35:06,985 Testing Epoch [8/40] Iter[29/62]		Loss: 0.3026
2019-10-29 00:35:07,016 Testing Epoch [8/40] Iter[30/62]		Loss: 0.3053
2019-10-29 00:35:07,047 Testing Epoch [8/40] Iter[31/62]		Loss: 0.3065
2019-10-29 00:35:07,078 Testing Epoch [8/40] Iter[32/62]		Loss: 0.3089
2019-10-29 00:35:07,109 Testing Epoch [8/40] Iter[33/62]		Loss: 0.3065
2019-10-29 00:35:07,140 Testing Epoch [8/40] Iter[34/62]		Loss: 0.3080
2019-10-29 00:35:07,171 Testing Epoch [8/40] Iter[35/62]		Loss: 0.3077
2019-10-29 00:35:07,202 Testing Epoch [8/40] Iter[36/62]		Loss: 0.3053
2019-10-29 00:35:07,233 Testing Epoch [8/40] Iter[37/62]		Loss: 0.3043
2019-10-29 00:35:07,264 Testing Epoch [8/40] Iter[38/62]		Loss: 0.3045
2019-10-29 00:35:07,294 Testing Epoch [8/40] Iter[39/62]		Loss: 0.3056
2019-10-29 00:35:07,325 Testing Epoch [8/40] Iter[40/62]		Loss: 0.3066
2019-10-29 00:35:07,356 Testing Epoch [8/40] Iter[41/62]		Loss: 0.3076
2019-10-29 00:35:07,387 Testing Epoch [8/40] Iter[42/62]		Loss: 0.3053
2019-10-29 00:35:07,418 Testing Epoch [8/40] Iter[43/62]		Loss: 0.3046
2019-10-29 00:35:07,449 Testing Epoch [8/40] Iter[44/62]		Loss: 0.3037
2019-10-29 00:35:07,480 Testing Epoch [8/40] Iter[45/62]		Loss: 0.3045
2019-10-29 00:35:07,510 Testing Epoch [8/40] Iter[46/62]		Loss: 0.3051
2019-10-29 00:35:07,541 Testing Epoch [8/40] Iter[47/62]		Loss: 0.3110
2019-10-29 00:35:07,572 Testing Epoch [8/40] Iter[48/62]		Loss: 0.3086
2019-10-29 00:35:07,603 Testing Epoch [8/40] Iter[49/62]		Loss: 0.3100
2019-10-29 00:35:07,634 Testing Epoch [8/40] Iter[50/62]		Loss: 0.3090
2019-10-29 00:35:07,664 Testing Epoch [8/40] Iter[51/62]		Loss: 0.3095
2019-10-29 00:35:07,695 Testing Epoch [8/40] Iter[52/62]		Loss: 0.3088
2019-10-29 00:35:07,726 Testing Epoch [8/40] Iter[53/62]		Loss: 0.3088
2019-10-29 00:35:07,757 Testing Epoch [8/40] Iter[54/62]		Loss: 0.3071
2019-10-29 00:35:07,787 Testing Epoch [8/40] Iter[55/62]		Loss: 0.3063
2019-10-29 00:35:07,818 Testing Epoch [8/40] Iter[56/62]		Loss: 0.3051
2019-10-29 00:35:07,848 Testing Epoch [8/40] Iter[57/62]		Loss: 0.3053
2019-10-29 00:35:07,878 Testing Epoch [8/40] Iter[58/62]		Loss: 0.3038
2019-10-29 00:35:07,909 Testing Epoch [8/40] Iter[59/62]		Loss: 0.3044
2019-10-29 00:35:07,939 Testing Epoch [8/40] Iter[60/62]		Loss: 0.3035
2019-10-29 00:35:07,970 Testing Epoch [8/40] Iter[61/62]		Loss: 0.3043
2019-10-29 00:35:07,987 Testing Epoch [8/40] Iter[62/62]		Loss: 0.3066
2019-10-29 00:35:08,053 Saving the Model
2019-10-29 00:35:08,508 Training Epoch [9/40] Iter[0/312]		Loss: 0.2958
2019-10-29 00:35:08,629 Training Epoch [9/40] Iter[1/312]		Loss: 0.4121
2019-10-29 00:35:08,750 Training Epoch [9/40] Iter[2/312]		Loss: 0.3880
2019-10-29 00:35:08,870 Training Epoch [9/40] Iter[3/312]		Loss: 0.3884
2019-10-29 00:35:08,991 Training Epoch [9/40] Iter[4/312]		Loss: 0.4059
2019-10-29 00:35:09,112 Training Epoch [9/40] Iter[5/312]		Loss: 0.3826
2019-10-29 00:35:09,232 Training Epoch [9/40] Iter[6/312]		Loss: 0.3739
2019-10-29 00:35:09,352 Training Epoch [9/40] Iter[7/312]		Loss: 0.3598
2019-10-29 00:35:09,474 Training Epoch [9/40] Iter[8/312]		Loss: 0.3513
2019-10-29 00:35:09,594 Training Epoch [9/40] Iter[9/312]		Loss: 0.3367
2019-10-29 00:35:09,715 Training Epoch [9/40] Iter[10/312]		Loss: 0.3388
2019-10-29 00:35:09,836 Training Epoch [9/40] Iter[11/312]		Loss: 0.3275
2019-10-29 00:35:09,958 Training Epoch [9/40] Iter[12/312]		Loss: 0.3228
2019-10-29 00:35:10,079 Training Epoch [9/40] Iter[13/312]		Loss: 0.3219
2019-10-29 00:35:10,201 Training Epoch [9/40] Iter[14/312]		Loss: 0.3204
2019-10-29 00:35:10,322 Training Epoch [9/40] Iter[15/312]		Loss: 0.3141
2019-10-29 00:35:10,443 Training Epoch [9/40] Iter[16/312]		Loss: 0.3139
2019-10-29 00:35:10,565 Training Epoch [9/40] Iter[17/312]		Loss: 0.3122
2019-10-29 00:35:10,687 Training Epoch [9/40] Iter[18/312]		Loss: 0.3060
2019-10-29 00:35:10,809 Training Epoch [9/40] Iter[19/312]		Loss: 0.3037
2019-10-29 00:35:10,930 Training Epoch [9/40] Iter[20/312]		Loss: 0.3014
2019-10-29 00:35:11,052 Training Epoch [9/40] Iter[21/312]		Loss: 0.2952
2019-10-29 00:35:11,173 Training Epoch [9/40] Iter[22/312]		Loss: 0.2918
2019-10-29 00:35:11,295 Training Epoch [9/40] Iter[23/312]		Loss: 0.2947
2019-10-29 00:35:11,416 Training Epoch [9/40] Iter[24/312]		Loss: 0.2931
2019-10-29 00:35:11,538 Training Epoch [9/40] Iter[25/312]		Loss: 0.2937
2019-10-29 00:35:11,659 Training Epoch [9/40] Iter[26/312]		Loss: 0.2979
2019-10-29 00:35:11,781 Training Epoch [9/40] Iter[27/312]		Loss: 0.2998
2019-10-29 00:35:11,903 Training Epoch [9/40] Iter[28/312]		Loss: 0.3029
2019-10-29 00:35:12,025 Training Epoch [9/40] Iter[29/312]		Loss: 0.3033
2019-10-29 00:35:12,146 Training Epoch [9/40] Iter[30/312]		Loss: 0.3072
2019-10-29 00:35:12,267 Training Epoch [9/40] Iter[31/312]		Loss: 0.3056
2019-10-29 00:35:12,389 Training Epoch [9/40] Iter[32/312]		Loss: 0.3016
2019-10-29 00:35:12,510 Training Epoch [9/40] Iter[33/312]		Loss: 0.3004
2019-10-29 00:35:12,631 Training Epoch [9/40] Iter[34/312]		Loss: 0.3003
2019-10-29 00:35:12,753 Training Epoch [9/40] Iter[35/312]		Loss: 0.2972
2019-10-29 00:35:12,874 Training Epoch [9/40] Iter[36/312]		Loss: 0.2935
2019-10-29 00:35:12,996 Training Epoch [9/40] Iter[37/312]		Loss: 0.2939
2019-10-29 00:35:13,117 Training Epoch [9/40] Iter[38/312]		Loss: 0.2918
2019-10-29 00:35:13,244 Training Epoch [9/40] Iter[39/312]		Loss: 0.2923
2019-10-29 00:35:13,365 Training Epoch [9/40] Iter[40/312]		Loss: 0.2900
2019-10-29 00:35:13,487 Training Epoch [9/40] Iter[41/312]		Loss: 0.2892
2019-10-29 00:35:13,612 Training Epoch [9/40] Iter[42/312]		Loss: 0.2877
2019-10-29 00:35:13,734 Training Epoch [9/40] Iter[43/312]		Loss: 0.2854
2019-10-29 00:35:13,856 Training Epoch [9/40] Iter[44/312]		Loss: 0.2863
2019-10-29 00:35:13,978 Training Epoch [9/40] Iter[45/312]		Loss: 0.2841
2019-10-29 00:35:14,099 Training Epoch [9/40] Iter[46/312]		Loss: 0.2822
2019-10-29 00:35:14,220 Training Epoch [9/40] Iter[47/312]		Loss: 0.2820
2019-10-29 00:35:14,341 Training Epoch [9/40] Iter[48/312]		Loss: 0.2808
2019-10-29 00:35:14,462 Training Epoch [9/40] Iter[49/312]		Loss: 0.2801
2019-10-29 00:35:14,584 Training Epoch [9/40] Iter[50/312]		Loss: 0.2788
2019-10-29 00:35:14,705 Training Epoch [9/40] Iter[51/312]		Loss: 0.2769
2019-10-29 00:35:14,826 Training Epoch [9/40] Iter[52/312]		Loss: 0.2777
2019-10-29 00:35:14,948 Training Epoch [9/40] Iter[53/312]		Loss: 0.2774
2019-10-29 00:35:15,069 Training Epoch [9/40] Iter[54/312]		Loss: 0.2771
2019-10-29 00:35:15,192 Training Epoch [9/40] Iter[55/312]		Loss: 0.2761
2019-10-29 00:35:15,314 Training Epoch [9/40] Iter[56/312]		Loss: 0.2750
2019-10-29 00:35:15,435 Training Epoch [9/40] Iter[57/312]		Loss: 0.2748
2019-10-29 00:35:15,557 Training Epoch [9/40] Iter[58/312]		Loss: 0.2756
2019-10-29 00:35:15,678 Training Epoch [9/40] Iter[59/312]		Loss: 0.2776
2019-10-29 00:35:15,800 Training Epoch [9/40] Iter[60/312]		Loss: 0.2775
2019-10-29 00:35:15,922 Training Epoch [9/40] Iter[61/312]		Loss: 0.2768
2019-10-29 00:35:16,048 Training Epoch [9/40] Iter[62/312]		Loss: 0.2761
2019-10-29 00:35:16,169 Training Epoch [9/40] Iter[63/312]		Loss: 0.2762
2019-10-29 00:35:16,291 Training Epoch [9/40] Iter[64/312]		Loss: 0.2763
2019-10-29 00:35:16,413 Training Epoch [9/40] Iter[65/312]		Loss: 0.2764
2019-10-29 00:35:16,534 Training Epoch [9/40] Iter[66/312]		Loss: 0.2759
2019-10-29 00:35:16,656 Training Epoch [9/40] Iter[67/312]		Loss: 0.2761
2019-10-29 00:35:16,777 Training Epoch [9/40] Iter[68/312]		Loss: 0.2795
2019-10-29 00:35:16,899 Training Epoch [9/40] Iter[69/312]		Loss: 0.2792
2019-10-29 00:35:17,020 Training Epoch [9/40] Iter[70/312]		Loss: 0.2795
2019-10-29 00:35:17,141 Training Epoch [9/40] Iter[71/312]		Loss: 0.2808
2019-10-29 00:35:17,263 Training Epoch [9/40] Iter[72/312]		Loss: 0.2798
2019-10-29 00:35:17,384 Training Epoch [9/40] Iter[73/312]		Loss: 0.2799
2019-10-29 00:35:17,506 Training Epoch [9/40] Iter[74/312]		Loss: 0.2803
2019-10-29 00:35:17,628 Training Epoch [9/40] Iter[75/312]		Loss: 0.2805
2019-10-29 00:35:17,749 Training Epoch [9/40] Iter[76/312]		Loss: 0.2794
2019-10-29 00:35:17,870 Training Epoch [9/40] Iter[77/312]		Loss: 0.2785
2019-10-29 00:35:17,992 Training Epoch [9/40] Iter[78/312]		Loss: 0.2780
2019-10-29 00:35:18,113 Training Epoch [9/40] Iter[79/312]		Loss: 0.2779
2019-10-29 00:35:18,234 Training Epoch [9/40] Iter[80/312]		Loss: 0.2783
2019-10-29 00:35:18,355 Training Epoch [9/40] Iter[81/312]		Loss: 0.2783
2019-10-29 00:35:18,476 Training Epoch [9/40] Iter[82/312]		Loss: 0.2772
2019-10-29 00:35:18,597 Training Epoch [9/40] Iter[83/312]		Loss: 0.2766
2019-10-29 00:35:18,717 Training Epoch [9/40] Iter[84/312]		Loss: 0.2767
2019-10-29 00:35:18,838 Training Epoch [9/40] Iter[85/312]		Loss: 0.2763
2019-10-29 00:35:18,959 Training Epoch [9/40] Iter[86/312]		Loss: 0.2763
2019-10-29 00:35:19,080 Training Epoch [9/40] Iter[87/312]		Loss: 0.2763
2019-10-29 00:35:19,202 Training Epoch [9/40] Iter[88/312]		Loss: 0.2770
2019-10-29 00:35:19,323 Training Epoch [9/40] Iter[89/312]		Loss: 0.2790
2019-10-29 00:35:19,445 Training Epoch [9/40] Iter[90/312]		Loss: 0.2793
2019-10-29 00:35:19,567 Training Epoch [9/40] Iter[91/312]		Loss: 0.2796
2019-10-29 00:35:19,688 Training Epoch [9/40] Iter[92/312]		Loss: 0.2797
2019-10-29 00:35:19,810 Training Epoch [9/40] Iter[93/312]		Loss: 0.2805
2019-10-29 00:35:19,931 Training Epoch [9/40] Iter[94/312]		Loss: 0.2820
2019-10-29 00:35:20,053 Training Epoch [9/40] Iter[95/312]		Loss: 0.2829
2019-10-29 00:35:20,175 Training Epoch [9/40] Iter[96/312]		Loss: 0.2824
2019-10-29 00:35:20,296 Training Epoch [9/40] Iter[97/312]		Loss: 0.2822
2019-10-29 00:35:20,418 Training Epoch [9/40] Iter[98/312]		Loss: 0.2828
2019-10-29 00:35:20,539 Training Epoch [9/40] Iter[99/312]		Loss: 0.2831
2019-10-29 00:35:20,661 Training Epoch [9/40] Iter[100/312]		Loss: 0.2833
2019-10-29 00:35:20,783 Training Epoch [9/40] Iter[101/312]		Loss: 0.2822
2019-10-29 00:35:20,905 Training Epoch [9/40] Iter[102/312]		Loss: 0.2823
2019-10-29 00:35:21,027 Training Epoch [9/40] Iter[103/312]		Loss: 0.2822
2019-10-29 00:35:21,148 Training Epoch [9/40] Iter[104/312]		Loss: 0.2821
2019-10-29 00:35:21,269 Training Epoch [9/40] Iter[105/312]		Loss: 0.2819
2019-10-29 00:35:21,391 Training Epoch [9/40] Iter[106/312]		Loss: 0.2819
2019-10-29 00:35:21,512 Training Epoch [9/40] Iter[107/312]		Loss: 0.2811
2019-10-29 00:35:21,633 Training Epoch [9/40] Iter[108/312]		Loss: 0.2801
2019-10-29 00:35:21,755 Training Epoch [9/40] Iter[109/312]		Loss: 0.2799
2019-10-29 00:35:21,876 Training Epoch [9/40] Iter[110/312]		Loss: 0.2793
2019-10-29 00:35:21,997 Training Epoch [9/40] Iter[111/312]		Loss: 0.2792
2019-10-29 00:35:22,119 Training Epoch [9/40] Iter[112/312]		Loss: 0.2787
2019-10-29 00:35:22,243 Training Epoch [9/40] Iter[113/312]		Loss: 0.2787
2019-10-29 00:35:22,364 Training Epoch [9/40] Iter[114/312]		Loss: 0.2785
2019-10-29 00:35:22,487 Training Epoch [9/40] Iter[115/312]		Loss: 0.2780
2019-10-29 00:35:22,608 Training Epoch [9/40] Iter[116/312]		Loss: 0.2780
2019-10-29 00:35:22,730 Training Epoch [9/40] Iter[117/312]		Loss: 0.2774
2019-10-29 00:35:22,851 Training Epoch [9/40] Iter[118/312]		Loss: 0.2769
2019-10-29 00:35:22,972 Training Epoch [9/40] Iter[119/312]		Loss: 0.2762
2019-10-29 00:35:23,094 Training Epoch [9/40] Iter[120/312]		Loss: 0.2757
2019-10-29 00:35:23,216 Training Epoch [9/40] Iter[121/312]		Loss: 0.2751
2019-10-29 00:35:23,338 Training Epoch [9/40] Iter[122/312]		Loss: 0.2746
2019-10-29 00:35:23,459 Training Epoch [9/40] Iter[123/312]		Loss: 0.2743
2019-10-29 00:35:23,581 Training Epoch [9/40] Iter[124/312]		Loss: 0.2740
2019-10-29 00:35:23,702 Training Epoch [9/40] Iter[125/312]		Loss: 0.2739
2019-10-29 00:35:23,824 Training Epoch [9/40] Iter[126/312]		Loss: 0.2733
2019-10-29 00:35:23,946 Training Epoch [9/40] Iter[127/312]		Loss: 0.2737
2019-10-29 00:35:24,067 Training Epoch [9/40] Iter[128/312]		Loss: 0.2730
2019-10-29 00:35:24,188 Training Epoch [9/40] Iter[129/312]		Loss: 0.2731
2019-10-29 00:35:24,310 Training Epoch [9/40] Iter[130/312]		Loss: 0.2729
2019-10-29 00:35:24,431 Training Epoch [9/40] Iter[131/312]		Loss: 0.2727
2019-10-29 00:35:24,552 Training Epoch [9/40] Iter[132/312]		Loss: 0.2725
2019-10-29 00:35:24,674 Training Epoch [9/40] Iter[133/312]		Loss: 0.2722
2019-10-29 00:35:24,795 Training Epoch [9/40] Iter[134/312]		Loss: 0.2714
2019-10-29 00:35:24,917 Training Epoch [9/40] Iter[135/312]		Loss: 0.2707
2019-10-29 00:35:25,038 Training Epoch [9/40] Iter[136/312]		Loss: 0.2704
2019-10-29 00:35:25,160 Training Epoch [9/40] Iter[137/312]		Loss: 0.2702
2019-10-29 00:35:25,282 Training Epoch [9/40] Iter[138/312]		Loss: 0.2703
2019-10-29 00:35:25,403 Training Epoch [9/40] Iter[139/312]		Loss: 0.2702
2019-10-29 00:35:25,525 Training Epoch [9/40] Iter[140/312]		Loss: 0.2697
2019-10-29 00:35:25,646 Training Epoch [9/40] Iter[141/312]		Loss: 0.2697
2019-10-29 00:35:25,768 Training Epoch [9/40] Iter[142/312]		Loss: 0.2697
2019-10-29 00:35:25,890 Training Epoch [9/40] Iter[143/312]		Loss: 0.2695
2019-10-29 00:35:26,011 Training Epoch [9/40] Iter[144/312]		Loss: 0.2693
2019-10-29 00:35:26,133 Training Epoch [9/40] Iter[145/312]		Loss: 0.2688
2019-10-29 00:35:26,254 Training Epoch [9/40] Iter[146/312]		Loss: 0.2684
2019-10-29 00:35:26,375 Training Epoch [9/40] Iter[147/312]		Loss: 0.2682
2019-10-29 00:35:26,496 Training Epoch [9/40] Iter[148/312]		Loss: 0.2682
2019-10-29 00:35:26,617 Training Epoch [9/40] Iter[149/312]		Loss: 0.2677
2019-10-29 00:35:26,738 Training Epoch [9/40] Iter[150/312]		Loss: 0.2676
2019-10-29 00:35:26,859 Training Epoch [9/40] Iter[151/312]		Loss: 0.2670
2019-10-29 00:35:26,980 Training Epoch [9/40] Iter[152/312]		Loss: 0.2667
2019-10-29 00:35:27,101 Training Epoch [9/40] Iter[153/312]		Loss: 0.2665
2019-10-29 00:35:27,223 Training Epoch [9/40] Iter[154/312]		Loss: 0.2660
2019-10-29 00:35:27,344 Training Epoch [9/40] Iter[155/312]		Loss: 0.2659
2019-10-29 00:35:27,465 Training Epoch [9/40] Iter[156/312]		Loss: 0.2659
2019-10-29 00:35:27,587 Training Epoch [9/40] Iter[157/312]		Loss: 0.2657
2019-10-29 00:35:27,709 Training Epoch [9/40] Iter[158/312]		Loss: 0.2655
2019-10-29 00:35:27,831 Training Epoch [9/40] Iter[159/312]		Loss: 0.2653
2019-10-29 00:35:27,952 Training Epoch [9/40] Iter[160/312]		Loss: 0.2654
2019-10-29 00:35:28,074 Training Epoch [9/40] Iter[161/312]		Loss: 0.2651
2019-10-29 00:35:28,196 Training Epoch [9/40] Iter[162/312]		Loss: 0.2646
2019-10-29 00:35:28,318 Training Epoch [9/40] Iter[163/312]		Loss: 0.2642
2019-10-29 00:35:28,440 Training Epoch [9/40] Iter[164/312]		Loss: 0.2645
2019-10-29 00:35:28,561 Training Epoch [9/40] Iter[165/312]		Loss: 0.2644
2019-10-29 00:35:28,683 Training Epoch [9/40] Iter[166/312]		Loss: 0.2649
2019-10-29 00:35:28,805 Training Epoch [9/40] Iter[167/312]		Loss: 0.2650
2019-10-29 00:35:28,927 Training Epoch [9/40] Iter[168/312]		Loss: 0.2645
2019-10-29 00:35:29,053 Training Epoch [9/40] Iter[169/312]		Loss: 0.2642
2019-10-29 00:35:29,175 Training Epoch [9/40] Iter[170/312]		Loss: 0.2638
2019-10-29 00:35:29,297 Training Epoch [9/40] Iter[171/312]		Loss: 0.2636
2019-10-29 00:35:29,419 Training Epoch [9/40] Iter[172/312]		Loss: 0.2639
2019-10-29 00:35:29,540 Training Epoch [9/40] Iter[173/312]		Loss: 0.2639
2019-10-29 00:35:29,661 Training Epoch [9/40] Iter[174/312]		Loss: 0.2637
2019-10-29 00:35:29,783 Training Epoch [9/40] Iter[175/312]		Loss: 0.2638
2019-10-29 00:35:29,904 Training Epoch [9/40] Iter[176/312]		Loss: 0.2638
2019-10-29 00:35:30,026 Training Epoch [9/40] Iter[177/312]		Loss: 0.2637
2019-10-29 00:35:30,147 Training Epoch [9/40] Iter[178/312]		Loss: 0.2635
2019-10-29 00:35:30,269 Training Epoch [9/40] Iter[179/312]		Loss: 0.2631
2019-10-29 00:35:30,390 Training Epoch [9/40] Iter[180/312]		Loss: 0.2627
2019-10-29 00:35:30,512 Training Epoch [9/40] Iter[181/312]		Loss: 0.2627
2019-10-29 00:35:30,633 Training Epoch [9/40] Iter[182/312]		Loss: 0.2625
2019-10-29 00:35:30,754 Training Epoch [9/40] Iter[183/312]		Loss: 0.2623
2019-10-29 00:35:30,876 Training Epoch [9/40] Iter[184/312]		Loss: 0.2619
2019-10-29 00:35:30,998 Training Epoch [9/40] Iter[185/312]		Loss: 0.2615
2019-10-29 00:35:31,120 Training Epoch [9/40] Iter[186/312]		Loss: 0.2613
2019-10-29 00:35:31,241 Training Epoch [9/40] Iter[187/312]		Loss: 0.2611
2019-10-29 00:35:31,362 Training Epoch [9/40] Iter[188/312]		Loss: 0.2608
2019-10-29 00:35:31,484 Training Epoch [9/40] Iter[189/312]		Loss: 0.2606
2019-10-29 00:35:31,606 Training Epoch [9/40] Iter[190/312]		Loss: 0.2601
2019-10-29 00:35:31,728 Training Epoch [9/40] Iter[191/312]		Loss: 0.2606
2019-10-29 00:35:31,849 Training Epoch [9/40] Iter[192/312]		Loss: 0.2605
2019-10-29 00:35:31,971 Training Epoch [9/40] Iter[193/312]		Loss: 0.2606
2019-10-29 00:35:32,092 Training Epoch [9/40] Iter[194/312]		Loss: 0.2608
2019-10-29 00:35:32,214 Training Epoch [9/40] Iter[195/312]		Loss: 0.2611
2019-10-29 00:35:32,336 Training Epoch [9/40] Iter[196/312]		Loss: 0.2610
2019-10-29 00:35:32,457 Training Epoch [9/40] Iter[197/312]		Loss: 0.2607
2019-10-29 00:35:32,578 Training Epoch [9/40] Iter[198/312]		Loss: 0.2605
2019-10-29 00:35:32,699 Training Epoch [9/40] Iter[199/312]		Loss: 0.2608
2019-10-29 00:35:32,821 Training Epoch [9/40] Iter[200/312]		Loss: 0.2606
2019-10-29 00:35:32,942 Training Epoch [9/40] Iter[201/312]		Loss: 0.2603
2019-10-29 00:35:33,064 Training Epoch [9/40] Iter[202/312]		Loss: 0.2604
2019-10-29 00:35:33,185 Training Epoch [9/40] Iter[203/312]		Loss: 0.2606
2019-10-29 00:35:33,307 Training Epoch [9/40] Iter[204/312]		Loss: 0.2610
2019-10-29 00:35:33,429 Training Epoch [9/40] Iter[205/312]		Loss: 0.2611
2019-10-29 00:35:33,550 Training Epoch [9/40] Iter[206/312]		Loss: 0.2611
2019-10-29 00:35:33,672 Training Epoch [9/40] Iter[207/312]		Loss: 0.2614
2019-10-29 00:35:33,793 Training Epoch [9/40] Iter[208/312]		Loss: 0.2614
2019-10-29 00:35:33,915 Training Epoch [9/40] Iter[209/312]		Loss: 0.2616
2019-10-29 00:35:34,036 Training Epoch [9/40] Iter[210/312]		Loss: 0.2616
2019-10-29 00:35:34,157 Training Epoch [9/40] Iter[211/312]		Loss: 0.2616
2019-10-29 00:35:34,278 Training Epoch [9/40] Iter[212/312]		Loss: 0.2618
2019-10-29 00:35:34,399 Training Epoch [9/40] Iter[213/312]		Loss: 0.2621
2019-10-29 00:35:34,521 Training Epoch [9/40] Iter[214/312]		Loss: 0.2620
2019-10-29 00:35:34,643 Training Epoch [9/40] Iter[215/312]		Loss: 0.2619
2019-10-29 00:35:34,764 Training Epoch [9/40] Iter[216/312]		Loss: 0.2621
2019-10-29 00:35:34,885 Training Epoch [9/40] Iter[217/312]		Loss: 0.2620
2019-10-29 00:35:35,006 Training Epoch [9/40] Iter[218/312]		Loss: 0.2622
2019-10-29 00:35:35,127 Training Epoch [9/40] Iter[219/312]		Loss: 0.2628
2019-10-29 00:35:35,248 Training Epoch [9/40] Iter[220/312]		Loss: 0.2633
2019-10-29 00:35:35,369 Training Epoch [9/40] Iter[221/312]		Loss: 0.2637
2019-10-29 00:35:35,490 Training Epoch [9/40] Iter[222/312]		Loss: 0.2639
2019-10-29 00:35:35,612 Training Epoch [9/40] Iter[223/312]		Loss: 0.2637
2019-10-29 00:35:35,733 Training Epoch [9/40] Iter[224/312]		Loss: 0.2636
2019-10-29 00:35:35,854 Training Epoch [9/40] Iter[225/312]		Loss: 0.2635
2019-10-29 00:35:35,975 Training Epoch [9/40] Iter[226/312]		Loss: 0.2639
2019-10-29 00:35:36,097 Training Epoch [9/40] Iter[227/312]		Loss: 0.2642
2019-10-29 00:35:36,218 Training Epoch [9/40] Iter[228/312]		Loss: 0.2644
2019-10-29 00:35:36,340 Training Epoch [9/40] Iter[229/312]		Loss: 0.2644
2019-10-29 00:35:36,462 Training Epoch [9/40] Iter[230/312]		Loss: 0.2644
2019-10-29 00:35:36,584 Training Epoch [9/40] Iter[231/312]		Loss: 0.2644
2019-10-29 00:35:36,705 Training Epoch [9/40] Iter[232/312]		Loss: 0.2648
2019-10-29 00:35:36,827 Training Epoch [9/40] Iter[233/312]		Loss: 0.2647
2019-10-29 00:35:36,949 Training Epoch [9/40] Iter[234/312]		Loss: 0.2646
2019-10-29 00:35:37,071 Training Epoch [9/40] Iter[235/312]		Loss: 0.2645
2019-10-29 00:35:37,192 Training Epoch [9/40] Iter[236/312]		Loss: 0.2640
2019-10-29 00:35:37,314 Training Epoch [9/40] Iter[237/312]		Loss: 0.2639
2019-10-29 00:35:37,435 Training Epoch [9/40] Iter[238/312]		Loss: 0.2640
2019-10-29 00:35:37,557 Training Epoch [9/40] Iter[239/312]		Loss: 0.2642
2019-10-29 00:35:37,679 Training Epoch [9/40] Iter[240/312]		Loss: 0.2640
2019-10-29 00:35:37,800 Training Epoch [9/40] Iter[241/312]		Loss: 0.2641
2019-10-29 00:35:37,922 Training Epoch [9/40] Iter[242/312]		Loss: 0.2646
2019-10-29 00:35:38,043 Training Epoch [9/40] Iter[243/312]		Loss: 0.2644
2019-10-29 00:35:38,165 Training Epoch [9/40] Iter[244/312]		Loss: 0.2643
2019-10-29 00:35:38,286 Training Epoch [9/40] Iter[245/312]		Loss: 0.2645
2019-10-29 00:35:38,407 Training Epoch [9/40] Iter[246/312]		Loss: 0.2646
2019-10-29 00:35:38,529 Training Epoch [9/40] Iter[247/312]		Loss: 0.2645
2019-10-29 00:35:38,650 Training Epoch [9/40] Iter[248/312]		Loss: 0.2643
2019-10-29 00:35:38,771 Training Epoch [9/40] Iter[249/312]		Loss: 0.2644
2019-10-29 00:35:38,893 Training Epoch [9/40] Iter[250/312]		Loss: 0.2641
2019-10-29 00:35:39,014 Training Epoch [9/40] Iter[251/312]		Loss: 0.2638
2019-10-29 00:35:39,135 Training Epoch [9/40] Iter[252/312]		Loss: 0.2636
2019-10-29 00:35:39,257 Training Epoch [9/40] Iter[253/312]		Loss: 0.2637
2019-10-29 00:35:39,378 Training Epoch [9/40] Iter[254/312]		Loss: 0.2637
2019-10-29 00:35:39,500 Training Epoch [9/40] Iter[255/312]		Loss: 0.2642
2019-10-29 00:35:39,622 Training Epoch [9/40] Iter[256/312]		Loss: 0.2639
2019-10-29 00:35:39,743 Training Epoch [9/40] Iter[257/312]		Loss: 0.2638
2019-10-29 00:35:39,865 Training Epoch [9/40] Iter[258/312]		Loss: 0.2634
2019-10-29 00:35:39,986 Training Epoch [9/40] Iter[259/312]		Loss: 0.2630
2019-10-29 00:35:40,108 Training Epoch [9/40] Iter[260/312]		Loss: 0.2631
2019-10-29 00:35:40,230 Training Epoch [9/40] Iter[261/312]		Loss: 0.2631
2019-10-29 00:35:40,351 Training Epoch [9/40] Iter[262/312]		Loss: 0.2630
2019-10-29 00:35:40,472 Training Epoch [9/40] Iter[263/312]		Loss: 0.2631
2019-10-29 00:35:40,594 Training Epoch [9/40] Iter[264/312]		Loss: 0.2633
2019-10-29 00:35:40,716 Training Epoch [9/40] Iter[265/312]		Loss: 0.2632
2019-10-29 00:35:40,837 Training Epoch [9/40] Iter[266/312]		Loss: 0.2632
2019-10-29 00:35:40,959 Training Epoch [9/40] Iter[267/312]		Loss: 0.2632
2019-10-29 00:35:41,081 Training Epoch [9/40] Iter[268/312]		Loss: 0.2633
2019-10-29 00:35:41,203 Training Epoch [9/40] Iter[269/312]		Loss: 0.2633
2019-10-29 00:35:41,325 Training Epoch [9/40] Iter[270/312]		Loss: 0.2631
2019-10-29 00:35:41,446 Training Epoch [9/40] Iter[271/312]		Loss: 0.2628
2019-10-29 00:35:41,569 Training Epoch [9/40] Iter[272/312]		Loss: 0.2626
2019-10-29 00:35:41,691 Training Epoch [9/40] Iter[273/312]		Loss: 0.2624
2019-10-29 00:35:41,813 Training Epoch [9/40] Iter[274/312]		Loss: 0.2628
2019-10-29 00:35:41,935 Training Epoch [9/40] Iter[275/312]		Loss: 0.2631
2019-10-29 00:35:42,056 Training Epoch [9/40] Iter[276/312]		Loss: 0.2627
2019-10-29 00:35:42,177 Training Epoch [9/40] Iter[277/312]		Loss: 0.2625
2019-10-29 00:35:42,299 Training Epoch [9/40] Iter[278/312]		Loss: 0.2623
2019-10-29 00:35:42,420 Training Epoch [9/40] Iter[279/312]		Loss: 0.2621
2019-10-29 00:35:42,542 Training Epoch [9/40] Iter[280/312]		Loss: 0.2620
2019-10-29 00:35:42,663 Training Epoch [9/40] Iter[281/312]		Loss: 0.2625
2019-10-29 00:35:42,785 Training Epoch [9/40] Iter[282/312]		Loss: 0.2622
2019-10-29 00:35:42,906 Training Epoch [9/40] Iter[283/312]		Loss: 0.2623
2019-10-29 00:35:43,028 Training Epoch [9/40] Iter[284/312]		Loss: 0.2621
2019-10-29 00:35:43,149 Training Epoch [9/40] Iter[285/312]		Loss: 0.2618
2019-10-29 00:35:43,270 Training Epoch [9/40] Iter[286/312]		Loss: 0.2616
2019-10-29 00:35:43,392 Training Epoch [9/40] Iter[287/312]		Loss: 0.2619
2019-10-29 00:35:43,513 Training Epoch [9/40] Iter[288/312]		Loss: 0.2617
2019-10-29 00:35:43,634 Training Epoch [9/40] Iter[289/312]		Loss: 0.2617
2019-10-29 00:35:43,755 Training Epoch [9/40] Iter[290/312]		Loss: 0.2618
2019-10-29 00:35:43,876 Training Epoch [9/40] Iter[291/312]		Loss: 0.2617
2019-10-29 00:35:43,997 Training Epoch [9/40] Iter[292/312]		Loss: 0.2617
2019-10-29 00:35:44,119 Training Epoch [9/40] Iter[293/312]		Loss: 0.2617
2019-10-29 00:35:44,240 Training Epoch [9/40] Iter[294/312]		Loss: 0.2618
2019-10-29 00:35:44,361 Training Epoch [9/40] Iter[295/312]		Loss: 0.2615
2019-10-29 00:35:44,483 Training Epoch [9/40] Iter[296/312]		Loss: 0.2614
2019-10-29 00:35:44,604 Training Epoch [9/40] Iter[297/312]		Loss: 0.2609
2019-10-29 00:35:44,725 Training Epoch [9/40] Iter[298/312]		Loss: 0.2609
2019-10-29 00:35:44,846 Training Epoch [9/40] Iter[299/312]		Loss: 0.2610
2019-10-29 00:35:44,968 Training Epoch [9/40] Iter[300/312]		Loss: 0.2607
2019-10-29 00:35:45,089 Training Epoch [9/40] Iter[301/312]		Loss: 0.2604
2019-10-29 00:35:45,211 Training Epoch [9/40] Iter[302/312]		Loss: 0.2606
2019-10-29 00:35:45,333 Training Epoch [9/40] Iter[303/312]		Loss: 0.2602
2019-10-29 00:35:45,455 Training Epoch [9/40] Iter[304/312]		Loss: 0.2600
2019-10-29 00:35:45,576 Training Epoch [9/40] Iter[305/312]		Loss: 0.2600
2019-10-29 00:35:45,697 Training Epoch [9/40] Iter[306/312]		Loss: 0.2599
2019-10-29 00:35:45,819 Training Epoch [9/40] Iter[307/312]		Loss: 0.2597
2019-10-29 00:35:45,940 Training Epoch [9/40] Iter[308/312]		Loss: 0.2599
2019-10-29 00:35:46,061 Training Epoch [9/40] Iter[309/312]		Loss: 0.2598
2019-10-29 00:35:46,182 Training Epoch [9/40] Iter[310/312]		Loss: 0.2597
2019-10-29 00:35:46,303 Training Epoch [9/40] Iter[311/312]		Loss: 0.2597
2019-10-29 00:35:46,364 Training Epoch [9/40] Iter[312/312]		Loss: 0.2599
2019-10-29 00:35:46,666 Testing Epoch [9/40] Iter[0/62]		Loss: 0.2474
2019-10-29 00:35:46,766 Testing Epoch [9/40] Iter[1/62]		Loss: 0.2702
2019-10-29 00:35:46,818 Testing Epoch [9/40] Iter[2/62]		Loss: 0.2527
2019-10-29 00:35:46,851 Testing Epoch [9/40] Iter[3/62]		Loss: 0.2537
2019-10-29 00:35:46,890 Testing Epoch [9/40] Iter[4/62]		Loss: 0.2547
2019-10-29 00:35:46,920 Testing Epoch [9/40] Iter[5/62]		Loss: 0.2423
2019-10-29 00:35:46,951 Testing Epoch [9/40] Iter[6/62]		Loss: 0.2482
2019-10-29 00:35:46,989 Testing Epoch [9/40] Iter[7/62]		Loss: 0.2546
2019-10-29 00:35:47,019 Testing Epoch [9/40] Iter[8/62]		Loss: 0.2552
2019-10-29 00:35:47,049 Testing Epoch [9/40] Iter[9/62]		Loss: 0.2529
2019-10-29 00:35:47,079 Testing Epoch [9/40] Iter[10/62]		Loss: 0.2545
2019-10-29 00:35:47,110 Testing Epoch [9/40] Iter[11/62]		Loss: 0.2645
2019-10-29 00:35:47,141 Testing Epoch [9/40] Iter[12/62]		Loss: 0.2625
2019-10-29 00:35:47,172 Testing Epoch [9/40] Iter[13/62]		Loss: 0.2656
2019-10-29 00:35:47,202 Testing Epoch [9/40] Iter[14/62]		Loss: 0.2794
2019-10-29 00:35:47,233 Testing Epoch [9/40] Iter[15/62]		Loss: 0.2820
2019-10-29 00:35:47,264 Testing Epoch [9/40] Iter[16/62]		Loss: 0.2799
2019-10-29 00:35:47,295 Testing Epoch [9/40] Iter[17/62]		Loss: 0.2777
2019-10-29 00:35:47,326 Testing Epoch [9/40] Iter[18/62]		Loss: 0.2744
2019-10-29 00:35:47,357 Testing Epoch [9/40] Iter[19/62]		Loss: 0.2738
2019-10-29 00:35:47,388 Testing Epoch [9/40] Iter[20/62]		Loss: 0.2776
2019-10-29 00:35:47,419 Testing Epoch [9/40] Iter[21/62]		Loss: 0.2754
2019-10-29 00:35:47,450 Testing Epoch [9/40] Iter[22/62]		Loss: 0.2761
2019-10-29 00:35:47,481 Testing Epoch [9/40] Iter[23/62]		Loss: 0.2758
2019-10-29 00:35:47,511 Testing Epoch [9/40] Iter[24/62]		Loss: 0.2792
2019-10-29 00:35:47,542 Testing Epoch [9/40] Iter[25/62]		Loss: 0.2782
2019-10-29 00:35:47,573 Testing Epoch [9/40] Iter[26/62]		Loss: 0.2768
2019-10-29 00:35:47,604 Testing Epoch [9/40] Iter[27/62]		Loss: 0.2832
2019-10-29 00:35:47,634 Testing Epoch [9/40] Iter[28/62]		Loss: 0.2835
2019-10-29 00:35:47,665 Testing Epoch [9/40] Iter[29/62]		Loss: 0.2845
2019-10-29 00:35:47,696 Testing Epoch [9/40] Iter[30/62]		Loss: 0.2861
2019-10-29 00:35:47,727 Testing Epoch [9/40] Iter[31/62]		Loss: 0.2854
2019-10-29 00:35:47,757 Testing Epoch [9/40] Iter[32/62]		Loss: 0.2863
2019-10-29 00:35:47,788 Testing Epoch [9/40] Iter[33/62]		Loss: 0.2856
2019-10-29 00:35:47,819 Testing Epoch [9/40] Iter[34/62]		Loss: 0.2862
2019-10-29 00:35:47,850 Testing Epoch [9/40] Iter[35/62]		Loss: 0.2859
2019-10-29 00:35:47,881 Testing Epoch [9/40] Iter[36/62]		Loss: 0.2848
2019-10-29 00:35:47,912 Testing Epoch [9/40] Iter[37/62]		Loss: 0.2838
2019-10-29 00:35:47,942 Testing Epoch [9/40] Iter[38/62]		Loss: 0.2841
2019-10-29 00:35:47,973 Testing Epoch [9/40] Iter[39/62]		Loss: 0.2849
2019-10-29 00:35:48,004 Testing Epoch [9/40] Iter[40/62]		Loss: 0.2871
2019-10-29 00:35:48,035 Testing Epoch [9/40] Iter[41/62]		Loss: 0.2864
2019-10-29 00:35:48,066 Testing Epoch [9/40] Iter[42/62]		Loss: 0.2860
2019-10-29 00:35:48,097 Testing Epoch [9/40] Iter[43/62]		Loss: 0.2866
2019-10-29 00:35:48,128 Testing Epoch [9/40] Iter[44/62]		Loss: 0.2888
2019-10-29 00:35:48,159 Testing Epoch [9/40] Iter[45/62]		Loss: 0.2892
2019-10-29 00:35:48,190 Testing Epoch [9/40] Iter[46/62]		Loss: 0.2896
2019-10-29 00:35:48,221 Testing Epoch [9/40] Iter[47/62]		Loss: 0.2958
2019-10-29 00:35:48,252 Testing Epoch [9/40] Iter[48/62]		Loss: 0.2950
2019-10-29 00:35:48,283 Testing Epoch [9/40] Iter[49/62]		Loss: 0.2954
2019-10-29 00:35:48,314 Testing Epoch [9/40] Iter[50/62]		Loss: 0.2942
2019-10-29 00:35:48,344 Testing Epoch [9/40] Iter[51/62]		Loss: 0.2937
2019-10-29 00:35:48,375 Testing Epoch [9/40] Iter[52/62]		Loss: 0.2923
2019-10-29 00:35:48,406 Testing Epoch [9/40] Iter[53/62]		Loss: 0.2923
2019-10-29 00:35:48,437 Testing Epoch [9/40] Iter[54/62]		Loss: 0.2913
2019-10-29 00:35:48,467 Testing Epoch [9/40] Iter[55/62]		Loss: 0.2909
2019-10-29 00:35:48,497 Testing Epoch [9/40] Iter[56/62]		Loss: 0.2906
2019-10-29 00:35:48,528 Testing Epoch [9/40] Iter[57/62]		Loss: 0.2907
2019-10-29 00:35:48,558 Testing Epoch [9/40] Iter[58/62]		Loss: 0.2902
2019-10-29 00:35:48,589 Testing Epoch [9/40] Iter[59/62]		Loss: 0.2909
2019-10-29 00:35:48,619 Testing Epoch [9/40] Iter[60/62]		Loss: 0.2897
2019-10-29 00:35:48,650 Testing Epoch [9/40] Iter[61/62]		Loss: 0.2898
2019-10-29 00:35:48,667 Testing Epoch [9/40] Iter[62/62]		Loss: 0.2903
2019-10-29 00:35:48,730 Saving the Model
2019-10-29 00:35:49,171 Training Epoch [10/40] Iter[0/312]		Loss: 0.1668
2019-10-29 00:35:49,296 Training Epoch [10/40] Iter[1/312]		Loss: 0.4095
2019-10-29 00:35:49,417 Training Epoch [10/40] Iter[2/312]		Loss: 0.4265
2019-10-29 00:35:49,538 Training Epoch [10/40] Iter[3/312]		Loss: 0.4060
2019-10-29 00:35:49,662 Training Epoch [10/40] Iter[4/312]		Loss: 0.3902
2019-10-29 00:35:49,782 Training Epoch [10/40] Iter[5/312]		Loss: 0.3949
2019-10-29 00:35:49,903 Training Epoch [10/40] Iter[6/312]		Loss: 0.3869
2019-10-29 00:35:50,023 Training Epoch [10/40] Iter[7/312]		Loss: 0.3679
2019-10-29 00:35:50,144 Training Epoch [10/40] Iter[8/312]		Loss: 0.3546
2019-10-29 00:35:50,265 Training Epoch [10/40] Iter[9/312]		Loss: 0.3490
2019-10-29 00:35:50,387 Training Epoch [10/40] Iter[10/312]		Loss: 0.3404
2019-10-29 00:35:50,508 Training Epoch [10/40] Iter[11/312]		Loss: 0.3336
2019-10-29 00:35:50,630 Training Epoch [10/40] Iter[12/312]		Loss: 0.3324
2019-10-29 00:35:50,752 Training Epoch [10/40] Iter[13/312]		Loss: 0.3209
2019-10-29 00:35:50,873 Training Epoch [10/40] Iter[14/312]		Loss: 0.3161
2019-10-29 00:35:50,995 Training Epoch [10/40] Iter[15/312]		Loss: 0.3141
2019-10-29 00:35:51,116 Training Epoch [10/40] Iter[16/312]		Loss: 0.3085
2019-10-29 00:35:51,238 Training Epoch [10/40] Iter[17/312]		Loss: 0.3035
2019-10-29 00:35:51,359 Training Epoch [10/40] Iter[18/312]		Loss: 0.3005
2019-10-29 00:35:51,481 Training Epoch [10/40] Iter[19/312]		Loss: 0.3005
2019-10-29 00:35:51,602 Training Epoch [10/40] Iter[20/312]		Loss: 0.2959
2019-10-29 00:35:51,723 Training Epoch [10/40] Iter[21/312]		Loss: 0.2925
2019-10-29 00:35:51,845 Training Epoch [10/40] Iter[22/312]		Loss: 0.2908
2019-10-29 00:35:51,966 Training Epoch [10/40] Iter[23/312]		Loss: 0.2869
2019-10-29 00:35:52,087 Training Epoch [10/40] Iter[24/312]		Loss: 0.2846
2019-10-29 00:35:52,208 Training Epoch [10/40] Iter[25/312]		Loss: 0.2845
2019-10-29 00:35:52,329 Training Epoch [10/40] Iter[26/312]		Loss: 0.2847
2019-10-29 00:35:52,450 Training Epoch [10/40] Iter[27/312]		Loss: 0.2829
2019-10-29 00:35:52,572 Training Epoch [10/40] Iter[28/312]		Loss: 0.2834
2019-10-29 00:35:52,692 Training Epoch [10/40] Iter[29/312]		Loss: 0.2809
2019-10-29 00:35:52,814 Training Epoch [10/40] Iter[30/312]		Loss: 0.2799
2019-10-29 00:35:52,934 Training Epoch [10/40] Iter[31/312]		Loss: 0.2774
2019-10-29 00:35:53,056 Training Epoch [10/40] Iter[32/312]		Loss: 0.2754
2019-10-29 00:35:53,176 Training Epoch [10/40] Iter[33/312]		Loss: 0.2748
2019-10-29 00:35:53,298 Training Epoch [10/40] Iter[34/312]		Loss: 0.2749
2019-10-29 00:35:53,419 Training Epoch [10/40] Iter[35/312]		Loss: 0.2726
2019-10-29 00:35:53,541 Training Epoch [10/40] Iter[36/312]		Loss: 0.2707
2019-10-29 00:35:53,662 Training Epoch [10/40] Iter[37/312]		Loss: 0.2705
2019-10-29 00:35:53,784 Training Epoch [10/40] Iter[38/312]		Loss: 0.2687
2019-10-29 00:35:53,906 Training Epoch [10/40] Iter[39/312]		Loss: 0.2680
2019-10-29 00:35:54,027 Training Epoch [10/40] Iter[40/312]		Loss: 0.2658
2019-10-29 00:35:54,148 Training Epoch [10/40] Iter[41/312]		Loss: 0.2679
2019-10-29 00:35:54,269 Training Epoch [10/40] Iter[42/312]		Loss: 0.2701
2019-10-29 00:35:54,391 Training Epoch [10/40] Iter[43/312]		Loss: 0.2694
2019-10-29 00:35:54,512 Training Epoch [10/40] Iter[44/312]		Loss: 0.2684
2019-10-29 00:35:54,634 Training Epoch [10/40] Iter[45/312]		Loss: 0.2679
2019-10-29 00:35:54,755 Training Epoch [10/40] Iter[46/312]		Loss: 0.2692
2019-10-29 00:35:54,877 Training Epoch [10/40] Iter[47/312]		Loss: 0.2672
2019-10-29 00:35:54,998 Training Epoch [10/40] Iter[48/312]		Loss: 0.2662
2019-10-29 00:35:55,120 Training Epoch [10/40] Iter[49/312]		Loss: 0.2650
2019-10-29 00:35:55,241 Training Epoch [10/40] Iter[50/312]		Loss: 0.2653
2019-10-29 00:35:55,363 Training Epoch [10/40] Iter[51/312]		Loss: 0.2643
2019-10-29 00:35:55,484 Training Epoch [10/40] Iter[52/312]		Loss: 0.2638
2019-10-29 00:35:55,605 Training Epoch [10/40] Iter[53/312]		Loss: 0.2641
2019-10-29 00:35:55,727 Training Epoch [10/40] Iter[54/312]		Loss: 0.2644
2019-10-29 00:35:55,848 Training Epoch [10/40] Iter[55/312]		Loss: 0.2641
2019-10-29 00:35:55,969 Training Epoch [10/40] Iter[56/312]		Loss: 0.2631
2019-10-29 00:35:56,090 Training Epoch [10/40] Iter[57/312]		Loss: 0.2624
2019-10-29 00:35:56,211 Training Epoch [10/40] Iter[58/312]		Loss: 0.2619
2019-10-29 00:35:56,333 Training Epoch [10/40] Iter[59/312]		Loss: 0.2610
2019-10-29 00:35:56,456 Training Epoch [10/40] Iter[60/312]		Loss: 0.2610
2019-10-29 00:35:56,577 Training Epoch [10/40] Iter[61/312]		Loss: 0.2592
2019-10-29 00:35:56,700 Training Epoch [10/40] Iter[62/312]		Loss: 0.2584
2019-10-29 00:35:56,822 Training Epoch [10/40] Iter[63/312]		Loss: 0.2584
2019-10-29 00:35:56,944 Training Epoch [10/40] Iter[64/312]		Loss: 0.2574
2019-10-29 00:35:57,067 Training Epoch [10/40] Iter[65/312]		Loss: 0.2568
2019-10-29 00:35:57,188 Training Epoch [10/40] Iter[66/312]		Loss: 0.2578
2019-10-29 00:35:57,310 Training Epoch [10/40] Iter[67/312]		Loss: 0.2575
2019-10-29 00:35:57,432 Training Epoch [10/40] Iter[68/312]		Loss: 0.2582
2019-10-29 00:35:57,553 Training Epoch [10/40] Iter[69/312]		Loss: 0.2569
2019-10-29 00:35:57,674 Training Epoch [10/40] Iter[70/312]		Loss: 0.2591
2019-10-29 00:35:57,796 Training Epoch [10/40] Iter[71/312]		Loss: 0.2586
2019-10-29 00:35:57,918 Training Epoch [10/40] Iter[72/312]		Loss: 0.2595
2019-10-29 00:35:58,039 Training Epoch [10/40] Iter[73/312]		Loss: 0.2603
2019-10-29 00:35:58,161 Training Epoch [10/40] Iter[74/312]		Loss: 0.2602
2019-10-29 00:35:58,283 Training Epoch [10/40] Iter[75/312]		Loss: 0.2599
2019-10-29 00:35:58,405 Training Epoch [10/40] Iter[76/312]		Loss: 0.2607
2019-10-29 00:35:58,526 Training Epoch [10/40] Iter[77/312]		Loss: 0.2602
2019-10-29 00:35:58,648 Training Epoch [10/40] Iter[78/312]		Loss: 0.2591
2019-10-29 00:35:58,770 Training Epoch [10/40] Iter[79/312]		Loss: 0.2583
2019-10-29 00:35:58,891 Training Epoch [10/40] Iter[80/312]		Loss: 0.2584
2019-10-29 00:35:59,013 Training Epoch [10/40] Iter[81/312]		Loss: 0.2581
2019-10-29 00:35:59,135 Training Epoch [10/40] Iter[82/312]		Loss: 0.2576
2019-10-29 00:35:59,260 Training Epoch [10/40] Iter[83/312]		Loss: 0.2567
2019-10-29 00:35:59,382 Training Epoch [10/40] Iter[84/312]		Loss: 0.2560
2019-10-29 00:35:59,503 Training Epoch [10/40] Iter[85/312]		Loss: 0.2575
2019-10-29 00:35:59,625 Training Epoch [10/40] Iter[86/312]		Loss: 0.2566
2019-10-29 00:35:59,746 Training Epoch [10/40] Iter[87/312]		Loss: 0.2553
2019-10-29 00:35:59,868 Training Epoch [10/40] Iter[88/312]		Loss: 0.2546
2019-10-29 00:35:59,989 Training Epoch [10/40] Iter[89/312]		Loss: 0.2547
2019-10-29 00:36:00,111 Training Epoch [10/40] Iter[90/312]		Loss: 0.2543
2019-10-29 00:36:00,232 Training Epoch [10/40] Iter[91/312]		Loss: 0.2533
2019-10-29 00:36:00,353 Training Epoch [10/40] Iter[92/312]		Loss: 0.2523
2019-10-29 00:36:00,475 Training Epoch [10/40] Iter[93/312]		Loss: 0.2516
2019-10-29 00:36:00,597 Training Epoch [10/40] Iter[94/312]		Loss: 0.2519
2019-10-29 00:36:00,718 Training Epoch [10/40] Iter[95/312]		Loss: 0.2517
2019-10-29 00:36:00,840 Training Epoch [10/40] Iter[96/312]		Loss: 0.2511
2019-10-29 00:36:00,961 Training Epoch [10/40] Iter[97/312]		Loss: 0.2504
2019-10-29 00:36:01,082 Training Epoch [10/40] Iter[98/312]		Loss: 0.2500
2019-10-29 00:36:01,208 Training Epoch [10/40] Iter[99/312]		Loss: 0.2497
2019-10-29 00:36:01,329 Training Epoch [10/40] Iter[100/312]		Loss: 0.2493
2019-10-29 00:36:01,451 Training Epoch [10/40] Iter[101/312]		Loss: 0.2499
2019-10-29 00:36:01,572 Training Epoch [10/40] Iter[102/312]		Loss: 0.2493
2019-10-29 00:36:01,693 Training Epoch [10/40] Iter[103/312]		Loss: 0.2490
2019-10-29 00:36:01,814 Training Epoch [10/40] Iter[104/312]		Loss: 0.2494
2019-10-29 00:36:01,935 Training Epoch [10/40] Iter[105/312]		Loss: 0.2489
2019-10-29 00:36:02,057 Training Epoch [10/40] Iter[106/312]		Loss: 0.2485
2019-10-29 00:36:02,179 Training Epoch [10/40] Iter[107/312]		Loss: 0.2488
2019-10-29 00:36:02,301 Training Epoch [10/40] Iter[108/312]		Loss: 0.2488
2019-10-29 00:36:02,423 Training Epoch [10/40] Iter[109/312]		Loss: 0.2484
2019-10-29 00:36:02,544 Training Epoch [10/40] Iter[110/312]		Loss: 0.2477
2019-10-29 00:36:02,666 Training Epoch [10/40] Iter[111/312]		Loss: 0.2481
2019-10-29 00:36:02,788 Training Epoch [10/40] Iter[112/312]		Loss: 0.2473
2019-10-29 00:36:02,909 Training Epoch [10/40] Iter[113/312]		Loss: 0.2477
2019-10-29 00:36:03,032 Training Epoch [10/40] Iter[114/312]		Loss: 0.2474
2019-10-29 00:36:03,153 Training Epoch [10/40] Iter[115/312]		Loss: 0.2473
2019-10-29 00:36:03,275 Training Epoch [10/40] Iter[116/312]		Loss: 0.2468
2019-10-29 00:36:03,397 Training Epoch [10/40] Iter[117/312]		Loss: 0.2464
2019-10-29 00:36:03,518 Training Epoch [10/40] Iter[118/312]		Loss: 0.2464
2019-10-29 00:36:03,640 Training Epoch [10/40] Iter[119/312]		Loss: 0.2466
2019-10-29 00:36:03,762 Training Epoch [10/40] Iter[120/312]		Loss: 0.2467
2019-10-29 00:36:03,884 Training Epoch [10/40] Iter[121/312]		Loss: 0.2464
2019-10-29 00:36:04,005 Training Epoch [10/40] Iter[122/312]		Loss: 0.2457
2019-10-29 00:36:04,127 Training Epoch [10/40] Iter[123/312]		Loss: 0.2457
2019-10-29 00:36:04,248 Training Epoch [10/40] Iter[124/312]		Loss: 0.2455
2019-10-29 00:36:04,370 Training Epoch [10/40] Iter[125/312]		Loss: 0.2454
2019-10-29 00:36:04,492 Training Epoch [10/40] Iter[126/312]		Loss: 0.2453
2019-10-29 00:36:04,613 Training Epoch [10/40] Iter[127/312]		Loss: 0.2451
2019-10-29 00:36:04,735 Training Epoch [10/40] Iter[128/312]		Loss: 0.2450
2019-10-29 00:36:04,856 Training Epoch [10/40] Iter[129/312]		Loss: 0.2450
2019-10-29 00:36:04,977 Training Epoch [10/40] Iter[130/312]		Loss: 0.2450
2019-10-29 00:36:05,099 Training Epoch [10/40] Iter[131/312]		Loss: 0.2451
2019-10-29 00:36:05,220 Training Epoch [10/40] Iter[132/312]		Loss: 0.2445
2019-10-29 00:36:05,341 Training Epoch [10/40] Iter[133/312]		Loss: 0.2447
2019-10-29 00:36:05,462 Training Epoch [10/40] Iter[134/312]		Loss: 0.2449
2019-10-29 00:36:05,584 Training Epoch [10/40] Iter[135/312]		Loss: 0.2448
2019-10-29 00:36:05,706 Training Epoch [10/40] Iter[136/312]		Loss: 0.2447
2019-10-29 00:36:05,828 Training Epoch [10/40] Iter[137/312]		Loss: 0.2448
2019-10-29 00:36:05,949 Training Epoch [10/40] Iter[138/312]		Loss: 0.2451
2019-10-29 00:36:06,071 Training Epoch [10/40] Iter[139/312]		Loss: 0.2448
2019-10-29 00:36:06,192 Training Epoch [10/40] Iter[140/312]		Loss: 0.2444
2019-10-29 00:36:06,314 Training Epoch [10/40] Iter[141/312]		Loss: 0.2439
2019-10-29 00:36:06,435 Training Epoch [10/40] Iter[142/312]		Loss: 0.2437
2019-10-29 00:36:06,557 Training Epoch [10/40] Iter[143/312]		Loss: 0.2434
2019-10-29 00:36:06,678 Training Epoch [10/40] Iter[144/312]		Loss: 0.2440
2019-10-29 00:36:06,800 Training Epoch [10/40] Iter[145/312]		Loss: 0.2448
2019-10-29 00:36:06,922 Training Epoch [10/40] Iter[146/312]		Loss: 0.2445
2019-10-29 00:36:07,044 Training Epoch [10/40] Iter[147/312]		Loss: 0.2444
2019-10-29 00:36:07,165 Training Epoch [10/40] Iter[148/312]		Loss: 0.2449
2019-10-29 00:36:07,287 Training Epoch [10/40] Iter[149/312]		Loss: 0.2448
2019-10-29 00:36:07,408 Training Epoch [10/40] Iter[150/312]		Loss: 0.2451
2019-10-29 00:36:07,530 Training Epoch [10/40] Iter[151/312]		Loss: 0.2450
2019-10-29 00:36:07,652 Training Epoch [10/40] Iter[152/312]		Loss: 0.2454
2019-10-29 00:36:07,773 Training Epoch [10/40] Iter[153/312]		Loss: 0.2453
2019-10-29 00:36:07,894 Training Epoch [10/40] Iter[154/312]		Loss: 0.2449
2019-10-29 00:36:08,016 Training Epoch [10/40] Iter[155/312]		Loss: 0.2447
2019-10-29 00:36:08,137 Training Epoch [10/40] Iter[156/312]		Loss: 0.2446
2019-10-29 00:36:08,259 Training Epoch [10/40] Iter[157/312]		Loss: 0.2453
2019-10-29 00:36:08,380 Training Epoch [10/40] Iter[158/312]		Loss: 0.2454
2019-10-29 00:36:08,502 Training Epoch [10/40] Iter[159/312]		Loss: 0.2461
2019-10-29 00:36:08,623 Training Epoch [10/40] Iter[160/312]		Loss: 0.2457
2019-10-29 00:36:08,745 Training Epoch [10/40] Iter[161/312]		Loss: 0.2459
2019-10-29 00:36:08,866 Training Epoch [10/40] Iter[162/312]		Loss: 0.2455
2019-10-29 00:36:08,987 Training Epoch [10/40] Iter[163/312]		Loss: 0.2455
2019-10-29 00:36:09,109 Training Epoch [10/40] Iter[164/312]		Loss: 0.2458
2019-10-29 00:36:09,230 Training Epoch [10/40] Iter[165/312]		Loss: 0.2454
2019-10-29 00:36:09,352 Training Epoch [10/40] Iter[166/312]		Loss: 0.2455
2019-10-29 00:36:09,473 Training Epoch [10/40] Iter[167/312]		Loss: 0.2452
2019-10-29 00:36:09,595 Training Epoch [10/40] Iter[168/312]		Loss: 0.2454
2019-10-29 00:36:09,716 Training Epoch [10/40] Iter[169/312]		Loss: 0.2451
2019-10-29 00:36:09,837 Training Epoch [10/40] Iter[170/312]		Loss: 0.2449
2019-10-29 00:36:09,958 Training Epoch [10/40] Iter[171/312]		Loss: 0.2446
2019-10-29 00:36:10,079 Training Epoch [10/40] Iter[172/312]		Loss: 0.2444
2019-10-29 00:36:10,200 Training Epoch [10/40] Iter[173/312]		Loss: 0.2446
2019-10-29 00:36:10,321 Training Epoch [10/40] Iter[174/312]		Loss: 0.2443
2019-10-29 00:36:10,442 Training Epoch [10/40] Iter[175/312]		Loss: 0.2445
2019-10-29 00:36:10,563 Training Epoch [10/40] Iter[176/312]		Loss: 0.2446
2019-10-29 00:36:10,684 Training Epoch [10/40] Iter[177/312]		Loss: 0.2453
2019-10-29 00:36:10,805 Training Epoch [10/40] Iter[178/312]		Loss: 0.2457
2019-10-29 00:36:10,927 Training Epoch [10/40] Iter[179/312]		Loss: 0.2458
2019-10-29 00:36:11,048 Training Epoch [10/40] Iter[180/312]		Loss: 0.2462
2019-10-29 00:36:11,169 Training Epoch [10/40] Iter[181/312]		Loss: 0.2458
2019-10-29 00:36:11,291 Training Epoch [10/40] Iter[182/312]		Loss: 0.2456
2019-10-29 00:36:11,413 Training Epoch [10/40] Iter[183/312]		Loss: 0.2453
2019-10-29 00:36:11,534 Training Epoch [10/40] Iter[184/312]		Loss: 0.2456
2019-10-29 00:36:11,655 Training Epoch [10/40] Iter[185/312]		Loss: 0.2454
2019-10-29 00:36:11,777 Training Epoch [10/40] Iter[186/312]		Loss: 0.2452
2019-10-29 00:36:11,899 Training Epoch [10/40] Iter[187/312]		Loss: 0.2451
2019-10-29 00:36:12,020 Training Epoch [10/40] Iter[188/312]		Loss: 0.2454
2019-10-29 00:36:12,142 Training Epoch [10/40] Iter[189/312]		Loss: 0.2461
2019-10-29 00:36:12,264 Training Epoch [10/40] Iter[190/312]		Loss: 0.2456
2019-10-29 00:36:12,385 Training Epoch [10/40] Iter[191/312]		Loss: 0.2456
2019-10-29 00:36:12,507 Training Epoch [10/40] Iter[192/312]		Loss: 0.2455
2019-10-29 00:36:12,629 Training Epoch [10/40] Iter[193/312]		Loss: 0.2454
2019-10-29 00:36:12,750 Training Epoch [10/40] Iter[194/312]		Loss: 0.2450
2019-10-29 00:36:12,877 Training Epoch [10/40] Iter[195/312]		Loss: 0.2448
2019-10-29 00:36:12,999 Training Epoch [10/40] Iter[196/312]		Loss: 0.2448
2019-10-29 00:36:13,121 Training Epoch [10/40] Iter[197/312]		Loss: 0.2453
2019-10-29 00:36:13,242 Training Epoch [10/40] Iter[198/312]		Loss: 0.2455
2019-10-29 00:36:13,364 Training Epoch [10/40] Iter[199/312]		Loss: 0.2455
2019-10-29 00:36:13,486 Training Epoch [10/40] Iter[200/312]		Loss: 0.2457
2019-10-29 00:36:13,607 Training Epoch [10/40] Iter[201/312]		Loss: 0.2460
2019-10-29 00:36:13,728 Training Epoch [10/40] Iter[202/312]		Loss: 0.2462
2019-10-29 00:36:13,849 Training Epoch [10/40] Iter[203/312]		Loss: 0.2467
2019-10-29 00:36:13,971 Training Epoch [10/40] Iter[204/312]		Loss: 0.2471
2019-10-29 00:36:14,092 Training Epoch [10/40] Iter[205/312]		Loss: 0.2471
2019-10-29 00:36:14,214 Training Epoch [10/40] Iter[206/312]		Loss: 0.2471
2019-10-29 00:36:14,335 Training Epoch [10/40] Iter[207/312]		Loss: 0.2474
2019-10-29 00:36:14,457 Training Epoch [10/40] Iter[208/312]		Loss: 0.2472
2019-10-29 00:36:14,578 Training Epoch [10/40] Iter[209/312]		Loss: 0.2473
2019-10-29 00:36:14,699 Training Epoch [10/40] Iter[210/312]		Loss: 0.2472
2019-10-29 00:36:14,820 Training Epoch [10/40] Iter[211/312]		Loss: 0.2469
2019-10-29 00:36:14,942 Training Epoch [10/40] Iter[212/312]		Loss: 0.2469
2019-10-29 00:36:15,064 Training Epoch [10/40] Iter[213/312]		Loss: 0.2468
2019-10-29 00:36:15,185 Training Epoch [10/40] Iter[214/312]		Loss: 0.2471
2019-10-29 00:36:15,306 Training Epoch [10/40] Iter[215/312]		Loss: 0.2477
2019-10-29 00:36:15,428 Training Epoch [10/40] Iter[216/312]		Loss: 0.2478
2019-10-29 00:36:15,549 Training Epoch [10/40] Iter[217/312]		Loss: 0.2478
2019-10-29 00:36:15,670 Training Epoch [10/40] Iter[218/312]		Loss: 0.2477
2019-10-29 00:36:15,792 Training Epoch [10/40] Iter[219/312]		Loss: 0.2481
2019-10-29 00:36:15,913 Training Epoch [10/40] Iter[220/312]		Loss: 0.2480
2019-10-29 00:36:16,035 Training Epoch [10/40] Iter[221/312]		Loss: 0.2476
2019-10-29 00:36:16,156 Training Epoch [10/40] Iter[222/312]		Loss: 0.2474
2019-10-29 00:36:16,278 Training Epoch [10/40] Iter[223/312]		Loss: 0.2474
2019-10-29 00:36:16,400 Training Epoch [10/40] Iter[224/312]		Loss: 0.2470
2019-10-29 00:36:16,522 Training Epoch [10/40] Iter[225/312]		Loss: 0.2471
2019-10-29 00:36:16,643 Training Epoch [10/40] Iter[226/312]		Loss: 0.2473
2019-10-29 00:36:16,765 Training Epoch [10/40] Iter[227/312]		Loss: 0.2474
2019-10-29 00:36:16,886 Training Epoch [10/40] Iter[228/312]		Loss: 0.2476
2019-10-29 00:36:17,007 Training Epoch [10/40] Iter[229/312]		Loss: 0.2479
2019-10-29 00:36:17,129 Training Epoch [10/40] Iter[230/312]		Loss: 0.2480
2019-10-29 00:36:17,250 Training Epoch [10/40] Iter[231/312]		Loss: 0.2481
2019-10-29 00:36:17,372 Training Epoch [10/40] Iter[232/312]		Loss: 0.2485
2019-10-29 00:36:17,494 Training Epoch [10/40] Iter[233/312]		Loss: 0.2490
2019-10-29 00:36:17,615 Training Epoch [10/40] Iter[234/312]		Loss: 0.2495
2019-10-29 00:36:17,736 Training Epoch [10/40] Iter[235/312]		Loss: 0.2494
2019-10-29 00:36:17,858 Training Epoch [10/40] Iter[236/312]		Loss: 0.2497
2019-10-29 00:36:17,979 Training Epoch [10/40] Iter[237/312]		Loss: 0.2497
2019-10-29 00:36:18,100 Training Epoch [10/40] Iter[238/312]		Loss: 0.2499
2019-10-29 00:36:18,222 Training Epoch [10/40] Iter[239/312]		Loss: 0.2497
2019-10-29 00:36:18,343 Training Epoch [10/40] Iter[240/312]		Loss: 0.2496
2019-10-29 00:36:18,465 Training Epoch [10/40] Iter[241/312]		Loss: 0.2499
2019-10-29 00:36:18,586 Training Epoch [10/40] Iter[242/312]		Loss: 0.2500
2019-10-29 00:36:18,708 Training Epoch [10/40] Iter[243/312]		Loss: 0.2497
2019-10-29 00:36:18,829 Training Epoch [10/40] Iter[244/312]		Loss: 0.2497
2019-10-29 00:36:18,950 Training Epoch [10/40] Iter[245/312]		Loss: 0.2495
2019-10-29 00:36:19,072 Training Epoch [10/40] Iter[246/312]		Loss: 0.2496
2019-10-29 00:36:19,193 Training Epoch [10/40] Iter[247/312]		Loss: 0.2495
2019-10-29 00:36:19,314 Training Epoch [10/40] Iter[248/312]		Loss: 0.2498
2019-10-29 00:36:19,436 Training Epoch [10/40] Iter[249/312]		Loss: 0.2496
2019-10-29 00:36:19,557 Training Epoch [10/40] Iter[250/312]		Loss: 0.2496
2019-10-29 00:36:19,678 Training Epoch [10/40] Iter[251/312]		Loss: 0.2497
2019-10-29 00:36:19,799 Training Epoch [10/40] Iter[252/312]		Loss: 0.2499
2019-10-29 00:36:19,920 Training Epoch [10/40] Iter[253/312]		Loss: 0.2499
2019-10-29 00:36:20,042 Training Epoch [10/40] Iter[254/312]		Loss: 0.2499
2019-10-29 00:36:20,163 Training Epoch [10/40] Iter[255/312]		Loss: 0.2499
2019-10-29 00:36:20,284 Training Epoch [10/40] Iter[256/312]		Loss: 0.2498
2019-10-29 00:36:20,405 Training Epoch [10/40] Iter[257/312]		Loss: 0.2500
2019-10-29 00:36:20,527 Training Epoch [10/40] Iter[258/312]		Loss: 0.2497
2019-10-29 00:36:20,649 Training Epoch [10/40] Iter[259/312]		Loss: 0.2497
2019-10-29 00:36:20,770 Training Epoch [10/40] Iter[260/312]		Loss: 0.2493
2019-10-29 00:36:20,892 Training Epoch [10/40] Iter[261/312]		Loss: 0.2492
2019-10-29 00:36:21,014 Training Epoch [10/40] Iter[262/312]		Loss: 0.2491
2019-10-29 00:36:21,135 Training Epoch [10/40] Iter[263/312]		Loss: 0.2488
2019-10-29 00:36:21,256 Training Epoch [10/40] Iter[264/312]		Loss: 0.2488
2019-10-29 00:36:21,379 Training Epoch [10/40] Iter[265/312]		Loss: 0.2486
2019-10-29 00:36:21,500 Training Epoch [10/40] Iter[266/312]		Loss: 0.2485
2019-10-29 00:36:21,621 Training Epoch [10/40] Iter[267/312]		Loss: 0.2484
2019-10-29 00:36:21,743 Training Epoch [10/40] Iter[268/312]		Loss: 0.2484
2019-10-29 00:36:21,864 Training Epoch [10/40] Iter[269/312]		Loss: 0.2480
2019-10-29 00:36:21,986 Training Epoch [10/40] Iter[270/312]		Loss: 0.2483
2019-10-29 00:36:22,108 Training Epoch [10/40] Iter[271/312]		Loss: 0.2483
2019-10-29 00:36:22,229 Training Epoch [10/40] Iter[272/312]		Loss: 0.2483
2019-10-29 00:36:22,351 Training Epoch [10/40] Iter[273/312]		Loss: 0.2479
2019-10-29 00:36:22,472 Training Epoch [10/40] Iter[274/312]		Loss: 0.2475
2019-10-29 00:36:22,593 Training Epoch [10/40] Iter[275/312]		Loss: 0.2474
2019-10-29 00:36:22,714 Training Epoch [10/40] Iter[276/312]		Loss: 0.2477
2019-10-29 00:36:22,837 Training Epoch [10/40] Iter[277/312]		Loss: 0.2479
2019-10-29 00:36:22,959 Training Epoch [10/40] Iter[278/312]		Loss: 0.2478
2019-10-29 00:36:23,080 Training Epoch [10/40] Iter[279/312]		Loss: 0.2477
2019-10-29 00:36:23,201 Training Epoch [10/40] Iter[280/312]		Loss: 0.2476
2019-10-29 00:36:23,322 Training Epoch [10/40] Iter[281/312]		Loss: 0.2478
2019-10-29 00:36:23,444 Training Epoch [10/40] Iter[282/312]		Loss: 0.2479
2019-10-29 00:36:23,565 Training Epoch [10/40] Iter[283/312]		Loss: 0.2478
2019-10-29 00:36:23,687 Training Epoch [10/40] Iter[284/312]		Loss: 0.2479
2019-10-29 00:36:23,808 Training Epoch [10/40] Iter[285/312]		Loss: 0.2477
2019-10-29 00:36:23,930 Training Epoch [10/40] Iter[286/312]		Loss: 0.2478
2019-10-29 00:36:24,052 Training Epoch [10/40] Iter[287/312]		Loss: 0.2478
2019-10-29 00:36:24,173 Training Epoch [10/40] Iter[288/312]		Loss: 0.2476
2019-10-29 00:36:24,294 Training Epoch [10/40] Iter[289/312]		Loss: 0.2479
2019-10-29 00:36:24,415 Training Epoch [10/40] Iter[290/312]		Loss: 0.2481
2019-10-29 00:36:24,537 Training Epoch [10/40] Iter[291/312]		Loss: 0.2478
2019-10-29 00:36:24,658 Training Epoch [10/40] Iter[292/312]		Loss: 0.2479
2019-10-29 00:36:24,780 Training Epoch [10/40] Iter[293/312]		Loss: 0.2480
2019-10-29 00:36:24,901 Training Epoch [10/40] Iter[294/312]		Loss: 0.2480
2019-10-29 00:36:25,023 Training Epoch [10/40] Iter[295/312]		Loss: 0.2482
2019-10-29 00:36:25,150 Training Epoch [10/40] Iter[296/312]		Loss: 0.2481
2019-10-29 00:36:25,272 Training Epoch [10/40] Iter[297/312]		Loss: 0.2483
2019-10-29 00:36:25,394 Training Epoch [10/40] Iter[298/312]		Loss: 0.2489
2019-10-29 00:36:25,516 Training Epoch [10/40] Iter[299/312]		Loss: 0.2493
2019-10-29 00:36:25,637 Training Epoch [10/40] Iter[300/312]		Loss: 0.2493
2019-10-29 00:36:25,759 Training Epoch [10/40] Iter[301/312]		Loss: 0.2495
2019-10-29 00:36:25,880 Training Epoch [10/40] Iter[302/312]		Loss: 0.2495
2019-10-29 00:36:26,002 Training Epoch [10/40] Iter[303/312]		Loss: 0.2494
2019-10-29 00:36:26,123 Training Epoch [10/40] Iter[304/312]		Loss: 0.2499
2019-10-29 00:36:26,244 Training Epoch [10/40] Iter[305/312]		Loss: 0.2497
2019-10-29 00:36:26,365 Training Epoch [10/40] Iter[306/312]		Loss: 0.2497
2019-10-29 00:36:26,486 Training Epoch [10/40] Iter[307/312]		Loss: 0.2495
2019-10-29 00:36:26,607 Training Epoch [10/40] Iter[308/312]		Loss: 0.2495
2019-10-29 00:36:26,728 Training Epoch [10/40] Iter[309/312]		Loss: 0.2496
2019-10-29 00:36:26,849 Training Epoch [10/40] Iter[310/312]		Loss: 0.2498
2019-10-29 00:36:26,970 Training Epoch [10/40] Iter[311/312]		Loss: 0.2502
2019-10-29 00:36:27,030 Training Epoch [10/40] Iter[312/312]		Loss: 0.2503
2019-10-29 00:36:27,329 Testing Epoch [10/40] Iter[0/62]		Loss: 0.2316
2019-10-29 00:36:27,448 Testing Epoch [10/40] Iter[1/62]		Loss: 0.2632
2019-10-29 00:36:27,485 Testing Epoch [10/40] Iter[2/62]		Loss: 0.2785
2019-10-29 00:36:27,517 Testing Epoch [10/40] Iter[3/62]		Loss: 0.2784
2019-10-29 00:36:27,554 Testing Epoch [10/40] Iter[4/62]		Loss: 0.2777
2019-10-29 00:36:27,585 Testing Epoch [10/40] Iter[5/62]		Loss: 0.2724
2019-10-29 00:36:27,618 Testing Epoch [10/40] Iter[6/62]		Loss: 0.2626
2019-10-29 00:36:27,649 Testing Epoch [10/40] Iter[7/62]		Loss: 0.2705
2019-10-29 00:36:27,679 Testing Epoch [10/40] Iter[8/62]		Loss: 0.2780
2019-10-29 00:36:27,717 Testing Epoch [10/40] Iter[9/62]		Loss: 0.2765
2019-10-29 00:36:27,747 Testing Epoch [10/40] Iter[10/62]		Loss: 0.2724
2019-10-29 00:36:27,779 Testing Epoch [10/40] Iter[11/62]		Loss: 0.2769
2019-10-29 00:36:27,809 Testing Epoch [10/40] Iter[12/62]		Loss: 0.2733
2019-10-29 00:36:27,840 Testing Epoch [10/40] Iter[13/62]		Loss: 0.2709
2019-10-29 00:36:27,871 Testing Epoch [10/40] Iter[14/62]		Loss: 0.2836
2019-10-29 00:36:27,902 Testing Epoch [10/40] Iter[15/62]		Loss: 0.2871
2019-10-29 00:36:27,933 Testing Epoch [10/40] Iter[16/62]		Loss: 0.2837
2019-10-29 00:36:27,964 Testing Epoch [10/40] Iter[17/62]		Loss: 0.2823
2019-10-29 00:36:27,994 Testing Epoch [10/40] Iter[18/62]		Loss: 0.2808
2019-10-29 00:36:28,025 Testing Epoch [10/40] Iter[19/62]		Loss: 0.2792
2019-10-29 00:36:28,056 Testing Epoch [10/40] Iter[20/62]		Loss: 0.2800
2019-10-29 00:36:28,087 Testing Epoch [10/40] Iter[21/62]		Loss: 0.2785
2019-10-29 00:36:28,117 Testing Epoch [10/40] Iter[22/62]		Loss: 0.2787
2019-10-29 00:36:28,148 Testing Epoch [10/40] Iter[23/62]		Loss: 0.2780
2019-10-29 00:36:28,179 Testing Epoch [10/40] Iter[24/62]		Loss: 0.2818
2019-10-29 00:36:28,210 Testing Epoch [10/40] Iter[25/62]		Loss: 0.2808
2019-10-29 00:36:28,241 Testing Epoch [10/40] Iter[26/62]		Loss: 0.2802
2019-10-29 00:36:28,272 Testing Epoch [10/40] Iter[27/62]		Loss: 0.2878
2019-10-29 00:36:28,303 Testing Epoch [10/40] Iter[28/62]		Loss: 0.2864
2019-10-29 00:36:28,333 Testing Epoch [10/40] Iter[29/62]		Loss: 0.2876
2019-10-29 00:36:28,364 Testing Epoch [10/40] Iter[30/62]		Loss: 0.2877
2019-10-29 00:36:28,395 Testing Epoch [10/40] Iter[31/62]		Loss: 0.2885
2019-10-29 00:36:28,425 Testing Epoch [10/40] Iter[32/62]		Loss: 0.2892
2019-10-29 00:36:28,456 Testing Epoch [10/40] Iter[33/62]		Loss: 0.2881
2019-10-29 00:36:28,487 Testing Epoch [10/40] Iter[34/62]		Loss: 0.2895
2019-10-29 00:36:28,517 Testing Epoch [10/40] Iter[35/62]		Loss: 0.2896
2019-10-29 00:36:28,548 Testing Epoch [10/40] Iter[36/62]		Loss: 0.2876
2019-10-29 00:36:28,579 Testing Epoch [10/40] Iter[37/62]		Loss: 0.2888
2019-10-29 00:36:28,609 Testing Epoch [10/40] Iter[38/62]		Loss: 0.2882
2019-10-29 00:36:28,640 Testing Epoch [10/40] Iter[39/62]		Loss: 0.2873
2019-10-29 00:36:28,670 Testing Epoch [10/40] Iter[40/62]		Loss: 0.2892
2019-10-29 00:36:28,701 Testing Epoch [10/40] Iter[41/62]		Loss: 0.2906
2019-10-29 00:36:28,732 Testing Epoch [10/40] Iter[42/62]		Loss: 0.2895
2019-10-29 00:36:28,762 Testing Epoch [10/40] Iter[43/62]		Loss: 0.2891
2019-10-29 00:36:28,793 Testing Epoch [10/40] Iter[44/62]		Loss: 0.2872
2019-10-29 00:36:28,823 Testing Epoch [10/40] Iter[45/62]		Loss: 0.2874
2019-10-29 00:36:28,854 Testing Epoch [10/40] Iter[46/62]		Loss: 0.2880
2019-10-29 00:36:28,885 Testing Epoch [10/40] Iter[47/62]		Loss: 0.2941
2019-10-29 00:36:28,915 Testing Epoch [10/40] Iter[48/62]		Loss: 0.2922
2019-10-29 00:36:28,946 Testing Epoch [10/40] Iter[49/62]		Loss: 0.2932
2019-10-29 00:36:28,977 Testing Epoch [10/40] Iter[50/62]		Loss: 0.2922
2019-10-29 00:36:29,008 Testing Epoch [10/40] Iter[51/62]		Loss: 0.2928
2019-10-29 00:36:29,038 Testing Epoch [10/40] Iter[52/62]		Loss: 0.2915
2019-10-29 00:36:29,069 Testing Epoch [10/40] Iter[53/62]		Loss: 0.2907
2019-10-29 00:36:29,100 Testing Epoch [10/40] Iter[54/62]		Loss: 0.2895
2019-10-29 00:36:29,130 Testing Epoch [10/40] Iter[55/62]		Loss: 0.2890
2019-10-29 00:36:29,160 Testing Epoch [10/40] Iter[56/62]		Loss: 0.2879
2019-10-29 00:36:29,191 Testing Epoch [10/40] Iter[57/62]		Loss: 0.2882
2019-10-29 00:36:29,221 Testing Epoch [10/40] Iter[58/62]		Loss: 0.2866
2019-10-29 00:36:29,252 Testing Epoch [10/40] Iter[59/62]		Loss: 0.2868
2019-10-29 00:36:29,282 Testing Epoch [10/40] Iter[60/62]		Loss: 0.2862
2019-10-29 00:36:29,313 Testing Epoch [10/40] Iter[61/62]		Loss: 0.2856
2019-10-29 00:36:29,330 Testing Epoch [10/40] Iter[62/62]		Loss: 0.2869
2019-10-29 00:36:29,395 Saving the Model
2019-10-29 00:36:29,848 Training Epoch [11/40] Iter[0/312]		Loss: 0.2429
2019-10-29 00:36:29,969 Training Epoch [11/40] Iter[1/312]		Loss: 0.2650
2019-10-29 00:36:30,089 Training Epoch [11/40] Iter[2/312]		Loss: 0.2420
2019-10-29 00:36:30,209 Training Epoch [11/40] Iter[3/312]		Loss: 0.2764
2019-10-29 00:36:30,331 Training Epoch [11/40] Iter[4/312]		Loss: 0.2722
2019-10-29 00:36:30,452 Training Epoch [11/40] Iter[5/312]		Loss: 0.2745
2019-10-29 00:36:30,572 Training Epoch [11/40] Iter[6/312]		Loss: 0.2579
2019-10-29 00:36:30,696 Training Epoch [11/40] Iter[7/312]		Loss: 0.2563
2019-10-29 00:36:30,818 Training Epoch [11/40] Iter[8/312]		Loss: 0.2580
2019-10-29 00:36:30,939 Training Epoch [11/40] Iter[9/312]		Loss: 0.2478
2019-10-29 00:36:31,060 Training Epoch [11/40] Iter[10/312]		Loss: 0.2433
2019-10-29 00:36:31,181 Training Epoch [11/40] Iter[11/312]		Loss: 0.2391
2019-10-29 00:36:31,302 Training Epoch [11/40] Iter[12/312]		Loss: 0.2311
2019-10-29 00:36:31,424 Training Epoch [11/40] Iter[13/312]		Loss: 0.2279
2019-10-29 00:36:31,545 Training Epoch [11/40] Iter[14/312]		Loss: 0.2254
2019-10-29 00:36:31,666 Training Epoch [11/40] Iter[15/312]		Loss: 0.2233
2019-10-29 00:36:31,788 Training Epoch [11/40] Iter[16/312]		Loss: 0.2229
2019-10-29 00:36:31,909 Training Epoch [11/40] Iter[17/312]		Loss: 0.2231
2019-10-29 00:36:32,030 Training Epoch [11/40] Iter[18/312]		Loss: 0.2207
2019-10-29 00:36:32,151 Training Epoch [11/40] Iter[19/312]		Loss: 0.2182
2019-10-29 00:36:32,272 Training Epoch [11/40] Iter[20/312]		Loss: 0.2156
2019-10-29 00:36:32,394 Training Epoch [11/40] Iter[21/312]		Loss: 0.2132
2019-10-29 00:36:32,515 Training Epoch [11/40] Iter[22/312]		Loss: 0.2105
2019-10-29 00:36:32,637 Training Epoch [11/40] Iter[23/312]		Loss: 0.2092
2019-10-29 00:36:32,758 Training Epoch [11/40] Iter[24/312]		Loss: 0.2069
2019-10-29 00:36:32,881 Training Epoch [11/40] Iter[25/312]		Loss: 0.2066
2019-10-29 00:36:33,003 Training Epoch [11/40] Iter[26/312]		Loss: 0.2052
2019-10-29 00:36:33,125 Training Epoch [11/40] Iter[27/312]		Loss: 0.2089
2019-10-29 00:36:33,246 Training Epoch [11/40] Iter[28/312]		Loss: 0.2066
2019-10-29 00:36:33,367 Training Epoch [11/40] Iter[29/312]		Loss: 0.2056
2019-10-29 00:36:33,489 Training Epoch [11/40] Iter[30/312]		Loss: 0.2052
2019-10-29 00:36:33,610 Training Epoch [11/40] Iter[31/312]		Loss: 0.2028
2019-10-29 00:36:33,731 Training Epoch [11/40] Iter[32/312]		Loss: 0.2004
2019-10-29 00:36:33,853 Training Epoch [11/40] Iter[33/312]		Loss: 0.2013
2019-10-29 00:36:33,974 Training Epoch [11/40] Iter[34/312]		Loss: 0.1988
2019-10-29 00:36:34,096 Training Epoch [11/40] Iter[35/312]		Loss: 0.1980
2019-10-29 00:36:34,217 Training Epoch [11/40] Iter[36/312]		Loss: 0.1972
2019-10-29 00:36:34,338 Training Epoch [11/40] Iter[37/312]		Loss: 0.1971
2019-10-29 00:36:34,459 Training Epoch [11/40] Iter[38/312]		Loss: 0.1969
2019-10-29 00:36:34,581 Training Epoch [11/40] Iter[39/312]		Loss: 0.1969
2019-10-29 00:36:34,702 Training Epoch [11/40] Iter[40/312]		Loss: 0.1958
2019-10-29 00:36:34,823 Training Epoch [11/40] Iter[41/312]		Loss: 0.1947
2019-10-29 00:36:34,945 Training Epoch [11/40] Iter[42/312]		Loss: 0.1932
2019-10-29 00:36:35,066 Training Epoch [11/40] Iter[43/312]		Loss: 0.1924
2019-10-29 00:36:35,188 Training Epoch [11/40] Iter[44/312]		Loss: 0.1915
2019-10-29 00:36:35,312 Training Epoch [11/40] Iter[45/312]		Loss: 0.1909
2019-10-29 00:36:35,433 Training Epoch [11/40] Iter[46/312]		Loss: 0.1902
2019-10-29 00:36:35,554 Training Epoch [11/40] Iter[47/312]		Loss: 0.1886
2019-10-29 00:36:35,676 Training Epoch [11/40] Iter[48/312]		Loss: 0.1877
2019-10-29 00:36:35,797 Training Epoch [11/40] Iter[49/312]		Loss: 0.1870
2019-10-29 00:36:35,918 Training Epoch [11/40] Iter[50/312]		Loss: 0.1864
2019-10-29 00:36:36,039 Training Epoch [11/40] Iter[51/312]		Loss: 0.1852
2019-10-29 00:36:36,161 Training Epoch [11/40] Iter[52/312]		Loss: 0.1855
2019-10-29 00:36:36,282 Training Epoch [11/40] Iter[53/312]		Loss: 0.1854
2019-10-29 00:36:36,403 Training Epoch [11/40] Iter[54/312]		Loss: 0.1856
2019-10-29 00:36:36,524 Training Epoch [11/40] Iter[55/312]		Loss: 0.1874
2019-10-29 00:36:36,645 Training Epoch [11/40] Iter[56/312]		Loss: 0.1872
2019-10-29 00:36:36,766 Training Epoch [11/40] Iter[57/312]		Loss: 0.1875
2019-10-29 00:36:36,887 Training Epoch [11/40] Iter[58/312]		Loss: 0.1865
2019-10-29 00:36:37,008 Training Epoch [11/40] Iter[59/312]		Loss: 0.1872
2019-10-29 00:36:37,129 Training Epoch [11/40] Iter[60/312]		Loss: 0.1861
2019-10-29 00:36:37,256 Training Epoch [11/40] Iter[61/312]		Loss: 0.1858
2019-10-29 00:36:37,377 Training Epoch [11/40] Iter[62/312]		Loss: 0.1863
2019-10-29 00:36:37,498 Training Epoch [11/40] Iter[63/312]		Loss: 0.1863
2019-10-29 00:36:37,619 Training Epoch [11/40] Iter[64/312]		Loss: 0.1870
2019-10-29 00:36:37,740 Training Epoch [11/40] Iter[65/312]		Loss: 0.1872
2019-10-29 00:36:37,861 Training Epoch [11/40] Iter[66/312]		Loss: 0.1870
2019-10-29 00:36:37,983 Training Epoch [11/40] Iter[67/312]		Loss: 0.1861
2019-10-29 00:36:38,104 Training Epoch [11/40] Iter[68/312]		Loss: 0.1860
2019-10-29 00:36:38,225 Training Epoch [11/40] Iter[69/312]		Loss: 0.1853
2019-10-29 00:36:38,346 Training Epoch [11/40] Iter[70/312]		Loss: 0.1848
2019-10-29 00:36:38,468 Training Epoch [11/40] Iter[71/312]		Loss: 0.1860
2019-10-29 00:36:38,589 Training Epoch [11/40] Iter[72/312]		Loss: 0.1850
2019-10-29 00:36:38,711 Training Epoch [11/40] Iter[73/312]		Loss: 0.1840
2019-10-29 00:36:38,833 Training Epoch [11/40] Iter[74/312]		Loss: 0.1845
2019-10-29 00:36:38,954 Training Epoch [11/40] Iter[75/312]		Loss: 0.1847
2019-10-29 00:36:39,075 Training Epoch [11/40] Iter[76/312]		Loss: 0.1843
2019-10-29 00:36:39,197 Training Epoch [11/40] Iter[77/312]		Loss: 0.1842
2019-10-29 00:36:39,318 Training Epoch [11/40] Iter[78/312]		Loss: 0.1841
2019-10-29 00:36:39,440 Training Epoch [11/40] Iter[79/312]		Loss: 0.1833
2019-10-29 00:36:39,561 Training Epoch [11/40] Iter[80/312]		Loss: 0.1829
2019-10-29 00:36:39,683 Training Epoch [11/40] Iter[81/312]		Loss: 0.1830
2019-10-29 00:36:39,804 Training Epoch [11/40] Iter[82/312]		Loss: 0.1830
2019-10-29 00:36:39,926 Training Epoch [11/40] Iter[83/312]		Loss: 0.1827
2019-10-29 00:36:40,048 Training Epoch [11/40] Iter[84/312]		Loss: 0.1825
2019-10-29 00:36:40,169 Training Epoch [11/40] Iter[85/312]		Loss: 0.1827
2019-10-29 00:36:40,290 Training Epoch [11/40] Iter[86/312]		Loss: 0.1820
2019-10-29 00:36:40,412 Training Epoch [11/40] Iter[87/312]		Loss: 0.1814
2019-10-29 00:36:40,532 Training Epoch [11/40] Iter[88/312]		Loss: 0.1813
2019-10-29 00:36:40,653 Training Epoch [11/40] Iter[89/312]		Loss: 0.1818
2019-10-29 00:36:40,774 Training Epoch [11/40] Iter[90/312]		Loss: 0.1823
2019-10-29 00:36:40,896 Training Epoch [11/40] Iter[91/312]		Loss: 0.1829
2019-10-29 00:36:41,017 Training Epoch [11/40] Iter[92/312]		Loss: 0.1831
2019-10-29 00:36:41,138 Training Epoch [11/40] Iter[93/312]		Loss: 0.1832
2019-10-29 00:36:41,259 Training Epoch [11/40] Iter[94/312]		Loss: 0.1835
2019-10-29 00:36:41,380 Training Epoch [11/40] Iter[95/312]		Loss: 0.1831
2019-10-29 00:36:41,502 Training Epoch [11/40] Iter[96/312]		Loss: 0.1829
2019-10-29 00:36:41,623 Training Epoch [11/40] Iter[97/312]		Loss: 0.1829
2019-10-29 00:36:41,745 Training Epoch [11/40] Iter[98/312]		Loss: 0.1824
2019-10-29 00:36:41,867 Training Epoch [11/40] Iter[99/312]		Loss: 0.1820
2019-10-29 00:36:41,988 Training Epoch [11/40] Iter[100/312]		Loss: 0.1821
2019-10-29 00:36:42,110 Training Epoch [11/40] Iter[101/312]		Loss: 0.1818
2019-10-29 00:36:42,231 Training Epoch [11/40] Iter[102/312]		Loss: 0.1816
2019-10-29 00:36:42,353 Training Epoch [11/40] Iter[103/312]		Loss: 0.1813
2019-10-29 00:36:42,474 Training Epoch [11/40] Iter[104/312]		Loss: 0.1809
2019-10-29 00:36:42,595 Training Epoch [11/40] Iter[105/312]		Loss: 0.1802
2019-10-29 00:36:42,716 Training Epoch [11/40] Iter[106/312]		Loss: 0.1805
2019-10-29 00:36:42,837 Training Epoch [11/40] Iter[107/312]		Loss: 0.1800
2019-10-29 00:36:42,959 Training Epoch [11/40] Iter[108/312]		Loss: 0.1799
2019-10-29 00:36:43,081 Training Epoch [11/40] Iter[109/312]		Loss: 0.1801
2019-10-29 00:36:43,202 Training Epoch [11/40] Iter[110/312]		Loss: 0.1799
2019-10-29 00:36:43,324 Training Epoch [11/40] Iter[111/312]		Loss: 0.1797
2019-10-29 00:36:43,445 Training Epoch [11/40] Iter[112/312]		Loss: 0.1797
2019-10-29 00:36:43,566 Training Epoch [11/40] Iter[113/312]		Loss: 0.1796
2019-10-29 00:36:43,688 Training Epoch [11/40] Iter[114/312]		Loss: 0.1794
2019-10-29 00:36:43,809 Training Epoch [11/40] Iter[115/312]		Loss: 0.1790
2019-10-29 00:36:43,930 Training Epoch [11/40] Iter[116/312]		Loss: 0.1790
2019-10-29 00:36:44,052 Training Epoch [11/40] Iter[117/312]		Loss: 0.1791
2019-10-29 00:36:44,173 Training Epoch [11/40] Iter[118/312]		Loss: 0.1790
2019-10-29 00:36:44,294 Training Epoch [11/40] Iter[119/312]		Loss: 0.1788
2019-10-29 00:36:44,416 Training Epoch [11/40] Iter[120/312]		Loss: 0.1785
2019-10-29 00:36:44,537 Training Epoch [11/40] Iter[121/312]		Loss: 0.1782
2019-10-29 00:36:44,658 Training Epoch [11/40] Iter[122/312]		Loss: 0.1784
2019-10-29 00:36:44,780 Training Epoch [11/40] Iter[123/312]		Loss: 0.1779
2019-10-29 00:36:44,901 Training Epoch [11/40] Iter[124/312]		Loss: 0.1781
2019-10-29 00:36:45,022 Training Epoch [11/40] Iter[125/312]		Loss: 0.1787
2019-10-29 00:36:45,144 Training Epoch [11/40] Iter[126/312]		Loss: 0.1784
2019-10-29 00:36:45,265 Training Epoch [11/40] Iter[127/312]		Loss: 0.1783
2019-10-29 00:36:45,387 Training Epoch [11/40] Iter[128/312]		Loss: 0.1783
2019-10-29 00:36:45,508 Training Epoch [11/40] Iter[129/312]		Loss: 0.1783
2019-10-29 00:36:45,629 Training Epoch [11/40] Iter[130/312]		Loss: 0.1782
2019-10-29 00:36:45,751 Training Epoch [11/40] Iter[131/312]		Loss: 0.1782
2019-10-29 00:36:45,872 Training Epoch [11/40] Iter[132/312]		Loss: 0.1787
2019-10-29 00:36:45,993 Training Epoch [11/40] Iter[133/312]		Loss: 0.1785
2019-10-29 00:36:46,114 Training Epoch [11/40] Iter[134/312]		Loss: 0.1786
2019-10-29 00:36:46,235 Training Epoch [11/40] Iter[135/312]		Loss: 0.1786
2019-10-29 00:36:46,356 Training Epoch [11/40] Iter[136/312]		Loss: 0.1783
2019-10-29 00:36:46,477 Training Epoch [11/40] Iter[137/312]		Loss: 0.1782
2019-10-29 00:36:46,598 Training Epoch [11/40] Iter[138/312]		Loss: 0.1781
2019-10-29 00:36:46,719 Training Epoch [11/40] Iter[139/312]		Loss: 0.1782
2019-10-29 00:36:46,840 Training Epoch [11/40] Iter[140/312]		Loss: 0.1784
2019-10-29 00:36:46,961 Training Epoch [11/40] Iter[141/312]		Loss: 0.1780
2019-10-29 00:36:47,082 Training Epoch [11/40] Iter[142/312]		Loss: 0.1779
2019-10-29 00:36:47,204 Training Epoch [11/40] Iter[143/312]		Loss: 0.1776
2019-10-29 00:36:47,324 Training Epoch [11/40] Iter[144/312]		Loss: 0.1774
2019-10-29 00:36:47,446 Training Epoch [11/40] Iter[145/312]		Loss: 0.1773
2019-10-29 00:36:47,567 Training Epoch [11/40] Iter[146/312]		Loss: 0.1773
2019-10-29 00:36:47,688 Training Epoch [11/40] Iter[147/312]		Loss: 0.1772
2019-10-29 00:36:47,809 Training Epoch [11/40] Iter[148/312]		Loss: 0.1770
2019-10-29 00:36:47,931 Training Epoch [11/40] Iter[149/312]		Loss: 0.1770
2019-10-29 00:36:48,052 Training Epoch [11/40] Iter[150/312]		Loss: 0.1767
2019-10-29 00:36:48,173 Training Epoch [11/40] Iter[151/312]		Loss: 0.1764
2019-10-29 00:36:48,295 Training Epoch [11/40] Iter[152/312]		Loss: 0.1761
2019-10-29 00:36:48,416 Training Epoch [11/40] Iter[153/312]		Loss: 0.1760
2019-10-29 00:36:48,538 Training Epoch [11/40] Iter[154/312]		Loss: 0.1759
2019-10-29 00:36:48,660 Training Epoch [11/40] Iter[155/312]		Loss: 0.1758
2019-10-29 00:36:48,781 Training Epoch [11/40] Iter[156/312]		Loss: 0.1760
2019-10-29 00:36:48,903 Training Epoch [11/40] Iter[157/312]		Loss: 0.1759
2019-10-29 00:36:49,025 Training Epoch [11/40] Iter[158/312]		Loss: 0.1762
2019-10-29 00:36:49,146 Training Epoch [11/40] Iter[159/312]		Loss: 0.1760
2019-10-29 00:36:49,268 Training Epoch [11/40] Iter[160/312]		Loss: 0.1758
2019-10-29 00:36:49,396 Training Epoch [11/40] Iter[161/312]		Loss: 0.1756
2019-10-29 00:36:49,517 Training Epoch [11/40] Iter[162/312]		Loss: 0.1755
2019-10-29 00:36:49,638 Training Epoch [11/40] Iter[163/312]		Loss: 0.1753
2019-10-29 00:36:49,759 Training Epoch [11/40] Iter[164/312]		Loss: 0.1754
2019-10-29 00:36:49,880 Training Epoch [11/40] Iter[165/312]		Loss: 0.1750
2019-10-29 00:36:50,001 Training Epoch [11/40] Iter[166/312]		Loss: 0.1751
2019-10-29 00:36:50,122 Training Epoch [11/40] Iter[167/312]		Loss: 0.1750
2019-10-29 00:36:50,243 Training Epoch [11/40] Iter[168/312]		Loss: 0.1757
2019-10-29 00:36:50,365 Training Epoch [11/40] Iter[169/312]		Loss: 0.1757
2019-10-29 00:36:50,486 Training Epoch [11/40] Iter[170/312]		Loss: 0.1757
2019-10-29 00:36:50,606 Training Epoch [11/40] Iter[171/312]		Loss: 0.1756
2019-10-29 00:36:50,728 Training Epoch [11/40] Iter[172/312]		Loss: 0.1754
2019-10-29 00:36:50,849 Training Epoch [11/40] Iter[173/312]		Loss: 0.1754
2019-10-29 00:36:50,970 Training Epoch [11/40] Iter[174/312]		Loss: 0.1749
2019-10-29 00:36:51,092 Training Epoch [11/40] Iter[175/312]		Loss: 0.1748
2019-10-29 00:36:51,213 Training Epoch [11/40] Iter[176/312]		Loss: 0.1749
2019-10-29 00:36:51,335 Training Epoch [11/40] Iter[177/312]		Loss: 0.1755
2019-10-29 00:36:51,456 Training Epoch [11/40] Iter[178/312]		Loss: 0.1754
2019-10-29 00:36:51,578 Training Epoch [11/40] Iter[179/312]		Loss: 0.1751
2019-10-29 00:36:51,699 Training Epoch [11/40] Iter[180/312]		Loss: 0.1748
2019-10-29 00:36:51,820 Training Epoch [11/40] Iter[181/312]		Loss: 0.1747
2019-10-29 00:36:51,942 Training Epoch [11/40] Iter[182/312]		Loss: 0.1744
2019-10-29 00:36:52,063 Training Epoch [11/40] Iter[183/312]		Loss: 0.1740
2019-10-29 00:36:52,185 Training Epoch [11/40] Iter[184/312]		Loss: 0.1742
2019-10-29 00:36:52,306 Training Epoch [11/40] Iter[185/312]		Loss: 0.1745
2019-10-29 00:36:52,428 Training Epoch [11/40] Iter[186/312]		Loss: 0.1743
2019-10-29 00:36:52,550 Training Epoch [11/40] Iter[187/312]		Loss: 0.1744
2019-10-29 00:36:52,671 Training Epoch [11/40] Iter[188/312]		Loss: 0.1744
2019-10-29 00:36:52,792 Training Epoch [11/40] Iter[189/312]		Loss: 0.1742
2019-10-29 00:36:52,913 Training Epoch [11/40] Iter[190/312]		Loss: 0.1741
2019-10-29 00:36:53,034 Training Epoch [11/40] Iter[191/312]		Loss: 0.1742
2019-10-29 00:36:53,156 Training Epoch [11/40] Iter[192/312]		Loss: 0.1739
2019-10-29 00:36:53,277 Training Epoch [11/40] Iter[193/312]		Loss: 0.1739
2019-10-29 00:36:53,400 Training Epoch [11/40] Iter[194/312]		Loss: 0.1741
2019-10-29 00:36:53,521 Training Epoch [11/40] Iter[195/312]		Loss: 0.1744
2019-10-29 00:36:53,642 Training Epoch [11/40] Iter[196/312]		Loss: 0.1743
2019-10-29 00:36:53,764 Training Epoch [11/40] Iter[197/312]		Loss: 0.1744
2019-10-29 00:36:53,885 Training Epoch [11/40] Iter[198/312]		Loss: 0.1746
2019-10-29 00:36:54,006 Training Epoch [11/40] Iter[199/312]		Loss: 0.1747
2019-10-29 00:36:54,127 Training Epoch [11/40] Iter[200/312]		Loss: 0.1745
2019-10-29 00:36:54,249 Training Epoch [11/40] Iter[201/312]		Loss: 0.1743
2019-10-29 00:36:54,370 Training Epoch [11/40] Iter[202/312]		Loss: 0.1740
2019-10-29 00:36:54,492 Training Epoch [11/40] Iter[203/312]		Loss: 0.1740
2019-10-29 00:36:54,613 Training Epoch [11/40] Iter[204/312]		Loss: 0.1742
2019-10-29 00:36:54,735 Training Epoch [11/40] Iter[205/312]		Loss: 0.1739
2019-10-29 00:36:54,856 Training Epoch [11/40] Iter[206/312]		Loss: 0.1738
2019-10-29 00:36:54,977 Training Epoch [11/40] Iter[207/312]		Loss: 0.1736
2019-10-29 00:36:55,098 Training Epoch [11/40] Iter[208/312]		Loss: 0.1734
2019-10-29 00:36:55,219 Training Epoch [11/40] Iter[209/312]		Loss: 0.1734
2019-10-29 00:36:55,340 Training Epoch [11/40] Iter[210/312]		Loss: 0.1731
2019-10-29 00:36:55,462 Training Epoch [11/40] Iter[211/312]		Loss: 0.1729
2019-10-29 00:36:55,583 Training Epoch [11/40] Iter[212/312]		Loss: 0.1728
2019-10-29 00:36:55,704 Training Epoch [11/40] Iter[213/312]		Loss: 0.1729
2019-10-29 00:36:55,825 Training Epoch [11/40] Iter[214/312]		Loss: 0.1726
2019-10-29 00:36:55,946 Training Epoch [11/40] Iter[215/312]		Loss: 0.1723
2019-10-29 00:36:56,067 Training Epoch [11/40] Iter[216/312]		Loss: 0.1727
2019-10-29 00:36:56,188 Training Epoch [11/40] Iter[217/312]		Loss: 0.1729
2019-10-29 00:36:56,310 Training Epoch [11/40] Iter[218/312]		Loss: 0.1727
2019-10-29 00:36:56,431 Training Epoch [11/40] Iter[219/312]		Loss: 0.1727
2019-10-29 00:36:56,553 Training Epoch [11/40] Iter[220/312]		Loss: 0.1730
2019-10-29 00:36:56,674 Training Epoch [11/40] Iter[221/312]		Loss: 0.1729
2019-10-29 00:36:56,796 Training Epoch [11/40] Iter[222/312]		Loss: 0.1726
2019-10-29 00:36:56,918 Training Epoch [11/40] Iter[223/312]		Loss: 0.1724
2019-10-29 00:36:57,039 Training Epoch [11/40] Iter[224/312]		Loss: 0.1724
2019-10-29 00:36:57,161 Training Epoch [11/40] Iter[225/312]		Loss: 0.1723
2019-10-29 00:36:57,283 Training Epoch [11/40] Iter[226/312]		Loss: 0.1724
2019-10-29 00:36:57,405 Training Epoch [11/40] Iter[227/312]		Loss: 0.1724
2019-10-29 00:36:57,527 Training Epoch [11/40] Iter[228/312]		Loss: 0.1721
2019-10-29 00:36:57,649 Training Epoch [11/40] Iter[229/312]		Loss: 0.1721
2019-10-29 00:36:57,771 Training Epoch [11/40] Iter[230/312]		Loss: 0.1719
2019-10-29 00:36:57,893 Training Epoch [11/40] Iter[231/312]		Loss: 0.1716
2019-10-29 00:36:58,014 Training Epoch [11/40] Iter[232/312]		Loss: 0.1717
2019-10-29 00:36:58,135 Training Epoch [11/40] Iter[233/312]		Loss: 0.1718
2019-10-29 00:36:58,257 Training Epoch [11/40] Iter[234/312]		Loss: 0.1721
2019-10-29 00:36:58,379 Training Epoch [11/40] Iter[235/312]		Loss: 0.1720
2019-10-29 00:36:58,500 Training Epoch [11/40] Iter[236/312]		Loss: 0.1721
2019-10-29 00:36:58,622 Training Epoch [11/40] Iter[237/312]		Loss: 0.1720
2019-10-29 00:36:58,744 Training Epoch [11/40] Iter[238/312]		Loss: 0.1719
2019-10-29 00:36:58,865 Training Epoch [11/40] Iter[239/312]		Loss: 0.1716
2019-10-29 00:36:58,987 Training Epoch [11/40] Iter[240/312]		Loss: 0.1715
2019-10-29 00:36:59,109 Training Epoch [11/40] Iter[241/312]		Loss: 0.1714
2019-10-29 00:36:59,230 Training Epoch [11/40] Iter[242/312]		Loss: 0.1711
2019-10-29 00:36:59,352 Training Epoch [11/40] Iter[243/312]		Loss: 0.1711
2019-10-29 00:36:59,473 Training Epoch [11/40] Iter[244/312]		Loss: 0.1713
2019-10-29 00:36:59,595 Training Epoch [11/40] Iter[245/312]		Loss: 0.1713
2019-10-29 00:36:59,717 Training Epoch [11/40] Iter[246/312]		Loss: 0.1711
2019-10-29 00:36:59,839 Training Epoch [11/40] Iter[247/312]		Loss: 0.1709
2019-10-29 00:36:59,960 Training Epoch [11/40] Iter[248/312]		Loss: 0.1711
2019-10-29 00:37:00,082 Training Epoch [11/40] Iter[249/312]		Loss: 0.1710
2019-10-29 00:37:00,204 Training Epoch [11/40] Iter[250/312]		Loss: 0.1708
2019-10-29 00:37:00,326 Training Epoch [11/40] Iter[251/312]		Loss: 0.1706
2019-10-29 00:37:00,447 Training Epoch [11/40] Iter[252/312]		Loss: 0.1705
2019-10-29 00:37:00,570 Training Epoch [11/40] Iter[253/312]		Loss: 0.1703
2019-10-29 00:37:00,692 Training Epoch [11/40] Iter[254/312]		Loss: 0.1705
2019-10-29 00:37:00,814 Training Epoch [11/40] Iter[255/312]		Loss: 0.1707
2019-10-29 00:37:00,936 Training Epoch [11/40] Iter[256/312]		Loss: 0.1705
2019-10-29 00:37:01,057 Training Epoch [11/40] Iter[257/312]		Loss: 0.1704
2019-10-29 00:37:01,179 Training Epoch [11/40] Iter[258/312]		Loss: 0.1704
2019-10-29 00:37:01,301 Training Epoch [11/40] Iter[259/312]		Loss: 0.1705
2019-10-29 00:37:01,423 Training Epoch [11/40] Iter[260/312]		Loss: 0.1706
2019-10-29 00:37:01,545 Training Epoch [11/40] Iter[261/312]		Loss: 0.1707
2019-10-29 00:37:01,666 Training Epoch [11/40] Iter[262/312]		Loss: 0.1709
2019-10-29 00:37:01,788 Training Epoch [11/40] Iter[263/312]		Loss: 0.1709
2019-10-29 00:37:01,909 Training Epoch [11/40] Iter[264/312]		Loss: 0.1709
2019-10-29 00:37:02,031 Training Epoch [11/40] Iter[265/312]		Loss: 0.1707
2019-10-29 00:37:02,153 Training Epoch [11/40] Iter[266/312]		Loss: 0.1705
2019-10-29 00:37:02,275 Training Epoch [11/40] Iter[267/312]		Loss: 0.1706
2019-10-29 00:37:02,396 Training Epoch [11/40] Iter[268/312]		Loss: 0.1704
2019-10-29 00:37:02,518 Training Epoch [11/40] Iter[269/312]		Loss: 0.1706
2019-10-29 00:37:02,639 Training Epoch [11/40] Iter[270/312]		Loss: 0.1705
2019-10-29 00:37:02,761 Training Epoch [11/40] Iter[271/312]		Loss: 0.1704
2019-10-29 00:37:02,882 Training Epoch [11/40] Iter[272/312]		Loss: 0.1702
2019-10-29 00:37:03,003 Training Epoch [11/40] Iter[273/312]		Loss: 0.1704
2019-10-29 00:37:03,125 Training Epoch [11/40] Iter[274/312]		Loss: 0.1703
2019-10-29 00:37:03,247 Training Epoch [11/40] Iter[275/312]		Loss: 0.1702
2019-10-29 00:37:03,368 Training Epoch [11/40] Iter[276/312]		Loss: 0.1705
2019-10-29 00:37:03,490 Training Epoch [11/40] Iter[277/312]		Loss: 0.1705
2019-10-29 00:37:03,611 Training Epoch [11/40] Iter[278/312]		Loss: 0.1703
2019-10-29 00:37:03,733 Training Epoch [11/40] Iter[279/312]		Loss: 0.1702
2019-10-29 00:37:03,854 Training Epoch [11/40] Iter[280/312]		Loss: 0.1700
2019-10-29 00:37:03,975 Training Epoch [11/40] Iter[281/312]		Loss: 0.1700
2019-10-29 00:37:04,096 Training Epoch [11/40] Iter[282/312]		Loss: 0.1701
2019-10-29 00:37:04,216 Training Epoch [11/40] Iter[283/312]		Loss: 0.1701
2019-10-29 00:37:04,337 Training Epoch [11/40] Iter[284/312]		Loss: 0.1701
2019-10-29 00:37:04,459 Training Epoch [11/40] Iter[285/312]		Loss: 0.1703
2019-10-29 00:37:04,580 Training Epoch [11/40] Iter[286/312]		Loss: 0.1700
2019-10-29 00:37:04,702 Training Epoch [11/40] Iter[287/312]		Loss: 0.1699
2019-10-29 00:37:04,823 Training Epoch [11/40] Iter[288/312]		Loss: 0.1696
2019-10-29 00:37:04,945 Training Epoch [11/40] Iter[289/312]		Loss: 0.1697
2019-10-29 00:37:05,066 Training Epoch [11/40] Iter[290/312]		Loss: 0.1696
2019-10-29 00:37:05,188 Training Epoch [11/40] Iter[291/312]		Loss: 0.1695
2019-10-29 00:37:05,309 Training Epoch [11/40] Iter[292/312]		Loss: 0.1697
2019-10-29 00:37:05,431 Training Epoch [11/40] Iter[293/312]		Loss: 0.1697
2019-10-29 00:37:05,553 Training Epoch [11/40] Iter[294/312]		Loss: 0.1696
2019-10-29 00:37:05,674 Training Epoch [11/40] Iter[295/312]		Loss: 0.1696
2019-10-29 00:37:05,796 Training Epoch [11/40] Iter[296/312]		Loss: 0.1695
2019-10-29 00:37:05,918 Training Epoch [11/40] Iter[297/312]		Loss: 0.1696
2019-10-29 00:37:06,040 Training Epoch [11/40] Iter[298/312]		Loss: 0.1693
2019-10-29 00:37:06,162 Training Epoch [11/40] Iter[299/312]		Loss: 0.1694
2019-10-29 00:37:06,283 Training Epoch [11/40] Iter[300/312]		Loss: 0.1694
2019-10-29 00:37:06,404 Training Epoch [11/40] Iter[301/312]		Loss: 0.1694
2019-10-29 00:37:06,525 Training Epoch [11/40] Iter[302/312]		Loss: 0.1693
2019-10-29 00:37:06,647 Training Epoch [11/40] Iter[303/312]		Loss: 0.1692
2019-10-29 00:37:06,768 Training Epoch [11/40] Iter[304/312]		Loss: 0.1690
2019-10-29 00:37:06,889 Training Epoch [11/40] Iter[305/312]		Loss: 0.1692
2019-10-29 00:37:07,010 Training Epoch [11/40] Iter[306/312]		Loss: 0.1690
2019-10-29 00:37:07,130 Training Epoch [11/40] Iter[307/312]		Loss: 0.1693
2019-10-29 00:37:07,251 Training Epoch [11/40] Iter[308/312]		Loss: 0.1691
2019-10-29 00:37:07,372 Training Epoch [11/40] Iter[309/312]		Loss: 0.1690
2019-10-29 00:37:07,493 Training Epoch [11/40] Iter[310/312]		Loss: 0.1691
2019-10-29 00:37:07,613 Training Epoch [11/40] Iter[311/312]		Loss: 0.1694
2019-10-29 00:37:07,673 Training Epoch [11/40] Iter[312/312]		Loss: 0.1695
2019-10-29 00:37:08,058 Testing Epoch [11/40] Iter[0/62]		Loss: 0.1241
2019-10-29 00:37:08,098 Testing Epoch [11/40] Iter[1/62]		Loss: 0.1429
2019-10-29 00:37:08,129 Testing Epoch [11/40] Iter[2/62]		Loss: 0.1432
2019-10-29 00:37:08,166 Testing Epoch [11/40] Iter[3/62]		Loss: 0.1504
2019-10-29 00:37:08,196 Testing Epoch [11/40] Iter[4/62]		Loss: 0.1454
2019-10-29 00:37:08,230 Testing Epoch [11/40] Iter[5/62]		Loss: 0.1432
2019-10-29 00:37:08,260 Testing Epoch [11/40] Iter[6/62]		Loss: 0.1482
2019-10-29 00:37:08,292 Testing Epoch [11/40] Iter[7/62]		Loss: 0.1577
2019-10-29 00:37:08,326 Testing Epoch [11/40] Iter[8/62]		Loss: 0.1663
2019-10-29 00:37:08,357 Testing Epoch [11/40] Iter[9/62]		Loss: 0.1629
2019-10-29 00:37:08,388 Testing Epoch [11/40] Iter[10/62]		Loss: 0.1616
2019-10-29 00:37:08,422 Testing Epoch [11/40] Iter[11/62]		Loss: 0.1679
2019-10-29 00:37:08,453 Testing Epoch [11/40] Iter[12/62]		Loss: 0.1689
2019-10-29 00:37:08,483 Testing Epoch [11/40] Iter[13/62]		Loss: 0.1722
2019-10-29 00:37:08,518 Testing Epoch [11/40] Iter[14/62]		Loss: 0.1866
2019-10-29 00:37:08,548 Testing Epoch [11/40] Iter[15/62]		Loss: 0.1901
2019-10-29 00:37:08,579 Testing Epoch [11/40] Iter[16/62]		Loss: 0.1883
2019-10-29 00:37:08,610 Testing Epoch [11/40] Iter[17/62]		Loss: 0.1871
2019-10-29 00:37:08,640 Testing Epoch [11/40] Iter[18/62]		Loss: 0.1838
2019-10-29 00:37:08,671 Testing Epoch [11/40] Iter[19/62]		Loss: 0.1812
2019-10-29 00:37:08,702 Testing Epoch [11/40] Iter[20/62]		Loss: 0.1814
2019-10-29 00:37:08,733 Testing Epoch [11/40] Iter[21/62]		Loss: 0.1793
2019-10-29 00:37:08,764 Testing Epoch [11/40] Iter[22/62]		Loss: 0.1793
2019-10-29 00:37:08,794 Testing Epoch [11/40] Iter[23/62]		Loss: 0.1773
2019-10-29 00:37:08,825 Testing Epoch [11/40] Iter[24/62]		Loss: 0.1802
2019-10-29 00:37:08,856 Testing Epoch [11/40] Iter[25/62]		Loss: 0.1791
2019-10-29 00:37:08,887 Testing Epoch [11/40] Iter[26/62]		Loss: 0.1779
2019-10-29 00:37:08,917 Testing Epoch [11/40] Iter[27/62]		Loss: 0.1845
2019-10-29 00:37:08,948 Testing Epoch [11/40] Iter[28/62]		Loss: 0.1867
2019-10-29 00:37:08,979 Testing Epoch [11/40] Iter[29/62]		Loss: 0.1867
2019-10-29 00:37:09,010 Testing Epoch [11/40] Iter[30/62]		Loss: 0.1878
2019-10-29 00:37:09,041 Testing Epoch [11/40] Iter[31/62]		Loss: 0.1873
2019-10-29 00:37:09,073 Testing Epoch [11/40] Iter[32/62]		Loss: 0.1893
2019-10-29 00:37:09,104 Testing Epoch [11/40] Iter[33/62]		Loss: 0.1880
2019-10-29 00:37:09,135 Testing Epoch [11/40] Iter[34/62]		Loss: 0.1895
2019-10-29 00:37:09,166 Testing Epoch [11/40] Iter[35/62]		Loss: 0.1894
2019-10-29 00:37:09,197 Testing Epoch [11/40] Iter[36/62]		Loss: 0.1881
2019-10-29 00:37:09,228 Testing Epoch [11/40] Iter[37/62]		Loss: 0.1880
2019-10-29 00:37:09,258 Testing Epoch [11/40] Iter[38/62]		Loss: 0.1878
2019-10-29 00:37:09,289 Testing Epoch [11/40] Iter[39/62]		Loss: 0.1876
2019-10-29 00:37:09,320 Testing Epoch [11/40] Iter[40/62]		Loss: 0.1882
2019-10-29 00:37:09,352 Testing Epoch [11/40] Iter[41/62]		Loss: 0.1887
2019-10-29 00:37:09,383 Testing Epoch [11/40] Iter[42/62]		Loss: 0.1868
2019-10-29 00:37:09,413 Testing Epoch [11/40] Iter[43/62]		Loss: 0.1863
2019-10-29 00:37:09,444 Testing Epoch [11/40] Iter[44/62]		Loss: 0.1846
2019-10-29 00:37:09,475 Testing Epoch [11/40] Iter[45/62]		Loss: 0.1850
2019-10-29 00:37:09,506 Testing Epoch [11/40] Iter[46/62]		Loss: 0.1851
2019-10-29 00:37:09,537 Testing Epoch [11/40] Iter[47/62]		Loss: 0.1905
2019-10-29 00:37:09,568 Testing Epoch [11/40] Iter[48/62]		Loss: 0.1896
2019-10-29 00:37:09,598 Testing Epoch [11/40] Iter[49/62]		Loss: 0.1906
2019-10-29 00:37:09,629 Testing Epoch [11/40] Iter[50/62]		Loss: 0.1900
2019-10-29 00:37:09,660 Testing Epoch [11/40] Iter[51/62]		Loss: 0.1898
2019-10-29 00:37:09,691 Testing Epoch [11/40] Iter[52/62]		Loss: 0.1880
2019-10-29 00:37:09,722 Testing Epoch [11/40] Iter[53/62]		Loss: 0.1880
2019-10-29 00:37:09,753 Testing Epoch [11/40] Iter[54/62]		Loss: 0.1869
2019-10-29 00:37:09,783 Testing Epoch [11/40] Iter[55/62]		Loss: 0.1872
2019-10-29 00:37:09,814 Testing Epoch [11/40] Iter[56/62]		Loss: 0.1867
2019-10-29 00:37:09,844 Testing Epoch [11/40] Iter[57/62]		Loss: 0.1863
2019-10-29 00:37:09,874 Testing Epoch [11/40] Iter[58/62]		Loss: 0.1856
2019-10-29 00:37:09,905 Testing Epoch [11/40] Iter[59/62]		Loss: 0.1860
2019-10-29 00:37:09,935 Testing Epoch [11/40] Iter[60/62]		Loss: 0.1856
2019-10-29 00:37:09,966 Testing Epoch [11/40] Iter[61/62]		Loss: 0.1853
2019-10-29 00:37:09,983 Testing Epoch [11/40] Iter[62/62]		Loss: 0.1861
2019-10-29 00:37:10,046 Saving the Model
2019-10-29 00:37:10,469 Training Epoch [12/40] Iter[0/312]		Loss: 0.0819
2019-10-29 00:37:10,592 Training Epoch [12/40] Iter[1/312]		Loss: 0.0974
2019-10-29 00:37:10,712 Training Epoch [12/40] Iter[2/312]		Loss: 0.1159
2019-10-29 00:37:10,835 Training Epoch [12/40] Iter[3/312]		Loss: 0.1250
2019-10-29 00:37:10,957 Training Epoch [12/40] Iter[4/312]		Loss: 0.1424
2019-10-29 00:37:11,078 Training Epoch [12/40] Iter[5/312]		Loss: 0.1409
2019-10-29 00:37:11,198 Training Epoch [12/40] Iter[6/312]		Loss: 0.1509
2019-10-29 00:37:11,319 Training Epoch [12/40] Iter[7/312]		Loss: 0.1594
2019-10-29 00:37:11,441 Training Epoch [12/40] Iter[8/312]		Loss: 0.1604
2019-10-29 00:37:11,562 Training Epoch [12/40] Iter[9/312]		Loss: 0.1586
2019-10-29 00:37:11,684 Training Epoch [12/40] Iter[10/312]		Loss: 0.1552
2019-10-29 00:37:11,805 Training Epoch [12/40] Iter[11/312]		Loss: 0.1546
2019-10-29 00:37:11,926 Training Epoch [12/40] Iter[12/312]		Loss: 0.1622
2019-10-29 00:37:12,047 Training Epoch [12/40] Iter[13/312]		Loss: 0.1644
2019-10-29 00:37:12,168 Training Epoch [12/40] Iter[14/312]		Loss: 0.1633
2019-10-29 00:37:12,289 Training Epoch [12/40] Iter[15/312]		Loss: 0.1641
2019-10-29 00:37:12,410 Training Epoch [12/40] Iter[16/312]		Loss: 0.1608
2019-10-29 00:37:12,531 Training Epoch [12/40] Iter[17/312]		Loss: 0.1592
2019-10-29 00:37:12,652 Training Epoch [12/40] Iter[18/312]		Loss: 0.1593
2019-10-29 00:37:12,774 Training Epoch [12/40] Iter[19/312]		Loss: 0.1595
2019-10-29 00:37:12,895 Training Epoch [12/40] Iter[20/312]		Loss: 0.1591
2019-10-29 00:37:13,016 Training Epoch [12/40] Iter[21/312]		Loss: 0.1566
2019-10-29 00:37:13,137 Training Epoch [12/40] Iter[22/312]		Loss: 0.1569
2019-10-29 00:37:13,259 Training Epoch [12/40] Iter[23/312]		Loss: 0.1537
2019-10-29 00:37:13,381 Training Epoch [12/40] Iter[24/312]		Loss: 0.1526
2019-10-29 00:37:13,502 Training Epoch [12/40] Iter[25/312]		Loss: 0.1525
2019-10-29 00:37:13,623 Training Epoch [12/40] Iter[26/312]		Loss: 0.1537
2019-10-29 00:37:13,745 Training Epoch [12/40] Iter[27/312]		Loss: 0.1522
2019-10-29 00:37:13,867 Training Epoch [12/40] Iter[28/312]		Loss: 0.1554
2019-10-29 00:37:13,988 Training Epoch [12/40] Iter[29/312]		Loss: 0.1555
2019-10-29 00:37:14,110 Training Epoch [12/40] Iter[30/312]		Loss: 0.1573
2019-10-29 00:37:14,232 Training Epoch [12/40] Iter[31/312]		Loss: 0.1567
2019-10-29 00:37:14,353 Training Epoch [12/40] Iter[32/312]		Loss: 0.1561
2019-10-29 00:37:14,475 Training Epoch [12/40] Iter[33/312]		Loss: 0.1556
2019-10-29 00:37:14,596 Training Epoch [12/40] Iter[34/312]		Loss: 0.1548
2019-10-29 00:37:14,717 Training Epoch [12/40] Iter[35/312]		Loss: 0.1537
2019-10-29 00:37:14,838 Training Epoch [12/40] Iter[36/312]		Loss: 0.1534
2019-10-29 00:37:14,959 Training Epoch [12/40] Iter[37/312]		Loss: 0.1541
2019-10-29 00:37:15,080 Training Epoch [12/40] Iter[38/312]		Loss: 0.1531
2019-10-29 00:37:15,201 Training Epoch [12/40] Iter[39/312]		Loss: 0.1524
2019-10-29 00:37:15,322 Training Epoch [12/40] Iter[40/312]		Loss: 0.1524
2019-10-29 00:37:15,443 Training Epoch [12/40] Iter[41/312]		Loss: 0.1528
2019-10-29 00:37:15,564 Training Epoch [12/40] Iter[42/312]		Loss: 0.1540
2019-10-29 00:37:15,685 Training Epoch [12/40] Iter[43/312]		Loss: 0.1544
2019-10-29 00:37:15,806 Training Epoch [12/40] Iter[44/312]		Loss: 0.1537
2019-10-29 00:37:15,927 Training Epoch [12/40] Iter[45/312]		Loss: 0.1542
2019-10-29 00:37:16,049 Training Epoch [12/40] Iter[46/312]		Loss: 0.1547
2019-10-29 00:37:16,171 Training Epoch [12/40] Iter[47/312]		Loss: 0.1545
2019-10-29 00:37:16,293 Training Epoch [12/40] Iter[48/312]		Loss: 0.1544
2019-10-29 00:37:16,414 Training Epoch [12/40] Iter[49/312]		Loss: 0.1537
2019-10-29 00:37:16,536 Training Epoch [12/40] Iter[50/312]		Loss: 0.1535
2019-10-29 00:37:16,658 Training Epoch [12/40] Iter[51/312]		Loss: 0.1541
2019-10-29 00:37:16,779 Training Epoch [12/40] Iter[52/312]		Loss: 0.1553
2019-10-29 00:37:16,901 Training Epoch [12/40] Iter[53/312]		Loss: 0.1561
2019-10-29 00:37:17,022 Training Epoch [12/40] Iter[54/312]		Loss: 0.1569
2019-10-29 00:37:17,143 Training Epoch [12/40] Iter[55/312]		Loss: 0.1567
2019-10-29 00:37:17,265 Training Epoch [12/40] Iter[56/312]		Loss: 0.1561
2019-10-29 00:37:17,386 Training Epoch [12/40] Iter[57/312]		Loss: 0.1554
2019-10-29 00:37:17,508 Training Epoch [12/40] Iter[58/312]		Loss: 0.1556
2019-10-29 00:37:17,630 Training Epoch [12/40] Iter[59/312]		Loss: 0.1552
2019-10-29 00:37:17,751 Training Epoch [12/40] Iter[60/312]		Loss: 0.1562
2019-10-29 00:37:17,872 Training Epoch [12/40] Iter[61/312]		Loss: 0.1561
2019-10-29 00:37:17,994 Training Epoch [12/40] Iter[62/312]		Loss: 0.1556
2019-10-29 00:37:18,120 Training Epoch [12/40] Iter[63/312]		Loss: 0.1555
2019-10-29 00:37:18,242 Training Epoch [12/40] Iter[64/312]		Loss: 0.1551
2019-10-29 00:37:18,363 Training Epoch [12/40] Iter[65/312]		Loss: 0.1549
2019-10-29 00:37:18,485 Training Epoch [12/40] Iter[66/312]		Loss: 0.1551
2019-10-29 00:37:18,606 Training Epoch [12/40] Iter[67/312]		Loss: 0.1546
2019-10-29 00:37:18,728 Training Epoch [12/40] Iter[68/312]		Loss: 0.1554
2019-10-29 00:37:18,849 Training Epoch [12/40] Iter[69/312]		Loss: 0.1549
2019-10-29 00:37:18,970 Training Epoch [12/40] Iter[70/312]		Loss: 0.1549
2019-10-29 00:37:19,092 Training Epoch [12/40] Iter[71/312]		Loss: 0.1546
2019-10-29 00:37:19,213 Training Epoch [12/40] Iter[72/312]		Loss: 0.1546
2019-10-29 00:37:19,335 Training Epoch [12/40] Iter[73/312]		Loss: 0.1554
2019-10-29 00:37:19,457 Training Epoch [12/40] Iter[74/312]		Loss: 0.1548
2019-10-29 00:37:19,578 Training Epoch [12/40] Iter[75/312]		Loss: 0.1547
2019-10-29 00:37:19,699 Training Epoch [12/40] Iter[76/312]		Loss: 0.1544
2019-10-29 00:37:19,821 Training Epoch [12/40] Iter[77/312]		Loss: 0.1538
2019-10-29 00:37:19,942 Training Epoch [12/40] Iter[78/312]		Loss: 0.1538
2019-10-29 00:37:20,063 Training Epoch [12/40] Iter[79/312]		Loss: 0.1532
2019-10-29 00:37:20,184 Training Epoch [12/40] Iter[80/312]		Loss: 0.1537
2019-10-29 00:37:20,305 Training Epoch [12/40] Iter[81/312]		Loss: 0.1538
2019-10-29 00:37:20,427 Training Epoch [12/40] Iter[82/312]		Loss: 0.1533
2019-10-29 00:37:20,553 Training Epoch [12/40] Iter[83/312]		Loss: 0.1532
2019-10-29 00:37:20,674 Training Epoch [12/40] Iter[84/312]		Loss: 0.1537
2019-10-29 00:37:20,795 Training Epoch [12/40] Iter[85/312]		Loss: 0.1536
2019-10-29 00:37:20,916 Training Epoch [12/40] Iter[86/312]		Loss: 0.1536
2019-10-29 00:37:21,037 Training Epoch [12/40] Iter[87/312]		Loss: 0.1533
2019-10-29 00:37:21,160 Training Epoch [12/40] Iter[88/312]		Loss: 0.1539
2019-10-29 00:37:21,281 Training Epoch [12/40] Iter[89/312]		Loss: 0.1536
2019-10-29 00:37:21,403 Training Epoch [12/40] Iter[90/312]		Loss: 0.1534
2019-10-29 00:37:21,525 Training Epoch [12/40] Iter[91/312]		Loss: 0.1531
2019-10-29 00:37:21,647 Training Epoch [12/40] Iter[92/312]		Loss: 0.1528
2019-10-29 00:37:21,773 Training Epoch [12/40] Iter[93/312]		Loss: 0.1524
2019-10-29 00:37:21,894 Training Epoch [12/40] Iter[94/312]		Loss: 0.1525
2019-10-29 00:37:22,016 Training Epoch [12/40] Iter[95/312]		Loss: 0.1520
2019-10-29 00:37:22,137 Training Epoch [12/40] Iter[96/312]		Loss: 0.1519
2019-10-29 00:37:22,259 Training Epoch [12/40] Iter[97/312]		Loss: 0.1521
2019-10-29 00:37:22,381 Training Epoch [12/40] Iter[98/312]		Loss: 0.1524
2019-10-29 00:37:22,502 Training Epoch [12/40] Iter[99/312]		Loss: 0.1529
2019-10-29 00:37:22,624 Training Epoch [12/40] Iter[100/312]		Loss: 0.1528
2019-10-29 00:37:22,746 Training Epoch [12/40] Iter[101/312]		Loss: 0.1530
2019-10-29 00:37:22,868 Training Epoch [12/40] Iter[102/312]		Loss: 0.1538
2019-10-29 00:37:22,989 Training Epoch [12/40] Iter[103/312]		Loss: 0.1540
2019-10-29 00:37:23,110 Training Epoch [12/40] Iter[104/312]		Loss: 0.1539
2019-10-29 00:37:23,232 Training Epoch [12/40] Iter[105/312]		Loss: 0.1539
2019-10-29 00:37:23,353 Training Epoch [12/40] Iter[106/312]		Loss: 0.1534
2019-10-29 00:37:23,475 Training Epoch [12/40] Iter[107/312]		Loss: 0.1540
2019-10-29 00:37:23,596 Training Epoch [12/40] Iter[108/312]		Loss: 0.1539
2019-10-29 00:37:23,717 Training Epoch [12/40] Iter[109/312]		Loss: 0.1535
2019-10-29 00:37:23,838 Training Epoch [12/40] Iter[110/312]		Loss: 0.1535
2019-10-29 00:37:23,959 Training Epoch [12/40] Iter[111/312]		Loss: 0.1532
2019-10-29 00:37:24,080 Training Epoch [12/40] Iter[112/312]		Loss: 0.1533
2019-10-29 00:37:24,202 Training Epoch [12/40] Iter[113/312]		Loss: 0.1532
2019-10-29 00:37:24,323 Training Epoch [12/40] Iter[114/312]		Loss: 0.1528
2019-10-29 00:37:24,445 Training Epoch [12/40] Iter[115/312]		Loss: 0.1526
2019-10-29 00:37:24,567 Training Epoch [12/40] Iter[116/312]		Loss: 0.1522
2019-10-29 00:37:24,689 Training Epoch [12/40] Iter[117/312]		Loss: 0.1524
2019-10-29 00:37:24,810 Training Epoch [12/40] Iter[118/312]		Loss: 0.1528
2019-10-29 00:37:24,932 Training Epoch [12/40] Iter[119/312]		Loss: 0.1534
2019-10-29 00:37:25,054 Training Epoch [12/40] Iter[120/312]		Loss: 0.1537
2019-10-29 00:37:25,175 Training Epoch [12/40] Iter[121/312]		Loss: 0.1533
2019-10-29 00:37:25,296 Training Epoch [12/40] Iter[122/312]		Loss: 0.1529
2019-10-29 00:37:25,417 Training Epoch [12/40] Iter[123/312]		Loss: 0.1531
2019-10-29 00:37:25,539 Training Epoch [12/40] Iter[124/312]		Loss: 0.1530
2019-10-29 00:37:25,660 Training Epoch [12/40] Iter[125/312]		Loss: 0.1530
2019-10-29 00:37:25,782 Training Epoch [12/40] Iter[126/312]		Loss: 0.1529
2019-10-29 00:37:25,904 Training Epoch [12/40] Iter[127/312]		Loss: 0.1531
2019-10-29 00:37:26,026 Training Epoch [12/40] Iter[128/312]		Loss: 0.1531
2019-10-29 00:37:26,148 Training Epoch [12/40] Iter[129/312]		Loss: 0.1531
2019-10-29 00:37:26,269 Training Epoch [12/40] Iter[130/312]		Loss: 0.1530
2019-10-29 00:37:26,391 Training Epoch [12/40] Iter[131/312]		Loss: 0.1533
2019-10-29 00:37:26,512 Training Epoch [12/40] Iter[132/312]		Loss: 0.1532
2019-10-29 00:37:26,634 Training Epoch [12/40] Iter[133/312]		Loss: 0.1534
2019-10-29 00:37:26,755 Training Epoch [12/40] Iter[134/312]		Loss: 0.1536
2019-10-29 00:37:26,877 Training Epoch [12/40] Iter[135/312]		Loss: 0.1536
2019-10-29 00:37:26,999 Training Epoch [12/40] Iter[136/312]		Loss: 0.1540
2019-10-29 00:37:27,120 Training Epoch [12/40] Iter[137/312]		Loss: 0.1541
2019-10-29 00:37:27,242 Training Epoch [12/40] Iter[138/312]		Loss: 0.1541
2019-10-29 00:37:27,363 Training Epoch [12/40] Iter[139/312]		Loss: 0.1536
2019-10-29 00:37:27,485 Training Epoch [12/40] Iter[140/312]		Loss: 0.1539
2019-10-29 00:37:27,606 Training Epoch [12/40] Iter[141/312]		Loss: 0.1537
2019-10-29 00:37:27,728 Training Epoch [12/40] Iter[142/312]		Loss: 0.1533
2019-10-29 00:37:27,849 Training Epoch [12/40] Iter[143/312]		Loss: 0.1532
2019-10-29 00:37:27,971 Training Epoch [12/40] Iter[144/312]		Loss: 0.1529
2019-10-29 00:37:28,092 Training Epoch [12/40] Iter[145/312]		Loss: 0.1528
2019-10-29 00:37:28,214 Training Epoch [12/40] Iter[146/312]		Loss: 0.1525
2019-10-29 00:37:28,335 Training Epoch [12/40] Iter[147/312]		Loss: 0.1525
2019-10-29 00:37:28,457 Training Epoch [12/40] Iter[148/312]		Loss: 0.1527
2019-10-29 00:37:28,578 Training Epoch [12/40] Iter[149/312]		Loss: 0.1527
2019-10-29 00:37:28,699 Training Epoch [12/40] Iter[150/312]		Loss: 0.1532
2019-10-29 00:37:28,825 Training Epoch [12/40] Iter[151/312]		Loss: 0.1534
2019-10-29 00:37:28,946 Training Epoch [12/40] Iter[152/312]		Loss: 0.1537
2019-10-29 00:37:29,067 Training Epoch [12/40] Iter[153/312]		Loss: 0.1535
2019-10-29 00:37:29,187 Training Epoch [12/40] Iter[154/312]		Loss: 0.1540
2019-10-29 00:37:29,309 Training Epoch [12/40] Iter[155/312]		Loss: 0.1539
2019-10-29 00:37:29,430 Training Epoch [12/40] Iter[156/312]		Loss: 0.1539
2019-10-29 00:37:29,550 Training Epoch [12/40] Iter[157/312]		Loss: 0.1539
2019-10-29 00:37:29,671 Training Epoch [12/40] Iter[158/312]		Loss: 0.1539
2019-10-29 00:37:29,792 Training Epoch [12/40] Iter[159/312]		Loss: 0.1537
2019-10-29 00:37:29,913 Training Epoch [12/40] Iter[160/312]		Loss: 0.1534
2019-10-29 00:37:30,035 Training Epoch [12/40] Iter[161/312]		Loss: 0.1531
2019-10-29 00:37:30,156 Training Epoch [12/40] Iter[162/312]		Loss: 0.1529
2019-10-29 00:37:30,277 Training Epoch [12/40] Iter[163/312]		Loss: 0.1527
2019-10-29 00:37:30,398 Training Epoch [12/40] Iter[164/312]		Loss: 0.1525
2019-10-29 00:37:30,519 Training Epoch [12/40] Iter[165/312]		Loss: 0.1524
2019-10-29 00:37:30,640 Training Epoch [12/40] Iter[166/312]		Loss: 0.1519
2019-10-29 00:37:30,761 Training Epoch [12/40] Iter[167/312]		Loss: 0.1521
2019-10-29 00:37:30,883 Training Epoch [12/40] Iter[168/312]		Loss: 0.1521
2019-10-29 00:37:31,005 Training Epoch [12/40] Iter[169/312]		Loss: 0.1520
2019-10-29 00:37:31,126 Training Epoch [12/40] Iter[170/312]		Loss: 0.1522
2019-10-29 00:37:31,247 Training Epoch [12/40] Iter[171/312]		Loss: 0.1523
2019-10-29 00:37:31,369 Training Epoch [12/40] Iter[172/312]		Loss: 0.1522
2019-10-29 00:37:31,490 Training Epoch [12/40] Iter[173/312]		Loss: 0.1526
2019-10-29 00:37:31,612 Training Epoch [12/40] Iter[174/312]		Loss: 0.1523
2019-10-29 00:37:31,733 Training Epoch [12/40] Iter[175/312]		Loss: 0.1524
2019-10-29 00:37:31,855 Training Epoch [12/40] Iter[176/312]		Loss: 0.1524
2019-10-29 00:37:31,977 Training Epoch [12/40] Iter[177/312]		Loss: 0.1523
2019-10-29 00:37:32,099 Training Epoch [12/40] Iter[178/312]		Loss: 0.1524
2019-10-29 00:37:32,221 Training Epoch [12/40] Iter[179/312]		Loss: 0.1523
2019-10-29 00:37:32,343 Training Epoch [12/40] Iter[180/312]		Loss: 0.1523
2019-10-29 00:37:32,464 Training Epoch [12/40] Iter[181/312]		Loss: 0.1522
2019-10-29 00:37:32,585 Training Epoch [12/40] Iter[182/312]		Loss: 0.1524
2019-10-29 00:37:32,706 Training Epoch [12/40] Iter[183/312]		Loss: 0.1521
2019-10-29 00:37:32,828 Training Epoch [12/40] Iter[184/312]		Loss: 0.1521
2019-10-29 00:37:32,949 Training Epoch [12/40] Iter[185/312]		Loss: 0.1518
2019-10-29 00:37:33,070 Training Epoch [12/40] Iter[186/312]		Loss: 0.1519
2019-10-29 00:37:33,191 Training Epoch [12/40] Iter[187/312]		Loss: 0.1523
2019-10-29 00:37:33,312 Training Epoch [12/40] Iter[188/312]		Loss: 0.1520
2019-10-29 00:37:33,434 Training Epoch [12/40] Iter[189/312]		Loss: 0.1520
2019-10-29 00:37:33,555 Training Epoch [12/40] Iter[190/312]		Loss: 0.1520
2019-10-29 00:37:33,677 Training Epoch [12/40] Iter[191/312]		Loss: 0.1519
2019-10-29 00:37:33,799 Training Epoch [12/40] Iter[192/312]		Loss: 0.1519
2019-10-29 00:37:33,920 Training Epoch [12/40] Iter[193/312]		Loss: 0.1518
2019-10-29 00:37:34,043 Training Epoch [12/40] Iter[194/312]		Loss: 0.1519
2019-10-29 00:37:34,165 Training Epoch [12/40] Iter[195/312]		Loss: 0.1517
2019-10-29 00:37:34,287 Training Epoch [12/40] Iter[196/312]		Loss: 0.1515
2019-10-29 00:37:34,409 Training Epoch [12/40] Iter[197/312]		Loss: 0.1517
2019-10-29 00:37:34,531 Training Epoch [12/40] Iter[198/312]		Loss: 0.1518
2019-10-29 00:37:34,653 Training Epoch [12/40] Iter[199/312]		Loss: 0.1518
2019-10-29 00:37:34,774 Training Epoch [12/40] Iter[200/312]		Loss: 0.1516
2019-10-29 00:37:34,896 Training Epoch [12/40] Iter[201/312]		Loss: 0.1514
2019-10-29 00:37:35,018 Training Epoch [12/40] Iter[202/312]		Loss: 0.1515
2019-10-29 00:37:35,140 Training Epoch [12/40] Iter[203/312]		Loss: 0.1512
2019-10-29 00:37:35,262 Training Epoch [12/40] Iter[204/312]		Loss: 0.1511
2019-10-29 00:37:35,384 Training Epoch [12/40] Iter[205/312]		Loss: 0.1510
2019-10-29 00:37:35,506 Training Epoch [12/40] Iter[206/312]		Loss: 0.1509
2019-10-29 00:37:35,628 Training Epoch [12/40] Iter[207/312]		Loss: 0.1511
2019-10-29 00:37:35,750 Training Epoch [12/40] Iter[208/312]		Loss: 0.1510
2019-10-29 00:37:35,872 Training Epoch [12/40] Iter[209/312]		Loss: 0.1510
2019-10-29 00:37:35,994 Training Epoch [12/40] Iter[210/312]		Loss: 0.1514
2019-10-29 00:37:36,116 Training Epoch [12/40] Iter[211/312]		Loss: 0.1513
2019-10-29 00:37:36,238 Training Epoch [12/40] Iter[212/312]		Loss: 0.1513
2019-10-29 00:37:36,360 Training Epoch [12/40] Iter[213/312]		Loss: 0.1514
2019-10-29 00:37:36,482 Training Epoch [12/40] Iter[214/312]		Loss: 0.1512
2019-10-29 00:37:36,604 Training Epoch [12/40] Iter[215/312]		Loss: 0.1511
2019-10-29 00:37:36,726 Training Epoch [12/40] Iter[216/312]		Loss: 0.1515
2019-10-29 00:37:36,848 Training Epoch [12/40] Iter[217/312]		Loss: 0.1516
2019-10-29 00:37:36,970 Training Epoch [12/40] Iter[218/312]		Loss: 0.1519
2019-10-29 00:37:37,092 Training Epoch [12/40] Iter[219/312]		Loss: 0.1518
2019-10-29 00:37:37,214 Training Epoch [12/40] Iter[220/312]		Loss: 0.1518
2019-10-29 00:37:37,336 Training Epoch [12/40] Iter[221/312]		Loss: 0.1517
2019-10-29 00:37:37,458 Training Epoch [12/40] Iter[222/312]		Loss: 0.1515
2019-10-29 00:37:37,579 Training Epoch [12/40] Iter[223/312]		Loss: 0.1516
2019-10-29 00:37:37,702 Training Epoch [12/40] Iter[224/312]		Loss: 0.1516
2019-10-29 00:37:37,824 Training Epoch [12/40] Iter[225/312]		Loss: 0.1516
2019-10-29 00:37:37,946 Training Epoch [12/40] Iter[226/312]		Loss: 0.1515
2019-10-29 00:37:38,067 Training Epoch [12/40] Iter[227/312]		Loss: 0.1515
2019-10-29 00:37:38,189 Training Epoch [12/40] Iter[228/312]		Loss: 0.1513
2019-10-29 00:37:38,311 Training Epoch [12/40] Iter[229/312]		Loss: 0.1513
2019-10-29 00:37:38,434 Training Epoch [12/40] Iter[230/312]		Loss: 0.1514
2019-10-29 00:37:38,555 Training Epoch [12/40] Iter[231/312]		Loss: 0.1513
2019-10-29 00:37:38,677 Training Epoch [12/40] Iter[232/312]		Loss: 0.1515
2019-10-29 00:37:38,799 Training Epoch [12/40] Iter[233/312]		Loss: 0.1513
2019-10-29 00:37:38,921 Training Epoch [12/40] Iter[234/312]		Loss: 0.1512
2019-10-29 00:37:39,043 Training Epoch [12/40] Iter[235/312]		Loss: 0.1511
2019-10-29 00:37:39,165 Training Epoch [12/40] Iter[236/312]		Loss: 0.1511
2019-10-29 00:37:39,287 Training Epoch [12/40] Iter[237/312]		Loss: 0.1509
2019-10-29 00:37:39,409 Training Epoch [12/40] Iter[238/312]		Loss: 0.1509
2019-10-29 00:37:39,531 Training Epoch [12/40] Iter[239/312]		Loss: 0.1507
2019-10-29 00:37:39,653 Training Epoch [12/40] Iter[240/312]		Loss: 0.1508
2019-10-29 00:37:39,775 Training Epoch [12/40] Iter[241/312]		Loss: 0.1508
2019-10-29 00:37:39,897 Training Epoch [12/40] Iter[242/312]		Loss: 0.1508
2019-10-29 00:37:40,019 Training Epoch [12/40] Iter[243/312]		Loss: 0.1507
2019-10-29 00:37:40,140 Training Epoch [12/40] Iter[244/312]		Loss: 0.1506
2019-10-29 00:37:40,262 Training Epoch [12/40] Iter[245/312]		Loss: 0.1506
2019-10-29 00:37:40,384 Training Epoch [12/40] Iter[246/312]		Loss: 0.1504
2019-10-29 00:37:40,507 Training Epoch [12/40] Iter[247/312]		Loss: 0.1503
2019-10-29 00:37:40,629 Training Epoch [12/40] Iter[248/312]		Loss: 0.1505
2019-10-29 00:37:40,751 Training Epoch [12/40] Iter[249/312]		Loss: 0.1503
2019-10-29 00:37:40,873 Training Epoch [12/40] Iter[250/312]		Loss: 0.1501
2019-10-29 00:37:40,994 Training Epoch [12/40] Iter[251/312]		Loss: 0.1499
2019-10-29 00:37:41,115 Training Epoch [12/40] Iter[252/312]		Loss: 0.1499
2019-10-29 00:37:41,237 Training Epoch [12/40] Iter[253/312]		Loss: 0.1499
2019-10-29 00:37:41,358 Training Epoch [12/40] Iter[254/312]		Loss: 0.1500
2019-10-29 00:37:41,480 Training Epoch [12/40] Iter[255/312]		Loss: 0.1499
2019-10-29 00:37:41,601 Training Epoch [12/40] Iter[256/312]		Loss: 0.1500
2019-10-29 00:37:41,722 Training Epoch [12/40] Iter[257/312]		Loss: 0.1498
2019-10-29 00:37:41,844 Training Epoch [12/40] Iter[258/312]		Loss: 0.1497
2019-10-29 00:37:41,966 Training Epoch [12/40] Iter[259/312]		Loss: 0.1498
2019-10-29 00:37:42,087 Training Epoch [12/40] Iter[260/312]		Loss: 0.1498
2019-10-29 00:37:42,209 Training Epoch [12/40] Iter[261/312]		Loss: 0.1498
2019-10-29 00:37:42,331 Training Epoch [12/40] Iter[262/312]		Loss: 0.1498
2019-10-29 00:37:42,453 Training Epoch [12/40] Iter[263/312]		Loss: 0.1496
2019-10-29 00:37:42,576 Training Epoch [12/40] Iter[264/312]		Loss: 0.1495
2019-10-29 00:37:42,697 Training Epoch [12/40] Iter[265/312]		Loss: 0.1493
2019-10-29 00:37:42,820 Training Epoch [12/40] Iter[266/312]		Loss: 0.1496
2019-10-29 00:37:42,942 Training Epoch [12/40] Iter[267/312]		Loss: 0.1496
2019-10-29 00:37:43,064 Training Epoch [12/40] Iter[268/312]		Loss: 0.1495
2019-10-29 00:37:43,186 Training Epoch [12/40] Iter[269/312]		Loss: 0.1494
2019-10-29 00:37:43,308 Training Epoch [12/40] Iter[270/312]		Loss: 0.1494
2019-10-29 00:37:43,430 Training Epoch [12/40] Iter[271/312]		Loss: 0.1493
2019-10-29 00:37:43,552 Training Epoch [12/40] Iter[272/312]		Loss: 0.1494
2019-10-29 00:37:43,674 Training Epoch [12/40] Iter[273/312]		Loss: 0.1494
2019-10-29 00:37:43,796 Training Epoch [12/40] Iter[274/312]		Loss: 0.1495
2019-10-29 00:37:43,918 Training Epoch [12/40] Iter[275/312]		Loss: 0.1495
2019-10-29 00:37:44,040 Training Epoch [12/40] Iter[276/312]		Loss: 0.1495
2019-10-29 00:37:44,162 Training Epoch [12/40] Iter[277/312]		Loss: 0.1494
2019-10-29 00:37:44,285 Training Epoch [12/40] Iter[278/312]		Loss: 0.1493
2019-10-29 00:37:44,407 Training Epoch [12/40] Iter[279/312]		Loss: 0.1492
2019-10-29 00:37:44,529 Training Epoch [12/40] Iter[280/312]		Loss: 0.1491
2019-10-29 00:37:44,651 Training Epoch [12/40] Iter[281/312]		Loss: 0.1490
2019-10-29 00:37:44,773 Training Epoch [12/40] Iter[282/312]		Loss: 0.1490
2019-10-29 00:37:44,895 Training Epoch [12/40] Iter[283/312]		Loss: 0.1493
2019-10-29 00:37:45,018 Training Epoch [12/40] Iter[284/312]		Loss: 0.1491
2019-10-29 00:37:45,140 Training Epoch [12/40] Iter[285/312]		Loss: 0.1491
2019-10-29 00:37:45,263 Training Epoch [12/40] Iter[286/312]		Loss: 0.1490
2019-10-29 00:37:45,385 Training Epoch [12/40] Iter[287/312]		Loss: 0.1491
2019-10-29 00:37:45,508 Training Epoch [12/40] Iter[288/312]		Loss: 0.1492
2019-10-29 00:37:45,630 Training Epoch [12/40] Iter[289/312]		Loss: 0.1490
2019-10-29 00:37:45,753 Training Epoch [12/40] Iter[290/312]		Loss: 0.1489
2019-10-29 00:37:45,875 Training Epoch [12/40] Iter[291/312]		Loss: 0.1490
2019-10-29 00:37:45,997 Training Epoch [12/40] Iter[292/312]		Loss: 0.1491
2019-10-29 00:37:46,119 Training Epoch [12/40] Iter[293/312]		Loss: 0.1492
2019-10-29 00:37:46,242 Training Epoch [12/40] Iter[294/312]		Loss: 0.1490
2019-10-29 00:37:46,365 Training Epoch [12/40] Iter[295/312]		Loss: 0.1490
2019-10-29 00:37:46,487 Training Epoch [12/40] Iter[296/312]		Loss: 0.1489
2019-10-29 00:37:46,610 Training Epoch [12/40] Iter[297/312]		Loss: 0.1490
2019-10-29 00:37:46,732 Training Epoch [12/40] Iter[298/312]		Loss: 0.1489
2019-10-29 00:37:46,854 Training Epoch [12/40] Iter[299/312]		Loss: 0.1492
2019-10-29 00:37:46,976 Training Epoch [12/40] Iter[300/312]		Loss: 0.1492
2019-10-29 00:37:47,098 Training Epoch [12/40] Iter[301/312]		Loss: 0.1491
2019-10-29 00:37:47,220 Training Epoch [12/40] Iter[302/312]		Loss: 0.1490
2019-10-29 00:37:47,342 Training Epoch [12/40] Iter[303/312]		Loss: 0.1488
2019-10-29 00:37:47,464 Training Epoch [12/40] Iter[304/312]		Loss: 0.1489
2019-10-29 00:37:47,586 Training Epoch [12/40] Iter[305/312]		Loss: 0.1488
2019-10-29 00:37:47,708 Training Epoch [12/40] Iter[306/312]		Loss: 0.1487
2019-10-29 00:37:47,829 Training Epoch [12/40] Iter[307/312]		Loss: 0.1487
2019-10-29 00:37:47,951 Training Epoch [12/40] Iter[308/312]		Loss: 0.1487
2019-10-29 00:37:48,072 Training Epoch [12/40] Iter[309/312]		Loss: 0.1486
2019-10-29 00:37:48,194 Training Epoch [12/40] Iter[310/312]		Loss: 0.1485
2019-10-29 00:37:48,316 Training Epoch [12/40] Iter[311/312]		Loss: 0.1486
2019-10-29 00:37:48,377 Training Epoch [12/40] Iter[312/312]		Loss: 0.1484
2019-10-29 00:37:48,781 Testing Epoch [12/40] Iter[0/62]		Loss: 0.1284
2019-10-29 00:37:48,813 Testing Epoch [12/40] Iter[1/62]		Loss: 0.1469
2019-10-29 00:37:48,854 Testing Epoch [12/40] Iter[2/62]		Loss: 0.1427
2019-10-29 00:37:48,889 Testing Epoch [12/40] Iter[3/62]		Loss: 0.1406
2019-10-29 00:37:48,919 Testing Epoch [12/40] Iter[4/62]		Loss: 0.1342
2019-10-29 00:37:48,950 Testing Epoch [12/40] Iter[5/62]		Loss: 0.1327
2019-10-29 00:37:48,980 Testing Epoch [12/40] Iter[6/62]		Loss: 0.1375
2019-10-29 00:37:49,018 Testing Epoch [12/40] Iter[7/62]		Loss: 0.1441
2019-10-29 00:37:49,048 Testing Epoch [12/40] Iter[8/62]		Loss: 0.1512
2019-10-29 00:37:49,079 Testing Epoch [12/40] Iter[9/62]		Loss: 0.1493
2019-10-29 00:37:49,110 Testing Epoch [12/40] Iter[10/62]		Loss: 0.1483
2019-10-29 00:37:49,142 Testing Epoch [12/40] Iter[11/62]		Loss: 0.1545
2019-10-29 00:37:49,173 Testing Epoch [12/40] Iter[12/62]		Loss: 0.1554
2019-10-29 00:37:49,210 Testing Epoch [12/40] Iter[13/62]		Loss: 0.1573
2019-10-29 00:37:49,241 Testing Epoch [12/40] Iter[14/62]		Loss: 0.1725
2019-10-29 00:37:49,272 Testing Epoch [12/40] Iter[15/62]		Loss: 0.1738
2019-10-29 00:37:49,306 Testing Epoch [12/40] Iter[16/62]		Loss: 0.1725
2019-10-29 00:37:49,338 Testing Epoch [12/40] Iter[17/62]		Loss: 0.1719
2019-10-29 00:37:49,370 Testing Epoch [12/40] Iter[18/62]		Loss: 0.1691
2019-10-29 00:37:49,406 Testing Epoch [12/40] Iter[19/62]		Loss: 0.1665
2019-10-29 00:37:49,438 Testing Epoch [12/40] Iter[20/62]		Loss: 0.1686
2019-10-29 00:37:49,469 Testing Epoch [12/40] Iter[21/62]		Loss: 0.1661
2019-10-29 00:37:49,502 Testing Epoch [12/40] Iter[22/62]		Loss: 0.1661
2019-10-29 00:37:49,534 Testing Epoch [12/40] Iter[23/62]		Loss: 0.1654
2019-10-29 00:37:49,565 Testing Epoch [12/40] Iter[24/62]		Loss: 0.1682
2019-10-29 00:37:49,598 Testing Epoch [12/40] Iter[25/62]		Loss: 0.1668
2019-10-29 00:37:49,629 Testing Epoch [12/40] Iter[26/62]		Loss: 0.1663
2019-10-29 00:37:49,661 Testing Epoch [12/40] Iter[27/62]		Loss: 0.1716
2019-10-29 00:37:49,694 Testing Epoch [12/40] Iter[28/62]		Loss: 0.1737
2019-10-29 00:37:49,726 Testing Epoch [12/40] Iter[29/62]		Loss: 0.1734
2019-10-29 00:37:49,757 Testing Epoch [12/40] Iter[30/62]		Loss: 0.1745
2019-10-29 00:37:49,794 Testing Epoch [12/40] Iter[31/62]		Loss: 0.1746
2019-10-29 00:37:49,825 Testing Epoch [12/40] Iter[32/62]		Loss: 0.1770
2019-10-29 00:37:49,862 Testing Epoch [12/40] Iter[33/62]		Loss: 0.1755
2019-10-29 00:37:49,894 Testing Epoch [12/40] Iter[34/62]		Loss: 0.1765
2019-10-29 00:37:49,925 Testing Epoch [12/40] Iter[35/62]		Loss: 0.1754
2019-10-29 00:37:49,958 Testing Epoch [12/40] Iter[36/62]		Loss: 0.1741
2019-10-29 00:37:49,989 Testing Epoch [12/40] Iter[37/62]		Loss: 0.1734
2019-10-29 00:37:50,021 Testing Epoch [12/40] Iter[38/62]		Loss: 0.1739
2019-10-29 00:37:50,058 Testing Epoch [12/40] Iter[39/62]		Loss: 0.1742
2019-10-29 00:37:50,089 Testing Epoch [12/40] Iter[40/62]		Loss: 0.1752
2019-10-29 00:37:50,121 Testing Epoch [12/40] Iter[41/62]		Loss: 0.1760
2019-10-29 00:37:50,154 Testing Epoch [12/40] Iter[42/62]		Loss: 0.1749
2019-10-29 00:37:50,186 Testing Epoch [12/40] Iter[43/62]		Loss: 0.1738
2019-10-29 00:37:50,217 Testing Epoch [12/40] Iter[44/62]		Loss: 0.1726
2019-10-29 00:37:50,254 Testing Epoch [12/40] Iter[45/62]		Loss: 0.1729
2019-10-29 00:37:50,285 Testing Epoch [12/40] Iter[46/62]		Loss: 0.1730
2019-10-29 00:37:50,317 Testing Epoch [12/40] Iter[47/62]		Loss: 0.1776
2019-10-29 00:37:50,350 Testing Epoch [12/40] Iter[48/62]		Loss: 0.1767
2019-10-29 00:37:50,382 Testing Epoch [12/40] Iter[49/62]		Loss: 0.1779
2019-10-29 00:37:50,413 Testing Epoch [12/40] Iter[50/62]		Loss: 0.1770
2019-10-29 00:37:50,446 Testing Epoch [12/40] Iter[51/62]		Loss: 0.1770
2019-10-29 00:37:50,478 Testing Epoch [12/40] Iter[52/62]		Loss: 0.1756
2019-10-29 00:37:50,509 Testing Epoch [12/40] Iter[53/62]		Loss: 0.1757
2019-10-29 00:37:50,546 Testing Epoch [12/40] Iter[54/62]		Loss: 0.1748
2019-10-29 00:37:50,577 Testing Epoch [12/40] Iter[55/62]		Loss: 0.1745
2019-10-29 00:37:50,608 Testing Epoch [12/40] Iter[56/62]		Loss: 0.1740
2019-10-29 00:37:50,639 Testing Epoch [12/40] Iter[57/62]		Loss: 0.1734
2019-10-29 00:37:50,670 Testing Epoch [12/40] Iter[58/62]		Loss: 0.1730
2019-10-29 00:37:50,701 Testing Epoch [12/40] Iter[59/62]		Loss: 0.1728
2019-10-29 00:37:50,732 Testing Epoch [12/40] Iter[60/62]		Loss: 0.1720
2019-10-29 00:37:50,763 Testing Epoch [12/40] Iter[61/62]		Loss: 0.1720
2019-10-29 00:37:50,781 Testing Epoch [12/40] Iter[62/62]		Loss: 0.1734
2019-10-29 00:37:50,849 Saving the Model
2019-10-29 00:37:51,288 Training Epoch [13/40] Iter[0/312]		Loss: 0.1416
2019-10-29 00:37:51,411 Training Epoch [13/40] Iter[1/312]		Loss: 0.1783
2019-10-29 00:37:51,533 Training Epoch [13/40] Iter[2/312]		Loss: 0.1646
2019-10-29 00:37:51,657 Training Epoch [13/40] Iter[3/312]		Loss: 0.1770
2019-10-29 00:37:51,778 Training Epoch [13/40] Iter[4/312]		Loss: 0.1806
2019-10-29 00:37:51,903 Training Epoch [13/40] Iter[5/312]		Loss: 0.1731
2019-10-29 00:37:52,024 Training Epoch [13/40] Iter[6/312]		Loss: 0.1723
2019-10-29 00:37:52,145 Training Epoch [13/40] Iter[7/312]		Loss: 0.1694
2019-10-29 00:37:52,266 Training Epoch [13/40] Iter[8/312]		Loss: 0.1607
2019-10-29 00:37:52,388 Training Epoch [13/40] Iter[9/312]		Loss: 0.1605
2019-10-29 00:37:52,510 Training Epoch [13/40] Iter[10/312]		Loss: 0.1552
2019-10-29 00:37:52,633 Training Epoch [13/40] Iter[11/312]		Loss: 0.1533
2019-10-29 00:37:52,755 Training Epoch [13/40] Iter[12/312]		Loss: 0.1558
2019-10-29 00:37:52,877 Training Epoch [13/40] Iter[13/312]		Loss: 0.1533
2019-10-29 00:37:53,000 Training Epoch [13/40] Iter[14/312]		Loss: 0.1509
2019-10-29 00:37:53,122 Training Epoch [13/40] Iter[15/312]		Loss: 0.1510
2019-10-29 00:37:53,244 Training Epoch [13/40] Iter[16/312]		Loss: 0.1500
2019-10-29 00:37:53,373 Training Epoch [13/40] Iter[17/312]		Loss: 0.1468
2019-10-29 00:37:53,495 Training Epoch [13/40] Iter[18/312]		Loss: 0.1460
2019-10-29 00:37:53,620 Training Epoch [13/40] Iter[19/312]		Loss: 0.1461
2019-10-29 00:37:53,743 Training Epoch [13/40] Iter[20/312]		Loss: 0.1478
2019-10-29 00:37:53,865 Training Epoch [13/40] Iter[21/312]		Loss: 0.1469
2019-10-29 00:37:53,987 Training Epoch [13/40] Iter[22/312]		Loss: 0.1452
2019-10-29 00:37:54,109 Training Epoch [13/40] Iter[23/312]		Loss: 0.1438
2019-10-29 00:37:54,231 Training Epoch [13/40] Iter[24/312]		Loss: 0.1451
2019-10-29 00:37:54,354 Training Epoch [13/40] Iter[25/312]		Loss: 0.1456
2019-10-29 00:37:54,476 Training Epoch [13/40] Iter[26/312]		Loss: 0.1455
2019-10-29 00:37:54,599 Training Epoch [13/40] Iter[27/312]		Loss: 0.1446
2019-10-29 00:37:54,721 Training Epoch [13/40] Iter[28/312]		Loss: 0.1435
2019-10-29 00:37:54,843 Training Epoch [13/40] Iter[29/312]		Loss: 0.1432
2019-10-29 00:37:54,966 Training Epoch [13/40] Iter[30/312]		Loss: 0.1436
2019-10-29 00:37:55,089 Training Epoch [13/40] Iter[31/312]		Loss: 0.1457
2019-10-29 00:37:55,211 Training Epoch [13/40] Iter[32/312]		Loss: 0.1481
2019-10-29 00:37:55,333 Training Epoch [13/40] Iter[33/312]		Loss: 0.1476
2019-10-29 00:37:55,455 Training Epoch [13/40] Iter[34/312]		Loss: 0.1492
2019-10-29 00:37:55,577 Training Epoch [13/40] Iter[35/312]		Loss: 0.1510
2019-10-29 00:37:55,698 Training Epoch [13/40] Iter[36/312]		Loss: 0.1491
2019-10-29 00:37:55,820 Training Epoch [13/40] Iter[37/312]		Loss: 0.1486
2019-10-29 00:37:55,942 Training Epoch [13/40] Iter[38/312]		Loss: 0.1477
2019-10-29 00:37:56,064 Training Epoch [13/40] Iter[39/312]		Loss: 0.1497
2019-10-29 00:37:56,186 Training Epoch [13/40] Iter[40/312]		Loss: 0.1489
2019-10-29 00:37:56,308 Training Epoch [13/40] Iter[41/312]		Loss: 0.1490
2019-10-29 00:37:56,430 Training Epoch [13/40] Iter[42/312]		Loss: 0.1476
2019-10-29 00:37:56,552 Training Epoch [13/40] Iter[43/312]		Loss: 0.1471
2019-10-29 00:37:56,673 Training Epoch [13/40] Iter[44/312]		Loss: 0.1466
2019-10-29 00:37:56,795 Training Epoch [13/40] Iter[45/312]		Loss: 0.1458
2019-10-29 00:37:56,916 Training Epoch [13/40] Iter[46/312]		Loss: 0.1456
2019-10-29 00:37:57,038 Training Epoch [13/40] Iter[47/312]		Loss: 0.1448
2019-10-29 00:37:57,160 Training Epoch [13/40] Iter[48/312]		Loss: 0.1437
2019-10-29 00:37:57,282 Training Epoch [13/40] Iter[49/312]		Loss: 0.1445
2019-10-29 00:37:57,404 Training Epoch [13/40] Iter[50/312]		Loss: 0.1440
2019-10-29 00:37:57,526 Training Epoch [13/40] Iter[51/312]		Loss: 0.1435
2019-10-29 00:37:57,648 Training Epoch [13/40] Iter[52/312]		Loss: 0.1432
2019-10-29 00:37:57,770 Training Epoch [13/40] Iter[53/312]		Loss: 0.1430
2019-10-29 00:37:57,892 Training Epoch [13/40] Iter[54/312]		Loss: 0.1437
2019-10-29 00:37:58,014 Training Epoch [13/40] Iter[55/312]		Loss: 0.1435
2019-10-29 00:37:58,136 Training Epoch [13/40] Iter[56/312]		Loss: 0.1433
2019-10-29 00:37:58,258 Training Epoch [13/40] Iter[57/312]		Loss: 0.1445
2019-10-29 00:37:58,381 Training Epoch [13/40] Iter[58/312]		Loss: 0.1447
2019-10-29 00:37:58,502 Training Epoch [13/40] Iter[59/312]		Loss: 0.1452
2019-10-29 00:37:58,624 Training Epoch [13/40] Iter[60/312]		Loss: 0.1444
2019-10-29 00:37:58,746 Training Epoch [13/40] Iter[61/312]		Loss: 0.1440
2019-10-29 00:37:58,868 Training Epoch [13/40] Iter[62/312]		Loss: 0.1442
2019-10-29 00:37:58,990 Training Epoch [13/40] Iter[63/312]		Loss: 0.1434
2019-10-29 00:37:59,112 Training Epoch [13/40] Iter[64/312]		Loss: 0.1427
2019-10-29 00:37:59,234 Training Epoch [13/40] Iter[65/312]		Loss: 0.1423
2019-10-29 00:37:59,356 Training Epoch [13/40] Iter[66/312]		Loss: 0.1419
2019-10-29 00:37:59,478 Training Epoch [13/40] Iter[67/312]		Loss: 0.1424
2019-10-29 00:37:59,600 Training Epoch [13/40] Iter[68/312]		Loss: 0.1422
2019-10-29 00:37:59,722 Training Epoch [13/40] Iter[69/312]		Loss: 0.1428
2019-10-29 00:37:59,844 Training Epoch [13/40] Iter[70/312]		Loss: 0.1429
2019-10-29 00:37:59,966 Training Epoch [13/40] Iter[71/312]		Loss: 0.1422
2019-10-29 00:38:00,087 Training Epoch [13/40] Iter[72/312]		Loss: 0.1415
2019-10-29 00:38:00,209 Training Epoch [13/40] Iter[73/312]		Loss: 0.1412
2019-10-29 00:38:00,332 Training Epoch [13/40] Iter[74/312]		Loss: 0.1414
2019-10-29 00:38:00,464 Training Epoch [13/40] Iter[75/312]		Loss: 0.1412
2019-10-29 00:38:00,589 Training Epoch [13/40] Iter[76/312]		Loss: 0.1409
2019-10-29 00:38:00,711 Training Epoch [13/40] Iter[77/312]		Loss: 0.1403
2019-10-29 00:38:00,832 Training Epoch [13/40] Iter[78/312]		Loss: 0.1413
2019-10-29 00:38:00,954 Training Epoch [13/40] Iter[79/312]		Loss: 0.1415
2019-10-29 00:38:01,076 Training Epoch [13/40] Iter[80/312]		Loss: 0.1412
2019-10-29 00:38:01,198 Training Epoch [13/40] Iter[81/312]		Loss: 0.1410
2019-10-29 00:38:01,320 Training Epoch [13/40] Iter[82/312]		Loss: 0.1408
2019-10-29 00:38:01,442 Training Epoch [13/40] Iter[83/312]		Loss: 0.1404
2019-10-29 00:38:01,564 Training Epoch [13/40] Iter[84/312]		Loss: 0.1402
2019-10-29 00:38:01,686 Training Epoch [13/40] Iter[85/312]		Loss: 0.1398
2019-10-29 00:38:01,808 Training Epoch [13/40] Iter[86/312]		Loss: 0.1395
2019-10-29 00:38:01,930 Training Epoch [13/40] Iter[87/312]		Loss: 0.1393
2019-10-29 00:38:02,052 Training Epoch [13/40] Iter[88/312]		Loss: 0.1407
2019-10-29 00:38:02,174 Training Epoch [13/40] Iter[89/312]		Loss: 0.1411
2019-10-29 00:38:02,296 Training Epoch [13/40] Iter[90/312]		Loss: 0.1408
2019-10-29 00:38:02,418 Training Epoch [13/40] Iter[91/312]		Loss: 0.1416
2019-10-29 00:38:02,540 Training Epoch [13/40] Iter[92/312]		Loss: 0.1413
2019-10-29 00:38:02,662 Training Epoch [13/40] Iter[93/312]		Loss: 0.1411
2019-10-29 00:38:02,784 Training Epoch [13/40] Iter[94/312]		Loss: 0.1415
2019-10-29 00:38:02,905 Training Epoch [13/40] Iter[95/312]		Loss: 0.1414
2019-10-29 00:38:03,027 Training Epoch [13/40] Iter[96/312]		Loss: 0.1411
2019-10-29 00:38:03,149 Training Epoch [13/40] Iter[97/312]		Loss: 0.1410
2019-10-29 00:38:03,271 Training Epoch [13/40] Iter[98/312]		Loss: 0.1407
2019-10-29 00:38:03,393 Training Epoch [13/40] Iter[99/312]		Loss: 0.1406
2019-10-29 00:38:03,515 Training Epoch [13/40] Iter[100/312]		Loss: 0.1406
2019-10-29 00:38:03,637 Training Epoch [13/40] Iter[101/312]		Loss: 0.1414
2019-10-29 00:38:03,758 Training Epoch [13/40] Iter[102/312]		Loss: 0.1422
2019-10-29 00:38:03,880 Training Epoch [13/40] Iter[103/312]		Loss: 0.1423
2019-10-29 00:38:04,002 Training Epoch [13/40] Iter[104/312]		Loss: 0.1426
2019-10-29 00:38:04,124 Training Epoch [13/40] Iter[105/312]		Loss: 0.1428
2019-10-29 00:38:04,246 Training Epoch [13/40] Iter[106/312]		Loss: 0.1431
2019-10-29 00:38:04,368 Training Epoch [13/40] Iter[107/312]		Loss: 0.1427
2019-10-29 00:38:04,490 Training Epoch [13/40] Iter[108/312]		Loss: 0.1427
2019-10-29 00:38:04,612 Training Epoch [13/40] Iter[109/312]		Loss: 0.1424
2019-10-29 00:38:04,734 Training Epoch [13/40] Iter[110/312]		Loss: 0.1425
2019-10-29 00:38:04,855 Training Epoch [13/40] Iter[111/312]		Loss: 0.1423
2019-10-29 00:38:04,977 Training Epoch [13/40] Iter[112/312]		Loss: 0.1420
2019-10-29 00:38:05,099 Training Epoch [13/40] Iter[113/312]		Loss: 0.1425
2019-10-29 00:38:05,221 Training Epoch [13/40] Iter[114/312]		Loss: 0.1421
2019-10-29 00:38:05,342 Training Epoch [13/40] Iter[115/312]		Loss: 0.1420
2019-10-29 00:38:05,465 Training Epoch [13/40] Iter[116/312]		Loss: 0.1419
2019-10-29 00:38:05,587 Training Epoch [13/40] Iter[117/312]		Loss: 0.1419
2019-10-29 00:38:05,708 Training Epoch [13/40] Iter[118/312]		Loss: 0.1416
2019-10-29 00:38:05,831 Training Epoch [13/40] Iter[119/312]		Loss: 0.1415
2019-10-29 00:38:05,953 Training Epoch [13/40] Iter[120/312]		Loss: 0.1413
2019-10-29 00:38:06,074 Training Epoch [13/40] Iter[121/312]		Loss: 0.1412
2019-10-29 00:38:06,196 Training Epoch [13/40] Iter[122/312]		Loss: 0.1416
2019-10-29 00:38:06,319 Training Epoch [13/40] Iter[123/312]		Loss: 0.1417
2019-10-29 00:38:06,441 Training Epoch [13/40] Iter[124/312]		Loss: 0.1413
2019-10-29 00:38:06,563 Training Epoch [13/40] Iter[125/312]		Loss: 0.1413
2019-10-29 00:38:06,685 Training Epoch [13/40] Iter[126/312]		Loss: 0.1410
2019-10-29 00:38:06,807 Training Epoch [13/40] Iter[127/312]		Loss: 0.1404
2019-10-29 00:38:06,929 Training Epoch [13/40] Iter[128/312]		Loss: 0.1403
2019-10-29 00:38:07,051 Training Epoch [13/40] Iter[129/312]		Loss: 0.1402
2019-10-29 00:38:07,173 Training Epoch [13/40] Iter[130/312]		Loss: 0.1398
2019-10-29 00:38:07,295 Training Epoch [13/40] Iter[131/312]		Loss: 0.1401
2019-10-29 00:38:07,417 Training Epoch [13/40] Iter[132/312]		Loss: 0.1401
2019-10-29 00:38:07,539 Training Epoch [13/40] Iter[133/312]		Loss: 0.1402
2019-10-29 00:38:07,661 Training Epoch [13/40] Iter[134/312]		Loss: 0.1401
2019-10-29 00:38:07,783 Training Epoch [13/40] Iter[135/312]		Loss: 0.1400
2019-10-29 00:38:07,905 Training Epoch [13/40] Iter[136/312]		Loss: 0.1397
2019-10-29 00:38:08,027 Training Epoch [13/40] Iter[137/312]		Loss: 0.1400
2019-10-29 00:38:08,148 Training Epoch [13/40] Iter[138/312]		Loss: 0.1402
2019-10-29 00:38:08,271 Training Epoch [13/40] Iter[139/312]		Loss: 0.1403
2019-10-29 00:38:08,393 Training Epoch [13/40] Iter[140/312]		Loss: 0.1403
2019-10-29 00:38:08,515 Training Epoch [13/40] Iter[141/312]		Loss: 0.1404
2019-10-29 00:38:08,637 Training Epoch [13/40] Iter[142/312]		Loss: 0.1407
2019-10-29 00:38:08,759 Training Epoch [13/40] Iter[143/312]		Loss: 0.1414
2019-10-29 00:38:08,881 Training Epoch [13/40] Iter[144/312]		Loss: 0.1411
2019-10-29 00:38:09,003 Training Epoch [13/40] Iter[145/312]		Loss: 0.1408
2019-10-29 00:38:09,125 Training Epoch [13/40] Iter[146/312]		Loss: 0.1407
2019-10-29 00:38:09,247 Training Epoch [13/40] Iter[147/312]		Loss: 0.1410
2019-10-29 00:38:09,369 Training Epoch [13/40] Iter[148/312]		Loss: 0.1411
2019-10-29 00:38:09,492 Training Epoch [13/40] Iter[149/312]		Loss: 0.1413
2019-10-29 00:38:09,613 Training Epoch [13/40] Iter[150/312]		Loss: 0.1412
2019-10-29 00:38:09,735 Training Epoch [13/40] Iter[151/312]		Loss: 0.1409
2019-10-29 00:38:09,857 Training Epoch [13/40] Iter[152/312]		Loss: 0.1412
2019-10-29 00:38:09,979 Training Epoch [13/40] Iter[153/312]		Loss: 0.1411
2019-10-29 00:38:10,101 Training Epoch [13/40] Iter[154/312]		Loss: 0.1408
2019-10-29 00:38:10,223 Training Epoch [13/40] Iter[155/312]		Loss: 0.1405
2019-10-29 00:38:10,344 Training Epoch [13/40] Iter[156/312]		Loss: 0.1404
2019-10-29 00:38:10,466 Training Epoch [13/40] Iter[157/312]		Loss: 0.1406
2019-10-29 00:38:10,589 Training Epoch [13/40] Iter[158/312]		Loss: 0.1412
2019-10-29 00:38:10,710 Training Epoch [13/40] Iter[159/312]		Loss: 0.1412
2019-10-29 00:38:10,832 Training Epoch [13/40] Iter[160/312]		Loss: 0.1410
2019-10-29 00:38:10,953 Training Epoch [13/40] Iter[161/312]		Loss: 0.1412
2019-10-29 00:38:11,074 Training Epoch [13/40] Iter[162/312]		Loss: 0.1408
2019-10-29 00:38:11,196 Training Epoch [13/40] Iter[163/312]		Loss: 0.1409
2019-10-29 00:38:11,318 Training Epoch [13/40] Iter[164/312]		Loss: 0.1411
2019-10-29 00:38:11,439 Training Epoch [13/40] Iter[165/312]		Loss: 0.1411
2019-10-29 00:38:11,560 Training Epoch [13/40] Iter[166/312]		Loss: 0.1413
2019-10-29 00:38:11,682 Training Epoch [13/40] Iter[167/312]		Loss: 0.1417
2019-10-29 00:38:11,803 Training Epoch [13/40] Iter[168/312]		Loss: 0.1420
2019-10-29 00:38:11,925 Training Epoch [13/40] Iter[169/312]		Loss: 0.1420
2019-10-29 00:38:12,046 Training Epoch [13/40] Iter[170/312]		Loss: 0.1420
2019-10-29 00:38:12,168 Training Epoch [13/40] Iter[171/312]		Loss: 0.1418
2019-10-29 00:38:12,289 Training Epoch [13/40] Iter[172/312]		Loss: 0.1418
2019-10-29 00:38:12,411 Training Epoch [13/40] Iter[173/312]		Loss: 0.1419
2019-10-29 00:38:12,532 Training Epoch [13/40] Iter[174/312]		Loss: 0.1419
2019-10-29 00:38:12,654 Training Epoch [13/40] Iter[175/312]		Loss: 0.1418
2019-10-29 00:38:12,776 Training Epoch [13/40] Iter[176/312]		Loss: 0.1418
2019-10-29 00:38:12,897 Training Epoch [13/40] Iter[177/312]		Loss: 0.1418
2019-10-29 00:38:13,019 Training Epoch [13/40] Iter[178/312]		Loss: 0.1417
2019-10-29 00:38:13,140 Training Epoch [13/40] Iter[179/312]		Loss: 0.1417
2019-10-29 00:38:13,262 Training Epoch [13/40] Iter[180/312]		Loss: 0.1421
2019-10-29 00:38:13,383 Training Epoch [13/40] Iter[181/312]		Loss: 0.1420
2019-10-29 00:38:13,504 Training Epoch [13/40] Iter[182/312]		Loss: 0.1423
2019-10-29 00:38:13,625 Training Epoch [13/40] Iter[183/312]		Loss: 0.1423
2019-10-29 00:38:13,746 Training Epoch [13/40] Iter[184/312]		Loss: 0.1423
2019-10-29 00:38:13,867 Training Epoch [13/40] Iter[185/312]		Loss: 0.1420
2019-10-29 00:38:13,988 Training Epoch [13/40] Iter[186/312]		Loss: 0.1419
2019-10-29 00:38:14,109 Training Epoch [13/40] Iter[187/312]		Loss: 0.1420
2019-10-29 00:38:14,231 Training Epoch [13/40] Iter[188/312]		Loss: 0.1421
2019-10-29 00:38:14,352 Training Epoch [13/40] Iter[189/312]		Loss: 0.1421
2019-10-29 00:38:14,473 Training Epoch [13/40] Iter[190/312]		Loss: 0.1419
2019-10-29 00:38:14,595 Training Epoch [13/40] Iter[191/312]		Loss: 0.1417
2019-10-29 00:38:14,717 Training Epoch [13/40] Iter[192/312]		Loss: 0.1417
2019-10-29 00:38:14,838 Training Epoch [13/40] Iter[193/312]		Loss: 0.1414
2019-10-29 00:38:14,960 Training Epoch [13/40] Iter[194/312]		Loss: 0.1414
2019-10-29 00:38:15,081 Training Epoch [13/40] Iter[195/312]		Loss: 0.1417
2019-10-29 00:38:15,202 Training Epoch [13/40] Iter[196/312]		Loss: 0.1419
2019-10-29 00:38:15,324 Training Epoch [13/40] Iter[197/312]		Loss: 0.1418
2019-10-29 00:38:15,445 Training Epoch [13/40] Iter[198/312]		Loss: 0.1417
2019-10-29 00:38:15,567 Training Epoch [13/40] Iter[199/312]		Loss: 0.1415
2019-10-29 00:38:15,689 Training Epoch [13/40] Iter[200/312]		Loss: 0.1413
2019-10-29 00:38:15,811 Training Epoch [13/40] Iter[201/312]		Loss: 0.1414
2019-10-29 00:38:15,933 Training Epoch [13/40] Iter[202/312]		Loss: 0.1412
2019-10-29 00:38:16,054 Training Epoch [13/40] Iter[203/312]		Loss: 0.1412
2019-10-29 00:38:16,176 Training Epoch [13/40] Iter[204/312]		Loss: 0.1411
2019-10-29 00:38:16,297 Training Epoch [13/40] Iter[205/312]		Loss: 0.1414
2019-10-29 00:38:16,418 Training Epoch [13/40] Iter[206/312]		Loss: 0.1416
2019-10-29 00:38:16,539 Training Epoch [13/40] Iter[207/312]		Loss: 0.1415
2019-10-29 00:38:16,660 Training Epoch [13/40] Iter[208/312]		Loss: 0.1413
2019-10-29 00:38:16,781 Training Epoch [13/40] Iter[209/312]		Loss: 0.1412
2019-10-29 00:38:16,902 Training Epoch [13/40] Iter[210/312]		Loss: 0.1410
2019-10-29 00:38:17,024 Training Epoch [13/40] Iter[211/312]		Loss: 0.1408
2019-10-29 00:38:17,145 Training Epoch [13/40] Iter[212/312]		Loss: 0.1407
2019-10-29 00:38:17,267 Training Epoch [13/40] Iter[213/312]		Loss: 0.1407
2019-10-29 00:38:17,388 Training Epoch [13/40] Iter[214/312]		Loss: 0.1407
2019-10-29 00:38:17,510 Training Epoch [13/40] Iter[215/312]		Loss: 0.1409
2019-10-29 00:38:17,631 Training Epoch [13/40] Iter[216/312]		Loss: 0.1410
2019-10-29 00:38:17,753 Training Epoch [13/40] Iter[217/312]		Loss: 0.1408
2019-10-29 00:38:17,875 Training Epoch [13/40] Iter[218/312]		Loss: 0.1406
2019-10-29 00:38:17,996 Training Epoch [13/40] Iter[219/312]		Loss: 0.1405
2019-10-29 00:38:18,118 Training Epoch [13/40] Iter[220/312]		Loss: 0.1404
2019-10-29 00:38:18,239 Training Epoch [13/40] Iter[221/312]		Loss: 0.1402
2019-10-29 00:38:18,361 Training Epoch [13/40] Iter[222/312]		Loss: 0.1403
2019-10-29 00:38:18,483 Training Epoch [13/40] Iter[223/312]		Loss: 0.1402
2019-10-29 00:38:18,604 Training Epoch [13/40] Iter[224/312]		Loss: 0.1406
2019-10-29 00:38:18,725 Training Epoch [13/40] Iter[225/312]		Loss: 0.1407
2019-10-29 00:38:18,847 Training Epoch [13/40] Iter[226/312]		Loss: 0.1405
2019-10-29 00:38:18,968 Training Epoch [13/40] Iter[227/312]		Loss: 0.1405
2019-10-29 00:38:19,090 Training Epoch [13/40] Iter[228/312]		Loss: 0.1406
2019-10-29 00:38:19,213 Training Epoch [13/40] Iter[229/312]		Loss: 0.1404
2019-10-29 00:38:19,334 Training Epoch [13/40] Iter[230/312]		Loss: 0.1405
2019-10-29 00:38:19,456 Training Epoch [13/40] Iter[231/312]		Loss: 0.1409
2019-10-29 00:38:19,578 Training Epoch [13/40] Iter[232/312]		Loss: 0.1410
2019-10-29 00:38:19,699 Training Epoch [13/40] Iter[233/312]		Loss: 0.1408
2019-10-29 00:38:19,821 Training Epoch [13/40] Iter[234/312]		Loss: 0.1407
2019-10-29 00:38:19,942 Training Epoch [13/40] Iter[235/312]		Loss: 0.1407
2019-10-29 00:38:20,063 Training Epoch [13/40] Iter[236/312]		Loss: 0.1406
2019-10-29 00:38:20,185 Training Epoch [13/40] Iter[237/312]		Loss: 0.1406
2019-10-29 00:38:20,306 Training Epoch [13/40] Iter[238/312]		Loss: 0.1408
2019-10-29 00:38:20,428 Training Epoch [13/40] Iter[239/312]		Loss: 0.1411
2019-10-29 00:38:20,550 Training Epoch [13/40] Iter[240/312]		Loss: 0.1410
2019-10-29 00:38:20,671 Training Epoch [13/40] Iter[241/312]		Loss: 0.1410
2019-10-29 00:38:20,792 Training Epoch [13/40] Iter[242/312]		Loss: 0.1410
2019-10-29 00:38:20,914 Training Epoch [13/40] Iter[243/312]		Loss: 0.1409
2019-10-29 00:38:21,036 Training Epoch [13/40] Iter[244/312]		Loss: 0.1408
2019-10-29 00:38:21,158 Training Epoch [13/40] Iter[245/312]		Loss: 0.1407
2019-10-29 00:38:21,279 Training Epoch [13/40] Iter[246/312]		Loss: 0.1405
2019-10-29 00:38:21,401 Training Epoch [13/40] Iter[247/312]		Loss: 0.1407
2019-10-29 00:38:21,523 Training Epoch [13/40] Iter[248/312]		Loss: 0.1409
2019-10-29 00:38:21,644 Training Epoch [13/40] Iter[249/312]		Loss: 0.1408
2019-10-29 00:38:21,765 Training Epoch [13/40] Iter[250/312]		Loss: 0.1413
2019-10-29 00:38:21,886 Training Epoch [13/40] Iter[251/312]		Loss: 0.1416
2019-10-29 00:38:22,006 Training Epoch [13/40] Iter[252/312]		Loss: 0.1417
2019-10-29 00:38:22,127 Training Epoch [13/40] Iter[253/312]		Loss: 0.1415
2019-10-29 00:38:22,249 Training Epoch [13/40] Iter[254/312]		Loss: 0.1414
2019-10-29 00:38:22,370 Training Epoch [13/40] Iter[255/312]		Loss: 0.1413
2019-10-29 00:38:22,492 Training Epoch [13/40] Iter[256/312]		Loss: 0.1417
2019-10-29 00:38:22,613 Training Epoch [13/40] Iter[257/312]		Loss: 0.1416
2019-10-29 00:38:22,734 Training Epoch [13/40] Iter[258/312]		Loss: 0.1416
2019-10-29 00:38:22,855 Training Epoch [13/40] Iter[259/312]		Loss: 0.1415
2019-10-29 00:38:22,976 Training Epoch [13/40] Iter[260/312]		Loss: 0.1419
2019-10-29 00:38:23,098 Training Epoch [13/40] Iter[261/312]		Loss: 0.1420
2019-10-29 00:38:23,219 Training Epoch [13/40] Iter[262/312]		Loss: 0.1419
2019-10-29 00:38:23,341 Training Epoch [13/40] Iter[263/312]		Loss: 0.1418
2019-10-29 00:38:23,463 Training Epoch [13/40] Iter[264/312]		Loss: 0.1417
2019-10-29 00:38:23,584 Training Epoch [13/40] Iter[265/312]		Loss: 0.1417
2019-10-29 00:38:23,706 Training Epoch [13/40] Iter[266/312]		Loss: 0.1415
2019-10-29 00:38:23,828 Training Epoch [13/40] Iter[267/312]		Loss: 0.1413
2019-10-29 00:38:23,949 Training Epoch [13/40] Iter[268/312]		Loss: 0.1413
2019-10-29 00:38:24,070 Training Epoch [13/40] Iter[269/312]		Loss: 0.1412
2019-10-29 00:38:24,192 Training Epoch [13/40] Iter[270/312]		Loss: 0.1410
2019-10-29 00:38:24,314 Training Epoch [13/40] Iter[271/312]		Loss: 0.1410
2019-10-29 00:38:24,435 Training Epoch [13/40] Iter[272/312]		Loss: 0.1409
2019-10-29 00:38:24,557 Training Epoch [13/40] Iter[273/312]		Loss: 0.1407
2019-10-29 00:38:24,679 Training Epoch [13/40] Iter[274/312]		Loss: 0.1407
2019-10-29 00:38:24,801 Training Epoch [13/40] Iter[275/312]		Loss: 0.1408
2019-10-29 00:38:24,922 Training Epoch [13/40] Iter[276/312]		Loss: 0.1409
2019-10-29 00:38:25,044 Training Epoch [13/40] Iter[277/312]		Loss: 0.1411
2019-10-29 00:38:25,165 Training Epoch [13/40] Iter[278/312]		Loss: 0.1411
2019-10-29 00:38:25,287 Training Epoch [13/40] Iter[279/312]		Loss: 0.1411
2019-10-29 00:38:25,408 Training Epoch [13/40] Iter[280/312]		Loss: 0.1413
2019-10-29 00:38:25,530 Training Epoch [13/40] Iter[281/312]		Loss: 0.1416
2019-10-29 00:38:25,651 Training Epoch [13/40] Iter[282/312]		Loss: 0.1416
2019-10-29 00:38:25,772 Training Epoch [13/40] Iter[283/312]		Loss: 0.1416
2019-10-29 00:38:25,894 Training Epoch [13/40] Iter[284/312]		Loss: 0.1415
2019-10-29 00:38:26,015 Training Epoch [13/40] Iter[285/312]		Loss: 0.1414
2019-10-29 00:38:26,138 Training Epoch [13/40] Iter[286/312]		Loss: 0.1413
2019-10-29 00:38:26,260 Training Epoch [13/40] Iter[287/312]		Loss: 0.1412
2019-10-29 00:38:26,381 Training Epoch [13/40] Iter[288/312]		Loss: 0.1415
2019-10-29 00:38:26,503 Training Epoch [13/40] Iter[289/312]		Loss: 0.1414
2019-10-29 00:38:26,624 Training Epoch [13/40] Iter[290/312]		Loss: 0.1413
2019-10-29 00:38:26,746 Training Epoch [13/40] Iter[291/312]		Loss: 0.1415
2019-10-29 00:38:26,867 Training Epoch [13/40] Iter[292/312]		Loss: 0.1414
2019-10-29 00:38:26,989 Training Epoch [13/40] Iter[293/312]		Loss: 0.1413
2019-10-29 00:38:27,110 Training Epoch [13/40] Iter[294/312]		Loss: 0.1414
2019-10-29 00:38:27,232 Training Epoch [13/40] Iter[295/312]		Loss: 0.1416
2019-10-29 00:38:27,353 Training Epoch [13/40] Iter[296/312]		Loss: 0.1416
2019-10-29 00:38:27,475 Training Epoch [13/40] Iter[297/312]		Loss: 0.1415
2019-10-29 00:38:27,596 Training Epoch [13/40] Iter[298/312]		Loss: 0.1415
2019-10-29 00:38:27,718 Training Epoch [13/40] Iter[299/312]		Loss: 0.1414
2019-10-29 00:38:27,840 Training Epoch [13/40] Iter[300/312]		Loss: 0.1415
2019-10-29 00:38:27,961 Training Epoch [13/40] Iter[301/312]		Loss: 0.1415
2019-10-29 00:38:28,083 Training Epoch [13/40] Iter[302/312]		Loss: 0.1414
2019-10-29 00:38:28,204 Training Epoch [13/40] Iter[303/312]		Loss: 0.1414
2019-10-29 00:38:28,326 Training Epoch [13/40] Iter[304/312]		Loss: 0.1415
2019-10-29 00:38:28,447 Training Epoch [13/40] Iter[305/312]		Loss: 0.1416
2019-10-29 00:38:28,568 Training Epoch [13/40] Iter[306/312]		Loss: 0.1417
2019-10-29 00:38:28,689 Training Epoch [13/40] Iter[307/312]		Loss: 0.1420
2019-10-29 00:38:28,810 Training Epoch [13/40] Iter[308/312]		Loss: 0.1419
2019-10-29 00:38:28,931 Training Epoch [13/40] Iter[309/312]		Loss: 0.1418
2019-10-29 00:38:29,051 Training Epoch [13/40] Iter[310/312]		Loss: 0.1418
2019-10-29 00:38:29,172 Training Epoch [13/40] Iter[311/312]		Loss: 0.1420
2019-10-29 00:38:29,232 Training Epoch [13/40] Iter[312/312]		Loss: 0.1419
2019-10-29 00:38:29,635 Testing Epoch [13/40] Iter[0/62]		Loss: 0.1198
2019-10-29 00:38:29,672 Testing Epoch [13/40] Iter[1/62]		Loss: 0.1471
2019-10-29 00:38:29,703 Testing Epoch [13/40] Iter[2/62]		Loss: 0.1377
2019-10-29 00:38:29,738 Testing Epoch [13/40] Iter[3/62]		Loss: 0.1366
2019-10-29 00:38:29,769 Testing Epoch [13/40] Iter[4/62]		Loss: 0.1337
2019-10-29 00:38:29,802 Testing Epoch [13/40] Iter[5/62]		Loss: 0.1322
2019-10-29 00:38:29,833 Testing Epoch [13/40] Iter[6/62]		Loss: 0.1382
2019-10-29 00:38:29,863 Testing Epoch [13/40] Iter[7/62]		Loss: 0.1447
2019-10-29 00:38:29,898 Testing Epoch [13/40] Iter[8/62]		Loss: 0.1499
2019-10-29 00:38:29,929 Testing Epoch [13/40] Iter[9/62]		Loss: 0.1456
2019-10-29 00:38:29,960 Testing Epoch [13/40] Iter[10/62]		Loss: 0.1444
2019-10-29 00:38:29,998 Testing Epoch [13/40] Iter[11/62]		Loss: 0.1510
2019-10-29 00:38:30,029 Testing Epoch [13/40] Iter[12/62]		Loss: 0.1510
2019-10-29 00:38:30,059 Testing Epoch [13/40] Iter[13/62]		Loss: 0.1530
2019-10-29 00:38:30,090 Testing Epoch [13/40] Iter[14/62]		Loss: 0.1675
2019-10-29 00:38:30,121 Testing Epoch [13/40] Iter[15/62]		Loss: 0.1694
2019-10-29 00:38:30,152 Testing Epoch [13/40] Iter[16/62]		Loss: 0.1678
2019-10-29 00:38:30,183 Testing Epoch [13/40] Iter[17/62]		Loss: 0.1677
2019-10-29 00:38:30,214 Testing Epoch [13/40] Iter[18/62]		Loss: 0.1637
2019-10-29 00:38:30,244 Testing Epoch [13/40] Iter[19/62]		Loss: 0.1618
2019-10-29 00:38:30,275 Testing Epoch [13/40] Iter[20/62]		Loss: 0.1624
2019-10-29 00:38:30,306 Testing Epoch [13/40] Iter[21/62]		Loss: 0.1604
2019-10-29 00:38:30,337 Testing Epoch [13/40] Iter[22/62]		Loss: 0.1607
2019-10-29 00:38:30,368 Testing Epoch [13/40] Iter[23/62]		Loss: 0.1592
2019-10-29 00:38:30,398 Testing Epoch [13/40] Iter[24/62]		Loss: 0.1621
2019-10-29 00:38:30,430 Testing Epoch [13/40] Iter[25/62]		Loss: 0.1608
2019-10-29 00:38:30,468 Testing Epoch [13/40] Iter[26/62]		Loss: 0.1598
2019-10-29 00:38:30,499 Testing Epoch [13/40] Iter[27/62]		Loss: 0.1651
2019-10-29 00:38:30,531 Testing Epoch [13/40] Iter[28/62]		Loss: 0.1675
2019-10-29 00:38:30,566 Testing Epoch [13/40] Iter[29/62]		Loss: 0.1673
2019-10-29 00:38:30,597 Testing Epoch [13/40] Iter[30/62]		Loss: 0.1687
2019-10-29 00:38:30,628 Testing Epoch [13/40] Iter[31/62]		Loss: 0.1683
2019-10-29 00:38:30,666 Testing Epoch [13/40] Iter[32/62]		Loss: 0.1703
2019-10-29 00:38:30,697 Testing Epoch [13/40] Iter[33/62]		Loss: 0.1691
2019-10-29 00:38:30,728 Testing Epoch [13/40] Iter[34/62]		Loss: 0.1706
2019-10-29 00:38:30,759 Testing Epoch [13/40] Iter[35/62]		Loss: 0.1702
2019-10-29 00:38:30,790 Testing Epoch [13/40] Iter[36/62]		Loss: 0.1689
2019-10-29 00:38:30,821 Testing Epoch [13/40] Iter[37/62]		Loss: 0.1687
2019-10-29 00:38:30,852 Testing Epoch [13/40] Iter[38/62]		Loss: 0.1690
2019-10-29 00:38:30,883 Testing Epoch [13/40] Iter[39/62]		Loss: 0.1694
2019-10-29 00:38:30,914 Testing Epoch [13/40] Iter[40/62]		Loss: 0.1703
2019-10-29 00:38:30,945 Testing Epoch [13/40] Iter[41/62]		Loss: 0.1708
2019-10-29 00:38:30,976 Testing Epoch [13/40] Iter[42/62]		Loss: 0.1695
2019-10-29 00:38:31,007 Testing Epoch [13/40] Iter[43/62]		Loss: 0.1692
2019-10-29 00:38:31,039 Testing Epoch [13/40] Iter[44/62]		Loss: 0.1680
2019-10-29 00:38:31,070 Testing Epoch [13/40] Iter[45/62]		Loss: 0.1685
2019-10-29 00:38:31,101 Testing Epoch [13/40] Iter[46/62]		Loss: 0.1688
2019-10-29 00:38:31,132 Testing Epoch [13/40] Iter[47/62]		Loss: 0.1737
2019-10-29 00:38:31,163 Testing Epoch [13/40] Iter[48/62]		Loss: 0.1726
2019-10-29 00:38:31,194 Testing Epoch [13/40] Iter[49/62]		Loss: 0.1735
2019-10-29 00:38:31,225 Testing Epoch [13/40] Iter[50/62]		Loss: 0.1731
2019-10-29 00:38:31,256 Testing Epoch [13/40] Iter[51/62]		Loss: 0.1733
2019-10-29 00:38:31,288 Testing Epoch [13/40] Iter[52/62]		Loss: 0.1717
2019-10-29 00:38:31,319 Testing Epoch [13/40] Iter[53/62]		Loss: 0.1719
2019-10-29 00:38:31,350 Testing Epoch [13/40] Iter[54/62]		Loss: 0.1710
2019-10-29 00:38:31,380 Testing Epoch [13/40] Iter[55/62]		Loss: 0.1710
2019-10-29 00:38:31,411 Testing Epoch [13/40] Iter[56/62]		Loss: 0.1706
2019-10-29 00:38:31,442 Testing Epoch [13/40] Iter[57/62]		Loss: 0.1702
2019-10-29 00:38:31,472 Testing Epoch [13/40] Iter[58/62]		Loss: 0.1698
2019-10-29 00:38:31,503 Testing Epoch [13/40] Iter[59/62]		Loss: 0.1699
2019-10-29 00:38:31,533 Testing Epoch [13/40] Iter[60/62]		Loss: 0.1693
2019-10-29 00:38:31,564 Testing Epoch [13/40] Iter[61/62]		Loss: 0.1692
2019-10-29 00:38:31,582 Testing Epoch [13/40] Iter[62/62]		Loss: 0.1702
2019-10-29 00:38:31,646 Saving the Model
2019-10-29 00:38:32,073 Training Epoch [14/40] Iter[0/312]		Loss: 0.1042
2019-10-29 00:38:32,197 Training Epoch [14/40] Iter[1/312]		Loss: 0.1205
2019-10-29 00:38:32,319 Training Epoch [14/40] Iter[2/312]		Loss: 0.1228
2019-10-29 00:38:32,444 Training Epoch [14/40] Iter[3/312]		Loss: 0.1313
2019-10-29 00:38:32,564 Training Epoch [14/40] Iter[4/312]		Loss: 0.1348
2019-10-29 00:38:32,685 Training Epoch [14/40] Iter[5/312]		Loss: 0.1280
2019-10-29 00:38:32,805 Training Epoch [14/40] Iter[6/312]		Loss: 0.1323
2019-10-29 00:38:32,928 Training Epoch [14/40] Iter[7/312]		Loss: 0.1292
2019-10-29 00:38:33,050 Training Epoch [14/40] Iter[8/312]		Loss: 0.1279
2019-10-29 00:38:33,172 Training Epoch [14/40] Iter[9/312]		Loss: 0.1311
2019-10-29 00:38:33,294 Training Epoch [14/40] Iter[10/312]		Loss: 0.1430
2019-10-29 00:38:33,416 Training Epoch [14/40] Iter[11/312]		Loss: 0.1383
2019-10-29 00:38:33,537 Training Epoch [14/40] Iter[12/312]		Loss: 0.1398
2019-10-29 00:38:33,659 Training Epoch [14/40] Iter[13/312]		Loss: 0.1381
2019-10-29 00:38:33,781 Training Epoch [14/40] Iter[14/312]		Loss: 0.1391
2019-10-29 00:38:33,903 Training Epoch [14/40] Iter[15/312]		Loss: 0.1364
2019-10-29 00:38:34,024 Training Epoch [14/40] Iter[16/312]		Loss: 0.1400
2019-10-29 00:38:34,146 Training Epoch [14/40] Iter[17/312]		Loss: 0.1398
2019-10-29 00:38:34,272 Training Epoch [14/40] Iter[18/312]		Loss: 0.1417
2019-10-29 00:38:34,394 Training Epoch [14/40] Iter[19/312]		Loss: 0.1437
2019-10-29 00:38:34,516 Training Epoch [14/40] Iter[20/312]		Loss: 0.1411
2019-10-29 00:38:34,644 Training Epoch [14/40] Iter[21/312]		Loss: 0.1417
2019-10-29 00:38:34,766 Training Epoch [14/40] Iter[22/312]		Loss: 0.1426
2019-10-29 00:38:34,887 Training Epoch [14/40] Iter[23/312]		Loss: 0.1476
2019-10-29 00:38:35,009 Training Epoch [14/40] Iter[24/312]		Loss: 0.1473
2019-10-29 00:38:35,131 Training Epoch [14/40] Iter[25/312]		Loss: 0.1476
2019-10-29 00:38:35,253 Training Epoch [14/40] Iter[26/312]		Loss: 0.1449
2019-10-29 00:38:35,375 Training Epoch [14/40] Iter[27/312]		Loss: 0.1451
2019-10-29 00:38:35,496 Training Epoch [14/40] Iter[28/312]		Loss: 0.1453
2019-10-29 00:38:35,618 Training Epoch [14/40] Iter[29/312]		Loss: 0.1460
2019-10-29 00:38:35,740 Training Epoch [14/40] Iter[30/312]		Loss: 0.1462
2019-10-29 00:38:35,862 Training Epoch [14/40] Iter[31/312]		Loss: 0.1473
2019-10-29 00:38:35,983 Training Epoch [14/40] Iter[32/312]		Loss: 0.1457
2019-10-29 00:38:36,105 Training Epoch [14/40] Iter[33/312]		Loss: 0.1475
2019-10-29 00:38:36,227 Training Epoch [14/40] Iter[34/312]		Loss: 0.1482
2019-10-29 00:38:36,349 Training Epoch [14/40] Iter[35/312]		Loss: 0.1475
2019-10-29 00:38:36,471 Training Epoch [14/40] Iter[36/312]		Loss: 0.1475
2019-10-29 00:38:36,593 Training Epoch [14/40] Iter[37/312]		Loss: 0.1456
2019-10-29 00:38:36,715 Training Epoch [14/40] Iter[38/312]		Loss: 0.1478
2019-10-29 00:38:36,837 Training Epoch [14/40] Iter[39/312]		Loss: 0.1466
2019-10-29 00:38:36,959 Training Epoch [14/40] Iter[40/312]		Loss: 0.1480
2019-10-29 00:38:37,081 Training Epoch [14/40] Iter[41/312]		Loss: 0.1470
2019-10-29 00:38:37,203 Training Epoch [14/40] Iter[42/312]		Loss: 0.1469
2019-10-29 00:38:37,325 Training Epoch [14/40] Iter[43/312]		Loss: 0.1456
2019-10-29 00:38:37,447 Training Epoch [14/40] Iter[44/312]		Loss: 0.1474
2019-10-29 00:38:37,569 Training Epoch [14/40] Iter[45/312]		Loss: 0.1482
2019-10-29 00:38:37,691 Training Epoch [14/40] Iter[46/312]		Loss: 0.1475
2019-10-29 00:38:37,813 Training Epoch [14/40] Iter[47/312]		Loss: 0.1497
2019-10-29 00:38:37,935 Training Epoch [14/40] Iter[48/312]		Loss: 0.1490
2019-10-29 00:38:38,057 Training Epoch [14/40] Iter[49/312]		Loss: 0.1486
2019-10-29 00:38:38,178 Training Epoch [14/40] Iter[50/312]		Loss: 0.1485
2019-10-29 00:38:38,300 Training Epoch [14/40] Iter[51/312]		Loss: 0.1481
2019-10-29 00:38:38,422 Training Epoch [14/40] Iter[52/312]		Loss: 0.1489
2019-10-29 00:38:38,544 Training Epoch [14/40] Iter[53/312]		Loss: 0.1499
2019-10-29 00:38:38,666 Training Epoch [14/40] Iter[54/312]		Loss: 0.1500
2019-10-29 00:38:38,789 Training Epoch [14/40] Iter[55/312]		Loss: 0.1500
2019-10-29 00:38:38,911 Training Epoch [14/40] Iter[56/312]		Loss: 0.1494
2019-10-29 00:38:39,033 Training Epoch [14/40] Iter[57/312]		Loss: 0.1497
2019-10-29 00:38:39,155 Training Epoch [14/40] Iter[58/312]		Loss: 0.1494
2019-10-29 00:38:39,277 Training Epoch [14/40] Iter[59/312]		Loss: 0.1490
2019-10-29 00:38:39,398 Training Epoch [14/40] Iter[60/312]		Loss: 0.1483
2019-10-29 00:38:39,520 Training Epoch [14/40] Iter[61/312]		Loss: 0.1485
2019-10-29 00:38:39,641 Training Epoch [14/40] Iter[62/312]		Loss: 0.1480
2019-10-29 00:38:39,763 Training Epoch [14/40] Iter[63/312]		Loss: 0.1478
2019-10-29 00:38:39,885 Training Epoch [14/40] Iter[64/312]		Loss: 0.1479
2019-10-29 00:38:40,007 Training Epoch [14/40] Iter[65/312]		Loss: 0.1487
2019-10-29 00:38:40,129 Training Epoch [14/40] Iter[66/312]		Loss: 0.1489
2019-10-29 00:38:40,252 Training Epoch [14/40] Iter[67/312]		Loss: 0.1486
2019-10-29 00:38:40,374 Training Epoch [14/40] Iter[68/312]		Loss: 0.1483
2019-10-29 00:38:40,496 Training Epoch [14/40] Iter[69/312]		Loss: 0.1478
2019-10-29 00:38:40,618 Training Epoch [14/40] Iter[70/312]		Loss: 0.1474
2019-10-29 00:38:40,739 Training Epoch [14/40] Iter[71/312]		Loss: 0.1480
2019-10-29 00:38:40,861 Training Epoch [14/40] Iter[72/312]		Loss: 0.1477
2019-10-29 00:38:40,983 Training Epoch [14/40] Iter[73/312]		Loss: 0.1480
2019-10-29 00:38:41,105 Training Epoch [14/40] Iter[74/312]		Loss: 0.1484
2019-10-29 00:38:41,227 Training Epoch [14/40] Iter[75/312]		Loss: 0.1480
2019-10-29 00:38:41,349 Training Epoch [14/40] Iter[76/312]		Loss: 0.1479
2019-10-29 00:38:41,471 Training Epoch [14/40] Iter[77/312]		Loss: 0.1474
2019-10-29 00:38:41,593 Training Epoch [14/40] Iter[78/312]		Loss: 0.1467
2019-10-29 00:38:41,714 Training Epoch [14/40] Iter[79/312]		Loss: 0.1463
2019-10-29 00:38:41,836 Training Epoch [14/40] Iter[80/312]		Loss: 0.1460
2019-10-29 00:38:41,957 Training Epoch [14/40] Iter[81/312]		Loss: 0.1460
2019-10-29 00:38:42,079 Training Epoch [14/40] Iter[82/312]		Loss: 0.1457
2019-10-29 00:38:42,201 Training Epoch [14/40] Iter[83/312]		Loss: 0.1452
2019-10-29 00:38:42,322 Training Epoch [14/40] Iter[84/312]		Loss: 0.1454
2019-10-29 00:38:42,444 Training Epoch [14/40] Iter[85/312]		Loss: 0.1450
2019-10-29 00:38:42,565 Training Epoch [14/40] Iter[86/312]		Loss: 0.1465
2019-10-29 00:38:42,686 Training Epoch [14/40] Iter[87/312]		Loss: 0.1458
2019-10-29 00:38:42,808 Training Epoch [14/40] Iter[88/312]		Loss: 0.1463
2019-10-29 00:38:42,929 Training Epoch [14/40] Iter[89/312]		Loss: 0.1461
2019-10-29 00:38:43,051 Training Epoch [14/40] Iter[90/312]		Loss: 0.1459
2019-10-29 00:38:43,172 Training Epoch [14/40] Iter[91/312]		Loss: 0.1454
2019-10-29 00:38:43,293 Training Epoch [14/40] Iter[92/312]		Loss: 0.1451
2019-10-29 00:38:43,414 Training Epoch [14/40] Iter[93/312]		Loss: 0.1451
2019-10-29 00:38:43,536 Training Epoch [14/40] Iter[94/312]		Loss: 0.1449
2019-10-29 00:38:43,657 Training Epoch [14/40] Iter[95/312]		Loss: 0.1447
2019-10-29 00:38:43,779 Training Epoch [14/40] Iter[96/312]		Loss: 0.1447
2019-10-29 00:38:43,900 Training Epoch [14/40] Iter[97/312]		Loss: 0.1446
2019-10-29 00:38:44,022 Training Epoch [14/40] Iter[98/312]		Loss: 0.1450
2019-10-29 00:38:44,143 Training Epoch [14/40] Iter[99/312]		Loss: 0.1448
2019-10-29 00:38:44,265 Training Epoch [14/40] Iter[100/312]		Loss: 0.1446
2019-10-29 00:38:44,386 Training Epoch [14/40] Iter[101/312]		Loss: 0.1448
2019-10-29 00:38:44,508 Training Epoch [14/40] Iter[102/312]		Loss: 0.1449
2019-10-29 00:38:44,630 Training Epoch [14/40] Iter[103/312]		Loss: 0.1458
2019-10-29 00:38:44,751 Training Epoch [14/40] Iter[104/312]		Loss: 0.1455
2019-10-29 00:38:44,872 Training Epoch [14/40] Iter[105/312]		Loss: 0.1453
2019-10-29 00:38:44,994 Training Epoch [14/40] Iter[106/312]		Loss: 0.1451
2019-10-29 00:38:45,115 Training Epoch [14/40] Iter[107/312]		Loss: 0.1446
2019-10-29 00:38:45,236 Training Epoch [14/40] Iter[108/312]		Loss: 0.1444
2019-10-29 00:38:45,358 Training Epoch [14/40] Iter[109/312]		Loss: 0.1445
2019-10-29 00:38:45,480 Training Epoch [14/40] Iter[110/312]		Loss: 0.1445
2019-10-29 00:38:45,602 Training Epoch [14/40] Iter[111/312]		Loss: 0.1443
2019-10-29 00:38:45,723 Training Epoch [14/40] Iter[112/312]		Loss: 0.1448
2019-10-29 00:38:45,845 Training Epoch [14/40] Iter[113/312]		Loss: 0.1447
2019-10-29 00:38:45,966 Training Epoch [14/40] Iter[114/312]		Loss: 0.1445
2019-10-29 00:38:46,088 Training Epoch [14/40] Iter[115/312]		Loss: 0.1440
2019-10-29 00:38:46,210 Training Epoch [14/40] Iter[116/312]		Loss: 0.1438
2019-10-29 00:38:46,333 Training Epoch [14/40] Iter[117/312]		Loss: 0.1436
2019-10-29 00:38:46,455 Training Epoch [14/40] Iter[118/312]		Loss: 0.1436
2019-10-29 00:38:46,577 Training Epoch [14/40] Iter[119/312]		Loss: 0.1436
2019-10-29 00:38:46,699 Training Epoch [14/40] Iter[120/312]		Loss: 0.1437
2019-10-29 00:38:46,821 Training Epoch [14/40] Iter[121/312]		Loss: 0.1442
2019-10-29 00:38:46,943 Training Epoch [14/40] Iter[122/312]		Loss: 0.1441
2019-10-29 00:38:47,065 Training Epoch [14/40] Iter[123/312]		Loss: 0.1441
2019-10-29 00:38:47,187 Training Epoch [14/40] Iter[124/312]		Loss: 0.1437
2019-10-29 00:38:47,309 Training Epoch [14/40] Iter[125/312]		Loss: 0.1435
2019-10-29 00:38:47,431 Training Epoch [14/40] Iter[126/312]		Loss: 0.1435
2019-10-29 00:38:47,554 Training Epoch [14/40] Iter[127/312]		Loss: 0.1433
2019-10-29 00:38:47,675 Training Epoch [14/40] Iter[128/312]		Loss: 0.1430
2019-10-29 00:38:47,797 Training Epoch [14/40] Iter[129/312]		Loss: 0.1428
2019-10-29 00:38:47,919 Training Epoch [14/40] Iter[130/312]		Loss: 0.1428
2019-10-29 00:38:48,041 Training Epoch [14/40] Iter[131/312]		Loss: 0.1431
2019-10-29 00:38:48,162 Training Epoch [14/40] Iter[132/312]		Loss: 0.1428
2019-10-29 00:38:48,284 Training Epoch [14/40] Iter[133/312]		Loss: 0.1430
2019-10-29 00:38:48,406 Training Epoch [14/40] Iter[134/312]		Loss: 0.1430
2019-10-29 00:38:48,527 Training Epoch [14/40] Iter[135/312]		Loss: 0.1426
2019-10-29 00:38:48,649 Training Epoch [14/40] Iter[136/312]		Loss: 0.1424
2019-10-29 00:38:48,771 Training Epoch [14/40] Iter[137/312]		Loss: 0.1423
2019-10-29 00:38:48,892 Training Epoch [14/40] Iter[138/312]		Loss: 0.1425
2019-10-29 00:38:49,014 Training Epoch [14/40] Iter[139/312]		Loss: 0.1427
2019-10-29 00:38:49,136 Training Epoch [14/40] Iter[140/312]		Loss: 0.1426
2019-10-29 00:38:49,258 Training Epoch [14/40] Iter[141/312]		Loss: 0.1421
2019-10-29 00:38:49,380 Training Epoch [14/40] Iter[142/312]		Loss: 0.1420
2019-10-29 00:38:49,502 Training Epoch [14/40] Iter[143/312]		Loss: 0.1421
2019-10-29 00:38:49,623 Training Epoch [14/40] Iter[144/312]		Loss: 0.1419
2019-10-29 00:38:49,745 Training Epoch [14/40] Iter[145/312]		Loss: 0.1432
2019-10-29 00:38:49,867 Training Epoch [14/40] Iter[146/312]		Loss: 0.1433
2019-10-29 00:38:49,989 Training Epoch [14/40] Iter[147/312]		Loss: 0.1436
2019-10-29 00:38:50,111 Training Epoch [14/40] Iter[148/312]		Loss: 0.1435
2019-10-29 00:38:50,233 Training Epoch [14/40] Iter[149/312]		Loss: 0.1436
2019-10-29 00:38:50,355 Training Epoch [14/40] Iter[150/312]		Loss: 0.1438
2019-10-29 00:38:50,477 Training Epoch [14/40] Iter[151/312]		Loss: 0.1438
2019-10-29 00:38:50,599 Training Epoch [14/40] Iter[152/312]		Loss: 0.1437
2019-10-29 00:38:50,721 Training Epoch [14/40] Iter[153/312]		Loss: 0.1437
2019-10-29 00:38:50,843 Training Epoch [14/40] Iter[154/312]		Loss: 0.1439
2019-10-29 00:38:50,965 Training Epoch [14/40] Iter[155/312]		Loss: 0.1438
2019-10-29 00:38:51,087 Training Epoch [14/40] Iter[156/312]		Loss: 0.1440
2019-10-29 00:38:51,209 Training Epoch [14/40] Iter[157/312]		Loss: 0.1441
2019-10-29 00:38:51,331 Training Epoch [14/40] Iter[158/312]		Loss: 0.1444
2019-10-29 00:38:51,453 Training Epoch [14/40] Iter[159/312]		Loss: 0.1442
2019-10-29 00:38:51,574 Training Epoch [14/40] Iter[160/312]		Loss: 0.1441
2019-10-29 00:38:51,697 Training Epoch [14/40] Iter[161/312]		Loss: 0.1438
2019-10-29 00:38:51,819 Training Epoch [14/40] Iter[162/312]		Loss: 0.1436
2019-10-29 00:38:51,940 Training Epoch [14/40] Iter[163/312]		Loss: 0.1434
2019-10-29 00:38:52,062 Training Epoch [14/40] Iter[164/312]		Loss: 0.1433
2019-10-29 00:38:52,184 Training Epoch [14/40] Iter[165/312]		Loss: 0.1430
2019-10-29 00:38:52,306 Training Epoch [14/40] Iter[166/312]		Loss: 0.1429
2019-10-29 00:38:52,428 Training Epoch [14/40] Iter[167/312]		Loss: 0.1432
2019-10-29 00:38:52,550 Training Epoch [14/40] Iter[168/312]		Loss: 0.1428
2019-10-29 00:38:52,671 Training Epoch [14/40] Iter[169/312]		Loss: 0.1426
2019-10-29 00:38:52,793 Training Epoch [14/40] Iter[170/312]		Loss: 0.1423
2019-10-29 00:38:52,915 Training Epoch [14/40] Iter[171/312]		Loss: 0.1421
2019-10-29 00:38:53,037 Training Epoch [14/40] Iter[172/312]		Loss: 0.1422
2019-10-29 00:38:53,158 Training Epoch [14/40] Iter[173/312]		Loss: 0.1420
2019-10-29 00:38:53,280 Training Epoch [14/40] Iter[174/312]		Loss: 0.1418
2019-10-29 00:38:53,402 Training Epoch [14/40] Iter[175/312]		Loss: 0.1417
2019-10-29 00:38:53,523 Training Epoch [14/40] Iter[176/312]		Loss: 0.1415
2019-10-29 00:38:53,645 Training Epoch [14/40] Iter[177/312]		Loss: 0.1413
2019-10-29 00:38:53,766 Training Epoch [14/40] Iter[178/312]		Loss: 0.1412
2019-10-29 00:38:53,888 Training Epoch [14/40] Iter[179/312]		Loss: 0.1413
2019-10-29 00:38:54,010 Training Epoch [14/40] Iter[180/312]		Loss: 0.1412
2019-10-29 00:38:54,131 Training Epoch [14/40] Iter[181/312]		Loss: 0.1411
2019-10-29 00:38:54,253 Training Epoch [14/40] Iter[182/312]		Loss: 0.1415
2019-10-29 00:38:54,374 Training Epoch [14/40] Iter[183/312]		Loss: 0.1415
2019-10-29 00:38:54,495 Training Epoch [14/40] Iter[184/312]		Loss: 0.1413
2019-10-29 00:38:54,617 Training Epoch [14/40] Iter[185/312]		Loss: 0.1410
2019-10-29 00:38:54,738 Training Epoch [14/40] Iter[186/312]		Loss: 0.1411
2019-10-29 00:38:54,860 Training Epoch [14/40] Iter[187/312]		Loss: 0.1411
2019-10-29 00:38:54,981 Training Epoch [14/40] Iter[188/312]		Loss: 0.1413
2019-10-29 00:38:55,103 Training Epoch [14/40] Iter[189/312]		Loss: 0.1414
2019-10-29 00:38:55,224 Training Epoch [14/40] Iter[190/312]		Loss: 0.1411
2019-10-29 00:38:55,345 Training Epoch [14/40] Iter[191/312]		Loss: 0.1411
2019-10-29 00:38:55,467 Training Epoch [14/40] Iter[192/312]		Loss: 0.1410
2019-10-29 00:38:55,588 Training Epoch [14/40] Iter[193/312]		Loss: 0.1411
2019-10-29 00:38:55,709 Training Epoch [14/40] Iter[194/312]		Loss: 0.1410
2019-10-29 00:38:55,831 Training Epoch [14/40] Iter[195/312]		Loss: 0.1407
2019-10-29 00:38:55,952 Training Epoch [14/40] Iter[196/312]		Loss: 0.1408
2019-10-29 00:38:56,073 Training Epoch [14/40] Iter[197/312]		Loss: 0.1407
2019-10-29 00:38:56,195 Training Epoch [14/40] Iter[198/312]		Loss: 0.1409
2019-10-29 00:38:56,316 Training Epoch [14/40] Iter[199/312]		Loss: 0.1406
2019-10-29 00:38:56,438 Training Epoch [14/40] Iter[200/312]		Loss: 0.1406
2019-10-29 00:38:56,559 Training Epoch [14/40] Iter[201/312]		Loss: 0.1408
2019-10-29 00:38:56,680 Training Epoch [14/40] Iter[202/312]		Loss: 0.1408
2019-10-29 00:38:56,801 Training Epoch [14/40] Iter[203/312]		Loss: 0.1407
2019-10-29 00:38:56,923 Training Epoch [14/40] Iter[204/312]		Loss: 0.1408
2019-10-29 00:38:57,045 Training Epoch [14/40] Iter[205/312]		Loss: 0.1410
2019-10-29 00:38:57,166 Training Epoch [14/40] Iter[206/312]		Loss: 0.1408
2019-10-29 00:38:57,288 Training Epoch [14/40] Iter[207/312]		Loss: 0.1407
2019-10-29 00:38:57,409 Training Epoch [14/40] Iter[208/312]		Loss: 0.1407
2019-10-29 00:38:57,530 Training Epoch [14/40] Iter[209/312]		Loss: 0.1405
2019-10-29 00:38:57,651 Training Epoch [14/40] Iter[210/312]		Loss: 0.1404
2019-10-29 00:38:57,773 Training Epoch [14/40] Iter[211/312]		Loss: 0.1404
2019-10-29 00:38:57,895 Training Epoch [14/40] Iter[212/312]		Loss: 0.1404
2019-10-29 00:38:58,016 Training Epoch [14/40] Iter[213/312]		Loss: 0.1402
2019-10-29 00:38:58,138 Training Epoch [14/40] Iter[214/312]		Loss: 0.1401
2019-10-29 00:38:58,260 Training Epoch [14/40] Iter[215/312]		Loss: 0.1399
2019-10-29 00:38:58,381 Training Epoch [14/40] Iter[216/312]		Loss: 0.1398
2019-10-29 00:38:58,503 Training Epoch [14/40] Iter[217/312]		Loss: 0.1399
2019-10-29 00:38:58,624 Training Epoch [14/40] Iter[218/312]		Loss: 0.1398
2019-10-29 00:38:58,745 Training Epoch [14/40] Iter[219/312]		Loss: 0.1400
2019-10-29 00:38:58,867 Training Epoch [14/40] Iter[220/312]		Loss: 0.1400
2019-10-29 00:38:58,989 Training Epoch [14/40] Iter[221/312]		Loss: 0.1399
2019-10-29 00:38:59,110 Training Epoch [14/40] Iter[222/312]		Loss: 0.1399
2019-10-29 00:38:59,232 Training Epoch [14/40] Iter[223/312]		Loss: 0.1398
2019-10-29 00:38:59,353 Training Epoch [14/40] Iter[224/312]		Loss: 0.1395
2019-10-29 00:38:59,475 Training Epoch [14/40] Iter[225/312]		Loss: 0.1396
2019-10-29 00:38:59,596 Training Epoch [14/40] Iter[226/312]		Loss: 0.1399
2019-10-29 00:38:59,717 Training Epoch [14/40] Iter[227/312]		Loss: 0.1397
2019-10-29 00:38:59,839 Training Epoch [14/40] Iter[228/312]		Loss: 0.1394
2019-10-29 00:38:59,960 Training Epoch [14/40] Iter[229/312]		Loss: 0.1396
2019-10-29 00:39:00,081 Training Epoch [14/40] Iter[230/312]		Loss: 0.1395
2019-10-29 00:39:00,202 Training Epoch [14/40] Iter[231/312]		Loss: 0.1396
2019-10-29 00:39:00,323 Training Epoch [14/40] Iter[232/312]		Loss: 0.1395
2019-10-29 00:39:00,445 Training Epoch [14/40] Iter[233/312]		Loss: 0.1396
2019-10-29 00:39:00,566 Training Epoch [14/40] Iter[234/312]		Loss: 0.1394
2019-10-29 00:39:00,687 Training Epoch [14/40] Iter[235/312]		Loss: 0.1394
2019-10-29 00:39:00,808 Training Epoch [14/40] Iter[236/312]		Loss: 0.1392
2019-10-29 00:39:00,930 Training Epoch [14/40] Iter[237/312]		Loss: 0.1391
2019-10-29 00:39:01,051 Training Epoch [14/40] Iter[238/312]		Loss: 0.1389
2019-10-29 00:39:01,173 Training Epoch [14/40] Iter[239/312]		Loss: 0.1389
2019-10-29 00:39:01,294 Training Epoch [14/40] Iter[240/312]		Loss: 0.1388
2019-10-29 00:39:01,416 Training Epoch [14/40] Iter[241/312]		Loss: 0.1390
2019-10-29 00:39:01,537 Training Epoch [14/40] Iter[242/312]		Loss: 0.1391
2019-10-29 00:39:01,658 Training Epoch [14/40] Iter[243/312]		Loss: 0.1396
2019-10-29 00:39:01,780 Training Epoch [14/40] Iter[244/312]		Loss: 0.1394
2019-10-29 00:39:01,902 Training Epoch [14/40] Iter[245/312]		Loss: 0.1396
2019-10-29 00:39:02,023 Training Epoch [14/40] Iter[246/312]		Loss: 0.1396
2019-10-29 00:39:02,145 Training Epoch [14/40] Iter[247/312]		Loss: 0.1396
2019-10-29 00:39:02,267 Training Epoch [14/40] Iter[248/312]		Loss: 0.1395
2019-10-29 00:39:02,389 Training Epoch [14/40] Iter[249/312]		Loss: 0.1395
2019-10-29 00:39:02,511 Training Epoch [14/40] Iter[250/312]		Loss: 0.1395
2019-10-29 00:39:02,633 Training Epoch [14/40] Iter[251/312]		Loss: 0.1394
2019-10-29 00:39:02,755 Training Epoch [14/40] Iter[252/312]		Loss: 0.1394
2019-10-29 00:39:02,877 Training Epoch [14/40] Iter[253/312]		Loss: 0.1393
2019-10-29 00:39:02,999 Training Epoch [14/40] Iter[254/312]		Loss: 0.1393
2019-10-29 00:39:03,121 Training Epoch [14/40] Iter[255/312]		Loss: 0.1391
2019-10-29 00:39:03,243 Training Epoch [14/40] Iter[256/312]		Loss: 0.1391
2019-10-29 00:39:03,365 Training Epoch [14/40] Iter[257/312]		Loss: 0.1391
2019-10-29 00:39:03,487 Training Epoch [14/40] Iter[258/312]		Loss: 0.1390
2019-10-29 00:39:03,609 Training Epoch [14/40] Iter[259/312]		Loss: 0.1390
2019-10-29 00:39:03,731 Training Epoch [14/40] Iter[260/312]		Loss: 0.1390
2019-10-29 00:39:03,853 Training Epoch [14/40] Iter[261/312]		Loss: 0.1390
2019-10-29 00:39:03,975 Training Epoch [14/40] Iter[262/312]		Loss: 0.1397
2019-10-29 00:39:04,097 Training Epoch [14/40] Iter[263/312]		Loss: 0.1395
2019-10-29 00:39:04,219 Training Epoch [14/40] Iter[264/312]		Loss: 0.1394
2019-10-29 00:39:04,341 Training Epoch [14/40] Iter[265/312]		Loss: 0.1393
2019-10-29 00:39:04,464 Training Epoch [14/40] Iter[266/312]		Loss: 0.1394
2019-10-29 00:39:04,585 Training Epoch [14/40] Iter[267/312]		Loss: 0.1394
2019-10-29 00:39:04,708 Training Epoch [14/40] Iter[268/312]		Loss: 0.1395
2019-10-29 00:39:04,830 Training Epoch [14/40] Iter[269/312]		Loss: 0.1394
2019-10-29 00:39:04,952 Training Epoch [14/40] Iter[270/312]		Loss: 0.1394
2019-10-29 00:39:05,074 Training Epoch [14/40] Iter[271/312]		Loss: 0.1397
2019-10-29 00:39:05,196 Training Epoch [14/40] Iter[272/312]		Loss: 0.1396
2019-10-29 00:39:05,317 Training Epoch [14/40] Iter[273/312]		Loss: 0.1395
2019-10-29 00:39:05,439 Training Epoch [14/40] Iter[274/312]		Loss: 0.1395
2019-10-29 00:39:05,561 Training Epoch [14/40] Iter[275/312]		Loss: 0.1395
2019-10-29 00:39:05,683 Training Epoch [14/40] Iter[276/312]		Loss: 0.1393
2019-10-29 00:39:05,805 Training Epoch [14/40] Iter[277/312]		Loss: 0.1391
2019-10-29 00:39:05,926 Training Epoch [14/40] Iter[278/312]		Loss: 0.1390
2019-10-29 00:39:06,048 Training Epoch [14/40] Iter[279/312]		Loss: 0.1390
2019-10-29 00:39:06,170 Training Epoch [14/40] Iter[280/312]		Loss: 0.1388
2019-10-29 00:39:06,291 Training Epoch [14/40] Iter[281/312]		Loss: 0.1388
2019-10-29 00:39:06,413 Training Epoch [14/40] Iter[282/312]		Loss: 0.1387
2019-10-29 00:39:06,535 Training Epoch [14/40] Iter[283/312]		Loss: 0.1385
2019-10-29 00:39:06,656 Training Epoch [14/40] Iter[284/312]		Loss: 0.1386
2019-10-29 00:39:06,778 Training Epoch [14/40] Iter[285/312]		Loss: 0.1385
2019-10-29 00:39:06,899 Training Epoch [14/40] Iter[286/312]		Loss: 0.1385
2019-10-29 00:39:07,021 Training Epoch [14/40] Iter[287/312]		Loss: 0.1385
2019-10-29 00:39:07,142 Training Epoch [14/40] Iter[288/312]		Loss: 0.1384
2019-10-29 00:39:07,264 Training Epoch [14/40] Iter[289/312]		Loss: 0.1384
2019-10-29 00:39:07,386 Training Epoch [14/40] Iter[290/312]		Loss: 0.1385
2019-10-29 00:39:07,508 Training Epoch [14/40] Iter[291/312]		Loss: 0.1385
2019-10-29 00:39:07,630 Training Epoch [14/40] Iter[292/312]		Loss: 0.1385
2019-10-29 00:39:07,752 Training Epoch [14/40] Iter[293/312]		Loss: 0.1384
2019-10-29 00:39:07,873 Training Epoch [14/40] Iter[294/312]		Loss: 0.1385
2019-10-29 00:39:07,996 Training Epoch [14/40] Iter[295/312]		Loss: 0.1384
2019-10-29 00:39:08,117 Training Epoch [14/40] Iter[296/312]		Loss: 0.1382
2019-10-29 00:39:08,239 Training Epoch [14/40] Iter[297/312]		Loss: 0.1382
2019-10-29 00:39:08,361 Training Epoch [14/40] Iter[298/312]		Loss: 0.1383
2019-10-29 00:39:08,483 Training Epoch [14/40] Iter[299/312]		Loss: 0.1383
2019-10-29 00:39:08,605 Training Epoch [14/40] Iter[300/312]		Loss: 0.1381
2019-10-29 00:39:08,727 Training Epoch [14/40] Iter[301/312]		Loss: 0.1382
2019-10-29 00:39:08,849 Training Epoch [14/40] Iter[302/312]		Loss: 0.1381
2019-10-29 00:39:08,971 Training Epoch [14/40] Iter[303/312]		Loss: 0.1381
2019-10-29 00:39:09,094 Training Epoch [14/40] Iter[304/312]		Loss: 0.1382
2019-10-29 00:39:09,215 Training Epoch [14/40] Iter[305/312]		Loss: 0.1382
2019-10-29 00:39:09,337 Training Epoch [14/40] Iter[306/312]		Loss: 0.1382
2019-10-29 00:39:09,458 Training Epoch [14/40] Iter[307/312]		Loss: 0.1380
2019-10-29 00:39:09,579 Training Epoch [14/40] Iter[308/312]		Loss: 0.1379
2019-10-29 00:39:09,700 Training Epoch [14/40] Iter[309/312]		Loss: 0.1380
2019-10-29 00:39:09,821 Training Epoch [14/40] Iter[310/312]		Loss: 0.1380
2019-10-29 00:39:09,942 Training Epoch [14/40] Iter[311/312]		Loss: 0.1378
2019-10-29 00:39:10,003 Training Epoch [14/40] Iter[312/312]		Loss: 0.1378
2019-10-29 00:39:10,400 Testing Epoch [14/40] Iter[0/62]		Loss: 0.1097
2019-10-29 00:39:10,446 Testing Epoch [14/40] Iter[1/62]		Loss: 0.1340
2019-10-29 00:39:10,482 Testing Epoch [14/40] Iter[2/62]		Loss: 0.1279
2019-10-29 00:39:10,513 Testing Epoch [14/40] Iter[3/62]		Loss: 0.1278
2019-10-29 00:39:10,554 Testing Epoch [14/40] Iter[4/62]		Loss: 0.1241
2019-10-29 00:39:10,586 Testing Epoch [14/40] Iter[5/62]		Loss: 0.1219
2019-10-29 00:39:10,616 Testing Epoch [14/40] Iter[6/62]		Loss: 0.1266
2019-10-29 00:39:10,647 Testing Epoch [14/40] Iter[7/62]		Loss: 0.1328
2019-10-29 00:39:10,686 Testing Epoch [14/40] Iter[8/62]		Loss: 0.1398
2019-10-29 00:39:10,717 Testing Epoch [14/40] Iter[9/62]		Loss: 0.1386
2019-10-29 00:39:10,749 Testing Epoch [14/40] Iter[10/62]		Loss: 0.1370
2019-10-29 00:39:10,780 Testing Epoch [14/40] Iter[11/62]		Loss: 0.1423
2019-10-29 00:39:10,811 Testing Epoch [14/40] Iter[12/62]		Loss: 0.1432
2019-10-29 00:39:10,842 Testing Epoch [14/40] Iter[13/62]		Loss: 0.1453
2019-10-29 00:39:10,873 Testing Epoch [14/40] Iter[14/62]		Loss: 0.1587
2019-10-29 00:39:10,904 Testing Epoch [14/40] Iter[15/62]		Loss: 0.1599
2019-10-29 00:39:10,936 Testing Epoch [14/40] Iter[16/62]		Loss: 0.1583
2019-10-29 00:39:10,967 Testing Epoch [14/40] Iter[17/62]		Loss: 0.1579
2019-10-29 00:39:10,998 Testing Epoch [14/40] Iter[18/62]		Loss: 0.1546
2019-10-29 00:39:11,029 Testing Epoch [14/40] Iter[19/62]		Loss: 0.1523
2019-10-29 00:39:11,060 Testing Epoch [14/40] Iter[20/62]		Loss: 0.1536
2019-10-29 00:39:11,092 Testing Epoch [14/40] Iter[21/62]		Loss: 0.1513
2019-10-29 00:39:11,123 Testing Epoch [14/40] Iter[22/62]		Loss: 0.1511
2019-10-29 00:39:11,154 Testing Epoch [14/40] Iter[23/62]		Loss: 0.1510
2019-10-29 00:39:11,186 Testing Epoch [14/40] Iter[24/62]		Loss: 0.1537
2019-10-29 00:39:11,217 Testing Epoch [14/40] Iter[25/62]		Loss: 0.1526
2019-10-29 00:39:11,248 Testing Epoch [14/40] Iter[26/62]		Loss: 0.1515
2019-10-29 00:39:11,280 Testing Epoch [14/40] Iter[27/62]		Loss: 0.1564
2019-10-29 00:39:11,311 Testing Epoch [14/40] Iter[28/62]		Loss: 0.1582
2019-10-29 00:39:11,342 Testing Epoch [14/40] Iter[29/62]		Loss: 0.1578
2019-10-29 00:39:11,373 Testing Epoch [14/40] Iter[30/62]		Loss: 0.1592
2019-10-29 00:39:11,404 Testing Epoch [14/40] Iter[31/62]		Loss: 0.1592
2019-10-29 00:39:11,435 Testing Epoch [14/40] Iter[32/62]		Loss: 0.1615
2019-10-29 00:39:11,466 Testing Epoch [14/40] Iter[33/62]		Loss: 0.1598
2019-10-29 00:39:11,497 Testing Epoch [14/40] Iter[34/62]		Loss: 0.1609
2019-10-29 00:39:11,528 Testing Epoch [14/40] Iter[35/62]		Loss: 0.1605
2019-10-29 00:39:11,559 Testing Epoch [14/40] Iter[36/62]		Loss: 0.1586
2019-10-29 00:39:11,590 Testing Epoch [14/40] Iter[37/62]		Loss: 0.1582
2019-10-29 00:39:11,621 Testing Epoch [14/40] Iter[38/62]		Loss: 0.1583
2019-10-29 00:39:11,652 Testing Epoch [14/40] Iter[39/62]		Loss: 0.1591
2019-10-29 00:39:11,683 Testing Epoch [14/40] Iter[40/62]		Loss: 0.1599
2019-10-29 00:39:11,714 Testing Epoch [14/40] Iter[41/62]		Loss: 0.1603
2019-10-29 00:39:11,745 Testing Epoch [14/40] Iter[42/62]		Loss: 0.1589
2019-10-29 00:39:11,777 Testing Epoch [14/40] Iter[43/62]		Loss: 0.1581
2019-10-29 00:39:11,808 Testing Epoch [14/40] Iter[44/62]		Loss: 0.1571
2019-10-29 00:39:11,839 Testing Epoch [14/40] Iter[45/62]		Loss: 0.1576
2019-10-29 00:39:11,870 Testing Epoch [14/40] Iter[46/62]		Loss: 0.1576
2019-10-29 00:39:11,901 Testing Epoch [14/40] Iter[47/62]		Loss: 0.1627
2019-10-29 00:39:11,933 Testing Epoch [14/40] Iter[48/62]		Loss: 0.1618
2019-10-29 00:39:11,964 Testing Epoch [14/40] Iter[49/62]		Loss: 0.1631
2019-10-29 00:39:11,995 Testing Epoch [14/40] Iter[50/62]		Loss: 0.1624
2019-10-29 00:39:12,026 Testing Epoch [14/40] Iter[51/62]		Loss: 0.1623
2019-10-29 00:39:12,057 Testing Epoch [14/40] Iter[52/62]		Loss: 0.1609
2019-10-29 00:39:12,088 Testing Epoch [14/40] Iter[53/62]		Loss: 0.1606
2019-10-29 00:39:12,119 Testing Epoch [14/40] Iter[54/62]		Loss: 0.1598
2019-10-29 00:39:12,150 Testing Epoch [14/40] Iter[55/62]		Loss: 0.1597
2019-10-29 00:39:12,181 Testing Epoch [14/40] Iter[56/62]		Loss: 0.1592
2019-10-29 00:39:12,212 Testing Epoch [14/40] Iter[57/62]		Loss: 0.1588
2019-10-29 00:39:12,243 Testing Epoch [14/40] Iter[58/62]		Loss: 0.1583
2019-10-29 00:39:12,273 Testing Epoch [14/40] Iter[59/62]		Loss: 0.1583
2019-10-29 00:39:12,304 Testing Epoch [14/40] Iter[60/62]		Loss: 0.1573
2019-10-29 00:39:12,335 Testing Epoch [14/40] Iter[61/62]		Loss: 0.1572
2019-10-29 00:39:12,353 Testing Epoch [14/40] Iter[62/62]		Loss: 0.1585
2019-10-29 00:39:12,419 Saving the Model
2019-10-29 00:39:12,870 Training Epoch [15/40] Iter[0/312]		Loss: 0.2308
2019-10-29 00:39:12,991 Training Epoch [15/40] Iter[1/312]		Loss: 0.1811
2019-10-29 00:39:13,115 Training Epoch [15/40] Iter[2/312]		Loss: 0.1761
2019-10-29 00:39:13,236 Training Epoch [15/40] Iter[3/312]		Loss: 0.1779
2019-10-29 00:39:13,357 Training Epoch [15/40] Iter[4/312]		Loss: 0.1664
2019-10-29 00:39:13,481 Training Epoch [15/40] Iter[5/312]		Loss: 0.1643
2019-10-29 00:39:13,601 Training Epoch [15/40] Iter[6/312]		Loss: 0.1666
2019-10-29 00:39:13,722 Training Epoch [15/40] Iter[7/312]		Loss: 0.1626
2019-10-29 00:39:13,843 Training Epoch [15/40] Iter[8/312]		Loss: 0.1691
2019-10-29 00:39:13,965 Training Epoch [15/40] Iter[9/312]		Loss: 0.1651
2019-10-29 00:39:14,087 Training Epoch [15/40] Iter[10/312]		Loss: 0.1600
2019-10-29 00:39:14,209 Training Epoch [15/40] Iter[11/312]		Loss: 0.1553
2019-10-29 00:39:14,332 Training Epoch [15/40] Iter[12/312]		Loss: 0.1552
2019-10-29 00:39:14,454 Training Epoch [15/40] Iter[13/312]		Loss: 0.1540
2019-10-29 00:39:14,576 Training Epoch [15/40] Iter[14/312]		Loss: 0.1523
2019-10-29 00:39:14,697 Training Epoch [15/40] Iter[15/312]		Loss: 0.1517
2019-10-29 00:39:14,819 Training Epoch [15/40] Iter[16/312]		Loss: 0.1502
2019-10-29 00:39:14,941 Training Epoch [15/40] Iter[17/312]		Loss: 0.1509
2019-10-29 00:39:15,065 Training Epoch [15/40] Iter[18/312]		Loss: 0.1497
2019-10-29 00:39:15,187 Training Epoch [15/40] Iter[19/312]		Loss: 0.1491
2019-10-29 00:39:15,309 Training Epoch [15/40] Iter[20/312]		Loss: 0.1472
2019-10-29 00:39:15,430 Training Epoch [15/40] Iter[21/312]		Loss: 0.1482
2019-10-29 00:39:15,552 Training Epoch [15/40] Iter[22/312]		Loss: 0.1464
2019-10-29 00:39:15,673 Training Epoch [15/40] Iter[23/312]		Loss: 0.1438
2019-10-29 00:39:15,795 Training Epoch [15/40] Iter[24/312]		Loss: 0.1427
2019-10-29 00:39:15,917 Training Epoch [15/40] Iter[25/312]		Loss: 0.1442
2019-10-29 00:39:16,038 Training Epoch [15/40] Iter[26/312]		Loss: 0.1416
2019-10-29 00:39:16,160 Training Epoch [15/40] Iter[27/312]		Loss: 0.1412
2019-10-29 00:39:16,282 Training Epoch [15/40] Iter[28/312]		Loss: 0.1399
2019-10-29 00:39:16,404 Training Epoch [15/40] Iter[29/312]		Loss: 0.1392
2019-10-29 00:39:16,525 Training Epoch [15/40] Iter[30/312]		Loss: 0.1393
2019-10-29 00:39:16,648 Training Epoch [15/40] Iter[31/312]		Loss: 0.1383
2019-10-29 00:39:16,769 Training Epoch [15/40] Iter[32/312]		Loss: 0.1403
2019-10-29 00:39:16,891 Training Epoch [15/40] Iter[33/312]		Loss: 0.1390
2019-10-29 00:39:17,013 Training Epoch [15/40] Iter[34/312]		Loss: 0.1395
2019-10-29 00:39:17,134 Training Epoch [15/40] Iter[35/312]		Loss: 0.1401
2019-10-29 00:39:17,256 Training Epoch [15/40] Iter[36/312]		Loss: 0.1392
2019-10-29 00:39:17,378 Training Epoch [15/40] Iter[37/312]		Loss: 0.1400
2019-10-29 00:39:17,499 Training Epoch [15/40] Iter[38/312]		Loss: 0.1390
2019-10-29 00:39:17,621 Training Epoch [15/40] Iter[39/312]		Loss: 0.1392
2019-10-29 00:39:17,743 Training Epoch [15/40] Iter[40/312]		Loss: 0.1385
2019-10-29 00:39:17,865 Training Epoch [15/40] Iter[41/312]		Loss: 0.1403
2019-10-29 00:39:17,987 Training Epoch [15/40] Iter[42/312]		Loss: 0.1413
2019-10-29 00:39:18,108 Training Epoch [15/40] Iter[43/312]		Loss: 0.1408
2019-10-29 00:39:18,230 Training Epoch [15/40] Iter[44/312]		Loss: 0.1408
2019-10-29 00:39:18,352 Training Epoch [15/40] Iter[45/312]		Loss: 0.1401
2019-10-29 00:39:18,474 Training Epoch [15/40] Iter[46/312]		Loss: 0.1400
2019-10-29 00:39:18,596 Training Epoch [15/40] Iter[47/312]		Loss: 0.1400
2019-10-29 00:39:18,718 Training Epoch [15/40] Iter[48/312]		Loss: 0.1395
2019-10-29 00:39:18,840 Training Epoch [15/40] Iter[49/312]		Loss: 0.1383
2019-10-29 00:39:18,961 Training Epoch [15/40] Iter[50/312]		Loss: 0.1375
2019-10-29 00:39:19,083 Training Epoch [15/40] Iter[51/312]		Loss: 0.1376
2019-10-29 00:39:19,205 Training Epoch [15/40] Iter[52/312]		Loss: 0.1370
2019-10-29 00:39:19,327 Training Epoch [15/40] Iter[53/312]		Loss: 0.1365
2019-10-29 00:39:19,449 Training Epoch [15/40] Iter[54/312]		Loss: 0.1366
2019-10-29 00:39:19,571 Training Epoch [15/40] Iter[55/312]		Loss: 0.1365
2019-10-29 00:39:19,697 Training Epoch [15/40] Iter[56/312]		Loss: 0.1360
2019-10-29 00:39:19,819 Training Epoch [15/40] Iter[57/312]		Loss: 0.1365
2019-10-29 00:39:19,941 Training Epoch [15/40] Iter[58/312]		Loss: 0.1360
2019-10-29 00:39:20,063 Training Epoch [15/40] Iter[59/312]		Loss: 0.1363
2019-10-29 00:39:20,185 Training Epoch [15/40] Iter[60/312]		Loss: 0.1371
2019-10-29 00:39:20,307 Training Epoch [15/40] Iter[61/312]		Loss: 0.1376
2019-10-29 00:39:20,429 Training Epoch [15/40] Iter[62/312]		Loss: 0.1374
2019-10-29 00:39:20,550 Training Epoch [15/40] Iter[63/312]		Loss: 0.1374
2019-10-29 00:39:20,672 Training Epoch [15/40] Iter[64/312]		Loss: 0.1370
2019-10-29 00:39:20,794 Training Epoch [15/40] Iter[65/312]		Loss: 0.1372
2019-10-29 00:39:20,916 Training Epoch [15/40] Iter[66/312]		Loss: 0.1376
2019-10-29 00:39:21,037 Training Epoch [15/40] Iter[67/312]		Loss: 0.1372
2019-10-29 00:39:21,160 Training Epoch [15/40] Iter[68/312]		Loss: 0.1369
2019-10-29 00:39:21,284 Training Epoch [15/40] Iter[69/312]		Loss: 0.1365
2019-10-29 00:39:21,406 Training Epoch [15/40] Iter[70/312]		Loss: 0.1360
2019-10-29 00:39:21,528 Training Epoch [15/40] Iter[71/312]		Loss: 0.1363
2019-10-29 00:39:21,650 Training Epoch [15/40] Iter[72/312]		Loss: 0.1364
2019-10-29 00:39:21,772 Training Epoch [15/40] Iter[73/312]		Loss: 0.1363
2019-10-29 00:39:21,894 Training Epoch [15/40] Iter[74/312]		Loss: 0.1356
2019-10-29 00:39:22,016 Training Epoch [15/40] Iter[75/312]		Loss: 0.1354
2019-10-29 00:39:22,138 Training Epoch [15/40] Iter[76/312]		Loss: 0.1363
2019-10-29 00:39:22,260 Training Epoch [15/40] Iter[77/312]		Loss: 0.1368
2019-10-29 00:39:22,382 Training Epoch [15/40] Iter[78/312]		Loss: 0.1371
2019-10-29 00:39:22,504 Training Epoch [15/40] Iter[79/312]		Loss: 0.1369
2019-10-29 00:39:22,626 Training Epoch [15/40] Iter[80/312]		Loss: 0.1368
2019-10-29 00:39:22,748 Training Epoch [15/40] Iter[81/312]		Loss: 0.1361
2019-10-29 00:39:22,869 Training Epoch [15/40] Iter[82/312]		Loss: 0.1355
2019-10-29 00:39:22,991 Training Epoch [15/40] Iter[83/312]		Loss: 0.1352
2019-10-29 00:39:23,113 Training Epoch [15/40] Iter[84/312]		Loss: 0.1354
2019-10-29 00:39:23,236 Training Epoch [15/40] Iter[85/312]		Loss: 0.1354
2019-10-29 00:39:23,358 Training Epoch [15/40] Iter[86/312]		Loss: 0.1359
2019-10-29 00:39:23,480 Training Epoch [15/40] Iter[87/312]		Loss: 0.1356
2019-10-29 00:39:23,602 Training Epoch [15/40] Iter[88/312]		Loss: 0.1353
2019-10-29 00:39:23,724 Training Epoch [15/40] Iter[89/312]		Loss: 0.1349
2019-10-29 00:39:23,846 Training Epoch [15/40] Iter[90/312]		Loss: 0.1351
2019-10-29 00:39:23,968 Training Epoch [15/40] Iter[91/312]		Loss: 0.1347
2019-10-29 00:39:24,089 Training Epoch [15/40] Iter[92/312]		Loss: 0.1343
2019-10-29 00:39:24,211 Training Epoch [15/40] Iter[93/312]		Loss: 0.1344
2019-10-29 00:39:24,333 Training Epoch [15/40] Iter[94/312]		Loss: 0.1340
2019-10-29 00:39:24,455 Training Epoch [15/40] Iter[95/312]		Loss: 0.1341
2019-10-29 00:39:24,577 Training Epoch [15/40] Iter[96/312]		Loss: 0.1337
2019-10-29 00:39:24,699 Training Epoch [15/40] Iter[97/312]		Loss: 0.1341
2019-10-29 00:39:24,821 Training Epoch [15/40] Iter[98/312]		Loss: 0.1341
2019-10-29 00:39:24,943 Training Epoch [15/40] Iter[99/312]		Loss: 0.1348
2019-10-29 00:39:25,065 Training Epoch [15/40] Iter[100/312]		Loss: 0.1349
2019-10-29 00:39:25,186 Training Epoch [15/40] Iter[101/312]		Loss: 0.1354
2019-10-29 00:39:25,308 Training Epoch [15/40] Iter[102/312]		Loss: 0.1353
2019-10-29 00:39:25,431 Training Epoch [15/40] Iter[103/312]		Loss: 0.1353
2019-10-29 00:39:25,552 Training Epoch [15/40] Iter[104/312]		Loss: 0.1351
2019-10-29 00:39:25,675 Training Epoch [15/40] Iter[105/312]		Loss: 0.1348
2019-10-29 00:39:25,797 Training Epoch [15/40] Iter[106/312]		Loss: 0.1348
2019-10-29 00:39:25,918 Training Epoch [15/40] Iter[107/312]		Loss: 0.1346
2019-10-29 00:39:26,041 Training Epoch [15/40] Iter[108/312]		Loss: 0.1346
2019-10-29 00:39:26,163 Training Epoch [15/40] Iter[109/312]		Loss: 0.1345
2019-10-29 00:39:26,285 Training Epoch [15/40] Iter[110/312]		Loss: 0.1346
2019-10-29 00:39:26,408 Training Epoch [15/40] Iter[111/312]		Loss: 0.1343
2019-10-29 00:39:26,530 Training Epoch [15/40] Iter[112/312]		Loss: 0.1339
2019-10-29 00:39:26,651 Training Epoch [15/40] Iter[113/312]		Loss: 0.1340
2019-10-29 00:39:26,774 Training Epoch [15/40] Iter[114/312]		Loss: 0.1337
2019-10-29 00:39:26,896 Training Epoch [15/40] Iter[115/312]		Loss: 0.1338
2019-10-29 00:39:27,017 Training Epoch [15/40] Iter[116/312]		Loss: 0.1339
2019-10-29 00:39:27,139 Training Epoch [15/40] Iter[117/312]		Loss: 0.1337
2019-10-29 00:39:27,261 Training Epoch [15/40] Iter[118/312]		Loss: 0.1338
2019-10-29 00:39:27,383 Training Epoch [15/40] Iter[119/312]		Loss: 0.1337
2019-10-29 00:39:27,505 Training Epoch [15/40] Iter[120/312]		Loss: 0.1340
2019-10-29 00:39:27,627 Training Epoch [15/40] Iter[121/312]		Loss: 0.1340
2019-10-29 00:39:27,749 Training Epoch [15/40] Iter[122/312]		Loss: 0.1341
2019-10-29 00:39:27,872 Training Epoch [15/40] Iter[123/312]		Loss: 0.1341
2019-10-29 00:39:27,993 Training Epoch [15/40] Iter[124/312]		Loss: 0.1343
2019-10-29 00:39:28,115 Training Epoch [15/40] Iter[125/312]		Loss: 0.1342
2019-10-29 00:39:28,238 Training Epoch [15/40] Iter[126/312]		Loss: 0.1343
2019-10-29 00:39:28,360 Training Epoch [15/40] Iter[127/312]		Loss: 0.1341
2019-10-29 00:39:28,482 Training Epoch [15/40] Iter[128/312]		Loss: 0.1344
2019-10-29 00:39:28,604 Training Epoch [15/40] Iter[129/312]		Loss: 0.1343
2019-10-29 00:39:28,726 Training Epoch [15/40] Iter[130/312]		Loss: 0.1345
2019-10-29 00:39:28,848 Training Epoch [15/40] Iter[131/312]		Loss: 0.1346
2019-10-29 00:39:28,970 Training Epoch [15/40] Iter[132/312]		Loss: 0.1343
2019-10-29 00:39:29,092 Training Epoch [15/40] Iter[133/312]		Loss: 0.1345
2019-10-29 00:39:29,214 Training Epoch [15/40] Iter[134/312]		Loss: 0.1346
2019-10-29 00:39:29,336 Training Epoch [15/40] Iter[135/312]		Loss: 0.1344
2019-10-29 00:39:29,458 Training Epoch [15/40] Iter[136/312]		Loss: 0.1340
2019-10-29 00:39:29,580 Training Epoch [15/40] Iter[137/312]		Loss: 0.1342
2019-10-29 00:39:29,702 Training Epoch [15/40] Iter[138/312]		Loss: 0.1341
2019-10-29 00:39:29,823 Training Epoch [15/40] Iter[139/312]		Loss: 0.1339
2019-10-29 00:39:29,945 Training Epoch [15/40] Iter[140/312]		Loss: 0.1341
2019-10-29 00:39:30,067 Training Epoch [15/40] Iter[141/312]		Loss: 0.1338
2019-10-29 00:39:30,190 Training Epoch [15/40] Iter[142/312]		Loss: 0.1340
2019-10-29 00:39:30,312 Training Epoch [15/40] Iter[143/312]		Loss: 0.1344
2019-10-29 00:39:30,434 Training Epoch [15/40] Iter[144/312]		Loss: 0.1344
2019-10-29 00:39:30,556 Training Epoch [15/40] Iter[145/312]		Loss: 0.1345
2019-10-29 00:39:30,677 Training Epoch [15/40] Iter[146/312]		Loss: 0.1346
2019-10-29 00:39:30,799 Training Epoch [15/40] Iter[147/312]		Loss: 0.1345
2019-10-29 00:39:30,921 Training Epoch [15/40] Iter[148/312]		Loss: 0.1345
2019-10-29 00:39:31,043 Training Epoch [15/40] Iter[149/312]		Loss: 0.1343
2019-10-29 00:39:31,165 Training Epoch [15/40] Iter[150/312]		Loss: 0.1343
2019-10-29 00:39:31,287 Training Epoch [15/40] Iter[151/312]		Loss: 0.1340
2019-10-29 00:39:31,409 Training Epoch [15/40] Iter[152/312]		Loss: 0.1339
2019-10-29 00:39:31,531 Training Epoch [15/40] Iter[153/312]		Loss: 0.1339
2019-10-29 00:39:31,653 Training Epoch [15/40] Iter[154/312]		Loss: 0.1343
2019-10-29 00:39:31,775 Training Epoch [15/40] Iter[155/312]		Loss: 0.1344
2019-10-29 00:39:31,897 Training Epoch [15/40] Iter[156/312]		Loss: 0.1344
2019-10-29 00:39:32,019 Training Epoch [15/40] Iter[157/312]		Loss: 0.1347
2019-10-29 00:39:32,141 Training Epoch [15/40] Iter[158/312]		Loss: 0.1345
2019-10-29 00:39:32,263 Training Epoch [15/40] Iter[159/312]		Loss: 0.1347
2019-10-29 00:39:32,385 Training Epoch [15/40] Iter[160/312]		Loss: 0.1352
2019-10-29 00:39:32,507 Training Epoch [15/40] Iter[161/312]		Loss: 0.1352
2019-10-29 00:39:32,629 Training Epoch [15/40] Iter[162/312]		Loss: 0.1350
2019-10-29 00:39:32,751 Training Epoch [15/40] Iter[163/312]		Loss: 0.1348
2019-10-29 00:39:32,873 Training Epoch [15/40] Iter[164/312]		Loss: 0.1346
2019-10-29 00:39:32,995 Training Epoch [15/40] Iter[165/312]		Loss: 0.1346
2019-10-29 00:39:33,117 Training Epoch [15/40] Iter[166/312]		Loss: 0.1347
2019-10-29 00:39:33,239 Training Epoch [15/40] Iter[167/312]		Loss: 0.1343
2019-10-29 00:39:33,361 Training Epoch [15/40] Iter[168/312]		Loss: 0.1340
2019-10-29 00:39:33,482 Training Epoch [15/40] Iter[169/312]		Loss: 0.1340
2019-10-29 00:39:33,604 Training Epoch [15/40] Iter[170/312]		Loss: 0.1343
2019-10-29 00:39:33,725 Training Epoch [15/40] Iter[171/312]		Loss: 0.1342
2019-10-29 00:39:33,847 Training Epoch [15/40] Iter[172/312]		Loss: 0.1341
2019-10-29 00:39:33,968 Training Epoch [15/40] Iter[173/312]		Loss: 0.1338
2019-10-29 00:39:34,090 Training Epoch [15/40] Iter[174/312]		Loss: 0.1336
2019-10-29 00:39:34,212 Training Epoch [15/40] Iter[175/312]		Loss: 0.1339
2019-10-29 00:39:34,334 Training Epoch [15/40] Iter[176/312]		Loss: 0.1340
2019-10-29 00:39:34,456 Training Epoch [15/40] Iter[177/312]		Loss: 0.1337
2019-10-29 00:39:34,578 Training Epoch [15/40] Iter[178/312]		Loss: 0.1337
2019-10-29 00:39:34,700 Training Epoch [15/40] Iter[179/312]		Loss: 0.1336
2019-10-29 00:39:34,822 Training Epoch [15/40] Iter[180/312]		Loss: 0.1334
2019-10-29 00:39:34,944 Training Epoch [15/40] Iter[181/312]		Loss: 0.1335
2019-10-29 00:39:35,066 Training Epoch [15/40] Iter[182/312]		Loss: 0.1336
2019-10-29 00:39:35,187 Training Epoch [15/40] Iter[183/312]		Loss: 0.1336
2019-10-29 00:39:35,310 Training Epoch [15/40] Iter[184/312]		Loss: 0.1336
2019-10-29 00:39:35,432 Training Epoch [15/40] Iter[185/312]		Loss: 0.1334
2019-10-29 00:39:35,554 Training Epoch [15/40] Iter[186/312]		Loss: 0.1334
2019-10-29 00:39:35,675 Training Epoch [15/40] Iter[187/312]		Loss: 0.1332
2019-10-29 00:39:35,797 Training Epoch [15/40] Iter[188/312]		Loss: 0.1333
2019-10-29 00:39:35,919 Training Epoch [15/40] Iter[189/312]		Loss: 0.1335
2019-10-29 00:39:36,041 Training Epoch [15/40] Iter[190/312]		Loss: 0.1339
2019-10-29 00:39:36,163 Training Epoch [15/40] Iter[191/312]		Loss: 0.1339
2019-10-29 00:39:36,284 Training Epoch [15/40] Iter[192/312]		Loss: 0.1336
2019-10-29 00:39:36,406 Training Epoch [15/40] Iter[193/312]		Loss: 0.1334
2019-10-29 00:39:36,528 Training Epoch [15/40] Iter[194/312]		Loss: 0.1334
2019-10-29 00:39:36,650 Training Epoch [15/40] Iter[195/312]		Loss: 0.1332
2019-10-29 00:39:36,772 Training Epoch [15/40] Iter[196/312]		Loss: 0.1331
2019-10-29 00:39:36,894 Training Epoch [15/40] Iter[197/312]		Loss: 0.1330
2019-10-29 00:39:37,016 Training Epoch [15/40] Iter[198/312]		Loss: 0.1330
2019-10-29 00:39:37,137 Training Epoch [15/40] Iter[199/312]		Loss: 0.1332
2019-10-29 00:39:37,259 Training Epoch [15/40] Iter[200/312]		Loss: 0.1330
2019-10-29 00:39:37,381 Training Epoch [15/40] Iter[201/312]		Loss: 0.1327
2019-10-29 00:39:37,503 Training Epoch [15/40] Iter[202/312]		Loss: 0.1326
2019-10-29 00:39:37,626 Training Epoch [15/40] Iter[203/312]		Loss: 0.1327
2019-10-29 00:39:37,747 Training Epoch [15/40] Iter[204/312]		Loss: 0.1327
2019-10-29 00:39:37,869 Training Epoch [15/40] Iter[205/312]		Loss: 0.1325
2019-10-29 00:39:37,991 Training Epoch [15/40] Iter[206/312]		Loss: 0.1325
2019-10-29 00:39:38,113 Training Epoch [15/40] Iter[207/312]		Loss: 0.1323
2019-10-29 00:39:38,235 Training Epoch [15/40] Iter[208/312]		Loss: 0.1327
2019-10-29 00:39:38,357 Training Epoch [15/40] Iter[209/312]		Loss: 0.1327
2019-10-29 00:39:38,479 Training Epoch [15/40] Iter[210/312]		Loss: 0.1327
2019-10-29 00:39:38,601 Training Epoch [15/40] Iter[211/312]		Loss: 0.1325
2019-10-29 00:39:38,723 Training Epoch [15/40] Iter[212/312]		Loss: 0.1324
2019-10-29 00:39:38,845 Training Epoch [15/40] Iter[213/312]		Loss: 0.1324
2019-10-29 00:39:38,967 Training Epoch [15/40] Iter[214/312]		Loss: 0.1324
2019-10-29 00:39:39,089 Training Epoch [15/40] Iter[215/312]		Loss: 0.1322
2019-10-29 00:39:39,210 Training Epoch [15/40] Iter[216/312]		Loss: 0.1323
2019-10-29 00:39:39,332 Training Epoch [15/40] Iter[217/312]		Loss: 0.1321
2019-10-29 00:39:39,454 Training Epoch [15/40] Iter[218/312]		Loss: 0.1322
2019-10-29 00:39:39,576 Training Epoch [15/40] Iter[219/312]		Loss: 0.1322
2019-10-29 00:39:39,698 Training Epoch [15/40] Iter[220/312]		Loss: 0.1321
2019-10-29 00:39:39,819 Training Epoch [15/40] Iter[221/312]		Loss: 0.1322
2019-10-29 00:39:39,941 Training Epoch [15/40] Iter[222/312]		Loss: 0.1322
2019-10-29 00:39:40,063 Training Epoch [15/40] Iter[223/312]		Loss: 0.1320
2019-10-29 00:39:40,184 Training Epoch [15/40] Iter[224/312]		Loss: 0.1321
2019-10-29 00:39:40,306 Training Epoch [15/40] Iter[225/312]		Loss: 0.1321
2019-10-29 00:39:40,429 Training Epoch [15/40] Iter[226/312]		Loss: 0.1321
2019-10-29 00:39:40,550 Training Epoch [15/40] Iter[227/312]		Loss: 0.1320
2019-10-29 00:39:40,672 Training Epoch [15/40] Iter[228/312]		Loss: 0.1319
2019-10-29 00:39:40,794 Training Epoch [15/40] Iter[229/312]		Loss: 0.1319
2019-10-29 00:39:40,916 Training Epoch [15/40] Iter[230/312]		Loss: 0.1317
2019-10-29 00:39:41,038 Training Epoch [15/40] Iter[231/312]		Loss: 0.1317
2019-10-29 00:39:41,160 Training Epoch [15/40] Iter[232/312]		Loss: 0.1319
2019-10-29 00:39:41,282 Training Epoch [15/40] Iter[233/312]		Loss: 0.1318
2019-10-29 00:39:41,404 Training Epoch [15/40] Iter[234/312]		Loss: 0.1316
2019-10-29 00:39:41,525 Training Epoch [15/40] Iter[235/312]		Loss: 0.1317
2019-10-29 00:39:41,647 Training Epoch [15/40] Iter[236/312]		Loss: 0.1317
2019-10-29 00:39:41,768 Training Epoch [15/40] Iter[237/312]		Loss: 0.1317
2019-10-29 00:39:41,890 Training Epoch [15/40] Iter[238/312]		Loss: 0.1318
2019-10-29 00:39:42,012 Training Epoch [15/40] Iter[239/312]		Loss: 0.1320
2019-10-29 00:39:42,133 Training Epoch [15/40] Iter[240/312]		Loss: 0.1320
2019-10-29 00:39:42,255 Training Epoch [15/40] Iter[241/312]		Loss: 0.1321
2019-10-29 00:39:42,377 Training Epoch [15/40] Iter[242/312]		Loss: 0.1321
2019-10-29 00:39:42,499 Training Epoch [15/40] Iter[243/312]		Loss: 0.1320
2019-10-29 00:39:42,620 Training Epoch [15/40] Iter[244/312]		Loss: 0.1320
2019-10-29 00:39:42,742 Training Epoch [15/40] Iter[245/312]		Loss: 0.1321
2019-10-29 00:39:42,864 Training Epoch [15/40] Iter[246/312]		Loss: 0.1322
2019-10-29 00:39:42,986 Training Epoch [15/40] Iter[247/312]		Loss: 0.1320
2019-10-29 00:39:43,108 Training Epoch [15/40] Iter[248/312]		Loss: 0.1321
2019-10-29 00:39:43,230 Training Epoch [15/40] Iter[249/312]		Loss: 0.1322
2019-10-29 00:39:43,352 Training Epoch [15/40] Iter[250/312]		Loss: 0.1323
2019-10-29 00:39:43,474 Training Epoch [15/40] Iter[251/312]		Loss: 0.1327
2019-10-29 00:39:43,600 Training Epoch [15/40] Iter[252/312]		Loss: 0.1328
2019-10-29 00:39:43,722 Training Epoch [15/40] Iter[253/312]		Loss: 0.1327
2019-10-29 00:39:43,844 Training Epoch [15/40] Iter[254/312]		Loss: 0.1327
2019-10-29 00:39:43,966 Training Epoch [15/40] Iter[255/312]		Loss: 0.1327
2019-10-29 00:39:44,088 Training Epoch [15/40] Iter[256/312]		Loss: 0.1327
2019-10-29 00:39:44,210 Training Epoch [15/40] Iter[257/312]		Loss: 0.1328
2019-10-29 00:39:44,332 Training Epoch [15/40] Iter[258/312]		Loss: 0.1327
2019-10-29 00:39:44,455 Training Epoch [15/40] Iter[259/312]		Loss: 0.1327
2019-10-29 00:39:44,577 Training Epoch [15/40] Iter[260/312]		Loss: 0.1328
2019-10-29 00:39:44,699 Training Epoch [15/40] Iter[261/312]		Loss: 0.1331
2019-10-29 00:39:44,821 Training Epoch [15/40] Iter[262/312]		Loss: 0.1332
2019-10-29 00:39:44,942 Training Epoch [15/40] Iter[263/312]		Loss: 0.1335
2019-10-29 00:39:45,064 Training Epoch [15/40] Iter[264/312]		Loss: 0.1336
2019-10-29 00:39:45,186 Training Epoch [15/40] Iter[265/312]		Loss: 0.1335
2019-10-29 00:39:45,308 Training Epoch [15/40] Iter[266/312]		Loss: 0.1335
2019-10-29 00:39:45,430 Training Epoch [15/40] Iter[267/312]		Loss: 0.1333
2019-10-29 00:39:45,552 Training Epoch [15/40] Iter[268/312]		Loss: 0.1333
2019-10-29 00:39:45,674 Training Epoch [15/40] Iter[269/312]		Loss: 0.1333
2019-10-29 00:39:45,796 Training Epoch [15/40] Iter[270/312]		Loss: 0.1335
2019-10-29 00:39:45,918 Training Epoch [15/40] Iter[271/312]		Loss: 0.1335
2019-10-29 00:39:46,040 Training Epoch [15/40] Iter[272/312]		Loss: 0.1337
2019-10-29 00:39:46,162 Training Epoch [15/40] Iter[273/312]		Loss: 0.1339
2019-10-29 00:39:46,284 Training Epoch [15/40] Iter[274/312]		Loss: 0.1338
2019-10-29 00:39:46,407 Training Epoch [15/40] Iter[275/312]		Loss: 0.1339
2019-10-29 00:39:46,528 Training Epoch [15/40] Iter[276/312]		Loss: 0.1341
2019-10-29 00:39:46,650 Training Epoch [15/40] Iter[277/312]		Loss: 0.1340
2019-10-29 00:39:46,772 Training Epoch [15/40] Iter[278/312]		Loss: 0.1340
2019-10-29 00:39:46,894 Training Epoch [15/40] Iter[279/312]		Loss: 0.1341
2019-10-29 00:39:47,016 Training Epoch [15/40] Iter[280/312]		Loss: 0.1339
2019-10-29 00:39:47,138 Training Epoch [15/40] Iter[281/312]		Loss: 0.1339
2019-10-29 00:39:47,260 Training Epoch [15/40] Iter[282/312]		Loss: 0.1340
2019-10-29 00:39:47,382 Training Epoch [15/40] Iter[283/312]		Loss: 0.1340
2019-10-29 00:39:47,504 Training Epoch [15/40] Iter[284/312]		Loss: 0.1339
2019-10-29 00:39:47,626 Training Epoch [15/40] Iter[285/312]		Loss: 0.1342
2019-10-29 00:39:47,748 Training Epoch [15/40] Iter[286/312]		Loss: 0.1343
2019-10-29 00:39:47,870 Training Epoch [15/40] Iter[287/312]		Loss: 0.1346
2019-10-29 00:39:47,992 Training Epoch [15/40] Iter[288/312]		Loss: 0.1346
2019-10-29 00:39:48,114 Training Epoch [15/40] Iter[289/312]		Loss: 0.1346
2019-10-29 00:39:48,236 Training Epoch [15/40] Iter[290/312]		Loss: 0.1345
2019-10-29 00:39:48,358 Training Epoch [15/40] Iter[291/312]		Loss: 0.1346
2019-10-29 00:39:48,480 Training Epoch [15/40] Iter[292/312]		Loss: 0.1345
2019-10-29 00:39:48,603 Training Epoch [15/40] Iter[293/312]		Loss: 0.1347
2019-10-29 00:39:48,725 Training Epoch [15/40] Iter[294/312]		Loss: 0.1345
2019-10-29 00:39:48,847 Training Epoch [15/40] Iter[295/312]		Loss: 0.1343
2019-10-29 00:39:48,969 Training Epoch [15/40] Iter[296/312]		Loss: 0.1343
2019-10-29 00:39:49,090 Training Epoch [15/40] Iter[297/312]		Loss: 0.1343
2019-10-29 00:39:49,213 Training Epoch [15/40] Iter[298/312]		Loss: 0.1342
2019-10-29 00:39:49,335 Training Epoch [15/40] Iter[299/312]		Loss: 0.1345
2019-10-29 00:39:49,457 Training Epoch [15/40] Iter[300/312]		Loss: 0.1347
2019-10-29 00:39:49,578 Training Epoch [15/40] Iter[301/312]		Loss: 0.1347
2019-10-29 00:39:49,700 Training Epoch [15/40] Iter[302/312]		Loss: 0.1347
2019-10-29 00:39:49,822 Training Epoch [15/40] Iter[303/312]		Loss: 0.1347
2019-10-29 00:39:49,944 Training Epoch [15/40] Iter[304/312]		Loss: 0.1348
2019-10-29 00:39:50,065 Training Epoch [15/40] Iter[305/312]		Loss: 0.1348
2019-10-29 00:39:50,186 Training Epoch [15/40] Iter[306/312]		Loss: 0.1348
2019-10-29 00:39:50,308 Training Epoch [15/40] Iter[307/312]		Loss: 0.1348
2019-10-29 00:39:50,429 Training Epoch [15/40] Iter[308/312]		Loss: 0.1347
2019-10-29 00:39:50,550 Training Epoch [15/40] Iter[309/312]		Loss: 0.1350
2019-10-29 00:39:50,671 Training Epoch [15/40] Iter[310/312]		Loss: 0.1349
2019-10-29 00:39:50,792 Training Epoch [15/40] Iter[311/312]		Loss: 0.1349
2019-10-29 00:39:50,852 Training Epoch [15/40] Iter[312/312]		Loss: 0.1348
2019-10-29 00:39:51,137 Testing Epoch [15/40] Iter[0/62]		Loss: 0.1035
2019-10-29 00:39:51,279 Testing Epoch [15/40] Iter[1/62]		Loss: 0.1344
2019-10-29 00:39:51,318 Testing Epoch [15/40] Iter[2/62]		Loss: 0.1271
2019-10-29 00:39:51,348 Testing Epoch [15/40] Iter[3/62]		Loss: 0.1290
2019-10-29 00:39:51,378 Testing Epoch [15/40] Iter[4/62]		Loss: 0.1272
2019-10-29 00:39:51,414 Testing Epoch [15/40] Iter[5/62]		Loss: 0.1289
2019-10-29 00:39:51,444 Testing Epoch [15/40] Iter[6/62]		Loss: 0.1330
2019-10-29 00:39:51,474 Testing Epoch [15/40] Iter[7/62]		Loss: 0.1396
2019-10-29 00:39:51,506 Testing Epoch [15/40] Iter[8/62]		Loss: 0.1462
2019-10-29 00:39:51,537 Testing Epoch [15/40] Iter[9/62]		Loss: 0.1434
2019-10-29 00:39:51,568 Testing Epoch [15/40] Iter[10/62]		Loss: 0.1418
2019-10-29 00:39:51,602 Testing Epoch [15/40] Iter[11/62]		Loss: 0.1488
2019-10-29 00:39:51,633 Testing Epoch [15/40] Iter[12/62]		Loss: 0.1496
2019-10-29 00:39:51,665 Testing Epoch [15/40] Iter[13/62]		Loss: 0.1523
2019-10-29 00:39:51,698 Testing Epoch [15/40] Iter[14/62]		Loss: 0.1642
2019-10-29 00:39:51,729 Testing Epoch [15/40] Iter[15/62]		Loss: 0.1668
2019-10-29 00:39:51,760 Testing Epoch [15/40] Iter[16/62]		Loss: 0.1649
2019-10-29 00:39:51,794 Testing Epoch [15/40] Iter[17/62]		Loss: 0.1640
2019-10-29 00:39:51,825 Testing Epoch [15/40] Iter[18/62]		Loss: 0.1614
2019-10-29 00:39:51,856 Testing Epoch [15/40] Iter[19/62]		Loss: 0.1594
2019-10-29 00:39:51,890 Testing Epoch [15/40] Iter[20/62]		Loss: 0.1595
2019-10-29 00:39:51,921 Testing Epoch [15/40] Iter[21/62]		Loss: 0.1573
2019-10-29 00:39:51,952 Testing Epoch [15/40] Iter[22/62]		Loss: 0.1564
2019-10-29 00:39:51,990 Testing Epoch [15/40] Iter[23/62]		Loss: 0.1547
2019-10-29 00:39:52,021 Testing Epoch [15/40] Iter[24/62]		Loss: 0.1575
2019-10-29 00:39:52,053 Testing Epoch [15/40] Iter[25/62]		Loss: 0.1568
2019-10-29 00:39:52,084 Testing Epoch [15/40] Iter[26/62]		Loss: 0.1562
2019-10-29 00:39:52,115 Testing Epoch [15/40] Iter[27/62]		Loss: 0.1619
2019-10-29 00:39:52,146 Testing Epoch [15/40] Iter[28/62]		Loss: 0.1635
2019-10-29 00:39:52,177 Testing Epoch [15/40] Iter[29/62]		Loss: 0.1636
2019-10-29 00:39:52,208 Testing Epoch [15/40] Iter[30/62]		Loss: 0.1652
2019-10-29 00:39:52,239 Testing Epoch [15/40] Iter[31/62]		Loss: 0.1646
2019-10-29 00:39:52,270 Testing Epoch [15/40] Iter[32/62]		Loss: 0.1669
2019-10-29 00:39:52,301 Testing Epoch [15/40] Iter[33/62]		Loss: 0.1652
2019-10-29 00:39:52,332 Testing Epoch [15/40] Iter[34/62]		Loss: 0.1665
2019-10-29 00:39:52,364 Testing Epoch [15/40] Iter[35/62]		Loss: 0.1669
2019-10-29 00:39:52,395 Testing Epoch [15/40] Iter[36/62]		Loss: 0.1653
2019-10-29 00:39:52,426 Testing Epoch [15/40] Iter[37/62]		Loss: 0.1652
2019-10-29 00:39:52,457 Testing Epoch [15/40] Iter[38/62]		Loss: 0.1649
2019-10-29 00:39:52,488 Testing Epoch [15/40] Iter[39/62]		Loss: 0.1651
2019-10-29 00:39:52,519 Testing Epoch [15/40] Iter[40/62]		Loss: 0.1655
2019-10-29 00:39:52,550 Testing Epoch [15/40] Iter[41/62]		Loss: 0.1657
2019-10-29 00:39:52,582 Testing Epoch [15/40] Iter[42/62]		Loss: 0.1639
2019-10-29 00:39:52,613 Testing Epoch [15/40] Iter[43/62]		Loss: 0.1632
2019-10-29 00:39:52,644 Testing Epoch [15/40] Iter[44/62]		Loss: 0.1616
2019-10-29 00:39:52,675 Testing Epoch [15/40] Iter[45/62]		Loss: 0.1625
2019-10-29 00:39:52,706 Testing Epoch [15/40] Iter[46/62]		Loss: 0.1626
2019-10-29 00:39:52,737 Testing Epoch [15/40] Iter[47/62]		Loss: 0.1673
2019-10-29 00:39:52,769 Testing Epoch [15/40] Iter[48/62]		Loss: 0.1661
2019-10-29 00:39:52,799 Testing Epoch [15/40] Iter[49/62]		Loss: 0.1671
2019-10-29 00:39:52,831 Testing Epoch [15/40] Iter[50/62]		Loss: 0.1665
2019-10-29 00:39:52,862 Testing Epoch [15/40] Iter[51/62]		Loss: 0.1666
2019-10-29 00:39:52,893 Testing Epoch [15/40] Iter[52/62]		Loss: 0.1651
2019-10-29 00:39:52,924 Testing Epoch [15/40] Iter[53/62]		Loss: 0.1648
2019-10-29 00:39:52,955 Testing Epoch [15/40] Iter[54/62]		Loss: 0.1640
2019-10-29 00:39:52,986 Testing Epoch [15/40] Iter[55/62]		Loss: 0.1638
2019-10-29 00:39:53,017 Testing Epoch [15/40] Iter[56/62]		Loss: 0.1634
2019-10-29 00:39:53,047 Testing Epoch [15/40] Iter[57/62]		Loss: 0.1634
2019-10-29 00:39:53,078 Testing Epoch [15/40] Iter[58/62]		Loss: 0.1630
2019-10-29 00:39:53,109 Testing Epoch [15/40] Iter[59/62]		Loss: 0.1631
2019-10-29 00:39:53,140 Testing Epoch [15/40] Iter[60/62]		Loss: 0.1625
2019-10-29 00:39:53,171 Testing Epoch [15/40] Iter[61/62]		Loss: 0.1622
2019-10-29 00:39:53,188 Testing Epoch [15/40] Iter[62/62]		Loss: 0.1630
2019-10-29 00:39:53,677 Training Epoch [16/40] Iter[0/312]		Loss: 0.1468
2019-10-29 00:39:53,799 Training Epoch [16/40] Iter[1/312]		Loss: 0.1589
2019-10-29 00:39:53,921 Training Epoch [16/40] Iter[2/312]		Loss: 0.1748
2019-10-29 00:39:54,045 Training Epoch [16/40] Iter[3/312]		Loss: 0.1641
2019-10-29 00:39:54,166 Training Epoch [16/40] Iter[4/312]		Loss: 0.1586
2019-10-29 00:39:54,288 Training Epoch [16/40] Iter[5/312]		Loss: 0.1519
2019-10-29 00:39:54,408 Training Epoch [16/40] Iter[6/312]		Loss: 0.1490
2019-10-29 00:39:54,531 Training Epoch [16/40] Iter[7/312]		Loss: 0.1461
2019-10-29 00:39:54,652 Training Epoch [16/40] Iter[8/312]		Loss: 0.1403
2019-10-29 00:39:54,774 Training Epoch [16/40] Iter[9/312]		Loss: 0.1381
2019-10-29 00:39:54,895 Training Epoch [16/40] Iter[10/312]		Loss: 0.1393
2019-10-29 00:39:55,017 Training Epoch [16/40] Iter[11/312]		Loss: 0.1470
2019-10-29 00:39:55,139 Training Epoch [16/40] Iter[12/312]		Loss: 0.1427
2019-10-29 00:39:55,261 Training Epoch [16/40] Iter[13/312]		Loss: 0.1437
2019-10-29 00:39:55,383 Training Epoch [16/40] Iter[14/312]		Loss: 0.1414
2019-10-29 00:39:55,505 Training Epoch [16/40] Iter[15/312]		Loss: 0.1425
2019-10-29 00:39:55,627 Training Epoch [16/40] Iter[16/312]		Loss: 0.1428
2019-10-29 00:39:55,749 Training Epoch [16/40] Iter[17/312]		Loss: 0.1423
2019-10-29 00:39:55,870 Training Epoch [16/40] Iter[18/312]		Loss: 0.1414
2019-10-29 00:39:55,992 Training Epoch [16/40] Iter[19/312]		Loss: 0.1424
2019-10-29 00:39:56,114 Training Epoch [16/40] Iter[20/312]		Loss: 0.1442
2019-10-29 00:39:56,236 Training Epoch [16/40] Iter[21/312]		Loss: 0.1431
2019-10-29 00:39:56,358 Training Epoch [16/40] Iter[22/312]		Loss: 0.1428
2019-10-29 00:39:56,480 Training Epoch [16/40] Iter[23/312]		Loss: 0.1422
2019-10-29 00:39:56,602 Training Epoch [16/40] Iter[24/312]		Loss: 0.1466
2019-10-29 00:39:56,724 Training Epoch [16/40] Iter[25/312]		Loss: 0.1458
2019-10-29 00:39:56,846 Training Epoch [16/40] Iter[26/312]		Loss: 0.1445
2019-10-29 00:39:56,968 Training Epoch [16/40] Iter[27/312]		Loss: 0.1451
2019-10-29 00:39:57,089 Training Epoch [16/40] Iter[28/312]		Loss: 0.1438
2019-10-29 00:39:57,211 Training Epoch [16/40] Iter[29/312]		Loss: 0.1438
2019-10-29 00:39:57,333 Training Epoch [16/40] Iter[30/312]		Loss: 0.1439
2019-10-29 00:39:57,455 Training Epoch [16/40] Iter[31/312]		Loss: 0.1426
2019-10-29 00:39:57,577 Training Epoch [16/40] Iter[32/312]		Loss: 0.1443
2019-10-29 00:39:57,699 Training Epoch [16/40] Iter[33/312]		Loss: 0.1438
2019-10-29 00:39:57,821 Training Epoch [16/40] Iter[34/312]		Loss: 0.1442
2019-10-29 00:39:57,942 Training Epoch [16/40] Iter[35/312]		Loss: 0.1428
2019-10-29 00:39:58,064 Training Epoch [16/40] Iter[36/312]		Loss: 0.1434
2019-10-29 00:39:58,187 Training Epoch [16/40] Iter[37/312]		Loss: 0.1432
2019-10-29 00:39:58,309 Training Epoch [16/40] Iter[38/312]		Loss: 0.1427
2019-10-29 00:39:58,431 Training Epoch [16/40] Iter[39/312]		Loss: 0.1430
2019-10-29 00:39:58,553 Training Epoch [16/40] Iter[40/312]		Loss: 0.1426
2019-10-29 00:39:58,675 Training Epoch [16/40] Iter[41/312]		Loss: 0.1417
2019-10-29 00:39:58,797 Training Epoch [16/40] Iter[42/312]		Loss: 0.1438
2019-10-29 00:39:58,919 Training Epoch [16/40] Iter[43/312]		Loss: 0.1441
2019-10-29 00:39:59,041 Training Epoch [16/40] Iter[44/312]		Loss: 0.1441
2019-10-29 00:39:59,163 Training Epoch [16/40] Iter[45/312]		Loss: 0.1428
2019-10-29 00:39:59,285 Training Epoch [16/40] Iter[46/312]		Loss: 0.1418
2019-10-29 00:39:59,407 Training Epoch [16/40] Iter[47/312]		Loss: 0.1415
2019-10-29 00:39:59,529 Training Epoch [16/40] Iter[48/312]		Loss: 0.1414
2019-10-29 00:39:59,651 Training Epoch [16/40] Iter[49/312]		Loss: 0.1408
2019-10-29 00:39:59,772 Training Epoch [16/40] Iter[50/312]		Loss: 0.1412
2019-10-29 00:39:59,894 Training Epoch [16/40] Iter[51/312]		Loss: 0.1412
2019-10-29 00:40:00,016 Training Epoch [16/40] Iter[52/312]		Loss: 0.1412
2019-10-29 00:40:00,138 Training Epoch [16/40] Iter[53/312]		Loss: 0.1407
2019-10-29 00:40:00,260 Training Epoch [16/40] Iter[54/312]		Loss: 0.1407
2019-10-29 00:40:00,382 Training Epoch [16/40] Iter[55/312]		Loss: 0.1404
2019-10-29 00:40:00,503 Training Epoch [16/40] Iter[56/312]		Loss: 0.1413
2019-10-29 00:40:00,629 Training Epoch [16/40] Iter[57/312]		Loss: 0.1405
2019-10-29 00:40:00,751 Training Epoch [16/40] Iter[58/312]		Loss: 0.1400
2019-10-29 00:40:00,873 Training Epoch [16/40] Iter[59/312]		Loss: 0.1406
2019-10-29 00:40:00,995 Training Epoch [16/40] Iter[60/312]		Loss: 0.1407
2019-10-29 00:40:01,117 Training Epoch [16/40] Iter[61/312]		Loss: 0.1405
2019-10-29 00:40:01,239 Training Epoch [16/40] Iter[62/312]		Loss: 0.1405
2019-10-29 00:40:01,361 Training Epoch [16/40] Iter[63/312]		Loss: 0.1414
2019-10-29 00:40:01,483 Training Epoch [16/40] Iter[64/312]		Loss: 0.1410
2019-10-29 00:40:01,605 Training Epoch [16/40] Iter[65/312]		Loss: 0.1416
2019-10-29 00:40:01,727 Training Epoch [16/40] Iter[66/312]		Loss: 0.1413
2019-10-29 00:40:01,849 Training Epoch [16/40] Iter[67/312]		Loss: 0.1416
2019-10-29 00:40:01,971 Training Epoch [16/40] Iter[68/312]		Loss: 0.1412
2019-10-29 00:40:02,093 Training Epoch [16/40] Iter[69/312]		Loss: 0.1405
2019-10-29 00:40:02,215 Training Epoch [16/40] Iter[70/312]		Loss: 0.1402
2019-10-29 00:40:02,337 Training Epoch [16/40] Iter[71/312]		Loss: 0.1394
2019-10-29 00:40:02,459 Training Epoch [16/40] Iter[72/312]		Loss: 0.1393
2019-10-29 00:40:02,581 Training Epoch [16/40] Iter[73/312]		Loss: 0.1391
2019-10-29 00:40:02,703 Training Epoch [16/40] Iter[74/312]		Loss: 0.1390
2019-10-29 00:40:02,824 Training Epoch [16/40] Iter[75/312]		Loss: 0.1388
2019-10-29 00:40:02,946 Training Epoch [16/40] Iter[76/312]		Loss: 0.1387
2019-10-29 00:40:03,068 Training Epoch [16/40] Iter[77/312]		Loss: 0.1390
2019-10-29 00:40:03,190 Training Epoch [16/40] Iter[78/312]		Loss: 0.1386
2019-10-29 00:40:03,313 Training Epoch [16/40] Iter[79/312]		Loss: 0.1382
2019-10-29 00:40:03,435 Training Epoch [16/40] Iter[80/312]		Loss: 0.1378
2019-10-29 00:40:03,557 Training Epoch [16/40] Iter[81/312]		Loss: 0.1372
2019-10-29 00:40:03,679 Training Epoch [16/40] Iter[82/312]		Loss: 0.1375
2019-10-29 00:40:03,801 Training Epoch [16/40] Iter[83/312]		Loss: 0.1368
2019-10-29 00:40:03,923 Training Epoch [16/40] Iter[84/312]		Loss: 0.1365
2019-10-29 00:40:04,045 Training Epoch [16/40] Iter[85/312]		Loss: 0.1367
2019-10-29 00:40:04,167 Training Epoch [16/40] Iter[86/312]		Loss: 0.1368
2019-10-29 00:40:04,289 Training Epoch [16/40] Iter[87/312]		Loss: 0.1365
2019-10-29 00:40:04,411 Training Epoch [16/40] Iter[88/312]		Loss: 0.1362
2019-10-29 00:40:04,533 Training Epoch [16/40] Iter[89/312]		Loss: 0.1361
2019-10-29 00:40:04,655 Training Epoch [16/40] Iter[90/312]		Loss: 0.1359
2019-10-29 00:40:04,777 Training Epoch [16/40] Iter[91/312]		Loss: 0.1359
2019-10-29 00:40:04,899 Training Epoch [16/40] Iter[92/312]		Loss: 0.1361
2019-10-29 00:40:05,021 Training Epoch [16/40] Iter[93/312]		Loss: 0.1355
2019-10-29 00:40:05,142 Training Epoch [16/40] Iter[94/312]		Loss: 0.1354
2019-10-29 00:40:05,264 Training Epoch [16/40] Iter[95/312]		Loss: 0.1355
2019-10-29 00:40:05,387 Training Epoch [16/40] Iter[96/312]		Loss: 0.1351
2019-10-29 00:40:05,512 Training Epoch [16/40] Iter[97/312]		Loss: 0.1349
2019-10-29 00:40:05,634 Training Epoch [16/40] Iter[98/312]		Loss: 0.1344
2019-10-29 00:40:05,756 Training Epoch [16/40] Iter[99/312]		Loss: 0.1345
2019-10-29 00:40:05,879 Training Epoch [16/40] Iter[100/312]		Loss: 0.1341
2019-10-29 00:40:06,001 Training Epoch [16/40] Iter[101/312]		Loss: 0.1341
2019-10-29 00:40:06,123 Training Epoch [16/40] Iter[102/312]		Loss: 0.1339
2019-10-29 00:40:06,245 Training Epoch [16/40] Iter[103/312]		Loss: 0.1338
2019-10-29 00:40:06,367 Training Epoch [16/40] Iter[104/312]		Loss: 0.1335
2019-10-29 00:40:06,489 Training Epoch [16/40] Iter[105/312]		Loss: 0.1333
2019-10-29 00:40:06,611 Training Epoch [16/40] Iter[106/312]		Loss: 0.1330
2019-10-29 00:40:06,733 Training Epoch [16/40] Iter[107/312]		Loss: 0.1327
2019-10-29 00:40:06,854 Training Epoch [16/40] Iter[108/312]		Loss: 0.1323
2019-10-29 00:40:06,976 Training Epoch [16/40] Iter[109/312]		Loss: 0.1319
2019-10-29 00:40:07,099 Training Epoch [16/40] Iter[110/312]		Loss: 0.1317
2019-10-29 00:40:07,220 Training Epoch [16/40] Iter[111/312]		Loss: 0.1320
2019-10-29 00:40:07,342 Training Epoch [16/40] Iter[112/312]		Loss: 0.1321
2019-10-29 00:40:07,464 Training Epoch [16/40] Iter[113/312]		Loss: 0.1318
2019-10-29 00:40:07,587 Training Epoch [16/40] Iter[114/312]		Loss: 0.1317
2019-10-29 00:40:07,708 Training Epoch [16/40] Iter[115/312]		Loss: 0.1317
2019-10-29 00:40:07,831 Training Epoch [16/40] Iter[116/312]		Loss: 0.1316
2019-10-29 00:40:07,952 Training Epoch [16/40] Iter[117/312]		Loss: 0.1317
2019-10-29 00:40:08,074 Training Epoch [16/40] Iter[118/312]		Loss: 0.1324
2019-10-29 00:40:08,196 Training Epoch [16/40] Iter[119/312]		Loss: 0.1326
2019-10-29 00:40:08,317 Training Epoch [16/40] Iter[120/312]		Loss: 0.1323
2019-10-29 00:40:08,439 Training Epoch [16/40] Iter[121/312]		Loss: 0.1324
2019-10-29 00:40:08,561 Training Epoch [16/40] Iter[122/312]		Loss: 0.1324
2019-10-29 00:40:08,683 Training Epoch [16/40] Iter[123/312]		Loss: 0.1321
2019-10-29 00:40:08,804 Training Epoch [16/40] Iter[124/312]		Loss: 0.1318
2019-10-29 00:40:08,927 Training Epoch [16/40] Iter[125/312]		Loss: 0.1319
2019-10-29 00:40:09,050 Training Epoch [16/40] Iter[126/312]		Loss: 0.1317
2019-10-29 00:40:09,171 Training Epoch [16/40] Iter[127/312]		Loss: 0.1322
2019-10-29 00:40:09,293 Training Epoch [16/40] Iter[128/312]		Loss: 0.1319
2019-10-29 00:40:09,415 Training Epoch [16/40] Iter[129/312]		Loss: 0.1316
2019-10-29 00:40:09,536 Training Epoch [16/40] Iter[130/312]		Loss: 0.1314
2019-10-29 00:40:09,658 Training Epoch [16/40] Iter[131/312]		Loss: 0.1315
2019-10-29 00:40:09,780 Training Epoch [16/40] Iter[132/312]		Loss: 0.1313
2019-10-29 00:40:09,902 Training Epoch [16/40] Iter[133/312]		Loss: 0.1318
2019-10-29 00:40:10,024 Training Epoch [16/40] Iter[134/312]		Loss: 0.1316
2019-10-29 00:40:10,146 Training Epoch [16/40] Iter[135/312]		Loss: 0.1319
2019-10-29 00:40:10,268 Training Epoch [16/40] Iter[136/312]		Loss: 0.1325
2019-10-29 00:40:10,390 Training Epoch [16/40] Iter[137/312]		Loss: 0.1330
2019-10-29 00:40:10,512 Training Epoch [16/40] Iter[138/312]		Loss: 0.1328
2019-10-29 00:40:10,634 Training Epoch [16/40] Iter[139/312]		Loss: 0.1327
2019-10-29 00:40:10,756 Training Epoch [16/40] Iter[140/312]		Loss: 0.1325
2019-10-29 00:40:10,877 Training Epoch [16/40] Iter[141/312]		Loss: 0.1324
2019-10-29 00:40:10,999 Training Epoch [16/40] Iter[142/312]		Loss: 0.1323
2019-10-29 00:40:11,121 Training Epoch [16/40] Iter[143/312]		Loss: 0.1325
2019-10-29 00:40:11,244 Training Epoch [16/40] Iter[144/312]		Loss: 0.1324
2019-10-29 00:40:11,366 Training Epoch [16/40] Iter[145/312]		Loss: 0.1324
2019-10-29 00:40:11,487 Training Epoch [16/40] Iter[146/312]		Loss: 0.1322
2019-10-29 00:40:11,609 Training Epoch [16/40] Iter[147/312]		Loss: 0.1322
2019-10-29 00:40:11,731 Training Epoch [16/40] Iter[148/312]		Loss: 0.1322
2019-10-29 00:40:11,853 Training Epoch [16/40] Iter[149/312]		Loss: 0.1323
2019-10-29 00:40:11,975 Training Epoch [16/40] Iter[150/312]		Loss: 0.1321
2019-10-29 00:40:12,097 Training Epoch [16/40] Iter[151/312]		Loss: 0.1320
2019-10-29 00:40:12,219 Training Epoch [16/40] Iter[152/312]		Loss: 0.1319
2019-10-29 00:40:12,341 Training Epoch [16/40] Iter[153/312]		Loss: 0.1319
2019-10-29 00:40:12,463 Training Epoch [16/40] Iter[154/312]		Loss: 0.1318
2019-10-29 00:40:12,584 Training Epoch [16/40] Iter[155/312]		Loss: 0.1319
2019-10-29 00:40:12,707 Training Epoch [16/40] Iter[156/312]		Loss: 0.1318
2019-10-29 00:40:12,829 Training Epoch [16/40] Iter[157/312]		Loss: 0.1321
2019-10-29 00:40:12,951 Training Epoch [16/40] Iter[158/312]		Loss: 0.1322
2019-10-29 00:40:13,072 Training Epoch [16/40] Iter[159/312]		Loss: 0.1321
2019-10-29 00:40:13,194 Training Epoch [16/40] Iter[160/312]		Loss: 0.1319
2019-10-29 00:40:13,316 Training Epoch [16/40] Iter[161/312]		Loss: 0.1317
2019-10-29 00:40:13,438 Training Epoch [16/40] Iter[162/312]		Loss: 0.1318
2019-10-29 00:40:13,560 Training Epoch [16/40] Iter[163/312]		Loss: 0.1318
2019-10-29 00:40:13,681 Training Epoch [16/40] Iter[164/312]		Loss: 0.1317
2019-10-29 00:40:13,803 Training Epoch [16/40] Iter[165/312]		Loss: 0.1316
2019-10-29 00:40:13,925 Training Epoch [16/40] Iter[166/312]		Loss: 0.1318
2019-10-29 00:40:14,047 Training Epoch [16/40] Iter[167/312]		Loss: 0.1315
2019-10-29 00:40:14,169 Training Epoch [16/40] Iter[168/312]		Loss: 0.1312
2019-10-29 00:40:14,291 Training Epoch [16/40] Iter[169/312]		Loss: 0.1312
2019-10-29 00:40:14,413 Training Epoch [16/40] Iter[170/312]		Loss: 0.1310
2019-10-29 00:40:14,535 Training Epoch [16/40] Iter[171/312]		Loss: 0.1308
2019-10-29 00:40:14,657 Training Epoch [16/40] Iter[172/312]		Loss: 0.1307
2019-10-29 00:40:14,779 Training Epoch [16/40] Iter[173/312]		Loss: 0.1307
2019-10-29 00:40:14,901 Training Epoch [16/40] Iter[174/312]		Loss: 0.1307
2019-10-29 00:40:15,023 Training Epoch [16/40] Iter[175/312]		Loss: 0.1307
2019-10-29 00:40:15,145 Training Epoch [16/40] Iter[176/312]		Loss: 0.1308
2019-10-29 00:40:15,267 Training Epoch [16/40] Iter[177/312]		Loss: 0.1308
2019-10-29 00:40:15,389 Training Epoch [16/40] Iter[178/312]		Loss: 0.1309
2019-10-29 00:40:15,511 Training Epoch [16/40] Iter[179/312]		Loss: 0.1309
2019-10-29 00:40:15,633 Training Epoch [16/40] Iter[180/312]		Loss: 0.1308
2019-10-29 00:40:15,756 Training Epoch [16/40] Iter[181/312]		Loss: 0.1308
2019-10-29 00:40:15,878 Training Epoch [16/40] Iter[182/312]		Loss: 0.1306
2019-10-29 00:40:16,000 Training Epoch [16/40] Iter[183/312]		Loss: 0.1303
2019-10-29 00:40:16,122 Training Epoch [16/40] Iter[184/312]		Loss: 0.1303
2019-10-29 00:40:16,244 Training Epoch [16/40] Iter[185/312]		Loss: 0.1302
2019-10-29 00:40:16,366 Training Epoch [16/40] Iter[186/312]		Loss: 0.1301
2019-10-29 00:40:16,487 Training Epoch [16/40] Iter[187/312]		Loss: 0.1302
2019-10-29 00:40:16,610 Training Epoch [16/40] Iter[188/312]		Loss: 0.1305
2019-10-29 00:40:16,731 Training Epoch [16/40] Iter[189/312]		Loss: 0.1302
2019-10-29 00:40:16,853 Training Epoch [16/40] Iter[190/312]		Loss: 0.1302
2019-10-29 00:40:16,975 Training Epoch [16/40] Iter[191/312]		Loss: 0.1300
2019-10-29 00:40:17,097 Training Epoch [16/40] Iter[192/312]		Loss: 0.1300
2019-10-29 00:40:17,219 Training Epoch [16/40] Iter[193/312]		Loss: 0.1299
2019-10-29 00:40:17,341 Training Epoch [16/40] Iter[194/312]		Loss: 0.1301
2019-10-29 00:40:17,463 Training Epoch [16/40] Iter[195/312]		Loss: 0.1301
2019-10-29 00:40:17,584 Training Epoch [16/40] Iter[196/312]		Loss: 0.1301
2019-10-29 00:40:17,706 Training Epoch [16/40] Iter[197/312]		Loss: 0.1300
2019-10-29 00:40:17,829 Training Epoch [16/40] Iter[198/312]		Loss: 0.1303
2019-10-29 00:40:17,950 Training Epoch [16/40] Iter[199/312]		Loss: 0.1301
2019-10-29 00:40:18,072 Training Epoch [16/40] Iter[200/312]		Loss: 0.1302
2019-10-29 00:40:18,194 Training Epoch [16/40] Iter[201/312]		Loss: 0.1303
2019-10-29 00:40:18,316 Training Epoch [16/40] Iter[202/312]		Loss: 0.1300
2019-10-29 00:40:18,438 Training Epoch [16/40] Iter[203/312]		Loss: 0.1299
2019-10-29 00:40:18,560 Training Epoch [16/40] Iter[204/312]		Loss: 0.1301
2019-10-29 00:40:18,682 Training Epoch [16/40] Iter[205/312]		Loss: 0.1299
2019-10-29 00:40:18,804 Training Epoch [16/40] Iter[206/312]		Loss: 0.1299
2019-10-29 00:40:18,926 Training Epoch [16/40] Iter[207/312]		Loss: 0.1300
2019-10-29 00:40:19,048 Training Epoch [16/40] Iter[208/312]		Loss: 0.1299
2019-10-29 00:40:19,170 Training Epoch [16/40] Iter[209/312]		Loss: 0.1297
2019-10-29 00:40:19,292 Training Epoch [16/40] Iter[210/312]		Loss: 0.1297
2019-10-29 00:40:19,414 Training Epoch [16/40] Iter[211/312]		Loss: 0.1299
2019-10-29 00:40:19,536 Training Epoch [16/40] Iter[212/312]		Loss: 0.1301
2019-10-29 00:40:19,658 Training Epoch [16/40] Iter[213/312]		Loss: 0.1300
2019-10-29 00:40:19,780 Training Epoch [16/40] Iter[214/312]		Loss: 0.1301
2019-10-29 00:40:19,902 Training Epoch [16/40] Iter[215/312]		Loss: 0.1303
2019-10-29 00:40:20,024 Training Epoch [16/40] Iter[216/312]		Loss: 0.1304
2019-10-29 00:40:20,146 Training Epoch [16/40] Iter[217/312]		Loss: 0.1306
2019-10-29 00:40:20,268 Training Epoch [16/40] Iter[218/312]		Loss: 0.1305
2019-10-29 00:40:20,390 Training Epoch [16/40] Iter[219/312]		Loss: 0.1302
2019-10-29 00:40:20,512 Training Epoch [16/40] Iter[220/312]		Loss: 0.1300
2019-10-29 00:40:20,634 Training Epoch [16/40] Iter[221/312]		Loss: 0.1298
2019-10-29 00:40:20,756 Training Epoch [16/40] Iter[222/312]		Loss: 0.1300
2019-10-29 00:40:20,878 Training Epoch [16/40] Iter[223/312]		Loss: 0.1301
2019-10-29 00:40:21,000 Training Epoch [16/40] Iter[224/312]		Loss: 0.1301
2019-10-29 00:40:21,122 Training Epoch [16/40] Iter[225/312]		Loss: 0.1300
2019-10-29 00:40:21,244 Training Epoch [16/40] Iter[226/312]		Loss: 0.1298
2019-10-29 00:40:21,366 Training Epoch [16/40] Iter[227/312]		Loss: 0.1297
2019-10-29 00:40:21,488 Training Epoch [16/40] Iter[228/312]		Loss: 0.1300
2019-10-29 00:40:21,610 Training Epoch [16/40] Iter[229/312]		Loss: 0.1301
2019-10-29 00:40:21,732 Training Epoch [16/40] Iter[230/312]		Loss: 0.1304
2019-10-29 00:40:21,854 Training Epoch [16/40] Iter[231/312]		Loss: 0.1304
2019-10-29 00:40:21,976 Training Epoch [16/40] Iter[232/312]		Loss: 0.1304
2019-10-29 00:40:22,098 Training Epoch [16/40] Iter[233/312]		Loss: 0.1303
2019-10-29 00:40:22,220 Training Epoch [16/40] Iter[234/312]		Loss: 0.1301
2019-10-29 00:40:22,342 Training Epoch [16/40] Iter[235/312]		Loss: 0.1299
2019-10-29 00:40:22,464 Training Epoch [16/40] Iter[236/312]		Loss: 0.1299
2019-10-29 00:40:22,586 Training Epoch [16/40] Iter[237/312]		Loss: 0.1297
2019-10-29 00:40:22,708 Training Epoch [16/40] Iter[238/312]		Loss: 0.1301
2019-10-29 00:40:22,830 Training Epoch [16/40] Iter[239/312]		Loss: 0.1299
2019-10-29 00:40:22,952 Training Epoch [16/40] Iter[240/312]		Loss: 0.1299
2019-10-29 00:40:23,074 Training Epoch [16/40] Iter[241/312]		Loss: 0.1300
2019-10-29 00:40:23,195 Training Epoch [16/40] Iter[242/312]		Loss: 0.1303
2019-10-29 00:40:23,317 Training Epoch [16/40] Iter[243/312]		Loss: 0.1304
2019-10-29 00:40:23,438 Training Epoch [16/40] Iter[244/312]		Loss: 0.1304
2019-10-29 00:40:23,565 Training Epoch [16/40] Iter[245/312]		Loss: 0.1302
2019-10-29 00:40:23,687 Training Epoch [16/40] Iter[246/312]		Loss: 0.1301
2019-10-29 00:40:23,808 Training Epoch [16/40] Iter[247/312]		Loss: 0.1301
2019-10-29 00:40:23,930 Training Epoch [16/40] Iter[248/312]		Loss: 0.1302
2019-10-29 00:40:24,051 Training Epoch [16/40] Iter[249/312]		Loss: 0.1302
2019-10-29 00:40:24,173 Training Epoch [16/40] Iter[250/312]		Loss: 0.1300
2019-10-29 00:40:24,294 Training Epoch [16/40] Iter[251/312]		Loss: 0.1299
2019-10-29 00:40:24,416 Training Epoch [16/40] Iter[252/312]		Loss: 0.1301
2019-10-29 00:40:24,537 Training Epoch [16/40] Iter[253/312]		Loss: 0.1301
2019-10-29 00:40:24,659 Training Epoch [16/40] Iter[254/312]		Loss: 0.1302
2019-10-29 00:40:24,781 Training Epoch [16/40] Iter[255/312]		Loss: 0.1301
2019-10-29 00:40:24,902 Training Epoch [16/40] Iter[256/312]		Loss: 0.1301
2019-10-29 00:40:25,028 Training Epoch [16/40] Iter[257/312]		Loss: 0.1304
2019-10-29 00:40:25,150 Training Epoch [16/40] Iter[258/312]		Loss: 0.1304
2019-10-29 00:40:25,272 Training Epoch [16/40] Iter[259/312]		Loss: 0.1304
2019-10-29 00:40:25,393 Training Epoch [16/40] Iter[260/312]		Loss: 0.1303
2019-10-29 00:40:25,515 Training Epoch [16/40] Iter[261/312]		Loss: 0.1304
2019-10-29 00:40:25,637 Training Epoch [16/40] Iter[262/312]		Loss: 0.1305
2019-10-29 00:40:25,758 Training Epoch [16/40] Iter[263/312]		Loss: 0.1308
2019-10-29 00:40:25,880 Training Epoch [16/40] Iter[264/312]		Loss: 0.1310
2019-10-29 00:40:26,001 Training Epoch [16/40] Iter[265/312]		Loss: 0.1310
2019-10-29 00:40:26,121 Training Epoch [16/40] Iter[266/312]		Loss: 0.1311
2019-10-29 00:40:26,242 Training Epoch [16/40] Iter[267/312]		Loss: 0.1312
2019-10-29 00:40:26,364 Training Epoch [16/40] Iter[268/312]		Loss: 0.1311
2019-10-29 00:40:26,485 Training Epoch [16/40] Iter[269/312]		Loss: 0.1310
2019-10-29 00:40:26,606 Training Epoch [16/40] Iter[270/312]		Loss: 0.1309
2019-10-29 00:40:26,727 Training Epoch [16/40] Iter[271/312]		Loss: 0.1308
2019-10-29 00:40:26,848 Training Epoch [16/40] Iter[272/312]		Loss: 0.1309
2019-10-29 00:40:26,970 Training Epoch [16/40] Iter[273/312]		Loss: 0.1310
2019-10-29 00:40:27,091 Training Epoch [16/40] Iter[274/312]		Loss: 0.1311
2019-10-29 00:40:27,213 Training Epoch [16/40] Iter[275/312]		Loss: 0.1311
2019-10-29 00:40:27,334 Training Epoch [16/40] Iter[276/312]		Loss: 0.1311
2019-10-29 00:40:27,456 Training Epoch [16/40] Iter[277/312]		Loss: 0.1309
2019-10-29 00:40:27,578 Training Epoch [16/40] Iter[278/312]		Loss: 0.1309
2019-10-29 00:40:27,699 Training Epoch [16/40] Iter[279/312]		Loss: 0.1307
2019-10-29 00:40:27,821 Training Epoch [16/40] Iter[280/312]		Loss: 0.1308
2019-10-29 00:40:27,942 Training Epoch [16/40] Iter[281/312]		Loss: 0.1308
2019-10-29 00:40:28,064 Training Epoch [16/40] Iter[282/312]		Loss: 0.1310
2019-10-29 00:40:28,186 Training Epoch [16/40] Iter[283/312]		Loss: 0.1311
2019-10-29 00:40:28,308 Training Epoch [16/40] Iter[284/312]		Loss: 0.1312
2019-10-29 00:40:28,430 Training Epoch [16/40] Iter[285/312]		Loss: 0.1311
2019-10-29 00:40:28,551 Training Epoch [16/40] Iter[286/312]		Loss: 0.1309
2019-10-29 00:40:28,673 Training Epoch [16/40] Iter[287/312]		Loss: 0.1309
2019-10-29 00:40:28,794 Training Epoch [16/40] Iter[288/312]		Loss: 0.1307
2019-10-29 00:40:28,915 Training Epoch [16/40] Iter[289/312]		Loss: 0.1308
2019-10-29 00:40:29,036 Training Epoch [16/40] Iter[290/312]		Loss: 0.1307
2019-10-29 00:40:29,157 Training Epoch [16/40] Iter[291/312]		Loss: 0.1307
2019-10-29 00:40:29,279 Training Epoch [16/40] Iter[292/312]		Loss: 0.1306
2019-10-29 00:40:29,400 Training Epoch [16/40] Iter[293/312]		Loss: 0.1305
2019-10-29 00:40:29,521 Training Epoch [16/40] Iter[294/312]		Loss: 0.1305
2019-10-29 00:40:29,643 Training Epoch [16/40] Iter[295/312]		Loss: 0.1307
2019-10-29 00:40:29,764 Training Epoch [16/40] Iter[296/312]		Loss: 0.1308
2019-10-29 00:40:29,886 Training Epoch [16/40] Iter[297/312]		Loss: 0.1307
2019-10-29 00:40:30,007 Training Epoch [16/40] Iter[298/312]		Loss: 0.1305
2019-10-29 00:40:30,128 Training Epoch [16/40] Iter[299/312]		Loss: 0.1305
2019-10-29 00:40:30,250 Training Epoch [16/40] Iter[300/312]		Loss: 0.1303
2019-10-29 00:40:30,377 Training Epoch [16/40] Iter[301/312]		Loss: 0.1303
2019-10-29 00:40:30,498 Training Epoch [16/40] Iter[302/312]		Loss: 0.1302
2019-10-29 00:40:30,619 Training Epoch [16/40] Iter[303/312]		Loss: 0.1302
2019-10-29 00:40:30,741 Training Epoch [16/40] Iter[304/312]		Loss: 0.1303
2019-10-29 00:40:30,862 Training Epoch [16/40] Iter[305/312]		Loss: 0.1305
2019-10-29 00:40:30,983 Training Epoch [16/40] Iter[306/312]		Loss: 0.1304
2019-10-29 00:40:31,103 Training Epoch [16/40] Iter[307/312]		Loss: 0.1303
2019-10-29 00:40:31,224 Training Epoch [16/40] Iter[308/312]		Loss: 0.1306
2019-10-29 00:40:31,345 Training Epoch [16/40] Iter[309/312]		Loss: 0.1305
2019-10-29 00:40:31,467 Training Epoch [16/40] Iter[310/312]		Loss: 0.1306
2019-10-29 00:40:31,588 Training Epoch [16/40] Iter[311/312]		Loss: 0.1306
2019-10-29 00:40:31,649 Training Epoch [16/40] Iter[312/312]		Loss: 0.1306
2019-10-29 00:40:32,061 Testing Epoch [16/40] Iter[0/62]		Loss: 0.1168
2019-10-29 00:40:32,101 Testing Epoch [16/40] Iter[1/62]		Loss: 0.1277
2019-10-29 00:40:32,133 Testing Epoch [16/40] Iter[2/62]		Loss: 0.1286
2019-10-29 00:40:32,164 Testing Epoch [16/40] Iter[3/62]		Loss: 0.1299
2019-10-29 00:40:32,198 Testing Epoch [16/40] Iter[4/62]		Loss: 0.1235
2019-10-29 00:40:32,228 Testing Epoch [16/40] Iter[5/62]		Loss: 0.1179
2019-10-29 00:40:32,258 Testing Epoch [16/40] Iter[6/62]		Loss: 0.1212
2019-10-29 00:40:32,290 Testing Epoch [16/40] Iter[7/62]		Loss: 0.1281
2019-10-29 00:40:32,321 Testing Epoch [16/40] Iter[8/62]		Loss: 0.1373
2019-10-29 00:40:32,352 Testing Epoch [16/40] Iter[9/62]		Loss: 0.1379
2019-10-29 00:40:32,389 Testing Epoch [16/40] Iter[10/62]		Loss: 0.1370
2019-10-29 00:40:32,420 Testing Epoch [16/40] Iter[11/62]		Loss: 0.1401
2019-10-29 00:40:32,451 Testing Epoch [16/40] Iter[12/62]		Loss: 0.1404
2019-10-29 00:40:32,482 Testing Epoch [16/40] Iter[13/62]		Loss: 0.1416
2019-10-29 00:40:32,513 Testing Epoch [16/40] Iter[14/62]		Loss: 0.1569
2019-10-29 00:40:32,544 Testing Epoch [16/40] Iter[15/62]		Loss: 0.1586
2019-10-29 00:40:32,575 Testing Epoch [16/40] Iter[16/62]		Loss: 0.1573
2019-10-29 00:40:32,606 Testing Epoch [16/40] Iter[17/62]		Loss: 0.1558
2019-10-29 00:40:32,637 Testing Epoch [16/40] Iter[18/62]		Loss: 0.1518
2019-10-29 00:40:32,667 Testing Epoch [16/40] Iter[19/62]		Loss: 0.1500
2019-10-29 00:40:32,698 Testing Epoch [16/40] Iter[20/62]		Loss: 0.1514
2019-10-29 00:40:32,729 Testing Epoch [16/40] Iter[21/62]		Loss: 0.1500
2019-10-29 00:40:32,760 Testing Epoch [16/40] Iter[22/62]		Loss: 0.1502
2019-10-29 00:40:32,791 Testing Epoch [16/40] Iter[23/62]		Loss: 0.1510
2019-10-29 00:40:32,822 Testing Epoch [16/40] Iter[24/62]		Loss: 0.1536
2019-10-29 00:40:32,853 Testing Epoch [16/40] Iter[25/62]		Loss: 0.1530
2019-10-29 00:40:32,884 Testing Epoch [16/40] Iter[26/62]		Loss: 0.1516
2019-10-29 00:40:32,915 Testing Epoch [16/40] Iter[27/62]		Loss: 0.1571
2019-10-29 00:40:32,946 Testing Epoch [16/40] Iter[28/62]		Loss: 0.1590
2019-10-29 00:40:32,977 Testing Epoch [16/40] Iter[29/62]		Loss: 0.1596
2019-10-29 00:40:33,008 Testing Epoch [16/40] Iter[30/62]		Loss: 0.1612
2019-10-29 00:40:33,038 Testing Epoch [16/40] Iter[31/62]		Loss: 0.1611
2019-10-29 00:40:33,069 Testing Epoch [16/40] Iter[32/62]		Loss: 0.1630
2019-10-29 00:40:33,100 Testing Epoch [16/40] Iter[33/62]		Loss: 0.1611
2019-10-29 00:40:33,131 Testing Epoch [16/40] Iter[34/62]		Loss: 0.1629
2019-10-29 00:40:33,161 Testing Epoch [16/40] Iter[35/62]		Loss: 0.1632
2019-10-29 00:40:33,192 Testing Epoch [16/40] Iter[36/62]		Loss: 0.1608
2019-10-29 00:40:33,223 Testing Epoch [16/40] Iter[37/62]		Loss: 0.1608
2019-10-29 00:40:33,254 Testing Epoch [16/40] Iter[38/62]		Loss: 0.1609
2019-10-29 00:40:33,285 Testing Epoch [16/40] Iter[39/62]		Loss: 0.1614
2019-10-29 00:40:33,315 Testing Epoch [16/40] Iter[40/62]		Loss: 0.1622
2019-10-29 00:40:33,346 Testing Epoch [16/40] Iter[41/62]		Loss: 0.1625
2019-10-29 00:40:33,377 Testing Epoch [16/40] Iter[42/62]		Loss: 0.1613
2019-10-29 00:40:33,408 Testing Epoch [16/40] Iter[43/62]		Loss: 0.1601
2019-10-29 00:40:33,439 Testing Epoch [16/40] Iter[44/62]		Loss: 0.1586
2019-10-29 00:40:33,469 Testing Epoch [16/40] Iter[45/62]		Loss: 0.1592
2019-10-29 00:40:33,500 Testing Epoch [16/40] Iter[46/62]		Loss: 0.1594
2019-10-29 00:40:33,531 Testing Epoch [16/40] Iter[47/62]		Loss: 0.1645
2019-10-29 00:40:33,562 Testing Epoch [16/40] Iter[48/62]		Loss: 0.1635
2019-10-29 00:40:33,593 Testing Epoch [16/40] Iter[49/62]		Loss: 0.1655
2019-10-29 00:40:33,623 Testing Epoch [16/40] Iter[50/62]		Loss: 0.1646
2019-10-29 00:40:33,654 Testing Epoch [16/40] Iter[51/62]		Loss: 0.1645
2019-10-29 00:40:33,685 Testing Epoch [16/40] Iter[52/62]		Loss: 0.1632
2019-10-29 00:40:33,715 Testing Epoch [16/40] Iter[53/62]		Loss: 0.1631
2019-10-29 00:40:33,746 Testing Epoch [16/40] Iter[54/62]		Loss: 0.1623
2019-10-29 00:40:33,777 Testing Epoch [16/40] Iter[55/62]		Loss: 0.1623
2019-10-29 00:40:33,807 Testing Epoch [16/40] Iter[56/62]		Loss: 0.1616
2019-10-29 00:40:33,837 Testing Epoch [16/40] Iter[57/62]		Loss: 0.1614
2019-10-29 00:40:33,868 Testing Epoch [16/40] Iter[58/62]		Loss: 0.1606
2019-10-29 00:40:33,898 Testing Epoch [16/40] Iter[59/62]		Loss: 0.1608
2019-10-29 00:40:33,928 Testing Epoch [16/40] Iter[60/62]		Loss: 0.1596
2019-10-29 00:40:33,959 Testing Epoch [16/40] Iter[61/62]		Loss: 0.1598
2019-10-29 00:40:33,976 Testing Epoch [16/40] Iter[62/62]		Loss: 0.1612
2019-10-29 00:40:34,448 Training Epoch [17/40] Iter[0/312]		Loss: 0.1392
2019-10-29 00:40:34,573 Training Epoch [17/40] Iter[1/312]		Loss: 0.1333
2019-10-29 00:40:34,693 Training Epoch [17/40] Iter[2/312]		Loss: 0.1191
2019-10-29 00:40:34,814 Training Epoch [17/40] Iter[3/312]		Loss: 0.1090
2019-10-29 00:40:34,937 Training Epoch [17/40] Iter[4/312]		Loss: 0.1105
2019-10-29 00:40:35,056 Training Epoch [17/40] Iter[5/312]		Loss: 0.1146
2019-10-29 00:40:35,176 Training Epoch [17/40] Iter[6/312]		Loss: 0.1142
2019-10-29 00:40:35,297 Training Epoch [17/40] Iter[7/312]		Loss: 0.1148
2019-10-29 00:40:35,419 Training Epoch [17/40] Iter[8/312]		Loss: 0.1149
2019-10-29 00:40:35,540 Training Epoch [17/40] Iter[9/312]		Loss: 0.1207
2019-10-29 00:40:35,661 Training Epoch [17/40] Iter[10/312]		Loss: 0.1195
2019-10-29 00:40:35,783 Training Epoch [17/40] Iter[11/312]		Loss: 0.1205
2019-10-29 00:40:35,905 Training Epoch [17/40] Iter[12/312]		Loss: 0.1214
2019-10-29 00:40:36,027 Training Epoch [17/40] Iter[13/312]		Loss: 0.1217
2019-10-29 00:40:36,149 Training Epoch [17/40] Iter[14/312]		Loss: 0.1221
2019-10-29 00:40:36,270 Training Epoch [17/40] Iter[15/312]		Loss: 0.1213
2019-10-29 00:40:36,391 Training Epoch [17/40] Iter[16/312]		Loss: 0.1226
2019-10-29 00:40:36,513 Training Epoch [17/40] Iter[17/312]		Loss: 0.1250
2019-10-29 00:40:36,634 Training Epoch [17/40] Iter[18/312]		Loss: 0.1238
2019-10-29 00:40:36,755 Training Epoch [17/40] Iter[19/312]		Loss: 0.1280
2019-10-29 00:40:36,877 Training Epoch [17/40] Iter[20/312]		Loss: 0.1302
2019-10-29 00:40:36,999 Training Epoch [17/40] Iter[21/312]		Loss: 0.1288
2019-10-29 00:40:37,121 Training Epoch [17/40] Iter[22/312]		Loss: 0.1268
2019-10-29 00:40:37,243 Training Epoch [17/40] Iter[23/312]		Loss: 0.1250
2019-10-29 00:40:37,364 Training Epoch [17/40] Iter[24/312]		Loss: 0.1270
2019-10-29 00:40:37,485 Training Epoch [17/40] Iter[25/312]		Loss: 0.1267
2019-10-29 00:40:37,606 Training Epoch [17/40] Iter[26/312]		Loss: 0.1253
2019-10-29 00:40:37,728 Training Epoch [17/40] Iter[27/312]		Loss: 0.1246
2019-10-29 00:40:37,849 Training Epoch [17/40] Iter[28/312]		Loss: 0.1263
2019-10-29 00:40:37,970 Training Epoch [17/40] Iter[29/312]		Loss: 0.1246
2019-10-29 00:40:38,091 Training Epoch [17/40] Iter[30/312]		Loss: 0.1258
2019-10-29 00:40:38,212 Training Epoch [17/40] Iter[31/312]		Loss: 0.1255
2019-10-29 00:40:38,333 Training Epoch [17/40] Iter[32/312]		Loss: 0.1245
2019-10-29 00:40:38,455 Training Epoch [17/40] Iter[33/312]		Loss: 0.1260
2019-10-29 00:40:38,576 Training Epoch [17/40] Iter[34/312]		Loss: 0.1252
2019-10-29 00:40:38,698 Training Epoch [17/40] Iter[35/312]		Loss: 0.1255
2019-10-29 00:40:38,819 Training Epoch [17/40] Iter[36/312]		Loss: 0.1263
2019-10-29 00:40:38,940 Training Epoch [17/40] Iter[37/312]		Loss: 0.1265
2019-10-29 00:40:39,062 Training Epoch [17/40] Iter[38/312]		Loss: 0.1264
2019-10-29 00:40:39,184 Training Epoch [17/40] Iter[39/312]		Loss: 0.1262
2019-10-29 00:40:39,305 Training Epoch [17/40] Iter[40/312]		Loss: 0.1260
2019-10-29 00:40:39,427 Training Epoch [17/40] Iter[41/312]		Loss: 0.1250
2019-10-29 00:40:39,549 Training Epoch [17/40] Iter[42/312]		Loss: 0.1240
2019-10-29 00:40:39,670 Training Epoch [17/40] Iter[43/312]		Loss: 0.1243
2019-10-29 00:40:39,791 Training Epoch [17/40] Iter[44/312]		Loss: 0.1244
2019-10-29 00:40:39,912 Training Epoch [17/40] Iter[45/312]		Loss: 0.1244
2019-10-29 00:40:40,034 Training Epoch [17/40] Iter[46/312]		Loss: 0.1241
2019-10-29 00:40:40,155 Training Epoch [17/40] Iter[47/312]		Loss: 0.1242
2019-10-29 00:40:40,277 Training Epoch [17/40] Iter[48/312]		Loss: 0.1258
2019-10-29 00:40:40,399 Training Epoch [17/40] Iter[49/312]		Loss: 0.1251
2019-10-29 00:40:40,520 Training Epoch [17/40] Iter[50/312]		Loss: 0.1247
2019-10-29 00:40:40,642 Training Epoch [17/40] Iter[51/312]		Loss: 0.1253
2019-10-29 00:40:40,763 Training Epoch [17/40] Iter[52/312]		Loss: 0.1254
2019-10-29 00:40:40,885 Training Epoch [17/40] Iter[53/312]		Loss: 0.1261
2019-10-29 00:40:41,006 Training Epoch [17/40] Iter[54/312]		Loss: 0.1264
2019-10-29 00:40:41,127 Training Epoch [17/40] Iter[55/312]		Loss: 0.1263
2019-10-29 00:40:41,249 Training Epoch [17/40] Iter[56/312]		Loss: 0.1263
2019-10-29 00:40:41,370 Training Epoch [17/40] Iter[57/312]		Loss: 0.1257
2019-10-29 00:40:41,491 Training Epoch [17/40] Iter[58/312]		Loss: 0.1250
2019-10-29 00:40:41,612 Training Epoch [17/40] Iter[59/312]		Loss: 0.1241
2019-10-29 00:40:41,734 Training Epoch [17/40] Iter[60/312]		Loss: 0.1238
2019-10-29 00:40:41,855 Training Epoch [17/40] Iter[61/312]		Loss: 0.1236
2019-10-29 00:40:41,976 Training Epoch [17/40] Iter[62/312]		Loss: 0.1238
2019-10-29 00:40:42,098 Training Epoch [17/40] Iter[63/312]		Loss: 0.1240
2019-10-29 00:40:42,219 Training Epoch [17/40] Iter[64/312]		Loss: 0.1234
2019-10-29 00:40:42,340 Training Epoch [17/40] Iter[65/312]		Loss: 0.1230
2019-10-29 00:40:42,462 Training Epoch [17/40] Iter[66/312]		Loss: 0.1232
2019-10-29 00:40:42,583 Training Epoch [17/40] Iter[67/312]		Loss: 0.1228
2019-10-29 00:40:42,704 Training Epoch [17/40] Iter[68/312]		Loss: 0.1223
2019-10-29 00:40:42,825 Training Epoch [17/40] Iter[69/312]		Loss: 0.1224
2019-10-29 00:40:42,946 Training Epoch [17/40] Iter[70/312]		Loss: 0.1228
2019-10-29 00:40:43,067 Training Epoch [17/40] Iter[71/312]		Loss: 0.1225
2019-10-29 00:40:43,188 Training Epoch [17/40] Iter[72/312]		Loss: 0.1224
2019-10-29 00:40:43,309 Training Epoch [17/40] Iter[73/312]		Loss: 0.1222
2019-10-29 00:40:43,430 Training Epoch [17/40] Iter[74/312]		Loss: 0.1241
2019-10-29 00:40:43,552 Training Epoch [17/40] Iter[75/312]		Loss: 0.1239
2019-10-29 00:40:43,673 Training Epoch [17/40] Iter[76/312]		Loss: 0.1245
2019-10-29 00:40:43,794 Training Epoch [17/40] Iter[77/312]		Loss: 0.1240
2019-10-29 00:40:43,915 Training Epoch [17/40] Iter[78/312]		Loss: 0.1237
2019-10-29 00:40:44,036 Training Epoch [17/40] Iter[79/312]		Loss: 0.1242
2019-10-29 00:40:44,158 Training Epoch [17/40] Iter[80/312]		Loss: 0.1246
2019-10-29 00:40:44,280 Training Epoch [17/40] Iter[81/312]		Loss: 0.1248
2019-10-29 00:40:44,401 Training Epoch [17/40] Iter[82/312]		Loss: 0.1249
2019-10-29 00:40:44,523 Training Epoch [17/40] Iter[83/312]		Loss: 0.1251
2019-10-29 00:40:44,645 Training Epoch [17/40] Iter[84/312]		Loss: 0.1252
2019-10-29 00:40:44,767 Training Epoch [17/40] Iter[85/312]		Loss: 0.1255
2019-10-29 00:40:44,888 Training Epoch [17/40] Iter[86/312]		Loss: 0.1251
2019-10-29 00:40:45,009 Training Epoch [17/40] Iter[87/312]		Loss: 0.1245
2019-10-29 00:40:45,130 Training Epoch [17/40] Iter[88/312]		Loss: 0.1255
2019-10-29 00:40:45,252 Training Epoch [17/40] Iter[89/312]		Loss: 0.1261
2019-10-29 00:40:45,373 Training Epoch [17/40] Iter[90/312]		Loss: 0.1260
2019-10-29 00:40:45,495 Training Epoch [17/40] Iter[91/312]		Loss: 0.1262
2019-10-29 00:40:45,616 Training Epoch [17/40] Iter[92/312]		Loss: 0.1262
2019-10-29 00:40:45,738 Training Epoch [17/40] Iter[93/312]		Loss: 0.1257
2019-10-29 00:40:45,859 Training Epoch [17/40] Iter[94/312]		Loss: 0.1262
2019-10-29 00:40:45,980 Training Epoch [17/40] Iter[95/312]		Loss: 0.1260
2019-10-29 00:40:46,102 Training Epoch [17/40] Iter[96/312]		Loss: 0.1262
2019-10-29 00:40:46,223 Training Epoch [17/40] Iter[97/312]		Loss: 0.1263
2019-10-29 00:40:46,344 Training Epoch [17/40] Iter[98/312]		Loss: 0.1267
2019-10-29 00:40:46,466 Training Epoch [17/40] Iter[99/312]		Loss: 0.1263
2019-10-29 00:40:46,587 Training Epoch [17/40] Iter[100/312]		Loss: 0.1261
2019-10-29 00:40:46,708 Training Epoch [17/40] Iter[101/312]		Loss: 0.1269
2019-10-29 00:40:46,829 Training Epoch [17/40] Iter[102/312]		Loss: 0.1268
2019-10-29 00:40:46,950 Training Epoch [17/40] Iter[103/312]		Loss: 0.1265
2019-10-29 00:40:47,071 Training Epoch [17/40] Iter[104/312]		Loss: 0.1262
2019-10-29 00:40:47,192 Training Epoch [17/40] Iter[105/312]		Loss: 0.1259
2019-10-29 00:40:47,314 Training Epoch [17/40] Iter[106/312]		Loss: 0.1254
2019-10-29 00:40:47,435 Training Epoch [17/40] Iter[107/312]		Loss: 0.1252
2019-10-29 00:40:47,557 Training Epoch [17/40] Iter[108/312]		Loss: 0.1249
2019-10-29 00:40:47,678 Training Epoch [17/40] Iter[109/312]		Loss: 0.1252
2019-10-29 00:40:47,800 Training Epoch [17/40] Iter[110/312]		Loss: 0.1249
2019-10-29 00:40:47,921 Training Epoch [17/40] Iter[111/312]		Loss: 0.1247
2019-10-29 00:40:48,043 Training Epoch [17/40] Iter[112/312]		Loss: 0.1250
2019-10-29 00:40:48,165 Training Epoch [17/40] Iter[113/312]		Loss: 0.1259
2019-10-29 00:40:48,286 Training Epoch [17/40] Iter[114/312]		Loss: 0.1265
2019-10-29 00:40:48,407 Training Epoch [17/40] Iter[115/312]		Loss: 0.1264
2019-10-29 00:40:48,529 Training Epoch [17/40] Iter[116/312]		Loss: 0.1264
2019-10-29 00:40:48,650 Training Epoch [17/40] Iter[117/312]		Loss: 0.1267
2019-10-29 00:40:48,772 Training Epoch [17/40] Iter[118/312]		Loss: 0.1267
2019-10-29 00:40:48,894 Training Epoch [17/40] Iter[119/312]		Loss: 0.1266
2019-10-29 00:40:49,015 Training Epoch [17/40] Iter[120/312]		Loss: 0.1261
2019-10-29 00:40:49,136 Training Epoch [17/40] Iter[121/312]		Loss: 0.1260
2019-10-29 00:40:49,258 Training Epoch [17/40] Iter[122/312]		Loss: 0.1259
2019-10-29 00:40:49,379 Training Epoch [17/40] Iter[123/312]		Loss: 0.1255
2019-10-29 00:40:49,501 Training Epoch [17/40] Iter[124/312]		Loss: 0.1254
2019-10-29 00:40:49,622 Training Epoch [17/40] Iter[125/312]		Loss: 0.1255
2019-10-29 00:40:49,744 Training Epoch [17/40] Iter[126/312]		Loss: 0.1255
2019-10-29 00:40:49,865 Training Epoch [17/40] Iter[127/312]		Loss: 0.1254
2019-10-29 00:40:49,987 Training Epoch [17/40] Iter[128/312]		Loss: 0.1251
2019-10-29 00:40:50,108 Training Epoch [17/40] Iter[129/312]		Loss: 0.1248
2019-10-29 00:40:50,230 Training Epoch [17/40] Iter[130/312]		Loss: 0.1254
2019-10-29 00:40:50,352 Training Epoch [17/40] Iter[131/312]		Loss: 0.1254
2019-10-29 00:40:50,473 Training Epoch [17/40] Iter[132/312]		Loss: 0.1255
2019-10-29 00:40:50,594 Training Epoch [17/40] Iter[133/312]		Loss: 0.1267
2019-10-29 00:40:50,715 Training Epoch [17/40] Iter[134/312]		Loss: 0.1273
2019-10-29 00:40:50,837 Training Epoch [17/40] Iter[135/312]		Loss: 0.1273
2019-10-29 00:40:50,959 Training Epoch [17/40] Iter[136/312]		Loss: 0.1272
2019-10-29 00:40:51,080 Training Epoch [17/40] Iter[137/312]		Loss: 0.1271
2019-10-29 00:40:51,201 Training Epoch [17/40] Iter[138/312]		Loss: 0.1272
2019-10-29 00:40:51,323 Training Epoch [17/40] Iter[139/312]		Loss: 0.1275
2019-10-29 00:40:51,444 Training Epoch [17/40] Iter[140/312]		Loss: 0.1274
2019-10-29 00:40:51,564 Training Epoch [17/40] Iter[141/312]		Loss: 0.1273
2019-10-29 00:40:51,686 Training Epoch [17/40] Iter[142/312]		Loss: 0.1273
2019-10-29 00:40:51,807 Training Epoch [17/40] Iter[143/312]		Loss: 0.1272
2019-10-29 00:40:51,928 Training Epoch [17/40] Iter[144/312]		Loss: 0.1273
2019-10-29 00:40:52,049 Training Epoch [17/40] Iter[145/312]		Loss: 0.1274
2019-10-29 00:40:52,170 Training Epoch [17/40] Iter[146/312]		Loss: 0.1271
2019-10-29 00:40:52,291 Training Epoch [17/40] Iter[147/312]		Loss: 0.1278
2019-10-29 00:40:52,412 Training Epoch [17/40] Iter[148/312]		Loss: 0.1276
2019-10-29 00:40:52,533 Training Epoch [17/40] Iter[149/312]		Loss: 0.1279
2019-10-29 00:40:52,655 Training Epoch [17/40] Iter[150/312]		Loss: 0.1279
2019-10-29 00:40:52,776 Training Epoch [17/40] Iter[151/312]		Loss: 0.1281
2019-10-29 00:40:52,898 Training Epoch [17/40] Iter[152/312]		Loss: 0.1279
2019-10-29 00:40:53,019 Training Epoch [17/40] Iter[153/312]		Loss: 0.1279
2019-10-29 00:40:53,141 Training Epoch [17/40] Iter[154/312]		Loss: 0.1280
2019-10-29 00:40:53,262 Training Epoch [17/40] Iter[155/312]		Loss: 0.1279
2019-10-29 00:40:53,384 Training Epoch [17/40] Iter[156/312]		Loss: 0.1280
2019-10-29 00:40:53,505 Training Epoch [17/40] Iter[157/312]		Loss: 0.1282
2019-10-29 00:40:53,627 Training Epoch [17/40] Iter[158/312]		Loss: 0.1281
2019-10-29 00:40:53,748 Training Epoch [17/40] Iter[159/312]		Loss: 0.1280
2019-10-29 00:40:53,870 Training Epoch [17/40] Iter[160/312]		Loss: 0.1281
2019-10-29 00:40:53,992 Training Epoch [17/40] Iter[161/312]		Loss: 0.1279
2019-10-29 00:40:54,113 Training Epoch [17/40] Iter[162/312]		Loss: 0.1278
2019-10-29 00:40:54,235 Training Epoch [17/40] Iter[163/312]		Loss: 0.1279
2019-10-29 00:40:54,356 Training Epoch [17/40] Iter[164/312]		Loss: 0.1278
2019-10-29 00:40:54,477 Training Epoch [17/40] Iter[165/312]		Loss: 0.1279
2019-10-29 00:40:54,598 Training Epoch [17/40] Iter[166/312]		Loss: 0.1277
2019-10-29 00:40:54,720 Training Epoch [17/40] Iter[167/312]		Loss: 0.1276
2019-10-29 00:40:54,842 Training Epoch [17/40] Iter[168/312]		Loss: 0.1275
2019-10-29 00:40:54,963 Training Epoch [17/40] Iter[169/312]		Loss: 0.1278
2019-10-29 00:40:55,086 Training Epoch [17/40] Iter[170/312]		Loss: 0.1276
2019-10-29 00:40:55,207 Training Epoch [17/40] Iter[171/312]		Loss: 0.1278
2019-10-29 00:40:55,329 Training Epoch [17/40] Iter[172/312]		Loss: 0.1277
2019-10-29 00:40:55,451 Training Epoch [17/40] Iter[173/312]		Loss: 0.1276
2019-10-29 00:40:55,572 Training Epoch [17/40] Iter[174/312]		Loss: 0.1278
2019-10-29 00:40:55,693 Training Epoch [17/40] Iter[175/312]		Loss: 0.1277
2019-10-29 00:40:55,814 Training Epoch [17/40] Iter[176/312]		Loss: 0.1277
2019-10-29 00:40:55,936 Training Epoch [17/40] Iter[177/312]		Loss: 0.1278
2019-10-29 00:40:56,058 Training Epoch [17/40] Iter[178/312]		Loss: 0.1279
2019-10-29 00:40:56,179 Training Epoch [17/40] Iter[179/312]		Loss: 0.1280
2019-10-29 00:40:56,301 Training Epoch [17/40] Iter[180/312]		Loss: 0.1281
2019-10-29 00:40:56,423 Training Epoch [17/40] Iter[181/312]		Loss: 0.1279
2019-10-29 00:40:56,545 Training Epoch [17/40] Iter[182/312]		Loss: 0.1279
2019-10-29 00:40:56,666 Training Epoch [17/40] Iter[183/312]		Loss: 0.1280
2019-10-29 00:40:56,787 Training Epoch [17/40] Iter[184/312]		Loss: 0.1279
2019-10-29 00:40:56,909 Training Epoch [17/40] Iter[185/312]		Loss: 0.1278
2019-10-29 00:40:57,031 Training Epoch [17/40] Iter[186/312]		Loss: 0.1281
2019-10-29 00:40:57,153 Training Epoch [17/40] Iter[187/312]		Loss: 0.1282
2019-10-29 00:40:57,275 Training Epoch [17/40] Iter[188/312]		Loss: 0.1285
2019-10-29 00:40:57,396 Training Epoch [17/40] Iter[189/312]		Loss: 0.1285
2019-10-29 00:40:57,518 Training Epoch [17/40] Iter[190/312]		Loss: 0.1287
2019-10-29 00:40:57,639 Training Epoch [17/40] Iter[191/312]		Loss: 0.1285
2019-10-29 00:40:57,761 Training Epoch [17/40] Iter[192/312]		Loss: 0.1283
2019-10-29 00:40:57,882 Training Epoch [17/40] Iter[193/312]		Loss: 0.1286
2019-10-29 00:40:58,004 Training Epoch [17/40] Iter[194/312]		Loss: 0.1285
2019-10-29 00:40:58,125 Training Epoch [17/40] Iter[195/312]		Loss: 0.1283
2019-10-29 00:40:58,247 Training Epoch [17/40] Iter[196/312]		Loss: 0.1283
2019-10-29 00:40:58,368 Training Epoch [17/40] Iter[197/312]		Loss: 0.1283
2019-10-29 00:40:58,490 Training Epoch [17/40] Iter[198/312]		Loss: 0.1282
2019-10-29 00:40:58,611 Training Epoch [17/40] Iter[199/312]		Loss: 0.1280
2019-10-29 00:40:58,732 Training Epoch [17/40] Iter[200/312]		Loss: 0.1281
2019-10-29 00:40:58,853 Training Epoch [17/40] Iter[201/312]		Loss: 0.1280
2019-10-29 00:40:58,974 Training Epoch [17/40] Iter[202/312]		Loss: 0.1283
2019-10-29 00:40:59,096 Training Epoch [17/40] Iter[203/312]		Loss: 0.1282
2019-10-29 00:40:59,217 Training Epoch [17/40] Iter[204/312]		Loss: 0.1281
2019-10-29 00:40:59,339 Training Epoch [17/40] Iter[205/312]		Loss: 0.1280
2019-10-29 00:40:59,461 Training Epoch [17/40] Iter[206/312]		Loss: 0.1280
2019-10-29 00:40:59,582 Training Epoch [17/40] Iter[207/312]		Loss: 0.1281
2019-10-29 00:40:59,704 Training Epoch [17/40] Iter[208/312]		Loss: 0.1283
2019-10-29 00:40:59,825 Training Epoch [17/40] Iter[209/312]		Loss: 0.1286
2019-10-29 00:40:59,946 Training Epoch [17/40] Iter[210/312]		Loss: 0.1288
2019-10-29 00:41:00,067 Training Epoch [17/40] Iter[211/312]		Loss: 0.1289
2019-10-29 00:41:00,188 Training Epoch [17/40] Iter[212/312]		Loss: 0.1289
2019-10-29 00:41:00,310 Training Epoch [17/40] Iter[213/312]		Loss: 0.1291
2019-10-29 00:41:00,431 Training Epoch [17/40] Iter[214/312]		Loss: 0.1293
2019-10-29 00:41:00,552 Training Epoch [17/40] Iter[215/312]		Loss: 0.1294
2019-10-29 00:41:00,673 Training Epoch [17/40] Iter[216/312]		Loss: 0.1293
2019-10-29 00:41:00,794 Training Epoch [17/40] Iter[217/312]		Loss: 0.1292
2019-10-29 00:41:00,916 Training Epoch [17/40] Iter[218/312]		Loss: 0.1292
2019-10-29 00:41:01,037 Training Epoch [17/40] Iter[219/312]		Loss: 0.1290
2019-10-29 00:41:01,159 Training Epoch [17/40] Iter[220/312]		Loss: 0.1291
2019-10-29 00:41:01,281 Training Epoch [17/40] Iter[221/312]		Loss: 0.1291
2019-10-29 00:41:01,403 Training Epoch [17/40] Iter[222/312]		Loss: 0.1291
2019-10-29 00:41:01,524 Training Epoch [17/40] Iter[223/312]		Loss: 0.1291
2019-10-29 00:41:01,645 Training Epoch [17/40] Iter[224/312]		Loss: 0.1293
2019-10-29 00:41:01,767 Training Epoch [17/40] Iter[225/312]		Loss: 0.1293
2019-10-29 00:41:01,888 Training Epoch [17/40] Iter[226/312]		Loss: 0.1293
2019-10-29 00:41:02,010 Training Epoch [17/40] Iter[227/312]		Loss: 0.1292
2019-10-29 00:41:02,131 Training Epoch [17/40] Iter[228/312]		Loss: 0.1292
2019-10-29 00:41:02,253 Training Epoch [17/40] Iter[229/312]		Loss: 0.1290
2019-10-29 00:41:02,375 Training Epoch [17/40] Iter[230/312]		Loss: 0.1288
2019-10-29 00:41:02,500 Training Epoch [17/40] Iter[231/312]		Loss: 0.1287
2019-10-29 00:41:02,621 Training Epoch [17/40] Iter[232/312]		Loss: 0.1287
2019-10-29 00:41:02,742 Training Epoch [17/40] Iter[233/312]		Loss: 0.1285
2019-10-29 00:41:02,864 Training Epoch [17/40] Iter[234/312]		Loss: 0.1285
2019-10-29 00:41:02,985 Training Epoch [17/40] Iter[235/312]		Loss: 0.1286
2019-10-29 00:41:03,105 Training Epoch [17/40] Iter[236/312]		Loss: 0.1285
2019-10-29 00:41:03,227 Training Epoch [17/40] Iter[237/312]		Loss: 0.1286
2019-10-29 00:41:03,348 Training Epoch [17/40] Iter[238/312]		Loss: 0.1284
2019-10-29 00:41:03,470 Training Epoch [17/40] Iter[239/312]		Loss: 0.1285
2019-10-29 00:41:03,591 Training Epoch [17/40] Iter[240/312]		Loss: 0.1286
2019-10-29 00:41:03,712 Training Epoch [17/40] Iter[241/312]		Loss: 0.1284
2019-10-29 00:41:03,833 Training Epoch [17/40] Iter[242/312]		Loss: 0.1284
2019-10-29 00:41:03,955 Training Epoch [17/40] Iter[243/312]		Loss: 0.1284
2019-10-29 00:41:04,076 Training Epoch [17/40] Iter[244/312]		Loss: 0.1285
2019-10-29 00:41:04,197 Training Epoch [17/40] Iter[245/312]		Loss: 0.1283
2019-10-29 00:41:04,319 Training Epoch [17/40] Iter[246/312]		Loss: 0.1282
2019-10-29 00:41:04,440 Training Epoch [17/40] Iter[247/312]		Loss: 0.1282
2019-10-29 00:41:04,562 Training Epoch [17/40] Iter[248/312]		Loss: 0.1284
2019-10-29 00:41:04,683 Training Epoch [17/40] Iter[249/312]		Loss: 0.1283
2019-10-29 00:41:04,805 Training Epoch [17/40] Iter[250/312]		Loss: 0.1284
2019-10-29 00:41:04,926 Training Epoch [17/40] Iter[251/312]		Loss: 0.1285
2019-10-29 00:41:05,047 Training Epoch [17/40] Iter[252/312]		Loss: 0.1283
2019-10-29 00:41:05,169 Training Epoch [17/40] Iter[253/312]		Loss: 0.1284
2019-10-29 00:41:05,291 Training Epoch [17/40] Iter[254/312]		Loss: 0.1284
2019-10-29 00:41:05,413 Training Epoch [17/40] Iter[255/312]		Loss: 0.1287
2019-10-29 00:41:05,535 Training Epoch [17/40] Iter[256/312]		Loss: 0.1288
2019-10-29 00:41:05,656 Training Epoch [17/40] Iter[257/312]		Loss: 0.1290
2019-10-29 00:41:05,778 Training Epoch [17/40] Iter[258/312]		Loss: 0.1290
2019-10-29 00:41:05,899 Training Epoch [17/40] Iter[259/312]		Loss: 0.1289
2019-10-29 00:41:06,021 Training Epoch [17/40] Iter[260/312]		Loss: 0.1291
2019-10-29 00:41:06,142 Training Epoch [17/40] Iter[261/312]		Loss: 0.1290
2019-10-29 00:41:06,264 Training Epoch [17/40] Iter[262/312]		Loss: 0.1290
2019-10-29 00:41:06,386 Training Epoch [17/40] Iter[263/312]		Loss: 0.1289
2019-10-29 00:41:06,507 Training Epoch [17/40] Iter[264/312]		Loss: 0.1288
2019-10-29 00:41:06,628 Training Epoch [17/40] Iter[265/312]		Loss: 0.1286
2019-10-29 00:41:06,750 Training Epoch [17/40] Iter[266/312]		Loss: 0.1285
2019-10-29 00:41:06,871 Training Epoch [17/40] Iter[267/312]		Loss: 0.1284
2019-10-29 00:41:06,992 Training Epoch [17/40] Iter[268/312]		Loss: 0.1284
2019-10-29 00:41:07,113 Training Epoch [17/40] Iter[269/312]		Loss: 0.1283
2019-10-29 00:41:07,234 Training Epoch [17/40] Iter[270/312]		Loss: 0.1283
2019-10-29 00:41:07,356 Training Epoch [17/40] Iter[271/312]		Loss: 0.1282
2019-10-29 00:41:07,477 Training Epoch [17/40] Iter[272/312]		Loss: 0.1282
2019-10-29 00:41:07,599 Training Epoch [17/40] Iter[273/312]		Loss: 0.1282
2019-10-29 00:41:07,720 Training Epoch [17/40] Iter[274/312]		Loss: 0.1281
2019-10-29 00:41:07,842 Training Epoch [17/40] Iter[275/312]		Loss: 0.1281
2019-10-29 00:41:07,963 Training Epoch [17/40] Iter[276/312]		Loss: 0.1281
2019-10-29 00:41:08,085 Training Epoch [17/40] Iter[277/312]		Loss: 0.1280
2019-10-29 00:41:08,207 Training Epoch [17/40] Iter[278/312]		Loss: 0.1279
2019-10-29 00:41:08,328 Training Epoch [17/40] Iter[279/312]		Loss: 0.1280
2019-10-29 00:41:08,449 Training Epoch [17/40] Iter[280/312]		Loss: 0.1279
2019-10-29 00:41:08,570 Training Epoch [17/40] Iter[281/312]		Loss: 0.1277
2019-10-29 00:41:08,691 Training Epoch [17/40] Iter[282/312]		Loss: 0.1276
2019-10-29 00:41:08,812 Training Epoch [17/40] Iter[283/312]		Loss: 0.1275
2019-10-29 00:41:08,933 Training Epoch [17/40] Iter[284/312]		Loss: 0.1277
2019-10-29 00:41:09,054 Training Epoch [17/40] Iter[285/312]		Loss: 0.1278
2019-10-29 00:41:09,174 Training Epoch [17/40] Iter[286/312]		Loss: 0.1278
2019-10-29 00:41:09,296 Training Epoch [17/40] Iter[287/312]		Loss: 0.1277
2019-10-29 00:41:09,418 Training Epoch [17/40] Iter[288/312]		Loss: 0.1278
2019-10-29 00:41:09,539 Training Epoch [17/40] Iter[289/312]		Loss: 0.1276
2019-10-29 00:41:09,661 Training Epoch [17/40] Iter[290/312]		Loss: 0.1275
2019-10-29 00:41:09,782 Training Epoch [17/40] Iter[291/312]		Loss: 0.1276
2019-10-29 00:41:09,904 Training Epoch [17/40] Iter[292/312]		Loss: 0.1278
2019-10-29 00:41:10,025 Training Epoch [17/40] Iter[293/312]		Loss: 0.1277
2019-10-29 00:41:10,147 Training Epoch [17/40] Iter[294/312]		Loss: 0.1277
2019-10-29 00:41:10,271 Training Epoch [17/40] Iter[295/312]		Loss: 0.1275
2019-10-29 00:41:10,394 Training Epoch [17/40] Iter[296/312]		Loss: 0.1277
2019-10-29 00:41:10,516 Training Epoch [17/40] Iter[297/312]		Loss: 0.1276
2019-10-29 00:41:10,637 Training Epoch [17/40] Iter[298/312]		Loss: 0.1276
2019-10-29 00:41:10,759 Training Epoch [17/40] Iter[299/312]		Loss: 0.1275
2019-10-29 00:41:10,881 Training Epoch [17/40] Iter[300/312]		Loss: 0.1275
2019-10-29 00:41:11,002 Training Epoch [17/40] Iter[301/312]		Loss: 0.1275
2019-10-29 00:41:11,124 Training Epoch [17/40] Iter[302/312]		Loss: 0.1276
2019-10-29 00:41:11,245 Training Epoch [17/40] Iter[303/312]		Loss: 0.1278
2019-10-29 00:41:11,367 Training Epoch [17/40] Iter[304/312]		Loss: 0.1277
2019-10-29 00:41:11,488 Training Epoch [17/40] Iter[305/312]		Loss: 0.1276
2019-10-29 00:41:11,609 Training Epoch [17/40] Iter[306/312]		Loss: 0.1275
2019-10-29 00:41:11,729 Training Epoch [17/40] Iter[307/312]		Loss: 0.1275
2019-10-29 00:41:11,849 Training Epoch [17/40] Iter[308/312]		Loss: 0.1275
2019-10-29 00:41:11,970 Training Epoch [17/40] Iter[309/312]		Loss: 0.1275
2019-10-29 00:41:12,091 Training Epoch [17/40] Iter[310/312]		Loss: 0.1274
2019-10-29 00:41:12,211 Training Epoch [17/40] Iter[311/312]		Loss: 0.1275
2019-10-29 00:41:12,272 Training Epoch [17/40] Iter[312/312]		Loss: 0.1274
2019-10-29 00:41:12,581 Testing Epoch [17/40] Iter[0/62]		Loss: 0.1379
2019-10-29 00:41:12,706 Testing Epoch [17/40] Iter[1/62]		Loss: 0.1524
2019-10-29 00:41:12,744 Testing Epoch [17/40] Iter[2/62]		Loss: 0.1441
2019-10-29 00:41:12,774 Testing Epoch [17/40] Iter[3/62]		Loss: 0.1437
2019-10-29 00:41:12,804 Testing Epoch [17/40] Iter[4/62]		Loss: 0.1391
2019-10-29 00:41:12,836 Testing Epoch [17/40] Iter[5/62]		Loss: 0.1340
2019-10-29 00:41:12,866 Testing Epoch [17/40] Iter[6/62]		Loss: 0.1366
2019-10-29 00:41:12,896 Testing Epoch [17/40] Iter[7/62]		Loss: 0.1433
2019-10-29 00:41:12,925 Testing Epoch [17/40] Iter[8/62]		Loss: 0.1500
2019-10-29 00:41:12,956 Testing Epoch [17/40] Iter[9/62]		Loss: 0.1501
2019-10-29 00:41:12,987 Testing Epoch [17/40] Iter[10/62]		Loss: 0.1483
2019-10-29 00:41:13,017 Testing Epoch [17/40] Iter[11/62]		Loss: 0.1528
2019-10-29 00:41:13,048 Testing Epoch [17/40] Iter[12/62]		Loss: 0.1534
2019-10-29 00:41:13,079 Testing Epoch [17/40] Iter[13/62]		Loss: 0.1546
2019-10-29 00:41:13,110 Testing Epoch [17/40] Iter[14/62]		Loss: 0.1686
2019-10-29 00:41:13,141 Testing Epoch [17/40] Iter[15/62]		Loss: 0.1689
2019-10-29 00:41:13,172 Testing Epoch [17/40] Iter[16/62]		Loss: 0.1684
2019-10-29 00:41:13,203 Testing Epoch [17/40] Iter[17/62]		Loss: 0.1672
2019-10-29 00:41:13,234 Testing Epoch [17/40] Iter[18/62]		Loss: 0.1641
2019-10-29 00:41:13,264 Testing Epoch [17/40] Iter[19/62]		Loss: 0.1624
2019-10-29 00:41:13,295 Testing Epoch [17/40] Iter[20/62]		Loss: 0.1646
2019-10-29 00:41:13,326 Testing Epoch [17/40] Iter[21/62]		Loss: 0.1627
2019-10-29 00:41:13,357 Testing Epoch [17/40] Iter[22/62]		Loss: 0.1625
2019-10-29 00:41:13,388 Testing Epoch [17/40] Iter[23/62]		Loss: 0.1632
2019-10-29 00:41:13,419 Testing Epoch [17/40] Iter[24/62]		Loss: 0.1662
2019-10-29 00:41:13,449 Testing Epoch [17/40] Iter[25/62]		Loss: 0.1652
2019-10-29 00:41:13,480 Testing Epoch [17/40] Iter[26/62]		Loss: 0.1641
2019-10-29 00:41:13,510 Testing Epoch [17/40] Iter[27/62]		Loss: 0.1686
2019-10-29 00:41:13,541 Testing Epoch [17/40] Iter[28/62]		Loss: 0.1705
2019-10-29 00:41:13,572 Testing Epoch [17/40] Iter[29/62]		Loss: 0.1703
2019-10-29 00:41:13,603 Testing Epoch [17/40] Iter[30/62]		Loss: 0.1718
2019-10-29 00:41:13,633 Testing Epoch [17/40] Iter[31/62]		Loss: 0.1717
2019-10-29 00:41:13,664 Testing Epoch [17/40] Iter[32/62]		Loss: 0.1731
2019-10-29 00:41:13,695 Testing Epoch [17/40] Iter[33/62]		Loss: 0.1715
2019-10-29 00:41:13,726 Testing Epoch [17/40] Iter[34/62]		Loss: 0.1731
2019-10-29 00:41:13,756 Testing Epoch [17/40] Iter[35/62]		Loss: 0.1728
2019-10-29 00:41:13,787 Testing Epoch [17/40] Iter[36/62]		Loss: 0.1711
2019-10-29 00:41:13,818 Testing Epoch [17/40] Iter[37/62]		Loss: 0.1708
2019-10-29 00:41:13,849 Testing Epoch [17/40] Iter[38/62]		Loss: 0.1712
2019-10-29 00:41:13,879 Testing Epoch [17/40] Iter[39/62]		Loss: 0.1715
2019-10-29 00:41:13,910 Testing Epoch [17/40] Iter[40/62]		Loss: 0.1725
2019-10-29 00:41:13,941 Testing Epoch [17/40] Iter[41/62]		Loss: 0.1726
2019-10-29 00:41:13,972 Testing Epoch [17/40] Iter[42/62]		Loss: 0.1714
2019-10-29 00:41:14,003 Testing Epoch [17/40] Iter[43/62]		Loss: 0.1705
2019-10-29 00:41:14,034 Testing Epoch [17/40] Iter[44/62]		Loss: 0.1696
2019-10-29 00:41:14,065 Testing Epoch [17/40] Iter[45/62]		Loss: 0.1705
2019-10-29 00:41:14,096 Testing Epoch [17/40] Iter[46/62]		Loss: 0.1705
2019-10-29 00:41:14,128 Testing Epoch [17/40] Iter[47/62]		Loss: 0.1755
2019-10-29 00:41:14,159 Testing Epoch [17/40] Iter[48/62]		Loss: 0.1747
2019-10-29 00:41:14,190 Testing Epoch [17/40] Iter[49/62]		Loss: 0.1761
2019-10-29 00:41:14,220 Testing Epoch [17/40] Iter[50/62]		Loss: 0.1756
2019-10-29 00:41:14,251 Testing Epoch [17/40] Iter[51/62]		Loss: 0.1755
2019-10-29 00:41:14,282 Testing Epoch [17/40] Iter[52/62]		Loss: 0.1745
2019-10-29 00:41:14,313 Testing Epoch [17/40] Iter[53/62]		Loss: 0.1744
2019-10-29 00:41:14,344 Testing Epoch [17/40] Iter[54/62]		Loss: 0.1736
2019-10-29 00:41:14,374 Testing Epoch [17/40] Iter[55/62]		Loss: 0.1737
2019-10-29 00:41:14,405 Testing Epoch [17/40] Iter[56/62]		Loss: 0.1731
2019-10-29 00:41:14,435 Testing Epoch [17/40] Iter[57/62]		Loss: 0.1728
2019-10-29 00:41:14,465 Testing Epoch [17/40] Iter[58/62]		Loss: 0.1724
2019-10-29 00:41:14,495 Testing Epoch [17/40] Iter[59/62]		Loss: 0.1723
2019-10-29 00:41:14,526 Testing Epoch [17/40] Iter[60/62]		Loss: 0.1712
2019-10-29 00:41:14,556 Testing Epoch [17/40] Iter[61/62]		Loss: 0.1712
2019-10-29 00:41:14,573 Testing Epoch [17/40] Iter[62/62]		Loss: 0.1725
2019-10-29 00:41:15,064 Training Epoch [18/40] Iter[0/312]		Loss: 0.1076
2019-10-29 00:41:15,188 Training Epoch [18/40] Iter[1/312]		Loss: 0.1118
2019-10-29 00:41:15,310 Training Epoch [18/40] Iter[2/312]		Loss: 0.1210
2019-10-29 00:41:15,433 Training Epoch [18/40] Iter[3/312]		Loss: 0.1180
2019-10-29 00:41:15,556 Training Epoch [18/40] Iter[4/312]		Loss: 0.1159
2019-10-29 00:41:15,676 Training Epoch [18/40] Iter[5/312]		Loss: 0.1106
2019-10-29 00:41:15,798 Training Epoch [18/40] Iter[6/312]		Loss: 0.1151
2019-10-29 00:41:15,919 Training Epoch [18/40] Iter[7/312]		Loss: 0.1121
2019-10-29 00:41:16,039 Training Epoch [18/40] Iter[8/312]		Loss: 0.1162
2019-10-29 00:41:16,161 Training Epoch [18/40] Iter[9/312]		Loss: 0.1200
2019-10-29 00:41:16,283 Training Epoch [18/40] Iter[10/312]		Loss: 0.1205
2019-10-29 00:41:16,405 Training Epoch [18/40] Iter[11/312]		Loss: 0.1290
2019-10-29 00:41:16,527 Training Epoch [18/40] Iter[12/312]		Loss: 0.1248
2019-10-29 00:41:16,648 Training Epoch [18/40] Iter[13/312]		Loss: 0.1246
2019-10-29 00:41:16,769 Training Epoch [18/40] Iter[14/312]		Loss: 0.1236
2019-10-29 00:41:16,890 Training Epoch [18/40] Iter[15/312]		Loss: 0.1218
2019-10-29 00:41:17,011 Training Epoch [18/40] Iter[16/312]		Loss: 0.1221
2019-10-29 00:41:17,132 Training Epoch [18/40] Iter[17/312]		Loss: 0.1241
2019-10-29 00:41:17,253 Training Epoch [18/40] Iter[18/312]		Loss: 0.1243
2019-10-29 00:41:17,375 Training Epoch [18/40] Iter[19/312]		Loss: 0.1249
2019-10-29 00:41:17,496 Training Epoch [18/40] Iter[20/312]		Loss: 0.1253
2019-10-29 00:41:17,617 Training Epoch [18/40] Iter[21/312]		Loss: 0.1260
2019-10-29 00:41:17,738 Training Epoch [18/40] Iter[22/312]		Loss: 0.1269
2019-10-29 00:41:17,859 Training Epoch [18/40] Iter[23/312]		Loss: 0.1252
2019-10-29 00:41:17,980 Training Epoch [18/40] Iter[24/312]		Loss: 0.1238
2019-10-29 00:41:18,102 Training Epoch [18/40] Iter[25/312]		Loss: 0.1232
2019-10-29 00:41:18,224 Training Epoch [18/40] Iter[26/312]		Loss: 0.1219
2019-10-29 00:41:18,345 Training Epoch [18/40] Iter[27/312]		Loss: 0.1214
2019-10-29 00:41:18,467 Training Epoch [18/40] Iter[28/312]		Loss: 0.1205
2019-10-29 00:41:18,589 Training Epoch [18/40] Iter[29/312]		Loss: 0.1196
2019-10-29 00:41:18,710 Training Epoch [18/40] Iter[30/312]		Loss: 0.1182
2019-10-29 00:41:18,831 Training Epoch [18/40] Iter[31/312]		Loss: 0.1201
2019-10-29 00:41:18,953 Training Epoch [18/40] Iter[32/312]		Loss: 0.1197
2019-10-29 00:41:19,074 Training Epoch [18/40] Iter[33/312]		Loss: 0.1187
2019-10-29 00:41:19,195 Training Epoch [18/40] Iter[34/312]		Loss: 0.1194
2019-10-29 00:41:19,317 Training Epoch [18/40] Iter[35/312]		Loss: 0.1190
2019-10-29 00:41:19,438 Training Epoch [18/40] Iter[36/312]		Loss: 0.1189
2019-10-29 00:41:19,560 Training Epoch [18/40] Iter[37/312]		Loss: 0.1182
2019-10-29 00:41:19,681 Training Epoch [18/40] Iter[38/312]		Loss: 0.1183
2019-10-29 00:41:19,802 Training Epoch [18/40] Iter[39/312]		Loss: 0.1185
2019-10-29 00:41:19,923 Training Epoch [18/40] Iter[40/312]		Loss: 0.1184
2019-10-29 00:41:20,044 Training Epoch [18/40] Iter[41/312]		Loss: 0.1179
2019-10-29 00:41:20,166 Training Epoch [18/40] Iter[42/312]		Loss: 0.1175
2019-10-29 00:41:20,288 Training Epoch [18/40] Iter[43/312]		Loss: 0.1168
2019-10-29 00:41:20,409 Training Epoch [18/40] Iter[44/312]		Loss: 0.1170
2019-10-29 00:41:20,532 Training Epoch [18/40] Iter[45/312]		Loss: 0.1179
2019-10-29 00:41:20,653 Training Epoch [18/40] Iter[46/312]		Loss: 0.1174
2019-10-29 00:41:20,774 Training Epoch [18/40] Iter[47/312]		Loss: 0.1168
2019-10-29 00:41:20,895 Training Epoch [18/40] Iter[48/312]		Loss: 0.1164
2019-10-29 00:41:21,017 Training Epoch [18/40] Iter[49/312]		Loss: 0.1169
2019-10-29 00:41:21,138 Training Epoch [18/40] Iter[50/312]		Loss: 0.1172
2019-10-29 00:41:21,259 Training Epoch [18/40] Iter[51/312]		Loss: 0.1166
2019-10-29 00:41:21,381 Training Epoch [18/40] Iter[52/312]		Loss: 0.1158
2019-10-29 00:41:21,503 Training Epoch [18/40] Iter[53/312]		Loss: 0.1158
2019-10-29 00:41:21,624 Training Epoch [18/40] Iter[54/312]		Loss: 0.1163
2019-10-29 00:41:21,746 Training Epoch [18/40] Iter[55/312]		Loss: 0.1161
2019-10-29 00:41:21,867 Training Epoch [18/40] Iter[56/312]		Loss: 0.1161
2019-10-29 00:41:21,989 Training Epoch [18/40] Iter[57/312]		Loss: 0.1162
2019-10-29 00:41:22,110 Training Epoch [18/40] Iter[58/312]		Loss: 0.1177
2019-10-29 00:41:22,232 Training Epoch [18/40] Iter[59/312]		Loss: 0.1186
2019-10-29 00:41:22,353 Training Epoch [18/40] Iter[60/312]		Loss: 0.1187
2019-10-29 00:41:22,475 Training Epoch [18/40] Iter[61/312]		Loss: 0.1179
2019-10-29 00:41:22,596 Training Epoch [18/40] Iter[62/312]		Loss: 0.1186
2019-10-29 00:41:22,718 Training Epoch [18/40] Iter[63/312]		Loss: 0.1184
2019-10-29 00:41:22,840 Training Epoch [18/40] Iter[64/312]		Loss: 0.1187
2019-10-29 00:41:22,961 Training Epoch [18/40] Iter[65/312]		Loss: 0.1183
2019-10-29 00:41:23,083 Training Epoch [18/40] Iter[66/312]		Loss: 0.1187
2019-10-29 00:41:23,205 Training Epoch [18/40] Iter[67/312]		Loss: 0.1193
2019-10-29 00:41:23,327 Training Epoch [18/40] Iter[68/312]		Loss: 0.1193
2019-10-29 00:41:23,449 Training Epoch [18/40] Iter[69/312]		Loss: 0.1201
2019-10-29 00:41:23,570 Training Epoch [18/40] Iter[70/312]		Loss: 0.1200
2019-10-29 00:41:23,691 Training Epoch [18/40] Iter[71/312]		Loss: 0.1206
2019-10-29 00:41:23,813 Training Epoch [18/40] Iter[72/312]		Loss: 0.1202
2019-10-29 00:41:23,934 Training Epoch [18/40] Iter[73/312]		Loss: 0.1198
2019-10-29 00:41:24,056 Training Epoch [18/40] Iter[74/312]		Loss: 0.1198
2019-10-29 00:41:24,177 Training Epoch [18/40] Iter[75/312]		Loss: 0.1202
2019-10-29 00:41:24,299 Training Epoch [18/40] Iter[76/312]		Loss: 0.1201
2019-10-29 00:41:24,420 Training Epoch [18/40] Iter[77/312]		Loss: 0.1201
2019-10-29 00:41:24,542 Training Epoch [18/40] Iter[78/312]		Loss: 0.1204
2019-10-29 00:41:24,663 Training Epoch [18/40] Iter[79/312]		Loss: 0.1205
2019-10-29 00:41:24,785 Training Epoch [18/40] Iter[80/312]		Loss: 0.1202
2019-10-29 00:41:24,906 Training Epoch [18/40] Iter[81/312]		Loss: 0.1203
2019-10-29 00:41:25,028 Training Epoch [18/40] Iter[82/312]		Loss: 0.1202
2019-10-29 00:41:25,150 Training Epoch [18/40] Iter[83/312]		Loss: 0.1206
2019-10-29 00:41:25,271 Training Epoch [18/40] Iter[84/312]		Loss: 0.1204
2019-10-29 00:41:25,392 Training Epoch [18/40] Iter[85/312]		Loss: 0.1211
2019-10-29 00:41:25,513 Training Epoch [18/40] Iter[86/312]		Loss: 0.1207
2019-10-29 00:41:25,636 Training Epoch [18/40] Iter[87/312]		Loss: 0.1204
2019-10-29 00:41:25,757 Training Epoch [18/40] Iter[88/312]		Loss: 0.1202
2019-10-29 00:41:25,878 Training Epoch [18/40] Iter[89/312]		Loss: 0.1202
2019-10-29 00:41:25,999 Training Epoch [18/40] Iter[90/312]		Loss: 0.1198
2019-10-29 00:41:26,120 Training Epoch [18/40] Iter[91/312]		Loss: 0.1196
2019-10-29 00:41:26,241 Training Epoch [18/40] Iter[92/312]		Loss: 0.1197
2019-10-29 00:41:26,362 Training Epoch [18/40] Iter[93/312]		Loss: 0.1197
2019-10-29 00:41:26,483 Training Epoch [18/40] Iter[94/312]		Loss: 0.1197
2019-10-29 00:41:26,604 Training Epoch [18/40] Iter[95/312]		Loss: 0.1200
2019-10-29 00:41:26,725 Training Epoch [18/40] Iter[96/312]		Loss: 0.1200
2019-10-29 00:41:26,847 Training Epoch [18/40] Iter[97/312]		Loss: 0.1204
2019-10-29 00:41:26,968 Training Epoch [18/40] Iter[98/312]		Loss: 0.1200
2019-10-29 00:41:27,089 Training Epoch [18/40] Iter[99/312]		Loss: 0.1202
2019-10-29 00:41:27,211 Training Epoch [18/40] Iter[100/312]		Loss: 0.1202
2019-10-29 00:41:27,333 Training Epoch [18/40] Iter[101/312]		Loss: 0.1203
2019-10-29 00:41:27,455 Training Epoch [18/40] Iter[102/312]		Loss: 0.1217
2019-10-29 00:41:27,577 Training Epoch [18/40] Iter[103/312]		Loss: 0.1212
2019-10-29 00:41:27,698 Training Epoch [18/40] Iter[104/312]		Loss: 0.1211
2019-10-29 00:41:27,820 Training Epoch [18/40] Iter[105/312]		Loss: 0.1209
2019-10-29 00:41:27,941 Training Epoch [18/40] Iter[106/312]		Loss: 0.1204
2019-10-29 00:41:28,063 Training Epoch [18/40] Iter[107/312]		Loss: 0.1211
2019-10-29 00:41:28,185 Training Epoch [18/40] Iter[108/312]		Loss: 0.1207
2019-10-29 00:41:28,306 Training Epoch [18/40] Iter[109/312]		Loss: 0.1209
2019-10-29 00:41:28,428 Training Epoch [18/40] Iter[110/312]		Loss: 0.1209
2019-10-29 00:41:28,550 Training Epoch [18/40] Iter[111/312]		Loss: 0.1212
2019-10-29 00:41:28,671 Training Epoch [18/40] Iter[112/312]		Loss: 0.1210
2019-10-29 00:41:28,793 Training Epoch [18/40] Iter[113/312]		Loss: 0.1209
2019-10-29 00:41:28,914 Training Epoch [18/40] Iter[114/312]		Loss: 0.1210
2019-10-29 00:41:29,035 Training Epoch [18/40] Iter[115/312]		Loss: 0.1212
2019-10-29 00:41:29,157 Training Epoch [18/40] Iter[116/312]		Loss: 0.1212
2019-10-29 00:41:29,278 Training Epoch [18/40] Iter[117/312]		Loss: 0.1211
2019-10-29 00:41:29,400 Training Epoch [18/40] Iter[118/312]		Loss: 0.1209
2019-10-29 00:41:29,521 Training Epoch [18/40] Iter[119/312]		Loss: 0.1210
2019-10-29 00:41:29,642 Training Epoch [18/40] Iter[120/312]		Loss: 0.1210
2019-10-29 00:41:29,764 Training Epoch [18/40] Iter[121/312]		Loss: 0.1208
2019-10-29 00:41:29,885 Training Epoch [18/40] Iter[122/312]		Loss: 0.1204
2019-10-29 00:41:30,006 Training Epoch [18/40] Iter[123/312]		Loss: 0.1202
2019-10-29 00:41:30,127 Training Epoch [18/40] Iter[124/312]		Loss: 0.1204
2019-10-29 00:41:30,249 Training Epoch [18/40] Iter[125/312]		Loss: 0.1206
2019-10-29 00:41:30,371 Training Epoch [18/40] Iter[126/312]		Loss: 0.1203
2019-10-29 00:41:30,493 Training Epoch [18/40] Iter[127/312]		Loss: 0.1209
2019-10-29 00:41:30,614 Training Epoch [18/40] Iter[128/312]		Loss: 0.1208
2019-10-29 00:41:30,737 Training Epoch [18/40] Iter[129/312]		Loss: 0.1207
2019-10-29 00:41:30,858 Training Epoch [18/40] Iter[130/312]		Loss: 0.1207
2019-10-29 00:41:30,980 Training Epoch [18/40] Iter[131/312]		Loss: 0.1211
2019-10-29 00:41:31,101 Training Epoch [18/40] Iter[132/312]		Loss: 0.1209
2019-10-29 00:41:31,222 Training Epoch [18/40] Iter[133/312]		Loss: 0.1209
2019-10-29 00:41:31,343 Training Epoch [18/40] Iter[134/312]		Loss: 0.1206
2019-10-29 00:41:31,464 Training Epoch [18/40] Iter[135/312]		Loss: 0.1206
2019-10-29 00:41:31,586 Training Epoch [18/40] Iter[136/312]		Loss: 0.1205
2019-10-29 00:41:31,708 Training Epoch [18/40] Iter[137/312]		Loss: 0.1204
2019-10-29 00:41:31,830 Training Epoch [18/40] Iter[138/312]		Loss: 0.1208
2019-10-29 00:41:31,951 Training Epoch [18/40] Iter[139/312]		Loss: 0.1208
2019-10-29 00:41:32,073 Training Epoch [18/40] Iter[140/312]		Loss: 0.1208
2019-10-29 00:41:32,195 Training Epoch [18/40] Iter[141/312]		Loss: 0.1207
2019-10-29 00:41:32,316 Training Epoch [18/40] Iter[142/312]		Loss: 0.1208
2019-10-29 00:41:32,437 Training Epoch [18/40] Iter[143/312]		Loss: 0.1208
2019-10-29 00:41:32,558 Training Epoch [18/40] Iter[144/312]		Loss: 0.1209
2019-10-29 00:41:32,680 Training Epoch [18/40] Iter[145/312]		Loss: 0.1208
2019-10-29 00:41:32,801 Training Epoch [18/40] Iter[146/312]		Loss: 0.1207
2019-10-29 00:41:32,922 Training Epoch [18/40] Iter[147/312]		Loss: 0.1205
2019-10-29 00:41:33,043 Training Epoch [18/40] Iter[148/312]		Loss: 0.1209
2019-10-29 00:41:33,165 Training Epoch [18/40] Iter[149/312]		Loss: 0.1223
2019-10-29 00:41:33,286 Training Epoch [18/40] Iter[150/312]		Loss: 0.1223
2019-10-29 00:41:33,408 Training Epoch [18/40] Iter[151/312]		Loss: 0.1222
2019-10-29 00:41:33,529 Training Epoch [18/40] Iter[152/312]		Loss: 0.1229
2019-10-29 00:41:33,650 Training Epoch [18/40] Iter[153/312]		Loss: 0.1227
2019-10-29 00:41:33,772 Training Epoch [18/40] Iter[154/312]		Loss: 0.1230
2019-10-29 00:41:33,893 Training Epoch [18/40] Iter[155/312]		Loss: 0.1234
2019-10-29 00:41:34,015 Training Epoch [18/40] Iter[156/312]		Loss: 0.1233
2019-10-29 00:41:34,136 Training Epoch [18/40] Iter[157/312]		Loss: 0.1234
2019-10-29 00:41:34,258 Training Epoch [18/40] Iter[158/312]		Loss: 0.1240
2019-10-29 00:41:34,379 Training Epoch [18/40] Iter[159/312]		Loss: 0.1239
2019-10-29 00:41:34,500 Training Epoch [18/40] Iter[160/312]		Loss: 0.1238
2019-10-29 00:41:34,621 Training Epoch [18/40] Iter[161/312]		Loss: 0.1236
2019-10-29 00:41:34,742 Training Epoch [18/40] Iter[162/312]		Loss: 0.1233
2019-10-29 00:41:34,863 Training Epoch [18/40] Iter[163/312]		Loss: 0.1234
2019-10-29 00:41:34,984 Training Epoch [18/40] Iter[164/312]		Loss: 0.1234
2019-10-29 00:41:35,105 Training Epoch [18/40] Iter[165/312]		Loss: 0.1230
2019-10-29 00:41:35,227 Training Epoch [18/40] Iter[166/312]		Loss: 0.1231
2019-10-29 00:41:35,348 Training Epoch [18/40] Iter[167/312]		Loss: 0.1230
2019-10-29 00:41:35,469 Training Epoch [18/40] Iter[168/312]		Loss: 0.1229
2019-10-29 00:41:35,591 Training Epoch [18/40] Iter[169/312]		Loss: 0.1232
2019-10-29 00:41:35,712 Training Epoch [18/40] Iter[170/312]		Loss: 0.1230
2019-10-29 00:41:35,835 Training Epoch [18/40] Iter[171/312]		Loss: 0.1229
2019-10-29 00:41:35,957 Training Epoch [18/40] Iter[172/312]		Loss: 0.1231
2019-10-29 00:41:36,078 Training Epoch [18/40] Iter[173/312]		Loss: 0.1229
2019-10-29 00:41:36,199 Training Epoch [18/40] Iter[174/312]		Loss: 0.1226
2019-10-29 00:41:36,321 Training Epoch [18/40] Iter[175/312]		Loss: 0.1225
2019-10-29 00:41:36,442 Training Epoch [18/40] Iter[176/312]		Loss: 0.1225
2019-10-29 00:41:36,564 Training Epoch [18/40] Iter[177/312]		Loss: 0.1223
2019-10-29 00:41:36,686 Training Epoch [18/40] Iter[178/312]		Loss: 0.1224
2019-10-29 00:41:36,808 Training Epoch [18/40] Iter[179/312]		Loss: 0.1225
2019-10-29 00:41:36,929 Training Epoch [18/40] Iter[180/312]		Loss: 0.1225
2019-10-29 00:41:37,051 Training Epoch [18/40] Iter[181/312]		Loss: 0.1226
2019-10-29 00:41:37,172 Training Epoch [18/40] Iter[182/312]		Loss: 0.1228
2019-10-29 00:41:37,294 Training Epoch [18/40] Iter[183/312]		Loss: 0.1230
2019-10-29 00:41:37,415 Training Epoch [18/40] Iter[184/312]		Loss: 0.1228
2019-10-29 00:41:37,537 Training Epoch [18/40] Iter[185/312]		Loss: 0.1227
2019-10-29 00:41:37,657 Training Epoch [18/40] Iter[186/312]		Loss: 0.1228
2019-10-29 00:41:37,779 Training Epoch [18/40] Iter[187/312]		Loss: 0.1230
2019-10-29 00:41:37,900 Training Epoch [18/40] Iter[188/312]		Loss: 0.1230
2019-10-29 00:41:38,021 Training Epoch [18/40] Iter[189/312]		Loss: 0.1230
2019-10-29 00:41:38,143 Training Epoch [18/40] Iter[190/312]		Loss: 0.1234
2019-10-29 00:41:38,264 Training Epoch [18/40] Iter[191/312]		Loss: 0.1236
2019-10-29 00:41:38,386 Training Epoch [18/40] Iter[192/312]		Loss: 0.1236
2019-10-29 00:41:38,507 Training Epoch [18/40] Iter[193/312]		Loss: 0.1236
2019-10-29 00:41:38,629 Training Epoch [18/40] Iter[194/312]		Loss: 0.1239
2019-10-29 00:41:38,750 Training Epoch [18/40] Iter[195/312]		Loss: 0.1240
2019-10-29 00:41:38,872 Training Epoch [18/40] Iter[196/312]		Loss: 0.1238
2019-10-29 00:41:38,993 Training Epoch [18/40] Iter[197/312]		Loss: 0.1239
2019-10-29 00:41:39,115 Training Epoch [18/40] Iter[198/312]		Loss: 0.1238
2019-10-29 00:41:39,236 Training Epoch [18/40] Iter[199/312]		Loss: 0.1238
2019-10-29 00:41:39,358 Training Epoch [18/40] Iter[200/312]		Loss: 0.1238
2019-10-29 00:41:39,480 Training Epoch [18/40] Iter[201/312]		Loss: 0.1240
2019-10-29 00:41:39,601 Training Epoch [18/40] Iter[202/312]		Loss: 0.1241
2019-10-29 00:41:39,722 Training Epoch [18/40] Iter[203/312]		Loss: 0.1240
2019-10-29 00:41:39,844 Training Epoch [18/40] Iter[204/312]		Loss: 0.1241
2019-10-29 00:41:39,965 Training Epoch [18/40] Iter[205/312]		Loss: 0.1239
2019-10-29 00:41:40,087 Training Epoch [18/40] Iter[206/312]		Loss: 0.1242
2019-10-29 00:41:40,208 Training Epoch [18/40] Iter[207/312]		Loss: 0.1243
2019-10-29 00:41:40,330 Training Epoch [18/40] Iter[208/312]		Loss: 0.1242
2019-10-29 00:41:40,452 Training Epoch [18/40] Iter[209/312]		Loss: 0.1241
2019-10-29 00:41:40,573 Training Epoch [18/40] Iter[210/312]		Loss: 0.1241
2019-10-29 00:41:40,695 Training Epoch [18/40] Iter[211/312]		Loss: 0.1239
2019-10-29 00:41:40,816 Training Epoch [18/40] Iter[212/312]		Loss: 0.1239
2019-10-29 00:41:40,939 Training Epoch [18/40] Iter[213/312]		Loss: 0.1240
2019-10-29 00:41:41,060 Training Epoch [18/40] Iter[214/312]		Loss: 0.1242
2019-10-29 00:41:41,182 Training Epoch [18/40] Iter[215/312]		Loss: 0.1244
2019-10-29 00:41:41,303 Training Epoch [18/40] Iter[216/312]		Loss: 0.1245
2019-10-29 00:41:41,425 Training Epoch [18/40] Iter[217/312]		Loss: 0.1243
2019-10-29 00:41:41,546 Training Epoch [18/40] Iter[218/312]		Loss: 0.1242
2019-10-29 00:41:41,667 Training Epoch [18/40] Iter[219/312]		Loss: 0.1241
2019-10-29 00:41:41,789 Training Epoch [18/40] Iter[220/312]		Loss: 0.1240
2019-10-29 00:41:41,910 Training Epoch [18/40] Iter[221/312]		Loss: 0.1241
2019-10-29 00:41:42,031 Training Epoch [18/40] Iter[222/312]		Loss: 0.1240
2019-10-29 00:41:42,153 Training Epoch [18/40] Iter[223/312]		Loss: 0.1242
2019-10-29 00:41:42,274 Training Epoch [18/40] Iter[224/312]		Loss: 0.1243
2019-10-29 00:41:42,396 Training Epoch [18/40] Iter[225/312]		Loss: 0.1241
2019-10-29 00:41:42,518 Training Epoch [18/40] Iter[226/312]		Loss: 0.1243
2019-10-29 00:41:42,639 Training Epoch [18/40] Iter[227/312]		Loss: 0.1241
2019-10-29 00:41:42,760 Training Epoch [18/40] Iter[228/312]		Loss: 0.1241
2019-10-29 00:41:42,881 Training Epoch [18/40] Iter[229/312]		Loss: 0.1241
2019-10-29 00:41:43,002 Training Epoch [18/40] Iter[230/312]		Loss: 0.1243
2019-10-29 00:41:43,123 Training Epoch [18/40] Iter[231/312]		Loss: 0.1245
2019-10-29 00:41:43,245 Training Epoch [18/40] Iter[232/312]		Loss: 0.1245
2019-10-29 00:41:43,366 Training Epoch [18/40] Iter[233/312]		Loss: 0.1244
2019-10-29 00:41:43,487 Training Epoch [18/40] Iter[234/312]		Loss: 0.1247
2019-10-29 00:41:43,608 Training Epoch [18/40] Iter[235/312]		Loss: 0.1247
2019-10-29 00:41:43,729 Training Epoch [18/40] Iter[236/312]		Loss: 0.1246
2019-10-29 00:41:43,850 Training Epoch [18/40] Iter[237/312]		Loss: 0.1246
2019-10-29 00:41:43,972 Training Epoch [18/40] Iter[238/312]		Loss: 0.1246
2019-10-29 00:41:44,093 Training Epoch [18/40] Iter[239/312]		Loss: 0.1250
2019-10-29 00:41:44,215 Training Epoch [18/40] Iter[240/312]		Loss: 0.1251
2019-10-29 00:41:44,337 Training Epoch [18/40] Iter[241/312]		Loss: 0.1250
2019-10-29 00:41:44,458 Training Epoch [18/40] Iter[242/312]		Loss: 0.1249
2019-10-29 00:41:44,580 Training Epoch [18/40] Iter[243/312]		Loss: 0.1248
2019-10-29 00:41:44,701 Training Epoch [18/40] Iter[244/312]		Loss: 0.1249
2019-10-29 00:41:44,822 Training Epoch [18/40] Iter[245/312]		Loss: 0.1248
2019-10-29 00:41:44,944 Training Epoch [18/40] Iter[246/312]		Loss: 0.1249
2019-10-29 00:41:45,066 Training Epoch [18/40] Iter[247/312]		Loss: 0.1249
2019-10-29 00:41:45,187 Training Epoch [18/40] Iter[248/312]		Loss: 0.1248
2019-10-29 00:41:45,309 Training Epoch [18/40] Iter[249/312]		Loss: 0.1246
2019-10-29 00:41:45,431 Training Epoch [18/40] Iter[250/312]		Loss: 0.1245
2019-10-29 00:41:45,553 Training Epoch [18/40] Iter[251/312]		Loss: 0.1243
2019-10-29 00:41:45,674 Training Epoch [18/40] Iter[252/312]		Loss: 0.1243
2019-10-29 00:41:45,795 Training Epoch [18/40] Iter[253/312]		Loss: 0.1244
2019-10-29 00:41:45,917 Training Epoch [18/40] Iter[254/312]		Loss: 0.1242
2019-10-29 00:41:46,040 Training Epoch [18/40] Iter[255/312]		Loss: 0.1241
2019-10-29 00:41:46,161 Training Epoch [18/40] Iter[256/312]		Loss: 0.1239
2019-10-29 00:41:46,282 Training Epoch [18/40] Iter[257/312]		Loss: 0.1238
2019-10-29 00:41:46,404 Training Epoch [18/40] Iter[258/312]		Loss: 0.1238
2019-10-29 00:41:46,525 Training Epoch [18/40] Iter[259/312]		Loss: 0.1238
2019-10-29 00:41:46,646 Training Epoch [18/40] Iter[260/312]		Loss: 0.1238
2019-10-29 00:41:46,767 Training Epoch [18/40] Iter[261/312]		Loss: 0.1238
2019-10-29 00:41:46,889 Training Epoch [18/40] Iter[262/312]		Loss: 0.1237
2019-10-29 00:41:47,010 Training Epoch [18/40] Iter[263/312]		Loss: 0.1237
2019-10-29 00:41:47,132 Training Epoch [18/40] Iter[264/312]		Loss: 0.1237
2019-10-29 00:41:47,254 Training Epoch [18/40] Iter[265/312]		Loss: 0.1238
2019-10-29 00:41:47,376 Training Epoch [18/40] Iter[266/312]		Loss: 0.1240
2019-10-29 00:41:47,497 Training Epoch [18/40] Iter[267/312]		Loss: 0.1239
2019-10-29 00:41:47,619 Training Epoch [18/40] Iter[268/312]		Loss: 0.1238
2019-10-29 00:41:47,740 Training Epoch [18/40] Iter[269/312]		Loss: 0.1238
2019-10-29 00:41:47,862 Training Epoch [18/40] Iter[270/312]		Loss: 0.1239
2019-10-29 00:41:47,983 Training Epoch [18/40] Iter[271/312]		Loss: 0.1238
2019-10-29 00:41:48,104 Training Epoch [18/40] Iter[272/312]		Loss: 0.1240
2019-10-29 00:41:48,226 Training Epoch [18/40] Iter[273/312]		Loss: 0.1241
2019-10-29 00:41:48,347 Training Epoch [18/40] Iter[274/312]		Loss: 0.1242
2019-10-29 00:41:48,469 Training Epoch [18/40] Iter[275/312]		Loss: 0.1243
2019-10-29 00:41:48,591 Training Epoch [18/40] Iter[276/312]		Loss: 0.1243
2019-10-29 00:41:48,712 Training Epoch [18/40] Iter[277/312]		Loss: 0.1242
2019-10-29 00:41:48,834 Training Epoch [18/40] Iter[278/312]		Loss: 0.1242
2019-10-29 00:41:48,955 Training Epoch [18/40] Iter[279/312]		Loss: 0.1241
2019-10-29 00:41:49,076 Training Epoch [18/40] Iter[280/312]		Loss: 0.1240
2019-10-29 00:41:49,198 Training Epoch [18/40] Iter[281/312]		Loss: 0.1239
2019-10-29 00:41:49,319 Training Epoch [18/40] Iter[282/312]		Loss: 0.1239
2019-10-29 00:41:49,441 Training Epoch [18/40] Iter[283/312]		Loss: 0.1240
2019-10-29 00:41:49,562 Training Epoch [18/40] Iter[284/312]		Loss: 0.1240
2019-10-29 00:41:49,684 Training Epoch [18/40] Iter[285/312]		Loss: 0.1239
2019-10-29 00:41:49,805 Training Epoch [18/40] Iter[286/312]		Loss: 0.1240
2019-10-29 00:41:49,927 Training Epoch [18/40] Iter[287/312]		Loss: 0.1240
2019-10-29 00:41:50,053 Training Epoch [18/40] Iter[288/312]		Loss: 0.1240
2019-10-29 00:41:50,174 Training Epoch [18/40] Iter[289/312]		Loss: 0.1240
2019-10-29 00:41:50,296 Training Epoch [18/40] Iter[290/312]		Loss: 0.1241
2019-10-29 00:41:50,418 Training Epoch [18/40] Iter[291/312]		Loss: 0.1239
2019-10-29 00:41:50,539 Training Epoch [18/40] Iter[292/312]		Loss: 0.1239
2019-10-29 00:41:50,661 Training Epoch [18/40] Iter[293/312]		Loss: 0.1239
2019-10-29 00:41:50,783 Training Epoch [18/40] Iter[294/312]		Loss: 0.1241
2019-10-29 00:41:50,905 Training Epoch [18/40] Iter[295/312]		Loss: 0.1245
2019-10-29 00:41:51,026 Training Epoch [18/40] Iter[296/312]		Loss: 0.1243
2019-10-29 00:41:51,147 Training Epoch [18/40] Iter[297/312]		Loss: 0.1242
2019-10-29 00:41:51,268 Training Epoch [18/40] Iter[298/312]		Loss: 0.1243
2019-10-29 00:41:51,389 Training Epoch [18/40] Iter[299/312]		Loss: 0.1241
2019-10-29 00:41:51,510 Training Epoch [18/40] Iter[300/312]		Loss: 0.1242
2019-10-29 00:41:51,631 Training Epoch [18/40] Iter[301/312]		Loss: 0.1243
2019-10-29 00:41:51,752 Training Epoch [18/40] Iter[302/312]		Loss: 0.1242
2019-10-29 00:41:51,874 Training Epoch [18/40] Iter[303/312]		Loss: 0.1242
2019-10-29 00:41:51,995 Training Epoch [18/40] Iter[304/312]		Loss: 0.1242
2019-10-29 00:41:52,115 Training Epoch [18/40] Iter[305/312]		Loss: 0.1243
2019-10-29 00:41:52,237 Training Epoch [18/40] Iter[306/312]		Loss: 0.1241
2019-10-29 00:41:52,358 Training Epoch [18/40] Iter[307/312]		Loss: 0.1240
2019-10-29 00:41:52,479 Training Epoch [18/40] Iter[308/312]		Loss: 0.1240
2019-10-29 00:41:52,600 Training Epoch [18/40] Iter[309/312]		Loss: 0.1241
2019-10-29 00:41:52,721 Training Epoch [18/40] Iter[310/312]		Loss: 0.1240
2019-10-29 00:41:52,842 Training Epoch [18/40] Iter[311/312]		Loss: 0.1240
2019-10-29 00:41:52,902 Training Epoch [18/40] Iter[312/312]		Loss: 0.1239
2019-10-29 00:41:53,289 Testing Epoch [18/40] Iter[0/62]		Loss: 0.1028
2019-10-29 00:41:53,322 Testing Epoch [18/40] Iter[1/62]		Loss: 0.1322
2019-10-29 00:41:53,362 Testing Epoch [18/40] Iter[2/62]		Loss: 0.1243
2019-10-29 00:41:53,393 Testing Epoch [18/40] Iter[3/62]		Loss: 0.1225
2019-10-29 00:41:53,430 Testing Epoch [18/40] Iter[4/62]		Loss: 0.1179
2019-10-29 00:41:53,460 Testing Epoch [18/40] Iter[5/62]		Loss: 0.1140
2019-10-29 00:41:53,490 Testing Epoch [18/40] Iter[6/62]		Loss: 0.1154
2019-10-29 00:41:53,526 Testing Epoch [18/40] Iter[7/62]		Loss: 0.1212
2019-10-29 00:41:53,558 Testing Epoch [18/40] Iter[8/62]		Loss: 0.1274
2019-10-29 00:41:53,587 Testing Epoch [18/40] Iter[9/62]		Loss: 0.1256
2019-10-29 00:41:53,622 Testing Epoch [18/40] Iter[10/62]		Loss: 0.1245
2019-10-29 00:41:53,652 Testing Epoch [18/40] Iter[11/62]		Loss: 0.1285
2019-10-29 00:41:53,689 Testing Epoch [18/40] Iter[12/62]		Loss: 0.1284
2019-10-29 00:41:53,722 Testing Epoch [18/40] Iter[13/62]		Loss: 0.1302
2019-10-29 00:41:53,754 Testing Epoch [18/40] Iter[14/62]		Loss: 0.1429
2019-10-29 00:41:53,785 Testing Epoch [18/40] Iter[15/62]		Loss: 0.1447
2019-10-29 00:41:53,815 Testing Epoch [18/40] Iter[16/62]		Loss: 0.1435
2019-10-29 00:41:53,850 Testing Epoch [18/40] Iter[17/62]		Loss: 0.1422
2019-10-29 00:41:53,880 Testing Epoch [18/40] Iter[18/62]		Loss: 0.1388
2019-10-29 00:41:53,911 Testing Epoch [18/40] Iter[19/62]		Loss: 0.1370
2019-10-29 00:41:53,946 Testing Epoch [18/40] Iter[20/62]		Loss: 0.1384
2019-10-29 00:41:53,977 Testing Epoch [18/40] Iter[21/62]		Loss: 0.1365
2019-10-29 00:41:54,007 Testing Epoch [18/40] Iter[22/62]		Loss: 0.1364
2019-10-29 00:41:54,042 Testing Epoch [18/40] Iter[23/62]		Loss: 0.1365
2019-10-29 00:41:54,073 Testing Epoch [18/40] Iter[24/62]		Loss: 0.1387
2019-10-29 00:41:54,104 Testing Epoch [18/40] Iter[25/62]		Loss: 0.1380
2019-10-29 00:41:54,138 Testing Epoch [18/40] Iter[26/62]		Loss: 0.1371
2019-10-29 00:41:54,169 Testing Epoch [18/40] Iter[27/62]		Loss: 0.1418
2019-10-29 00:41:54,200 Testing Epoch [18/40] Iter[28/62]		Loss: 0.1435
2019-10-29 00:41:54,238 Testing Epoch [18/40] Iter[29/62]		Loss: 0.1437
2019-10-29 00:41:54,269 Testing Epoch [18/40] Iter[30/62]		Loss: 0.1457
2019-10-29 00:41:54,300 Testing Epoch [18/40] Iter[31/62]		Loss: 0.1452
2019-10-29 00:41:54,330 Testing Epoch [18/40] Iter[32/62]		Loss: 0.1468
2019-10-29 00:41:54,361 Testing Epoch [18/40] Iter[33/62]		Loss: 0.1449
2019-10-29 00:41:54,392 Testing Epoch [18/40] Iter[34/62]		Loss: 0.1465
2019-10-29 00:41:54,423 Testing Epoch [18/40] Iter[35/62]		Loss: 0.1467
2019-10-29 00:41:54,453 Testing Epoch [18/40] Iter[36/62]		Loss: 0.1449
2019-10-29 00:41:54,484 Testing Epoch [18/40] Iter[37/62]		Loss: 0.1446
2019-10-29 00:41:54,515 Testing Epoch [18/40] Iter[38/62]		Loss: 0.1447
2019-10-29 00:41:54,546 Testing Epoch [18/40] Iter[39/62]		Loss: 0.1451
2019-10-29 00:41:54,576 Testing Epoch [18/40] Iter[40/62]		Loss: 0.1458
2019-10-29 00:41:54,607 Testing Epoch [18/40] Iter[41/62]		Loss: 0.1460
2019-10-29 00:41:54,638 Testing Epoch [18/40] Iter[42/62]		Loss: 0.1449
2019-10-29 00:41:54,669 Testing Epoch [18/40] Iter[43/62]		Loss: 0.1443
2019-10-29 00:41:54,700 Testing Epoch [18/40] Iter[44/62]		Loss: 0.1432
2019-10-29 00:41:54,731 Testing Epoch [18/40] Iter[45/62]		Loss: 0.1440
2019-10-29 00:41:54,762 Testing Epoch [18/40] Iter[46/62]		Loss: 0.1443
2019-10-29 00:41:54,793 Testing Epoch [18/40] Iter[47/62]		Loss: 0.1491
2019-10-29 00:41:54,823 Testing Epoch [18/40] Iter[48/62]		Loss: 0.1481
2019-10-29 00:41:54,854 Testing Epoch [18/40] Iter[49/62]		Loss: 0.1494
2019-10-29 00:41:54,885 Testing Epoch [18/40] Iter[50/62]		Loss: 0.1490
2019-10-29 00:41:54,916 Testing Epoch [18/40] Iter[51/62]		Loss: 0.1490
2019-10-29 00:41:54,947 Testing Epoch [18/40] Iter[52/62]		Loss: 0.1477
2019-10-29 00:41:54,978 Testing Epoch [18/40] Iter[53/62]		Loss: 0.1475
2019-10-29 00:41:55,008 Testing Epoch [18/40] Iter[54/62]		Loss: 0.1468
2019-10-29 00:41:55,038 Testing Epoch [18/40] Iter[55/62]		Loss: 0.1469
2019-10-29 00:41:55,069 Testing Epoch [18/40] Iter[56/62]		Loss: 0.1466
2019-10-29 00:41:55,099 Testing Epoch [18/40] Iter[57/62]		Loss: 0.1463
2019-10-29 00:41:55,129 Testing Epoch [18/40] Iter[58/62]		Loss: 0.1459
2019-10-29 00:41:55,159 Testing Epoch [18/40] Iter[59/62]		Loss: 0.1459
2019-10-29 00:41:55,190 Testing Epoch [18/40] Iter[60/62]		Loss: 0.1451
2019-10-29 00:41:55,220 Testing Epoch [18/40] Iter[61/62]		Loss: 0.1448
2019-10-29 00:41:55,237 Testing Epoch [18/40] Iter[62/62]		Loss: 0.1461
2019-10-29 00:41:55,301 Saving the Model
2019-10-29 00:41:55,740 Training Epoch [19/40] Iter[0/312]		Loss: 0.1159
2019-10-29 00:41:55,861 Training Epoch [19/40] Iter[1/312]		Loss: 0.1091
2019-10-29 00:41:55,984 Training Epoch [19/40] Iter[2/312]		Loss: 0.1109
2019-10-29 00:41:56,106 Training Epoch [19/40] Iter[3/312]		Loss: 0.1101
2019-10-29 00:41:56,229 Training Epoch [19/40] Iter[4/312]		Loss: 0.1142
2019-10-29 00:41:56,351 Training Epoch [19/40] Iter[5/312]		Loss: 0.1130
2019-10-29 00:41:56,472 Training Epoch [19/40] Iter[6/312]		Loss: 0.1209
2019-10-29 00:41:56,593 Training Epoch [19/40] Iter[7/312]		Loss: 0.1212
2019-10-29 00:41:56,714 Training Epoch [19/40] Iter[8/312]		Loss: 0.1190
2019-10-29 00:41:56,836 Training Epoch [19/40] Iter[9/312]		Loss: 0.1183
2019-10-29 00:41:56,958 Training Epoch [19/40] Iter[10/312]		Loss: 0.1207
2019-10-29 00:41:57,079 Training Epoch [19/40] Iter[11/312]		Loss: 0.1202
2019-10-29 00:41:57,200 Training Epoch [19/40] Iter[12/312]		Loss: 0.1232
2019-10-29 00:41:57,322 Training Epoch [19/40] Iter[13/312]		Loss: 0.1251
2019-10-29 00:41:57,443 Training Epoch [19/40] Iter[14/312]		Loss: 0.1213
2019-10-29 00:41:57,565 Training Epoch [19/40] Iter[15/312]		Loss: 0.1219
2019-10-29 00:41:57,686 Training Epoch [19/40] Iter[16/312]		Loss: 0.1237
2019-10-29 00:41:57,807 Training Epoch [19/40] Iter[17/312]		Loss: 0.1230
2019-10-29 00:41:57,929 Training Epoch [19/40] Iter[18/312]		Loss: 0.1230
2019-10-29 00:41:58,050 Training Epoch [19/40] Iter[19/312]		Loss: 0.1219
2019-10-29 00:41:58,172 Training Epoch [19/40] Iter[20/312]		Loss: 0.1236
2019-10-29 00:41:58,293 Training Epoch [19/40] Iter[21/312]		Loss: 0.1232
2019-10-29 00:41:58,414 Training Epoch [19/40] Iter[22/312]		Loss: 0.1244
2019-10-29 00:41:58,536 Training Epoch [19/40] Iter[23/312]		Loss: 0.1230
2019-10-29 00:41:58,657 Training Epoch [19/40] Iter[24/312]		Loss: 0.1221
2019-10-29 00:41:58,778 Training Epoch [19/40] Iter[25/312]		Loss: 0.1225
2019-10-29 00:41:58,900 Training Epoch [19/40] Iter[26/312]		Loss: 0.1224
2019-10-29 00:41:59,021 Training Epoch [19/40] Iter[27/312]		Loss: 0.1227
2019-10-29 00:41:59,142 Training Epoch [19/40] Iter[28/312]		Loss: 0.1228
2019-10-29 00:41:59,263 Training Epoch [19/40] Iter[29/312]		Loss: 0.1230
2019-10-29 00:41:59,385 Training Epoch [19/40] Iter[30/312]		Loss: 0.1220
2019-10-29 00:41:59,506 Training Epoch [19/40] Iter[31/312]		Loss: 0.1217
2019-10-29 00:41:59,627 Training Epoch [19/40] Iter[32/312]		Loss: 0.1228
2019-10-29 00:41:59,748 Training Epoch [19/40] Iter[33/312]		Loss: 0.1235
2019-10-29 00:41:59,869 Training Epoch [19/40] Iter[34/312]		Loss: 0.1242
2019-10-29 00:41:59,990 Training Epoch [19/40] Iter[35/312]		Loss: 0.1240
2019-10-29 00:42:00,112 Training Epoch [19/40] Iter[36/312]		Loss: 0.1237
2019-10-29 00:42:00,233 Training Epoch [19/40] Iter[37/312]		Loss: 0.1253
2019-10-29 00:42:00,354 Training Epoch [19/40] Iter[38/312]		Loss: 0.1253
2019-10-29 00:42:00,476 Training Epoch [19/40] Iter[39/312]		Loss: 0.1262
2019-10-29 00:42:00,604 Training Epoch [19/40] Iter[40/312]		Loss: 0.1255
2019-10-29 00:42:00,725 Training Epoch [19/40] Iter[41/312]		Loss: 0.1252
2019-10-29 00:42:00,847 Training Epoch [19/40] Iter[42/312]		Loss: 0.1262
2019-10-29 00:42:00,968 Training Epoch [19/40] Iter[43/312]		Loss: 0.1250
2019-10-29 00:42:01,090 Training Epoch [19/40] Iter[44/312]		Loss: 0.1250
2019-10-29 00:42:01,212 Training Epoch [19/40] Iter[45/312]		Loss: 0.1252
2019-10-29 00:42:01,333 Training Epoch [19/40] Iter[46/312]		Loss: 0.1248
2019-10-29 00:42:01,455 Training Epoch [19/40] Iter[47/312]		Loss: 0.1249
2019-10-29 00:42:01,576 Training Epoch [19/40] Iter[48/312]		Loss: 0.1253
2019-10-29 00:42:01,698 Training Epoch [19/40] Iter[49/312]		Loss: 0.1246
2019-10-29 00:42:01,828 Training Epoch [19/40] Iter[50/312]		Loss: 0.1241
2019-10-29 00:42:01,952 Training Epoch [19/40] Iter[51/312]		Loss: 0.1248
2019-10-29 00:42:02,074 Training Epoch [19/40] Iter[52/312]		Loss: 0.1238
2019-10-29 00:42:02,196 Training Epoch [19/40] Iter[53/312]		Loss: 0.1231
2019-10-29 00:42:02,320 Training Epoch [19/40] Iter[54/312]		Loss: 0.1226
2019-10-29 00:42:02,444 Training Epoch [19/40] Iter[55/312]		Loss: 0.1233
2019-10-29 00:42:02,566 Training Epoch [19/40] Iter[56/312]		Loss: 0.1232
2019-10-29 00:42:02,688 Training Epoch [19/40] Iter[57/312]		Loss: 0.1232
2019-10-29 00:42:02,815 Training Epoch [19/40] Iter[58/312]		Loss: 0.1230
2019-10-29 00:42:02,937 Training Epoch [19/40] Iter[59/312]		Loss: 0.1229
2019-10-29 00:42:03,058 Training Epoch [19/40] Iter[60/312]		Loss: 0.1227
2019-10-29 00:42:03,179 Training Epoch [19/40] Iter[61/312]		Loss: 0.1223
2019-10-29 00:42:03,301 Training Epoch [19/40] Iter[62/312]		Loss: 0.1220
2019-10-29 00:42:03,423 Training Epoch [19/40] Iter[63/312]		Loss: 0.1227
2019-10-29 00:42:03,545 Training Epoch [19/40] Iter[64/312]		Loss: 0.1225
2019-10-29 00:42:03,666 Training Epoch [19/40] Iter[65/312]		Loss: 0.1220
2019-10-29 00:42:03,788 Training Epoch [19/40] Iter[66/312]		Loss: 0.1216
2019-10-29 00:42:03,910 Training Epoch [19/40] Iter[67/312]		Loss: 0.1211
2019-10-29 00:42:04,031 Training Epoch [19/40] Iter[68/312]		Loss: 0.1208
2019-10-29 00:42:04,153 Training Epoch [19/40] Iter[69/312]		Loss: 0.1204
2019-10-29 00:42:04,275 Training Epoch [19/40] Iter[70/312]		Loss: 0.1199
2019-10-29 00:42:04,400 Training Epoch [19/40] Iter[71/312]		Loss: 0.1196
2019-10-29 00:42:04,522 Training Epoch [19/40] Iter[72/312]		Loss: 0.1200
2019-10-29 00:42:04,644 Training Epoch [19/40] Iter[73/312]		Loss: 0.1203
2019-10-29 00:42:04,766 Training Epoch [19/40] Iter[74/312]		Loss: 0.1202
2019-10-29 00:42:04,888 Training Epoch [19/40] Iter[75/312]		Loss: 0.1198
2019-10-29 00:42:05,010 Training Epoch [19/40] Iter[76/312]		Loss: 0.1197
2019-10-29 00:42:05,131 Training Epoch [19/40] Iter[77/312]		Loss: 0.1190
2019-10-29 00:42:05,252 Training Epoch [19/40] Iter[78/312]		Loss: 0.1190
2019-10-29 00:42:05,375 Training Epoch [19/40] Iter[79/312]		Loss: 0.1193
2019-10-29 00:42:05,497 Training Epoch [19/40] Iter[80/312]		Loss: 0.1198
2019-10-29 00:42:05,619 Training Epoch [19/40] Iter[81/312]		Loss: 0.1201
2019-10-29 00:42:05,740 Training Epoch [19/40] Iter[82/312]		Loss: 0.1202
2019-10-29 00:42:05,863 Training Epoch [19/40] Iter[83/312]		Loss: 0.1208
2019-10-29 00:42:05,985 Training Epoch [19/40] Iter[84/312]		Loss: 0.1206
2019-10-29 00:42:06,106 Training Epoch [19/40] Iter[85/312]		Loss: 0.1208
2019-10-29 00:42:06,228 Training Epoch [19/40] Iter[86/312]		Loss: 0.1211
2019-10-29 00:42:06,350 Training Epoch [19/40] Iter[87/312]		Loss: 0.1212
2019-10-29 00:42:06,476 Training Epoch [19/40] Iter[88/312]		Loss: 0.1212
2019-10-29 00:42:06,598 Training Epoch [19/40] Iter[89/312]		Loss: 0.1209
2019-10-29 00:42:06,720 Training Epoch [19/40] Iter[90/312]		Loss: 0.1212
2019-10-29 00:42:06,841 Training Epoch [19/40] Iter[91/312]		Loss: 0.1212
2019-10-29 00:42:06,963 Training Epoch [19/40] Iter[92/312]		Loss: 0.1210
2019-10-29 00:42:07,084 Training Epoch [19/40] Iter[93/312]		Loss: 0.1208
2019-10-29 00:42:07,206 Training Epoch [19/40] Iter[94/312]		Loss: 0.1203
2019-10-29 00:42:07,328 Training Epoch [19/40] Iter[95/312]		Loss: 0.1202
2019-10-29 00:42:07,449 Training Epoch [19/40] Iter[96/312]		Loss: 0.1204
2019-10-29 00:42:07,571 Training Epoch [19/40] Iter[97/312]		Loss: 0.1200
2019-10-29 00:42:07,692 Training Epoch [19/40] Iter[98/312]		Loss: 0.1200
2019-10-29 00:42:07,814 Training Epoch [19/40] Iter[99/312]		Loss: 0.1199
2019-10-29 00:42:07,935 Training Epoch [19/40] Iter[100/312]		Loss: 0.1197
2019-10-29 00:42:08,056 Training Epoch [19/40] Iter[101/312]		Loss: 0.1196
2019-10-29 00:42:08,178 Training Epoch [19/40] Iter[102/312]		Loss: 0.1192
2019-10-29 00:42:08,299 Training Epoch [19/40] Iter[103/312]		Loss: 0.1190
2019-10-29 00:42:08,420 Training Epoch [19/40] Iter[104/312]		Loss: 0.1190
2019-10-29 00:42:08,541 Training Epoch [19/40] Iter[105/312]		Loss: 0.1190
2019-10-29 00:42:08,662 Training Epoch [19/40] Iter[106/312]		Loss: 0.1189
2019-10-29 00:42:08,783 Training Epoch [19/40] Iter[107/312]		Loss: 0.1188
2019-10-29 00:42:08,904 Training Epoch [19/40] Iter[108/312]		Loss: 0.1185
2019-10-29 00:42:09,025 Training Epoch [19/40] Iter[109/312]		Loss: 0.1190
2019-10-29 00:42:09,146 Training Epoch [19/40] Iter[110/312]		Loss: 0.1191
2019-10-29 00:42:09,268 Training Epoch [19/40] Iter[111/312]		Loss: 0.1188
2019-10-29 00:42:09,389 Training Epoch [19/40] Iter[112/312]		Loss: 0.1187
2019-10-29 00:42:09,511 Training Epoch [19/40] Iter[113/312]		Loss: 0.1188
2019-10-29 00:42:09,632 Training Epoch [19/40] Iter[114/312]		Loss: 0.1190
2019-10-29 00:42:09,754 Training Epoch [19/40] Iter[115/312]		Loss: 0.1188
2019-10-29 00:42:09,875 Training Epoch [19/40] Iter[116/312]		Loss: 0.1190
2019-10-29 00:42:09,996 Training Epoch [19/40] Iter[117/312]		Loss: 0.1190
2019-10-29 00:42:10,118 Training Epoch [19/40] Iter[118/312]		Loss: 0.1189
2019-10-29 00:42:10,239 Training Epoch [19/40] Iter[119/312]		Loss: 0.1189
2019-10-29 00:42:10,361 Training Epoch [19/40] Iter[120/312]		Loss: 0.1194
2019-10-29 00:42:10,483 Training Epoch [19/40] Iter[121/312]		Loss: 0.1194
2019-10-29 00:42:10,604 Training Epoch [19/40] Iter[122/312]		Loss: 0.1196
2019-10-29 00:42:10,726 Training Epoch [19/40] Iter[123/312]		Loss: 0.1198
2019-10-29 00:42:10,847 Training Epoch [19/40] Iter[124/312]		Loss: 0.1199
2019-10-29 00:42:10,969 Training Epoch [19/40] Iter[125/312]		Loss: 0.1199
2019-10-29 00:42:11,090 Training Epoch [19/40] Iter[126/312]		Loss: 0.1202
2019-10-29 00:42:11,211 Training Epoch [19/40] Iter[127/312]		Loss: 0.1203
2019-10-29 00:42:11,333 Training Epoch [19/40] Iter[128/312]		Loss: 0.1202
2019-10-29 00:42:11,454 Training Epoch [19/40] Iter[129/312]		Loss: 0.1205
2019-10-29 00:42:11,576 Training Epoch [19/40] Iter[130/312]		Loss: 0.1203
2019-10-29 00:42:11,697 Training Epoch [19/40] Iter[131/312]		Loss: 0.1206
2019-10-29 00:42:11,820 Training Epoch [19/40] Iter[132/312]		Loss: 0.1210
2019-10-29 00:42:11,941 Training Epoch [19/40] Iter[133/312]		Loss: 0.1216
2019-10-29 00:42:12,062 Training Epoch [19/40] Iter[134/312]		Loss: 0.1220
2019-10-29 00:42:12,183 Training Epoch [19/40] Iter[135/312]		Loss: 0.1223
2019-10-29 00:42:12,305 Training Epoch [19/40] Iter[136/312]		Loss: 0.1222
2019-10-29 00:42:12,426 Training Epoch [19/40] Iter[137/312]		Loss: 0.1224
2019-10-29 00:42:12,547 Training Epoch [19/40] Iter[138/312]		Loss: 0.1230
2019-10-29 00:42:12,670 Training Epoch [19/40] Iter[139/312]		Loss: 0.1230
2019-10-29 00:42:12,791 Training Epoch [19/40] Iter[140/312]		Loss: 0.1228
2019-10-29 00:42:12,913 Training Epoch [19/40] Iter[141/312]		Loss: 0.1230
2019-10-29 00:42:13,034 Training Epoch [19/40] Iter[142/312]		Loss: 0.1230
2019-10-29 00:42:13,156 Training Epoch [19/40] Iter[143/312]		Loss: 0.1228
2019-10-29 00:42:13,278 Training Epoch [19/40] Iter[144/312]		Loss: 0.1228
2019-10-29 00:42:13,399 Training Epoch [19/40] Iter[145/312]		Loss: 0.1227
2019-10-29 00:42:13,521 Training Epoch [19/40] Iter[146/312]		Loss: 0.1226
2019-10-29 00:42:13,642 Training Epoch [19/40] Iter[147/312]		Loss: 0.1224
2019-10-29 00:42:13,764 Training Epoch [19/40] Iter[148/312]		Loss: 0.1226
2019-10-29 00:42:13,885 Training Epoch [19/40] Iter[149/312]		Loss: 0.1230
2019-10-29 00:42:14,007 Training Epoch [19/40] Iter[150/312]		Loss: 0.1231
2019-10-29 00:42:14,129 Training Epoch [19/40] Iter[151/312]		Loss: 0.1232
2019-10-29 00:42:14,250 Training Epoch [19/40] Iter[152/312]		Loss: 0.1234
2019-10-29 00:42:14,372 Training Epoch [19/40] Iter[153/312]		Loss: 0.1233
2019-10-29 00:42:14,493 Training Epoch [19/40] Iter[154/312]		Loss: 0.1238
2019-10-29 00:42:14,614 Training Epoch [19/40] Iter[155/312]		Loss: 0.1239
2019-10-29 00:42:14,736 Training Epoch [19/40] Iter[156/312]		Loss: 0.1240
2019-10-29 00:42:14,857 Training Epoch [19/40] Iter[157/312]		Loss: 0.1241
2019-10-29 00:42:14,979 Training Epoch [19/40] Iter[158/312]		Loss: 0.1241
2019-10-29 00:42:15,100 Training Epoch [19/40] Iter[159/312]		Loss: 0.1244
2019-10-29 00:42:15,221 Training Epoch [19/40] Iter[160/312]		Loss: 0.1244
2019-10-29 00:42:15,343 Training Epoch [19/40] Iter[161/312]		Loss: 0.1243
2019-10-29 00:42:15,464 Training Epoch [19/40] Iter[162/312]		Loss: 0.1243
2019-10-29 00:42:15,585 Training Epoch [19/40] Iter[163/312]		Loss: 0.1245
2019-10-29 00:42:15,707 Training Epoch [19/40] Iter[164/312]		Loss: 0.1245
2019-10-29 00:42:15,829 Training Epoch [19/40] Iter[165/312]		Loss: 0.1244
2019-10-29 00:42:15,950 Training Epoch [19/40] Iter[166/312]		Loss: 0.1242
2019-10-29 00:42:16,072 Training Epoch [19/40] Iter[167/312]		Loss: 0.1244
2019-10-29 00:42:16,193 Training Epoch [19/40] Iter[168/312]		Loss: 0.1241
2019-10-29 00:42:16,315 Training Epoch [19/40] Iter[169/312]		Loss: 0.1238
2019-10-29 00:42:16,436 Training Epoch [19/40] Iter[170/312]		Loss: 0.1236
2019-10-29 00:42:16,557 Training Epoch [19/40] Iter[171/312]		Loss: 0.1235
2019-10-29 00:42:16,678 Training Epoch [19/40] Iter[172/312]		Loss: 0.1232
2019-10-29 00:42:16,799 Training Epoch [19/40] Iter[173/312]		Loss: 0.1231
2019-10-29 00:42:16,920 Training Epoch [19/40] Iter[174/312]		Loss: 0.1229
2019-10-29 00:42:17,041 Training Epoch [19/40] Iter[175/312]		Loss: 0.1230
2019-10-29 00:42:17,162 Training Epoch [19/40] Iter[176/312]		Loss: 0.1231
2019-10-29 00:42:17,283 Training Epoch [19/40] Iter[177/312]		Loss: 0.1235
2019-10-29 00:42:17,404 Training Epoch [19/40] Iter[178/312]		Loss: 0.1235
2019-10-29 00:42:17,525 Training Epoch [19/40] Iter[179/312]		Loss: 0.1233
2019-10-29 00:42:17,647 Training Epoch [19/40] Iter[180/312]		Loss: 0.1236
2019-10-29 00:42:17,768 Training Epoch [19/40] Iter[181/312]		Loss: 0.1233
2019-10-29 00:42:17,890 Training Epoch [19/40] Iter[182/312]		Loss: 0.1232
2019-10-29 00:42:18,012 Training Epoch [19/40] Iter[183/312]		Loss: 0.1235
2019-10-29 00:42:18,134 Training Epoch [19/40] Iter[184/312]		Loss: 0.1235
2019-10-29 00:42:18,255 Training Epoch [19/40] Iter[185/312]		Loss: 0.1237
2019-10-29 00:42:18,376 Training Epoch [19/40] Iter[186/312]		Loss: 0.1239
2019-10-29 00:42:18,498 Training Epoch [19/40] Iter[187/312]		Loss: 0.1240
2019-10-29 00:42:18,619 Training Epoch [19/40] Iter[188/312]		Loss: 0.1239
2019-10-29 00:42:18,741 Training Epoch [19/40] Iter[189/312]		Loss: 0.1237
2019-10-29 00:42:18,863 Training Epoch [19/40] Iter[190/312]		Loss: 0.1237
2019-10-29 00:42:18,985 Training Epoch [19/40] Iter[191/312]		Loss: 0.1235
2019-10-29 00:42:19,107 Training Epoch [19/40] Iter[192/312]		Loss: 0.1233
2019-10-29 00:42:19,228 Training Epoch [19/40] Iter[193/312]		Loss: 0.1233
2019-10-29 00:42:19,349 Training Epoch [19/40] Iter[194/312]		Loss: 0.1232
2019-10-29 00:42:19,471 Training Epoch [19/40] Iter[195/312]		Loss: 0.1231
2019-10-29 00:42:19,592 Training Epoch [19/40] Iter[196/312]		Loss: 0.1231
2019-10-29 00:42:19,714 Training Epoch [19/40] Iter[197/312]		Loss: 0.1229
2019-10-29 00:42:19,835 Training Epoch [19/40] Iter[198/312]		Loss: 0.1228
2019-10-29 00:42:19,956 Training Epoch [19/40] Iter[199/312]		Loss: 0.1226
2019-10-29 00:42:20,077 Training Epoch [19/40] Iter[200/312]		Loss: 0.1226
2019-10-29 00:42:20,198 Training Epoch [19/40] Iter[201/312]		Loss: 0.1227
2019-10-29 00:42:20,320 Training Epoch [19/40] Iter[202/312]		Loss: 0.1228
2019-10-29 00:42:20,441 Training Epoch [19/40] Iter[203/312]		Loss: 0.1227
2019-10-29 00:42:20,562 Training Epoch [19/40] Iter[204/312]		Loss: 0.1229
2019-10-29 00:42:20,683 Training Epoch [19/40] Iter[205/312]		Loss: 0.1228
2019-10-29 00:42:20,804 Training Epoch [19/40] Iter[206/312]		Loss: 0.1229
2019-10-29 00:42:20,926 Training Epoch [19/40] Iter[207/312]		Loss: 0.1229
2019-10-29 00:42:21,048 Training Epoch [19/40] Iter[208/312]		Loss: 0.1228
2019-10-29 00:42:21,170 Training Epoch [19/40] Iter[209/312]		Loss: 0.1228
2019-10-29 00:42:21,291 Training Epoch [19/40] Iter[210/312]		Loss: 0.1229
2019-10-29 00:42:21,412 Training Epoch [19/40] Iter[211/312]		Loss: 0.1227
2019-10-29 00:42:21,534 Training Epoch [19/40] Iter[212/312]		Loss: 0.1229
2019-10-29 00:42:21,655 Training Epoch [19/40] Iter[213/312]		Loss: 0.1231
2019-10-29 00:42:21,777 Training Epoch [19/40] Iter[214/312]		Loss: 0.1231
2019-10-29 00:42:21,898 Training Epoch [19/40] Iter[215/312]		Loss: 0.1231
2019-10-29 00:42:22,019 Training Epoch [19/40] Iter[216/312]		Loss: 0.1230
2019-10-29 00:42:22,142 Training Epoch [19/40] Iter[217/312]		Loss: 0.1228
2019-10-29 00:42:22,264 Training Epoch [19/40] Iter[218/312]		Loss: 0.1228
2019-10-29 00:42:22,386 Training Epoch [19/40] Iter[219/312]		Loss: 0.1226
2019-10-29 00:42:22,508 Training Epoch [19/40] Iter[220/312]		Loss: 0.1225
2019-10-29 00:42:22,630 Training Epoch [19/40] Iter[221/312]		Loss: 0.1227
2019-10-29 00:42:22,751 Training Epoch [19/40] Iter[222/312]		Loss: 0.1227
2019-10-29 00:42:22,873 Training Epoch [19/40] Iter[223/312]		Loss: 0.1230
2019-10-29 00:42:22,994 Training Epoch [19/40] Iter[224/312]		Loss: 0.1230
2019-10-29 00:42:23,115 Training Epoch [19/40] Iter[225/312]		Loss: 0.1229
2019-10-29 00:42:23,237 Training Epoch [19/40] Iter[226/312]		Loss: 0.1229
2019-10-29 00:42:23,359 Training Epoch [19/40] Iter[227/312]		Loss: 0.1230
2019-10-29 00:42:23,480 Training Epoch [19/40] Iter[228/312]		Loss: 0.1232
2019-10-29 00:42:23,601 Training Epoch [19/40] Iter[229/312]		Loss: 0.1234
2019-10-29 00:42:23,723 Training Epoch [19/40] Iter[230/312]		Loss: 0.1233
2019-10-29 00:42:23,844 Training Epoch [19/40] Iter[231/312]		Loss: 0.1232
2019-10-29 00:42:23,966 Training Epoch [19/40] Iter[232/312]		Loss: 0.1231
2019-10-29 00:42:24,087 Training Epoch [19/40] Iter[233/312]		Loss: 0.1233
2019-10-29 00:42:24,209 Training Epoch [19/40] Iter[234/312]		Loss: 0.1233
2019-10-29 00:42:24,331 Training Epoch [19/40] Iter[235/312]		Loss: 0.1233
2019-10-29 00:42:24,452 Training Epoch [19/40] Iter[236/312]		Loss: 0.1232
2019-10-29 00:42:24,574 Training Epoch [19/40] Iter[237/312]		Loss: 0.1231
2019-10-29 00:42:24,696 Training Epoch [19/40] Iter[238/312]		Loss: 0.1232
2019-10-29 00:42:24,817 Training Epoch [19/40] Iter[239/312]		Loss: 0.1233
2019-10-29 00:42:24,938 Training Epoch [19/40] Iter[240/312]		Loss: 0.1235
2019-10-29 00:42:25,060 Training Epoch [19/40] Iter[241/312]		Loss: 0.1236
2019-10-29 00:42:25,181 Training Epoch [19/40] Iter[242/312]		Loss: 0.1236
2019-10-29 00:42:25,302 Training Epoch [19/40] Iter[243/312]		Loss: 0.1234
2019-10-29 00:42:25,423 Training Epoch [19/40] Iter[244/312]		Loss: 0.1235
2019-10-29 00:42:25,544 Training Epoch [19/40] Iter[245/312]		Loss: 0.1236
2019-10-29 00:42:25,665 Training Epoch [19/40] Iter[246/312]		Loss: 0.1235
2019-10-29 00:42:25,787 Training Epoch [19/40] Iter[247/312]		Loss: 0.1234
2019-10-29 00:42:25,908 Training Epoch [19/40] Iter[248/312]		Loss: 0.1235
2019-10-29 00:42:26,029 Training Epoch [19/40] Iter[249/312]		Loss: 0.1235
2019-10-29 00:42:26,150 Training Epoch [19/40] Iter[250/312]		Loss: 0.1234
2019-10-29 00:42:26,272 Training Epoch [19/40] Iter[251/312]		Loss: 0.1234
2019-10-29 00:42:26,394 Training Epoch [19/40] Iter[252/312]		Loss: 0.1233
2019-10-29 00:42:26,515 Training Epoch [19/40] Iter[253/312]		Loss: 0.1233
2019-10-29 00:42:26,637 Training Epoch [19/40] Iter[254/312]		Loss: 0.1232
2019-10-29 00:42:26,759 Training Epoch [19/40] Iter[255/312]		Loss: 0.1230
2019-10-29 00:42:26,880 Training Epoch [19/40] Iter[256/312]		Loss: 0.1229
2019-10-29 00:42:27,001 Training Epoch [19/40] Iter[257/312]		Loss: 0.1231
2019-10-29 00:42:27,123 Training Epoch [19/40] Iter[258/312]		Loss: 0.1231
2019-10-29 00:42:27,245 Training Epoch [19/40] Iter[259/312]		Loss: 0.1231
2019-10-29 00:42:27,367 Training Epoch [19/40] Iter[260/312]		Loss: 0.1230
2019-10-29 00:42:27,489 Training Epoch [19/40] Iter[261/312]		Loss: 0.1229
2019-10-29 00:42:27,610 Training Epoch [19/40] Iter[262/312]		Loss: 0.1228
2019-10-29 00:42:27,732 Training Epoch [19/40] Iter[263/312]		Loss: 0.1229
2019-10-29 00:42:27,853 Training Epoch [19/40] Iter[264/312]		Loss: 0.1230
2019-10-29 00:42:27,975 Training Epoch [19/40] Iter[265/312]		Loss: 0.1230
2019-10-29 00:42:28,096 Training Epoch [19/40] Iter[266/312]		Loss: 0.1229
2019-10-29 00:42:28,217 Training Epoch [19/40] Iter[267/312]		Loss: 0.1231
2019-10-29 00:42:28,339 Training Epoch [19/40] Iter[268/312]		Loss: 0.1229
2019-10-29 00:42:28,460 Training Epoch [19/40] Iter[269/312]		Loss: 0.1227
2019-10-29 00:42:28,581 Training Epoch [19/40] Iter[270/312]		Loss: 0.1227
2019-10-29 00:42:28,702 Training Epoch [19/40] Iter[271/312]		Loss: 0.1226
2019-10-29 00:42:28,824 Training Epoch [19/40] Iter[272/312]		Loss: 0.1226
2019-10-29 00:42:28,945 Training Epoch [19/40] Iter[273/312]		Loss: 0.1226
2019-10-29 00:42:29,066 Training Epoch [19/40] Iter[274/312]		Loss: 0.1225
2019-10-29 00:42:29,187 Training Epoch [19/40] Iter[275/312]		Loss: 0.1224
2019-10-29 00:42:29,309 Training Epoch [19/40] Iter[276/312]		Loss: 0.1223
2019-10-29 00:42:29,431 Training Epoch [19/40] Iter[277/312]		Loss: 0.1222
2019-10-29 00:42:29,552 Training Epoch [19/40] Iter[278/312]		Loss: 0.1222
2019-10-29 00:42:29,674 Training Epoch [19/40] Iter[279/312]		Loss: 0.1221
2019-10-29 00:42:29,796 Training Epoch [19/40] Iter[280/312]		Loss: 0.1220
2019-10-29 00:42:29,917 Training Epoch [19/40] Iter[281/312]		Loss: 0.1222
2019-10-29 00:42:30,039 Training Epoch [19/40] Iter[282/312]		Loss: 0.1221
2019-10-29 00:42:30,161 Training Epoch [19/40] Iter[283/312]		Loss: 0.1219
2019-10-29 00:42:30,282 Training Epoch [19/40] Iter[284/312]		Loss: 0.1219
2019-10-29 00:42:30,404 Training Epoch [19/40] Iter[285/312]		Loss: 0.1219
2019-10-29 00:42:30,525 Training Epoch [19/40] Iter[286/312]		Loss: 0.1218
2019-10-29 00:42:30,647 Training Epoch [19/40] Iter[287/312]		Loss: 0.1219
2019-10-29 00:42:30,768 Training Epoch [19/40] Iter[288/312]		Loss: 0.1222
2019-10-29 00:42:30,890 Training Epoch [19/40] Iter[289/312]		Loss: 0.1222
2019-10-29 00:42:31,013 Training Epoch [19/40] Iter[290/312]		Loss: 0.1221
2019-10-29 00:42:31,134 Training Epoch [19/40] Iter[291/312]		Loss: 0.1221
2019-10-29 00:42:31,256 Training Epoch [19/40] Iter[292/312]		Loss: 0.1221
2019-10-29 00:42:31,377 Training Epoch [19/40] Iter[293/312]		Loss: 0.1221
2019-10-29 00:42:31,499 Training Epoch [19/40] Iter[294/312]		Loss: 0.1220
2019-10-29 00:42:31,621 Training Epoch [19/40] Iter[295/312]		Loss: 0.1220
2019-10-29 00:42:31,743 Training Epoch [19/40] Iter[296/312]		Loss: 0.1221
2019-10-29 00:42:31,864 Training Epoch [19/40] Iter[297/312]		Loss: 0.1222
2019-10-29 00:42:31,985 Training Epoch [19/40] Iter[298/312]		Loss: 0.1221
2019-10-29 00:42:32,106 Training Epoch [19/40] Iter[299/312]		Loss: 0.1220
2019-10-29 00:42:32,228 Training Epoch [19/40] Iter[300/312]		Loss: 0.1221
2019-10-29 00:42:32,350 Training Epoch [19/40] Iter[301/312]		Loss: 0.1221
2019-10-29 00:42:32,472 Training Epoch [19/40] Iter[302/312]		Loss: 0.1221
2019-10-29 00:42:32,593 Training Epoch [19/40] Iter[303/312]		Loss: 0.1221
2019-10-29 00:42:32,714 Training Epoch [19/40] Iter[304/312]		Loss: 0.1220
2019-10-29 00:42:32,835 Training Epoch [19/40] Iter[305/312]		Loss: 0.1220
2019-10-29 00:42:32,956 Training Epoch [19/40] Iter[306/312]		Loss: 0.1218
2019-10-29 00:42:33,077 Training Epoch [19/40] Iter[307/312]		Loss: 0.1218
2019-10-29 00:42:33,198 Training Epoch [19/40] Iter[308/312]		Loss: 0.1218
2019-10-29 00:42:33,319 Training Epoch [19/40] Iter[309/312]		Loss: 0.1219
2019-10-29 00:42:33,440 Training Epoch [19/40] Iter[310/312]		Loss: 0.1217
2019-10-29 00:42:33,561 Training Epoch [19/40] Iter[311/312]		Loss: 0.1218
2019-10-29 00:42:33,621 Training Epoch [19/40] Iter[312/312]		Loss: 0.1219
2019-10-29 00:42:34,017 Testing Epoch [19/40] Iter[0/62]		Loss: 0.1144
2019-10-29 00:42:34,053 Testing Epoch [19/40] Iter[1/62]		Loss: 0.1396
2019-10-29 00:42:34,086 Testing Epoch [19/40] Iter[2/62]		Loss: 0.1308
2019-10-29 00:42:34,116 Testing Epoch [19/40] Iter[3/62]		Loss: 0.1282
2019-10-29 00:42:34,150 Testing Epoch [19/40] Iter[4/62]		Loss: 0.1231
2019-10-29 00:42:34,180 Testing Epoch [19/40] Iter[5/62]		Loss: 0.1192
2019-10-29 00:42:34,210 Testing Epoch [19/40] Iter[6/62]		Loss: 0.1228
2019-10-29 00:42:34,242 Testing Epoch [19/40] Iter[7/62]		Loss: 0.1273
2019-10-29 00:42:34,273 Testing Epoch [19/40] Iter[8/62]		Loss: 0.1340
2019-10-29 00:42:34,303 Testing Epoch [19/40] Iter[9/62]		Loss: 0.1346
2019-10-29 00:42:34,338 Testing Epoch [19/40] Iter[10/62]		Loss: 0.1333
2019-10-29 00:42:34,368 Testing Epoch [19/40] Iter[11/62]		Loss: 0.1374
2019-10-29 00:42:34,399 Testing Epoch [19/40] Iter[12/62]		Loss: 0.1388
2019-10-29 00:42:34,434 Testing Epoch [19/40] Iter[13/62]		Loss: 0.1402
2019-10-29 00:42:34,465 Testing Epoch [19/40] Iter[14/62]		Loss: 0.1532
2019-10-29 00:42:34,496 Testing Epoch [19/40] Iter[15/62]		Loss: 0.1541
2019-10-29 00:42:34,530 Testing Epoch [19/40] Iter[16/62]		Loss: 0.1529
2019-10-29 00:42:34,562 Testing Epoch [19/40] Iter[17/62]		Loss: 0.1524
2019-10-29 00:42:34,593 Testing Epoch [19/40] Iter[18/62]		Loss: 0.1495
2019-10-29 00:42:34,623 Testing Epoch [19/40] Iter[19/62]		Loss: 0.1476
2019-10-29 00:42:34,654 Testing Epoch [19/40] Iter[20/62]		Loss: 0.1493
2019-10-29 00:42:34,685 Testing Epoch [19/40] Iter[21/62]		Loss: 0.1473
2019-10-29 00:42:34,717 Testing Epoch [19/40] Iter[22/62]		Loss: 0.1466
2019-10-29 00:42:34,748 Testing Epoch [19/40] Iter[23/62]		Loss: 0.1468
2019-10-29 00:42:34,780 Testing Epoch [19/40] Iter[24/62]		Loss: 0.1494
2019-10-29 00:42:34,811 Testing Epoch [19/40] Iter[25/62]		Loss: 0.1484
2019-10-29 00:42:34,842 Testing Epoch [19/40] Iter[26/62]		Loss: 0.1474
2019-10-29 00:42:34,873 Testing Epoch [19/40] Iter[27/62]		Loss: 0.1514
2019-10-29 00:42:34,904 Testing Epoch [19/40] Iter[28/62]		Loss: 0.1534
2019-10-29 00:42:34,935 Testing Epoch [19/40] Iter[29/62]		Loss: 0.1534
2019-10-29 00:42:34,966 Testing Epoch [19/40] Iter[30/62]		Loss: 0.1550
2019-10-29 00:42:34,997 Testing Epoch [19/40] Iter[31/62]		Loss: 0.1546
2019-10-29 00:42:35,028 Testing Epoch [19/40] Iter[32/62]		Loss: 0.1564
2019-10-29 00:42:35,059 Testing Epoch [19/40] Iter[33/62]		Loss: 0.1550
2019-10-29 00:42:35,090 Testing Epoch [19/40] Iter[34/62]		Loss: 0.1567
2019-10-29 00:42:35,121 Testing Epoch [19/40] Iter[35/62]		Loss: 0.1567
2019-10-29 00:42:35,153 Testing Epoch [19/40] Iter[36/62]		Loss: 0.1554
2019-10-29 00:42:35,184 Testing Epoch [19/40] Iter[37/62]		Loss: 0.1550
2019-10-29 00:42:35,214 Testing Epoch [19/40] Iter[38/62]		Loss: 0.1557
2019-10-29 00:42:35,245 Testing Epoch [19/40] Iter[39/62]		Loss: 0.1562
2019-10-29 00:42:35,276 Testing Epoch [19/40] Iter[40/62]		Loss: 0.1572
2019-10-29 00:42:35,307 Testing Epoch [19/40] Iter[41/62]		Loss: 0.1573
2019-10-29 00:42:35,338 Testing Epoch [19/40] Iter[42/62]		Loss: 0.1562
2019-10-29 00:42:35,369 Testing Epoch [19/40] Iter[43/62]		Loss: 0.1552
2019-10-29 00:42:35,400 Testing Epoch [19/40] Iter[44/62]		Loss: 0.1541
2019-10-29 00:42:35,431 Testing Epoch [19/40] Iter[45/62]		Loss: 0.1548
2019-10-29 00:42:35,461 Testing Epoch [19/40] Iter[46/62]		Loss: 0.1549
2019-10-29 00:42:35,492 Testing Epoch [19/40] Iter[47/62]		Loss: 0.1595
2019-10-29 00:42:35,523 Testing Epoch [19/40] Iter[48/62]		Loss: 0.1586
2019-10-29 00:42:35,554 Testing Epoch [19/40] Iter[49/62]		Loss: 0.1601
2019-10-29 00:42:35,585 Testing Epoch [19/40] Iter[50/62]		Loss: 0.1595
2019-10-29 00:42:35,615 Testing Epoch [19/40] Iter[51/62]		Loss: 0.1595
2019-10-29 00:42:35,646 Testing Epoch [19/40] Iter[52/62]		Loss: 0.1585
2019-10-29 00:42:35,677 Testing Epoch [19/40] Iter[53/62]		Loss: 0.1583
2019-10-29 00:42:35,708 Testing Epoch [19/40] Iter[54/62]		Loss: 0.1577
2019-10-29 00:42:35,739 Testing Epoch [19/40] Iter[55/62]		Loss: 0.1577
2019-10-29 00:42:35,769 Testing Epoch [19/40] Iter[56/62]		Loss: 0.1572
2019-10-29 00:42:35,800 Testing Epoch [19/40] Iter[57/62]		Loss: 0.1569
2019-10-29 00:42:35,830 Testing Epoch [19/40] Iter[58/62]		Loss: 0.1566
2019-10-29 00:42:35,861 Testing Epoch [19/40] Iter[59/62]		Loss: 0.1565
2019-10-29 00:42:35,891 Testing Epoch [19/40] Iter[60/62]		Loss: 0.1557
2019-10-29 00:42:35,921 Testing Epoch [19/40] Iter[61/62]		Loss: 0.1555
2019-10-29 00:42:35,938 Testing Epoch [19/40] Iter[62/62]		Loss: 0.1564
2019-10-29 00:42:36,420 Training Epoch [20/40] Iter[0/312]		Loss: 0.1021
2019-10-29 00:42:36,542 Training Epoch [20/40] Iter[1/312]		Loss: 0.0929
2019-10-29 00:42:36,664 Training Epoch [20/40] Iter[2/312]		Loss: 0.0928
2019-10-29 00:42:36,785 Training Epoch [20/40] Iter[3/312]		Loss: 0.0983
2019-10-29 00:42:36,908 Training Epoch [20/40] Iter[4/312]		Loss: 0.1157
2019-10-29 00:42:37,028 Training Epoch [20/40] Iter[5/312]		Loss: 0.1128
2019-10-29 00:42:37,148 Training Epoch [20/40] Iter[6/312]		Loss: 0.1254
2019-10-29 00:42:37,270 Training Epoch [20/40] Iter[7/312]		Loss: 0.1295
2019-10-29 00:42:37,392 Training Epoch [20/40] Iter[8/312]		Loss: 0.1283
2019-10-29 00:42:37,513 Training Epoch [20/40] Iter[9/312]		Loss: 0.1293
2019-10-29 00:42:37,634 Training Epoch [20/40] Iter[10/312]		Loss: 0.1339
2019-10-29 00:42:37,755 Training Epoch [20/40] Iter[11/312]		Loss: 0.1336
2019-10-29 00:42:37,876 Training Epoch [20/40] Iter[12/312]		Loss: 0.1328
2019-10-29 00:42:37,998 Training Epoch [20/40] Iter[13/312]		Loss: 0.1320
2019-10-29 00:42:38,120 Training Epoch [20/40] Iter[14/312]		Loss: 0.1296
2019-10-29 00:42:38,243 Training Epoch [20/40] Iter[15/312]		Loss: 0.1307
2019-10-29 00:42:38,364 Training Epoch [20/40] Iter[16/312]		Loss: 0.1303
2019-10-29 00:42:38,486 Training Epoch [20/40] Iter[17/312]		Loss: 0.1286
2019-10-29 00:42:38,607 Training Epoch [20/40] Iter[18/312]		Loss: 0.1264
2019-10-29 00:42:38,729 Training Epoch [20/40] Iter[19/312]		Loss: 0.1264
2019-10-29 00:42:38,851 Training Epoch [20/40] Iter[20/312]		Loss: 0.1256
2019-10-29 00:42:38,972 Training Epoch [20/40] Iter[21/312]		Loss: 0.1241
2019-10-29 00:42:39,093 Training Epoch [20/40] Iter[22/312]		Loss: 0.1230
2019-10-29 00:42:39,214 Training Epoch [20/40] Iter[23/312]		Loss: 0.1215
2019-10-29 00:42:39,336 Training Epoch [20/40] Iter[24/312]		Loss: 0.1216
2019-10-29 00:42:39,458 Training Epoch [20/40] Iter[25/312]		Loss: 0.1244
2019-10-29 00:42:39,580 Training Epoch [20/40] Iter[26/312]		Loss: 0.1226
2019-10-29 00:42:39,701 Training Epoch [20/40] Iter[27/312]		Loss: 0.1207
2019-10-29 00:42:39,823 Training Epoch [20/40] Iter[28/312]		Loss: 0.1206
2019-10-29 00:42:39,944 Training Epoch [20/40] Iter[29/312]		Loss: 0.1212
2019-10-29 00:42:40,065 Training Epoch [20/40] Iter[30/312]		Loss: 0.1219
2019-10-29 00:42:40,187 Training Epoch [20/40] Iter[31/312]		Loss: 0.1216
2019-10-29 00:42:40,309 Training Epoch [20/40] Iter[32/312]		Loss: 0.1205
2019-10-29 00:42:40,430 Training Epoch [20/40] Iter[33/312]		Loss: 0.1217
2019-10-29 00:42:40,552 Training Epoch [20/40] Iter[34/312]		Loss: 0.1235
2019-10-29 00:42:40,673 Training Epoch [20/40] Iter[35/312]		Loss: 0.1240
2019-10-29 00:42:40,794 Training Epoch [20/40] Iter[36/312]		Loss: 0.1238
2019-10-29 00:42:40,916 Training Epoch [20/40] Iter[37/312]		Loss: 0.1234
2019-10-29 00:42:41,037 Training Epoch [20/40] Iter[38/312]		Loss: 0.1223
2019-10-29 00:42:41,158 Training Epoch [20/40] Iter[39/312]		Loss: 0.1227
2019-10-29 00:42:41,280 Training Epoch [20/40] Iter[40/312]		Loss: 0.1234
2019-10-29 00:42:41,401 Training Epoch [20/40] Iter[41/312]		Loss: 0.1243
2019-10-29 00:42:41,523 Training Epoch [20/40] Iter[42/312]		Loss: 0.1242
2019-10-29 00:42:41,644 Training Epoch [20/40] Iter[43/312]		Loss: 0.1244
2019-10-29 00:42:41,766 Training Epoch [20/40] Iter[44/312]		Loss: 0.1236
2019-10-29 00:42:41,887 Training Epoch [20/40] Iter[45/312]		Loss: 0.1227
2019-10-29 00:42:42,008 Training Epoch [20/40] Iter[46/312]		Loss: 0.1223
2019-10-29 00:42:42,129 Training Epoch [20/40] Iter[47/312]		Loss: 0.1215
2019-10-29 00:42:42,250 Training Epoch [20/40] Iter[48/312]		Loss: 0.1214
2019-10-29 00:42:42,371 Training Epoch [20/40] Iter[49/312]		Loss: 0.1217
2019-10-29 00:42:42,493 Training Epoch [20/40] Iter[50/312]		Loss: 0.1221
2019-10-29 00:42:42,615 Training Epoch [20/40] Iter[51/312]		Loss: 0.1217
2019-10-29 00:42:42,736 Training Epoch [20/40] Iter[52/312]		Loss: 0.1208
2019-10-29 00:42:42,858 Training Epoch [20/40] Iter[53/312]		Loss: 0.1201
2019-10-29 00:42:42,979 Training Epoch [20/40] Iter[54/312]		Loss: 0.1195
2019-10-29 00:42:43,100 Training Epoch [20/40] Iter[55/312]		Loss: 0.1187
2019-10-29 00:42:43,221 Training Epoch [20/40] Iter[56/312]		Loss: 0.1184
2019-10-29 00:42:43,343 Training Epoch [20/40] Iter[57/312]		Loss: 0.1189
2019-10-29 00:42:43,464 Training Epoch [20/40] Iter[58/312]		Loss: 0.1193
2019-10-29 00:42:43,586 Training Epoch [20/40] Iter[59/312]		Loss: 0.1202
2019-10-29 00:42:43,708 Training Epoch [20/40] Iter[60/312]		Loss: 0.1199
2019-10-29 00:42:43,830 Training Epoch [20/40] Iter[61/312]		Loss: 0.1211
2019-10-29 00:42:43,952 Training Epoch [20/40] Iter[62/312]		Loss: 0.1203
2019-10-29 00:42:44,073 Training Epoch [20/40] Iter[63/312]		Loss: 0.1205
2019-10-29 00:42:44,194 Training Epoch [20/40] Iter[64/312]		Loss: 0.1201
2019-10-29 00:42:44,316 Training Epoch [20/40] Iter[65/312]		Loss: 0.1204
2019-10-29 00:42:44,437 Training Epoch [20/40] Iter[66/312]		Loss: 0.1204
2019-10-29 00:42:44,559 Training Epoch [20/40] Iter[67/312]		Loss: 0.1219
2019-10-29 00:42:44,681 Training Epoch [20/40] Iter[68/312]		Loss: 0.1218
2019-10-29 00:42:44,802 Training Epoch [20/40] Iter[69/312]		Loss: 0.1231
2019-10-29 00:42:44,924 Training Epoch [20/40] Iter[70/312]		Loss: 0.1224
2019-10-29 00:42:45,045 Training Epoch [20/40] Iter[71/312]		Loss: 0.1219
2019-10-29 00:42:45,167 Training Epoch [20/40] Iter[72/312]		Loss: 0.1222
2019-10-29 00:42:45,289 Training Epoch [20/40] Iter[73/312]		Loss: 0.1219
2019-10-29 00:42:45,410 Training Epoch [20/40] Iter[74/312]		Loss: 0.1216
2019-10-29 00:42:45,531 Training Epoch [20/40] Iter[75/312]		Loss: 0.1212
2019-10-29 00:42:45,653 Training Epoch [20/40] Iter[76/312]		Loss: 0.1211
2019-10-29 00:42:45,774 Training Epoch [20/40] Iter[77/312]		Loss: 0.1206
2019-10-29 00:42:45,895 Training Epoch [20/40] Iter[78/312]		Loss: 0.1204
2019-10-29 00:42:46,016 Training Epoch [20/40] Iter[79/312]		Loss: 0.1211
2019-10-29 00:42:46,138 Training Epoch [20/40] Iter[80/312]		Loss: 0.1206
2019-10-29 00:42:46,259 Training Epoch [20/40] Iter[81/312]		Loss: 0.1207
2019-10-29 00:42:46,381 Training Epoch [20/40] Iter[82/312]		Loss: 0.1203
2019-10-29 00:42:46,502 Training Epoch [20/40] Iter[83/312]		Loss: 0.1198
2019-10-29 00:42:46,623 Training Epoch [20/40] Iter[84/312]		Loss: 0.1193
2019-10-29 00:42:46,745 Training Epoch [20/40] Iter[85/312]		Loss: 0.1195
2019-10-29 00:42:46,867 Training Epoch [20/40] Iter[86/312]		Loss: 0.1193
2019-10-29 00:42:46,988 Training Epoch [20/40] Iter[87/312]		Loss: 0.1198
2019-10-29 00:42:47,109 Training Epoch [20/40] Iter[88/312]		Loss: 0.1198
2019-10-29 00:42:47,231 Training Epoch [20/40] Iter[89/312]		Loss: 0.1195
2019-10-29 00:42:47,353 Training Epoch [20/40] Iter[90/312]		Loss: 0.1199
2019-10-29 00:42:47,475 Training Epoch [20/40] Iter[91/312]		Loss: 0.1204
2019-10-29 00:42:47,596 Training Epoch [20/40] Iter[92/312]		Loss: 0.1206
2019-10-29 00:42:47,719 Training Epoch [20/40] Iter[93/312]		Loss: 0.1204
2019-10-29 00:42:47,841 Training Epoch [20/40] Iter[94/312]		Loss: 0.1208
2019-10-29 00:42:47,963 Training Epoch [20/40] Iter[95/312]		Loss: 0.1205
2019-10-29 00:42:48,085 Training Epoch [20/40] Iter[96/312]		Loss: 0.1203
2019-10-29 00:42:48,206 Training Epoch [20/40] Iter[97/312]		Loss: 0.1203
2019-10-29 00:42:48,333 Training Epoch [20/40] Iter[98/312]		Loss: 0.1198
2019-10-29 00:42:48,455 Training Epoch [20/40] Iter[99/312]		Loss: 0.1197
2019-10-29 00:42:48,576 Training Epoch [20/40] Iter[100/312]		Loss: 0.1193
2019-10-29 00:42:48,697 Training Epoch [20/40] Iter[101/312]		Loss: 0.1190
2019-10-29 00:42:48,819 Training Epoch [20/40] Iter[102/312]		Loss: 0.1188
2019-10-29 00:42:48,940 Training Epoch [20/40] Iter[103/312]		Loss: 0.1186
2019-10-29 00:42:49,062 Training Epoch [20/40] Iter[104/312]		Loss: 0.1187
2019-10-29 00:42:49,183 Training Epoch [20/40] Iter[105/312]		Loss: 0.1184
2019-10-29 00:42:49,305 Training Epoch [20/40] Iter[106/312]		Loss: 0.1186
2019-10-29 00:42:49,426 Training Epoch [20/40] Iter[107/312]		Loss: 0.1185
2019-10-29 00:42:49,548 Training Epoch [20/40] Iter[108/312]		Loss: 0.1182
2019-10-29 00:42:49,669 Training Epoch [20/40] Iter[109/312]		Loss: 0.1181
2019-10-29 00:42:49,791 Training Epoch [20/40] Iter[110/312]		Loss: 0.1181
2019-10-29 00:42:49,912 Training Epoch [20/40] Iter[111/312]		Loss: 0.1179
2019-10-29 00:42:50,034 Training Epoch [20/40] Iter[112/312]		Loss: 0.1177
2019-10-29 00:42:50,155 Training Epoch [20/40] Iter[113/312]		Loss: 0.1180
2019-10-29 00:42:50,277 Training Epoch [20/40] Iter[114/312]		Loss: 0.1177
2019-10-29 00:42:50,398 Training Epoch [20/40] Iter[115/312]		Loss: 0.1176
2019-10-29 00:42:50,520 Training Epoch [20/40] Iter[116/312]		Loss: 0.1171
2019-10-29 00:42:50,641 Training Epoch [20/40] Iter[117/312]		Loss: 0.1173
2019-10-29 00:42:50,762 Training Epoch [20/40] Iter[118/312]		Loss: 0.1174
2019-10-29 00:42:50,883 Training Epoch [20/40] Iter[119/312]		Loss: 0.1175
2019-10-29 00:42:51,004 Training Epoch [20/40] Iter[120/312]		Loss: 0.1173
2019-10-29 00:42:51,125 Training Epoch [20/40] Iter[121/312]		Loss: 0.1169
2019-10-29 00:42:51,246 Training Epoch [20/40] Iter[122/312]		Loss: 0.1166
2019-10-29 00:42:51,368 Training Epoch [20/40] Iter[123/312]		Loss: 0.1167
2019-10-29 00:42:51,489 Training Epoch [20/40] Iter[124/312]		Loss: 0.1165
2019-10-29 00:42:51,610 Training Epoch [20/40] Iter[125/312]		Loss: 0.1165
2019-10-29 00:42:51,731 Training Epoch [20/40] Iter[126/312]		Loss: 0.1166
2019-10-29 00:42:51,852 Training Epoch [20/40] Iter[127/312]		Loss: 0.1164
2019-10-29 00:42:51,974 Training Epoch [20/40] Iter[128/312]		Loss: 0.1164
2019-10-29 00:42:52,096 Training Epoch [20/40] Iter[129/312]		Loss: 0.1165
2019-10-29 00:42:52,217 Training Epoch [20/40] Iter[130/312]		Loss: 0.1167
2019-10-29 00:42:52,339 Training Epoch [20/40] Iter[131/312]		Loss: 0.1165
2019-10-29 00:42:52,461 Training Epoch [20/40] Iter[132/312]		Loss: 0.1168
2019-10-29 00:42:52,582 Training Epoch [20/40] Iter[133/312]		Loss: 0.1167
2019-10-29 00:42:52,703 Training Epoch [20/40] Iter[134/312]		Loss: 0.1166
2019-10-29 00:42:52,825 Training Epoch [20/40] Iter[135/312]		Loss: 0.1168
2019-10-29 00:42:52,947 Training Epoch [20/40] Iter[136/312]		Loss: 0.1168
2019-10-29 00:42:53,068 Training Epoch [20/40] Iter[137/312]		Loss: 0.1165
2019-10-29 00:42:53,190 Training Epoch [20/40] Iter[138/312]		Loss: 0.1166
2019-10-29 00:42:53,313 Training Epoch [20/40] Iter[139/312]		Loss: 0.1166
2019-10-29 00:42:53,434 Training Epoch [20/40] Iter[140/312]		Loss: 0.1165
2019-10-29 00:42:53,556 Training Epoch [20/40] Iter[141/312]		Loss: 0.1165
2019-10-29 00:42:53,676 Training Epoch [20/40] Iter[142/312]		Loss: 0.1164
2019-10-29 00:42:53,798 Training Epoch [20/40] Iter[143/312]		Loss: 0.1165
2019-10-29 00:42:53,919 Training Epoch [20/40] Iter[144/312]		Loss: 0.1163
2019-10-29 00:42:54,040 Training Epoch [20/40] Iter[145/312]		Loss: 0.1165
2019-10-29 00:42:54,161 Training Epoch [20/40] Iter[146/312]		Loss: 0.1165
2019-10-29 00:42:54,282 Training Epoch [20/40] Iter[147/312]		Loss: 0.1163
2019-10-29 00:42:54,403 Training Epoch [20/40] Iter[148/312]		Loss: 0.1164
2019-10-29 00:42:54,524 Training Epoch [20/40] Iter[149/312]		Loss: 0.1167
2019-10-29 00:42:54,646 Training Epoch [20/40] Iter[150/312]		Loss: 0.1168
2019-10-29 00:42:54,767 Training Epoch [20/40] Iter[151/312]		Loss: 0.1169
2019-10-29 00:42:54,889 Training Epoch [20/40] Iter[152/312]		Loss: 0.1171
2019-10-29 00:42:55,010 Training Epoch [20/40] Iter[153/312]		Loss: 0.1171
2019-10-29 00:42:55,132 Training Epoch [20/40] Iter[154/312]		Loss: 0.1172
2019-10-29 00:42:55,254 Training Epoch [20/40] Iter[155/312]		Loss: 0.1174
2019-10-29 00:42:55,376 Training Epoch [20/40] Iter[156/312]		Loss: 0.1172
2019-10-29 00:42:55,498 Training Epoch [20/40] Iter[157/312]		Loss: 0.1169
2019-10-29 00:42:55,620 Training Epoch [20/40] Iter[158/312]		Loss: 0.1169
2019-10-29 00:42:55,742 Training Epoch [20/40] Iter[159/312]		Loss: 0.1168
2019-10-29 00:42:55,864 Training Epoch [20/40] Iter[160/312]		Loss: 0.1170
2019-10-29 00:42:55,986 Training Epoch [20/40] Iter[161/312]		Loss: 0.1171
2019-10-29 00:42:56,108 Training Epoch [20/40] Iter[162/312]		Loss: 0.1169
2019-10-29 00:42:56,230 Training Epoch [20/40] Iter[163/312]		Loss: 0.1168
2019-10-29 00:42:56,352 Training Epoch [20/40] Iter[164/312]		Loss: 0.1169
2019-10-29 00:42:56,474 Training Epoch [20/40] Iter[165/312]		Loss: 0.1166
2019-10-29 00:42:56,596 Training Epoch [20/40] Iter[166/312]		Loss: 0.1165
2019-10-29 00:42:56,718 Training Epoch [20/40] Iter[167/312]		Loss: 0.1166
2019-10-29 00:42:56,840 Training Epoch [20/40] Iter[168/312]		Loss: 0.1165
2019-10-29 00:42:56,961 Training Epoch [20/40] Iter[169/312]		Loss: 0.1163
2019-10-29 00:42:57,083 Training Epoch [20/40] Iter[170/312]		Loss: 0.1164
2019-10-29 00:42:57,205 Training Epoch [20/40] Iter[171/312]		Loss: 0.1162
2019-10-29 00:42:57,327 Training Epoch [20/40] Iter[172/312]		Loss: 0.1164
2019-10-29 00:42:57,449 Training Epoch [20/40] Iter[173/312]		Loss: 0.1164
2019-10-29 00:42:57,570 Training Epoch [20/40] Iter[174/312]		Loss: 0.1166
2019-10-29 00:42:57,692 Training Epoch [20/40] Iter[175/312]		Loss: 0.1168
2019-10-29 00:42:57,814 Training Epoch [20/40] Iter[176/312]		Loss: 0.1168
2019-10-29 00:42:57,936 Training Epoch [20/40] Iter[177/312]		Loss: 0.1166
2019-10-29 00:42:58,059 Training Epoch [20/40] Iter[178/312]		Loss: 0.1167
2019-10-29 00:42:58,181 Training Epoch [20/40] Iter[179/312]		Loss: 0.1169
2019-10-29 00:42:58,303 Training Epoch [20/40] Iter[180/312]		Loss: 0.1170
2019-10-29 00:42:58,425 Training Epoch [20/40] Iter[181/312]		Loss: 0.1170
2019-10-29 00:42:58,547 Training Epoch [20/40] Iter[182/312]		Loss: 0.1171
2019-10-29 00:42:58,669 Training Epoch [20/40] Iter[183/312]		Loss: 0.1171
2019-10-29 00:42:58,791 Training Epoch [20/40] Iter[184/312]		Loss: 0.1170
2019-10-29 00:42:58,913 Training Epoch [20/40] Iter[185/312]		Loss: 0.1170
2019-10-29 00:42:59,035 Training Epoch [20/40] Iter[186/312]		Loss: 0.1171
2019-10-29 00:42:59,157 Training Epoch [20/40] Iter[187/312]		Loss: 0.1170
2019-10-29 00:42:59,278 Training Epoch [20/40] Iter[188/312]		Loss: 0.1169
2019-10-29 00:42:59,399 Training Epoch [20/40] Iter[189/312]		Loss: 0.1169
2019-10-29 00:42:59,521 Training Epoch [20/40] Iter[190/312]		Loss: 0.1169
2019-10-29 00:42:59,643 Training Epoch [20/40] Iter[191/312]		Loss: 0.1168
2019-10-29 00:42:59,764 Training Epoch [20/40] Iter[192/312]		Loss: 0.1168
2019-10-29 00:42:59,885 Training Epoch [20/40] Iter[193/312]		Loss: 0.1170
2019-10-29 00:43:00,007 Training Epoch [20/40] Iter[194/312]		Loss: 0.1171
2019-10-29 00:43:00,128 Training Epoch [20/40] Iter[195/312]		Loss: 0.1173
2019-10-29 00:43:00,249 Training Epoch [20/40] Iter[196/312]		Loss: 0.1171
2019-10-29 00:43:00,371 Training Epoch [20/40] Iter[197/312]		Loss: 0.1170
2019-10-29 00:43:00,493 Training Epoch [20/40] Iter[198/312]		Loss: 0.1168
2019-10-29 00:43:00,616 Training Epoch [20/40] Iter[199/312]		Loss: 0.1170
2019-10-29 00:43:00,737 Training Epoch [20/40] Iter[200/312]		Loss: 0.1170
2019-10-29 00:43:00,859 Training Epoch [20/40] Iter[201/312]		Loss: 0.1170
2019-10-29 00:43:00,981 Training Epoch [20/40] Iter[202/312]		Loss: 0.1171
2019-10-29 00:43:01,103 Training Epoch [20/40] Iter[203/312]		Loss: 0.1171
2019-10-29 00:43:01,224 Training Epoch [20/40] Iter[204/312]		Loss: 0.1169
2019-10-29 00:43:01,347 Training Epoch [20/40] Iter[205/312]		Loss: 0.1170
2019-10-29 00:43:01,468 Training Epoch [20/40] Iter[206/312]		Loss: 0.1170
2019-10-29 00:43:01,591 Training Epoch [20/40] Iter[207/312]		Loss: 0.1168
2019-10-29 00:43:01,713 Training Epoch [20/40] Iter[208/312]		Loss: 0.1167
2019-10-29 00:43:01,835 Training Epoch [20/40] Iter[209/312]		Loss: 0.1166
2019-10-29 00:43:01,957 Training Epoch [20/40] Iter[210/312]		Loss: 0.1165
2019-10-29 00:43:02,080 Training Epoch [20/40] Iter[211/312]		Loss: 0.1166
2019-10-29 00:43:02,202 Training Epoch [20/40] Iter[212/312]		Loss: 0.1166
2019-10-29 00:43:02,323 Training Epoch [20/40] Iter[213/312]		Loss: 0.1166
2019-10-29 00:43:02,445 Training Epoch [20/40] Iter[214/312]		Loss: 0.1167
2019-10-29 00:43:02,567 Training Epoch [20/40] Iter[215/312]		Loss: 0.1169
2019-10-29 00:43:02,689 Training Epoch [20/40] Iter[216/312]		Loss: 0.1167
2019-10-29 00:43:02,811 Training Epoch [20/40] Iter[217/312]		Loss: 0.1166
2019-10-29 00:43:02,932 Training Epoch [20/40] Iter[218/312]		Loss: 0.1164
2019-10-29 00:43:03,054 Training Epoch [20/40] Iter[219/312]		Loss: 0.1164
2019-10-29 00:43:03,177 Training Epoch [20/40] Iter[220/312]		Loss: 0.1165
2019-10-29 00:43:03,298 Training Epoch [20/40] Iter[221/312]		Loss: 0.1164
2019-10-29 00:43:03,421 Training Epoch [20/40] Iter[222/312]		Loss: 0.1165
2019-10-29 00:43:03,542 Training Epoch [20/40] Iter[223/312]		Loss: 0.1163
2019-10-29 00:43:03,664 Training Epoch [20/40] Iter[224/312]		Loss: 0.1162
2019-10-29 00:43:03,786 Training Epoch [20/40] Iter[225/312]		Loss: 0.1160
2019-10-29 00:43:03,908 Training Epoch [20/40] Iter[226/312]		Loss: 0.1159
2019-10-29 00:43:04,030 Training Epoch [20/40] Iter[227/312]		Loss: 0.1162
2019-10-29 00:43:04,152 Training Epoch [20/40] Iter[228/312]		Loss: 0.1161
2019-10-29 00:43:04,273 Training Epoch [20/40] Iter[229/312]		Loss: 0.1159
2019-10-29 00:43:04,395 Training Epoch [20/40] Iter[230/312]		Loss: 0.1159
2019-10-29 00:43:04,517 Training Epoch [20/40] Iter[231/312]		Loss: 0.1160
2019-10-29 00:43:04,639 Training Epoch [20/40] Iter[232/312]		Loss: 0.1163
2019-10-29 00:43:04,760 Training Epoch [20/40] Iter[233/312]		Loss: 0.1163
2019-10-29 00:43:04,882 Training Epoch [20/40] Iter[234/312]		Loss: 0.1162
2019-10-29 00:43:05,004 Training Epoch [20/40] Iter[235/312]		Loss: 0.1163
2019-10-29 00:43:05,126 Training Epoch [20/40] Iter[236/312]		Loss: 0.1165
2019-10-29 00:43:05,249 Training Epoch [20/40] Iter[237/312]		Loss: 0.1165
2019-10-29 00:43:05,371 Training Epoch [20/40] Iter[238/312]		Loss: 0.1165
2019-10-29 00:43:05,493 Training Epoch [20/40] Iter[239/312]		Loss: 0.1165
2019-10-29 00:43:05,614 Training Epoch [20/40] Iter[240/312]		Loss: 0.1165
2019-10-29 00:43:05,735 Training Epoch [20/40] Iter[241/312]		Loss: 0.1164
2019-10-29 00:43:05,857 Training Epoch [20/40] Iter[242/312]		Loss: 0.1164
2019-10-29 00:43:05,978 Training Epoch [20/40] Iter[243/312]		Loss: 0.1165
2019-10-29 00:43:06,100 Training Epoch [20/40] Iter[244/312]		Loss: 0.1165
2019-10-29 00:43:06,221 Training Epoch [20/40] Iter[245/312]		Loss: 0.1164
2019-10-29 00:43:06,343 Training Epoch [20/40] Iter[246/312]		Loss: 0.1163
2019-10-29 00:43:06,464 Training Epoch [20/40] Iter[247/312]		Loss: 0.1165
2019-10-29 00:43:06,586 Training Epoch [20/40] Iter[248/312]		Loss: 0.1165
2019-10-29 00:43:06,707 Training Epoch [20/40] Iter[249/312]		Loss: 0.1164
2019-10-29 00:43:06,828 Training Epoch [20/40] Iter[250/312]		Loss: 0.1164
2019-10-29 00:43:06,950 Training Epoch [20/40] Iter[251/312]		Loss: 0.1163
2019-10-29 00:43:07,071 Training Epoch [20/40] Iter[252/312]		Loss: 0.1163
2019-10-29 00:43:07,193 Training Epoch [20/40] Iter[253/312]		Loss: 0.1162
2019-10-29 00:43:07,314 Training Epoch [20/40] Iter[254/312]		Loss: 0.1163
2019-10-29 00:43:07,436 Training Epoch [20/40] Iter[255/312]		Loss: 0.1161
2019-10-29 00:43:07,558 Training Epoch [20/40] Iter[256/312]		Loss: 0.1160
2019-10-29 00:43:07,679 Training Epoch [20/40] Iter[257/312]		Loss: 0.1159
2019-10-29 00:43:07,801 Training Epoch [20/40] Iter[258/312]		Loss: 0.1160
2019-10-29 00:43:07,922 Training Epoch [20/40] Iter[259/312]		Loss: 0.1160
2019-10-29 00:43:08,043 Training Epoch [20/40] Iter[260/312]		Loss: 0.1159
2019-10-29 00:43:08,164 Training Epoch [20/40] Iter[261/312]		Loss: 0.1160
2019-10-29 00:43:08,286 Training Epoch [20/40] Iter[262/312]		Loss: 0.1161
2019-10-29 00:43:08,407 Training Epoch [20/40] Iter[263/312]		Loss: 0.1159
2019-10-29 00:43:08,528 Training Epoch [20/40] Iter[264/312]		Loss: 0.1159
2019-10-29 00:43:08,649 Training Epoch [20/40] Iter[265/312]		Loss: 0.1161
2019-10-29 00:43:08,770 Training Epoch [20/40] Iter[266/312]		Loss: 0.1162
2019-10-29 00:43:08,892 Training Epoch [20/40] Iter[267/312]		Loss: 0.1162
2019-10-29 00:43:09,013 Training Epoch [20/40] Iter[268/312]		Loss: 0.1161
2019-10-29 00:43:09,134 Training Epoch [20/40] Iter[269/312]		Loss: 0.1161
2019-10-29 00:43:09,256 Training Epoch [20/40] Iter[270/312]		Loss: 0.1160
2019-10-29 00:43:09,378 Training Epoch [20/40] Iter[271/312]		Loss: 0.1161
2019-10-29 00:43:09,499 Training Epoch [20/40] Iter[272/312]		Loss: 0.1161
2019-10-29 00:43:09,621 Training Epoch [20/40] Iter[273/312]		Loss: 0.1162
2019-10-29 00:43:09,742 Training Epoch [20/40] Iter[274/312]		Loss: 0.1160
2019-10-29 00:43:09,863 Training Epoch [20/40] Iter[275/312]		Loss: 0.1160
2019-10-29 00:43:09,985 Training Epoch [20/40] Iter[276/312]		Loss: 0.1162
2019-10-29 00:43:10,106 Training Epoch [20/40] Iter[277/312]		Loss: 0.1162
2019-10-29 00:43:10,228 Training Epoch [20/40] Iter[278/312]		Loss: 0.1163
2019-10-29 00:43:10,350 Training Epoch [20/40] Iter[279/312]		Loss: 0.1165
2019-10-29 00:43:10,471 Training Epoch [20/40] Iter[280/312]		Loss: 0.1164
2019-10-29 00:43:10,593 Training Epoch [20/40] Iter[281/312]		Loss: 0.1165
2019-10-29 00:43:10,714 Training Epoch [20/40] Iter[282/312]		Loss: 0.1165
2019-10-29 00:43:10,836 Training Epoch [20/40] Iter[283/312]		Loss: 0.1166
2019-10-29 00:43:10,957 Training Epoch [20/40] Iter[284/312]		Loss: 0.1166
2019-10-29 00:43:11,078 Training Epoch [20/40] Iter[285/312]		Loss: 0.1165
2019-10-29 00:43:11,199 Training Epoch [20/40] Iter[286/312]		Loss: 0.1165
2019-10-29 00:43:11,321 Training Epoch [20/40] Iter[287/312]		Loss: 0.1164
2019-10-29 00:43:11,442 Training Epoch [20/40] Iter[288/312]		Loss: 0.1163
2019-10-29 00:43:11,564 Training Epoch [20/40] Iter[289/312]		Loss: 0.1163
2019-10-29 00:43:11,685 Training Epoch [20/40] Iter[290/312]		Loss: 0.1164
2019-10-29 00:43:11,806 Training Epoch [20/40] Iter[291/312]		Loss: 0.1162
2019-10-29 00:43:11,928 Training Epoch [20/40] Iter[292/312]		Loss: 0.1162
2019-10-29 00:43:12,049 Training Epoch [20/40] Iter[293/312]		Loss: 0.1163
2019-10-29 00:43:12,170 Training Epoch [20/40] Iter[294/312]		Loss: 0.1164
2019-10-29 00:43:12,292 Training Epoch [20/40] Iter[295/312]		Loss: 0.1164
2019-10-29 00:43:12,414 Training Epoch [20/40] Iter[296/312]		Loss: 0.1163
2019-10-29 00:43:12,535 Training Epoch [20/40] Iter[297/312]		Loss: 0.1164
2019-10-29 00:43:12,658 Training Epoch [20/40] Iter[298/312]		Loss: 0.1164
2019-10-29 00:43:12,779 Training Epoch [20/40] Iter[299/312]		Loss: 0.1164
2019-10-29 00:43:12,900 Training Epoch [20/40] Iter[300/312]		Loss: 0.1165
2019-10-29 00:43:13,022 Training Epoch [20/40] Iter[301/312]		Loss: 0.1166
2019-10-29 00:43:13,144 Training Epoch [20/40] Iter[302/312]		Loss: 0.1165
2019-10-29 00:43:13,266 Training Epoch [20/40] Iter[303/312]		Loss: 0.1168
2019-10-29 00:43:13,387 Training Epoch [20/40] Iter[304/312]		Loss: 0.1168
2019-10-29 00:43:13,509 Training Epoch [20/40] Iter[305/312]		Loss: 0.1167
2019-10-29 00:43:13,630 Training Epoch [20/40] Iter[306/312]		Loss: 0.1167
2019-10-29 00:43:13,751 Training Epoch [20/40] Iter[307/312]		Loss: 0.1168
2019-10-29 00:43:13,873 Training Epoch [20/40] Iter[308/312]		Loss: 0.1168
2019-10-29 00:43:13,993 Training Epoch [20/40] Iter[309/312]		Loss: 0.1167
2019-10-29 00:43:14,114 Training Epoch [20/40] Iter[310/312]		Loss: 0.1168
2019-10-29 00:43:14,235 Training Epoch [20/40] Iter[311/312]		Loss: 0.1168
2019-10-29 00:43:14,295 Training Epoch [20/40] Iter[312/312]		Loss: 0.1169
2019-10-29 00:43:14,634 Testing Epoch [20/40] Iter[0/62]		Loss: 0.0963
2019-10-29 00:43:14,705 Testing Epoch [20/40] Iter[1/62]		Loss: 0.1299
2019-10-29 00:43:14,744 Testing Epoch [20/40] Iter[2/62]		Loss: 0.1215
2019-10-29 00:43:14,774 Testing Epoch [20/40] Iter[3/62]		Loss: 0.1199
2019-10-29 00:43:14,811 Testing Epoch [20/40] Iter[4/62]		Loss: 0.1151
2019-10-29 00:43:14,842 Testing Epoch [20/40] Iter[5/62]		Loss: 0.1118
2019-10-29 00:43:14,873 Testing Epoch [20/40] Iter[6/62]		Loss: 0.1149
2019-10-29 00:43:14,906 Testing Epoch [20/40] Iter[7/62]		Loss: 0.1213
2019-10-29 00:43:14,935 Testing Epoch [20/40] Iter[8/62]		Loss: 0.1277
2019-10-29 00:43:14,966 Testing Epoch [20/40] Iter[9/62]		Loss: 0.1249
2019-10-29 00:43:15,002 Testing Epoch [20/40] Iter[10/62]		Loss: 0.1231
2019-10-29 00:43:15,032 Testing Epoch [20/40] Iter[11/62]		Loss: 0.1289
2019-10-29 00:43:15,063 Testing Epoch [20/40] Iter[12/62]		Loss: 0.1295
2019-10-29 00:43:15,098 Testing Epoch [20/40] Iter[13/62]		Loss: 0.1321
2019-10-29 00:43:15,128 Testing Epoch [20/40] Iter[14/62]		Loss: 0.1443
2019-10-29 00:43:15,159 Testing Epoch [20/40] Iter[15/62]		Loss: 0.1464
2019-10-29 00:43:15,194 Testing Epoch [20/40] Iter[16/62]		Loss: 0.1442
2019-10-29 00:43:15,225 Testing Epoch [20/40] Iter[17/62]		Loss: 0.1438
2019-10-29 00:43:15,256 Testing Epoch [20/40] Iter[18/62]		Loss: 0.1406
2019-10-29 00:43:15,293 Testing Epoch [20/40] Iter[19/62]		Loss: 0.1385
2019-10-29 00:43:15,324 Testing Epoch [20/40] Iter[20/62]		Loss: 0.1399
2019-10-29 00:43:15,355 Testing Epoch [20/40] Iter[21/62]		Loss: 0.1379
2019-10-29 00:43:15,386 Testing Epoch [20/40] Iter[22/62]		Loss: 0.1369
2019-10-29 00:43:15,417 Testing Epoch [20/40] Iter[23/62]		Loss: 0.1365
2019-10-29 00:43:15,448 Testing Epoch [20/40] Iter[24/62]		Loss: 0.1383
2019-10-29 00:43:15,479 Testing Epoch [20/40] Iter[25/62]		Loss: 0.1375
2019-10-29 00:43:15,510 Testing Epoch [20/40] Iter[26/62]		Loss: 0.1366
2019-10-29 00:43:15,540 Testing Epoch [20/40] Iter[27/62]		Loss: 0.1411
2019-10-29 00:43:15,571 Testing Epoch [20/40] Iter[28/62]		Loss: 0.1428
2019-10-29 00:43:15,602 Testing Epoch [20/40] Iter[29/62]		Loss: 0.1425
2019-10-29 00:43:15,633 Testing Epoch [20/40] Iter[30/62]		Loss: 0.1441
2019-10-29 00:43:15,664 Testing Epoch [20/40] Iter[31/62]		Loss: 0.1438
2019-10-29 00:43:15,694 Testing Epoch [20/40] Iter[32/62]		Loss: 0.1456
2019-10-29 00:43:15,725 Testing Epoch [20/40] Iter[33/62]		Loss: 0.1440
2019-10-29 00:43:15,756 Testing Epoch [20/40] Iter[34/62]		Loss: 0.1455
2019-10-29 00:43:15,787 Testing Epoch [20/40] Iter[35/62]		Loss: 0.1461
2019-10-29 00:43:15,818 Testing Epoch [20/40] Iter[36/62]		Loss: 0.1445
2019-10-29 00:43:15,849 Testing Epoch [20/40] Iter[37/62]		Loss: 0.1441
2019-10-29 00:43:15,880 Testing Epoch [20/40] Iter[38/62]		Loss: 0.1440
2019-10-29 00:43:15,910 Testing Epoch [20/40] Iter[39/62]		Loss: 0.1442
2019-10-29 00:43:15,941 Testing Epoch [20/40] Iter[40/62]		Loss: 0.1446
2019-10-29 00:43:15,972 Testing Epoch [20/40] Iter[41/62]		Loss: 0.1448
2019-10-29 00:43:16,003 Testing Epoch [20/40] Iter[42/62]		Loss: 0.1432
2019-10-29 00:43:16,034 Testing Epoch [20/40] Iter[43/62]		Loss: 0.1427
2019-10-29 00:43:16,065 Testing Epoch [20/40] Iter[44/62]		Loss: 0.1416
2019-10-29 00:43:16,096 Testing Epoch [20/40] Iter[45/62]		Loss: 0.1425
2019-10-29 00:43:16,127 Testing Epoch [20/40] Iter[46/62]		Loss: 0.1427
2019-10-29 00:43:16,157 Testing Epoch [20/40] Iter[47/62]		Loss: 0.1475
2019-10-29 00:43:16,188 Testing Epoch [20/40] Iter[48/62]		Loss: 0.1464
2019-10-29 00:43:16,219 Testing Epoch [20/40] Iter[49/62]		Loss: 0.1477
2019-10-29 00:43:16,249 Testing Epoch [20/40] Iter[50/62]		Loss: 0.1473
2019-10-29 00:43:16,280 Testing Epoch [20/40] Iter[51/62]		Loss: 0.1472
2019-10-29 00:43:16,311 Testing Epoch [20/40] Iter[52/62]		Loss: 0.1461
2019-10-29 00:43:16,342 Testing Epoch [20/40] Iter[53/62]		Loss: 0.1459
2019-10-29 00:43:16,373 Testing Epoch [20/40] Iter[54/62]		Loss: 0.1453
2019-10-29 00:43:16,403 Testing Epoch [20/40] Iter[55/62]		Loss: 0.1453
2019-10-29 00:43:16,433 Testing Epoch [20/40] Iter[56/62]		Loss: 0.1452
2019-10-29 00:43:16,463 Testing Epoch [20/40] Iter[57/62]		Loss: 0.1451
2019-10-29 00:43:16,493 Testing Epoch [20/40] Iter[58/62]		Loss: 0.1445
2019-10-29 00:43:16,524 Testing Epoch [20/40] Iter[59/62]		Loss: 0.1448
2019-10-29 00:43:16,554 Testing Epoch [20/40] Iter[60/62]		Loss: 0.1442
2019-10-29 00:43:16,584 Testing Epoch [20/40] Iter[61/62]		Loss: 0.1439
2019-10-29 00:43:16,601 Testing Epoch [20/40] Iter[62/62]		Loss: 0.1447
2019-10-29 00:43:16,664 Saving the Model
2019-10-29 00:43:17,041 Training Epoch [21/40] Iter[0/312]		Loss: 0.1235
2019-10-29 00:43:17,165 Training Epoch [21/40] Iter[1/312]		Loss: 0.1152
2019-10-29 00:43:17,286 Training Epoch [21/40] Iter[2/312]		Loss: 0.1031
2019-10-29 00:43:17,410 Training Epoch [21/40] Iter[3/312]		Loss: 0.0999
2019-10-29 00:43:17,531 Training Epoch [21/40] Iter[4/312]		Loss: 0.1010
2019-10-29 00:43:17,651 Training Epoch [21/40] Iter[5/312]		Loss: 0.1034
2019-10-29 00:43:17,771 Training Epoch [21/40] Iter[6/312]		Loss: 0.0979
2019-10-29 00:43:17,893 Training Epoch [21/40] Iter[7/312]		Loss: 0.1012
2019-10-29 00:43:18,014 Training Epoch [21/40] Iter[8/312]		Loss: 0.0982
2019-10-29 00:43:18,135 Training Epoch [21/40] Iter[9/312]		Loss: 0.1018
2019-10-29 00:43:18,256 Training Epoch [21/40] Iter[10/312]		Loss: 0.1039
2019-10-29 00:43:18,378 Training Epoch [21/40] Iter[11/312]		Loss: 0.1045
2019-10-29 00:43:18,499 Training Epoch [21/40] Iter[12/312]		Loss: 0.1040
2019-10-29 00:43:18,623 Training Epoch [21/40] Iter[13/312]		Loss: 0.1010
2019-10-29 00:43:18,745 Training Epoch [21/40] Iter[14/312]		Loss: 0.1077
2019-10-29 00:43:18,866 Training Epoch [21/40] Iter[15/312]		Loss: 0.1095
2019-10-29 00:43:18,988 Training Epoch [21/40] Iter[16/312]		Loss: 0.1093
2019-10-29 00:43:19,110 Training Epoch [21/40] Iter[17/312]		Loss: 0.1116
2019-10-29 00:43:19,232 Training Epoch [21/40] Iter[18/312]		Loss: 0.1109
2019-10-29 00:43:19,353 Training Epoch [21/40] Iter[19/312]		Loss: 0.1104
2019-10-29 00:43:19,475 Training Epoch [21/40] Iter[20/312]		Loss: 0.1096
2019-10-29 00:43:19,596 Training Epoch [21/40] Iter[21/312]		Loss: 0.1109
2019-10-29 00:43:19,717 Training Epoch [21/40] Iter[22/312]		Loss: 0.1094
2019-10-29 00:43:19,838 Training Epoch [21/40] Iter[23/312]		Loss: 0.1106
2019-10-29 00:43:19,959 Training Epoch [21/40] Iter[24/312]		Loss: 0.1103
2019-10-29 00:43:20,080 Training Epoch [21/40] Iter[25/312]		Loss: 0.1094
2019-10-29 00:43:20,202 Training Epoch [21/40] Iter[26/312]		Loss: 0.1086
2019-10-29 00:43:20,324 Training Epoch [21/40] Iter[27/312]		Loss: 0.1089
2019-10-29 00:43:20,445 Training Epoch [21/40] Iter[28/312]		Loss: 0.1088
2019-10-29 00:43:20,568 Training Epoch [21/40] Iter[29/312]		Loss: 0.1078
2019-10-29 00:43:20,689 Training Epoch [21/40] Iter[30/312]		Loss: 0.1071
2019-10-29 00:43:20,810 Training Epoch [21/40] Iter[31/312]		Loss: 0.1063
2019-10-29 00:43:20,932 Training Epoch [21/40] Iter[32/312]		Loss: 0.1055
2019-10-29 00:43:21,054 Training Epoch [21/40] Iter[33/312]		Loss: 0.1056
2019-10-29 00:43:21,175 Training Epoch [21/40] Iter[34/312]		Loss: 0.1051
2019-10-29 00:43:21,296 Training Epoch [21/40] Iter[35/312]		Loss: 0.1048
2019-10-29 00:43:21,418 Training Epoch [21/40] Iter[36/312]		Loss: 0.1044
2019-10-29 00:43:21,540 Training Epoch [21/40] Iter[37/312]		Loss: 0.1059
2019-10-29 00:43:21,661 Training Epoch [21/40] Iter[38/312]		Loss: 0.1053
2019-10-29 00:43:21,782 Training Epoch [21/40] Iter[39/312]		Loss: 0.1054
2019-10-29 00:43:21,908 Training Epoch [21/40] Iter[40/312]		Loss: 0.1051
2019-10-29 00:43:22,030 Training Epoch [21/40] Iter[41/312]		Loss: 0.1050
2019-10-29 00:43:22,151 Training Epoch [21/40] Iter[42/312]		Loss: 0.1049
2019-10-29 00:43:22,273 Training Epoch [21/40] Iter[43/312]		Loss: 0.1043
2019-10-29 00:43:22,395 Training Epoch [21/40] Iter[44/312]		Loss: 0.1045
2019-10-29 00:43:22,516 Training Epoch [21/40] Iter[45/312]		Loss: 0.1049
2019-10-29 00:43:22,637 Training Epoch [21/40] Iter[46/312]		Loss: 0.1046
2019-10-29 00:43:22,759 Training Epoch [21/40] Iter[47/312]		Loss: 0.1051
2019-10-29 00:43:22,880 Training Epoch [21/40] Iter[48/312]		Loss: 0.1065
2019-10-29 00:43:23,002 Training Epoch [21/40] Iter[49/312]		Loss: 0.1060
2019-10-29 00:43:23,124 Training Epoch [21/40] Iter[50/312]		Loss: 0.1053
2019-10-29 00:43:23,245 Training Epoch [21/40] Iter[51/312]		Loss: 0.1048
2019-10-29 00:43:23,367 Training Epoch [21/40] Iter[52/312]		Loss: 0.1047
2019-10-29 00:43:23,488 Training Epoch [21/40] Iter[53/312]		Loss: 0.1045
2019-10-29 00:43:23,610 Training Epoch [21/40] Iter[54/312]		Loss: 0.1050
2019-10-29 00:43:23,732 Training Epoch [21/40] Iter[55/312]		Loss: 0.1060
2019-10-29 00:43:23,853 Training Epoch [21/40] Iter[56/312]		Loss: 0.1062
2019-10-29 00:43:23,974 Training Epoch [21/40] Iter[57/312]		Loss: 0.1064
2019-10-29 00:43:24,100 Training Epoch [21/40] Iter[58/312]		Loss: 0.1060
2019-10-29 00:43:24,221 Training Epoch [21/40] Iter[59/312]		Loss: 0.1064
2019-10-29 00:43:24,343 Training Epoch [21/40] Iter[60/312]		Loss: 0.1065
2019-10-29 00:43:24,465 Training Epoch [21/40] Iter[61/312]		Loss: 0.1065
2019-10-29 00:43:24,586 Training Epoch [21/40] Iter[62/312]		Loss: 0.1064
2019-10-29 00:43:24,708 Training Epoch [21/40] Iter[63/312]		Loss: 0.1064
2019-10-29 00:43:24,829 Training Epoch [21/40] Iter[64/312]		Loss: 0.1066
2019-10-29 00:43:24,952 Training Epoch [21/40] Iter[65/312]		Loss: 0.1066
2019-10-29 00:43:25,073 Training Epoch [21/40] Iter[66/312]		Loss: 0.1070
2019-10-29 00:43:25,194 Training Epoch [21/40] Iter[67/312]		Loss: 0.1076
2019-10-29 00:43:25,315 Training Epoch [21/40] Iter[68/312]		Loss: 0.1074
2019-10-29 00:43:25,436 Training Epoch [21/40] Iter[69/312]		Loss: 0.1075
2019-10-29 00:43:25,557 Training Epoch [21/40] Iter[70/312]		Loss: 0.1080
2019-10-29 00:43:25,678 Training Epoch [21/40] Iter[71/312]		Loss: 0.1086
2019-10-29 00:43:25,799 Training Epoch [21/40] Iter[72/312]		Loss: 0.1082
2019-10-29 00:43:25,921 Training Epoch [21/40] Iter[73/312]		Loss: 0.1080
2019-10-29 00:43:26,047 Training Epoch [21/40] Iter[74/312]		Loss: 0.1082
2019-10-29 00:43:26,168 Training Epoch [21/40] Iter[75/312]		Loss: 0.1088
2019-10-29 00:43:26,289 Training Epoch [21/40] Iter[76/312]		Loss: 0.1089
2019-10-29 00:43:26,410 Training Epoch [21/40] Iter[77/312]		Loss: 0.1087
2019-10-29 00:43:26,533 Training Epoch [21/40] Iter[78/312]		Loss: 0.1083
2019-10-29 00:43:26,654 Training Epoch [21/40] Iter[79/312]		Loss: 0.1084
2019-10-29 00:43:26,776 Training Epoch [21/40] Iter[80/312]		Loss: 0.1090
2019-10-29 00:43:26,897 Training Epoch [21/40] Iter[81/312]		Loss: 0.1087
2019-10-29 00:43:27,020 Training Epoch [21/40] Iter[82/312]		Loss: 0.1092
2019-10-29 00:43:27,141 Training Epoch [21/40] Iter[83/312]		Loss: 0.1099
2019-10-29 00:43:27,263 Training Epoch [21/40] Iter[84/312]		Loss: 0.1097
2019-10-29 00:43:27,386 Training Epoch [21/40] Iter[85/312]		Loss: 0.1093
2019-10-29 00:43:27,507 Training Epoch [21/40] Iter[86/312]		Loss: 0.1093
2019-10-29 00:43:27,629 Training Epoch [21/40] Iter[87/312]		Loss: 0.1090
2019-10-29 00:43:27,750 Training Epoch [21/40] Iter[88/312]		Loss: 0.1086
2019-10-29 00:43:27,872 Training Epoch [21/40] Iter[89/312]		Loss: 0.1083
2019-10-29 00:43:27,994 Training Epoch [21/40] Iter[90/312]		Loss: 0.1081
2019-10-29 00:43:28,116 Training Epoch [21/40] Iter[91/312]		Loss: 0.1081
2019-10-29 00:43:28,237 Training Epoch [21/40] Iter[92/312]		Loss: 0.1080
2019-10-29 00:43:28,358 Training Epoch [21/40] Iter[93/312]		Loss: 0.1085
2019-10-29 00:43:28,480 Training Epoch [21/40] Iter[94/312]		Loss: 0.1083
2019-10-29 00:43:28,602 Training Epoch [21/40] Iter[95/312]		Loss: 0.1081
2019-10-29 00:43:28,723 Training Epoch [21/40] Iter[96/312]		Loss: 0.1077
2019-10-29 00:43:28,845 Training Epoch [21/40] Iter[97/312]		Loss: 0.1074
2019-10-29 00:43:28,967 Training Epoch [21/40] Iter[98/312]		Loss: 0.1072
2019-10-29 00:43:29,088 Training Epoch [21/40] Iter[99/312]		Loss: 0.1067
2019-10-29 00:43:29,209 Training Epoch [21/40] Iter[100/312]		Loss: 0.1072
2019-10-29 00:43:29,331 Training Epoch [21/40] Iter[101/312]		Loss: 0.1070
2019-10-29 00:43:29,452 Training Epoch [21/40] Iter[102/312]		Loss: 0.1079
2019-10-29 00:43:29,573 Training Epoch [21/40] Iter[103/312]		Loss: 0.1080
2019-10-29 00:43:29,695 Training Epoch [21/40] Iter[104/312]		Loss: 0.1077
2019-10-29 00:43:29,816 Training Epoch [21/40] Iter[105/312]		Loss: 0.1074
2019-10-29 00:43:29,938 Training Epoch [21/40] Iter[106/312]		Loss: 0.1075
2019-10-29 00:43:30,059 Training Epoch [21/40] Iter[107/312]		Loss: 0.1075
2019-10-29 00:43:30,180 Training Epoch [21/40] Iter[108/312]		Loss: 0.1075
2019-10-29 00:43:30,302 Training Epoch [21/40] Iter[109/312]		Loss: 0.1073
2019-10-29 00:43:30,424 Training Epoch [21/40] Iter[110/312]		Loss: 0.1069
2019-10-29 00:43:30,545 Training Epoch [21/40] Iter[111/312]		Loss: 0.1070
2019-10-29 00:43:30,666 Training Epoch [21/40] Iter[112/312]		Loss: 0.1068
2019-10-29 00:43:30,788 Training Epoch [21/40] Iter[113/312]		Loss: 0.1066
2019-10-29 00:43:30,909 Training Epoch [21/40] Iter[114/312]		Loss: 0.1067
2019-10-29 00:43:31,031 Training Epoch [21/40] Iter[115/312]		Loss: 0.1066
2019-10-29 00:43:31,153 Training Epoch [21/40] Iter[116/312]		Loss: 0.1067
2019-10-29 00:43:31,274 Training Epoch [21/40] Iter[117/312]		Loss: 0.1065
2019-10-29 00:43:31,396 Training Epoch [21/40] Iter[118/312]		Loss: 0.1063
2019-10-29 00:43:31,517 Training Epoch [21/40] Iter[119/312]		Loss: 0.1059
2019-10-29 00:43:31,639 Training Epoch [21/40] Iter[120/312]		Loss: 0.1056
2019-10-29 00:43:31,760 Training Epoch [21/40] Iter[121/312]		Loss: 0.1055
2019-10-29 00:43:31,882 Training Epoch [21/40] Iter[122/312]		Loss: 0.1055
2019-10-29 00:43:32,003 Training Epoch [21/40] Iter[123/312]		Loss: 0.1056
2019-10-29 00:43:32,125 Training Epoch [21/40] Iter[124/312]		Loss: 0.1056
2019-10-29 00:43:32,246 Training Epoch [21/40] Iter[125/312]		Loss: 0.1056
2019-10-29 00:43:32,368 Training Epoch [21/40] Iter[126/312]		Loss: 0.1055
2019-10-29 00:43:32,489 Training Epoch [21/40] Iter[127/312]		Loss: 0.1055
2019-10-29 00:43:32,611 Training Epoch [21/40] Iter[128/312]		Loss: 0.1056
2019-10-29 00:43:32,732 Training Epoch [21/40] Iter[129/312]		Loss: 0.1055
2019-10-29 00:43:32,853 Training Epoch [21/40] Iter[130/312]		Loss: 0.1055
2019-10-29 00:43:32,975 Training Epoch [21/40] Iter[131/312]		Loss: 0.1055
2019-10-29 00:43:33,096 Training Epoch [21/40] Iter[132/312]		Loss: 0.1057
2019-10-29 00:43:33,217 Training Epoch [21/40] Iter[133/312]		Loss: 0.1054
2019-10-29 00:43:33,339 Training Epoch [21/40] Iter[134/312]		Loss: 0.1051
2019-10-29 00:43:33,461 Training Epoch [21/40] Iter[135/312]		Loss: 0.1053
2019-10-29 00:43:33,582 Training Epoch [21/40] Iter[136/312]		Loss: 0.1052
2019-10-29 00:43:33,703 Training Epoch [21/40] Iter[137/312]		Loss: 0.1051
2019-10-29 00:43:33,825 Training Epoch [21/40] Iter[138/312]		Loss: 0.1052
2019-10-29 00:43:33,946 Training Epoch [21/40] Iter[139/312]		Loss: 0.1051
2019-10-29 00:43:34,067 Training Epoch [21/40] Iter[140/312]		Loss: 0.1052
2019-10-29 00:43:34,188 Training Epoch [21/40] Iter[141/312]		Loss: 0.1053
2019-10-29 00:43:34,310 Training Epoch [21/40] Iter[142/312]		Loss: 0.1052
2019-10-29 00:43:34,431 Training Epoch [21/40] Iter[143/312]		Loss: 0.1050
2019-10-29 00:43:34,552 Training Epoch [21/40] Iter[144/312]		Loss: 0.1048
2019-10-29 00:43:34,674 Training Epoch [21/40] Iter[145/312]		Loss: 0.1049
2019-10-29 00:43:34,795 Training Epoch [21/40] Iter[146/312]		Loss: 0.1049
2019-10-29 00:43:34,917 Training Epoch [21/40] Iter[147/312]		Loss: 0.1051
2019-10-29 00:43:35,039 Training Epoch [21/40] Iter[148/312]		Loss: 0.1051
2019-10-29 00:43:35,160 Training Epoch [21/40] Iter[149/312]		Loss: 0.1049
2019-10-29 00:43:35,282 Training Epoch [21/40] Iter[150/312]		Loss: 0.1049
2019-10-29 00:43:35,404 Training Epoch [21/40] Iter[151/312]		Loss: 0.1048
2019-10-29 00:43:35,525 Training Epoch [21/40] Iter[152/312]		Loss: 0.1049
2019-10-29 00:43:35,647 Training Epoch [21/40] Iter[153/312]		Loss: 0.1052
2019-10-29 00:43:35,772 Training Epoch [21/40] Iter[154/312]		Loss: 0.1048
2019-10-29 00:43:35,894 Training Epoch [21/40] Iter[155/312]		Loss: 0.1051
2019-10-29 00:43:36,015 Training Epoch [21/40] Iter[156/312]		Loss: 0.1052
2019-10-29 00:43:36,137 Training Epoch [21/40] Iter[157/312]		Loss: 0.1055
2019-10-29 00:43:36,259 Training Epoch [21/40] Iter[158/312]		Loss: 0.1051
2019-10-29 00:43:36,381 Training Epoch [21/40] Iter[159/312]		Loss: 0.1050
2019-10-29 00:43:36,502 Training Epoch [21/40] Iter[160/312]		Loss: 0.1048
2019-10-29 00:43:36,624 Training Epoch [21/40] Iter[161/312]		Loss: 0.1051
2019-10-29 00:43:36,746 Training Epoch [21/40] Iter[162/312]		Loss: 0.1048
2019-10-29 00:43:36,867 Training Epoch [21/40] Iter[163/312]		Loss: 0.1047
2019-10-29 00:43:36,988 Training Epoch [21/40] Iter[164/312]		Loss: 0.1048
2019-10-29 00:43:37,110 Training Epoch [21/40] Iter[165/312]		Loss: 0.1046
2019-10-29 00:43:37,231 Training Epoch [21/40] Iter[166/312]		Loss: 0.1046
2019-10-29 00:43:37,353 Training Epoch [21/40] Iter[167/312]		Loss: 0.1048
2019-10-29 00:43:37,474 Training Epoch [21/40] Iter[168/312]		Loss: 0.1046
2019-10-29 00:43:37,596 Training Epoch [21/40] Iter[169/312]		Loss: 0.1048
2019-10-29 00:43:37,717 Training Epoch [21/40] Iter[170/312]		Loss: 0.1047
2019-10-29 00:43:37,838 Training Epoch [21/40] Iter[171/312]		Loss: 0.1047
2019-10-29 00:43:37,960 Training Epoch [21/40] Iter[172/312]		Loss: 0.1045
2019-10-29 00:43:38,081 Training Epoch [21/40] Iter[173/312]		Loss: 0.1043
2019-10-29 00:43:38,203 Training Epoch [21/40] Iter[174/312]		Loss: 0.1044
2019-10-29 00:43:38,325 Training Epoch [21/40] Iter[175/312]		Loss: 0.1043
2019-10-29 00:43:38,447 Training Epoch [21/40] Iter[176/312]		Loss: 0.1044
2019-10-29 00:43:38,568 Training Epoch [21/40] Iter[177/312]		Loss: 0.1045
2019-10-29 00:43:38,689 Training Epoch [21/40] Iter[178/312]		Loss: 0.1043
2019-10-29 00:43:38,811 Training Epoch [21/40] Iter[179/312]		Loss: 0.1043
2019-10-29 00:43:38,932 Training Epoch [21/40] Iter[180/312]		Loss: 0.1047
2019-10-29 00:43:39,052 Training Epoch [21/40] Iter[181/312]		Loss: 0.1046
2019-10-29 00:43:39,174 Training Epoch [21/40] Iter[182/312]		Loss: 0.1046
2019-10-29 00:43:39,295 Training Epoch [21/40] Iter[183/312]		Loss: 0.1048
2019-10-29 00:43:39,416 Training Epoch [21/40] Iter[184/312]		Loss: 0.1047
2019-10-29 00:43:39,537 Training Epoch [21/40] Iter[185/312]		Loss: 0.1045
2019-10-29 00:43:39,659 Training Epoch [21/40] Iter[186/312]		Loss: 0.1045
2019-10-29 00:43:39,780 Training Epoch [21/40] Iter[187/312]		Loss: 0.1043
2019-10-29 00:43:39,902 Training Epoch [21/40] Iter[188/312]		Loss: 0.1048
2019-10-29 00:43:40,024 Training Epoch [21/40] Iter[189/312]		Loss: 0.1051
2019-10-29 00:43:40,145 Training Epoch [21/40] Iter[190/312]		Loss: 0.1052
2019-10-29 00:43:40,266 Training Epoch [21/40] Iter[191/312]		Loss: 0.1052
2019-10-29 00:43:40,388 Training Epoch [21/40] Iter[192/312]		Loss: 0.1053
2019-10-29 00:43:40,510 Training Epoch [21/40] Iter[193/312]		Loss: 0.1054
2019-10-29 00:43:40,632 Training Epoch [21/40] Iter[194/312]		Loss: 0.1056
2019-10-29 00:43:40,754 Training Epoch [21/40] Iter[195/312]		Loss: 0.1059
2019-10-29 00:43:40,875 Training Epoch [21/40] Iter[196/312]		Loss: 0.1058
2019-10-29 00:43:40,996 Training Epoch [21/40] Iter[197/312]		Loss: 0.1063
2019-10-29 00:43:41,117 Training Epoch [21/40] Iter[198/312]		Loss: 0.1063
2019-10-29 00:43:41,239 Training Epoch [21/40] Iter[199/312]		Loss: 0.1063
2019-10-29 00:43:41,361 Training Epoch [21/40] Iter[200/312]		Loss: 0.1062
2019-10-29 00:43:41,482 Training Epoch [21/40] Iter[201/312]		Loss: 0.1063
2019-10-29 00:43:41,603 Training Epoch [21/40] Iter[202/312]		Loss: 0.1061
2019-10-29 00:43:41,724 Training Epoch [21/40] Iter[203/312]		Loss: 0.1062
2019-10-29 00:43:41,845 Training Epoch [21/40] Iter[204/312]		Loss: 0.1061
2019-10-29 00:43:41,967 Training Epoch [21/40] Iter[205/312]		Loss: 0.1062
2019-10-29 00:43:42,088 Training Epoch [21/40] Iter[206/312]		Loss: 0.1065
2019-10-29 00:43:42,209 Training Epoch [21/40] Iter[207/312]		Loss: 0.1064
2019-10-29 00:43:42,331 Training Epoch [21/40] Iter[208/312]		Loss: 0.1062
2019-10-29 00:43:42,452 Training Epoch [21/40] Iter[209/312]		Loss: 0.1063
2019-10-29 00:43:42,574 Training Epoch [21/40] Iter[210/312]		Loss: 0.1063
2019-10-29 00:43:42,696 Training Epoch [21/40] Iter[211/312]		Loss: 0.1062
2019-10-29 00:43:42,817 Training Epoch [21/40] Iter[212/312]		Loss: 0.1061
2019-10-29 00:43:42,939 Training Epoch [21/40] Iter[213/312]		Loss: 0.1062
2019-10-29 00:43:43,060 Training Epoch [21/40] Iter[214/312]		Loss: 0.1063
2019-10-29 00:43:43,181 Training Epoch [21/40] Iter[215/312]		Loss: 0.1063
2019-10-29 00:43:43,302 Training Epoch [21/40] Iter[216/312]		Loss: 0.1062
2019-10-29 00:43:43,423 Training Epoch [21/40] Iter[217/312]		Loss: 0.1060
2019-10-29 00:43:43,544 Training Epoch [21/40] Iter[218/312]		Loss: 0.1060
2019-10-29 00:43:43,666 Training Epoch [21/40] Iter[219/312]		Loss: 0.1060
2019-10-29 00:43:43,787 Training Epoch [21/40] Iter[220/312]		Loss: 0.1059
2019-10-29 00:43:43,907 Training Epoch [21/40] Iter[221/312]		Loss: 0.1064
2019-10-29 00:43:44,028 Training Epoch [21/40] Iter[222/312]		Loss: 0.1063
2019-10-29 00:43:44,150 Training Epoch [21/40] Iter[223/312]		Loss: 0.1063
2019-10-29 00:43:44,271 Training Epoch [21/40] Iter[224/312]		Loss: 0.1062
2019-10-29 00:43:44,393 Training Epoch [21/40] Iter[225/312]		Loss: 0.1062
2019-10-29 00:43:44,515 Training Epoch [21/40] Iter[226/312]		Loss: 0.1062
2019-10-29 00:43:44,636 Training Epoch [21/40] Iter[227/312]		Loss: 0.1062
2019-10-29 00:43:44,758 Training Epoch [21/40] Iter[228/312]		Loss: 0.1061
2019-10-29 00:43:44,879 Training Epoch [21/40] Iter[229/312]		Loss: 0.1062
2019-10-29 00:43:45,000 Training Epoch [21/40] Iter[230/312]		Loss: 0.1061
2019-10-29 00:43:45,122 Training Epoch [21/40] Iter[231/312]		Loss: 0.1062
2019-10-29 00:43:45,243 Training Epoch [21/40] Iter[232/312]		Loss: 0.1061
2019-10-29 00:43:45,365 Training Epoch [21/40] Iter[233/312]		Loss: 0.1059
2019-10-29 00:43:45,487 Training Epoch [21/40] Iter[234/312]		Loss: 0.1058
2019-10-29 00:43:45,609 Training Epoch [21/40] Iter[235/312]		Loss: 0.1057
2019-10-29 00:43:45,731 Training Epoch [21/40] Iter[236/312]		Loss: 0.1058
2019-10-29 00:43:45,853 Training Epoch [21/40] Iter[237/312]		Loss: 0.1057
2019-10-29 00:43:45,974 Training Epoch [21/40] Iter[238/312]		Loss: 0.1057
2019-10-29 00:43:46,096 Training Epoch [21/40] Iter[239/312]		Loss: 0.1056
2019-10-29 00:43:46,217 Training Epoch [21/40] Iter[240/312]		Loss: 0.1055
2019-10-29 00:43:46,339 Training Epoch [21/40] Iter[241/312]		Loss: 0.1055
2019-10-29 00:43:46,461 Training Epoch [21/40] Iter[242/312]		Loss: 0.1057
2019-10-29 00:43:46,582 Training Epoch [21/40] Iter[243/312]		Loss: 0.1059
2019-10-29 00:43:46,703 Training Epoch [21/40] Iter[244/312]		Loss: 0.1059
2019-10-29 00:43:46,824 Training Epoch [21/40] Iter[245/312]		Loss: 0.1063
2019-10-29 00:43:46,945 Training Epoch [21/40] Iter[246/312]		Loss: 0.1064
2019-10-29 00:43:47,066 Training Epoch [21/40] Iter[247/312]		Loss: 0.1065
2019-10-29 00:43:47,188 Training Epoch [21/40] Iter[248/312]		Loss: 0.1065
2019-10-29 00:43:47,309 Training Epoch [21/40] Iter[249/312]		Loss: 0.1066
2019-10-29 00:43:47,431 Training Epoch [21/40] Iter[250/312]		Loss: 0.1067
2019-10-29 00:43:47,553 Training Epoch [21/40] Iter[251/312]		Loss: 0.1065
2019-10-29 00:43:47,674 Training Epoch [21/40] Iter[252/312]		Loss: 0.1065
2019-10-29 00:43:47,796 Training Epoch [21/40] Iter[253/312]		Loss: 0.1066
2019-10-29 00:43:47,917 Training Epoch [21/40] Iter[254/312]		Loss: 0.1065
2019-10-29 00:43:48,039 Training Epoch [21/40] Iter[255/312]		Loss: 0.1066
2019-10-29 00:43:48,161 Training Epoch [21/40] Iter[256/312]		Loss: 0.1066
2019-10-29 00:43:48,282 Training Epoch [21/40] Iter[257/312]		Loss: 0.1065
2019-10-29 00:43:48,403 Training Epoch [21/40] Iter[258/312]		Loss: 0.1066
2019-10-29 00:43:48,525 Training Epoch [21/40] Iter[259/312]		Loss: 0.1067
2019-10-29 00:43:48,646 Training Epoch [21/40] Iter[260/312]		Loss: 0.1068
2019-10-29 00:43:48,768 Training Epoch [21/40] Iter[261/312]		Loss: 0.1067
2019-10-29 00:43:48,890 Training Epoch [21/40] Iter[262/312]		Loss: 0.1067
2019-10-29 00:43:49,012 Training Epoch [21/40] Iter[263/312]		Loss: 0.1067
2019-10-29 00:43:49,134 Training Epoch [21/40] Iter[264/312]		Loss: 0.1068
2019-10-29 00:43:49,255 Training Epoch [21/40] Iter[265/312]		Loss: 0.1069
2019-10-29 00:43:49,377 Training Epoch [21/40] Iter[266/312]		Loss: 0.1069
2019-10-29 00:43:49,498 Training Epoch [21/40] Iter[267/312]		Loss: 0.1068
2019-10-29 00:43:49,621 Training Epoch [21/40] Iter[268/312]		Loss: 0.1068
2019-10-29 00:43:49,743 Training Epoch [21/40] Iter[269/312]		Loss: 0.1068
2019-10-29 00:43:49,864 Training Epoch [21/40] Iter[270/312]		Loss: 0.1068
2019-10-29 00:43:49,986 Training Epoch [21/40] Iter[271/312]		Loss: 0.1067
2019-10-29 00:43:50,107 Training Epoch [21/40] Iter[272/312]		Loss: 0.1066
2019-10-29 00:43:50,228 Training Epoch [21/40] Iter[273/312]		Loss: 0.1065
2019-10-29 00:43:50,350 Training Epoch [21/40] Iter[274/312]		Loss: 0.1066
2019-10-29 00:43:50,472 Training Epoch [21/40] Iter[275/312]		Loss: 0.1064
2019-10-29 00:43:50,593 Training Epoch [21/40] Iter[276/312]		Loss: 0.1064
2019-10-29 00:43:50,715 Training Epoch [21/40] Iter[277/312]		Loss: 0.1064
2019-10-29 00:43:50,836 Training Epoch [21/40] Iter[278/312]		Loss: 0.1065
2019-10-29 00:43:50,958 Training Epoch [21/40] Iter[279/312]		Loss: 0.1065
2019-10-29 00:43:51,079 Training Epoch [21/40] Iter[280/312]		Loss: 0.1066
2019-10-29 00:43:51,200 Training Epoch [21/40] Iter[281/312]		Loss: 0.1066
2019-10-29 00:43:51,322 Training Epoch [21/40] Iter[282/312]		Loss: 0.1066
2019-10-29 00:43:51,443 Training Epoch [21/40] Iter[283/312]		Loss: 0.1065
2019-10-29 00:43:51,565 Training Epoch [21/40] Iter[284/312]		Loss: 0.1065
2019-10-29 00:43:51,686 Training Epoch [21/40] Iter[285/312]		Loss: 0.1065
2019-10-29 00:43:51,807 Training Epoch [21/40] Iter[286/312]		Loss: 0.1064
2019-10-29 00:43:51,927 Training Epoch [21/40] Iter[287/312]		Loss: 0.1065
2019-10-29 00:43:52,049 Training Epoch [21/40] Iter[288/312]		Loss: 0.1068
2019-10-29 00:43:52,170 Training Epoch [21/40] Iter[289/312]		Loss: 0.1067
2019-10-29 00:43:52,291 Training Epoch [21/40] Iter[290/312]		Loss: 0.1067
2019-10-29 00:43:52,413 Training Epoch [21/40] Iter[291/312]		Loss: 0.1067
2019-10-29 00:43:52,534 Training Epoch [21/40] Iter[292/312]		Loss: 0.1067
2019-10-29 00:43:52,655 Training Epoch [21/40] Iter[293/312]		Loss: 0.1066
2019-10-29 00:43:52,776 Training Epoch [21/40] Iter[294/312]		Loss: 0.1066
2019-10-29 00:43:52,898 Training Epoch [21/40] Iter[295/312]		Loss: 0.1066
2019-10-29 00:43:53,020 Training Epoch [21/40] Iter[296/312]		Loss: 0.1066
2019-10-29 00:43:53,141 Training Epoch [21/40] Iter[297/312]		Loss: 0.1067
2019-10-29 00:43:53,263 Training Epoch [21/40] Iter[298/312]		Loss: 0.1067
2019-10-29 00:43:53,385 Training Epoch [21/40] Iter[299/312]		Loss: 0.1066
2019-10-29 00:43:53,506 Training Epoch [21/40] Iter[300/312]		Loss: 0.1066
2019-10-29 00:43:53,627 Training Epoch [21/40] Iter[301/312]		Loss: 0.1066
2019-10-29 00:43:53,748 Training Epoch [21/40] Iter[302/312]		Loss: 0.1066
2019-10-29 00:43:53,870 Training Epoch [21/40] Iter[303/312]		Loss: 0.1067
2019-10-29 00:43:53,991 Training Epoch [21/40] Iter[304/312]		Loss: 0.1067
2019-10-29 00:43:54,112 Training Epoch [21/40] Iter[305/312]		Loss: 0.1069
2019-10-29 00:43:54,233 Training Epoch [21/40] Iter[306/312]		Loss: 0.1067
2019-10-29 00:43:54,355 Training Epoch [21/40] Iter[307/312]		Loss: 0.1067
2019-10-29 00:43:54,476 Training Epoch [21/40] Iter[308/312]		Loss: 0.1067
2019-10-29 00:43:54,597 Training Epoch [21/40] Iter[309/312]		Loss: 0.1067
2019-10-29 00:43:54,718 Training Epoch [21/40] Iter[310/312]		Loss: 0.1066
2019-10-29 00:43:54,839 Training Epoch [21/40] Iter[311/312]		Loss: 0.1066
2019-10-29 00:43:54,900 Training Epoch [21/40] Iter[312/312]		Loss: 0.1066
2019-10-29 00:43:55,280 Testing Epoch [21/40] Iter[0/62]		Loss: 0.0925
2019-10-29 00:43:55,329 Testing Epoch [21/40] Iter[1/62]		Loss: 0.1271
2019-10-29 00:43:55,374 Testing Epoch [21/40] Iter[2/62]		Loss: 0.1192
2019-10-29 00:43:55,408 Testing Epoch [21/40] Iter[3/62]		Loss: 0.1172
2019-10-29 00:43:55,439 Testing Epoch [21/40] Iter[4/62]		Loss: 0.1137
2019-10-29 00:43:55,469 Testing Epoch [21/40] Iter[5/62]		Loss: 0.1116
2019-10-29 00:43:55,499 Testing Epoch [21/40] Iter[6/62]		Loss: 0.1139
2019-10-29 00:43:55,530 Testing Epoch [21/40] Iter[7/62]		Loss: 0.1192
2019-10-29 00:43:55,560 Testing Epoch [21/40] Iter[8/62]		Loss: 0.1253
2019-10-29 00:43:55,591 Testing Epoch [21/40] Iter[9/62]		Loss: 0.1221
2019-10-29 00:43:55,622 Testing Epoch [21/40] Iter[10/62]		Loss: 0.1202
2019-10-29 00:43:55,653 Testing Epoch [21/40] Iter[11/62]		Loss: 0.1259
2019-10-29 00:43:55,684 Testing Epoch [21/40] Iter[12/62]		Loss: 0.1269
2019-10-29 00:43:55,715 Testing Epoch [21/40] Iter[13/62]		Loss: 0.1292
2019-10-29 00:43:55,746 Testing Epoch [21/40] Iter[14/62]		Loss: 0.1410
2019-10-29 00:43:55,777 Testing Epoch [21/40] Iter[15/62]		Loss: 0.1432
2019-10-29 00:43:55,808 Testing Epoch [21/40] Iter[16/62]		Loss: 0.1410
2019-10-29 00:43:55,839 Testing Epoch [21/40] Iter[17/62]		Loss: 0.1408
2019-10-29 00:43:55,869 Testing Epoch [21/40] Iter[18/62]		Loss: 0.1379
2019-10-29 00:43:55,900 Testing Epoch [21/40] Iter[19/62]		Loss: 0.1357
2019-10-29 00:43:55,931 Testing Epoch [21/40] Iter[20/62]		Loss: 0.1372
2019-10-29 00:43:55,962 Testing Epoch [21/40] Iter[21/62]		Loss: 0.1352
2019-10-29 00:43:55,992 Testing Epoch [21/40] Iter[22/62]		Loss: 0.1343
2019-10-29 00:43:56,023 Testing Epoch [21/40] Iter[23/62]		Loss: 0.1339
2019-10-29 00:43:56,054 Testing Epoch [21/40] Iter[24/62]		Loss: 0.1357
2019-10-29 00:43:56,085 Testing Epoch [21/40] Iter[25/62]		Loss: 0.1350
2019-10-29 00:43:56,116 Testing Epoch [21/40] Iter[26/62]		Loss: 0.1339
2019-10-29 00:43:56,147 Testing Epoch [21/40] Iter[27/62]		Loss: 0.1383
2019-10-29 00:43:56,178 Testing Epoch [21/40] Iter[28/62]		Loss: 0.1402
2019-10-29 00:43:56,209 Testing Epoch [21/40] Iter[29/62]		Loss: 0.1401
2019-10-29 00:43:56,240 Testing Epoch [21/40] Iter[30/62]		Loss: 0.1417
2019-10-29 00:43:56,271 Testing Epoch [21/40] Iter[31/62]		Loss: 0.1410
2019-10-29 00:43:56,303 Testing Epoch [21/40] Iter[32/62]		Loss: 0.1427
2019-10-29 00:43:56,334 Testing Epoch [21/40] Iter[33/62]		Loss: 0.1409
2019-10-29 00:43:56,364 Testing Epoch [21/40] Iter[34/62]		Loss: 0.1423
2019-10-29 00:43:56,395 Testing Epoch [21/40] Iter[35/62]		Loss: 0.1428
2019-10-29 00:43:56,426 Testing Epoch [21/40] Iter[36/62]		Loss: 0.1411
2019-10-29 00:43:56,457 Testing Epoch [21/40] Iter[37/62]		Loss: 0.1407
2019-10-29 00:43:56,488 Testing Epoch [21/40] Iter[38/62]		Loss: 0.1407
2019-10-29 00:43:56,518 Testing Epoch [21/40] Iter[39/62]		Loss: 0.1411
2019-10-29 00:43:56,549 Testing Epoch [21/40] Iter[40/62]		Loss: 0.1415
2019-10-29 00:43:56,580 Testing Epoch [21/40] Iter[41/62]		Loss: 0.1417
2019-10-29 00:43:56,611 Testing Epoch [21/40] Iter[42/62]		Loss: 0.1402
2019-10-29 00:43:56,642 Testing Epoch [21/40] Iter[43/62]		Loss: 0.1397
2019-10-29 00:43:56,673 Testing Epoch [21/40] Iter[44/62]		Loss: 0.1386
2019-10-29 00:43:56,704 Testing Epoch [21/40] Iter[45/62]		Loss: 0.1396
2019-10-29 00:43:56,735 Testing Epoch [21/40] Iter[46/62]		Loss: 0.1396
2019-10-29 00:43:56,766 Testing Epoch [21/40] Iter[47/62]		Loss: 0.1443
2019-10-29 00:43:56,797 Testing Epoch [21/40] Iter[48/62]		Loss: 0.1433
2019-10-29 00:43:56,828 Testing Epoch [21/40] Iter[49/62]		Loss: 0.1446
2019-10-29 00:43:56,859 Testing Epoch [21/40] Iter[50/62]		Loss: 0.1442
2019-10-29 00:43:56,890 Testing Epoch [21/40] Iter[51/62]		Loss: 0.1442
2019-10-29 00:43:56,920 Testing Epoch [21/40] Iter[52/62]		Loss: 0.1430
2019-10-29 00:43:56,951 Testing Epoch [21/40] Iter[53/62]		Loss: 0.1428
2019-10-29 00:43:56,982 Testing Epoch [21/40] Iter[54/62]		Loss: 0.1422
2019-10-29 00:43:57,012 Testing Epoch [21/40] Iter[55/62]		Loss: 0.1422
2019-10-29 00:43:57,043 Testing Epoch [21/40] Iter[56/62]		Loss: 0.1421
2019-10-29 00:43:57,073 Testing Epoch [21/40] Iter[57/62]		Loss: 0.1420
2019-10-29 00:43:57,104 Testing Epoch [21/40] Iter[58/62]		Loss: 0.1415
2019-10-29 00:43:57,134 Testing Epoch [21/40] Iter[59/62]		Loss: 0.1416
2019-10-29 00:43:57,164 Testing Epoch [21/40] Iter[60/62]		Loss: 0.1410
2019-10-29 00:43:57,194 Testing Epoch [21/40] Iter[61/62]		Loss: 0.1406
2019-10-29 00:43:57,212 Testing Epoch [21/40] Iter[62/62]		Loss: 0.1414
2019-10-29 00:43:57,275 Saving the Model
2019-10-29 00:43:57,719 Training Epoch [22/40] Iter[0/312]		Loss: 0.1229
2019-10-29 00:43:57,840 Training Epoch [22/40] Iter[1/312]		Loss: 0.1065
2019-10-29 00:43:57,961 Training Epoch [22/40] Iter[2/312]		Loss: 0.0977
2019-10-29 00:43:58,082 Training Epoch [22/40] Iter[3/312]		Loss: 0.0953
2019-10-29 00:43:58,206 Training Epoch [22/40] Iter[4/312]		Loss: 0.0875
2019-10-29 00:43:58,326 Training Epoch [22/40] Iter[5/312]		Loss: 0.0913
2019-10-29 00:43:58,447 Training Epoch [22/40] Iter[6/312]		Loss: 0.0960
2019-10-29 00:43:58,568 Training Epoch [22/40] Iter[7/312]		Loss: 0.0988
2019-10-29 00:43:58,690 Training Epoch [22/40] Iter[8/312]		Loss: 0.1022
2019-10-29 00:43:58,811 Training Epoch [22/40] Iter[9/312]		Loss: 0.1056
2019-10-29 00:43:58,933 Training Epoch [22/40] Iter[10/312]		Loss: 0.1057
2019-10-29 00:43:59,054 Training Epoch [22/40] Iter[11/312]		Loss: 0.1062
2019-10-29 00:43:59,176 Training Epoch [22/40] Iter[12/312]		Loss: 0.1037
2019-10-29 00:43:59,297 Training Epoch [22/40] Iter[13/312]		Loss: 0.1025
2019-10-29 00:43:59,419 Training Epoch [22/40] Iter[14/312]		Loss: 0.1013
2019-10-29 00:43:59,540 Training Epoch [22/40] Iter[15/312]		Loss: 0.0986
2019-10-29 00:43:59,662 Training Epoch [22/40] Iter[16/312]		Loss: 0.0977
2019-10-29 00:43:59,783 Training Epoch [22/40] Iter[17/312]		Loss: 0.0981
2019-10-29 00:43:59,905 Training Epoch [22/40] Iter[18/312]		Loss: 0.1030
2019-10-29 00:44:00,027 Training Epoch [22/40] Iter[19/312]		Loss: 0.1046
2019-10-29 00:44:00,148 Training Epoch [22/40] Iter[20/312]		Loss: 0.1032
2019-10-29 00:44:00,269 Training Epoch [22/40] Iter[21/312]		Loss: 0.1022
2019-10-29 00:44:00,390 Training Epoch [22/40] Iter[22/312]		Loss: 0.1029
2019-10-29 00:44:00,512 Training Epoch [22/40] Iter[23/312]		Loss: 0.1065
2019-10-29 00:44:00,634 Training Epoch [22/40] Iter[24/312]		Loss: 0.1053
2019-10-29 00:44:00,755 Training Epoch [22/40] Iter[25/312]		Loss: 0.1082
2019-10-29 00:44:00,877 Training Epoch [22/40] Iter[26/312]		Loss: 0.1094
2019-10-29 00:44:00,998 Training Epoch [22/40] Iter[27/312]		Loss: 0.1105
2019-10-29 00:44:01,119 Training Epoch [22/40] Iter[28/312]		Loss: 0.1097
2019-10-29 00:44:01,240 Training Epoch [22/40] Iter[29/312]		Loss: 0.1097
2019-10-29 00:44:01,362 Training Epoch [22/40] Iter[30/312]		Loss: 0.1077
2019-10-29 00:44:01,483 Training Epoch [22/40] Iter[31/312]		Loss: 0.1071
2019-10-29 00:44:01,605 Training Epoch [22/40] Iter[32/312]		Loss: 0.1070
2019-10-29 00:44:01,727 Training Epoch [22/40] Iter[33/312]		Loss: 0.1080
2019-10-29 00:44:01,849 Training Epoch [22/40] Iter[34/312]		Loss: 0.1075
2019-10-29 00:44:01,971 Training Epoch [22/40] Iter[35/312]		Loss: 0.1074
2019-10-29 00:44:02,093 Training Epoch [22/40] Iter[36/312]		Loss: 0.1064
2019-10-29 00:44:02,215 Training Epoch [22/40] Iter[37/312]		Loss: 0.1059
2019-10-29 00:44:02,336 Training Epoch [22/40] Iter[38/312]		Loss: 0.1056
2019-10-29 00:44:02,458 Training Epoch [22/40] Iter[39/312]		Loss: 0.1043
2019-10-29 00:44:02,580 Training Epoch [22/40] Iter[40/312]		Loss: 0.1038
2019-10-29 00:44:02,702 Training Epoch [22/40] Iter[41/312]		Loss: 0.1031
2019-10-29 00:44:02,823 Training Epoch [22/40] Iter[42/312]		Loss: 0.1030
2019-10-29 00:44:02,945 Training Epoch [22/40] Iter[43/312]		Loss: 0.1033
2019-10-29 00:44:03,066 Training Epoch [22/40] Iter[44/312]		Loss: 0.1048
2019-10-29 00:44:03,188 Training Epoch [22/40] Iter[45/312]		Loss: 0.1042
2019-10-29 00:44:03,309 Training Epoch [22/40] Iter[46/312]		Loss: 0.1040
2019-10-29 00:44:03,436 Training Epoch [22/40] Iter[47/312]		Loss: 0.1035
2019-10-29 00:44:03,558 Training Epoch [22/40] Iter[48/312]		Loss: 0.1033
2019-10-29 00:44:03,679 Training Epoch [22/40] Iter[49/312]		Loss: 0.1033
2019-10-29 00:44:03,801 Training Epoch [22/40] Iter[50/312]		Loss: 0.1035
2019-10-29 00:44:03,922 Training Epoch [22/40] Iter[51/312]		Loss: 0.1034
2019-10-29 00:44:04,043 Training Epoch [22/40] Iter[52/312]		Loss: 0.1035
2019-10-29 00:44:04,164 Training Epoch [22/40] Iter[53/312]		Loss: 0.1041
2019-10-29 00:44:04,286 Training Epoch [22/40] Iter[54/312]		Loss: 0.1035
2019-10-29 00:44:04,407 Training Epoch [22/40] Iter[55/312]		Loss: 0.1037
2019-10-29 00:44:04,529 Training Epoch [22/40] Iter[56/312]		Loss: 0.1037
2019-10-29 00:44:04,651 Training Epoch [22/40] Iter[57/312]		Loss: 0.1033
2019-10-29 00:44:04,773 Training Epoch [22/40] Iter[58/312]		Loss: 0.1037
2019-10-29 00:44:04,894 Training Epoch [22/40] Iter[59/312]		Loss: 0.1040
2019-10-29 00:44:05,016 Training Epoch [22/40] Iter[60/312]		Loss: 0.1050
2019-10-29 00:44:05,138 Training Epoch [22/40] Iter[61/312]		Loss: 0.1050
2019-10-29 00:44:05,259 Training Epoch [22/40] Iter[62/312]		Loss: 0.1049
2019-10-29 00:44:05,381 Training Epoch [22/40] Iter[63/312]		Loss: 0.1048
2019-10-29 00:44:05,502 Training Epoch [22/40] Iter[64/312]		Loss: 0.1047
2019-10-29 00:44:05,624 Training Epoch [22/40] Iter[65/312]		Loss: 0.1042
2019-10-29 00:44:05,746 Training Epoch [22/40] Iter[66/312]		Loss: 0.1046
2019-10-29 00:44:05,868 Training Epoch [22/40] Iter[67/312]		Loss: 0.1045
2019-10-29 00:44:05,990 Training Epoch [22/40] Iter[68/312]		Loss: 0.1042
2019-10-29 00:44:06,112 Training Epoch [22/40] Iter[69/312]		Loss: 0.1042
2019-10-29 00:44:06,234 Training Epoch [22/40] Iter[70/312]		Loss: 0.1038
2019-10-29 00:44:06,355 Training Epoch [22/40] Iter[71/312]		Loss: 0.1049
2019-10-29 00:44:06,478 Training Epoch [22/40] Iter[72/312]		Loss: 0.1045
2019-10-29 00:44:06,600 Training Epoch [22/40] Iter[73/312]		Loss: 0.1043
2019-10-29 00:44:06,721 Training Epoch [22/40] Iter[74/312]		Loss: 0.1041
2019-10-29 00:44:06,842 Training Epoch [22/40] Iter[75/312]		Loss: 0.1040
2019-10-29 00:44:06,964 Training Epoch [22/40] Iter[76/312]		Loss: 0.1055
2019-10-29 00:44:07,086 Training Epoch [22/40] Iter[77/312]		Loss: 0.1050
2019-10-29 00:44:07,207 Training Epoch [22/40] Iter[78/312]		Loss: 0.1054
2019-10-29 00:44:07,329 Training Epoch [22/40] Iter[79/312]		Loss: 0.1057
2019-10-29 00:44:07,451 Training Epoch [22/40] Iter[80/312]		Loss: 0.1055
2019-10-29 00:44:07,573 Training Epoch [22/40] Iter[81/312]		Loss: 0.1049
2019-10-29 00:44:07,694 Training Epoch [22/40] Iter[82/312]		Loss: 0.1056
2019-10-29 00:44:07,815 Training Epoch [22/40] Iter[83/312]		Loss: 0.1060
2019-10-29 00:44:07,936 Training Epoch [22/40] Iter[84/312]		Loss: 0.1062
2019-10-29 00:44:08,058 Training Epoch [22/40] Iter[85/312]		Loss: 0.1064
2019-10-29 00:44:08,180 Training Epoch [22/40] Iter[86/312]		Loss: 0.1060
2019-10-29 00:44:08,302 Training Epoch [22/40] Iter[87/312]		Loss: 0.1059
2019-10-29 00:44:08,423 Training Epoch [22/40] Iter[88/312]		Loss: 0.1056
2019-10-29 00:44:08,545 Training Epoch [22/40] Iter[89/312]		Loss: 0.1051
2019-10-29 00:44:08,666 Training Epoch [22/40] Iter[90/312]		Loss: 0.1050
2019-10-29 00:44:08,787 Training Epoch [22/40] Iter[91/312]		Loss: 0.1048
2019-10-29 00:44:08,908 Training Epoch [22/40] Iter[92/312]		Loss: 0.1047
2019-10-29 00:44:09,029 Training Epoch [22/40] Iter[93/312]		Loss: 0.1049
2019-10-29 00:44:09,150 Training Epoch [22/40] Iter[94/312]		Loss: 0.1051
2019-10-29 00:44:09,271 Training Epoch [22/40] Iter[95/312]		Loss: 0.1059
2019-10-29 00:44:09,392 Training Epoch [22/40] Iter[96/312]		Loss: 0.1058
2019-10-29 00:44:09,514 Training Epoch [22/40] Iter[97/312]		Loss: 0.1057
2019-10-29 00:44:09,636 Training Epoch [22/40] Iter[98/312]		Loss: 0.1058
2019-10-29 00:44:09,757 Training Epoch [22/40] Iter[99/312]		Loss: 0.1061
2019-10-29 00:44:09,879 Training Epoch [22/40] Iter[100/312]		Loss: 0.1059
2019-10-29 00:44:10,001 Training Epoch [22/40] Iter[101/312]		Loss: 0.1064
2019-10-29 00:44:10,122 Training Epoch [22/40] Iter[102/312]		Loss: 0.1064
2019-10-29 00:44:10,244 Training Epoch [22/40] Iter[103/312]		Loss: 0.1061
2019-10-29 00:44:10,366 Training Epoch [22/40] Iter[104/312]		Loss: 0.1057
2019-10-29 00:44:10,488 Training Epoch [22/40] Iter[105/312]		Loss: 0.1054
2019-10-29 00:44:10,609 Training Epoch [22/40] Iter[106/312]		Loss: 0.1051
2019-10-29 00:44:10,731 Training Epoch [22/40] Iter[107/312]		Loss: 0.1049
2019-10-29 00:44:10,853 Training Epoch [22/40] Iter[108/312]		Loss: 0.1048
2019-10-29 00:44:10,974 Training Epoch [22/40] Iter[109/312]		Loss: 0.1043
2019-10-29 00:44:11,095 Training Epoch [22/40] Iter[110/312]		Loss: 0.1043
2019-10-29 00:44:11,217 Training Epoch [22/40] Iter[111/312]		Loss: 0.1041
2019-10-29 00:44:11,338 Training Epoch [22/40] Iter[112/312]		Loss: 0.1039
2019-10-29 00:44:11,460 Training Epoch [22/40] Iter[113/312]		Loss: 0.1039
2019-10-29 00:44:11,581 Training Epoch [22/40] Iter[114/312]		Loss: 0.1038
2019-10-29 00:44:11,703 Training Epoch [22/40] Iter[115/312]		Loss: 0.1040
2019-10-29 00:44:11,824 Training Epoch [22/40] Iter[116/312]		Loss: 0.1039
2019-10-29 00:44:11,945 Training Epoch [22/40] Iter[117/312]		Loss: 0.1038
2019-10-29 00:44:12,066 Training Epoch [22/40] Iter[118/312]		Loss: 0.1037
2019-10-29 00:44:12,188 Training Epoch [22/40] Iter[119/312]		Loss: 0.1039
2019-10-29 00:44:12,310 Training Epoch [22/40] Iter[120/312]		Loss: 0.1040
2019-10-29 00:44:12,431 Training Epoch [22/40] Iter[121/312]		Loss: 0.1040
2019-10-29 00:44:12,552 Training Epoch [22/40] Iter[122/312]		Loss: 0.1041
2019-10-29 00:44:12,674 Training Epoch [22/40] Iter[123/312]		Loss: 0.1040
2019-10-29 00:44:12,795 Training Epoch [22/40] Iter[124/312]		Loss: 0.1045
2019-10-29 00:44:12,917 Training Epoch [22/40] Iter[125/312]		Loss: 0.1042
2019-10-29 00:44:13,039 Training Epoch [22/40] Iter[126/312]		Loss: 0.1039
2019-10-29 00:44:13,161 Training Epoch [22/40] Iter[127/312]		Loss: 0.1036
2019-10-29 00:44:13,282 Training Epoch [22/40] Iter[128/312]		Loss: 0.1033
2019-10-29 00:44:13,404 Training Epoch [22/40] Iter[129/312]		Loss: 0.1035
2019-10-29 00:44:13,525 Training Epoch [22/40] Iter[130/312]		Loss: 0.1035
2019-10-29 00:44:13,647 Training Epoch [22/40] Iter[131/312]		Loss: 0.1038
2019-10-29 00:44:13,768 Training Epoch [22/40] Iter[132/312]		Loss: 0.1037
2019-10-29 00:44:13,890 Training Epoch [22/40] Iter[133/312]		Loss: 0.1039
2019-10-29 00:44:14,011 Training Epoch [22/40] Iter[134/312]		Loss: 0.1038
2019-10-29 00:44:14,132 Training Epoch [22/40] Iter[135/312]		Loss: 0.1040
2019-10-29 00:44:14,254 Training Epoch [22/40] Iter[136/312]		Loss: 0.1040
2019-10-29 00:44:14,376 Training Epoch [22/40] Iter[137/312]		Loss: 0.1039
2019-10-29 00:44:14,497 Training Epoch [22/40] Iter[138/312]		Loss: 0.1039
2019-10-29 00:44:14,618 Training Epoch [22/40] Iter[139/312]		Loss: 0.1041
2019-10-29 00:44:14,740 Training Epoch [22/40] Iter[140/312]		Loss: 0.1040
2019-10-29 00:44:14,861 Training Epoch [22/40] Iter[141/312]		Loss: 0.1044
2019-10-29 00:44:14,983 Training Epoch [22/40] Iter[142/312]		Loss: 0.1046
2019-10-29 00:44:15,104 Training Epoch [22/40] Iter[143/312]		Loss: 0.1044
2019-10-29 00:44:15,225 Training Epoch [22/40] Iter[144/312]		Loss: 0.1042
2019-10-29 00:44:15,347 Training Epoch [22/40] Iter[145/312]		Loss: 0.1042
2019-10-29 00:44:15,469 Training Epoch [22/40] Iter[146/312]		Loss: 0.1040
2019-10-29 00:44:15,591 Training Epoch [22/40] Iter[147/312]		Loss: 0.1039
2019-10-29 00:44:15,713 Training Epoch [22/40] Iter[148/312]		Loss: 0.1038
2019-10-29 00:44:15,835 Training Epoch [22/40] Iter[149/312]		Loss: 0.1036
2019-10-29 00:44:15,956 Training Epoch [22/40] Iter[150/312]		Loss: 0.1036
2019-10-29 00:44:16,077 Training Epoch [22/40] Iter[151/312]		Loss: 0.1041
2019-10-29 00:44:16,199 Training Epoch [22/40] Iter[152/312]		Loss: 0.1042
2019-10-29 00:44:16,320 Training Epoch [22/40] Iter[153/312]		Loss: 0.1045
2019-10-29 00:44:16,442 Training Epoch [22/40] Iter[154/312]		Loss: 0.1044
2019-10-29 00:44:16,564 Training Epoch [22/40] Iter[155/312]		Loss: 0.1045
2019-10-29 00:44:16,685 Training Epoch [22/40] Iter[156/312]		Loss: 0.1042
2019-10-29 00:44:16,807 Training Epoch [22/40] Iter[157/312]		Loss: 0.1044
2019-10-29 00:44:16,928 Training Epoch [22/40] Iter[158/312]		Loss: 0.1042
2019-10-29 00:44:17,049 Training Epoch [22/40] Iter[159/312]		Loss: 0.1045
2019-10-29 00:44:17,170 Training Epoch [22/40] Iter[160/312]		Loss: 0.1044
2019-10-29 00:44:17,292 Training Epoch [22/40] Iter[161/312]		Loss: 0.1042
2019-10-29 00:44:17,413 Training Epoch [22/40] Iter[162/312]		Loss: 0.1039
2019-10-29 00:44:17,534 Training Epoch [22/40] Iter[163/312]		Loss: 0.1039
2019-10-29 00:44:17,655 Training Epoch [22/40] Iter[164/312]		Loss: 0.1037
2019-10-29 00:44:17,776 Training Epoch [22/40] Iter[165/312]		Loss: 0.1037
2019-10-29 00:44:17,898 Training Epoch [22/40] Iter[166/312]		Loss: 0.1035
2019-10-29 00:44:18,019 Training Epoch [22/40] Iter[167/312]		Loss: 0.1035
2019-10-29 00:44:18,140 Training Epoch [22/40] Iter[168/312]		Loss: 0.1036
2019-10-29 00:44:18,261 Training Epoch [22/40] Iter[169/312]		Loss: 0.1037
2019-10-29 00:44:18,383 Training Epoch [22/40] Iter[170/312]		Loss: 0.1035
2019-10-29 00:44:18,504 Training Epoch [22/40] Iter[171/312]		Loss: 0.1035
2019-10-29 00:44:18,625 Training Epoch [22/40] Iter[172/312]		Loss: 0.1036
2019-10-29 00:44:18,747 Training Epoch [22/40] Iter[173/312]		Loss: 0.1034
2019-10-29 00:44:18,868 Training Epoch [22/40] Iter[174/312]		Loss: 0.1032
2019-10-29 00:44:18,990 Training Epoch [22/40] Iter[175/312]		Loss: 0.1032
2019-10-29 00:44:19,112 Training Epoch [22/40] Iter[176/312]		Loss: 0.1033
2019-10-29 00:44:19,234 Training Epoch [22/40] Iter[177/312]		Loss: 0.1034
2019-10-29 00:44:19,356 Training Epoch [22/40] Iter[178/312]		Loss: 0.1033
2019-10-29 00:44:19,478 Training Epoch [22/40] Iter[179/312]		Loss: 0.1034
2019-10-29 00:44:19,599 Training Epoch [22/40] Iter[180/312]		Loss: 0.1038
2019-10-29 00:44:19,721 Training Epoch [22/40] Iter[181/312]		Loss: 0.1039
2019-10-29 00:44:19,842 Training Epoch [22/40] Iter[182/312]		Loss: 0.1040
2019-10-29 00:44:19,963 Training Epoch [22/40] Iter[183/312]		Loss: 0.1040
2019-10-29 00:44:20,085 Training Epoch [22/40] Iter[184/312]		Loss: 0.1040
2019-10-29 00:44:20,207 Training Epoch [22/40] Iter[185/312]		Loss: 0.1039
2019-10-29 00:44:20,329 Training Epoch [22/40] Iter[186/312]		Loss: 0.1038
2019-10-29 00:44:20,451 Training Epoch [22/40] Iter[187/312]		Loss: 0.1037
2019-10-29 00:44:20,572 Training Epoch [22/40] Iter[188/312]		Loss: 0.1038
2019-10-29 00:44:20,694 Training Epoch [22/40] Iter[189/312]		Loss: 0.1038
2019-10-29 00:44:20,816 Training Epoch [22/40] Iter[190/312]		Loss: 0.1036
2019-10-29 00:44:20,937 Training Epoch [22/40] Iter[191/312]		Loss: 0.1034
2019-10-29 00:44:21,058 Training Epoch [22/40] Iter[192/312]		Loss: 0.1035
2019-10-29 00:44:21,180 Training Epoch [22/40] Iter[193/312]		Loss: 0.1036
2019-10-29 00:44:21,301 Training Epoch [22/40] Iter[194/312]		Loss: 0.1035
2019-10-29 00:44:21,423 Training Epoch [22/40] Iter[195/312]		Loss: 0.1035
2019-10-29 00:44:21,545 Training Epoch [22/40] Iter[196/312]		Loss: 0.1035
2019-10-29 00:44:21,666 Training Epoch [22/40] Iter[197/312]		Loss: 0.1035
2019-10-29 00:44:21,787 Training Epoch [22/40] Iter[198/312]		Loss: 0.1034
2019-10-29 00:44:21,908 Training Epoch [22/40] Iter[199/312]		Loss: 0.1035
2019-10-29 00:44:22,030 Training Epoch [22/40] Iter[200/312]		Loss: 0.1036
2019-10-29 00:44:22,151 Training Epoch [22/40] Iter[201/312]		Loss: 0.1036
2019-10-29 00:44:22,273 Training Epoch [22/40] Iter[202/312]		Loss: 0.1035
2019-10-29 00:44:22,395 Training Epoch [22/40] Iter[203/312]		Loss: 0.1036
2019-10-29 00:44:22,516 Training Epoch [22/40] Iter[204/312]		Loss: 0.1038
2019-10-29 00:44:22,638 Training Epoch [22/40] Iter[205/312]		Loss: 0.1038
2019-10-29 00:44:22,759 Training Epoch [22/40] Iter[206/312]		Loss: 0.1038
2019-10-29 00:44:22,881 Training Epoch [22/40] Iter[207/312]		Loss: 0.1039
2019-10-29 00:44:23,002 Training Epoch [22/40] Iter[208/312]		Loss: 0.1038
2019-10-29 00:44:23,124 Training Epoch [22/40] Iter[209/312]		Loss: 0.1038
2019-10-29 00:44:23,245 Training Epoch [22/40] Iter[210/312]		Loss: 0.1038
2019-10-29 00:44:23,367 Training Epoch [22/40] Iter[211/312]		Loss: 0.1040
2019-10-29 00:44:23,489 Training Epoch [22/40] Iter[212/312]		Loss: 0.1041
2019-10-29 00:44:23,611 Training Epoch [22/40] Iter[213/312]		Loss: 0.1039
2019-10-29 00:44:23,733 Training Epoch [22/40] Iter[214/312]		Loss: 0.1040
2019-10-29 00:44:23,854 Training Epoch [22/40] Iter[215/312]		Loss: 0.1039
2019-10-29 00:44:23,976 Training Epoch [22/40] Iter[216/312]		Loss: 0.1040
2019-10-29 00:44:24,097 Training Epoch [22/40] Iter[217/312]		Loss: 0.1042
2019-10-29 00:44:24,219 Training Epoch [22/40] Iter[218/312]		Loss: 0.1047
2019-10-29 00:44:24,340 Training Epoch [22/40] Iter[219/312]		Loss: 0.1046
2019-10-29 00:44:24,462 Training Epoch [22/40] Iter[220/312]		Loss: 0.1046
2019-10-29 00:44:24,583 Training Epoch [22/40] Iter[221/312]		Loss: 0.1045
2019-10-29 00:44:24,705 Training Epoch [22/40] Iter[222/312]		Loss: 0.1045
2019-10-29 00:44:24,826 Training Epoch [22/40] Iter[223/312]		Loss: 0.1046
2019-10-29 00:44:24,948 Training Epoch [22/40] Iter[224/312]		Loss: 0.1045
2019-10-29 00:44:25,069 Training Epoch [22/40] Iter[225/312]		Loss: 0.1044
2019-10-29 00:44:25,190 Training Epoch [22/40] Iter[226/312]		Loss: 0.1045
2019-10-29 00:44:25,312 Training Epoch [22/40] Iter[227/312]		Loss: 0.1045
2019-10-29 00:44:25,433 Training Epoch [22/40] Iter[228/312]		Loss: 0.1044
2019-10-29 00:44:25,555 Training Epoch [22/40] Iter[229/312]		Loss: 0.1044
2019-10-29 00:44:25,676 Training Epoch [22/40] Iter[230/312]		Loss: 0.1046
2019-10-29 00:44:25,798 Training Epoch [22/40] Iter[231/312]		Loss: 0.1047
2019-10-29 00:44:25,920 Training Epoch [22/40] Iter[232/312]		Loss: 0.1049
2019-10-29 00:44:26,042 Training Epoch [22/40] Iter[233/312]		Loss: 0.1050
2019-10-29 00:44:26,163 Training Epoch [22/40] Iter[234/312]		Loss: 0.1050
2019-10-29 00:44:26,284 Training Epoch [22/40] Iter[235/312]		Loss: 0.1052
2019-10-29 00:44:26,405 Training Epoch [22/40] Iter[236/312]		Loss: 0.1052
2019-10-29 00:44:26,527 Training Epoch [22/40] Iter[237/312]		Loss: 0.1051
2019-10-29 00:44:26,648 Training Epoch [22/40] Iter[238/312]		Loss: 0.1052
2019-10-29 00:44:26,768 Training Epoch [22/40] Iter[239/312]		Loss: 0.1052
2019-10-29 00:44:26,889 Training Epoch [22/40] Iter[240/312]		Loss: 0.1051
2019-10-29 00:44:27,010 Training Epoch [22/40] Iter[241/312]		Loss: 0.1051
2019-10-29 00:44:27,131 Training Epoch [22/40] Iter[242/312]		Loss: 0.1052
2019-10-29 00:44:27,253 Training Epoch [22/40] Iter[243/312]		Loss: 0.1051
2019-10-29 00:44:27,374 Training Epoch [22/40] Iter[244/312]		Loss: 0.1049
2019-10-29 00:44:27,495 Training Epoch [22/40] Iter[245/312]		Loss: 0.1048
2019-10-29 00:44:27,616 Training Epoch [22/40] Iter[246/312]		Loss: 0.1047
2019-10-29 00:44:27,738 Training Epoch [22/40] Iter[247/312]		Loss: 0.1047
2019-10-29 00:44:27,860 Training Epoch [22/40] Iter[248/312]		Loss: 0.1047
2019-10-29 00:44:27,982 Training Epoch [22/40] Iter[249/312]		Loss: 0.1046
2019-10-29 00:44:28,103 Training Epoch [22/40] Iter[250/312]		Loss: 0.1048
2019-10-29 00:44:28,225 Training Epoch [22/40] Iter[251/312]		Loss: 0.1048
2019-10-29 00:44:28,346 Training Epoch [22/40] Iter[252/312]		Loss: 0.1046
2019-10-29 00:44:28,468 Training Epoch [22/40] Iter[253/312]		Loss: 0.1045
2019-10-29 00:44:28,589 Training Epoch [22/40] Iter[254/312]		Loss: 0.1045
2019-10-29 00:44:28,711 Training Epoch [22/40] Iter[255/312]		Loss: 0.1045
2019-10-29 00:44:28,833 Training Epoch [22/40] Iter[256/312]		Loss: 0.1045
2019-10-29 00:44:28,955 Training Epoch [22/40] Iter[257/312]		Loss: 0.1047
2019-10-29 00:44:29,077 Training Epoch [22/40] Iter[258/312]		Loss: 0.1051
2019-10-29 00:44:29,198 Training Epoch [22/40] Iter[259/312]		Loss: 0.1052
2019-10-29 00:44:29,321 Training Epoch [22/40] Iter[260/312]		Loss: 0.1052
2019-10-29 00:44:29,442 Training Epoch [22/40] Iter[261/312]		Loss: 0.1051
2019-10-29 00:44:29,564 Training Epoch [22/40] Iter[262/312]		Loss: 0.1050
2019-10-29 00:44:29,685 Training Epoch [22/40] Iter[263/312]		Loss: 0.1049
2019-10-29 00:44:29,806 Training Epoch [22/40] Iter[264/312]		Loss: 0.1050
2019-10-29 00:44:29,928 Training Epoch [22/40] Iter[265/312]		Loss: 0.1050
2019-10-29 00:44:30,049 Training Epoch [22/40] Iter[266/312]		Loss: 0.1049
2019-10-29 00:44:30,170 Training Epoch [22/40] Iter[267/312]		Loss: 0.1051
2019-10-29 00:44:30,291 Training Epoch [22/40] Iter[268/312]		Loss: 0.1050
2019-10-29 00:44:30,413 Training Epoch [22/40] Iter[269/312]		Loss: 0.1049
2019-10-29 00:44:30,534 Training Epoch [22/40] Iter[270/312]		Loss: 0.1048
2019-10-29 00:44:30,656 Training Epoch [22/40] Iter[271/312]		Loss: 0.1049
2019-10-29 00:44:30,778 Training Epoch [22/40] Iter[272/312]		Loss: 0.1048
2019-10-29 00:44:30,899 Training Epoch [22/40] Iter[273/312]		Loss: 0.1048
2019-10-29 00:44:31,022 Training Epoch [22/40] Iter[274/312]		Loss: 0.1048
2019-10-29 00:44:31,144 Training Epoch [22/40] Iter[275/312]		Loss: 0.1047
2019-10-29 00:44:31,265 Training Epoch [22/40] Iter[276/312]		Loss: 0.1047
2019-10-29 00:44:31,387 Training Epoch [22/40] Iter[277/312]		Loss: 0.1047
2019-10-29 00:44:31,509 Training Epoch [22/40] Iter[278/312]		Loss: 0.1045
2019-10-29 00:44:31,631 Training Epoch [22/40] Iter[279/312]		Loss: 0.1046
2019-10-29 00:44:31,753 Training Epoch [22/40] Iter[280/312]		Loss: 0.1045
2019-10-29 00:44:31,874 Training Epoch [22/40] Iter[281/312]		Loss: 0.1048
2019-10-29 00:44:31,996 Training Epoch [22/40] Iter[282/312]		Loss: 0.1048
2019-10-29 00:44:32,117 Training Epoch [22/40] Iter[283/312]		Loss: 0.1047
2019-10-29 00:44:32,240 Training Epoch [22/40] Iter[284/312]		Loss: 0.1047
2019-10-29 00:44:32,362 Training Epoch [22/40] Iter[285/312]		Loss: 0.1048
2019-10-29 00:44:32,483 Training Epoch [22/40] Iter[286/312]		Loss: 0.1048
2019-10-29 00:44:32,605 Training Epoch [22/40] Iter[287/312]		Loss: 0.1048
2019-10-29 00:44:32,726 Training Epoch [22/40] Iter[288/312]		Loss: 0.1049
2019-10-29 00:44:32,848 Training Epoch [22/40] Iter[289/312]		Loss: 0.1049
2019-10-29 00:44:32,970 Training Epoch [22/40] Iter[290/312]		Loss: 0.1050
2019-10-29 00:44:33,091 Training Epoch [22/40] Iter[291/312]		Loss: 0.1051
2019-10-29 00:44:33,212 Training Epoch [22/40] Iter[292/312]		Loss: 0.1051
2019-10-29 00:44:33,334 Training Epoch [22/40] Iter[293/312]		Loss: 0.1050
2019-10-29 00:44:33,455 Training Epoch [22/40] Iter[294/312]		Loss: 0.1051
2019-10-29 00:44:33,577 Training Epoch [22/40] Iter[295/312]		Loss: 0.1051
2019-10-29 00:44:33,699 Training Epoch [22/40] Iter[296/312]		Loss: 0.1050
2019-10-29 00:44:33,821 Training Epoch [22/40] Iter[297/312]		Loss: 0.1052
2019-10-29 00:44:33,943 Training Epoch [22/40] Iter[298/312]		Loss: 0.1054
2019-10-29 00:44:34,064 Training Epoch [22/40] Iter[299/312]		Loss: 0.1053
2019-10-29 00:44:34,185 Training Epoch [22/40] Iter[300/312]		Loss: 0.1054
2019-10-29 00:44:34,307 Training Epoch [22/40] Iter[301/312]		Loss: 0.1054
2019-10-29 00:44:34,429 Training Epoch [22/40] Iter[302/312]		Loss: 0.1055
2019-10-29 00:44:34,550 Training Epoch [22/40] Iter[303/312]		Loss: 0.1055
2019-10-29 00:44:34,672 Training Epoch [22/40] Iter[304/312]		Loss: 0.1054
2019-10-29 00:44:34,793 Training Epoch [22/40] Iter[305/312]		Loss: 0.1054
2019-10-29 00:44:34,914 Training Epoch [22/40] Iter[306/312]		Loss: 0.1054
2019-10-29 00:44:35,034 Training Epoch [22/40] Iter[307/312]		Loss: 0.1053
2019-10-29 00:44:35,154 Training Epoch [22/40] Iter[308/312]		Loss: 0.1052
2019-10-29 00:44:35,275 Training Epoch [22/40] Iter[309/312]		Loss: 0.1052
2019-10-29 00:44:35,395 Training Epoch [22/40] Iter[310/312]		Loss: 0.1052
2019-10-29 00:44:35,516 Training Epoch [22/40] Iter[311/312]		Loss: 0.1050
2019-10-29 00:44:35,576 Training Epoch [22/40] Iter[312/312]		Loss: 0.1050
2019-10-29 00:44:35,910 Testing Epoch [22/40] Iter[0/62]		Loss: 0.0901
2019-10-29 00:44:35,993 Testing Epoch [22/40] Iter[1/62]		Loss: 0.1232
2019-10-29 00:44:36,034 Testing Epoch [22/40] Iter[2/62]		Loss: 0.1175
2019-10-29 00:44:36,066 Testing Epoch [22/40] Iter[3/62]		Loss: 0.1164
2019-10-29 00:44:36,098 Testing Epoch [22/40] Iter[4/62]		Loss: 0.1122
2019-10-29 00:44:36,131 Testing Epoch [22/40] Iter[5/62]		Loss: 0.1099
2019-10-29 00:44:36,162 Testing Epoch [22/40] Iter[6/62]		Loss: 0.1109
2019-10-29 00:44:36,194 Testing Epoch [22/40] Iter[7/62]		Loss: 0.1171
2019-10-29 00:44:36,224 Testing Epoch [22/40] Iter[8/62]		Loss: 0.1234
2019-10-29 00:44:36,258 Testing Epoch [22/40] Iter[9/62]		Loss: 0.1203
2019-10-29 00:44:36,289 Testing Epoch [22/40] Iter[10/62]		Loss: 0.1186
2019-10-29 00:44:36,320 Testing Epoch [22/40] Iter[11/62]		Loss: 0.1240
2019-10-29 00:44:36,358 Testing Epoch [22/40] Iter[12/62]		Loss: 0.1250
2019-10-29 00:44:36,389 Testing Epoch [22/40] Iter[13/62]		Loss: 0.1272
2019-10-29 00:44:36,421 Testing Epoch [22/40] Iter[14/62]		Loss: 0.1396
2019-10-29 00:44:36,452 Testing Epoch [22/40] Iter[15/62]		Loss: 0.1415
2019-10-29 00:44:36,484 Testing Epoch [22/40] Iter[16/62]		Loss: 0.1396
2019-10-29 00:44:36,515 Testing Epoch [22/40] Iter[17/62]		Loss: 0.1389
2019-10-29 00:44:36,546 Testing Epoch [22/40] Iter[18/62]		Loss: 0.1355
2019-10-29 00:44:36,577 Testing Epoch [22/40] Iter[19/62]		Loss: 0.1334
2019-10-29 00:44:36,608 Testing Epoch [22/40] Iter[20/62]		Loss: 0.1349
2019-10-29 00:44:36,639 Testing Epoch [22/40] Iter[21/62]		Loss: 0.1331
2019-10-29 00:44:36,669 Testing Epoch [22/40] Iter[22/62]		Loss: 0.1323
2019-10-29 00:44:36,700 Testing Epoch [22/40] Iter[23/62]		Loss: 0.1321
2019-10-29 00:44:36,731 Testing Epoch [22/40] Iter[24/62]		Loss: 0.1339
2019-10-29 00:44:36,762 Testing Epoch [22/40] Iter[25/62]		Loss: 0.1331
2019-10-29 00:44:36,793 Testing Epoch [22/40] Iter[26/62]		Loss: 0.1320
2019-10-29 00:44:36,824 Testing Epoch [22/40] Iter[27/62]		Loss: 0.1365
2019-10-29 00:44:36,855 Testing Epoch [22/40] Iter[28/62]		Loss: 0.1384
2019-10-29 00:44:36,886 Testing Epoch [22/40] Iter[29/62]		Loss: 0.1383
2019-10-29 00:44:36,917 Testing Epoch [22/40] Iter[30/62]		Loss: 0.1399
2019-10-29 00:44:36,948 Testing Epoch [22/40] Iter[31/62]		Loss: 0.1392
2019-10-29 00:44:36,979 Testing Epoch [22/40] Iter[32/62]		Loss: 0.1409
2019-10-29 00:44:37,010 Testing Epoch [22/40] Iter[33/62]		Loss: 0.1390
2019-10-29 00:44:37,041 Testing Epoch [22/40] Iter[34/62]		Loss: 0.1405
2019-10-29 00:44:37,071 Testing Epoch [22/40] Iter[35/62]		Loss: 0.1408
2019-10-29 00:44:37,102 Testing Epoch [22/40] Iter[36/62]		Loss: 0.1392
2019-10-29 00:44:37,133 Testing Epoch [22/40] Iter[37/62]		Loss: 0.1389
2019-10-29 00:44:37,164 Testing Epoch [22/40] Iter[38/62]		Loss: 0.1390
2019-10-29 00:44:37,195 Testing Epoch [22/40] Iter[39/62]		Loss: 0.1393
2019-10-29 00:44:37,226 Testing Epoch [22/40] Iter[40/62]		Loss: 0.1398
2019-10-29 00:44:37,257 Testing Epoch [22/40] Iter[41/62]		Loss: 0.1400
2019-10-29 00:44:37,288 Testing Epoch [22/40] Iter[42/62]		Loss: 0.1386
2019-10-29 00:44:37,319 Testing Epoch [22/40] Iter[43/62]		Loss: 0.1382
2019-10-29 00:44:37,349 Testing Epoch [22/40] Iter[44/62]		Loss: 0.1370
2019-10-29 00:44:37,380 Testing Epoch [22/40] Iter[45/62]		Loss: 0.1380
2019-10-29 00:44:37,411 Testing Epoch [22/40] Iter[46/62]		Loss: 0.1381
2019-10-29 00:44:37,442 Testing Epoch [22/40] Iter[47/62]		Loss: 0.1430
2019-10-29 00:44:37,473 Testing Epoch [22/40] Iter[48/62]		Loss: 0.1420
2019-10-29 00:44:37,504 Testing Epoch [22/40] Iter[49/62]		Loss: 0.1434
2019-10-29 00:44:37,535 Testing Epoch [22/40] Iter[50/62]		Loss: 0.1431
2019-10-29 00:44:37,566 Testing Epoch [22/40] Iter[51/62]		Loss: 0.1431
2019-10-29 00:44:37,597 Testing Epoch [22/40] Iter[52/62]		Loss: 0.1419
2019-10-29 00:44:37,628 Testing Epoch [22/40] Iter[53/62]		Loss: 0.1417
2019-10-29 00:44:37,659 Testing Epoch [22/40] Iter[54/62]		Loss: 0.1410
2019-10-29 00:44:37,689 Testing Epoch [22/40] Iter[55/62]		Loss: 0.1411
2019-10-29 00:44:37,719 Testing Epoch [22/40] Iter[56/62]		Loss: 0.1410
2019-10-29 00:44:37,750 Testing Epoch [22/40] Iter[57/62]		Loss: 0.1408
2019-10-29 00:44:37,780 Testing Epoch [22/40] Iter[58/62]		Loss: 0.1403
2019-10-29 00:44:37,810 Testing Epoch [22/40] Iter[59/62]		Loss: 0.1404
2019-10-29 00:44:37,841 Testing Epoch [22/40] Iter[60/62]		Loss: 0.1398
2019-10-29 00:44:37,871 Testing Epoch [22/40] Iter[61/62]		Loss: 0.1394
2019-10-29 00:44:37,888 Testing Epoch [22/40] Iter[62/62]		Loss: 0.1401
2019-10-29 00:44:37,953 Saving the Model
2019-10-29 00:44:38,392 Training Epoch [23/40] Iter[0/312]		Loss: 0.1067
2019-10-29 00:44:38,512 Training Epoch [23/40] Iter[1/312]		Loss: 0.1409
2019-10-29 00:44:38,632 Training Epoch [23/40] Iter[2/312]		Loss: 0.1126
2019-10-29 00:44:38,752 Training Epoch [23/40] Iter[3/312]		Loss: 0.1086
2019-10-29 00:44:38,876 Training Epoch [23/40] Iter[4/312]		Loss: 0.1030
2019-10-29 00:44:38,996 Training Epoch [23/40] Iter[5/312]		Loss: 0.1008
2019-10-29 00:44:39,116 Training Epoch [23/40] Iter[6/312]		Loss: 0.0959
2019-10-29 00:44:39,238 Training Epoch [23/40] Iter[7/312]		Loss: 0.0956
2019-10-29 00:44:39,359 Training Epoch [23/40] Iter[8/312]		Loss: 0.1002
2019-10-29 00:44:39,481 Training Epoch [23/40] Iter[9/312]		Loss: 0.0986
2019-10-29 00:44:39,603 Training Epoch [23/40] Iter[10/312]		Loss: 0.0968
2019-10-29 00:44:39,724 Training Epoch [23/40] Iter[11/312]		Loss: 0.0957
2019-10-29 00:44:39,846 Training Epoch [23/40] Iter[12/312]		Loss: 0.0983
2019-10-29 00:44:39,967 Training Epoch [23/40] Iter[13/312]		Loss: 0.0991
2019-10-29 00:44:40,089 Training Epoch [23/40] Iter[14/312]		Loss: 0.1003
2019-10-29 00:44:40,210 Training Epoch [23/40] Iter[15/312]		Loss: 0.1022
2019-10-29 00:44:40,332 Training Epoch [23/40] Iter[16/312]		Loss: 0.1003
2019-10-29 00:44:40,453 Training Epoch [23/40] Iter[17/312]		Loss: 0.1002
2019-10-29 00:44:40,575 Training Epoch [23/40] Iter[18/312]		Loss: 0.0996
2019-10-29 00:44:40,697 Training Epoch [23/40] Iter[19/312]		Loss: 0.0983
2019-10-29 00:44:40,818 Training Epoch [23/40] Iter[20/312]		Loss: 0.1020
2019-10-29 00:44:40,940 Training Epoch [23/40] Iter[21/312]		Loss: 0.1033
2019-10-29 00:44:41,061 Training Epoch [23/40] Iter[22/312]		Loss: 0.1041
2019-10-29 00:44:41,182 Training Epoch [23/40] Iter[23/312]		Loss: 0.1037
2019-10-29 00:44:41,304 Training Epoch [23/40] Iter[24/312]		Loss: 0.1032
2019-10-29 00:44:41,425 Training Epoch [23/40] Iter[25/312]		Loss: 0.1040
2019-10-29 00:44:41,547 Training Epoch [23/40] Iter[26/312]		Loss: 0.1039
2019-10-29 00:44:41,668 Training Epoch [23/40] Iter[27/312]		Loss: 0.1042
2019-10-29 00:44:41,789 Training Epoch [23/40] Iter[28/312]		Loss: 0.1047
2019-10-29 00:44:41,911 Training Epoch [23/40] Iter[29/312]		Loss: 0.1045
2019-10-29 00:44:42,032 Training Epoch [23/40] Iter[30/312]		Loss: 0.1037
2019-10-29 00:44:42,153 Training Epoch [23/40] Iter[31/312]		Loss: 0.1041
2019-10-29 00:44:42,275 Training Epoch [23/40] Iter[32/312]		Loss: 0.1031
2019-10-29 00:44:42,397 Training Epoch [23/40] Iter[33/312]		Loss: 0.1024
2019-10-29 00:44:42,518 Training Epoch [23/40] Iter[34/312]		Loss: 0.1021
2019-10-29 00:44:42,639 Training Epoch [23/40] Iter[35/312]		Loss: 0.1030
2019-10-29 00:44:42,761 Training Epoch [23/40] Iter[36/312]		Loss: 0.1022
2019-10-29 00:44:42,882 Training Epoch [23/40] Iter[37/312]		Loss: 0.1025
2019-10-29 00:44:43,003 Training Epoch [23/40] Iter[38/312]		Loss: 0.1020
2019-10-29 00:44:43,125 Training Epoch [23/40] Iter[39/312]		Loss: 0.1013
2019-10-29 00:44:43,246 Training Epoch [23/40] Iter[40/312]		Loss: 0.1007
2019-10-29 00:44:43,367 Training Epoch [23/40] Iter[41/312]		Loss: 0.1011
2019-10-29 00:44:43,489 Training Epoch [23/40] Iter[42/312]		Loss: 0.1013
2019-10-29 00:44:43,610 Training Epoch [23/40] Iter[43/312]		Loss: 0.1015
2019-10-29 00:44:43,731 Training Epoch [23/40] Iter[44/312]		Loss: 0.1015
2019-10-29 00:44:43,852 Training Epoch [23/40] Iter[45/312]		Loss: 0.1016
2019-10-29 00:44:43,973 Training Epoch [23/40] Iter[46/312]		Loss: 0.1011
2019-10-29 00:44:44,096 Training Epoch [23/40] Iter[47/312]		Loss: 0.1016
2019-10-29 00:44:44,217 Training Epoch [23/40] Iter[48/312]		Loss: 0.1015
2019-10-29 00:44:44,338 Training Epoch [23/40] Iter[49/312]		Loss: 0.1016
2019-10-29 00:44:44,460 Training Epoch [23/40] Iter[50/312]		Loss: 0.1021
2019-10-29 00:44:44,581 Training Epoch [23/40] Iter[51/312]		Loss: 0.1027
2019-10-29 00:44:44,703 Training Epoch [23/40] Iter[52/312]		Loss: 0.1031
2019-10-29 00:44:44,824 Training Epoch [23/40] Iter[53/312]		Loss: 0.1032
2019-10-29 00:44:44,946 Training Epoch [23/40] Iter[54/312]		Loss: 0.1033
2019-10-29 00:44:45,067 Training Epoch [23/40] Iter[55/312]		Loss: 0.1037
2019-10-29 00:44:45,189 Training Epoch [23/40] Iter[56/312]		Loss: 0.1034
2019-10-29 00:44:45,310 Training Epoch [23/40] Iter[57/312]		Loss: 0.1039
2019-10-29 00:44:45,432 Training Epoch [23/40] Iter[58/312]		Loss: 0.1050
2019-10-29 00:44:45,553 Training Epoch [23/40] Iter[59/312]		Loss: 0.1055
2019-10-29 00:44:45,675 Training Epoch [23/40] Iter[60/312]		Loss: 0.1053
2019-10-29 00:44:45,797 Training Epoch [23/40] Iter[61/312]		Loss: 0.1052
2019-10-29 00:44:45,919 Training Epoch [23/40] Iter[62/312]		Loss: 0.1052
2019-10-29 00:44:46,041 Training Epoch [23/40] Iter[63/312]		Loss: 0.1054
2019-10-29 00:44:46,162 Training Epoch [23/40] Iter[64/312]		Loss: 0.1049
2019-10-29 00:44:46,283 Training Epoch [23/40] Iter[65/312]		Loss: 0.1042
2019-10-29 00:44:46,405 Training Epoch [23/40] Iter[66/312]		Loss: 0.1038
2019-10-29 00:44:46,528 Training Epoch [23/40] Iter[67/312]		Loss: 0.1041
2019-10-29 00:44:46,649 Training Epoch [23/40] Iter[68/312]		Loss: 0.1036
2019-10-29 00:44:46,770 Training Epoch [23/40] Iter[69/312]		Loss: 0.1040
2019-10-29 00:44:46,892 Training Epoch [23/40] Iter[70/312]		Loss: 0.1039
2019-10-29 00:44:47,013 Training Epoch [23/40] Iter[71/312]		Loss: 0.1042
2019-10-29 00:44:47,134 Training Epoch [23/40] Iter[72/312]		Loss: 0.1040
2019-10-29 00:44:47,255 Training Epoch [23/40] Iter[73/312]		Loss: 0.1037
2019-10-29 00:44:47,377 Training Epoch [23/40] Iter[74/312]		Loss: 0.1034
2019-10-29 00:44:47,498 Training Epoch [23/40] Iter[75/312]		Loss: 0.1032
2019-10-29 00:44:47,620 Training Epoch [23/40] Iter[76/312]		Loss: 0.1029
2019-10-29 00:44:47,742 Training Epoch [23/40] Iter[77/312]		Loss: 0.1034
2019-10-29 00:44:47,864 Training Epoch [23/40] Iter[78/312]		Loss: 0.1041
2019-10-29 00:44:47,985 Training Epoch [23/40] Iter[79/312]		Loss: 0.1038
2019-10-29 00:44:48,106 Training Epoch [23/40] Iter[80/312]		Loss: 0.1035
2019-10-29 00:44:48,228 Training Epoch [23/40] Iter[81/312]		Loss: 0.1033
2019-10-29 00:44:48,349 Training Epoch [23/40] Iter[82/312]		Loss: 0.1034
2019-10-29 00:44:48,472 Training Epoch [23/40] Iter[83/312]		Loss: 0.1032
2019-10-29 00:44:48,593 Training Epoch [23/40] Iter[84/312]		Loss: 0.1038
2019-10-29 00:44:48,714 Training Epoch [23/40] Iter[85/312]		Loss: 0.1035
2019-10-29 00:44:48,835 Training Epoch [23/40] Iter[86/312]		Loss: 0.1038
2019-10-29 00:44:48,956 Training Epoch [23/40] Iter[87/312]		Loss: 0.1042
2019-10-29 00:44:49,078 Training Epoch [23/40] Iter[88/312]		Loss: 0.1039
2019-10-29 00:44:49,200 Training Epoch [23/40] Iter[89/312]		Loss: 0.1043
2019-10-29 00:44:49,322 Training Epoch [23/40] Iter[90/312]		Loss: 0.1046
2019-10-29 00:44:49,443 Training Epoch [23/40] Iter[91/312]		Loss: 0.1048
2019-10-29 00:44:49,564 Training Epoch [23/40] Iter[92/312]		Loss: 0.1045
2019-10-29 00:44:49,686 Training Epoch [23/40] Iter[93/312]		Loss: 0.1045
2019-10-29 00:44:49,807 Training Epoch [23/40] Iter[94/312]		Loss: 0.1044
2019-10-29 00:44:49,928 Training Epoch [23/40] Iter[95/312]		Loss: 0.1047
2019-10-29 00:44:50,050 Training Epoch [23/40] Iter[96/312]		Loss: 0.1047
2019-10-29 00:44:50,171 Training Epoch [23/40] Iter[97/312]		Loss: 0.1046
2019-10-29 00:44:50,293 Training Epoch [23/40] Iter[98/312]		Loss: 0.1050
2019-10-29 00:44:50,414 Training Epoch [23/40] Iter[99/312]		Loss: 0.1048
2019-10-29 00:44:50,535 Training Epoch [23/40] Iter[100/312]		Loss: 0.1047
2019-10-29 00:44:50,657 Training Epoch [23/40] Iter[101/312]		Loss: 0.1044
2019-10-29 00:44:50,778 Training Epoch [23/40] Iter[102/312]		Loss: 0.1045
2019-10-29 00:44:50,899 Training Epoch [23/40] Iter[103/312]		Loss: 0.1042
2019-10-29 00:44:51,021 Training Epoch [23/40] Iter[104/312]		Loss: 0.1040
2019-10-29 00:44:51,142 Training Epoch [23/40] Iter[105/312]		Loss: 0.1036
2019-10-29 00:44:51,264 Training Epoch [23/40] Iter[106/312]		Loss: 0.1035
2019-10-29 00:44:51,385 Training Epoch [23/40] Iter[107/312]		Loss: 0.1034
2019-10-29 00:44:51,507 Training Epoch [23/40] Iter[108/312]		Loss: 0.1036
2019-10-29 00:44:51,628 Training Epoch [23/40] Iter[109/312]		Loss: 0.1033
2019-10-29 00:44:51,749 Training Epoch [23/40] Iter[110/312]		Loss: 0.1033
2019-10-29 00:44:51,870 Training Epoch [23/40] Iter[111/312]		Loss: 0.1038
2019-10-29 00:44:51,991 Training Epoch [23/40] Iter[112/312]		Loss: 0.1038
2019-10-29 00:44:52,113 Training Epoch [23/40] Iter[113/312]		Loss: 0.1038
2019-10-29 00:44:52,234 Training Epoch [23/40] Iter[114/312]		Loss: 0.1040
2019-10-29 00:44:52,355 Training Epoch [23/40] Iter[115/312]		Loss: 0.1038
2019-10-29 00:44:52,476 Training Epoch [23/40] Iter[116/312]		Loss: 0.1036
2019-10-29 00:44:52,597 Training Epoch [23/40] Iter[117/312]		Loss: 0.1034
2019-10-29 00:44:52,719 Training Epoch [23/40] Iter[118/312]		Loss: 0.1033
2019-10-29 00:44:52,840 Training Epoch [23/40] Iter[119/312]		Loss: 0.1032
2019-10-29 00:44:52,962 Training Epoch [23/40] Iter[120/312]		Loss: 0.1029
2019-10-29 00:44:53,083 Training Epoch [23/40] Iter[121/312]		Loss: 0.1030
2019-10-29 00:44:53,205 Training Epoch [23/40] Iter[122/312]		Loss: 0.1028
2019-10-29 00:44:53,326 Training Epoch [23/40] Iter[123/312]		Loss: 0.1030
2019-10-29 00:44:53,448 Training Epoch [23/40] Iter[124/312]		Loss: 0.1030
2019-10-29 00:44:53,569 Training Epoch [23/40] Iter[125/312]		Loss: 0.1029
2019-10-29 00:44:53,691 Training Epoch [23/40] Iter[126/312]		Loss: 0.1028
2019-10-29 00:44:53,813 Training Epoch [23/40] Iter[127/312]		Loss: 0.1026
2019-10-29 00:44:53,935 Training Epoch [23/40] Iter[128/312]		Loss: 0.1024
2019-10-29 00:44:54,056 Training Epoch [23/40] Iter[129/312]		Loss: 0.1025
2019-10-29 00:44:54,178 Training Epoch [23/40] Iter[130/312]		Loss: 0.1025
2019-10-29 00:44:54,301 Training Epoch [23/40] Iter[131/312]		Loss: 0.1029
2019-10-29 00:44:54,423 Training Epoch [23/40] Iter[132/312]		Loss: 0.1030
2019-10-29 00:44:54,544 Training Epoch [23/40] Iter[133/312]		Loss: 0.1028
2019-10-29 00:44:54,666 Training Epoch [23/40] Iter[134/312]		Loss: 0.1031
2019-10-29 00:44:54,787 Training Epoch [23/40] Iter[135/312]		Loss: 0.1030
2019-10-29 00:44:54,909 Training Epoch [23/40] Iter[136/312]		Loss: 0.1026
2019-10-29 00:44:55,030 Training Epoch [23/40] Iter[137/312]		Loss: 0.1028
2019-10-29 00:44:55,152 Training Epoch [23/40] Iter[138/312]		Loss: 0.1030
2019-10-29 00:44:55,273 Training Epoch [23/40] Iter[139/312]		Loss: 0.1032
2019-10-29 00:44:55,395 Training Epoch [23/40] Iter[140/312]		Loss: 0.1031
2019-10-29 00:44:55,517 Training Epoch [23/40] Iter[141/312]		Loss: 0.1029
2019-10-29 00:44:55,638 Training Epoch [23/40] Iter[142/312]		Loss: 0.1029
2019-10-29 00:44:55,760 Training Epoch [23/40] Iter[143/312]		Loss: 0.1029
2019-10-29 00:44:55,881 Training Epoch [23/40] Iter[144/312]		Loss: 0.1030
2019-10-29 00:44:56,002 Training Epoch [23/40] Iter[145/312]		Loss: 0.1028
2019-10-29 00:44:56,123 Training Epoch [23/40] Iter[146/312]		Loss: 0.1027
2019-10-29 00:44:56,245 Training Epoch [23/40] Iter[147/312]		Loss: 0.1028
2019-10-29 00:44:56,367 Training Epoch [23/40] Iter[148/312]		Loss: 0.1027
2019-10-29 00:44:56,489 Training Epoch [23/40] Iter[149/312]		Loss: 0.1029
2019-10-29 00:44:56,610 Training Epoch [23/40] Iter[150/312]		Loss: 0.1032
2019-10-29 00:44:56,731 Training Epoch [23/40] Iter[151/312]		Loss: 0.1035
2019-10-29 00:44:56,853 Training Epoch [23/40] Iter[152/312]		Loss: 0.1036
2019-10-29 00:44:56,974 Training Epoch [23/40] Iter[153/312]		Loss: 0.1035
2019-10-29 00:44:57,096 Training Epoch [23/40] Iter[154/312]		Loss: 0.1038
2019-10-29 00:44:57,217 Training Epoch [23/40] Iter[155/312]		Loss: 0.1035
2019-10-29 00:44:57,339 Training Epoch [23/40] Iter[156/312]		Loss: 0.1032
2019-10-29 00:44:57,461 Training Epoch [23/40] Iter[157/312]		Loss: 0.1033
2019-10-29 00:44:57,582 Training Epoch [23/40] Iter[158/312]		Loss: 0.1037
2019-10-29 00:44:57,704 Training Epoch [23/40] Iter[159/312]		Loss: 0.1035
2019-10-29 00:44:57,825 Training Epoch [23/40] Iter[160/312]		Loss: 0.1035
2019-10-29 00:44:57,947 Training Epoch [23/40] Iter[161/312]		Loss: 0.1032
2019-10-29 00:44:58,068 Training Epoch [23/40] Iter[162/312]		Loss: 0.1032
2019-10-29 00:44:58,189 Training Epoch [23/40] Iter[163/312]		Loss: 0.1034
2019-10-29 00:44:58,311 Training Epoch [23/40] Iter[164/312]		Loss: 0.1032
2019-10-29 00:44:58,433 Training Epoch [23/40] Iter[165/312]		Loss: 0.1034
2019-10-29 00:44:58,554 Training Epoch [23/40] Iter[166/312]		Loss: 0.1037
2019-10-29 00:44:58,676 Training Epoch [23/40] Iter[167/312]		Loss: 0.1037
2019-10-29 00:44:58,797 Training Epoch [23/40] Iter[168/312]		Loss: 0.1037
2019-10-29 00:44:58,918 Training Epoch [23/40] Iter[169/312]		Loss: 0.1038
2019-10-29 00:44:59,039 Training Epoch [23/40] Iter[170/312]		Loss: 0.1037
2019-10-29 00:44:59,161 Training Epoch [23/40] Iter[171/312]		Loss: 0.1035
2019-10-29 00:44:59,282 Training Epoch [23/40] Iter[172/312]		Loss: 0.1034
2019-10-29 00:44:59,403 Training Epoch [23/40] Iter[173/312]		Loss: 0.1038
2019-10-29 00:44:59,524 Training Epoch [23/40] Iter[174/312]		Loss: 0.1037
2019-10-29 00:44:59,646 Training Epoch [23/40] Iter[175/312]		Loss: 0.1042
2019-10-29 00:44:59,768 Training Epoch [23/40] Iter[176/312]		Loss: 0.1042
2019-10-29 00:44:59,889 Training Epoch [23/40] Iter[177/312]		Loss: 0.1041
2019-10-29 00:45:00,010 Training Epoch [23/40] Iter[178/312]		Loss: 0.1040
2019-10-29 00:45:00,132 Training Epoch [23/40] Iter[179/312]		Loss: 0.1043
2019-10-29 00:45:00,253 Training Epoch [23/40] Iter[180/312]		Loss: 0.1043
2019-10-29 00:45:00,374 Training Epoch [23/40] Iter[181/312]		Loss: 0.1043
2019-10-29 00:45:00,495 Training Epoch [23/40] Iter[182/312]		Loss: 0.1042
2019-10-29 00:45:00,616 Training Epoch [23/40] Iter[183/312]		Loss: 0.1044
2019-10-29 00:45:00,737 Training Epoch [23/40] Iter[184/312]		Loss: 0.1042
2019-10-29 00:45:00,859 Training Epoch [23/40] Iter[185/312]		Loss: 0.1042
2019-10-29 00:45:00,980 Training Epoch [23/40] Iter[186/312]		Loss: 0.1042
2019-10-29 00:45:01,101 Training Epoch [23/40] Iter[187/312]		Loss: 0.1042
2019-10-29 00:45:01,223 Training Epoch [23/40] Iter[188/312]		Loss: 0.1044
2019-10-29 00:45:01,345 Training Epoch [23/40] Iter[189/312]		Loss: 0.1043
2019-10-29 00:45:01,466 Training Epoch [23/40] Iter[190/312]		Loss: 0.1040
2019-10-29 00:45:01,588 Training Epoch [23/40] Iter[191/312]		Loss: 0.1040
2019-10-29 00:45:01,710 Training Epoch [23/40] Iter[192/312]		Loss: 0.1041
2019-10-29 00:45:01,831 Training Epoch [23/40] Iter[193/312]		Loss: 0.1045
2019-10-29 00:45:01,953 Training Epoch [23/40] Iter[194/312]		Loss: 0.1045
2019-10-29 00:45:02,075 Training Epoch [23/40] Iter[195/312]		Loss: 0.1045
2019-10-29 00:45:02,197 Training Epoch [23/40] Iter[196/312]		Loss: 0.1043
2019-10-29 00:45:02,318 Training Epoch [23/40] Iter[197/312]		Loss: 0.1043
2019-10-29 00:45:02,441 Training Epoch [23/40] Iter[198/312]		Loss: 0.1042
2019-10-29 00:45:02,562 Training Epoch [23/40] Iter[199/312]		Loss: 0.1041
2019-10-29 00:45:02,684 Training Epoch [23/40] Iter[200/312]		Loss: 0.1040
2019-10-29 00:45:02,806 Training Epoch [23/40] Iter[201/312]		Loss: 0.1039
2019-10-29 00:45:02,927 Training Epoch [23/40] Iter[202/312]		Loss: 0.1039
2019-10-29 00:45:03,048 Training Epoch [23/40] Iter[203/312]		Loss: 0.1041
2019-10-29 00:45:03,170 Training Epoch [23/40] Iter[204/312]		Loss: 0.1043
2019-10-29 00:45:03,291 Training Epoch [23/40] Iter[205/312]		Loss: 0.1043
2019-10-29 00:45:03,412 Training Epoch [23/40] Iter[206/312]		Loss: 0.1042
2019-10-29 00:45:03,534 Training Epoch [23/40] Iter[207/312]		Loss: 0.1043
2019-10-29 00:45:03,655 Training Epoch [23/40] Iter[208/312]		Loss: 0.1044
2019-10-29 00:45:03,776 Training Epoch [23/40] Iter[209/312]		Loss: 0.1043
2019-10-29 00:45:03,897 Training Epoch [23/40] Iter[210/312]		Loss: 0.1045
2019-10-29 00:45:04,019 Training Epoch [23/40] Iter[211/312]		Loss: 0.1044
2019-10-29 00:45:04,140 Training Epoch [23/40] Iter[212/312]		Loss: 0.1043
2019-10-29 00:45:04,262 Training Epoch [23/40] Iter[213/312]		Loss: 0.1044
2019-10-29 00:45:04,383 Training Epoch [23/40] Iter[214/312]		Loss: 0.1042
2019-10-29 00:45:04,505 Training Epoch [23/40] Iter[215/312]		Loss: 0.1041
2019-10-29 00:45:04,627 Training Epoch [23/40] Iter[216/312]		Loss: 0.1041
2019-10-29 00:45:04,748 Training Epoch [23/40] Iter[217/312]		Loss: 0.1041
2019-10-29 00:45:04,869 Training Epoch [23/40] Iter[218/312]		Loss: 0.1040
2019-10-29 00:45:04,991 Training Epoch [23/40] Iter[219/312]		Loss: 0.1040
2019-10-29 00:45:05,113 Training Epoch [23/40] Iter[220/312]		Loss: 0.1040
2019-10-29 00:45:05,234 Training Epoch [23/40] Iter[221/312]		Loss: 0.1039
2019-10-29 00:45:05,356 Training Epoch [23/40] Iter[222/312]		Loss: 0.1038
2019-10-29 00:45:05,478 Training Epoch [23/40] Iter[223/312]		Loss: 0.1037
2019-10-29 00:45:05,600 Training Epoch [23/40] Iter[224/312]		Loss: 0.1037
2019-10-29 00:45:05,722 Training Epoch [23/40] Iter[225/312]		Loss: 0.1039
2019-10-29 00:45:05,843 Training Epoch [23/40] Iter[226/312]		Loss: 0.1038
2019-10-29 00:45:05,965 Training Epoch [23/40] Iter[227/312]		Loss: 0.1038
2019-10-29 00:45:06,086 Training Epoch [23/40] Iter[228/312]		Loss: 0.1039
2019-10-29 00:45:06,207 Training Epoch [23/40] Iter[229/312]		Loss: 0.1037
2019-10-29 00:45:06,329 Training Epoch [23/40] Iter[230/312]		Loss: 0.1038
2019-10-29 00:45:06,450 Training Epoch [23/40] Iter[231/312]		Loss: 0.1037
2019-10-29 00:45:06,571 Training Epoch [23/40] Iter[232/312]		Loss: 0.1038
2019-10-29 00:45:06,693 Training Epoch [23/40] Iter[233/312]		Loss: 0.1037
2019-10-29 00:45:06,815 Training Epoch [23/40] Iter[234/312]		Loss: 0.1039
2019-10-29 00:45:06,936 Training Epoch [23/40] Iter[235/312]		Loss: 0.1041
2019-10-29 00:45:07,058 Training Epoch [23/40] Iter[236/312]		Loss: 0.1041
2019-10-29 00:45:07,179 Training Epoch [23/40] Iter[237/312]		Loss: 0.1040
2019-10-29 00:45:07,302 Training Epoch [23/40] Iter[238/312]		Loss: 0.1041
2019-10-29 00:45:07,423 Training Epoch [23/40] Iter[239/312]		Loss: 0.1041
2019-10-29 00:45:07,544 Training Epoch [23/40] Iter[240/312]		Loss: 0.1042
2019-10-29 00:45:07,666 Training Epoch [23/40] Iter[241/312]		Loss: 0.1041
2019-10-29 00:45:07,788 Training Epoch [23/40] Iter[242/312]		Loss: 0.1043
2019-10-29 00:45:07,910 Training Epoch [23/40] Iter[243/312]		Loss: 0.1044
2019-10-29 00:45:08,032 Training Epoch [23/40] Iter[244/312]		Loss: 0.1045
2019-10-29 00:45:08,153 Training Epoch [23/40] Iter[245/312]		Loss: 0.1046
2019-10-29 00:45:08,275 Training Epoch [23/40] Iter[246/312]		Loss: 0.1044
2019-10-29 00:45:08,396 Training Epoch [23/40] Iter[247/312]		Loss: 0.1044
2019-10-29 00:45:08,518 Training Epoch [23/40] Iter[248/312]		Loss: 0.1044
2019-10-29 00:45:08,639 Training Epoch [23/40] Iter[249/312]		Loss: 0.1043
2019-10-29 00:45:08,760 Training Epoch [23/40] Iter[250/312]		Loss: 0.1043
2019-10-29 00:45:08,881 Training Epoch [23/40] Iter[251/312]		Loss: 0.1043
2019-10-29 00:45:09,002 Training Epoch [23/40] Iter[252/312]		Loss: 0.1041
2019-10-29 00:45:09,124 Training Epoch [23/40] Iter[253/312]		Loss: 0.1042
2019-10-29 00:45:09,245 Training Epoch [23/40] Iter[254/312]		Loss: 0.1042
2019-10-29 00:45:09,366 Training Epoch [23/40] Iter[255/312]		Loss: 0.1043
2019-10-29 00:45:09,488 Training Epoch [23/40] Iter[256/312]		Loss: 0.1046
2019-10-29 00:45:09,610 Training Epoch [23/40] Iter[257/312]		Loss: 0.1045
2019-10-29 00:45:09,732 Training Epoch [23/40] Iter[258/312]		Loss: 0.1046
2019-10-29 00:45:09,854 Training Epoch [23/40] Iter[259/312]		Loss: 0.1049
2019-10-29 00:45:09,975 Training Epoch [23/40] Iter[260/312]		Loss: 0.1050
2019-10-29 00:45:10,097 Training Epoch [23/40] Iter[261/312]		Loss: 0.1049
2019-10-29 00:45:10,218 Training Epoch [23/40] Iter[262/312]		Loss: 0.1049
2019-10-29 00:45:10,340 Training Epoch [23/40] Iter[263/312]		Loss: 0.1048
2019-10-29 00:45:10,461 Training Epoch [23/40] Iter[264/312]		Loss: 0.1048
2019-10-29 00:45:10,583 Training Epoch [23/40] Iter[265/312]		Loss: 0.1050
2019-10-29 00:45:10,704 Training Epoch [23/40] Iter[266/312]		Loss: 0.1050
2019-10-29 00:45:10,826 Training Epoch [23/40] Iter[267/312]		Loss: 0.1054
2019-10-29 00:45:10,948 Training Epoch [23/40] Iter[268/312]		Loss: 0.1052
2019-10-29 00:45:11,069 Training Epoch [23/40] Iter[269/312]		Loss: 0.1054
2019-10-29 00:45:11,191 Training Epoch [23/40] Iter[270/312]		Loss: 0.1054
2019-10-29 00:45:11,312 Training Epoch [23/40] Iter[271/312]		Loss: 0.1053
2019-10-29 00:45:11,434 Training Epoch [23/40] Iter[272/312]		Loss: 0.1053
2019-10-29 00:45:11,555 Training Epoch [23/40] Iter[273/312]		Loss: 0.1052
2019-10-29 00:45:11,676 Training Epoch [23/40] Iter[274/312]		Loss: 0.1051
2019-10-29 00:45:11,797 Training Epoch [23/40] Iter[275/312]		Loss: 0.1051
2019-10-29 00:45:11,919 Training Epoch [23/40] Iter[276/312]		Loss: 0.1051
2019-10-29 00:45:12,040 Training Epoch [23/40] Iter[277/312]		Loss: 0.1053
2019-10-29 00:45:12,161 Training Epoch [23/40] Iter[278/312]		Loss: 0.1052
2019-10-29 00:45:12,282 Training Epoch [23/40] Iter[279/312]		Loss: 0.1052
2019-10-29 00:45:12,405 Training Epoch [23/40] Iter[280/312]		Loss: 0.1053
2019-10-29 00:45:12,526 Training Epoch [23/40] Iter[281/312]		Loss: 0.1054
2019-10-29 00:45:12,648 Training Epoch [23/40] Iter[282/312]		Loss: 0.1055
2019-10-29 00:45:12,769 Training Epoch [23/40] Iter[283/312]		Loss: 0.1054
2019-10-29 00:45:12,891 Training Epoch [23/40] Iter[284/312]		Loss: 0.1054
2019-10-29 00:45:13,012 Training Epoch [23/40] Iter[285/312]		Loss: 0.1053
2019-10-29 00:45:13,134 Training Epoch [23/40] Iter[286/312]		Loss: 0.1054
2019-10-29 00:45:13,255 Training Epoch [23/40] Iter[287/312]		Loss: 0.1052
2019-10-29 00:45:13,377 Training Epoch [23/40] Iter[288/312]		Loss: 0.1052
2019-10-29 00:45:13,499 Training Epoch [23/40] Iter[289/312]		Loss: 0.1053
2019-10-29 00:45:13,620 Training Epoch [23/40] Iter[290/312]		Loss: 0.1053
2019-10-29 00:45:13,742 Training Epoch [23/40] Iter[291/312]		Loss: 0.1052
2019-10-29 00:45:13,863 Training Epoch [23/40] Iter[292/312]		Loss: 0.1052
2019-10-29 00:45:13,984 Training Epoch [23/40] Iter[293/312]		Loss: 0.1052
2019-10-29 00:45:14,106 Training Epoch [23/40] Iter[294/312]		Loss: 0.1052
2019-10-29 00:45:14,228 Training Epoch [23/40] Iter[295/312]		Loss: 0.1052
2019-10-29 00:45:14,349 Training Epoch [23/40] Iter[296/312]		Loss: 0.1053
2019-10-29 00:45:14,471 Training Epoch [23/40] Iter[297/312]		Loss: 0.1054
2019-10-29 00:45:14,592 Training Epoch [23/40] Iter[298/312]		Loss: 0.1055
2019-10-29 00:45:14,714 Training Epoch [23/40] Iter[299/312]		Loss: 0.1054
2019-10-29 00:45:14,835 Training Epoch [23/40] Iter[300/312]		Loss: 0.1053
2019-10-29 00:45:14,957 Training Epoch [23/40] Iter[301/312]		Loss: 0.1052
2019-10-29 00:45:15,078 Training Epoch [23/40] Iter[302/312]		Loss: 0.1053
2019-10-29 00:45:15,199 Training Epoch [23/40] Iter[303/312]		Loss: 0.1052
2019-10-29 00:45:15,321 Training Epoch [23/40] Iter[304/312]		Loss: 0.1052
2019-10-29 00:45:15,442 Training Epoch [23/40] Iter[305/312]		Loss: 0.1051
2019-10-29 00:45:15,563 Training Epoch [23/40] Iter[306/312]		Loss: 0.1051
2019-10-29 00:45:15,684 Training Epoch [23/40] Iter[307/312]		Loss: 0.1050
2019-10-29 00:45:15,805 Training Epoch [23/40] Iter[308/312]		Loss: 0.1050
2019-10-29 00:45:15,925 Training Epoch [23/40] Iter[309/312]		Loss: 0.1049
2019-10-29 00:45:16,046 Training Epoch [23/40] Iter[310/312]		Loss: 0.1049
2019-10-29 00:45:16,167 Training Epoch [23/40] Iter[311/312]		Loss: 0.1049
2019-10-29 00:45:16,228 Training Epoch [23/40] Iter[312/312]		Loss: 0.1050
2019-10-29 00:45:16,617 Testing Epoch [23/40] Iter[0/62]		Loss: 0.0914
2019-10-29 00:45:16,662 Testing Epoch [23/40] Iter[1/62]		Loss: 0.1255
2019-10-29 00:45:16,694 Testing Epoch [23/40] Iter[2/62]		Loss: 0.1177
2019-10-29 00:45:16,726 Testing Epoch [23/40] Iter[3/62]		Loss: 0.1158
2019-10-29 00:45:16,762 Testing Epoch [23/40] Iter[4/62]		Loss: 0.1113
2019-10-29 00:45:16,792 Testing Epoch [23/40] Iter[5/62]		Loss: 0.1088
2019-10-29 00:45:16,821 Testing Epoch [23/40] Iter[6/62]		Loss: 0.1104
2019-10-29 00:45:16,854 Testing Epoch [23/40] Iter[7/62]		Loss: 0.1167
2019-10-29 00:45:16,884 Testing Epoch [23/40] Iter[8/62]		Loss: 0.1233
2019-10-29 00:45:16,915 Testing Epoch [23/40] Iter[9/62]		Loss: 0.1204
2019-10-29 00:45:16,950 Testing Epoch [23/40] Iter[10/62]		Loss: 0.1182
2019-10-29 00:45:16,980 Testing Epoch [23/40] Iter[11/62]		Loss: 0.1235
2019-10-29 00:45:17,011 Testing Epoch [23/40] Iter[12/62]		Loss: 0.1245
2019-10-29 00:45:17,046 Testing Epoch [23/40] Iter[13/62]		Loss: 0.1266
2019-10-29 00:45:17,076 Testing Epoch [23/40] Iter[14/62]		Loss: 0.1390
2019-10-29 00:45:17,107 Testing Epoch [23/40] Iter[15/62]		Loss: 0.1408
2019-10-29 00:45:17,142 Testing Epoch [23/40] Iter[16/62]		Loss: 0.1388
2019-10-29 00:45:17,172 Testing Epoch [23/40] Iter[17/62]		Loss: 0.1381
2019-10-29 00:45:17,203 Testing Epoch [23/40] Iter[18/62]		Loss: 0.1348
2019-10-29 00:45:17,233 Testing Epoch [23/40] Iter[19/62]		Loss: 0.1329
2019-10-29 00:45:17,264 Testing Epoch [23/40] Iter[20/62]		Loss: 0.1342
2019-10-29 00:45:17,295 Testing Epoch [23/40] Iter[21/62]		Loss: 0.1323
2019-10-29 00:45:17,328 Testing Epoch [23/40] Iter[22/62]		Loss: 0.1316
2019-10-29 00:45:17,358 Testing Epoch [23/40] Iter[23/62]		Loss: 0.1315
2019-10-29 00:45:17,389 Testing Epoch [23/40] Iter[24/62]		Loss: 0.1335
2019-10-29 00:45:17,419 Testing Epoch [23/40] Iter[25/62]		Loss: 0.1327
2019-10-29 00:45:17,450 Testing Epoch [23/40] Iter[26/62]		Loss: 0.1314
2019-10-29 00:45:17,481 Testing Epoch [23/40] Iter[27/62]		Loss: 0.1361
2019-10-29 00:45:17,511 Testing Epoch [23/40] Iter[28/62]		Loss: 0.1380
2019-10-29 00:45:17,542 Testing Epoch [23/40] Iter[29/62]		Loss: 0.1378
2019-10-29 00:45:17,573 Testing Epoch [23/40] Iter[30/62]		Loss: 0.1395
2019-10-29 00:45:17,603 Testing Epoch [23/40] Iter[31/62]		Loss: 0.1387
2019-10-29 00:45:17,634 Testing Epoch [23/40] Iter[32/62]		Loss: 0.1405
2019-10-29 00:45:17,665 Testing Epoch [23/40] Iter[33/62]		Loss: 0.1386
2019-10-29 00:45:17,696 Testing Epoch [23/40] Iter[34/62]		Loss: 0.1402
2019-10-29 00:45:17,726 Testing Epoch [23/40] Iter[35/62]		Loss: 0.1406
2019-10-29 00:45:17,757 Testing Epoch [23/40] Iter[36/62]		Loss: 0.1388
2019-10-29 00:45:17,788 Testing Epoch [23/40] Iter[37/62]		Loss: 0.1385
2019-10-29 00:45:17,819 Testing Epoch [23/40] Iter[38/62]		Loss: 0.1386
2019-10-29 00:45:17,849 Testing Epoch [23/40] Iter[39/62]		Loss: 0.1389
2019-10-29 00:45:17,880 Testing Epoch [23/40] Iter[40/62]		Loss: 0.1394
2019-10-29 00:45:17,911 Testing Epoch [23/40] Iter[41/62]		Loss: 0.1396
2019-10-29 00:45:17,941 Testing Epoch [23/40] Iter[42/62]		Loss: 0.1382
2019-10-29 00:45:17,972 Testing Epoch [23/40] Iter[43/62]		Loss: 0.1378
2019-10-29 00:45:18,003 Testing Epoch [23/40] Iter[44/62]		Loss: 0.1368
2019-10-29 00:45:18,033 Testing Epoch [23/40] Iter[45/62]		Loss: 0.1377
2019-10-29 00:45:18,064 Testing Epoch [23/40] Iter[46/62]		Loss: 0.1378
2019-10-29 00:45:18,095 Testing Epoch [23/40] Iter[47/62]		Loss: 0.1427
2019-10-29 00:45:18,125 Testing Epoch [23/40] Iter[48/62]		Loss: 0.1418
2019-10-29 00:45:18,156 Testing Epoch [23/40] Iter[49/62]		Loss: 0.1432
2019-10-29 00:45:18,187 Testing Epoch [23/40] Iter[50/62]		Loss: 0.1428
2019-10-29 00:45:18,217 Testing Epoch [23/40] Iter[51/62]		Loss: 0.1429
2019-10-29 00:45:18,248 Testing Epoch [23/40] Iter[52/62]		Loss: 0.1417
2019-10-29 00:45:18,278 Testing Epoch [23/40] Iter[53/62]		Loss: 0.1415
2019-10-29 00:45:18,309 Testing Epoch [23/40] Iter[54/62]		Loss: 0.1410
2019-10-29 00:45:18,339 Testing Epoch [23/40] Iter[55/62]		Loss: 0.1411
2019-10-29 00:45:18,370 Testing Epoch [23/40] Iter[56/62]		Loss: 0.1409
2019-10-29 00:45:18,400 Testing Epoch [23/40] Iter[57/62]		Loss: 0.1407
2019-10-29 00:45:18,430 Testing Epoch [23/40] Iter[58/62]		Loss: 0.1403
2019-10-29 00:45:18,460 Testing Epoch [23/40] Iter[59/62]		Loss: 0.1404
2019-10-29 00:45:18,490 Testing Epoch [23/40] Iter[60/62]		Loss: 0.1398
2019-10-29 00:45:18,521 Testing Epoch [23/40] Iter[61/62]		Loss: 0.1395
2019-10-29 00:45:18,538 Testing Epoch [23/40] Iter[62/62]		Loss: 0.1402
2019-10-29 00:45:19,012 Training Epoch [24/40] Iter[0/312]		Loss: 0.1134
2019-10-29 00:45:19,134 Training Epoch [24/40] Iter[1/312]		Loss: 0.0897
2019-10-29 00:45:19,255 Training Epoch [24/40] Iter[2/312]		Loss: 0.0913
2019-10-29 00:45:19,376 Training Epoch [24/40] Iter[3/312]		Loss: 0.0851
2019-10-29 00:45:19,499 Training Epoch [24/40] Iter[4/312]		Loss: 0.0846
2019-10-29 00:45:19,619 Training Epoch [24/40] Iter[5/312]		Loss: 0.0863
2019-10-29 00:45:19,739 Training Epoch [24/40] Iter[6/312]		Loss: 0.0851
2019-10-29 00:45:19,860 Training Epoch [24/40] Iter[7/312]		Loss: 0.0857
2019-10-29 00:45:19,981 Training Epoch [24/40] Iter[8/312]		Loss: 0.0880
2019-10-29 00:45:20,102 Training Epoch [24/40] Iter[9/312]		Loss: 0.0874
2019-10-29 00:45:20,223 Training Epoch [24/40] Iter[10/312]		Loss: 0.0897
2019-10-29 00:45:20,345 Training Epoch [24/40] Iter[11/312]		Loss: 0.0921
2019-10-29 00:45:20,466 Training Epoch [24/40] Iter[12/312]		Loss: 0.0937
2019-10-29 00:45:20,588 Training Epoch [24/40] Iter[13/312]		Loss: 0.0959
2019-10-29 00:45:20,709 Training Epoch [24/40] Iter[14/312]		Loss: 0.0975
2019-10-29 00:45:20,831 Training Epoch [24/40] Iter[15/312]		Loss: 0.0984
2019-10-29 00:45:20,952 Training Epoch [24/40] Iter[16/312]		Loss: 0.1017
2019-10-29 00:45:21,074 Training Epoch [24/40] Iter[17/312]		Loss: 0.1031
2019-10-29 00:45:21,196 Training Epoch [24/40] Iter[18/312]		Loss: 0.1043
2019-10-29 00:45:21,317 Training Epoch [24/40] Iter[19/312]		Loss: 0.1075
2019-10-29 00:45:21,439 Training Epoch [24/40] Iter[20/312]		Loss: 0.1060
2019-10-29 00:45:21,561 Training Epoch [24/40] Iter[21/312]		Loss: 0.1064
2019-10-29 00:45:21,682 Training Epoch [24/40] Iter[22/312]		Loss: 0.1065
2019-10-29 00:45:21,804 Training Epoch [24/40] Iter[23/312]		Loss: 0.1069
2019-10-29 00:45:21,925 Training Epoch [24/40] Iter[24/312]		Loss: 0.1067
2019-10-29 00:45:22,047 Training Epoch [24/40] Iter[25/312]		Loss: 0.1047
2019-10-29 00:45:22,169 Training Epoch [24/40] Iter[26/312]		Loss: 0.1053
2019-10-29 00:45:22,291 Training Epoch [24/40] Iter[27/312]		Loss: 0.1060
2019-10-29 00:45:22,413 Training Epoch [24/40] Iter[28/312]		Loss: 0.1046
2019-10-29 00:45:22,535 Training Epoch [24/40] Iter[29/312]		Loss: 0.1050
2019-10-29 00:45:22,656 Training Epoch [24/40] Iter[30/312]		Loss: 0.1050
2019-10-29 00:45:22,777 Training Epoch [24/40] Iter[31/312]		Loss: 0.1043
2019-10-29 00:45:22,899 Training Epoch [24/40] Iter[32/312]		Loss: 0.1029
2019-10-29 00:45:23,021 Training Epoch [24/40] Iter[33/312]		Loss: 0.1033
2019-10-29 00:45:23,142 Training Epoch [24/40] Iter[34/312]		Loss: 0.1025
2019-10-29 00:45:23,263 Training Epoch [24/40] Iter[35/312]		Loss: 0.1037
2019-10-29 00:45:23,385 Training Epoch [24/40] Iter[36/312]		Loss: 0.1029
2019-10-29 00:45:23,506 Training Epoch [24/40] Iter[37/312]		Loss: 0.1029
2019-10-29 00:45:23,628 Training Epoch [24/40] Iter[38/312]		Loss: 0.1036
2019-10-29 00:45:23,750 Training Epoch [24/40] Iter[39/312]		Loss: 0.1029
2019-10-29 00:45:23,871 Training Epoch [24/40] Iter[40/312]		Loss: 0.1026
2019-10-29 00:45:23,993 Training Epoch [24/40] Iter[41/312]		Loss: 0.1026
2019-10-29 00:45:24,114 Training Epoch [24/40] Iter[42/312]		Loss: 0.1020
2019-10-29 00:45:24,236 Training Epoch [24/40] Iter[43/312]		Loss: 0.1013
2019-10-29 00:45:24,357 Training Epoch [24/40] Iter[44/312]		Loss: 0.1015
2019-10-29 00:45:24,479 Training Epoch [24/40] Iter[45/312]		Loss: 0.1017
2019-10-29 00:45:24,600 Training Epoch [24/40] Iter[46/312]		Loss: 0.1012
2019-10-29 00:45:24,722 Training Epoch [24/40] Iter[47/312]		Loss: 0.1009
2019-10-29 00:45:24,844 Training Epoch [24/40] Iter[48/312]		Loss: 0.1010
2019-10-29 00:45:24,966 Training Epoch [24/40] Iter[49/312]		Loss: 0.1011
2019-10-29 00:45:25,092 Training Epoch [24/40] Iter[50/312]		Loss: 0.1008
2019-10-29 00:45:25,214 Training Epoch [24/40] Iter[51/312]		Loss: 0.1001
2019-10-29 00:45:25,335 Training Epoch [24/40] Iter[52/312]		Loss: 0.1003
2019-10-29 00:45:25,457 Training Epoch [24/40] Iter[53/312]		Loss: 0.1004
2019-10-29 00:45:25,579 Training Epoch [24/40] Iter[54/312]		Loss: 0.1000
2019-10-29 00:45:25,701 Training Epoch [24/40] Iter[55/312]		Loss: 0.0997
2019-10-29 00:45:25,822 Training Epoch [24/40] Iter[56/312]		Loss: 0.1002
2019-10-29 00:45:25,944 Training Epoch [24/40] Iter[57/312]		Loss: 0.1005
2019-10-29 00:45:26,066 Training Epoch [24/40] Iter[58/312]		Loss: 0.1016
2019-10-29 00:45:26,187 Training Epoch [24/40] Iter[59/312]		Loss: 0.1015
2019-10-29 00:45:26,309 Training Epoch [24/40] Iter[60/312]		Loss: 0.1019
2019-10-29 00:45:26,431 Training Epoch [24/40] Iter[61/312]		Loss: 0.1019
2019-10-29 00:45:26,552 Training Epoch [24/40] Iter[62/312]		Loss: 0.1017
2019-10-29 00:45:26,673 Training Epoch [24/40] Iter[63/312]		Loss: 0.1019
2019-10-29 00:45:26,795 Training Epoch [24/40] Iter[64/312]		Loss: 0.1027
2019-10-29 00:45:26,916 Training Epoch [24/40] Iter[65/312]		Loss: 0.1025
2019-10-29 00:45:27,038 Training Epoch [24/40] Iter[66/312]		Loss: 0.1030
2019-10-29 00:45:27,159 Training Epoch [24/40] Iter[67/312]		Loss: 0.1029
2019-10-29 00:45:27,281 Training Epoch [24/40] Iter[68/312]		Loss: 0.1030
2019-10-29 00:45:27,402 Training Epoch [24/40] Iter[69/312]		Loss: 0.1031
2019-10-29 00:45:27,524 Training Epoch [24/40] Iter[70/312]		Loss: 0.1032
2019-10-29 00:45:27,646 Training Epoch [24/40] Iter[71/312]		Loss: 0.1038
2019-10-29 00:45:27,768 Training Epoch [24/40] Iter[72/312]		Loss: 0.1034
2019-10-29 00:45:27,889 Training Epoch [24/40] Iter[73/312]		Loss: 0.1034
2019-10-29 00:45:28,011 Training Epoch [24/40] Iter[74/312]		Loss: 0.1036
2019-10-29 00:45:28,132 Training Epoch [24/40] Iter[75/312]		Loss: 0.1034
2019-10-29 00:45:28,254 Training Epoch [24/40] Iter[76/312]		Loss: 0.1033
2019-10-29 00:45:28,375 Training Epoch [24/40] Iter[77/312]		Loss: 0.1037
2019-10-29 00:45:28,497 Training Epoch [24/40] Iter[78/312]		Loss: 0.1042
2019-10-29 00:45:28,618 Training Epoch [24/40] Iter[79/312]		Loss: 0.1039
2019-10-29 00:45:28,739 Training Epoch [24/40] Iter[80/312]		Loss: 0.1038
2019-10-29 00:45:28,860 Training Epoch [24/40] Iter[81/312]		Loss: 0.1036
2019-10-29 00:45:28,981 Training Epoch [24/40] Iter[82/312]		Loss: 0.1038
2019-10-29 00:45:29,102 Training Epoch [24/40] Iter[83/312]		Loss: 0.1044
2019-10-29 00:45:29,224 Training Epoch [24/40] Iter[84/312]		Loss: 0.1042
2019-10-29 00:45:29,345 Training Epoch [24/40] Iter[85/312]		Loss: 0.1043
2019-10-29 00:45:29,466 Training Epoch [24/40] Iter[86/312]		Loss: 0.1041
2019-10-29 00:45:29,588 Training Epoch [24/40] Iter[87/312]		Loss: 0.1042
2019-10-29 00:45:29,710 Training Epoch [24/40] Iter[88/312]		Loss: 0.1038
2019-10-29 00:45:29,832 Training Epoch [24/40] Iter[89/312]		Loss: 0.1035
2019-10-29 00:45:29,954 Training Epoch [24/40] Iter[90/312]		Loss: 0.1033
2019-10-29 00:45:30,075 Training Epoch [24/40] Iter[91/312]		Loss: 0.1032
2019-10-29 00:45:30,196 Training Epoch [24/40] Iter[92/312]		Loss: 0.1030
2019-10-29 00:45:30,317 Training Epoch [24/40] Iter[93/312]		Loss: 0.1028
2019-10-29 00:45:30,439 Training Epoch [24/40] Iter[94/312]		Loss: 0.1024
2019-10-29 00:45:30,561 Training Epoch [24/40] Iter[95/312]		Loss: 0.1023
2019-10-29 00:45:30,683 Training Epoch [24/40] Iter[96/312]		Loss: 0.1020
2019-10-29 00:45:30,804 Training Epoch [24/40] Iter[97/312]		Loss: 0.1025
2019-10-29 00:45:30,926 Training Epoch [24/40] Iter[98/312]		Loss: 0.1025
2019-10-29 00:45:31,047 Training Epoch [24/40] Iter[99/312]		Loss: 0.1024
2019-10-29 00:45:31,169 Training Epoch [24/40] Iter[100/312]		Loss: 0.1022
2019-10-29 00:45:31,290 Training Epoch [24/40] Iter[101/312]		Loss: 0.1022
2019-10-29 00:45:31,412 Training Epoch [24/40] Iter[102/312]		Loss: 0.1019
2019-10-29 00:45:31,533 Training Epoch [24/40] Iter[103/312]		Loss: 0.1028
2019-10-29 00:45:31,654 Training Epoch [24/40] Iter[104/312]		Loss: 0.1027
2019-10-29 00:45:31,776 Training Epoch [24/40] Iter[105/312]		Loss: 0.1025
2019-10-29 00:45:31,897 Training Epoch [24/40] Iter[106/312]		Loss: 0.1025
2019-10-29 00:45:32,019 Training Epoch [24/40] Iter[107/312]		Loss: 0.1025
2019-10-29 00:45:32,140 Training Epoch [24/40] Iter[108/312]		Loss: 0.1021
2019-10-29 00:45:32,261 Training Epoch [24/40] Iter[109/312]		Loss: 0.1021
2019-10-29 00:45:32,382 Training Epoch [24/40] Iter[110/312]		Loss: 0.1017
2019-10-29 00:45:32,504 Training Epoch [24/40] Iter[111/312]		Loss: 0.1014
2019-10-29 00:45:32,626 Training Epoch [24/40] Iter[112/312]		Loss: 0.1014
2019-10-29 00:45:32,747 Training Epoch [24/40] Iter[113/312]		Loss: 0.1012
2019-10-29 00:45:32,869 Training Epoch [24/40] Iter[114/312]		Loss: 0.1011
2019-10-29 00:45:32,991 Training Epoch [24/40] Iter[115/312]		Loss: 0.1014
2019-10-29 00:45:33,113 Training Epoch [24/40] Iter[116/312]		Loss: 0.1014
2019-10-29 00:45:33,234 Training Epoch [24/40] Iter[117/312]		Loss: 0.1017
2019-10-29 00:45:33,355 Training Epoch [24/40] Iter[118/312]		Loss: 0.1015
2019-10-29 00:45:33,477 Training Epoch [24/40] Iter[119/312]		Loss: 0.1013
2019-10-29 00:45:33,599 Training Epoch [24/40] Iter[120/312]		Loss: 0.1014
2019-10-29 00:45:33,720 Training Epoch [24/40] Iter[121/312]		Loss: 0.1015
2019-10-29 00:45:33,841 Training Epoch [24/40] Iter[122/312]		Loss: 0.1015
2019-10-29 00:45:33,963 Training Epoch [24/40] Iter[123/312]		Loss: 0.1015
2019-10-29 00:45:34,085 Training Epoch [24/40] Iter[124/312]		Loss: 0.1014
2019-10-29 00:45:34,207 Training Epoch [24/40] Iter[125/312]		Loss: 0.1012
2019-10-29 00:45:34,329 Training Epoch [24/40] Iter[126/312]		Loss: 0.1016
2019-10-29 00:45:34,450 Training Epoch [24/40] Iter[127/312]		Loss: 0.1020
2019-10-29 00:45:34,571 Training Epoch [24/40] Iter[128/312]		Loss: 0.1026
2019-10-29 00:45:34,693 Training Epoch [24/40] Iter[129/312]		Loss: 0.1028
2019-10-29 00:45:34,815 Training Epoch [24/40] Iter[130/312]		Loss: 0.1029
2019-10-29 00:45:34,936 Training Epoch [24/40] Iter[131/312]		Loss: 0.1027
2019-10-29 00:45:35,057 Training Epoch [24/40] Iter[132/312]		Loss: 0.1031
2019-10-29 00:45:35,179 Training Epoch [24/40] Iter[133/312]		Loss: 0.1032
2019-10-29 00:45:35,300 Training Epoch [24/40] Iter[134/312]		Loss: 0.1031
2019-10-29 00:45:35,422 Training Epoch [24/40] Iter[135/312]		Loss: 0.1030
2019-10-29 00:45:35,543 Training Epoch [24/40] Iter[136/312]		Loss: 0.1027
2019-10-29 00:45:35,664 Training Epoch [24/40] Iter[137/312]		Loss: 0.1026
2019-10-29 00:45:35,786 Training Epoch [24/40] Iter[138/312]		Loss: 0.1023
2019-10-29 00:45:35,907 Training Epoch [24/40] Iter[139/312]		Loss: 0.1025
2019-10-29 00:45:36,028 Training Epoch [24/40] Iter[140/312]		Loss: 0.1027
2019-10-29 00:45:36,149 Training Epoch [24/40] Iter[141/312]		Loss: 0.1026
2019-10-29 00:45:36,271 Training Epoch [24/40] Iter[142/312]		Loss: 0.1026
2019-10-29 00:45:36,392 Training Epoch [24/40] Iter[143/312]		Loss: 0.1023
2019-10-29 00:45:36,514 Training Epoch [24/40] Iter[144/312]		Loss: 0.1023
2019-10-29 00:45:36,635 Training Epoch [24/40] Iter[145/312]		Loss: 0.1023
2019-10-29 00:45:36,757 Training Epoch [24/40] Iter[146/312]		Loss: 0.1021
2019-10-29 00:45:36,878 Training Epoch [24/40] Iter[147/312]		Loss: 0.1022
2019-10-29 00:45:36,998 Training Epoch [24/40] Iter[148/312]		Loss: 0.1021
2019-10-29 00:45:37,120 Training Epoch [24/40] Iter[149/312]		Loss: 0.1024
2019-10-29 00:45:37,241 Training Epoch [24/40] Iter[150/312]		Loss: 0.1025
2019-10-29 00:45:37,361 Training Epoch [24/40] Iter[151/312]		Loss: 0.1024
2019-10-29 00:45:37,483 Training Epoch [24/40] Iter[152/312]		Loss: 0.1023
2019-10-29 00:45:37,604 Training Epoch [24/40] Iter[153/312]		Loss: 0.1020
2019-10-29 00:45:37,725 Training Epoch [24/40] Iter[154/312]		Loss: 0.1020
2019-10-29 00:45:37,846 Training Epoch [24/40] Iter[155/312]		Loss: 0.1022
2019-10-29 00:45:37,967 Training Epoch [24/40] Iter[156/312]		Loss: 0.1021
2019-10-29 00:45:38,088 Training Epoch [24/40] Iter[157/312]		Loss: 0.1023
2019-10-29 00:45:38,210 Training Epoch [24/40] Iter[158/312]		Loss: 0.1027
2019-10-29 00:45:38,332 Training Epoch [24/40] Iter[159/312]		Loss: 0.1027
2019-10-29 00:45:38,454 Training Epoch [24/40] Iter[160/312]		Loss: 0.1028
2019-10-29 00:45:38,575 Training Epoch [24/40] Iter[161/312]		Loss: 0.1027
2019-10-29 00:45:38,697 Training Epoch [24/40] Iter[162/312]		Loss: 0.1029
2019-10-29 00:45:38,818 Training Epoch [24/40] Iter[163/312]		Loss: 0.1032
2019-10-29 00:45:38,940 Training Epoch [24/40] Iter[164/312]		Loss: 0.1033
2019-10-29 00:45:39,061 Training Epoch [24/40] Iter[165/312]		Loss: 0.1032
2019-10-29 00:45:39,183 Training Epoch [24/40] Iter[166/312]		Loss: 0.1032
2019-10-29 00:45:39,304 Training Epoch [24/40] Iter[167/312]		Loss: 0.1031
2019-10-29 00:45:39,426 Training Epoch [24/40] Iter[168/312]		Loss: 0.1032
2019-10-29 00:45:39,548 Training Epoch [24/40] Iter[169/312]		Loss: 0.1031
2019-10-29 00:45:39,670 Training Epoch [24/40] Iter[170/312]		Loss: 0.1033
2019-10-29 00:45:39,791 Training Epoch [24/40] Iter[171/312]		Loss: 0.1035
2019-10-29 00:45:39,912 Training Epoch [24/40] Iter[172/312]		Loss: 0.1034
2019-10-29 00:45:40,033 Training Epoch [24/40] Iter[173/312]		Loss: 0.1034
2019-10-29 00:45:40,154 Training Epoch [24/40] Iter[174/312]		Loss: 0.1033
2019-10-29 00:45:40,276 Training Epoch [24/40] Iter[175/312]		Loss: 0.1033
2019-10-29 00:45:40,397 Training Epoch [24/40] Iter[176/312]		Loss: 0.1032
2019-10-29 00:45:40,519 Training Epoch [24/40] Iter[177/312]		Loss: 0.1033
2019-10-29 00:45:40,640 Training Epoch [24/40] Iter[178/312]		Loss: 0.1033
2019-10-29 00:45:40,761 Training Epoch [24/40] Iter[179/312]		Loss: 0.1031
2019-10-29 00:45:40,883 Training Epoch [24/40] Iter[180/312]		Loss: 0.1030
2019-10-29 00:45:41,004 Training Epoch [24/40] Iter[181/312]		Loss: 0.1030
2019-10-29 00:45:41,125 Training Epoch [24/40] Iter[182/312]		Loss: 0.1030
2019-10-29 00:45:41,247 Training Epoch [24/40] Iter[183/312]		Loss: 0.1036
2019-10-29 00:45:41,368 Training Epoch [24/40] Iter[184/312]		Loss: 0.1036
2019-10-29 00:45:41,490 Training Epoch [24/40] Iter[185/312]		Loss: 0.1034
2019-10-29 00:45:41,612 Training Epoch [24/40] Iter[186/312]		Loss: 0.1034
2019-10-29 00:45:41,733 Training Epoch [24/40] Iter[187/312]		Loss: 0.1033
2019-10-29 00:45:41,855 Training Epoch [24/40] Iter[188/312]		Loss: 0.1033
2019-10-29 00:45:41,976 Training Epoch [24/40] Iter[189/312]		Loss: 0.1033
2019-10-29 00:45:42,098 Training Epoch [24/40] Iter[190/312]		Loss: 0.1034
2019-10-29 00:45:42,220 Training Epoch [24/40] Iter[191/312]		Loss: 0.1036
2019-10-29 00:45:42,341 Training Epoch [24/40] Iter[192/312]		Loss: 0.1037
2019-10-29 00:45:42,462 Training Epoch [24/40] Iter[193/312]		Loss: 0.1039
2019-10-29 00:45:42,584 Training Epoch [24/40] Iter[194/312]		Loss: 0.1038
2019-10-29 00:45:42,706 Training Epoch [24/40] Iter[195/312]		Loss: 0.1037
2019-10-29 00:45:42,828 Training Epoch [24/40] Iter[196/312]		Loss: 0.1036
2019-10-29 00:45:42,949 Training Epoch [24/40] Iter[197/312]		Loss: 0.1040
2019-10-29 00:45:43,070 Training Epoch [24/40] Iter[198/312]		Loss: 0.1039
2019-10-29 00:45:43,191 Training Epoch [24/40] Iter[199/312]		Loss: 0.1036
2019-10-29 00:45:43,313 Training Epoch [24/40] Iter[200/312]		Loss: 0.1038
2019-10-29 00:45:43,434 Training Epoch [24/40] Iter[201/312]		Loss: 0.1037
2019-10-29 00:45:43,556 Training Epoch [24/40] Iter[202/312]		Loss: 0.1036
2019-10-29 00:45:43,677 Training Epoch [24/40] Iter[203/312]		Loss: 0.1035
2019-10-29 00:45:43,799 Training Epoch [24/40] Iter[204/312]		Loss: 0.1035
2019-10-29 00:45:43,920 Training Epoch [24/40] Iter[205/312]		Loss: 0.1033
2019-10-29 00:45:44,041 Training Epoch [24/40] Iter[206/312]		Loss: 0.1032
2019-10-29 00:45:44,163 Training Epoch [24/40] Iter[207/312]		Loss: 0.1032
2019-10-29 00:45:44,285 Training Epoch [24/40] Iter[208/312]		Loss: 0.1030
2019-10-29 00:45:44,406 Training Epoch [24/40] Iter[209/312]		Loss: 0.1028
2019-10-29 00:45:44,528 Training Epoch [24/40] Iter[210/312]		Loss: 0.1027
2019-10-29 00:45:44,649 Training Epoch [24/40] Iter[211/312]		Loss: 0.1028
2019-10-29 00:45:44,771 Training Epoch [24/40] Iter[212/312]		Loss: 0.1028
2019-10-29 00:45:44,893 Training Epoch [24/40] Iter[213/312]		Loss: 0.1031
2019-10-29 00:45:45,014 Training Epoch [24/40] Iter[214/312]		Loss: 0.1032
2019-10-29 00:45:45,135 Training Epoch [24/40] Iter[215/312]		Loss: 0.1031
2019-10-29 00:45:45,257 Training Epoch [24/40] Iter[216/312]		Loss: 0.1031
2019-10-29 00:45:45,378 Training Epoch [24/40] Iter[217/312]		Loss: 0.1030
2019-10-29 00:45:45,500 Training Epoch [24/40] Iter[218/312]		Loss: 0.1030
2019-10-29 00:45:45,621 Training Epoch [24/40] Iter[219/312]		Loss: 0.1028
2019-10-29 00:45:45,742 Training Epoch [24/40] Iter[220/312]		Loss: 0.1030
2019-10-29 00:45:45,864 Training Epoch [24/40] Iter[221/312]		Loss: 0.1031
2019-10-29 00:45:45,985 Training Epoch [24/40] Iter[222/312]		Loss: 0.1030
2019-10-29 00:45:46,106 Training Epoch [24/40] Iter[223/312]		Loss: 0.1033
2019-10-29 00:45:46,227 Training Epoch [24/40] Iter[224/312]		Loss: 0.1033
2019-10-29 00:45:46,349 Training Epoch [24/40] Iter[225/312]		Loss: 0.1032
2019-10-29 00:45:46,470 Training Epoch [24/40] Iter[226/312]		Loss: 0.1030
2019-10-29 00:45:46,591 Training Epoch [24/40] Iter[227/312]		Loss: 0.1030
2019-10-29 00:45:46,713 Training Epoch [24/40] Iter[228/312]		Loss: 0.1031
2019-10-29 00:45:46,835 Training Epoch [24/40] Iter[229/312]		Loss: 0.1031
2019-10-29 00:45:46,957 Training Epoch [24/40] Iter[230/312]		Loss: 0.1031
2019-10-29 00:45:47,079 Training Epoch [24/40] Iter[231/312]		Loss: 0.1034
2019-10-29 00:45:47,200 Training Epoch [24/40] Iter[232/312]		Loss: 0.1032
2019-10-29 00:45:47,321 Training Epoch [24/40] Iter[233/312]		Loss: 0.1032
2019-10-29 00:45:47,443 Training Epoch [24/40] Iter[234/312]		Loss: 0.1031
2019-10-29 00:45:47,565 Training Epoch [24/40] Iter[235/312]		Loss: 0.1031
2019-10-29 00:45:47,686 Training Epoch [24/40] Iter[236/312]		Loss: 0.1031
2019-10-29 00:45:47,808 Training Epoch [24/40] Iter[237/312]		Loss: 0.1031
2019-10-29 00:45:47,929 Training Epoch [24/40] Iter[238/312]		Loss: 0.1030
2019-10-29 00:45:48,051 Training Epoch [24/40] Iter[239/312]		Loss: 0.1030
2019-10-29 00:45:48,172 Training Epoch [24/40] Iter[240/312]		Loss: 0.1029
2019-10-29 00:45:48,294 Training Epoch [24/40] Iter[241/312]		Loss: 0.1028
2019-10-29 00:45:48,416 Training Epoch [24/40] Iter[242/312]		Loss: 0.1027
2019-10-29 00:45:48,537 Training Epoch [24/40] Iter[243/312]		Loss: 0.1026
2019-10-29 00:45:48,658 Training Epoch [24/40] Iter[244/312]		Loss: 0.1026
2019-10-29 00:45:48,780 Training Epoch [24/40] Iter[245/312]		Loss: 0.1026
2019-10-29 00:45:48,901 Training Epoch [24/40] Iter[246/312]		Loss: 0.1025
2019-10-29 00:45:49,022 Training Epoch [24/40] Iter[247/312]		Loss: 0.1030
2019-10-29 00:45:49,144 Training Epoch [24/40] Iter[248/312]		Loss: 0.1028
2019-10-29 00:45:49,265 Training Epoch [24/40] Iter[249/312]		Loss: 0.1028
2019-10-29 00:45:49,386 Training Epoch [24/40] Iter[250/312]		Loss: 0.1029
2019-10-29 00:45:49,508 Training Epoch [24/40] Iter[251/312]		Loss: 0.1030
2019-10-29 00:45:49,629 Training Epoch [24/40] Iter[252/312]		Loss: 0.1030
2019-10-29 00:45:49,751 Training Epoch [24/40] Iter[253/312]		Loss: 0.1028
2019-10-29 00:45:49,873 Training Epoch [24/40] Iter[254/312]		Loss: 0.1030
2019-10-29 00:45:49,995 Training Epoch [24/40] Iter[255/312]		Loss: 0.1030
2019-10-29 00:45:50,116 Training Epoch [24/40] Iter[256/312]		Loss: 0.1030
2019-10-29 00:45:50,238 Training Epoch [24/40] Iter[257/312]		Loss: 0.1031
2019-10-29 00:45:50,359 Training Epoch [24/40] Iter[258/312]		Loss: 0.1030
2019-10-29 00:45:50,481 Training Epoch [24/40] Iter[259/312]		Loss: 0.1031
2019-10-29 00:45:50,603 Training Epoch [24/40] Iter[260/312]		Loss: 0.1031
2019-10-29 00:45:50,724 Training Epoch [24/40] Iter[261/312]		Loss: 0.1030
2019-10-29 00:45:50,846 Training Epoch [24/40] Iter[262/312]		Loss: 0.1029
2019-10-29 00:45:50,967 Training Epoch [24/40] Iter[263/312]		Loss: 0.1028
2019-10-29 00:45:51,088 Training Epoch [24/40] Iter[264/312]		Loss: 0.1026
2019-10-29 00:45:51,211 Training Epoch [24/40] Iter[265/312]		Loss: 0.1024
2019-10-29 00:45:51,332 Training Epoch [24/40] Iter[266/312]		Loss: 0.1027
2019-10-29 00:45:51,454 Training Epoch [24/40] Iter[267/312]		Loss: 0.1026
2019-10-29 00:45:51,575 Training Epoch [24/40] Iter[268/312]		Loss: 0.1026
2019-10-29 00:45:51,696 Training Epoch [24/40] Iter[269/312]		Loss: 0.1025
2019-10-29 00:45:51,818 Training Epoch [24/40] Iter[270/312]		Loss: 0.1028
2019-10-29 00:45:51,940 Training Epoch [24/40] Iter[271/312]		Loss: 0.1029
2019-10-29 00:45:52,061 Training Epoch [24/40] Iter[272/312]		Loss: 0.1030
2019-10-29 00:45:52,182 Training Epoch [24/40] Iter[273/312]		Loss: 0.1030
2019-10-29 00:45:52,304 Training Epoch [24/40] Iter[274/312]		Loss: 0.1030
2019-10-29 00:45:52,425 Training Epoch [24/40] Iter[275/312]		Loss: 0.1030
2019-10-29 00:45:52,547 Training Epoch [24/40] Iter[276/312]		Loss: 0.1030
2019-10-29 00:45:52,668 Training Epoch [24/40] Iter[277/312]		Loss: 0.1030
2019-10-29 00:45:52,790 Training Epoch [24/40] Iter[278/312]		Loss: 0.1029
2019-10-29 00:45:52,911 Training Epoch [24/40] Iter[279/312]		Loss: 0.1030
2019-10-29 00:45:53,032 Training Epoch [24/40] Iter[280/312]		Loss: 0.1030
2019-10-29 00:45:53,154 Training Epoch [24/40] Iter[281/312]		Loss: 0.1030
2019-10-29 00:45:53,275 Training Epoch [24/40] Iter[282/312]		Loss: 0.1030
2019-10-29 00:45:53,397 Training Epoch [24/40] Iter[283/312]		Loss: 0.1030
2019-10-29 00:45:53,518 Training Epoch [24/40] Iter[284/312]		Loss: 0.1030
2019-10-29 00:45:53,639 Training Epoch [24/40] Iter[285/312]		Loss: 0.1029
2019-10-29 00:45:53,760 Training Epoch [24/40] Iter[286/312]		Loss: 0.1028
2019-10-29 00:45:53,882 Training Epoch [24/40] Iter[287/312]		Loss: 0.1030
2019-10-29 00:45:54,003 Training Epoch [24/40] Iter[288/312]		Loss: 0.1032
2019-10-29 00:45:54,124 Training Epoch [24/40] Iter[289/312]		Loss: 0.1031
2019-10-29 00:45:54,246 Training Epoch [24/40] Iter[290/312]		Loss: 0.1031
2019-10-29 00:45:54,367 Training Epoch [24/40] Iter[291/312]		Loss: 0.1032
2019-10-29 00:45:54,488 Training Epoch [24/40] Iter[292/312]		Loss: 0.1032
2019-10-29 00:45:54,610 Training Epoch [24/40] Iter[293/312]		Loss: 0.1032
2019-10-29 00:45:54,731 Training Epoch [24/40] Iter[294/312]		Loss: 0.1034
2019-10-29 00:45:54,852 Training Epoch [24/40] Iter[295/312]		Loss: 0.1034
2019-10-29 00:45:54,974 Training Epoch [24/40] Iter[296/312]		Loss: 0.1034
2019-10-29 00:45:55,096 Training Epoch [24/40] Iter[297/312]		Loss: 0.1033
2019-10-29 00:45:55,218 Training Epoch [24/40] Iter[298/312]		Loss: 0.1033
2019-10-29 00:45:55,340 Training Epoch [24/40] Iter[299/312]		Loss: 0.1033
2019-10-29 00:45:55,462 Training Epoch [24/40] Iter[300/312]		Loss: 0.1033
2019-10-29 00:45:55,584 Training Epoch [24/40] Iter[301/312]		Loss: 0.1033
2019-10-29 00:45:55,705 Training Epoch [24/40] Iter[302/312]		Loss: 0.1032
2019-10-29 00:45:55,826 Training Epoch [24/40] Iter[303/312]		Loss: 0.1032
2019-10-29 00:45:55,948 Training Epoch [24/40] Iter[304/312]		Loss: 0.1032
2019-10-29 00:45:56,069 Training Epoch [24/40] Iter[305/312]		Loss: 0.1031
2019-10-29 00:45:56,190 Training Epoch [24/40] Iter[306/312]		Loss: 0.1031
2019-10-29 00:45:56,311 Training Epoch [24/40] Iter[307/312]		Loss: 0.1030
2019-10-29 00:45:56,433 Training Epoch [24/40] Iter[308/312]		Loss: 0.1030
2019-10-29 00:45:56,554 Training Epoch [24/40] Iter[309/312]		Loss: 0.1029
2019-10-29 00:45:56,675 Training Epoch [24/40] Iter[310/312]		Loss: 0.1029
2019-10-29 00:45:56,795 Training Epoch [24/40] Iter[311/312]		Loss: 0.1029
2019-10-29 00:45:56,856 Training Epoch [24/40] Iter[312/312]		Loss: 0.1029
2019-10-29 00:45:57,269 Testing Epoch [24/40] Iter[0/62]		Loss: 0.0911
2019-10-29 00:45:57,303 Testing Epoch [24/40] Iter[1/62]		Loss: 0.1258
2019-10-29 00:45:57,342 Testing Epoch [24/40] Iter[2/62]		Loss: 0.1175
2019-10-29 00:45:57,374 Testing Epoch [24/40] Iter[3/62]		Loss: 0.1160
2019-10-29 00:45:57,404 Testing Epoch [24/40] Iter[4/62]		Loss: 0.1115
2019-10-29 00:45:57,435 Testing Epoch [24/40] Iter[5/62]		Loss: 0.1087
2019-10-29 00:45:57,470 Testing Epoch [24/40] Iter[6/62]		Loss: 0.1100
2019-10-29 00:45:57,502 Testing Epoch [24/40] Iter[7/62]		Loss: 0.1155
2019-10-29 00:45:57,531 Testing Epoch [24/40] Iter[8/62]		Loss: 0.1217
2019-10-29 00:45:57,562 Testing Epoch [24/40] Iter[9/62]		Loss: 0.1196
2019-10-29 00:45:57,598 Testing Epoch [24/40] Iter[10/62]		Loss: 0.1177
2019-10-29 00:45:57,628 Testing Epoch [24/40] Iter[11/62]		Loss: 0.1225
2019-10-29 00:45:57,659 Testing Epoch [24/40] Iter[12/62]		Loss: 0.1233
2019-10-29 00:45:57,694 Testing Epoch [24/40] Iter[13/62]		Loss: 0.1253
2019-10-29 00:45:57,725 Testing Epoch [24/40] Iter[14/62]		Loss: 0.1377
2019-10-29 00:45:57,756 Testing Epoch [24/40] Iter[15/62]		Loss: 0.1394
2019-10-29 00:45:57,790 Testing Epoch [24/40] Iter[16/62]		Loss: 0.1375
2019-10-29 00:45:57,820 Testing Epoch [24/40] Iter[17/62]		Loss: 0.1368
2019-10-29 00:45:57,851 Testing Epoch [24/40] Iter[18/62]		Loss: 0.1335
2019-10-29 00:45:57,886 Testing Epoch [24/40] Iter[19/62]		Loss: 0.1314
2019-10-29 00:45:57,917 Testing Epoch [24/40] Iter[20/62]		Loss: 0.1329
2019-10-29 00:45:57,948 Testing Epoch [24/40] Iter[21/62]		Loss: 0.1309
2019-10-29 00:45:57,982 Testing Epoch [24/40] Iter[22/62]		Loss: 0.1303
2019-10-29 00:45:58,013 Testing Epoch [24/40] Iter[23/62]		Loss: 0.1303
2019-10-29 00:45:58,043 Testing Epoch [24/40] Iter[24/62]		Loss: 0.1323
2019-10-29 00:45:58,078 Testing Epoch [24/40] Iter[25/62]		Loss: 0.1315
2019-10-29 00:45:58,109 Testing Epoch [24/40] Iter[26/62]		Loss: 0.1304
2019-10-29 00:45:58,140 Testing Epoch [24/40] Iter[27/62]		Loss: 0.1348
2019-10-29 00:45:58,174 Testing Epoch [24/40] Iter[28/62]		Loss: 0.1366
2019-10-29 00:45:58,205 Testing Epoch [24/40] Iter[29/62]		Loss: 0.1365
2019-10-29 00:45:58,237 Testing Epoch [24/40] Iter[30/62]		Loss: 0.1382
2019-10-29 00:45:58,270 Testing Epoch [24/40] Iter[31/62]		Loss: 0.1376
2019-10-29 00:45:58,301 Testing Epoch [24/40] Iter[32/62]		Loss: 0.1392
2019-10-29 00:45:58,333 Testing Epoch [24/40] Iter[33/62]		Loss: 0.1373
2019-10-29 00:45:58,366 Testing Epoch [24/40] Iter[34/62]		Loss: 0.1389
2019-10-29 00:45:58,397 Testing Epoch [24/40] Iter[35/62]		Loss: 0.1393
2019-10-29 00:45:58,428 Testing Epoch [24/40] Iter[36/62]		Loss: 0.1376
2019-10-29 00:45:58,462 Testing Epoch [24/40] Iter[37/62]		Loss: 0.1372
2019-10-29 00:45:58,493 Testing Epoch [24/40] Iter[38/62]		Loss: 0.1375
2019-10-29 00:45:58,526 Testing Epoch [24/40] Iter[39/62]		Loss: 0.1379
2019-10-29 00:45:58,556 Testing Epoch [24/40] Iter[40/62]		Loss: 0.1385
2019-10-29 00:45:58,590 Testing Epoch [24/40] Iter[41/62]		Loss: 0.1386
2019-10-29 00:45:58,621 Testing Epoch [24/40] Iter[42/62]		Loss: 0.1373
2019-10-29 00:45:58,651 Testing Epoch [24/40] Iter[43/62]		Loss: 0.1368
2019-10-29 00:45:58,686 Testing Epoch [24/40] Iter[44/62]		Loss: 0.1357
2019-10-29 00:45:58,716 Testing Epoch [24/40] Iter[45/62]		Loss: 0.1367
2019-10-29 00:45:58,747 Testing Epoch [24/40] Iter[46/62]		Loss: 0.1369
2019-10-29 00:45:58,782 Testing Epoch [24/40] Iter[47/62]		Loss: 0.1419
2019-10-29 00:45:58,813 Testing Epoch [24/40] Iter[48/62]		Loss: 0.1409
2019-10-29 00:45:58,845 Testing Epoch [24/40] Iter[49/62]		Loss: 0.1423
2019-10-29 00:45:58,882 Testing Epoch [24/40] Iter[50/62]		Loss: 0.1420
2019-10-29 00:45:58,913 Testing Epoch [24/40] Iter[51/62]		Loss: 0.1421
2019-10-29 00:45:58,944 Testing Epoch [24/40] Iter[52/62]		Loss: 0.1409
2019-10-29 00:45:58,975 Testing Epoch [24/40] Iter[53/62]		Loss: 0.1407
2019-10-29 00:45:59,006 Testing Epoch [24/40] Iter[54/62]		Loss: 0.1401
2019-10-29 00:45:59,036 Testing Epoch [24/40] Iter[55/62]		Loss: 0.1402
2019-10-29 00:45:59,067 Testing Epoch [24/40] Iter[56/62]		Loss: 0.1401
2019-10-29 00:45:59,097 Testing Epoch [24/40] Iter[57/62]		Loss: 0.1399
2019-10-29 00:45:59,128 Testing Epoch [24/40] Iter[58/62]		Loss: 0.1395
2019-10-29 00:45:59,158 Testing Epoch [24/40] Iter[59/62]		Loss: 0.1395
2019-10-29 00:45:59,188 Testing Epoch [24/40] Iter[60/62]		Loss: 0.1388
2019-10-29 00:45:59,219 Testing Epoch [24/40] Iter[61/62]		Loss: 0.1385
2019-10-29 00:45:59,236 Testing Epoch [24/40] Iter[62/62]		Loss: 0.1392
2019-10-29 00:45:59,299 Saving the Model
2019-10-29 00:45:59,758 Training Epoch [25/40] Iter[0/312]		Loss: 0.1012
2019-10-29 00:45:59,879 Training Epoch [25/40] Iter[1/312]		Loss: 0.0991
2019-10-29 00:45:59,999 Training Epoch [25/40] Iter[2/312]		Loss: 0.0889
2019-10-29 00:46:00,119 Training Epoch [25/40] Iter[3/312]		Loss: 0.0962
2019-10-29 00:46:00,242 Training Epoch [25/40] Iter[4/312]		Loss: 0.0962
2019-10-29 00:46:00,363 Training Epoch [25/40] Iter[5/312]		Loss: 0.0969
2019-10-29 00:46:00,483 Training Epoch [25/40] Iter[6/312]		Loss: 0.1028
2019-10-29 00:46:00,603 Training Epoch [25/40] Iter[7/312]		Loss: 0.1045
2019-10-29 00:46:00,725 Training Epoch [25/40] Iter[8/312]		Loss: 0.1052
2019-10-29 00:46:00,846 Training Epoch [25/40] Iter[9/312]		Loss: 0.1025
2019-10-29 00:46:00,968 Training Epoch [25/40] Iter[10/312]		Loss: 0.1038
2019-10-29 00:46:01,089 Training Epoch [25/40] Iter[11/312]		Loss: 0.1049
2019-10-29 00:46:01,210 Training Epoch [25/40] Iter[12/312]		Loss: 0.1022
2019-10-29 00:46:01,337 Training Epoch [25/40] Iter[13/312]		Loss: 0.1023
2019-10-29 00:46:01,458 Training Epoch [25/40] Iter[14/312]		Loss: 0.1001
2019-10-29 00:46:01,579 Training Epoch [25/40] Iter[15/312]		Loss: 0.0984
2019-10-29 00:46:01,701 Training Epoch [25/40] Iter[16/312]		Loss: 0.0971
2019-10-29 00:46:01,824 Training Epoch [25/40] Iter[17/312]		Loss: 0.0979
2019-10-29 00:46:01,946 Training Epoch [25/40] Iter[18/312]		Loss: 0.0971
2019-10-29 00:46:02,067 Training Epoch [25/40] Iter[19/312]		Loss: 0.0962
2019-10-29 00:46:02,188 Training Epoch [25/40] Iter[20/312]		Loss: 0.0955
2019-10-29 00:46:02,309 Training Epoch [25/40] Iter[21/312]		Loss: 0.0948
2019-10-29 00:46:02,431 Training Epoch [25/40] Iter[22/312]		Loss: 0.0964
2019-10-29 00:46:02,552 Training Epoch [25/40] Iter[23/312]		Loss: 0.0972
2019-10-29 00:46:02,673 Training Epoch [25/40] Iter[24/312]		Loss: 0.0982
2019-10-29 00:46:02,794 Training Epoch [25/40] Iter[25/312]		Loss: 0.0979
2019-10-29 00:46:02,915 Training Epoch [25/40] Iter[26/312]		Loss: 0.0972
2019-10-29 00:46:03,036 Training Epoch [25/40] Iter[27/312]		Loss: 0.0973
2019-10-29 00:46:03,157 Training Epoch [25/40] Iter[28/312]		Loss: 0.0980
2019-10-29 00:46:03,279 Training Epoch [25/40] Iter[29/312]		Loss: 0.0988
2019-10-29 00:46:03,400 Training Epoch [25/40] Iter[30/312]		Loss: 0.0991
2019-10-29 00:46:03,521 Training Epoch [25/40] Iter[31/312]		Loss: 0.1004
2019-10-29 00:46:03,642 Training Epoch [25/40] Iter[32/312]		Loss: 0.0991
2019-10-29 00:46:03,764 Training Epoch [25/40] Iter[33/312]		Loss: 0.1005
2019-10-29 00:46:03,885 Training Epoch [25/40] Iter[34/312]		Loss: 0.0999
2019-10-29 00:46:04,007 Training Epoch [25/40] Iter[35/312]		Loss: 0.1003
2019-10-29 00:46:04,130 Training Epoch [25/40] Iter[36/312]		Loss: 0.0999
2019-10-29 00:46:04,252 Training Epoch [25/40] Iter[37/312]		Loss: 0.0991
2019-10-29 00:46:04,374 Training Epoch [25/40] Iter[38/312]		Loss: 0.1003
2019-10-29 00:46:04,495 Training Epoch [25/40] Iter[39/312]		Loss: 0.0997
2019-10-29 00:46:04,617 Training Epoch [25/40] Iter[40/312]		Loss: 0.0996
2019-10-29 00:46:04,738 Training Epoch [25/40] Iter[41/312]		Loss: 0.0993
2019-10-29 00:46:04,860 Training Epoch [25/40] Iter[42/312]		Loss: 0.0990
2019-10-29 00:46:04,981 Training Epoch [25/40] Iter[43/312]		Loss: 0.0988
2019-10-29 00:46:05,103 Training Epoch [25/40] Iter[44/312]		Loss: 0.0978
2019-10-29 00:46:05,224 Training Epoch [25/40] Iter[45/312]		Loss: 0.0966
2019-10-29 00:46:05,346 Training Epoch [25/40] Iter[46/312]		Loss: 0.0962
2019-10-29 00:46:05,468 Training Epoch [25/40] Iter[47/312]		Loss: 0.0963
2019-10-29 00:46:05,589 Training Epoch [25/40] Iter[48/312]		Loss: 0.0971
2019-10-29 00:46:05,711 Training Epoch [25/40] Iter[49/312]		Loss: 0.0973
2019-10-29 00:46:05,832 Training Epoch [25/40] Iter[50/312]		Loss: 0.0977
2019-10-29 00:46:05,953 Training Epoch [25/40] Iter[51/312]		Loss: 0.0979
2019-10-29 00:46:06,074 Training Epoch [25/40] Iter[52/312]		Loss: 0.0980
2019-10-29 00:46:06,195 Training Epoch [25/40] Iter[53/312]		Loss: 0.0973
2019-10-29 00:46:06,316 Training Epoch [25/40] Iter[54/312]		Loss: 0.0968
2019-10-29 00:46:06,437 Training Epoch [25/40] Iter[55/312]		Loss: 0.0971
2019-10-29 00:46:06,559 Training Epoch [25/40] Iter[56/312]		Loss: 0.0964
2019-10-29 00:46:06,680 Training Epoch [25/40] Iter[57/312]		Loss: 0.0961
2019-10-29 00:46:06,801 Training Epoch [25/40] Iter[58/312]		Loss: 0.0970
2019-10-29 00:46:06,923 Training Epoch [25/40] Iter[59/312]		Loss: 0.0980
2019-10-29 00:46:07,044 Training Epoch [25/40] Iter[60/312]		Loss: 0.0979
2019-10-29 00:46:07,166 Training Epoch [25/40] Iter[61/312]		Loss: 0.0975
2019-10-29 00:46:07,288 Training Epoch [25/40] Iter[62/312]		Loss: 0.0974
2019-10-29 00:46:07,409 Training Epoch [25/40] Iter[63/312]		Loss: 0.0977
2019-10-29 00:46:07,531 Training Epoch [25/40] Iter[64/312]		Loss: 0.0980
2019-10-29 00:46:07,652 Training Epoch [25/40] Iter[65/312]		Loss: 0.0977
2019-10-29 00:46:07,774 Training Epoch [25/40] Iter[66/312]		Loss: 0.0977
2019-10-29 00:46:07,895 Training Epoch [25/40] Iter[67/312]		Loss: 0.0981
2019-10-29 00:46:08,017 Training Epoch [25/40] Iter[68/312]		Loss: 0.0979
2019-10-29 00:46:08,138 Training Epoch [25/40] Iter[69/312]		Loss: 0.0980
2019-10-29 00:46:08,259 Training Epoch [25/40] Iter[70/312]		Loss: 0.0977
2019-10-29 00:46:08,381 Training Epoch [25/40] Iter[71/312]		Loss: 0.0977
2019-10-29 00:46:08,503 Training Epoch [25/40] Iter[72/312]		Loss: 0.0983
2019-10-29 00:46:08,624 Training Epoch [25/40] Iter[73/312]		Loss: 0.0986
2019-10-29 00:46:08,746 Training Epoch [25/40] Iter[74/312]		Loss: 0.0987
2019-10-29 00:46:08,868 Training Epoch [25/40] Iter[75/312]		Loss: 0.0984
2019-10-29 00:46:08,989 Training Epoch [25/40] Iter[76/312]		Loss: 0.0983
2019-10-29 00:46:09,110 Training Epoch [25/40] Iter[77/312]		Loss: 0.0984
2019-10-29 00:46:09,232 Training Epoch [25/40] Iter[78/312]		Loss: 0.0982
2019-10-29 00:46:09,354 Training Epoch [25/40] Iter[79/312]		Loss: 0.0980
2019-10-29 00:46:09,475 Training Epoch [25/40] Iter[80/312]		Loss: 0.0984
2019-10-29 00:46:09,597 Training Epoch [25/40] Iter[81/312]		Loss: 0.0982
2019-10-29 00:46:09,718 Training Epoch [25/40] Iter[82/312]		Loss: 0.0982
2019-10-29 00:46:09,840 Training Epoch [25/40] Iter[83/312]		Loss: 0.0986
2019-10-29 00:46:09,961 Training Epoch [25/40] Iter[84/312]		Loss: 0.0985
2019-10-29 00:46:10,083 Training Epoch [25/40] Iter[85/312]		Loss: 0.0986
2019-10-29 00:46:10,205 Training Epoch [25/40] Iter[86/312]		Loss: 0.0991
2019-10-29 00:46:10,326 Training Epoch [25/40] Iter[87/312]		Loss: 0.0991
2019-10-29 00:46:10,448 Training Epoch [25/40] Iter[88/312]		Loss: 0.0997
2019-10-29 00:46:10,570 Training Epoch [25/40] Iter[89/312]		Loss: 0.0997
2019-10-29 00:46:10,692 Training Epoch [25/40] Iter[90/312]		Loss: 0.0996
2019-10-29 00:46:10,813 Training Epoch [25/40] Iter[91/312]		Loss: 0.0993
2019-10-29 00:46:10,934 Training Epoch [25/40] Iter[92/312]		Loss: 0.0991
2019-10-29 00:46:11,056 Training Epoch [25/40] Iter[93/312]		Loss: 0.0993
2019-10-29 00:46:11,177 Training Epoch [25/40] Iter[94/312]		Loss: 0.0989
2019-10-29 00:46:11,298 Training Epoch [25/40] Iter[95/312]		Loss: 0.0993
2019-10-29 00:46:11,420 Training Epoch [25/40] Iter[96/312]		Loss: 0.0999
2019-10-29 00:46:11,541 Training Epoch [25/40] Iter[97/312]		Loss: 0.0999
2019-10-29 00:46:11,663 Training Epoch [25/40] Iter[98/312]		Loss: 0.0998
2019-10-29 00:46:11,784 Training Epoch [25/40] Iter[99/312]		Loss: 0.0994
2019-10-29 00:46:11,905 Training Epoch [25/40] Iter[100/312]		Loss: 0.0992
2019-10-29 00:46:12,026 Training Epoch [25/40] Iter[101/312]		Loss: 0.0990
2019-10-29 00:46:12,147 Training Epoch [25/40] Iter[102/312]		Loss: 0.0989
2019-10-29 00:46:12,269 Training Epoch [25/40] Iter[103/312]		Loss: 0.0988
2019-10-29 00:46:12,390 Training Epoch [25/40] Iter[104/312]		Loss: 0.0986
2019-10-29 00:46:12,512 Training Epoch [25/40] Iter[105/312]		Loss: 0.0987
2019-10-29 00:46:12,634 Training Epoch [25/40] Iter[106/312]		Loss: 0.0985
2019-10-29 00:46:12,756 Training Epoch [25/40] Iter[107/312]		Loss: 0.0984
2019-10-29 00:46:12,878 Training Epoch [25/40] Iter[108/312]		Loss: 0.0984
2019-10-29 00:46:12,999 Training Epoch [25/40] Iter[109/312]		Loss: 0.0987
2019-10-29 00:46:13,121 Training Epoch [25/40] Iter[110/312]		Loss: 0.0986
2019-10-29 00:46:13,242 Training Epoch [25/40] Iter[111/312]		Loss: 0.0987
2019-10-29 00:46:13,364 Training Epoch [25/40] Iter[112/312]		Loss: 0.0989
2019-10-29 00:46:13,486 Training Epoch [25/40] Iter[113/312]		Loss: 0.0988
2019-10-29 00:46:13,607 Training Epoch [25/40] Iter[114/312]		Loss: 0.0989
2019-10-29 00:46:13,729 Training Epoch [25/40] Iter[115/312]		Loss: 0.0990
2019-10-29 00:46:13,851 Training Epoch [25/40] Iter[116/312]		Loss: 0.0994
2019-10-29 00:46:13,973 Training Epoch [25/40] Iter[117/312]		Loss: 0.0996
2019-10-29 00:46:14,094 Training Epoch [25/40] Iter[118/312]		Loss: 0.1001
2019-10-29 00:46:14,215 Training Epoch [25/40] Iter[119/312]		Loss: 0.1005
2019-10-29 00:46:14,337 Training Epoch [25/40] Iter[120/312]		Loss: 0.1006
2019-10-29 00:46:14,458 Training Epoch [25/40] Iter[121/312]		Loss: 0.1006
2019-10-29 00:46:14,580 Training Epoch [25/40] Iter[122/312]		Loss: 0.1007
2019-10-29 00:46:14,701 Training Epoch [25/40] Iter[123/312]		Loss: 0.1009
2019-10-29 00:46:14,822 Training Epoch [25/40] Iter[124/312]		Loss: 0.1009
2019-10-29 00:46:14,943 Training Epoch [25/40] Iter[125/312]		Loss: 0.1009
2019-10-29 00:46:15,065 Training Epoch [25/40] Iter[126/312]		Loss: 0.1006
2019-10-29 00:46:15,186 Training Epoch [25/40] Iter[127/312]		Loss: 0.1006
2019-10-29 00:46:15,308 Training Epoch [25/40] Iter[128/312]		Loss: 0.1008
2019-10-29 00:46:15,429 Training Epoch [25/40] Iter[129/312]		Loss: 0.1010
2019-10-29 00:46:15,551 Training Epoch [25/40] Iter[130/312]		Loss: 0.1011
2019-10-29 00:46:15,672 Training Epoch [25/40] Iter[131/312]		Loss: 0.1010
2019-10-29 00:46:15,795 Training Epoch [25/40] Iter[132/312]		Loss: 0.1010
2019-10-29 00:46:15,916 Training Epoch [25/40] Iter[133/312]		Loss: 0.1010
2019-10-29 00:46:16,038 Training Epoch [25/40] Iter[134/312]		Loss: 0.1008
2019-10-29 00:46:16,160 Training Epoch [25/40] Iter[135/312]		Loss: 0.1006
2019-10-29 00:46:16,281 Training Epoch [25/40] Iter[136/312]		Loss: 0.1005
2019-10-29 00:46:16,403 Training Epoch [25/40] Iter[137/312]		Loss: 0.1004
2019-10-29 00:46:16,524 Training Epoch [25/40] Iter[138/312]		Loss: 0.1006
2019-10-29 00:46:16,646 Training Epoch [25/40] Iter[139/312]		Loss: 0.1005
2019-10-29 00:46:16,767 Training Epoch [25/40] Iter[140/312]		Loss: 0.1005
2019-10-29 00:46:16,889 Training Epoch [25/40] Iter[141/312]		Loss: 0.1007
2019-10-29 00:46:17,011 Training Epoch [25/40] Iter[142/312]		Loss: 0.1009
2019-10-29 00:46:17,132 Training Epoch [25/40] Iter[143/312]		Loss: 0.1009
2019-10-29 00:46:17,254 Training Epoch [25/40] Iter[144/312]		Loss: 0.1009
2019-10-29 00:46:17,375 Training Epoch [25/40] Iter[145/312]		Loss: 0.1008
2019-10-29 00:46:17,497 Training Epoch [25/40] Iter[146/312]		Loss: 0.1006
2019-10-29 00:46:17,618 Training Epoch [25/40] Iter[147/312]		Loss: 0.1009
2019-10-29 00:46:17,740 Training Epoch [25/40] Iter[148/312]		Loss: 0.1007
2019-10-29 00:46:17,861 Training Epoch [25/40] Iter[149/312]		Loss: 0.1009
2019-10-29 00:46:17,982 Training Epoch [25/40] Iter[150/312]		Loss: 0.1013
2019-10-29 00:46:18,103 Training Epoch [25/40] Iter[151/312]		Loss: 0.1011
2019-10-29 00:46:18,225 Training Epoch [25/40] Iter[152/312]		Loss: 0.1014
2019-10-29 00:46:18,346 Training Epoch [25/40] Iter[153/312]		Loss: 0.1015
2019-10-29 00:46:18,468 Training Epoch [25/40] Iter[154/312]		Loss: 0.1015
2019-10-29 00:46:18,589 Training Epoch [25/40] Iter[155/312]		Loss: 0.1016
2019-10-29 00:46:18,711 Training Epoch [25/40] Iter[156/312]		Loss: 0.1013
2019-10-29 00:46:18,832 Training Epoch [25/40] Iter[157/312]		Loss: 0.1011
2019-10-29 00:46:18,953 Training Epoch [25/40] Iter[158/312]		Loss: 0.1012
2019-10-29 00:46:19,075 Training Epoch [25/40] Iter[159/312]		Loss: 0.1018
2019-10-29 00:46:19,197 Training Epoch [25/40] Iter[160/312]		Loss: 0.1020
2019-10-29 00:46:19,318 Training Epoch [25/40] Iter[161/312]		Loss: 0.1021
2019-10-29 00:46:19,439 Training Epoch [25/40] Iter[162/312]		Loss: 0.1021
2019-10-29 00:46:19,562 Training Epoch [25/40] Iter[163/312]		Loss: 0.1021
2019-10-29 00:46:19,684 Training Epoch [25/40] Iter[164/312]		Loss: 0.1022
2019-10-29 00:46:19,805 Training Epoch [25/40] Iter[165/312]		Loss: 0.1021
2019-10-29 00:46:19,926 Training Epoch [25/40] Iter[166/312]		Loss: 0.1020
2019-10-29 00:46:20,047 Training Epoch [25/40] Iter[167/312]		Loss: 0.1018
2019-10-29 00:46:20,168 Training Epoch [25/40] Iter[168/312]		Loss: 0.1018
2019-10-29 00:46:20,290 Training Epoch [25/40] Iter[169/312]		Loss: 0.1023
2019-10-29 00:46:20,411 Training Epoch [25/40] Iter[170/312]		Loss: 0.1023
2019-10-29 00:46:20,532 Training Epoch [25/40] Iter[171/312]		Loss: 0.1021
2019-10-29 00:46:20,653 Training Epoch [25/40] Iter[172/312]		Loss: 0.1019
2019-10-29 00:46:20,774 Training Epoch [25/40] Iter[173/312]		Loss: 0.1019
2019-10-29 00:46:20,895 Training Epoch [25/40] Iter[174/312]		Loss: 0.1019
2019-10-29 00:46:21,017 Training Epoch [25/40] Iter[175/312]		Loss: 0.1020
2019-10-29 00:46:21,138 Training Epoch [25/40] Iter[176/312]		Loss: 0.1020
2019-10-29 00:46:21,260 Training Epoch [25/40] Iter[177/312]		Loss: 0.1020
2019-10-29 00:46:21,382 Training Epoch [25/40] Iter[178/312]		Loss: 0.1018
2019-10-29 00:46:21,503 Training Epoch [25/40] Iter[179/312]		Loss: 0.1016
2019-10-29 00:46:21,625 Training Epoch [25/40] Iter[180/312]		Loss: 0.1016
2019-10-29 00:46:21,746 Training Epoch [25/40] Iter[181/312]		Loss: 0.1017
2019-10-29 00:46:21,868 Training Epoch [25/40] Iter[182/312]		Loss: 0.1016
2019-10-29 00:46:21,990 Training Epoch [25/40] Iter[183/312]		Loss: 0.1015
2019-10-29 00:46:22,111 Training Epoch [25/40] Iter[184/312]		Loss: 0.1014
2019-10-29 00:46:22,233 Training Epoch [25/40] Iter[185/312]		Loss: 0.1014
2019-10-29 00:46:22,355 Training Epoch [25/40] Iter[186/312]		Loss: 0.1013
2019-10-29 00:46:22,477 Training Epoch [25/40] Iter[187/312]		Loss: 0.1011
2019-10-29 00:46:22,598 Training Epoch [25/40] Iter[188/312]		Loss: 0.1010
2019-10-29 00:46:22,719 Training Epoch [25/40] Iter[189/312]		Loss: 0.1009
2019-10-29 00:46:22,841 Training Epoch [25/40] Iter[190/312]		Loss: 0.1008
2019-10-29 00:46:22,962 Training Epoch [25/40] Iter[191/312]		Loss: 0.1007
2019-10-29 00:46:23,084 Training Epoch [25/40] Iter[192/312]		Loss: 0.1008
2019-10-29 00:46:23,205 Training Epoch [25/40] Iter[193/312]		Loss: 0.1014
2019-10-29 00:46:23,326 Training Epoch [25/40] Iter[194/312]		Loss: 0.1016
2019-10-29 00:46:23,448 Training Epoch [25/40] Iter[195/312]		Loss: 0.1018
2019-10-29 00:46:23,569 Training Epoch [25/40] Iter[196/312]		Loss: 0.1019
2019-10-29 00:46:23,690 Training Epoch [25/40] Iter[197/312]		Loss: 0.1021
2019-10-29 00:46:23,811 Training Epoch [25/40] Iter[198/312]		Loss: 0.1021
2019-10-29 00:46:23,932 Training Epoch [25/40] Iter[199/312]		Loss: 0.1019
2019-10-29 00:46:24,054 Training Epoch [25/40] Iter[200/312]		Loss: 0.1021
2019-10-29 00:46:24,175 Training Epoch [25/40] Iter[201/312]		Loss: 0.1022
2019-10-29 00:46:24,298 Training Epoch [25/40] Iter[202/312]		Loss: 0.1022
2019-10-29 00:46:24,419 Training Epoch [25/40] Iter[203/312]		Loss: 0.1022
2019-10-29 00:46:24,541 Training Epoch [25/40] Iter[204/312]		Loss: 0.1020
2019-10-29 00:46:24,664 Training Epoch [25/40] Iter[205/312]		Loss: 0.1020
2019-10-29 00:46:24,785 Training Epoch [25/40] Iter[206/312]		Loss: 0.1021
2019-10-29 00:46:24,907 Training Epoch [25/40] Iter[207/312]		Loss: 0.1021
2019-10-29 00:46:25,029 Training Epoch [25/40] Iter[208/312]		Loss: 0.1020
2019-10-29 00:46:25,150 Training Epoch [25/40] Iter[209/312]		Loss: 0.1021
2019-10-29 00:46:25,272 Training Epoch [25/40] Iter[210/312]		Loss: 0.1020
2019-10-29 00:46:25,393 Training Epoch [25/40] Iter[211/312]		Loss: 0.1021
2019-10-29 00:46:25,515 Training Epoch [25/40] Iter[212/312]		Loss: 0.1021
2019-10-29 00:46:25,637 Training Epoch [25/40] Iter[213/312]		Loss: 0.1022
2019-10-29 00:46:25,759 Training Epoch [25/40] Iter[214/312]		Loss: 0.1022
2019-10-29 00:46:25,881 Training Epoch [25/40] Iter[215/312]		Loss: 0.1021
2019-10-29 00:46:26,002 Training Epoch [25/40] Iter[216/312]		Loss: 0.1023
2019-10-29 00:46:26,124 Training Epoch [25/40] Iter[217/312]		Loss: 0.1022
2019-10-29 00:46:26,246 Training Epoch [25/40] Iter[218/312]		Loss: 0.1021
2019-10-29 00:46:26,367 Training Epoch [25/40] Iter[219/312]		Loss: 0.1020
2019-10-29 00:46:26,489 Training Epoch [25/40] Iter[220/312]		Loss: 0.1023
2019-10-29 00:46:26,610 Training Epoch [25/40] Iter[221/312]		Loss: 0.1021
2019-10-29 00:46:26,731 Training Epoch [25/40] Iter[222/312]		Loss: 0.1022
2019-10-29 00:46:26,853 Training Epoch [25/40] Iter[223/312]		Loss: 0.1023
2019-10-29 00:46:26,974 Training Epoch [25/40] Iter[224/312]		Loss: 0.1023
2019-10-29 00:46:27,096 Training Epoch [25/40] Iter[225/312]		Loss: 0.1025
2019-10-29 00:46:27,217 Training Epoch [25/40] Iter[226/312]		Loss: 0.1024
2019-10-29 00:46:27,338 Training Epoch [25/40] Iter[227/312]		Loss: 0.1025
2019-10-29 00:46:27,459 Training Epoch [25/40] Iter[228/312]		Loss: 0.1027
2019-10-29 00:46:27,581 Training Epoch [25/40] Iter[229/312]		Loss: 0.1028
2019-10-29 00:46:27,703 Training Epoch [25/40] Iter[230/312]		Loss: 0.1030
2019-10-29 00:46:27,825 Training Epoch [25/40] Iter[231/312]		Loss: 0.1031
2019-10-29 00:46:27,946 Training Epoch [25/40] Iter[232/312]		Loss: 0.1029
2019-10-29 00:46:28,068 Training Epoch [25/40] Iter[233/312]		Loss: 0.1029
2019-10-29 00:46:28,189 Training Epoch [25/40] Iter[234/312]		Loss: 0.1029
2019-10-29 00:46:28,310 Training Epoch [25/40] Iter[235/312]		Loss: 0.1028
2019-10-29 00:46:28,431 Training Epoch [25/40] Iter[236/312]		Loss: 0.1031
2019-10-29 00:46:28,552 Training Epoch [25/40] Iter[237/312]		Loss: 0.1031
2019-10-29 00:46:28,673 Training Epoch [25/40] Iter[238/312]		Loss: 0.1033
2019-10-29 00:46:28,794 Training Epoch [25/40] Iter[239/312]		Loss: 0.1032
2019-10-29 00:46:28,916 Training Epoch [25/40] Iter[240/312]		Loss: 0.1033
2019-10-29 00:46:29,037 Training Epoch [25/40] Iter[241/312]		Loss: 0.1033
2019-10-29 00:46:29,157 Training Epoch [25/40] Iter[242/312]		Loss: 0.1032
2019-10-29 00:46:29,279 Training Epoch [25/40] Iter[243/312]		Loss: 0.1033
2019-10-29 00:46:29,401 Training Epoch [25/40] Iter[244/312]		Loss: 0.1033
2019-10-29 00:46:29,523 Training Epoch [25/40] Iter[245/312]		Loss: 0.1034
2019-10-29 00:46:29,645 Training Epoch [25/40] Iter[246/312]		Loss: 0.1034
2019-10-29 00:46:29,767 Training Epoch [25/40] Iter[247/312]		Loss: 0.1033
2019-10-29 00:46:29,888 Training Epoch [25/40] Iter[248/312]		Loss: 0.1031
2019-10-29 00:46:30,009 Training Epoch [25/40] Iter[249/312]		Loss: 0.1031
2019-10-29 00:46:30,131 Training Epoch [25/40] Iter[250/312]		Loss: 0.1031
2019-10-29 00:46:30,253 Training Epoch [25/40] Iter[251/312]		Loss: 0.1030
2019-10-29 00:46:30,375 Training Epoch [25/40] Iter[252/312]		Loss: 0.1031
2019-10-29 00:46:30,497 Training Epoch [25/40] Iter[253/312]		Loss: 0.1032
2019-10-29 00:46:30,619 Training Epoch [25/40] Iter[254/312]		Loss: 0.1032
2019-10-29 00:46:30,740 Training Epoch [25/40] Iter[255/312]		Loss: 0.1032
2019-10-29 00:46:30,862 Training Epoch [25/40] Iter[256/312]		Loss: 0.1032
2019-10-29 00:46:30,984 Training Epoch [25/40] Iter[257/312]		Loss: 0.1031
2019-10-29 00:46:31,106 Training Epoch [25/40] Iter[258/312]		Loss: 0.1029
2019-10-29 00:46:31,227 Training Epoch [25/40] Iter[259/312]		Loss: 0.1031
2019-10-29 00:46:31,348 Training Epoch [25/40] Iter[260/312]		Loss: 0.1030
2019-10-29 00:46:31,470 Training Epoch [25/40] Iter[261/312]		Loss: 0.1034
2019-10-29 00:46:31,591 Training Epoch [25/40] Iter[262/312]		Loss: 0.1034
2019-10-29 00:46:31,712 Training Epoch [25/40] Iter[263/312]		Loss: 0.1034
2019-10-29 00:46:31,834 Training Epoch [25/40] Iter[264/312]		Loss: 0.1033
2019-10-29 00:46:31,955 Training Epoch [25/40] Iter[265/312]		Loss: 0.1033
2019-10-29 00:46:32,077 Training Epoch [25/40] Iter[266/312]		Loss: 0.1033
2019-10-29 00:46:32,198 Training Epoch [25/40] Iter[267/312]		Loss: 0.1034
2019-10-29 00:46:32,320 Training Epoch [25/40] Iter[268/312]		Loss: 0.1034
2019-10-29 00:46:32,441 Training Epoch [25/40] Iter[269/312]		Loss: 0.1033
2019-10-29 00:46:32,563 Training Epoch [25/40] Iter[270/312]		Loss: 0.1032
2019-10-29 00:46:32,685 Training Epoch [25/40] Iter[271/312]		Loss: 0.1033
2019-10-29 00:46:32,807 Training Epoch [25/40] Iter[272/312]		Loss: 0.1033
2019-10-29 00:46:32,929 Training Epoch [25/40] Iter[273/312]		Loss: 0.1035
2019-10-29 00:46:33,050 Training Epoch [25/40] Iter[274/312]		Loss: 0.1034
2019-10-29 00:46:33,172 Training Epoch [25/40] Iter[275/312]		Loss: 0.1033
2019-10-29 00:46:33,293 Training Epoch [25/40] Iter[276/312]		Loss: 0.1035
2019-10-29 00:46:33,415 Training Epoch [25/40] Iter[277/312]		Loss: 0.1035
2019-10-29 00:46:33,536 Training Epoch [25/40] Iter[278/312]		Loss: 0.1035
2019-10-29 00:46:33,657 Training Epoch [25/40] Iter[279/312]		Loss: 0.1035
2019-10-29 00:46:33,778 Training Epoch [25/40] Iter[280/312]		Loss: 0.1034
2019-10-29 00:46:33,900 Training Epoch [25/40] Iter[281/312]		Loss: 0.1034
2019-10-29 00:46:34,022 Training Epoch [25/40] Iter[282/312]		Loss: 0.1034
2019-10-29 00:46:34,143 Training Epoch [25/40] Iter[283/312]		Loss: 0.1034
2019-10-29 00:46:34,265 Training Epoch [25/40] Iter[284/312]		Loss: 0.1032
2019-10-29 00:46:34,386 Training Epoch [25/40] Iter[285/312]		Loss: 0.1032
2019-10-29 00:46:34,508 Training Epoch [25/40] Iter[286/312]		Loss: 0.1032
2019-10-29 00:46:34,630 Training Epoch [25/40] Iter[287/312]		Loss: 0.1031
2019-10-29 00:46:34,752 Training Epoch [25/40] Iter[288/312]		Loss: 0.1030
2019-10-29 00:46:34,873 Training Epoch [25/40] Iter[289/312]		Loss: 0.1030
2019-10-29 00:46:34,996 Training Epoch [25/40] Iter[290/312]		Loss: 0.1030
2019-10-29 00:46:35,117 Training Epoch [25/40] Iter[291/312]		Loss: 0.1031
2019-10-29 00:46:35,238 Training Epoch [25/40] Iter[292/312]		Loss: 0.1031
2019-10-29 00:46:35,360 Training Epoch [25/40] Iter[293/312]		Loss: 0.1031
2019-10-29 00:46:35,481 Training Epoch [25/40] Iter[294/312]		Loss: 0.1031
2019-10-29 00:46:35,603 Training Epoch [25/40] Iter[295/312]		Loss: 0.1030
2019-10-29 00:46:35,724 Training Epoch [25/40] Iter[296/312]		Loss: 0.1031
2019-10-29 00:46:35,846 Training Epoch [25/40] Iter[297/312]		Loss: 0.1032
2019-10-29 00:46:35,967 Training Epoch [25/40] Iter[298/312]		Loss: 0.1031
2019-10-29 00:46:36,089 Training Epoch [25/40] Iter[299/312]		Loss: 0.1033
2019-10-29 00:46:36,211 Training Epoch [25/40] Iter[300/312]		Loss: 0.1033
2019-10-29 00:46:36,332 Training Epoch [25/40] Iter[301/312]		Loss: 0.1031
2019-10-29 00:46:36,454 Training Epoch [25/40] Iter[302/312]		Loss: 0.1033
2019-10-29 00:46:36,575 Training Epoch [25/40] Iter[303/312]		Loss: 0.1033
2019-10-29 00:46:36,696 Training Epoch [25/40] Iter[304/312]		Loss: 0.1033
2019-10-29 00:46:36,817 Training Epoch [25/40] Iter[305/312]		Loss: 0.1032
2019-10-29 00:46:36,937 Training Epoch [25/40] Iter[306/312]		Loss: 0.1036
2019-10-29 00:46:37,058 Training Epoch [25/40] Iter[307/312]		Loss: 0.1036
2019-10-29 00:46:37,178 Training Epoch [25/40] Iter[308/312]		Loss: 0.1035
2019-10-29 00:46:37,299 Training Epoch [25/40] Iter[309/312]		Loss: 0.1035
2019-10-29 00:46:37,420 Training Epoch [25/40] Iter[310/312]		Loss: 0.1035
2019-10-29 00:46:37,540 Training Epoch [25/40] Iter[311/312]		Loss: 0.1035
2019-10-29 00:46:37,600 Training Epoch [25/40] Iter[312/312]		Loss: 0.1036
2019-10-29 00:46:38,001 Testing Epoch [25/40] Iter[0/62]		Loss: 0.0913
2019-10-29 00:46:38,038 Testing Epoch [25/40] Iter[1/62]		Loss: 0.1258
2019-10-29 00:46:38,070 Testing Epoch [25/40] Iter[2/62]		Loss: 0.1180
2019-10-29 00:46:38,102 Testing Epoch [25/40] Iter[3/62]		Loss: 0.1165
2019-10-29 00:46:38,132 Testing Epoch [25/40] Iter[4/62]		Loss: 0.1110
2019-10-29 00:46:38,166 Testing Epoch [25/40] Iter[5/62]		Loss: 0.1079
2019-10-29 00:46:38,196 Testing Epoch [25/40] Iter[6/62]		Loss: 0.1093
2019-10-29 00:46:38,230 Testing Epoch [25/40] Iter[7/62]		Loss: 0.1154
2019-10-29 00:46:38,260 Testing Epoch [25/40] Iter[8/62]		Loss: 0.1214
2019-10-29 00:46:38,291 Testing Epoch [25/40] Iter[9/62]		Loss: 0.1193
2019-10-29 00:46:38,326 Testing Epoch [25/40] Iter[10/62]		Loss: 0.1173
2019-10-29 00:46:38,357 Testing Epoch [25/40] Iter[11/62]		Loss: 0.1219
2019-10-29 00:46:38,388 Testing Epoch [25/40] Iter[12/62]		Loss: 0.1224
2019-10-29 00:46:38,426 Testing Epoch [25/40] Iter[13/62]		Loss: 0.1244
2019-10-29 00:46:38,457 Testing Epoch [25/40] Iter[14/62]		Loss: 0.1369
2019-10-29 00:46:38,488 Testing Epoch [25/40] Iter[15/62]		Loss: 0.1383
2019-10-29 00:46:38,519 Testing Epoch [25/40] Iter[16/62]		Loss: 0.1363
2019-10-29 00:46:38,551 Testing Epoch [25/40] Iter[17/62]		Loss: 0.1354
2019-10-29 00:46:38,582 Testing Epoch [25/40] Iter[18/62]		Loss: 0.1321
2019-10-29 00:46:38,613 Testing Epoch [25/40] Iter[19/62]		Loss: 0.1301
2019-10-29 00:46:38,644 Testing Epoch [25/40] Iter[20/62]		Loss: 0.1318
2019-10-29 00:46:38,675 Testing Epoch [25/40] Iter[21/62]		Loss: 0.1298
2019-10-29 00:46:38,706 Testing Epoch [25/40] Iter[22/62]		Loss: 0.1294
2019-10-29 00:46:38,737 Testing Epoch [25/40] Iter[23/62]		Loss: 0.1296
2019-10-29 00:46:38,769 Testing Epoch [25/40] Iter[24/62]		Loss: 0.1318
2019-10-29 00:46:38,800 Testing Epoch [25/40] Iter[25/62]		Loss: 0.1312
2019-10-29 00:46:38,831 Testing Epoch [25/40] Iter[26/62]		Loss: 0.1301
2019-10-29 00:46:38,862 Testing Epoch [25/40] Iter[27/62]		Loss: 0.1344
2019-10-29 00:46:38,893 Testing Epoch [25/40] Iter[28/62]		Loss: 0.1361
2019-10-29 00:46:38,924 Testing Epoch [25/40] Iter[29/62]		Loss: 0.1361
2019-10-29 00:46:38,955 Testing Epoch [25/40] Iter[30/62]		Loss: 0.1379
2019-10-29 00:46:38,986 Testing Epoch [25/40] Iter[31/62]		Loss: 0.1373
2019-10-29 00:46:39,017 Testing Epoch [25/40] Iter[32/62]		Loss: 0.1390
2019-10-29 00:46:39,048 Testing Epoch [25/40] Iter[33/62]		Loss: 0.1371
2019-10-29 00:46:39,079 Testing Epoch [25/40] Iter[34/62]		Loss: 0.1388
2019-10-29 00:46:39,110 Testing Epoch [25/40] Iter[35/62]		Loss: 0.1392
2019-10-29 00:46:39,143 Testing Epoch [25/40] Iter[36/62]		Loss: 0.1374
2019-10-29 00:46:39,174 Testing Epoch [25/40] Iter[37/62]		Loss: 0.1371
2019-10-29 00:46:39,205 Testing Epoch [25/40] Iter[38/62]		Loss: 0.1373
2019-10-29 00:46:39,236 Testing Epoch [25/40] Iter[39/62]		Loss: 0.1378
2019-10-29 00:46:39,267 Testing Epoch [25/40] Iter[40/62]		Loss: 0.1383
2019-10-29 00:46:39,299 Testing Epoch [25/40] Iter[41/62]		Loss: 0.1384
2019-10-29 00:46:39,329 Testing Epoch [25/40] Iter[42/62]		Loss: 0.1369
2019-10-29 00:46:39,360 Testing Epoch [25/40] Iter[43/62]		Loss: 0.1364
2019-10-29 00:46:39,391 Testing Epoch [25/40] Iter[44/62]		Loss: 0.1352
2019-10-29 00:46:39,422 Testing Epoch [25/40] Iter[45/62]		Loss: 0.1361
2019-10-29 00:46:39,452 Testing Epoch [25/40] Iter[46/62]		Loss: 0.1364
2019-10-29 00:46:39,483 Testing Epoch [25/40] Iter[47/62]		Loss: 0.1413
2019-10-29 00:46:39,514 Testing Epoch [25/40] Iter[48/62]		Loss: 0.1403
2019-10-29 00:46:39,545 Testing Epoch [25/40] Iter[49/62]		Loss: 0.1417
2019-10-29 00:46:39,576 Testing Epoch [25/40] Iter[50/62]		Loss: 0.1413
2019-10-29 00:46:39,606 Testing Epoch [25/40] Iter[51/62]		Loss: 0.1414
2019-10-29 00:46:39,637 Testing Epoch [25/40] Iter[52/62]		Loss: 0.1403
2019-10-29 00:46:39,668 Testing Epoch [25/40] Iter[53/62]		Loss: 0.1401
2019-10-29 00:46:39,699 Testing Epoch [25/40] Iter[54/62]		Loss: 0.1394
2019-10-29 00:46:39,729 Testing Epoch [25/40] Iter[55/62]		Loss: 0.1394
2019-10-29 00:46:39,760 Testing Epoch [25/40] Iter[56/62]		Loss: 0.1393
2019-10-29 00:46:39,790 Testing Epoch [25/40] Iter[57/62]		Loss: 0.1391
2019-10-29 00:46:39,821 Testing Epoch [25/40] Iter[58/62]		Loss: 0.1386
2019-10-29 00:46:39,851 Testing Epoch [25/40] Iter[59/62]		Loss: 0.1387
2019-10-29 00:46:39,881 Testing Epoch [25/40] Iter[60/62]		Loss: 0.1380
2019-10-29 00:46:39,912 Testing Epoch [25/40] Iter[61/62]		Loss: 0.1378
2019-10-29 00:46:39,929 Testing Epoch [25/40] Iter[62/62]		Loss: 0.1387
2019-10-29 00:46:39,996 Saving the Model
2019-10-29 00:46:40,417 Training Epoch [26/40] Iter[0/312]		Loss: 0.1104
2019-10-29 00:46:40,541 Training Epoch [26/40] Iter[1/312]		Loss: 0.1191
2019-10-29 00:46:40,661 Training Epoch [26/40] Iter[2/312]		Loss: 0.1170
2019-10-29 00:46:40,781 Training Epoch [26/40] Iter[3/312]		Loss: 0.1092
2019-10-29 00:46:40,902 Training Epoch [26/40] Iter[4/312]		Loss: 0.0988
2019-10-29 00:46:41,026 Training Epoch [26/40] Iter[5/312]		Loss: 0.0990
2019-10-29 00:46:41,147 Training Epoch [26/40] Iter[6/312]		Loss: 0.0938
2019-10-29 00:46:41,268 Training Epoch [26/40] Iter[7/312]		Loss: 0.0957
2019-10-29 00:46:41,389 Training Epoch [26/40] Iter[8/312]		Loss: 0.0997
2019-10-29 00:46:41,510 Training Epoch [26/40] Iter[9/312]		Loss: 0.1053
2019-10-29 00:46:41,632 Training Epoch [26/40] Iter[10/312]		Loss: 0.1071
2019-10-29 00:46:41,754 Training Epoch [26/40] Iter[11/312]		Loss: 0.1067
2019-10-29 00:46:41,875 Training Epoch [26/40] Iter[12/312]		Loss: 0.1082
2019-10-29 00:46:41,997 Training Epoch [26/40] Iter[13/312]		Loss: 0.1051
2019-10-29 00:46:42,118 Training Epoch [26/40] Iter[14/312]		Loss: 0.1052
2019-10-29 00:46:42,240 Training Epoch [26/40] Iter[15/312]		Loss: 0.1062
2019-10-29 00:46:42,362 Training Epoch [26/40] Iter[16/312]		Loss: 0.1058
2019-10-29 00:46:42,484 Training Epoch [26/40] Iter[17/312]		Loss: 0.1056
2019-10-29 00:46:42,606 Training Epoch [26/40] Iter[18/312]		Loss: 0.1091
2019-10-29 00:46:42,727 Training Epoch [26/40] Iter[19/312]		Loss: 0.1090
2019-10-29 00:46:42,849 Training Epoch [26/40] Iter[20/312]		Loss: 0.1077
2019-10-29 00:46:42,971 Training Epoch [26/40] Iter[21/312]		Loss: 0.1067
2019-10-29 00:46:43,092 Training Epoch [26/40] Iter[22/312]		Loss: 0.1066
2019-10-29 00:46:43,214 Training Epoch [26/40] Iter[23/312]		Loss: 0.1061
2019-10-29 00:46:43,335 Training Epoch [26/40] Iter[24/312]		Loss: 0.1047
2019-10-29 00:46:43,457 Training Epoch [26/40] Iter[25/312]		Loss: 0.1030
2019-10-29 00:46:43,579 Training Epoch [26/40] Iter[26/312]		Loss: 0.1030
2019-10-29 00:46:43,700 Training Epoch [26/40] Iter[27/312]		Loss: 0.1037
2019-10-29 00:46:43,821 Training Epoch [26/40] Iter[28/312]		Loss: 0.1022
2019-10-29 00:46:43,943 Training Epoch [26/40] Iter[29/312]		Loss: 0.1023
2019-10-29 00:46:44,064 Training Epoch [26/40] Iter[30/312]		Loss: 0.1022
2019-10-29 00:46:44,186 Training Epoch [26/40] Iter[31/312]		Loss: 0.1017
2019-10-29 00:46:44,307 Training Epoch [26/40] Iter[32/312]		Loss: 0.1026
2019-10-29 00:46:44,429 Training Epoch [26/40] Iter[33/312]		Loss: 0.1017
2019-10-29 00:46:44,551 Training Epoch [26/40] Iter[34/312]		Loss: 0.1010
2019-10-29 00:46:44,673 Training Epoch [26/40] Iter[35/312]		Loss: 0.1016
2019-10-29 00:46:44,794 Training Epoch [26/40] Iter[36/312]		Loss: 0.1022
2019-10-29 00:46:44,916 Training Epoch [26/40] Iter[37/312]		Loss: 0.1016
2019-10-29 00:46:45,038 Training Epoch [26/40] Iter[38/312]		Loss: 0.1023
2019-10-29 00:46:45,159 Training Epoch [26/40] Iter[39/312]		Loss: 0.1033
2019-10-29 00:46:45,280 Training Epoch [26/40] Iter[40/312]		Loss: 0.1025
2019-10-29 00:46:45,401 Training Epoch [26/40] Iter[41/312]		Loss: 0.1026
2019-10-29 00:46:45,522 Training Epoch [26/40] Iter[42/312]		Loss: 0.1031
2019-10-29 00:46:45,643 Training Epoch [26/40] Iter[43/312]		Loss: 0.1026
2019-10-29 00:46:45,764 Training Epoch [26/40] Iter[44/312]		Loss: 0.1021
2019-10-29 00:46:45,886 Training Epoch [26/40] Iter[45/312]		Loss: 0.1026
2019-10-29 00:46:46,008 Training Epoch [26/40] Iter[46/312]		Loss: 0.1020
2019-10-29 00:46:46,129 Training Epoch [26/40] Iter[47/312]		Loss: 0.1012
2019-10-29 00:46:46,251 Training Epoch [26/40] Iter[48/312]		Loss: 0.1010
2019-10-29 00:46:46,376 Training Epoch [26/40] Iter[49/312]		Loss: 0.1010
2019-10-29 00:46:46,498 Training Epoch [26/40] Iter[50/312]		Loss: 0.1008
2019-10-29 00:46:46,624 Training Epoch [26/40] Iter[51/312]		Loss: 0.1004
2019-10-29 00:46:46,746 Training Epoch [26/40] Iter[52/312]		Loss: 0.0998
2019-10-29 00:46:46,872 Training Epoch [26/40] Iter[53/312]		Loss: 0.0997
2019-10-29 00:46:46,993 Training Epoch [26/40] Iter[54/312]		Loss: 0.1009
2019-10-29 00:46:47,120 Training Epoch [26/40] Iter[55/312]		Loss: 0.1005
2019-10-29 00:46:47,242 Training Epoch [26/40] Iter[56/312]		Loss: 0.1001
2019-10-29 00:46:47,363 Training Epoch [26/40] Iter[57/312]		Loss: 0.1010
2019-10-29 00:46:47,485 Training Epoch [26/40] Iter[58/312]		Loss: 0.1013
2019-10-29 00:46:47,607 Training Epoch [26/40] Iter[59/312]		Loss: 0.1018
2019-10-29 00:46:47,729 Training Epoch [26/40] Iter[60/312]		Loss: 0.1018
2019-10-29 00:46:47,850 Training Epoch [26/40] Iter[61/312]		Loss: 0.1014
2019-10-29 00:46:47,972 Training Epoch [26/40] Iter[62/312]		Loss: 0.1017
2019-10-29 00:46:48,093 Training Epoch [26/40] Iter[63/312]		Loss: 0.1014
2019-10-29 00:46:48,215 Training Epoch [26/40] Iter[64/312]		Loss: 0.1015
2019-10-29 00:46:48,336 Training Epoch [26/40] Iter[65/312]		Loss: 0.1014
2019-10-29 00:46:48,457 Training Epoch [26/40] Iter[66/312]		Loss: 0.1015
2019-10-29 00:46:48,579 Training Epoch [26/40] Iter[67/312]		Loss: 0.1017
2019-10-29 00:46:48,700 Training Epoch [26/40] Iter[68/312]		Loss: 0.1018
2019-10-29 00:46:48,821 Training Epoch [26/40] Iter[69/312]		Loss: 0.1016
2019-10-29 00:46:48,943 Training Epoch [26/40] Iter[70/312]		Loss: 0.1015
2019-10-29 00:46:49,064 Training Epoch [26/40] Iter[71/312]		Loss: 0.1026
2019-10-29 00:46:49,185 Training Epoch [26/40] Iter[72/312]		Loss: 0.1024
2019-10-29 00:46:49,307 Training Epoch [26/40] Iter[73/312]		Loss: 0.1022
2019-10-29 00:46:49,429 Training Epoch [26/40] Iter[74/312]		Loss: 0.1020
2019-10-29 00:46:49,550 Training Epoch [26/40] Iter[75/312]		Loss: 0.1018
2019-10-29 00:46:49,672 Training Epoch [26/40] Iter[76/312]		Loss: 0.1018
2019-10-29 00:46:49,794 Training Epoch [26/40] Iter[77/312]		Loss: 0.1016
2019-10-29 00:46:49,915 Training Epoch [26/40] Iter[78/312]		Loss: 0.1014
2019-10-29 00:46:50,036 Training Epoch [26/40] Iter[79/312]		Loss: 0.1011
2019-10-29 00:46:50,158 Training Epoch [26/40] Iter[80/312]		Loss: 0.1020
2019-10-29 00:46:50,280 Training Epoch [26/40] Iter[81/312]		Loss: 0.1017
2019-10-29 00:46:50,402 Training Epoch [26/40] Iter[82/312]		Loss: 0.1017
2019-10-29 00:46:50,523 Training Epoch [26/40] Iter[83/312]		Loss: 0.1015
2019-10-29 00:46:50,644 Training Epoch [26/40] Iter[84/312]		Loss: 0.1015
2019-10-29 00:46:50,765 Training Epoch [26/40] Iter[85/312]		Loss: 0.1018
2019-10-29 00:46:50,887 Training Epoch [26/40] Iter[86/312]		Loss: 0.1020
2019-10-29 00:46:51,009 Training Epoch [26/40] Iter[87/312]		Loss: 0.1020
2019-10-29 00:46:51,131 Training Epoch [26/40] Iter[88/312]		Loss: 0.1016
2019-10-29 00:46:51,252 Training Epoch [26/40] Iter[89/312]		Loss: 0.1013
2019-10-29 00:46:51,373 Training Epoch [26/40] Iter[90/312]		Loss: 0.1024
2019-10-29 00:46:51,495 Training Epoch [26/40] Iter[91/312]		Loss: 0.1030
2019-10-29 00:46:51,616 Training Epoch [26/40] Iter[92/312]		Loss: 0.1032
2019-10-29 00:46:51,738 Training Epoch [26/40] Iter[93/312]		Loss: 0.1028
2019-10-29 00:46:51,859 Training Epoch [26/40] Iter[94/312]		Loss: 0.1030
2019-10-29 00:46:51,981 Training Epoch [26/40] Iter[95/312]		Loss: 0.1032
2019-10-29 00:46:52,102 Training Epoch [26/40] Iter[96/312]		Loss: 0.1030
2019-10-29 00:46:52,224 Training Epoch [26/40] Iter[97/312]		Loss: 0.1037
2019-10-29 00:46:52,345 Training Epoch [26/40] Iter[98/312]		Loss: 0.1036
2019-10-29 00:46:52,466 Training Epoch [26/40] Iter[99/312]		Loss: 0.1035
2019-10-29 00:46:52,588 Training Epoch [26/40] Iter[100/312]		Loss: 0.1036
2019-10-29 00:46:52,709 Training Epoch [26/40] Iter[101/312]		Loss: 0.1038
2019-10-29 00:46:52,831 Training Epoch [26/40] Iter[102/312]		Loss: 0.1036
2019-10-29 00:46:52,957 Training Epoch [26/40] Iter[103/312]		Loss: 0.1038
2019-10-29 00:46:53,079 Training Epoch [26/40] Iter[104/312]		Loss: 0.1035
2019-10-29 00:46:53,201 Training Epoch [26/40] Iter[105/312]		Loss: 0.1037
2019-10-29 00:46:53,322 Training Epoch [26/40] Iter[106/312]		Loss: 0.1040
2019-10-29 00:46:53,443 Training Epoch [26/40] Iter[107/312]		Loss: 0.1044
2019-10-29 00:46:53,564 Training Epoch [26/40] Iter[108/312]		Loss: 0.1045
2019-10-29 00:46:53,685 Training Epoch [26/40] Iter[109/312]		Loss: 0.1045
2019-10-29 00:46:53,806 Training Epoch [26/40] Iter[110/312]		Loss: 0.1048
2019-10-29 00:46:53,927 Training Epoch [26/40] Iter[111/312]		Loss: 0.1047
2019-10-29 00:46:54,049 Training Epoch [26/40] Iter[112/312]		Loss: 0.1048
2019-10-29 00:46:54,170 Training Epoch [26/40] Iter[113/312]		Loss: 0.1049
2019-10-29 00:46:54,291 Training Epoch [26/40] Iter[114/312]		Loss: 0.1047
2019-10-29 00:46:54,412 Training Epoch [26/40] Iter[115/312]		Loss: 0.1049
2019-10-29 00:46:54,533 Training Epoch [26/40] Iter[116/312]		Loss: 0.1046
2019-10-29 00:46:54,655 Training Epoch [26/40] Iter[117/312]		Loss: 0.1050
2019-10-29 00:46:54,776 Training Epoch [26/40] Iter[118/312]		Loss: 0.1051
2019-10-29 00:46:54,897 Training Epoch [26/40] Iter[119/312]		Loss: 0.1060
2019-10-29 00:46:55,019 Training Epoch [26/40] Iter[120/312]		Loss: 0.1059
2019-10-29 00:46:55,145 Training Epoch [26/40] Iter[121/312]		Loss: 0.1056
2019-10-29 00:46:55,266 Training Epoch [26/40] Iter[122/312]		Loss: 0.1057
2019-10-29 00:46:55,388 Training Epoch [26/40] Iter[123/312]		Loss: 0.1059
2019-10-29 00:46:55,509 Training Epoch [26/40] Iter[124/312]		Loss: 0.1061
2019-10-29 00:46:55,633 Training Epoch [26/40] Iter[125/312]		Loss: 0.1061
2019-10-29 00:46:55,754 Training Epoch [26/40] Iter[126/312]		Loss: 0.1059
2019-10-29 00:46:55,876 Training Epoch [26/40] Iter[127/312]		Loss: 0.1059
2019-10-29 00:46:55,998 Training Epoch [26/40] Iter[128/312]		Loss: 0.1058
2019-10-29 00:46:56,119 Training Epoch [26/40] Iter[129/312]		Loss: 0.1054
2019-10-29 00:46:56,241 Training Epoch [26/40] Iter[130/312]		Loss: 0.1052
2019-10-29 00:46:56,363 Training Epoch [26/40] Iter[131/312]		Loss: 0.1054
2019-10-29 00:46:56,485 Training Epoch [26/40] Iter[132/312]		Loss: 0.1054
2019-10-29 00:46:56,606 Training Epoch [26/40] Iter[133/312]		Loss: 0.1053
2019-10-29 00:46:56,732 Training Epoch [26/40] Iter[134/312]		Loss: 0.1053
2019-10-29 00:46:56,854 Training Epoch [26/40] Iter[135/312]		Loss: 0.1051
2019-10-29 00:46:56,976 Training Epoch [26/40] Iter[136/312]		Loss: 0.1050
2019-10-29 00:46:57,097 Training Epoch [26/40] Iter[137/312]		Loss: 0.1047
2019-10-29 00:46:57,219 Training Epoch [26/40] Iter[138/312]		Loss: 0.1046
2019-10-29 00:46:57,340 Training Epoch [26/40] Iter[139/312]		Loss: 0.1047
2019-10-29 00:46:57,462 Training Epoch [26/40] Iter[140/312]		Loss: 0.1050
2019-10-29 00:46:57,583 Training Epoch [26/40] Iter[141/312]		Loss: 0.1049
2019-10-29 00:46:57,705 Training Epoch [26/40] Iter[142/312]		Loss: 0.1047
2019-10-29 00:46:57,826 Training Epoch [26/40] Iter[143/312]		Loss: 0.1045
2019-10-29 00:46:57,947 Training Epoch [26/40] Iter[144/312]		Loss: 0.1050
2019-10-29 00:46:58,069 Training Epoch [26/40] Iter[145/312]		Loss: 0.1050
2019-10-29 00:46:58,190 Training Epoch [26/40] Iter[146/312]		Loss: 0.1048
2019-10-29 00:46:58,312 Training Epoch [26/40] Iter[147/312]		Loss: 0.1047
2019-10-29 00:46:58,436 Training Epoch [26/40] Iter[148/312]		Loss: 0.1046
2019-10-29 00:46:58,558 Training Epoch [26/40] Iter[149/312]		Loss: 0.1045
2019-10-29 00:46:58,679 Training Epoch [26/40] Iter[150/312]		Loss: 0.1049
2019-10-29 00:46:58,801 Training Epoch [26/40] Iter[151/312]		Loss: 0.1050
2019-10-29 00:46:58,922 Training Epoch [26/40] Iter[152/312]		Loss: 0.1050
2019-10-29 00:46:59,043 Training Epoch [26/40] Iter[153/312]		Loss: 0.1048
2019-10-29 00:46:59,165 Training Epoch [26/40] Iter[154/312]		Loss: 0.1047
2019-10-29 00:46:59,286 Training Epoch [26/40] Iter[155/312]		Loss: 0.1045
2019-10-29 00:46:59,408 Training Epoch [26/40] Iter[156/312]		Loss: 0.1042
2019-10-29 00:46:59,530 Training Epoch [26/40] Iter[157/312]		Loss: 0.1043
2019-10-29 00:46:59,651 Training Epoch [26/40] Iter[158/312]		Loss: 0.1043
2019-10-29 00:46:59,772 Training Epoch [26/40] Iter[159/312]		Loss: 0.1041
2019-10-29 00:46:59,894 Training Epoch [26/40] Iter[160/312]		Loss: 0.1043
2019-10-29 00:47:00,015 Training Epoch [26/40] Iter[161/312]		Loss: 0.1042
2019-10-29 00:47:00,136 Training Epoch [26/40] Iter[162/312]		Loss: 0.1044
2019-10-29 00:47:00,258 Training Epoch [26/40] Iter[163/312]		Loss: 0.1043
2019-10-29 00:47:00,380 Training Epoch [26/40] Iter[164/312]		Loss: 0.1047
2019-10-29 00:47:00,501 Training Epoch [26/40] Iter[165/312]		Loss: 0.1047
2019-10-29 00:47:00,624 Training Epoch [26/40] Iter[166/312]		Loss: 0.1054
2019-10-29 00:47:00,745 Training Epoch [26/40] Iter[167/312]		Loss: 0.1055
2019-10-29 00:47:00,866 Training Epoch [26/40] Iter[168/312]		Loss: 0.1054
2019-10-29 00:47:00,987 Training Epoch [26/40] Iter[169/312]		Loss: 0.1056
2019-10-29 00:47:01,109 Training Epoch [26/40] Iter[170/312]		Loss: 0.1055
2019-10-29 00:47:01,230 Training Epoch [26/40] Iter[171/312]		Loss: 0.1055
2019-10-29 00:47:01,352 Training Epoch [26/40] Iter[172/312]		Loss: 0.1055
2019-10-29 00:47:01,474 Training Epoch [26/40] Iter[173/312]		Loss: 0.1056
2019-10-29 00:47:01,595 Training Epoch [26/40] Iter[174/312]		Loss: 0.1060
2019-10-29 00:47:01,717 Training Epoch [26/40] Iter[175/312]		Loss: 0.1060
2019-10-29 00:47:01,838 Training Epoch [26/40] Iter[176/312]		Loss: 0.1059
2019-10-29 00:47:01,959 Training Epoch [26/40] Iter[177/312]		Loss: 0.1058
2019-10-29 00:47:02,081 Training Epoch [26/40] Iter[178/312]		Loss: 0.1059
2019-10-29 00:47:02,203 Training Epoch [26/40] Iter[179/312]		Loss: 0.1059
2019-10-29 00:47:02,324 Training Epoch [26/40] Iter[180/312]		Loss: 0.1058
2019-10-29 00:47:02,446 Training Epoch [26/40] Iter[181/312]		Loss: 0.1056
2019-10-29 00:47:02,567 Training Epoch [26/40] Iter[182/312]		Loss: 0.1055
2019-10-29 00:47:02,689 Training Epoch [26/40] Iter[183/312]		Loss: 0.1053
2019-10-29 00:47:02,810 Training Epoch [26/40] Iter[184/312]		Loss: 0.1057
2019-10-29 00:47:02,931 Training Epoch [26/40] Iter[185/312]		Loss: 0.1054
2019-10-29 00:47:03,053 Training Epoch [26/40] Iter[186/312]		Loss: 0.1053
2019-10-29 00:47:03,174 Training Epoch [26/40] Iter[187/312]		Loss: 0.1051
2019-10-29 00:47:03,295 Training Epoch [26/40] Iter[188/312]		Loss: 0.1052
2019-10-29 00:47:03,416 Training Epoch [26/40] Iter[189/312]		Loss: 0.1053
2019-10-29 00:47:03,538 Training Epoch [26/40] Iter[190/312]		Loss: 0.1051
2019-10-29 00:47:03,659 Training Epoch [26/40] Iter[191/312]		Loss: 0.1050
2019-10-29 00:47:03,780 Training Epoch [26/40] Iter[192/312]		Loss: 0.1050
2019-10-29 00:47:03,901 Training Epoch [26/40] Iter[193/312]		Loss: 0.1053
2019-10-29 00:47:04,022 Training Epoch [26/40] Iter[194/312]		Loss: 0.1055
2019-10-29 00:47:04,144 Training Epoch [26/40] Iter[195/312]		Loss: 0.1054
2019-10-29 00:47:04,265 Training Epoch [26/40] Iter[196/312]		Loss: 0.1053
2019-10-29 00:47:04,387 Training Epoch [26/40] Iter[197/312]		Loss: 0.1054
2019-10-29 00:47:04,509 Training Epoch [26/40] Iter[198/312]		Loss: 0.1055
2019-10-29 00:47:04,630 Training Epoch [26/40] Iter[199/312]		Loss: 0.1055
2019-10-29 00:47:04,752 Training Epoch [26/40] Iter[200/312]		Loss: 0.1056
2019-10-29 00:47:04,873 Training Epoch [26/40] Iter[201/312]		Loss: 0.1056
2019-10-29 00:47:04,995 Training Epoch [26/40] Iter[202/312]		Loss: 0.1054
2019-10-29 00:47:05,116 Training Epoch [26/40] Iter[203/312]		Loss: 0.1053
2019-10-29 00:47:05,238 Training Epoch [26/40] Iter[204/312]		Loss: 0.1051
2019-10-29 00:47:05,361 Training Epoch [26/40] Iter[205/312]		Loss: 0.1049
2019-10-29 00:47:05,482 Training Epoch [26/40] Iter[206/312]		Loss: 0.1051
2019-10-29 00:47:05,604 Training Epoch [26/40] Iter[207/312]		Loss: 0.1052
2019-10-29 00:47:05,726 Training Epoch [26/40] Iter[208/312]		Loss: 0.1053
2019-10-29 00:47:05,848 Training Epoch [26/40] Iter[209/312]		Loss: 0.1054
2019-10-29 00:47:05,969 Training Epoch [26/40] Iter[210/312]		Loss: 0.1052
2019-10-29 00:47:06,090 Training Epoch [26/40] Iter[211/312]		Loss: 0.1050
2019-10-29 00:47:06,211 Training Epoch [26/40] Iter[212/312]		Loss: 0.1050
2019-10-29 00:47:06,333 Training Epoch [26/40] Iter[213/312]		Loss: 0.1049
2019-10-29 00:47:06,454 Training Epoch [26/40] Iter[214/312]		Loss: 0.1048
2019-10-29 00:47:06,575 Training Epoch [26/40] Iter[215/312]		Loss: 0.1051
2019-10-29 00:47:06,696 Training Epoch [26/40] Iter[216/312]		Loss: 0.1051
2019-10-29 00:47:06,818 Training Epoch [26/40] Iter[217/312]		Loss: 0.1051
2019-10-29 00:47:06,939 Training Epoch [26/40] Iter[218/312]		Loss: 0.1051
2019-10-29 00:47:07,061 Training Epoch [26/40] Iter[219/312]		Loss: 0.1051
2019-10-29 00:47:07,181 Training Epoch [26/40] Iter[220/312]		Loss: 0.1049
2019-10-29 00:47:07,303 Training Epoch [26/40] Iter[221/312]		Loss: 0.1054
2019-10-29 00:47:07,425 Training Epoch [26/40] Iter[222/312]		Loss: 0.1054
2019-10-29 00:47:07,547 Training Epoch [26/40] Iter[223/312]		Loss: 0.1054
2019-10-29 00:47:07,668 Training Epoch [26/40] Iter[224/312]		Loss: 0.1052
2019-10-29 00:47:07,790 Training Epoch [26/40] Iter[225/312]		Loss: 0.1050
2019-10-29 00:47:07,912 Training Epoch [26/40] Iter[226/312]		Loss: 0.1050
2019-10-29 00:47:08,034 Training Epoch [26/40] Iter[227/312]		Loss: 0.1049
2019-10-29 00:47:08,155 Training Epoch [26/40] Iter[228/312]		Loss: 0.1051
2019-10-29 00:47:08,277 Training Epoch [26/40] Iter[229/312]		Loss: 0.1051
2019-10-29 00:47:08,399 Training Epoch [26/40] Iter[230/312]		Loss: 0.1053
2019-10-29 00:47:08,521 Training Epoch [26/40] Iter[231/312]		Loss: 0.1056
2019-10-29 00:47:08,643 Training Epoch [26/40] Iter[232/312]		Loss: 0.1056
2019-10-29 00:47:08,764 Training Epoch [26/40] Iter[233/312]		Loss: 0.1057
2019-10-29 00:47:08,887 Training Epoch [26/40] Iter[234/312]		Loss: 0.1056
2019-10-29 00:47:09,008 Training Epoch [26/40] Iter[235/312]		Loss: 0.1055
2019-10-29 00:47:09,130 Training Epoch [26/40] Iter[236/312]		Loss: 0.1053
2019-10-29 00:47:09,252 Training Epoch [26/40] Iter[237/312]		Loss: 0.1054
2019-10-29 00:47:09,374 Training Epoch [26/40] Iter[238/312]		Loss: 0.1054
2019-10-29 00:47:09,495 Training Epoch [26/40] Iter[239/312]		Loss: 0.1053
2019-10-29 00:47:09,617 Training Epoch [26/40] Iter[240/312]		Loss: 0.1052
2019-10-29 00:47:09,739 Training Epoch [26/40] Iter[241/312]		Loss: 0.1051
2019-10-29 00:47:09,860 Training Epoch [26/40] Iter[242/312]		Loss: 0.1050
2019-10-29 00:47:09,982 Training Epoch [26/40] Iter[243/312]		Loss: 0.1050
2019-10-29 00:47:10,103 Training Epoch [26/40] Iter[244/312]		Loss: 0.1051
2019-10-29 00:47:10,225 Training Epoch [26/40] Iter[245/312]		Loss: 0.1054
2019-10-29 00:47:10,347 Training Epoch [26/40] Iter[246/312]		Loss: 0.1054
2019-10-29 00:47:10,469 Training Epoch [26/40] Iter[247/312]		Loss: 0.1053
2019-10-29 00:47:10,591 Training Epoch [26/40] Iter[248/312]		Loss: 0.1053
2019-10-29 00:47:10,715 Training Epoch [26/40] Iter[249/312]		Loss: 0.1054
2019-10-29 00:47:10,838 Training Epoch [26/40] Iter[250/312]		Loss: 0.1053
2019-10-29 00:47:10,960 Training Epoch [26/40] Iter[251/312]		Loss: 0.1052
2019-10-29 00:47:11,082 Training Epoch [26/40] Iter[252/312]		Loss: 0.1052
2019-10-29 00:47:11,204 Training Epoch [26/40] Iter[253/312]		Loss: 0.1051
2019-10-29 00:47:11,326 Training Epoch [26/40] Iter[254/312]		Loss: 0.1050
2019-10-29 00:47:11,448 Training Epoch [26/40] Iter[255/312]		Loss: 0.1050
2019-10-29 00:47:11,569 Training Epoch [26/40] Iter[256/312]		Loss: 0.1049
2019-10-29 00:47:11,690 Training Epoch [26/40] Iter[257/312]		Loss: 0.1052
2019-10-29 00:47:11,812 Training Epoch [26/40] Iter[258/312]		Loss: 0.1051
2019-10-29 00:47:11,933 Training Epoch [26/40] Iter[259/312]		Loss: 0.1053
2019-10-29 00:47:12,055 Training Epoch [26/40] Iter[260/312]		Loss: 0.1051
2019-10-29 00:47:12,176 Training Epoch [26/40] Iter[261/312]		Loss: 0.1051
2019-10-29 00:47:12,297 Training Epoch [26/40] Iter[262/312]		Loss: 0.1052
2019-10-29 00:47:12,418 Training Epoch [26/40] Iter[263/312]		Loss: 0.1050
2019-10-29 00:47:12,540 Training Epoch [26/40] Iter[264/312]		Loss: 0.1050
2019-10-29 00:47:12,662 Training Epoch [26/40] Iter[265/312]		Loss: 0.1050
2019-10-29 00:47:12,784 Training Epoch [26/40] Iter[266/312]		Loss: 0.1049
2019-10-29 00:47:12,906 Training Epoch [26/40] Iter[267/312]		Loss: 0.1051
2019-10-29 00:47:13,028 Training Epoch [26/40] Iter[268/312]		Loss: 0.1050
2019-10-29 00:47:13,149 Training Epoch [26/40] Iter[269/312]		Loss: 0.1052
2019-10-29 00:47:13,271 Training Epoch [26/40] Iter[270/312]		Loss: 0.1051
2019-10-29 00:47:13,393 Training Epoch [26/40] Iter[271/312]		Loss: 0.1051
2019-10-29 00:47:13,514 Training Epoch [26/40] Iter[272/312]		Loss: 0.1050
2019-10-29 00:47:13,635 Training Epoch [26/40] Iter[273/312]		Loss: 0.1052
2019-10-29 00:47:13,757 Training Epoch [26/40] Iter[274/312]		Loss: 0.1052
2019-10-29 00:47:13,879 Training Epoch [26/40] Iter[275/312]		Loss: 0.1051
2019-10-29 00:47:14,000 Training Epoch [26/40] Iter[276/312]		Loss: 0.1052
2019-10-29 00:47:14,122 Training Epoch [26/40] Iter[277/312]		Loss: 0.1052
2019-10-29 00:47:14,244 Training Epoch [26/40] Iter[278/312]		Loss: 0.1051
2019-10-29 00:47:14,366 Training Epoch [26/40] Iter[279/312]		Loss: 0.1049
2019-10-29 00:47:14,487 Training Epoch [26/40] Iter[280/312]		Loss: 0.1048
2019-10-29 00:47:14,609 Training Epoch [26/40] Iter[281/312]		Loss: 0.1046
2019-10-29 00:47:14,730 Training Epoch [26/40] Iter[282/312]		Loss: 0.1048
2019-10-29 00:47:14,851 Training Epoch [26/40] Iter[283/312]		Loss: 0.1048
2019-10-29 00:47:14,972 Training Epoch [26/40] Iter[284/312]		Loss: 0.1047
2019-10-29 00:47:15,094 Training Epoch [26/40] Iter[285/312]		Loss: 0.1047
2019-10-29 00:47:15,215 Training Epoch [26/40] Iter[286/312]		Loss: 0.1047
2019-10-29 00:47:15,336 Training Epoch [26/40] Iter[287/312]		Loss: 0.1046
2019-10-29 00:47:15,458 Training Epoch [26/40] Iter[288/312]		Loss: 0.1046
2019-10-29 00:47:15,579 Training Epoch [26/40] Iter[289/312]		Loss: 0.1045
2019-10-29 00:47:15,700 Training Epoch [26/40] Iter[290/312]		Loss: 0.1045
2019-10-29 00:47:15,822 Training Epoch [26/40] Iter[291/312]		Loss: 0.1046
2019-10-29 00:47:15,944 Training Epoch [26/40] Iter[292/312]		Loss: 0.1046
2019-10-29 00:47:16,065 Training Epoch [26/40] Iter[293/312]		Loss: 0.1045
2019-10-29 00:47:16,187 Training Epoch [26/40] Iter[294/312]		Loss: 0.1044
2019-10-29 00:47:16,309 Training Epoch [26/40] Iter[295/312]		Loss: 0.1044
2019-10-29 00:47:16,430 Training Epoch [26/40] Iter[296/312]		Loss: 0.1042
2019-10-29 00:47:16,551 Training Epoch [26/40] Iter[297/312]		Loss: 0.1042
2019-10-29 00:47:16,673 Training Epoch [26/40] Iter[298/312]		Loss: 0.1042
2019-10-29 00:47:16,795 Training Epoch [26/40] Iter[299/312]		Loss: 0.1041
2019-10-29 00:47:16,917 Training Epoch [26/40] Iter[300/312]		Loss: 0.1041
2019-10-29 00:47:17,038 Training Epoch [26/40] Iter[301/312]		Loss: 0.1040
2019-10-29 00:47:17,159 Training Epoch [26/40] Iter[302/312]		Loss: 0.1040
2019-10-29 00:47:17,281 Training Epoch [26/40] Iter[303/312]		Loss: 0.1041
2019-10-29 00:47:17,403 Training Epoch [26/40] Iter[304/312]		Loss: 0.1042
2019-10-29 00:47:17,525 Training Epoch [26/40] Iter[305/312]		Loss: 0.1041
2019-10-29 00:47:17,646 Training Epoch [26/40] Iter[306/312]		Loss: 0.1041
2019-10-29 00:47:17,767 Training Epoch [26/40] Iter[307/312]		Loss: 0.1040
2019-10-29 00:47:17,889 Training Epoch [26/40] Iter[308/312]		Loss: 0.1039
2019-10-29 00:47:18,010 Training Epoch [26/40] Iter[309/312]		Loss: 0.1039
2019-10-29 00:47:18,131 Training Epoch [26/40] Iter[310/312]		Loss: 0.1038
2019-10-29 00:47:18,252 Training Epoch [26/40] Iter[311/312]		Loss: 0.1037
2019-10-29 00:47:18,313 Training Epoch [26/40] Iter[312/312]		Loss: 0.1036
2019-10-29 00:47:18,741 Testing Epoch [26/40] Iter[0/62]		Loss: 0.0931
2019-10-29 00:47:18,774 Testing Epoch [26/40] Iter[1/62]		Loss: 0.1261
2019-10-29 00:47:18,804 Testing Epoch [26/40] Iter[2/62]		Loss: 0.1177
2019-10-29 00:47:18,834 Testing Epoch [26/40] Iter[3/62]		Loss: 0.1154
2019-10-29 00:47:18,865 Testing Epoch [26/40] Iter[4/62]		Loss: 0.1111
2019-10-29 00:47:18,898 Testing Epoch [26/40] Iter[5/62]		Loss: 0.1086
2019-10-29 00:47:18,927 Testing Epoch [26/40] Iter[6/62]		Loss: 0.1101
2019-10-29 00:47:18,957 Testing Epoch [26/40] Iter[7/62]		Loss: 0.1159
2019-10-29 00:47:18,990 Testing Epoch [26/40] Iter[8/62]		Loss: 0.1228
2019-10-29 00:47:19,021 Testing Epoch [26/40] Iter[9/62]		Loss: 0.1199
2019-10-29 00:47:19,051 Testing Epoch [26/40] Iter[10/62]		Loss: 0.1177
2019-10-29 00:47:19,086 Testing Epoch [26/40] Iter[11/62]		Loss: 0.1225
2019-10-29 00:47:19,122 Testing Epoch [26/40] Iter[12/62]		Loss: 0.1236
2019-10-29 00:47:19,153 Testing Epoch [26/40] Iter[13/62]		Loss: 0.1257
2019-10-29 00:47:19,184 Testing Epoch [26/40] Iter[14/62]		Loss: 0.1382
2019-10-29 00:47:19,215 Testing Epoch [26/40] Iter[15/62]		Loss: 0.1398
2019-10-29 00:47:19,246 Testing Epoch [26/40] Iter[16/62]		Loss: 0.1381
2019-10-29 00:47:19,277 Testing Epoch [26/40] Iter[17/62]		Loss: 0.1375
2019-10-29 00:47:19,307 Testing Epoch [26/40] Iter[18/62]		Loss: 0.1342
2019-10-29 00:47:19,338 Testing Epoch [26/40] Iter[19/62]		Loss: 0.1320
2019-10-29 00:47:19,369 Testing Epoch [26/40] Iter[20/62]		Loss: 0.1337
2019-10-29 00:47:19,400 Testing Epoch [26/40] Iter[21/62]		Loss: 0.1317
2019-10-29 00:47:19,431 Testing Epoch [26/40] Iter[22/62]		Loss: 0.1311
2019-10-29 00:47:19,462 Testing Epoch [26/40] Iter[23/62]		Loss: 0.1313
2019-10-29 00:47:19,492 Testing Epoch [26/40] Iter[24/62]		Loss: 0.1330
2019-10-29 00:47:19,523 Testing Epoch [26/40] Iter[25/62]		Loss: 0.1322
2019-10-29 00:47:19,554 Testing Epoch [26/40] Iter[26/62]		Loss: 0.1310
2019-10-29 00:47:19,585 Testing Epoch [26/40] Iter[27/62]		Loss: 0.1356
2019-10-29 00:47:19,616 Testing Epoch [26/40] Iter[28/62]		Loss: 0.1375
2019-10-29 00:47:19,646 Testing Epoch [26/40] Iter[29/62]		Loss: 0.1374
2019-10-29 00:47:19,677 Testing Epoch [26/40] Iter[30/62]		Loss: 0.1391
2019-10-29 00:47:19,708 Testing Epoch [26/40] Iter[31/62]		Loss: 0.1383
2019-10-29 00:47:19,739 Testing Epoch [26/40] Iter[32/62]		Loss: 0.1400
2019-10-29 00:47:19,770 Testing Epoch [26/40] Iter[33/62]		Loss: 0.1380
2019-10-29 00:47:19,801 Testing Epoch [26/40] Iter[34/62]		Loss: 0.1394
2019-10-29 00:47:19,832 Testing Epoch [26/40] Iter[35/62]		Loss: 0.1398
2019-10-29 00:47:19,862 Testing Epoch [26/40] Iter[36/62]		Loss: 0.1380
2019-10-29 00:47:19,893 Testing Epoch [26/40] Iter[37/62]		Loss: 0.1377
2019-10-29 00:47:19,924 Testing Epoch [26/40] Iter[38/62]		Loss: 0.1379
2019-10-29 00:47:19,954 Testing Epoch [26/40] Iter[39/62]		Loss: 0.1383
2019-10-29 00:47:19,985 Testing Epoch [26/40] Iter[40/62]		Loss: 0.1387
2019-10-29 00:47:20,016 Testing Epoch [26/40] Iter[41/62]		Loss: 0.1389
2019-10-29 00:47:20,047 Testing Epoch [26/40] Iter[42/62]		Loss: 0.1375
2019-10-29 00:47:20,078 Testing Epoch [26/40] Iter[43/62]		Loss: 0.1369
2019-10-29 00:47:20,108 Testing Epoch [26/40] Iter[44/62]		Loss: 0.1358
2019-10-29 00:47:20,139 Testing Epoch [26/40] Iter[45/62]		Loss: 0.1367
2019-10-29 00:47:20,170 Testing Epoch [26/40] Iter[46/62]		Loss: 0.1367
2019-10-29 00:47:20,200 Testing Epoch [26/40] Iter[47/62]		Loss: 0.1415
2019-10-29 00:47:20,231 Testing Epoch [26/40] Iter[48/62]		Loss: 0.1406
2019-10-29 00:47:20,262 Testing Epoch [26/40] Iter[49/62]		Loss: 0.1421
2019-10-29 00:47:20,292 Testing Epoch [26/40] Iter[50/62]		Loss: 0.1417
2019-10-29 00:47:20,323 Testing Epoch [26/40] Iter[51/62]		Loss: 0.1417
2019-10-29 00:47:20,353 Testing Epoch [26/40] Iter[52/62]		Loss: 0.1406
2019-10-29 00:47:20,384 Testing Epoch [26/40] Iter[53/62]		Loss: 0.1404
2019-10-29 00:47:20,415 Testing Epoch [26/40] Iter[54/62]		Loss: 0.1398
2019-10-29 00:47:20,445 Testing Epoch [26/40] Iter[55/62]		Loss: 0.1399
2019-10-29 00:47:20,475 Testing Epoch [26/40] Iter[56/62]		Loss: 0.1397
2019-10-29 00:47:20,506 Testing Epoch [26/40] Iter[57/62]		Loss: 0.1395
2019-10-29 00:47:20,536 Testing Epoch [26/40] Iter[58/62]		Loss: 0.1391
2019-10-29 00:47:20,566 Testing Epoch [26/40] Iter[59/62]		Loss: 0.1391
2019-10-29 00:47:20,596 Testing Epoch [26/40] Iter[60/62]		Loss: 0.1385
2019-10-29 00:47:20,627 Testing Epoch [26/40] Iter[61/62]		Loss: 0.1382
2019-10-29 00:47:20,644 Testing Epoch [26/40] Iter[62/62]		Loss: 0.1389
2019-10-29 00:47:21,122 Training Epoch [27/40] Iter[0/312]		Loss: 0.2134
2019-10-29 00:47:21,244 Training Epoch [27/40] Iter[1/312]		Loss: 0.1568
2019-10-29 00:47:21,366 Training Epoch [27/40] Iter[2/312]		Loss: 0.1281
2019-10-29 00:47:21,489 Training Epoch [27/40] Iter[3/312]		Loss: 0.1213
2019-10-29 00:47:21,610 Training Epoch [27/40] Iter[4/312]		Loss: 0.1227
2019-10-29 00:47:21,731 Training Epoch [27/40] Iter[5/312]		Loss: 0.1350
2019-10-29 00:47:21,853 Training Epoch [27/40] Iter[6/312]		Loss: 0.1331
2019-10-29 00:47:21,974 Training Epoch [27/40] Iter[7/312]		Loss: 0.1269
2019-10-29 00:47:22,095 Training Epoch [27/40] Iter[8/312]		Loss: 0.1251
2019-10-29 00:47:22,217 Training Epoch [27/40] Iter[9/312]		Loss: 0.1280
2019-10-29 00:47:22,338 Training Epoch [27/40] Iter[10/312]		Loss: 0.1219
2019-10-29 00:47:22,460 Training Epoch [27/40] Iter[11/312]		Loss: 0.1197
2019-10-29 00:47:22,582 Training Epoch [27/40] Iter[12/312]		Loss: 0.1159
2019-10-29 00:47:22,703 Training Epoch [27/40] Iter[13/312]		Loss: 0.1144
2019-10-29 00:47:22,825 Training Epoch [27/40] Iter[14/312]		Loss: 0.1127
2019-10-29 00:47:22,946 Training Epoch [27/40] Iter[15/312]		Loss: 0.1110
2019-10-29 00:47:23,067 Training Epoch [27/40] Iter[16/312]		Loss: 0.1084
2019-10-29 00:47:23,189 Training Epoch [27/40] Iter[17/312]		Loss: 0.1068
2019-10-29 00:47:23,310 Training Epoch [27/40] Iter[18/312]		Loss: 0.1070
2019-10-29 00:47:23,432 Training Epoch [27/40] Iter[19/312]		Loss: 0.1058
2019-10-29 00:47:23,553 Training Epoch [27/40] Iter[20/312]		Loss: 0.1042
2019-10-29 00:47:23,674 Training Epoch [27/40] Iter[21/312]		Loss: 0.1030
2019-10-29 00:47:23,795 Training Epoch [27/40] Iter[22/312]		Loss: 0.1046
2019-10-29 00:47:23,916 Training Epoch [27/40] Iter[23/312]		Loss: 0.1042
2019-10-29 00:47:24,037 Training Epoch [27/40] Iter[24/312]		Loss: 0.1028
2019-10-29 00:47:24,160 Training Epoch [27/40] Iter[25/312]		Loss: 0.1026
2019-10-29 00:47:24,282 Training Epoch [27/40] Iter[26/312]		Loss: 0.1023
2019-10-29 00:47:24,403 Training Epoch [27/40] Iter[27/312]		Loss: 0.1022
2019-10-29 00:47:24,524 Training Epoch [27/40] Iter[28/312]		Loss: 0.1016
2019-10-29 00:47:24,645 Training Epoch [27/40] Iter[29/312]		Loss: 0.1059
2019-10-29 00:47:24,767 Training Epoch [27/40] Iter[30/312]		Loss: 0.1057
2019-10-29 00:47:24,889 Training Epoch [27/40] Iter[31/312]		Loss: 0.1049
2019-10-29 00:47:25,011 Training Epoch [27/40] Iter[32/312]		Loss: 0.1055
2019-10-29 00:47:25,132 Training Epoch [27/40] Iter[33/312]		Loss: 0.1042
2019-10-29 00:47:25,253 Training Epoch [27/40] Iter[34/312]		Loss: 0.1034
2019-10-29 00:47:25,375 Training Epoch [27/40] Iter[35/312]		Loss: 0.1027
2019-10-29 00:47:25,496 Training Epoch [27/40] Iter[36/312]		Loss: 0.1040
2019-10-29 00:47:25,617 Training Epoch [27/40] Iter[37/312]		Loss: 0.1040
2019-10-29 00:47:25,739 Training Epoch [27/40] Iter[38/312]		Loss: 0.1033
2019-10-29 00:47:25,860 Training Epoch [27/40] Iter[39/312]		Loss: 0.1050
2019-10-29 00:47:25,982 Training Epoch [27/40] Iter[40/312]		Loss: 0.1040
2019-10-29 00:47:26,104 Training Epoch [27/40] Iter[41/312]		Loss: 0.1041
2019-10-29 00:47:26,226 Training Epoch [27/40] Iter[42/312]		Loss: 0.1042
2019-10-29 00:47:26,347 Training Epoch [27/40] Iter[43/312]		Loss: 0.1036
2019-10-29 00:47:26,468 Training Epoch [27/40] Iter[44/312]		Loss: 0.1038
2019-10-29 00:47:26,590 Training Epoch [27/40] Iter[45/312]		Loss: 0.1042
2019-10-29 00:47:26,712 Training Epoch [27/40] Iter[46/312]		Loss: 0.1034
2019-10-29 00:47:26,833 Training Epoch [27/40] Iter[47/312]		Loss: 0.1031
2019-10-29 00:47:26,954 Training Epoch [27/40] Iter[48/312]		Loss: 0.1022
2019-10-29 00:47:27,075 Training Epoch [27/40] Iter[49/312]		Loss: 0.1016
2019-10-29 00:47:27,197 Training Epoch [27/40] Iter[50/312]		Loss: 0.1018
2019-10-29 00:47:27,318 Training Epoch [27/40] Iter[51/312]		Loss: 0.1013
2019-10-29 00:47:27,440 Training Epoch [27/40] Iter[52/312]		Loss: 0.1019
2019-10-29 00:47:27,561 Training Epoch [27/40] Iter[53/312]		Loss: 0.1017
2019-10-29 00:47:27,683 Training Epoch [27/40] Iter[54/312]		Loss: 0.1015
2019-10-29 00:47:27,804 Training Epoch [27/40] Iter[55/312]		Loss: 0.1018
2019-10-29 00:47:27,925 Training Epoch [27/40] Iter[56/312]		Loss: 0.1018
2019-10-29 00:47:28,047 Training Epoch [27/40] Iter[57/312]		Loss: 0.1016
2019-10-29 00:47:28,168 Training Epoch [27/40] Iter[58/312]		Loss: 0.1007
2019-10-29 00:47:28,290 Training Epoch [27/40] Iter[59/312]		Loss: 0.1004
2019-10-29 00:47:28,412 Training Epoch [27/40] Iter[60/312]		Loss: 0.1001
2019-10-29 00:47:28,533 Training Epoch [27/40] Iter[61/312]		Loss: 0.1000
2019-10-29 00:47:28,654 Training Epoch [27/40] Iter[62/312]		Loss: 0.0999
2019-10-29 00:47:28,776 Training Epoch [27/40] Iter[63/312]		Loss: 0.1007
2019-10-29 00:47:28,897 Training Epoch [27/40] Iter[64/312]		Loss: 0.1005
2019-10-29 00:47:29,018 Training Epoch [27/40] Iter[65/312]		Loss: 0.1002
2019-10-29 00:47:29,140 Training Epoch [27/40] Iter[66/312]		Loss: 0.1004
2019-10-29 00:47:29,260 Training Epoch [27/40] Iter[67/312]		Loss: 0.1003
2019-10-29 00:47:29,382 Training Epoch [27/40] Iter[68/312]		Loss: 0.1001
2019-10-29 00:47:29,503 Training Epoch [27/40] Iter[69/312]		Loss: 0.1002
2019-10-29 00:47:29,624 Training Epoch [27/40] Iter[70/312]		Loss: 0.1006
2019-10-29 00:47:29,746 Training Epoch [27/40] Iter[71/312]		Loss: 0.1007
2019-10-29 00:47:29,867 Training Epoch [27/40] Iter[72/312]		Loss: 0.1012
2019-10-29 00:47:29,989 Training Epoch [27/40] Iter[73/312]		Loss: 0.1007
2019-10-29 00:47:30,110 Training Epoch [27/40] Iter[74/312]		Loss: 0.1006
2019-10-29 00:47:30,232 Training Epoch [27/40] Iter[75/312]		Loss: 0.1009
2019-10-29 00:47:30,354 Training Epoch [27/40] Iter[76/312]		Loss: 0.1005
2019-10-29 00:47:30,475 Training Epoch [27/40] Iter[77/312]		Loss: 0.1005
2019-10-29 00:47:30,597 Training Epoch [27/40] Iter[78/312]		Loss: 0.1010
2019-10-29 00:47:30,718 Training Epoch [27/40] Iter[79/312]		Loss: 0.1011
2019-10-29 00:47:30,839 Training Epoch [27/40] Iter[80/312]		Loss: 0.1015
2019-10-29 00:47:30,961 Training Epoch [27/40] Iter[81/312]		Loss: 0.1017
2019-10-29 00:47:31,082 Training Epoch [27/40] Iter[82/312]		Loss: 0.1012
2019-10-29 00:47:31,204 Training Epoch [27/40] Iter[83/312]		Loss: 0.1012
2019-10-29 00:47:31,326 Training Epoch [27/40] Iter[84/312]		Loss: 0.1016
2019-10-29 00:47:31,449 Training Epoch [27/40] Iter[85/312]		Loss: 0.1016
2019-10-29 00:47:31,571 Training Epoch [27/40] Iter[86/312]		Loss: 0.1015
2019-10-29 00:47:31,692 Training Epoch [27/40] Iter[87/312]		Loss: 0.1016
2019-10-29 00:47:31,814 Training Epoch [27/40] Iter[88/312]		Loss: 0.1012
2019-10-29 00:47:31,935 Training Epoch [27/40] Iter[89/312]		Loss: 0.1016
2019-10-29 00:47:32,057 Training Epoch [27/40] Iter[90/312]		Loss: 0.1018
2019-10-29 00:47:32,178 Training Epoch [27/40] Iter[91/312]		Loss: 0.1015
2019-10-29 00:47:32,299 Training Epoch [27/40] Iter[92/312]		Loss: 0.1017
2019-10-29 00:47:32,421 Training Epoch [27/40] Iter[93/312]		Loss: 0.1017
2019-10-29 00:47:32,542 Training Epoch [27/40] Iter[94/312]		Loss: 0.1020
2019-10-29 00:47:32,664 Training Epoch [27/40] Iter[95/312]		Loss: 0.1025
2019-10-29 00:47:32,785 Training Epoch [27/40] Iter[96/312]		Loss: 0.1025
2019-10-29 00:47:32,906 Training Epoch [27/40] Iter[97/312]		Loss: 0.1023
2019-10-29 00:47:33,027 Training Epoch [27/40] Iter[98/312]		Loss: 0.1025
2019-10-29 00:47:33,149 Training Epoch [27/40] Iter[99/312]		Loss: 0.1025
2019-10-29 00:47:33,270 Training Epoch [27/40] Iter[100/312]		Loss: 0.1026
2019-10-29 00:47:33,392 Training Epoch [27/40] Iter[101/312]		Loss: 0.1027
2019-10-29 00:47:33,514 Training Epoch [27/40] Iter[102/312]		Loss: 0.1025
2019-10-29 00:47:33,635 Training Epoch [27/40] Iter[103/312]		Loss: 0.1026
2019-10-29 00:47:33,757 Training Epoch [27/40] Iter[104/312]		Loss: 0.1027
2019-10-29 00:47:33,880 Training Epoch [27/40] Iter[105/312]		Loss: 0.1026
2019-10-29 00:47:34,002 Training Epoch [27/40] Iter[106/312]		Loss: 0.1025
2019-10-29 00:47:34,123 Training Epoch [27/40] Iter[107/312]		Loss: 0.1024
2019-10-29 00:47:34,244 Training Epoch [27/40] Iter[108/312]		Loss: 0.1023
2019-10-29 00:47:34,366 Training Epoch [27/40] Iter[109/312]		Loss: 0.1025
2019-10-29 00:47:34,487 Training Epoch [27/40] Iter[110/312]		Loss: 0.1030
2019-10-29 00:47:34,609 Training Epoch [27/40] Iter[111/312]		Loss: 0.1030
2019-10-29 00:47:34,731 Training Epoch [27/40] Iter[112/312]		Loss: 0.1030
2019-10-29 00:47:34,852 Training Epoch [27/40] Iter[113/312]		Loss: 0.1029
2019-10-29 00:47:34,974 Training Epoch [27/40] Iter[114/312]		Loss: 0.1030
2019-10-29 00:47:35,095 Training Epoch [27/40] Iter[115/312]		Loss: 0.1029
2019-10-29 00:47:35,216 Training Epoch [27/40] Iter[116/312]		Loss: 0.1031
2019-10-29 00:47:35,338 Training Epoch [27/40] Iter[117/312]		Loss: 0.1034
2019-10-29 00:47:35,459 Training Epoch [27/40] Iter[118/312]		Loss: 0.1034
2019-10-29 00:47:35,580 Training Epoch [27/40] Iter[119/312]		Loss: 0.1035
2019-10-29 00:47:35,702 Training Epoch [27/40] Iter[120/312]		Loss: 0.1034
2019-10-29 00:47:35,823 Training Epoch [27/40] Iter[121/312]		Loss: 0.1032
2019-10-29 00:47:35,944 Training Epoch [27/40] Iter[122/312]		Loss: 0.1030
2019-10-29 00:47:36,066 Training Epoch [27/40] Iter[123/312]		Loss: 0.1028
2019-10-29 00:47:36,187 Training Epoch [27/40] Iter[124/312]		Loss: 0.1027
2019-10-29 00:47:36,309 Training Epoch [27/40] Iter[125/312]		Loss: 0.1030
2019-10-29 00:47:36,430 Training Epoch [27/40] Iter[126/312]		Loss: 0.1029
2019-10-29 00:47:36,551 Training Epoch [27/40] Iter[127/312]		Loss: 0.1027
2019-10-29 00:47:36,673 Training Epoch [27/40] Iter[128/312]		Loss: 0.1029
2019-10-29 00:47:36,794 Training Epoch [27/40] Iter[129/312]		Loss: 0.1026
2019-10-29 00:47:36,916 Training Epoch [27/40] Iter[130/312]		Loss: 0.1024
2019-10-29 00:47:37,037 Training Epoch [27/40] Iter[131/312]		Loss: 0.1022
2019-10-29 00:47:37,159 Training Epoch [27/40] Iter[132/312]		Loss: 0.1021
2019-10-29 00:47:37,285 Training Epoch [27/40] Iter[133/312]		Loss: 0.1019
2019-10-29 00:47:37,407 Training Epoch [27/40] Iter[134/312]		Loss: 0.1018
2019-10-29 00:47:37,528 Training Epoch [27/40] Iter[135/312]		Loss: 0.1023
2019-10-29 00:47:37,649 Training Epoch [27/40] Iter[136/312]		Loss: 0.1019
2019-10-29 00:47:37,771 Training Epoch [27/40] Iter[137/312]		Loss: 0.1022
2019-10-29 00:47:37,892 Training Epoch [27/40] Iter[138/312]		Loss: 0.1020
2019-10-29 00:47:38,013 Training Epoch [27/40] Iter[139/312]		Loss: 0.1025
2019-10-29 00:47:38,135 Training Epoch [27/40] Iter[140/312]		Loss: 0.1022
2019-10-29 00:47:38,255 Training Epoch [27/40] Iter[141/312]		Loss: 0.1028
2019-10-29 00:47:38,376 Training Epoch [27/40] Iter[142/312]		Loss: 0.1026
2019-10-29 00:47:38,498 Training Epoch [27/40] Iter[143/312]		Loss: 0.1024
2019-10-29 00:47:38,619 Training Epoch [27/40] Iter[144/312]		Loss: 0.1023
2019-10-29 00:47:38,741 Training Epoch [27/40] Iter[145/312]		Loss: 0.1024
2019-10-29 00:47:38,862 Training Epoch [27/40] Iter[146/312]		Loss: 0.1027
2019-10-29 00:47:38,984 Training Epoch [27/40] Iter[147/312]		Loss: 0.1026
2019-10-29 00:47:39,105 Training Epoch [27/40] Iter[148/312]		Loss: 0.1025
2019-10-29 00:47:39,226 Training Epoch [27/40] Iter[149/312]		Loss: 0.1023
2019-10-29 00:47:39,348 Training Epoch [27/40] Iter[150/312]		Loss: 0.1024
2019-10-29 00:47:39,470 Training Epoch [27/40] Iter[151/312]		Loss: 0.1024
2019-10-29 00:47:39,591 Training Epoch [27/40] Iter[152/312]		Loss: 0.1025
2019-10-29 00:47:39,713 Training Epoch [27/40] Iter[153/312]		Loss: 0.1023
2019-10-29 00:47:39,835 Training Epoch [27/40] Iter[154/312]		Loss: 0.1021
2019-10-29 00:47:39,956 Training Epoch [27/40] Iter[155/312]		Loss: 0.1020
2019-10-29 00:47:40,078 Training Epoch [27/40] Iter[156/312]		Loss: 0.1020
2019-10-29 00:47:40,200 Training Epoch [27/40] Iter[157/312]		Loss: 0.1019
2019-10-29 00:47:40,321 Training Epoch [27/40] Iter[158/312]		Loss: 0.1020
2019-10-29 00:47:40,443 Training Epoch [27/40] Iter[159/312]		Loss: 0.1019
2019-10-29 00:47:40,564 Training Epoch [27/40] Iter[160/312]		Loss: 0.1019
2019-10-29 00:47:40,685 Training Epoch [27/40] Iter[161/312]		Loss: 0.1023
2019-10-29 00:47:40,807 Training Epoch [27/40] Iter[162/312]		Loss: 0.1029
2019-10-29 00:47:40,928 Training Epoch [27/40] Iter[163/312]		Loss: 0.1032
2019-10-29 00:47:41,049 Training Epoch [27/40] Iter[164/312]		Loss: 0.1034
2019-10-29 00:47:41,170 Training Epoch [27/40] Iter[165/312]		Loss: 0.1033
2019-10-29 00:47:41,292 Training Epoch [27/40] Iter[166/312]		Loss: 0.1037
2019-10-29 00:47:41,413 Training Epoch [27/40] Iter[167/312]		Loss: 0.1036
2019-10-29 00:47:41,535 Training Epoch [27/40] Iter[168/312]		Loss: 0.1035
2019-10-29 00:47:41,656 Training Epoch [27/40] Iter[169/312]		Loss: 0.1035
2019-10-29 00:47:41,779 Training Epoch [27/40] Iter[170/312]		Loss: 0.1033
2019-10-29 00:47:41,901 Training Epoch [27/40] Iter[171/312]		Loss: 0.1033
2019-10-29 00:47:42,022 Training Epoch [27/40] Iter[172/312]		Loss: 0.1032
2019-10-29 00:47:42,144 Training Epoch [27/40] Iter[173/312]		Loss: 0.1031
2019-10-29 00:47:42,265 Training Epoch [27/40] Iter[174/312]		Loss: 0.1032
2019-10-29 00:47:42,387 Training Epoch [27/40] Iter[175/312]		Loss: 0.1031
2019-10-29 00:47:42,508 Training Epoch [27/40] Iter[176/312]		Loss: 0.1029
2019-10-29 00:47:42,630 Training Epoch [27/40] Iter[177/312]		Loss: 0.1030
2019-10-29 00:47:42,751 Training Epoch [27/40] Iter[178/312]		Loss: 0.1031
2019-10-29 00:47:42,873 Training Epoch [27/40] Iter[179/312]		Loss: 0.1032
2019-10-29 00:47:42,994 Training Epoch [27/40] Iter[180/312]		Loss: 0.1034
2019-10-29 00:47:43,116 Training Epoch [27/40] Iter[181/312]		Loss: 0.1032
2019-10-29 00:47:43,238 Training Epoch [27/40] Iter[182/312]		Loss: 0.1033
2019-10-29 00:47:43,360 Training Epoch [27/40] Iter[183/312]		Loss: 0.1034
2019-10-29 00:47:43,481 Training Epoch [27/40] Iter[184/312]		Loss: 0.1034
2019-10-29 00:47:43,603 Training Epoch [27/40] Iter[185/312]		Loss: 0.1033
2019-10-29 00:47:43,724 Training Epoch [27/40] Iter[186/312]		Loss: 0.1033
2019-10-29 00:47:43,846 Training Epoch [27/40] Iter[187/312]		Loss: 0.1034
2019-10-29 00:47:43,967 Training Epoch [27/40] Iter[188/312]		Loss: 0.1033
2019-10-29 00:47:44,089 Training Epoch [27/40] Iter[189/312]		Loss: 0.1033
2019-10-29 00:47:44,211 Training Epoch [27/40] Iter[190/312]		Loss: 0.1032
2019-10-29 00:47:44,332 Training Epoch [27/40] Iter[191/312]		Loss: 0.1034
2019-10-29 00:47:44,454 Training Epoch [27/40] Iter[192/312]		Loss: 0.1034
2019-10-29 00:47:44,576 Training Epoch [27/40] Iter[193/312]		Loss: 0.1033
2019-10-29 00:47:44,697 Training Epoch [27/40] Iter[194/312]		Loss: 0.1033
2019-10-29 00:47:44,818 Training Epoch [27/40] Iter[195/312]		Loss: 0.1032
2019-10-29 00:47:44,939 Training Epoch [27/40] Iter[196/312]		Loss: 0.1033
2019-10-29 00:47:45,060 Training Epoch [27/40] Iter[197/312]		Loss: 0.1034
2019-10-29 00:47:45,182 Training Epoch [27/40] Iter[198/312]		Loss: 0.1036
2019-10-29 00:47:45,303 Training Epoch [27/40] Iter[199/312]		Loss: 0.1035
2019-10-29 00:47:45,425 Training Epoch [27/40] Iter[200/312]		Loss: 0.1033
2019-10-29 00:47:45,546 Training Epoch [27/40] Iter[201/312]		Loss: 0.1031
2019-10-29 00:47:45,668 Training Epoch [27/40] Iter[202/312]		Loss: 0.1031
2019-10-29 00:47:45,789 Training Epoch [27/40] Iter[203/312]		Loss: 0.1032
2019-10-29 00:47:45,911 Training Epoch [27/40] Iter[204/312]		Loss: 0.1038
2019-10-29 00:47:46,032 Training Epoch [27/40] Iter[205/312]		Loss: 0.1039
2019-10-29 00:47:46,153 Training Epoch [27/40] Iter[206/312]		Loss: 0.1038
2019-10-29 00:47:46,274 Training Epoch [27/40] Iter[207/312]		Loss: 0.1037
2019-10-29 00:47:46,396 Training Epoch [27/40] Iter[208/312]		Loss: 0.1037
2019-10-29 00:47:46,517 Training Epoch [27/40] Iter[209/312]		Loss: 0.1036
2019-10-29 00:47:46,638 Training Epoch [27/40] Iter[210/312]		Loss: 0.1034
2019-10-29 00:47:46,759 Training Epoch [27/40] Iter[211/312]		Loss: 0.1036
2019-10-29 00:47:46,882 Training Epoch [27/40] Iter[212/312]		Loss: 0.1036
2019-10-29 00:47:47,003 Training Epoch [27/40] Iter[213/312]		Loss: 0.1035
2019-10-29 00:47:47,124 Training Epoch [27/40] Iter[214/312]		Loss: 0.1033
2019-10-29 00:47:47,246 Training Epoch [27/40] Iter[215/312]		Loss: 0.1033
2019-10-29 00:47:47,368 Training Epoch [27/40] Iter[216/312]		Loss: 0.1036
2019-10-29 00:47:47,490 Training Epoch [27/40] Iter[217/312]		Loss: 0.1037
2019-10-29 00:47:47,612 Training Epoch [27/40] Iter[218/312]		Loss: 0.1036
2019-10-29 00:47:47,733 Training Epoch [27/40] Iter[219/312]		Loss: 0.1035
2019-10-29 00:47:47,854 Training Epoch [27/40] Iter[220/312]		Loss: 0.1033
2019-10-29 00:47:47,975 Training Epoch [27/40] Iter[221/312]		Loss: 0.1034
2019-10-29 00:47:48,097 Training Epoch [27/40] Iter[222/312]		Loss: 0.1033
2019-10-29 00:47:48,219 Training Epoch [27/40] Iter[223/312]		Loss: 0.1032
2019-10-29 00:47:48,340 Training Epoch [27/40] Iter[224/312]		Loss: 0.1031
2019-10-29 00:47:48,462 Training Epoch [27/40] Iter[225/312]		Loss: 0.1032
2019-10-29 00:47:48,584 Training Epoch [27/40] Iter[226/312]		Loss: 0.1030
2019-10-29 00:47:48,705 Training Epoch [27/40] Iter[227/312]		Loss: 0.1031
2019-10-29 00:47:48,827 Training Epoch [27/40] Iter[228/312]		Loss: 0.1033
2019-10-29 00:47:48,948 Training Epoch [27/40] Iter[229/312]		Loss: 0.1033
2019-10-29 00:47:49,069 Training Epoch [27/40] Iter[230/312]		Loss: 0.1033
2019-10-29 00:47:49,190 Training Epoch [27/40] Iter[231/312]		Loss: 0.1034
2019-10-29 00:47:49,312 Training Epoch [27/40] Iter[232/312]		Loss: 0.1036
2019-10-29 00:47:49,433 Training Epoch [27/40] Iter[233/312]		Loss: 0.1035
2019-10-29 00:47:49,555 Training Epoch [27/40] Iter[234/312]		Loss: 0.1034
2019-10-29 00:47:49,676 Training Epoch [27/40] Iter[235/312]		Loss: 0.1035
2019-10-29 00:47:49,797 Training Epoch [27/40] Iter[236/312]		Loss: 0.1034
2019-10-29 00:47:49,918 Training Epoch [27/40] Iter[237/312]		Loss: 0.1034
2019-10-29 00:47:50,040 Training Epoch [27/40] Iter[238/312]		Loss: 0.1034
2019-10-29 00:47:50,161 Training Epoch [27/40] Iter[239/312]		Loss: 0.1034
2019-10-29 00:47:50,282 Training Epoch [27/40] Iter[240/312]		Loss: 0.1034
2019-10-29 00:47:50,409 Training Epoch [27/40] Iter[241/312]		Loss: 0.1035
2019-10-29 00:47:50,531 Training Epoch [27/40] Iter[242/312]		Loss: 0.1036
2019-10-29 00:47:50,653 Training Epoch [27/40] Iter[243/312]		Loss: 0.1035
2019-10-29 00:47:50,774 Training Epoch [27/40] Iter[244/312]		Loss: 0.1038
2019-10-29 00:47:50,896 Training Epoch [27/40] Iter[245/312]		Loss: 0.1038
2019-10-29 00:47:51,018 Training Epoch [27/40] Iter[246/312]		Loss: 0.1042
2019-10-29 00:47:51,140 Training Epoch [27/40] Iter[247/312]		Loss: 0.1041
2019-10-29 00:47:51,261 Training Epoch [27/40] Iter[248/312]		Loss: 0.1043
2019-10-29 00:47:51,382 Training Epoch [27/40] Iter[249/312]		Loss: 0.1041
2019-10-29 00:47:51,504 Training Epoch [27/40] Iter[250/312]		Loss: 0.1041
2019-10-29 00:47:51,625 Training Epoch [27/40] Iter[251/312]		Loss: 0.1040
2019-10-29 00:47:51,747 Training Epoch [27/40] Iter[252/312]		Loss: 0.1041
2019-10-29 00:47:51,869 Training Epoch [27/40] Iter[253/312]		Loss: 0.1040
2019-10-29 00:47:51,992 Training Epoch [27/40] Iter[254/312]		Loss: 0.1040
2019-10-29 00:47:52,114 Training Epoch [27/40] Iter[255/312]		Loss: 0.1041
2019-10-29 00:47:52,236 Training Epoch [27/40] Iter[256/312]		Loss: 0.1041
2019-10-29 00:47:52,357 Training Epoch [27/40] Iter[257/312]		Loss: 0.1040
2019-10-29 00:47:52,479 Training Epoch [27/40] Iter[258/312]		Loss: 0.1039
2019-10-29 00:47:52,601 Training Epoch [27/40] Iter[259/312]		Loss: 0.1040
2019-10-29 00:47:52,723 Training Epoch [27/40] Iter[260/312]		Loss: 0.1043
2019-10-29 00:47:52,844 Training Epoch [27/40] Iter[261/312]		Loss: 0.1041
2019-10-29 00:47:52,966 Training Epoch [27/40] Iter[262/312]		Loss: 0.1040
2019-10-29 00:47:53,087 Training Epoch [27/40] Iter[263/312]		Loss: 0.1039
2019-10-29 00:47:53,208 Training Epoch [27/40] Iter[264/312]		Loss: 0.1038
2019-10-29 00:47:53,330 Training Epoch [27/40] Iter[265/312]		Loss: 0.1038
2019-10-29 00:47:53,451 Training Epoch [27/40] Iter[266/312]		Loss: 0.1039
2019-10-29 00:47:53,572 Training Epoch [27/40] Iter[267/312]		Loss: 0.1038
2019-10-29 00:47:53,694 Training Epoch [27/40] Iter[268/312]		Loss: 0.1038
2019-10-29 00:47:53,815 Training Epoch [27/40] Iter[269/312]		Loss: 0.1039
2019-10-29 00:47:53,937 Training Epoch [27/40] Iter[270/312]		Loss: 0.1038
2019-10-29 00:47:54,058 Training Epoch [27/40] Iter[271/312]		Loss: 0.1038
2019-10-29 00:47:54,179 Training Epoch [27/40] Iter[272/312]		Loss: 0.1037
2019-10-29 00:47:54,301 Training Epoch [27/40] Iter[273/312]		Loss: 0.1038
2019-10-29 00:47:54,422 Training Epoch [27/40] Iter[274/312]		Loss: 0.1038
2019-10-29 00:47:54,543 Training Epoch [27/40] Iter[275/312]		Loss: 0.1037
2019-10-29 00:47:54,664 Training Epoch [27/40] Iter[276/312]		Loss: 0.1036
2019-10-29 00:47:54,785 Training Epoch [27/40] Iter[277/312]		Loss: 0.1035
2019-10-29 00:47:54,907 Training Epoch [27/40] Iter[278/312]		Loss: 0.1037
2019-10-29 00:47:55,028 Training Epoch [27/40] Iter[279/312]		Loss: 0.1038
2019-10-29 00:47:55,149 Training Epoch [27/40] Iter[280/312]		Loss: 0.1037
2019-10-29 00:47:55,270 Training Epoch [27/40] Iter[281/312]		Loss: 0.1037
2019-10-29 00:47:55,391 Training Epoch [27/40] Iter[282/312]		Loss: 0.1038
2019-10-29 00:47:55,512 Training Epoch [27/40] Iter[283/312]		Loss: 0.1037
2019-10-29 00:47:55,634 Training Epoch [27/40] Iter[284/312]		Loss: 0.1037
2019-10-29 00:47:55,755 Training Epoch [27/40] Iter[285/312]		Loss: 0.1039
2019-10-29 00:47:55,877 Training Epoch [27/40] Iter[286/312]		Loss: 0.1038
2019-10-29 00:47:55,998 Training Epoch [27/40] Iter[287/312]		Loss: 0.1037
2019-10-29 00:47:56,120 Training Epoch [27/40] Iter[288/312]		Loss: 0.1038
2019-10-29 00:47:56,241 Training Epoch [27/40] Iter[289/312]		Loss: 0.1036
2019-10-29 00:47:56,362 Training Epoch [27/40] Iter[290/312]		Loss: 0.1035
2019-10-29 00:47:56,484 Training Epoch [27/40] Iter[291/312]		Loss: 0.1034
2019-10-29 00:47:56,606 Training Epoch [27/40] Iter[292/312]		Loss: 0.1035
2019-10-29 00:47:56,727 Training Epoch [27/40] Iter[293/312]		Loss: 0.1035
2019-10-29 00:47:56,849 Training Epoch [27/40] Iter[294/312]		Loss: 0.1035
2019-10-29 00:47:56,971 Training Epoch [27/40] Iter[295/312]		Loss: 0.1036
2019-10-29 00:47:57,093 Training Epoch [27/40] Iter[296/312]		Loss: 0.1036
2019-10-29 00:47:57,215 Training Epoch [27/40] Iter[297/312]		Loss: 0.1036
2019-10-29 00:47:57,336 Training Epoch [27/40] Iter[298/312]		Loss: 0.1036
2019-10-29 00:47:57,458 Training Epoch [27/40] Iter[299/312]		Loss: 0.1035
2019-10-29 00:47:57,579 Training Epoch [27/40] Iter[300/312]		Loss: 0.1035
2019-10-29 00:47:57,700 Training Epoch [27/40] Iter[301/312]		Loss: 0.1036
2019-10-29 00:47:57,821 Training Epoch [27/40] Iter[302/312]		Loss: 0.1037
2019-10-29 00:47:57,942 Training Epoch [27/40] Iter[303/312]		Loss: 0.1037
2019-10-29 00:47:58,063 Training Epoch [27/40] Iter[304/312]		Loss: 0.1036
2019-10-29 00:47:58,184 Training Epoch [27/40] Iter[305/312]		Loss: 0.1035
2019-10-29 00:47:58,306 Training Epoch [27/40] Iter[306/312]		Loss: 0.1036
2019-10-29 00:47:58,427 Training Epoch [27/40] Iter[307/312]		Loss: 0.1036
2019-10-29 00:47:58,548 Training Epoch [27/40] Iter[308/312]		Loss: 0.1036
2019-10-29 00:47:58,668 Training Epoch [27/40] Iter[309/312]		Loss: 0.1035
2019-10-29 00:47:58,789 Training Epoch [27/40] Iter[310/312]		Loss: 0.1036
2019-10-29 00:47:58,911 Training Epoch [27/40] Iter[311/312]		Loss: 0.1035
2019-10-29 00:47:58,972 Training Epoch [27/40] Iter[312/312]		Loss: 0.1035
2019-10-29 00:47:59,356 Testing Epoch [27/40] Iter[0/62]		Loss: 0.0868
2019-10-29 00:47:59,393 Testing Epoch [27/40] Iter[1/62]		Loss: 0.1232
2019-10-29 00:47:59,431 Testing Epoch [27/40] Iter[2/62]		Loss: 0.1155
2019-10-29 00:47:59,463 Testing Epoch [27/40] Iter[3/62]		Loss: 0.1140
2019-10-29 00:47:59,498 Testing Epoch [27/40] Iter[4/62]		Loss: 0.1095
2019-10-29 00:47:59,528 Testing Epoch [27/40] Iter[5/62]		Loss: 0.1069
2019-10-29 00:47:59,557 Testing Epoch [27/40] Iter[6/62]		Loss: 0.1082
2019-10-29 00:47:59,590 Testing Epoch [27/40] Iter[7/62]		Loss: 0.1148
2019-10-29 00:47:59,622 Testing Epoch [27/40] Iter[8/62]		Loss: 0.1212
2019-10-29 00:47:59,652 Testing Epoch [27/40] Iter[9/62]		Loss: 0.1186
2019-10-29 00:47:59,686 Testing Epoch [27/40] Iter[10/62]		Loss: 0.1168
2019-10-29 00:47:59,717 Testing Epoch [27/40] Iter[11/62]		Loss: 0.1213
2019-10-29 00:47:59,747 Testing Epoch [27/40] Iter[12/62]		Loss: 0.1218
2019-10-29 00:47:59,782 Testing Epoch [27/40] Iter[13/62]		Loss: 0.1240
2019-10-29 00:47:59,813 Testing Epoch [27/40] Iter[14/62]		Loss: 0.1361
2019-10-29 00:47:59,843 Testing Epoch [27/40] Iter[15/62]		Loss: 0.1378
2019-10-29 00:47:59,878 Testing Epoch [27/40] Iter[16/62]		Loss: 0.1358
2019-10-29 00:47:59,909 Testing Epoch [27/40] Iter[17/62]		Loss: 0.1352
2019-10-29 00:47:59,939 Testing Epoch [27/40] Iter[18/62]		Loss: 0.1324
2019-10-29 00:47:59,974 Testing Epoch [27/40] Iter[19/62]		Loss: 0.1301
2019-10-29 00:48:00,006 Testing Epoch [27/40] Iter[20/62]		Loss: 0.1316
2019-10-29 00:48:00,037 Testing Epoch [27/40] Iter[21/62]		Loss: 0.1298
2019-10-29 00:48:00,067 Testing Epoch [27/40] Iter[22/62]		Loss: 0.1293
2019-10-29 00:48:00,102 Testing Epoch [27/40] Iter[23/62]		Loss: 0.1295
2019-10-29 00:48:00,133 Testing Epoch [27/40] Iter[24/62]		Loss: 0.1315
2019-10-29 00:48:00,164 Testing Epoch [27/40] Iter[25/62]		Loss: 0.1309
2019-10-29 00:48:00,198 Testing Epoch [27/40] Iter[26/62]		Loss: 0.1299
2019-10-29 00:48:00,229 Testing Epoch [27/40] Iter[27/62]		Loss: 0.1345
2019-10-29 00:48:00,260 Testing Epoch [27/40] Iter[28/62]		Loss: 0.1360
2019-10-29 00:48:00,294 Testing Epoch [27/40] Iter[29/62]		Loss: 0.1360
2019-10-29 00:48:00,325 Testing Epoch [27/40] Iter[30/62]		Loss: 0.1378
2019-10-29 00:48:00,356 Testing Epoch [27/40] Iter[31/62]		Loss: 0.1371
2019-10-29 00:48:00,393 Testing Epoch [27/40] Iter[32/62]		Loss: 0.1388
2019-10-29 00:48:00,424 Testing Epoch [27/40] Iter[33/62]		Loss: 0.1370
2019-10-29 00:48:00,455 Testing Epoch [27/40] Iter[34/62]		Loss: 0.1385
2019-10-29 00:48:00,486 Testing Epoch [27/40] Iter[35/62]		Loss: 0.1390
2019-10-29 00:48:00,517 Testing Epoch [27/40] Iter[36/62]		Loss: 0.1371
2019-10-29 00:48:00,548 Testing Epoch [27/40] Iter[37/62]		Loss: 0.1367
2019-10-29 00:48:00,579 Testing Epoch [27/40] Iter[38/62]		Loss: 0.1368
2019-10-29 00:48:00,610 Testing Epoch [27/40] Iter[39/62]		Loss: 0.1373
2019-10-29 00:48:00,641 Testing Epoch [27/40] Iter[40/62]		Loss: 0.1377
2019-10-29 00:48:00,678 Testing Epoch [27/40] Iter[41/62]		Loss: 0.1378
2019-10-29 00:48:00,709 Testing Epoch [27/40] Iter[42/62]		Loss: 0.1363
2019-10-29 00:48:00,740 Testing Epoch [27/40] Iter[43/62]		Loss: 0.1358
2019-10-29 00:48:00,771 Testing Epoch [27/40] Iter[44/62]		Loss: 0.1346
2019-10-29 00:48:00,801 Testing Epoch [27/40] Iter[45/62]		Loss: 0.1356
2019-10-29 00:48:00,832 Testing Epoch [27/40] Iter[46/62]		Loss: 0.1358
2019-10-29 00:48:00,863 Testing Epoch [27/40] Iter[47/62]		Loss: 0.1408
2019-10-29 00:48:00,894 Testing Epoch [27/40] Iter[48/62]		Loss: 0.1397
2019-10-29 00:48:00,925 Testing Epoch [27/40] Iter[49/62]		Loss: 0.1411
2019-10-29 00:48:00,956 Testing Epoch [27/40] Iter[50/62]		Loss: 0.1407
2019-10-29 00:48:00,987 Testing Epoch [27/40] Iter[51/62]		Loss: 0.1408
2019-10-29 00:48:01,018 Testing Epoch [27/40] Iter[52/62]		Loss: 0.1397
2019-10-29 00:48:01,048 Testing Epoch [27/40] Iter[53/62]		Loss: 0.1395
2019-10-29 00:48:01,079 Testing Epoch [27/40] Iter[54/62]		Loss: 0.1389
2019-10-29 00:48:01,110 Testing Epoch [27/40] Iter[55/62]		Loss: 0.1389
2019-10-29 00:48:01,140 Testing Epoch [27/40] Iter[56/62]		Loss: 0.1387
2019-10-29 00:48:01,170 Testing Epoch [27/40] Iter[57/62]		Loss: 0.1386
2019-10-29 00:48:01,201 Testing Epoch [27/40] Iter[58/62]		Loss: 0.1381
2019-10-29 00:48:01,231 Testing Epoch [27/40] Iter[59/62]		Loss: 0.1381
2019-10-29 00:48:01,262 Testing Epoch [27/40] Iter[60/62]		Loss: 0.1375
2019-10-29 00:48:01,292 Testing Epoch [27/40] Iter[61/62]		Loss: 0.1373
2019-10-29 00:48:01,309 Testing Epoch [27/40] Iter[62/62]		Loss: 0.1382
2019-10-29 00:48:01,379 Saving the Model
2019-10-29 00:48:01,813 Training Epoch [28/40] Iter[0/312]		Loss: 0.1996
2019-10-29 00:48:01,933 Training Epoch [28/40] Iter[1/312]		Loss: 0.1335
2019-10-29 00:48:02,056 Training Epoch [28/40] Iter[2/312]		Loss: 0.1325
2019-10-29 00:48:02,180 Training Epoch [28/40] Iter[3/312]		Loss: 0.1239
2019-10-29 00:48:02,304 Training Epoch [28/40] Iter[4/312]		Loss: 0.1178
2019-10-29 00:48:02,428 Training Epoch [28/40] Iter[5/312]		Loss: 0.1172
2019-10-29 00:48:02,549 Training Epoch [28/40] Iter[6/312]		Loss: 0.1206
2019-10-29 00:48:02,671 Training Epoch [28/40] Iter[7/312]		Loss: 0.1234
2019-10-29 00:48:02,792 Training Epoch [28/40] Iter[8/312]		Loss: 0.1223
2019-10-29 00:48:02,913 Training Epoch [28/40] Iter[9/312]		Loss: 0.1163
2019-10-29 00:48:03,035 Training Epoch [28/40] Iter[10/312]		Loss: 0.1142
2019-10-29 00:48:03,156 Training Epoch [28/40] Iter[11/312]		Loss: 0.1096
2019-10-29 00:48:03,277 Training Epoch [28/40] Iter[12/312]		Loss: 0.1060
2019-10-29 00:48:03,398 Training Epoch [28/40] Iter[13/312]		Loss: 0.1059
2019-10-29 00:48:03,519 Training Epoch [28/40] Iter[14/312]		Loss: 0.1040
2019-10-29 00:48:03,640 Training Epoch [28/40] Iter[15/312]		Loss: 0.1056
2019-10-29 00:48:03,761 Training Epoch [28/40] Iter[16/312]		Loss: 0.1049
2019-10-29 00:48:03,883 Training Epoch [28/40] Iter[17/312]		Loss: 0.1037
2019-10-29 00:48:04,004 Training Epoch [28/40] Iter[18/312]		Loss: 0.1059
2019-10-29 00:48:04,125 Training Epoch [28/40] Iter[19/312]		Loss: 0.1051
2019-10-29 00:48:04,246 Training Epoch [28/40] Iter[20/312]		Loss: 0.1039
2019-10-29 00:48:04,368 Training Epoch [28/40] Iter[21/312]		Loss: 0.1044
2019-10-29 00:48:04,491 Training Epoch [28/40] Iter[22/312]		Loss: 0.1039
2019-10-29 00:48:04,612 Training Epoch [28/40] Iter[23/312]		Loss: 0.1041
2019-10-29 00:48:04,734 Training Epoch [28/40] Iter[24/312]		Loss: 0.1062
2019-10-29 00:48:04,855 Training Epoch [28/40] Iter[25/312]		Loss: 0.1041
2019-10-29 00:48:04,976 Training Epoch [28/40] Iter[26/312]		Loss: 0.1040
2019-10-29 00:48:05,098 Training Epoch [28/40] Iter[27/312]		Loss: 0.1028
2019-10-29 00:48:05,220 Training Epoch [28/40] Iter[28/312]		Loss: 0.1024
2019-10-29 00:48:05,341 Training Epoch [28/40] Iter[29/312]		Loss: 0.1020
2019-10-29 00:48:05,464 Training Epoch [28/40] Iter[30/312]		Loss: 0.1021
2019-10-29 00:48:05,585 Training Epoch [28/40] Iter[31/312]		Loss: 0.1021
2019-10-29 00:48:05,707 Training Epoch [28/40] Iter[32/312]		Loss: 0.1017
2019-10-29 00:48:05,829 Training Epoch [28/40] Iter[33/312]		Loss: 0.1031
2019-10-29 00:48:05,951 Training Epoch [28/40] Iter[34/312]		Loss: 0.1028
2019-10-29 00:48:06,073 Training Epoch [28/40] Iter[35/312]		Loss: 0.1039
2019-10-29 00:48:06,195 Training Epoch [28/40] Iter[36/312]		Loss: 0.1030
2019-10-29 00:48:06,317 Training Epoch [28/40] Iter[37/312]		Loss: 0.1023
2019-10-29 00:48:06,439 Training Epoch [28/40] Iter[38/312]		Loss: 0.1019
2019-10-29 00:48:06,560 Training Epoch [28/40] Iter[39/312]		Loss: 0.1021
2019-10-29 00:48:06,681 Training Epoch [28/40] Iter[40/312]		Loss: 0.1030
2019-10-29 00:48:06,803 Training Epoch [28/40] Iter[41/312]		Loss: 0.1032
2019-10-29 00:48:06,924 Training Epoch [28/40] Iter[42/312]		Loss: 0.1030
2019-10-29 00:48:07,046 Training Epoch [28/40] Iter[43/312]		Loss: 0.1037
2019-10-29 00:48:07,168 Training Epoch [28/40] Iter[44/312]		Loss: 0.1028
2019-10-29 00:48:07,290 Training Epoch [28/40] Iter[45/312]		Loss: 0.1027
2019-10-29 00:48:07,412 Training Epoch [28/40] Iter[46/312]		Loss: 0.1028
2019-10-29 00:48:07,534 Training Epoch [28/40] Iter[47/312]		Loss: 0.1025
2019-10-29 00:48:07,656 Training Epoch [28/40] Iter[48/312]		Loss: 0.1026
2019-10-29 00:48:07,778 Training Epoch [28/40] Iter[49/312]		Loss: 0.1020
2019-10-29 00:48:07,900 Training Epoch [28/40] Iter[50/312]		Loss: 0.1019
2019-10-29 00:48:08,022 Training Epoch [28/40] Iter[51/312]		Loss: 0.1015
2019-10-29 00:48:08,143 Training Epoch [28/40] Iter[52/312]		Loss: 0.1021
2019-10-29 00:48:08,266 Training Epoch [28/40] Iter[53/312]		Loss: 0.1015
2019-10-29 00:48:08,388 Training Epoch [28/40] Iter[54/312]		Loss: 0.1009
2019-10-29 00:48:08,510 Training Epoch [28/40] Iter[55/312]		Loss: 0.1012
2019-10-29 00:48:08,632 Training Epoch [28/40] Iter[56/312]		Loss: 0.1024
2019-10-29 00:48:08,753 Training Epoch [28/40] Iter[57/312]		Loss: 0.1029
2019-10-29 00:48:08,875 Training Epoch [28/40] Iter[58/312]		Loss: 0.1029
2019-10-29 00:48:08,997 Training Epoch [28/40] Iter[59/312]		Loss: 0.1024
2019-10-29 00:48:09,125 Training Epoch [28/40] Iter[60/312]		Loss: 0.1022
2019-10-29 00:48:09,247 Training Epoch [28/40] Iter[61/312]		Loss: 0.1020
2019-10-29 00:48:09,369 Training Epoch [28/40] Iter[62/312]		Loss: 0.1023
2019-10-29 00:48:09,491 Training Epoch [28/40] Iter[63/312]		Loss: 0.1023
2019-10-29 00:48:09,613 Training Epoch [28/40] Iter[64/312]		Loss: 0.1022
2019-10-29 00:48:09,735 Training Epoch [28/40] Iter[65/312]		Loss: 0.1030
2019-10-29 00:48:09,857 Training Epoch [28/40] Iter[66/312]		Loss: 0.1027
2019-10-29 00:48:09,979 Training Epoch [28/40] Iter[67/312]		Loss: 0.1024
2019-10-29 00:48:10,100 Training Epoch [28/40] Iter[68/312]		Loss: 0.1021
2019-10-29 00:48:10,222 Training Epoch [28/40] Iter[69/312]		Loss: 0.1019
2019-10-29 00:48:10,344 Training Epoch [28/40] Iter[70/312]		Loss: 0.1025
2019-10-29 00:48:10,466 Training Epoch [28/40] Iter[71/312]		Loss: 0.1023
2019-10-29 00:48:10,588 Training Epoch [28/40] Iter[72/312]		Loss: 0.1024
2019-10-29 00:48:10,709 Training Epoch [28/40] Iter[73/312]		Loss: 0.1021
2019-10-29 00:48:10,832 Training Epoch [28/40] Iter[74/312]		Loss: 0.1014
2019-10-29 00:48:10,953 Training Epoch [28/40] Iter[75/312]		Loss: 0.1017
2019-10-29 00:48:11,075 Training Epoch [28/40] Iter[76/312]		Loss: 0.1016
2019-10-29 00:48:11,197 Training Epoch [28/40] Iter[77/312]		Loss: 0.1016
2019-10-29 00:48:11,319 Training Epoch [28/40] Iter[78/312]		Loss: 0.1011
2019-10-29 00:48:11,441 Training Epoch [28/40] Iter[79/312]		Loss: 0.1009
2019-10-29 00:48:11,562 Training Epoch [28/40] Iter[80/312]		Loss: 0.1016
2019-10-29 00:48:11,684 Training Epoch [28/40] Iter[81/312]		Loss: 0.1015
2019-10-29 00:48:11,806 Training Epoch [28/40] Iter[82/312]		Loss: 0.1010
2019-10-29 00:48:11,927 Training Epoch [28/40] Iter[83/312]		Loss: 0.1011
2019-10-29 00:48:12,049 Training Epoch [28/40] Iter[84/312]		Loss: 0.1010
2019-10-29 00:48:12,170 Training Epoch [28/40] Iter[85/312]		Loss: 0.1008
2019-10-29 00:48:12,292 Training Epoch [28/40] Iter[86/312]		Loss: 0.1008
2019-10-29 00:48:12,414 Training Epoch [28/40] Iter[87/312]		Loss: 0.1007
2019-10-29 00:48:12,535 Training Epoch [28/40] Iter[88/312]		Loss: 0.1008
2019-10-29 00:48:12,657 Training Epoch [28/40] Iter[89/312]		Loss: 0.1011
2019-10-29 00:48:12,778 Training Epoch [28/40] Iter[90/312]		Loss: 0.1016
2019-10-29 00:48:12,900 Training Epoch [28/40] Iter[91/312]		Loss: 0.1021
2019-10-29 00:48:13,022 Training Epoch [28/40] Iter[92/312]		Loss: 0.1023
2019-10-29 00:48:13,144 Training Epoch [28/40] Iter[93/312]		Loss: 0.1019
2019-10-29 00:48:13,266 Training Epoch [28/40] Iter[94/312]		Loss: 0.1025
2019-10-29 00:48:13,388 Training Epoch [28/40] Iter[95/312]		Loss: 0.1027
2019-10-29 00:48:13,510 Training Epoch [28/40] Iter[96/312]		Loss: 0.1028
2019-10-29 00:48:13,631 Training Epoch [28/40] Iter[97/312]		Loss: 0.1029
2019-10-29 00:48:13,753 Training Epoch [28/40] Iter[98/312]		Loss: 0.1030
2019-10-29 00:48:13,875 Training Epoch [28/40] Iter[99/312]		Loss: 0.1031
2019-10-29 00:48:13,996 Training Epoch [28/40] Iter[100/312]		Loss: 0.1029
2019-10-29 00:48:14,118 Training Epoch [28/40] Iter[101/312]		Loss: 0.1029
2019-10-29 00:48:14,240 Training Epoch [28/40] Iter[102/312]		Loss: 0.1028
2019-10-29 00:48:14,362 Training Epoch [28/40] Iter[103/312]		Loss: 0.1025
2019-10-29 00:48:14,484 Training Epoch [28/40] Iter[104/312]		Loss: 0.1021
2019-10-29 00:48:14,606 Training Epoch [28/40] Iter[105/312]		Loss: 0.1021
2019-10-29 00:48:14,728 Training Epoch [28/40] Iter[106/312]		Loss: 0.1023
2019-10-29 00:48:14,850 Training Epoch [28/40] Iter[107/312]		Loss: 0.1026
2019-10-29 00:48:14,972 Training Epoch [28/40] Iter[108/312]		Loss: 0.1025
2019-10-29 00:48:15,093 Training Epoch [28/40] Iter[109/312]		Loss: 0.1021
2019-10-29 00:48:15,215 Training Epoch [28/40] Iter[110/312]		Loss: 0.1023
2019-10-29 00:48:15,336 Training Epoch [28/40] Iter[111/312]		Loss: 0.1027
2019-10-29 00:48:15,458 Training Epoch [28/40] Iter[112/312]		Loss: 0.1024
2019-10-29 00:48:15,580 Training Epoch [28/40] Iter[113/312]		Loss: 0.1023
2019-10-29 00:48:15,702 Training Epoch [28/40] Iter[114/312]		Loss: 0.1026
2019-10-29 00:48:15,824 Training Epoch [28/40] Iter[115/312]		Loss: 0.1028
2019-10-29 00:48:15,946 Training Epoch [28/40] Iter[116/312]		Loss: 0.1027
2019-10-29 00:48:16,068 Training Epoch [28/40] Iter[117/312]		Loss: 0.1030
2019-10-29 00:48:16,189 Training Epoch [28/40] Iter[118/312]		Loss: 0.1027
2019-10-29 00:48:16,311 Training Epoch [28/40] Iter[119/312]		Loss: 0.1027
2019-10-29 00:48:16,433 Training Epoch [28/40] Iter[120/312]		Loss: 0.1025
2019-10-29 00:48:16,555 Training Epoch [28/40] Iter[121/312]		Loss: 0.1025
2019-10-29 00:48:16,677 Training Epoch [28/40] Iter[122/312]		Loss: 0.1025
2019-10-29 00:48:16,798 Training Epoch [28/40] Iter[123/312]		Loss: 0.1022
2019-10-29 00:48:16,920 Training Epoch [28/40] Iter[124/312]		Loss: 0.1024
2019-10-29 00:48:17,041 Training Epoch [28/40] Iter[125/312]		Loss: 0.1023
2019-10-29 00:48:17,162 Training Epoch [28/40] Iter[126/312]		Loss: 0.1025
2019-10-29 00:48:17,284 Training Epoch [28/40] Iter[127/312]		Loss: 0.1022
2019-10-29 00:48:17,406 Training Epoch [28/40] Iter[128/312]		Loss: 0.1021
2019-10-29 00:48:17,528 Training Epoch [28/40] Iter[129/312]		Loss: 0.1020
2019-10-29 00:48:17,651 Training Epoch [28/40] Iter[130/312]		Loss: 0.1020
2019-10-29 00:48:17,773 Training Epoch [28/40] Iter[131/312]		Loss: 0.1023
2019-10-29 00:48:17,895 Training Epoch [28/40] Iter[132/312]		Loss: 0.1023
2019-10-29 00:48:18,016 Training Epoch [28/40] Iter[133/312]		Loss: 0.1022
2019-10-29 00:48:18,138 Training Epoch [28/40] Iter[134/312]		Loss: 0.1019
2019-10-29 00:48:18,259 Training Epoch [28/40] Iter[135/312]		Loss: 0.1018
2019-10-29 00:48:18,380 Training Epoch [28/40] Iter[136/312]		Loss: 0.1019
2019-10-29 00:48:18,502 Training Epoch [28/40] Iter[137/312]		Loss: 0.1022
2019-10-29 00:48:18,623 Training Epoch [28/40] Iter[138/312]		Loss: 0.1020
2019-10-29 00:48:18,744 Training Epoch [28/40] Iter[139/312]		Loss: 0.1017
2019-10-29 00:48:18,866 Training Epoch [28/40] Iter[140/312]		Loss: 0.1020
2019-10-29 00:48:18,987 Training Epoch [28/40] Iter[141/312]		Loss: 0.1017
2019-10-29 00:48:19,109 Training Epoch [28/40] Iter[142/312]		Loss: 0.1017
2019-10-29 00:48:19,230 Training Epoch [28/40] Iter[143/312]		Loss: 0.1019
2019-10-29 00:48:19,351 Training Epoch [28/40] Iter[144/312]		Loss: 0.1016
2019-10-29 00:48:19,473 Training Epoch [28/40] Iter[145/312]		Loss: 0.1015
2019-10-29 00:48:19,594 Training Epoch [28/40] Iter[146/312]		Loss: 0.1012
2019-10-29 00:48:19,715 Training Epoch [28/40] Iter[147/312]		Loss: 0.1011
2019-10-29 00:48:19,837 Training Epoch [28/40] Iter[148/312]		Loss: 0.1011
2019-10-29 00:48:19,958 Training Epoch [28/40] Iter[149/312]		Loss: 0.1010
2019-10-29 00:48:20,080 Training Epoch [28/40] Iter[150/312]		Loss: 0.1013
2019-10-29 00:48:20,201 Training Epoch [28/40] Iter[151/312]		Loss: 0.1010
2019-10-29 00:48:20,322 Training Epoch [28/40] Iter[152/312]		Loss: 0.1014
2019-10-29 00:48:20,444 Training Epoch [28/40] Iter[153/312]		Loss: 0.1012
2019-10-29 00:48:20,565 Training Epoch [28/40] Iter[154/312]		Loss: 0.1012
2019-10-29 00:48:20,686 Training Epoch [28/40] Iter[155/312]		Loss: 0.1014
2019-10-29 00:48:20,808 Training Epoch [28/40] Iter[156/312]		Loss: 0.1017
2019-10-29 00:48:20,929 Training Epoch [28/40] Iter[157/312]		Loss: 0.1017
2019-10-29 00:48:21,050 Training Epoch [28/40] Iter[158/312]		Loss: 0.1017
2019-10-29 00:48:21,171 Training Epoch [28/40] Iter[159/312]		Loss: 0.1019
2019-10-29 00:48:21,292 Training Epoch [28/40] Iter[160/312]		Loss: 0.1019
2019-10-29 00:48:21,413 Training Epoch [28/40] Iter[161/312]		Loss: 0.1022
2019-10-29 00:48:21,535 Training Epoch [28/40] Iter[162/312]		Loss: 0.1026
2019-10-29 00:48:21,657 Training Epoch [28/40] Iter[163/312]		Loss: 0.1027
2019-10-29 00:48:21,778 Training Epoch [28/40] Iter[164/312]		Loss: 0.1027
2019-10-29 00:48:21,900 Training Epoch [28/40] Iter[165/312]		Loss: 0.1027
2019-10-29 00:48:22,021 Training Epoch [28/40] Iter[166/312]		Loss: 0.1029
2019-10-29 00:48:22,143 Training Epoch [28/40] Iter[167/312]		Loss: 0.1027
2019-10-29 00:48:22,264 Training Epoch [28/40] Iter[168/312]		Loss: 0.1027
2019-10-29 00:48:22,386 Training Epoch [28/40] Iter[169/312]		Loss: 0.1027
2019-10-29 00:48:22,508 Training Epoch [28/40] Iter[170/312]		Loss: 0.1029
2019-10-29 00:48:22,629 Training Epoch [28/40] Iter[171/312]		Loss: 0.1027
2019-10-29 00:48:22,751 Training Epoch [28/40] Iter[172/312]		Loss: 0.1027
2019-10-29 00:48:22,873 Training Epoch [28/40] Iter[173/312]		Loss: 0.1030
2019-10-29 00:48:22,995 Training Epoch [28/40] Iter[174/312]		Loss: 0.1031
2019-10-29 00:48:23,116 Training Epoch [28/40] Iter[175/312]		Loss: 0.1034
2019-10-29 00:48:23,238 Training Epoch [28/40] Iter[176/312]		Loss: 0.1033
2019-10-29 00:48:23,359 Training Epoch [28/40] Iter[177/312]		Loss: 0.1033
2019-10-29 00:48:23,481 Training Epoch [28/40] Iter[178/312]		Loss: 0.1031
2019-10-29 00:48:23,603 Training Epoch [28/40] Iter[179/312]		Loss: 0.1031
2019-10-29 00:48:23,724 Training Epoch [28/40] Iter[180/312]		Loss: 0.1030
2019-10-29 00:48:23,845 Training Epoch [28/40] Iter[181/312]		Loss: 0.1030
2019-10-29 00:48:23,966 Training Epoch [28/40] Iter[182/312]		Loss: 0.1033
2019-10-29 00:48:24,087 Training Epoch [28/40] Iter[183/312]		Loss: 0.1031
2019-10-29 00:48:24,208 Training Epoch [28/40] Iter[184/312]		Loss: 0.1030
2019-10-29 00:48:24,329 Training Epoch [28/40] Iter[185/312]		Loss: 0.1028
2019-10-29 00:48:24,451 Training Epoch [28/40] Iter[186/312]		Loss: 0.1026
2019-10-29 00:48:24,572 Training Epoch [28/40] Iter[187/312]		Loss: 0.1026
2019-10-29 00:48:24,693 Training Epoch [28/40] Iter[188/312]		Loss: 0.1025
2019-10-29 00:48:24,815 Training Epoch [28/40] Iter[189/312]		Loss: 0.1022
2019-10-29 00:48:24,937 Training Epoch [28/40] Iter[190/312]		Loss: 0.1022
2019-10-29 00:48:25,059 Training Epoch [28/40] Iter[191/312]		Loss: 0.1020
2019-10-29 00:48:25,180 Training Epoch [28/40] Iter[192/312]		Loss: 0.1020
2019-10-29 00:48:25,301 Training Epoch [28/40] Iter[193/312]		Loss: 0.1019
2019-10-29 00:48:25,423 Training Epoch [28/40] Iter[194/312]		Loss: 0.1021
2019-10-29 00:48:25,544 Training Epoch [28/40] Iter[195/312]		Loss: 0.1022
2019-10-29 00:48:25,666 Training Epoch [28/40] Iter[196/312]		Loss: 0.1021
2019-10-29 00:48:25,788 Training Epoch [28/40] Iter[197/312]		Loss: 0.1020
2019-10-29 00:48:25,910 Training Epoch [28/40] Iter[198/312]		Loss: 0.1019
2019-10-29 00:48:26,031 Training Epoch [28/40] Iter[199/312]		Loss: 0.1018
2019-10-29 00:48:26,153 Training Epoch [28/40] Iter[200/312]		Loss: 0.1016
2019-10-29 00:48:26,275 Training Epoch [28/40] Iter[201/312]		Loss: 0.1020
2019-10-29 00:48:26,397 Training Epoch [28/40] Iter[202/312]		Loss: 0.1019
2019-10-29 00:48:26,518 Training Epoch [28/40] Iter[203/312]		Loss: 0.1019
2019-10-29 00:48:26,640 Training Epoch [28/40] Iter[204/312]		Loss: 0.1018
2019-10-29 00:48:26,761 Training Epoch [28/40] Iter[205/312]		Loss: 0.1017
2019-10-29 00:48:26,883 Training Epoch [28/40] Iter[206/312]		Loss: 0.1017
2019-10-29 00:48:27,005 Training Epoch [28/40] Iter[207/312]		Loss: 0.1022
2019-10-29 00:48:27,127 Training Epoch [28/40] Iter[208/312]		Loss: 0.1022
2019-10-29 00:48:27,248 Training Epoch [28/40] Iter[209/312]		Loss: 0.1023
2019-10-29 00:48:27,369 Training Epoch [28/40] Iter[210/312]		Loss: 0.1025
2019-10-29 00:48:27,491 Training Epoch [28/40] Iter[211/312]		Loss: 0.1025
2019-10-29 00:48:27,612 Training Epoch [28/40] Iter[212/312]		Loss: 0.1025
2019-10-29 00:48:27,733 Training Epoch [28/40] Iter[213/312]		Loss: 0.1025
2019-10-29 00:48:27,854 Training Epoch [28/40] Iter[214/312]		Loss: 0.1027
2019-10-29 00:48:27,975 Training Epoch [28/40] Iter[215/312]		Loss: 0.1027
2019-10-29 00:48:28,097 Training Epoch [28/40] Iter[216/312]		Loss: 0.1027
2019-10-29 00:48:28,218 Training Epoch [28/40] Iter[217/312]		Loss: 0.1027
2019-10-29 00:48:28,339 Training Epoch [28/40] Iter[218/312]		Loss: 0.1029
2019-10-29 00:48:28,460 Training Epoch [28/40] Iter[219/312]		Loss: 0.1031
2019-10-29 00:48:28,582 Training Epoch [28/40] Iter[220/312]		Loss: 0.1029
2019-10-29 00:48:28,703 Training Epoch [28/40] Iter[221/312]		Loss: 0.1032
2019-10-29 00:48:28,825 Training Epoch [28/40] Iter[222/312]		Loss: 0.1034
2019-10-29 00:48:28,946 Training Epoch [28/40] Iter[223/312]		Loss: 0.1035
2019-10-29 00:48:29,067 Training Epoch [28/40] Iter[224/312]		Loss: 0.1034
2019-10-29 00:48:29,188 Training Epoch [28/40] Iter[225/312]		Loss: 0.1033
2019-10-29 00:48:29,309 Training Epoch [28/40] Iter[226/312]		Loss: 0.1033
2019-10-29 00:48:29,431 Training Epoch [28/40] Iter[227/312]		Loss: 0.1032
2019-10-29 00:48:29,557 Training Epoch [28/40] Iter[228/312]		Loss: 0.1032
2019-10-29 00:48:29,678 Training Epoch [28/40] Iter[229/312]		Loss: 0.1030
2019-10-29 00:48:29,799 Training Epoch [28/40] Iter[230/312]		Loss: 0.1030
2019-10-29 00:48:29,921 Training Epoch [28/40] Iter[231/312]		Loss: 0.1030
2019-10-29 00:48:30,042 Training Epoch [28/40] Iter[232/312]		Loss: 0.1031
2019-10-29 00:48:30,163 Training Epoch [28/40] Iter[233/312]		Loss: 0.1031
2019-10-29 00:48:30,285 Training Epoch [28/40] Iter[234/312]		Loss: 0.1031
2019-10-29 00:48:30,406 Training Epoch [28/40] Iter[235/312]		Loss: 0.1032
2019-10-29 00:48:30,528 Training Epoch [28/40] Iter[236/312]		Loss: 0.1031
2019-10-29 00:48:30,650 Training Epoch [28/40] Iter[237/312]		Loss: 0.1031
2019-10-29 00:48:30,771 Training Epoch [28/40] Iter[238/312]		Loss: 0.1030
2019-10-29 00:48:30,893 Training Epoch [28/40] Iter[239/312]		Loss: 0.1031
2019-10-29 00:48:31,014 Training Epoch [28/40] Iter[240/312]		Loss: 0.1030
2019-10-29 00:48:31,135 Training Epoch [28/40] Iter[241/312]		Loss: 0.1029
2019-10-29 00:48:31,257 Training Epoch [28/40] Iter[242/312]		Loss: 0.1032
2019-10-29 00:48:31,379 Training Epoch [28/40] Iter[243/312]		Loss: 0.1031
2019-10-29 00:48:31,501 Training Epoch [28/40] Iter[244/312]		Loss: 0.1031
2019-10-29 00:48:31,623 Training Epoch [28/40] Iter[245/312]		Loss: 0.1030
2019-10-29 00:48:31,744 Training Epoch [28/40] Iter[246/312]		Loss: 0.1028
2019-10-29 00:48:31,865 Training Epoch [28/40] Iter[247/312]		Loss: 0.1028
2019-10-29 00:48:31,987 Training Epoch [28/40] Iter[248/312]		Loss: 0.1029
2019-10-29 00:48:32,108 Training Epoch [28/40] Iter[249/312]		Loss: 0.1027
2019-10-29 00:48:32,230 Training Epoch [28/40] Iter[250/312]		Loss: 0.1027
2019-10-29 00:48:32,351 Training Epoch [28/40] Iter[251/312]		Loss: 0.1027
2019-10-29 00:48:32,472 Training Epoch [28/40] Iter[252/312]		Loss: 0.1027
2019-10-29 00:48:32,594 Training Epoch [28/40] Iter[253/312]		Loss: 0.1027
2019-10-29 00:48:32,715 Training Epoch [28/40] Iter[254/312]		Loss: 0.1026
2019-10-29 00:48:32,837 Training Epoch [28/40] Iter[255/312]		Loss: 0.1028
2019-10-29 00:48:32,958 Training Epoch [28/40] Iter[256/312]		Loss: 0.1030
2019-10-29 00:48:33,079 Training Epoch [28/40] Iter[257/312]		Loss: 0.1031
2019-10-29 00:48:33,201 Training Epoch [28/40] Iter[258/312]		Loss: 0.1032
2019-10-29 00:48:33,323 Training Epoch [28/40] Iter[259/312]		Loss: 0.1034
2019-10-29 00:48:33,445 Training Epoch [28/40] Iter[260/312]		Loss: 0.1032
2019-10-29 00:48:33,567 Training Epoch [28/40] Iter[261/312]		Loss: 0.1033
2019-10-29 00:48:33,689 Training Epoch [28/40] Iter[262/312]		Loss: 0.1033
2019-10-29 00:48:33,810 Training Epoch [28/40] Iter[263/312]		Loss: 0.1033
2019-10-29 00:48:33,931 Training Epoch [28/40] Iter[264/312]		Loss: 0.1033
2019-10-29 00:48:34,052 Training Epoch [28/40] Iter[265/312]		Loss: 0.1032
2019-10-29 00:48:34,173 Training Epoch [28/40] Iter[266/312]		Loss: 0.1032
2019-10-29 00:48:34,294 Training Epoch [28/40] Iter[267/312]		Loss: 0.1032
2019-10-29 00:48:34,415 Training Epoch [28/40] Iter[268/312]		Loss: 0.1031
2019-10-29 00:48:34,536 Training Epoch [28/40] Iter[269/312]		Loss: 0.1032
2019-10-29 00:48:34,657 Training Epoch [28/40] Iter[270/312]		Loss: 0.1032
2019-10-29 00:48:34,778 Training Epoch [28/40] Iter[271/312]		Loss: 0.1032
2019-10-29 00:48:34,899 Training Epoch [28/40] Iter[272/312]		Loss: 0.1033
2019-10-29 00:48:35,020 Training Epoch [28/40] Iter[273/312]		Loss: 0.1031
2019-10-29 00:48:35,142 Training Epoch [28/40] Iter[274/312]		Loss: 0.1032
2019-10-29 00:48:35,263 Training Epoch [28/40] Iter[275/312]		Loss: 0.1032
2019-10-29 00:48:35,384 Training Epoch [28/40] Iter[276/312]		Loss: 0.1032
2019-10-29 00:48:35,506 Training Epoch [28/40] Iter[277/312]		Loss: 0.1032
2019-10-29 00:48:35,628 Training Epoch [28/40] Iter[278/312]		Loss: 0.1032
2019-10-29 00:48:35,749 Training Epoch [28/40] Iter[279/312]		Loss: 0.1036
2019-10-29 00:48:35,871 Training Epoch [28/40] Iter[280/312]		Loss: 0.1034
2019-10-29 00:48:35,993 Training Epoch [28/40] Iter[281/312]		Loss: 0.1034
2019-10-29 00:48:36,114 Training Epoch [28/40] Iter[282/312]		Loss: 0.1035
2019-10-29 00:48:36,235 Training Epoch [28/40] Iter[283/312]		Loss: 0.1034
2019-10-29 00:48:36,356 Training Epoch [28/40] Iter[284/312]		Loss: 0.1034
2019-10-29 00:48:36,478 Training Epoch [28/40] Iter[285/312]		Loss: 0.1034
2019-10-29 00:48:36,599 Training Epoch [28/40] Iter[286/312]		Loss: 0.1034
2019-10-29 00:48:36,721 Training Epoch [28/40] Iter[287/312]		Loss: 0.1033
2019-10-29 00:48:36,842 Training Epoch [28/40] Iter[288/312]		Loss: 0.1032
2019-10-29 00:48:36,963 Training Epoch [28/40] Iter[289/312]		Loss: 0.1032
2019-10-29 00:48:37,085 Training Epoch [28/40] Iter[290/312]		Loss: 0.1032
2019-10-29 00:48:37,206 Training Epoch [28/40] Iter[291/312]		Loss: 0.1032
2019-10-29 00:48:37,328 Training Epoch [28/40] Iter[292/312]		Loss: 0.1033
2019-10-29 00:48:37,449 Training Epoch [28/40] Iter[293/312]		Loss: 0.1032
2019-10-29 00:48:37,571 Training Epoch [28/40] Iter[294/312]		Loss: 0.1032
2019-10-29 00:48:37,692 Training Epoch [28/40] Iter[295/312]		Loss: 0.1032
2019-10-29 00:48:37,813 Training Epoch [28/40] Iter[296/312]		Loss: 0.1032
2019-10-29 00:48:37,935 Training Epoch [28/40] Iter[297/312]		Loss: 0.1032
2019-10-29 00:48:38,056 Training Epoch [28/40] Iter[298/312]		Loss: 0.1031
2019-10-29 00:48:38,178 Training Epoch [28/40] Iter[299/312]		Loss: 0.1031
2019-10-29 00:48:38,300 Training Epoch [28/40] Iter[300/312]		Loss: 0.1031
2019-10-29 00:48:38,422 Training Epoch [28/40] Iter[301/312]		Loss: 0.1030
2019-10-29 00:48:38,543 Training Epoch [28/40] Iter[302/312]		Loss: 0.1029
2019-10-29 00:48:38,664 Training Epoch [28/40] Iter[303/312]		Loss: 0.1028
2019-10-29 00:48:38,785 Training Epoch [28/40] Iter[304/312]		Loss: 0.1030
2019-10-29 00:48:38,906 Training Epoch [28/40] Iter[305/312]		Loss: 0.1029
2019-10-29 00:48:39,026 Training Epoch [28/40] Iter[306/312]		Loss: 0.1029
2019-10-29 00:48:39,147 Training Epoch [28/40] Iter[307/312]		Loss: 0.1028
2019-10-29 00:48:39,267 Training Epoch [28/40] Iter[308/312]		Loss: 0.1028
2019-10-29 00:48:39,388 Training Epoch [28/40] Iter[309/312]		Loss: 0.1028
2019-10-29 00:48:39,510 Training Epoch [28/40] Iter[310/312]		Loss: 0.1027
2019-10-29 00:48:39,631 Training Epoch [28/40] Iter[311/312]		Loss: 0.1027
2019-10-29 00:48:39,691 Training Epoch [28/40] Iter[312/312]		Loss: 0.1027
2019-10-29 00:48:40,086 Testing Epoch [28/40] Iter[0/62]		Loss: 0.0963
2019-10-29 00:48:40,126 Testing Epoch [28/40] Iter[1/62]		Loss: 0.1271
2019-10-29 00:48:40,158 Testing Epoch [28/40] Iter[2/62]		Loss: 0.1174
2019-10-29 00:48:40,189 Testing Epoch [28/40] Iter[3/62]		Loss: 0.1151
2019-10-29 00:48:40,229 Testing Epoch [28/40] Iter[4/62]		Loss: 0.1102
2019-10-29 00:48:40,262 Testing Epoch [28/40] Iter[5/62]		Loss: 0.1064
2019-10-29 00:48:40,292 Testing Epoch [28/40] Iter[6/62]		Loss: 0.1078
2019-10-29 00:48:40,322 Testing Epoch [28/40] Iter[7/62]		Loss: 0.1143
2019-10-29 00:48:40,358 Testing Epoch [28/40] Iter[8/62]		Loss: 0.1217
2019-10-29 00:48:40,389 Testing Epoch [28/40] Iter[9/62]		Loss: 0.1195
2019-10-29 00:48:40,419 Testing Epoch [28/40] Iter[10/62]		Loss: 0.1174
2019-10-29 00:48:40,454 Testing Epoch [28/40] Iter[11/62]		Loss: 0.1218
2019-10-29 00:48:40,485 Testing Epoch [28/40] Iter[12/62]		Loss: 0.1223
2019-10-29 00:48:40,515 Testing Epoch [28/40] Iter[13/62]		Loss: 0.1240
2019-10-29 00:48:40,550 Testing Epoch [28/40] Iter[14/62]		Loss: 0.1370
2019-10-29 00:48:40,580 Testing Epoch [28/40] Iter[15/62]		Loss: 0.1385
2019-10-29 00:48:40,611 Testing Epoch [28/40] Iter[16/62]		Loss: 0.1368
2019-10-29 00:48:40,646 Testing Epoch [28/40] Iter[17/62]		Loss: 0.1359
2019-10-29 00:48:40,677 Testing Epoch [28/40] Iter[18/62]		Loss: 0.1326
2019-10-29 00:48:40,708 Testing Epoch [28/40] Iter[19/62]		Loss: 0.1304
2019-10-29 00:48:40,745 Testing Epoch [28/40] Iter[20/62]		Loss: 0.1322
2019-10-29 00:48:40,778 Testing Epoch [28/40] Iter[21/62]		Loss: 0.1304
2019-10-29 00:48:40,809 Testing Epoch [28/40] Iter[22/62]		Loss: 0.1297
2019-10-29 00:48:40,839 Testing Epoch [28/40] Iter[23/62]		Loss: 0.1303
2019-10-29 00:48:40,874 Testing Epoch [28/40] Iter[24/62]		Loss: 0.1320
2019-10-29 00:48:40,905 Testing Epoch [28/40] Iter[25/62]		Loss: 0.1313
2019-10-29 00:48:40,935 Testing Epoch [28/40] Iter[26/62]		Loss: 0.1301
2019-10-29 00:48:40,970 Testing Epoch [28/40] Iter[27/62]		Loss: 0.1350
2019-10-29 00:48:41,001 Testing Epoch [28/40] Iter[28/62]		Loss: 0.1368
2019-10-29 00:48:41,033 Testing Epoch [28/40] Iter[29/62]		Loss: 0.1369
2019-10-29 00:48:41,066 Testing Epoch [28/40] Iter[30/62]		Loss: 0.1385
2019-10-29 00:48:41,097 Testing Epoch [28/40] Iter[31/62]		Loss: 0.1379
2019-10-29 00:48:41,128 Testing Epoch [28/40] Iter[32/62]		Loss: 0.1395
2019-10-29 00:48:41,162 Testing Epoch [28/40] Iter[33/62]		Loss: 0.1375
2019-10-29 00:48:41,193 Testing Epoch [28/40] Iter[34/62]		Loss: 0.1390
2019-10-29 00:48:41,224 Testing Epoch [28/40] Iter[35/62]		Loss: 0.1392
2019-10-29 00:48:41,261 Testing Epoch [28/40] Iter[36/62]		Loss: 0.1374
2019-10-29 00:48:41,292 Testing Epoch [28/40] Iter[37/62]		Loss: 0.1371
2019-10-29 00:48:41,323 Testing Epoch [28/40] Iter[38/62]		Loss: 0.1373
2019-10-29 00:48:41,354 Testing Epoch [28/40] Iter[39/62]		Loss: 0.1377
2019-10-29 00:48:41,385 Testing Epoch [28/40] Iter[40/62]		Loss: 0.1381
2019-10-29 00:48:41,415 Testing Epoch [28/40] Iter[41/62]		Loss: 0.1381
2019-10-29 00:48:41,446 Testing Epoch [28/40] Iter[42/62]		Loss: 0.1367
2019-10-29 00:48:41,477 Testing Epoch [28/40] Iter[43/62]		Loss: 0.1361
2019-10-29 00:48:41,508 Testing Epoch [28/40] Iter[44/62]		Loss: 0.1349
2019-10-29 00:48:41,538 Testing Epoch [28/40] Iter[45/62]		Loss: 0.1359
2019-10-29 00:48:41,569 Testing Epoch [28/40] Iter[46/62]		Loss: 0.1360
2019-10-29 00:48:41,600 Testing Epoch [28/40] Iter[47/62]		Loss: 0.1409
2019-10-29 00:48:41,631 Testing Epoch [28/40] Iter[48/62]		Loss: 0.1400
2019-10-29 00:48:41,661 Testing Epoch [28/40] Iter[49/62]		Loss: 0.1416
2019-10-29 00:48:41,692 Testing Epoch [28/40] Iter[50/62]		Loss: 0.1411
2019-10-29 00:48:41,723 Testing Epoch [28/40] Iter[51/62]		Loss: 0.1412
2019-10-29 00:48:41,753 Testing Epoch [28/40] Iter[52/62]		Loss: 0.1401
2019-10-29 00:48:41,784 Testing Epoch [28/40] Iter[53/62]		Loss: 0.1400
2019-10-29 00:48:41,815 Testing Epoch [28/40] Iter[54/62]		Loss: 0.1394
2019-10-29 00:48:41,845 Testing Epoch [28/40] Iter[55/62]		Loss: 0.1396
2019-10-29 00:48:41,876 Testing Epoch [28/40] Iter[56/62]		Loss: 0.1393
2019-10-29 00:48:41,906 Testing Epoch [28/40] Iter[57/62]		Loss: 0.1391
2019-10-29 00:48:41,936 Testing Epoch [28/40] Iter[58/62]		Loss: 0.1386
2019-10-29 00:48:41,967 Testing Epoch [28/40] Iter[59/62]		Loss: 0.1386
2019-10-29 00:48:41,997 Testing Epoch [28/40] Iter[60/62]		Loss: 0.1379
2019-10-29 00:48:42,027 Testing Epoch [28/40] Iter[61/62]		Loss: 0.1377
2019-10-29 00:48:42,045 Testing Epoch [28/40] Iter[62/62]		Loss: 0.1385
2019-10-29 00:48:42,540 Training Epoch [29/40] Iter[0/312]		Loss: 0.1045
2019-10-29 00:48:42,664 Training Epoch [29/40] Iter[1/312]		Loss: 0.1226
2019-10-29 00:48:42,785 Training Epoch [29/40] Iter[2/312]		Loss: 0.1218
2019-10-29 00:48:42,905 Training Epoch [29/40] Iter[3/312]		Loss: 0.1131
2019-10-29 00:48:43,029 Training Epoch [29/40] Iter[4/312]		Loss: 0.1127
2019-10-29 00:48:43,149 Training Epoch [29/40] Iter[5/312]		Loss: 0.1058
2019-10-29 00:48:43,270 Training Epoch [29/40] Iter[6/312]		Loss: 0.1011
2019-10-29 00:48:43,394 Training Epoch [29/40] Iter[7/312]		Loss: 0.0990
2019-10-29 00:48:43,515 Training Epoch [29/40] Iter[8/312]		Loss: 0.1025
2019-10-29 00:48:43,637 Training Epoch [29/40] Iter[9/312]		Loss: 0.1042
2019-10-29 00:48:43,758 Training Epoch [29/40] Iter[10/312]		Loss: 0.1017
2019-10-29 00:48:43,879 Training Epoch [29/40] Iter[11/312]		Loss: 0.1007
2019-10-29 00:48:44,001 Training Epoch [29/40] Iter[12/312]		Loss: 0.1056
2019-10-29 00:48:44,122 Training Epoch [29/40] Iter[13/312]		Loss: 0.1074
2019-10-29 00:48:44,244 Training Epoch [29/40] Iter[14/312]		Loss: 0.1093
2019-10-29 00:48:44,366 Training Epoch [29/40] Iter[15/312]		Loss: 0.1063
2019-10-29 00:48:44,487 Training Epoch [29/40] Iter[16/312]		Loss: 0.1091
2019-10-29 00:48:44,608 Training Epoch [29/40] Iter[17/312]		Loss: 0.1085
2019-10-29 00:48:44,730 Training Epoch [29/40] Iter[18/312]		Loss: 0.1065
2019-10-29 00:48:44,851 Training Epoch [29/40] Iter[19/312]		Loss: 0.1046
2019-10-29 00:48:44,972 Training Epoch [29/40] Iter[20/312]		Loss: 0.1043
2019-10-29 00:48:45,094 Training Epoch [29/40] Iter[21/312]		Loss: 0.1037
2019-10-29 00:48:45,215 Training Epoch [29/40] Iter[22/312]		Loss: 0.1055
2019-10-29 00:48:45,336 Training Epoch [29/40] Iter[23/312]		Loss: 0.1055
2019-10-29 00:48:45,457 Training Epoch [29/40] Iter[24/312]		Loss: 0.1045
2019-10-29 00:48:45,579 Training Epoch [29/40] Iter[25/312]		Loss: 0.1068
2019-10-29 00:48:45,700 Training Epoch [29/40] Iter[26/312]		Loss: 0.1123
2019-10-29 00:48:45,822 Training Epoch [29/40] Iter[27/312]		Loss: 0.1106
2019-10-29 00:48:45,943 Training Epoch [29/40] Iter[28/312]		Loss: 0.1097
2019-10-29 00:48:46,064 Training Epoch [29/40] Iter[29/312]		Loss: 0.1099
2019-10-29 00:48:46,185 Training Epoch [29/40] Iter[30/312]		Loss: 0.1110
2019-10-29 00:48:46,307 Training Epoch [29/40] Iter[31/312]		Loss: 0.1103
2019-10-29 00:48:46,428 Training Epoch [29/40] Iter[32/312]		Loss: 0.1105
2019-10-29 00:48:46,549 Training Epoch [29/40] Iter[33/312]		Loss: 0.1097
2019-10-29 00:48:46,671 Training Epoch [29/40] Iter[34/312]		Loss: 0.1104
2019-10-29 00:48:46,792 Training Epoch [29/40] Iter[35/312]		Loss: 0.1094
2019-10-29 00:48:46,913 Training Epoch [29/40] Iter[36/312]		Loss: 0.1098
2019-10-29 00:48:47,034 Training Epoch [29/40] Iter[37/312]		Loss: 0.1104
2019-10-29 00:48:47,155 Training Epoch [29/40] Iter[38/312]		Loss: 0.1105
2019-10-29 00:48:47,276 Training Epoch [29/40] Iter[39/312]		Loss: 0.1101
2019-10-29 00:48:47,398 Training Epoch [29/40] Iter[40/312]		Loss: 0.1096
2019-10-29 00:48:47,519 Training Epoch [29/40] Iter[41/312]		Loss: 0.1089
2019-10-29 00:48:47,640 Training Epoch [29/40] Iter[42/312]		Loss: 0.1089
2019-10-29 00:48:47,761 Training Epoch [29/40] Iter[43/312]		Loss: 0.1085
2019-10-29 00:48:47,882 Training Epoch [29/40] Iter[44/312]		Loss: 0.1092
2019-10-29 00:48:48,003 Training Epoch [29/40] Iter[45/312]		Loss: 0.1085
2019-10-29 00:48:48,124 Training Epoch [29/40] Iter[46/312]		Loss: 0.1080
2019-10-29 00:48:48,245 Training Epoch [29/40] Iter[47/312]		Loss: 0.1073
2019-10-29 00:48:48,367 Training Epoch [29/40] Iter[48/312]		Loss: 0.1074
2019-10-29 00:48:48,490 Training Epoch [29/40] Iter[49/312]		Loss: 0.1087
2019-10-29 00:48:48,612 Training Epoch [29/40] Iter[50/312]		Loss: 0.1086
2019-10-29 00:48:48,734 Training Epoch [29/40] Iter[51/312]		Loss: 0.1081
2019-10-29 00:48:48,855 Training Epoch [29/40] Iter[52/312]		Loss: 0.1085
2019-10-29 00:48:48,980 Training Epoch [29/40] Iter[53/312]		Loss: 0.1084
2019-10-29 00:48:49,108 Training Epoch [29/40] Iter[54/312]		Loss: 0.1080
2019-10-29 00:48:49,232 Training Epoch [29/40] Iter[55/312]		Loss: 0.1075
2019-10-29 00:48:49,354 Training Epoch [29/40] Iter[56/312]		Loss: 0.1069
2019-10-29 00:48:49,477 Training Epoch [29/40] Iter[57/312]		Loss: 0.1066
2019-10-29 00:48:49,598 Training Epoch [29/40] Iter[58/312]		Loss: 0.1062
2019-10-29 00:48:49,724 Training Epoch [29/40] Iter[59/312]		Loss: 0.1059
2019-10-29 00:48:49,849 Training Epoch [29/40] Iter[60/312]		Loss: 0.1059
2019-10-29 00:48:49,972 Training Epoch [29/40] Iter[61/312]		Loss: 0.1053
2019-10-29 00:48:50,099 Training Epoch [29/40] Iter[62/312]		Loss: 0.1048
2019-10-29 00:48:50,220 Training Epoch [29/40] Iter[63/312]		Loss: 0.1042
2019-10-29 00:48:50,342 Training Epoch [29/40] Iter[64/312]		Loss: 0.1037
2019-10-29 00:48:50,464 Training Epoch [29/40] Iter[65/312]		Loss: 0.1032
2019-10-29 00:48:50,588 Training Epoch [29/40] Iter[66/312]		Loss: 0.1033
2019-10-29 00:48:50,709 Training Epoch [29/40] Iter[67/312]		Loss: 0.1030
2019-10-29 00:48:50,830 Training Epoch [29/40] Iter[68/312]		Loss: 0.1035
2019-10-29 00:48:50,952 Training Epoch [29/40] Iter[69/312]		Loss: 0.1037
2019-10-29 00:48:51,076 Training Epoch [29/40] Iter[70/312]		Loss: 0.1033
2019-10-29 00:48:51,197 Training Epoch [29/40] Iter[71/312]		Loss: 0.1035
2019-10-29 00:48:51,318 Training Epoch [29/40] Iter[72/312]		Loss: 0.1036
2019-10-29 00:48:51,440 Training Epoch [29/40] Iter[73/312]		Loss: 0.1044
2019-10-29 00:48:51,568 Training Epoch [29/40] Iter[74/312]		Loss: 0.1051
2019-10-29 00:48:51,689 Training Epoch [29/40] Iter[75/312]		Loss: 0.1050
2019-10-29 00:48:51,811 Training Epoch [29/40] Iter[76/312]		Loss: 0.1045
2019-10-29 00:48:51,932 Training Epoch [29/40] Iter[77/312]		Loss: 0.1045
2019-10-29 00:48:52,053 Training Epoch [29/40] Iter[78/312]		Loss: 0.1048
2019-10-29 00:48:52,175 Training Epoch [29/40] Iter[79/312]		Loss: 0.1051
2019-10-29 00:48:52,296 Training Epoch [29/40] Iter[80/312]		Loss: 0.1048
2019-10-29 00:48:52,418 Training Epoch [29/40] Iter[81/312]		Loss: 0.1054
2019-10-29 00:48:52,539 Training Epoch [29/40] Iter[82/312]		Loss: 0.1053
2019-10-29 00:48:52,661 Training Epoch [29/40] Iter[83/312]		Loss: 0.1052
2019-10-29 00:48:52,782 Training Epoch [29/40] Iter[84/312]		Loss: 0.1048
2019-10-29 00:48:52,904 Training Epoch [29/40] Iter[85/312]		Loss: 0.1050
2019-10-29 00:48:53,025 Training Epoch [29/40] Iter[86/312]		Loss: 0.1048
2019-10-29 00:48:53,147 Training Epoch [29/40] Iter[87/312]		Loss: 0.1054
2019-10-29 00:48:53,268 Training Epoch [29/40] Iter[88/312]		Loss: 0.1060
2019-10-29 00:48:53,390 Training Epoch [29/40] Iter[89/312]		Loss: 0.1059
2019-10-29 00:48:53,513 Training Epoch [29/40] Iter[90/312]		Loss: 0.1057
2019-10-29 00:48:53,634 Training Epoch [29/40] Iter[91/312]		Loss: 0.1054
2019-10-29 00:48:53,756 Training Epoch [29/40] Iter[92/312]		Loss: 0.1058
2019-10-29 00:48:53,878 Training Epoch [29/40] Iter[93/312]		Loss: 0.1056
2019-10-29 00:48:53,999 Training Epoch [29/40] Iter[94/312]		Loss: 0.1054
2019-10-29 00:48:54,121 Training Epoch [29/40] Iter[95/312]		Loss: 0.1056
2019-10-29 00:48:54,242 Training Epoch [29/40] Iter[96/312]		Loss: 0.1054
2019-10-29 00:48:54,364 Training Epoch [29/40] Iter[97/312]		Loss: 0.1052
2019-10-29 00:48:54,485 Training Epoch [29/40] Iter[98/312]		Loss: 0.1050
2019-10-29 00:48:54,606 Training Epoch [29/40] Iter[99/312]		Loss: 0.1051
2019-10-29 00:48:54,727 Training Epoch [29/40] Iter[100/312]		Loss: 0.1053
2019-10-29 00:48:54,849 Training Epoch [29/40] Iter[101/312]		Loss: 0.1054
2019-10-29 00:48:54,971 Training Epoch [29/40] Iter[102/312]		Loss: 0.1050
2019-10-29 00:48:55,092 Training Epoch [29/40] Iter[103/312]		Loss: 0.1057
2019-10-29 00:48:55,214 Training Epoch [29/40] Iter[104/312]		Loss: 0.1055
2019-10-29 00:48:55,335 Training Epoch [29/40] Iter[105/312]		Loss: 0.1057
2019-10-29 00:48:55,457 Training Epoch [29/40] Iter[106/312]		Loss: 0.1055
2019-10-29 00:48:55,578 Training Epoch [29/40] Iter[107/312]		Loss: 0.1053
2019-10-29 00:48:55,700 Training Epoch [29/40] Iter[108/312]		Loss: 0.1052
2019-10-29 00:48:55,821 Training Epoch [29/40] Iter[109/312]		Loss: 0.1050
2019-10-29 00:48:55,941 Training Epoch [29/40] Iter[110/312]		Loss: 0.1050
2019-10-29 00:48:56,062 Training Epoch [29/40] Iter[111/312]		Loss: 0.1049
2019-10-29 00:48:56,183 Training Epoch [29/40] Iter[112/312]		Loss: 0.1046
2019-10-29 00:48:56,304 Training Epoch [29/40] Iter[113/312]		Loss: 0.1049
2019-10-29 00:48:56,425 Training Epoch [29/40] Iter[114/312]		Loss: 0.1054
2019-10-29 00:48:56,546 Training Epoch [29/40] Iter[115/312]		Loss: 0.1053
2019-10-29 00:48:56,667 Training Epoch [29/40] Iter[116/312]		Loss: 0.1053
2019-10-29 00:48:56,788 Training Epoch [29/40] Iter[117/312]		Loss: 0.1055
2019-10-29 00:48:56,909 Training Epoch [29/40] Iter[118/312]		Loss: 0.1052
2019-10-29 00:48:57,030 Training Epoch [29/40] Iter[119/312]		Loss: 0.1049
2019-10-29 00:48:57,151 Training Epoch [29/40] Iter[120/312]		Loss: 0.1048
2019-10-29 00:48:57,272 Training Epoch [29/40] Iter[121/312]		Loss: 0.1046
2019-10-29 00:48:57,394 Training Epoch [29/40] Iter[122/312]		Loss: 0.1044
2019-10-29 00:48:57,516 Training Epoch [29/40] Iter[123/312]		Loss: 0.1041
2019-10-29 00:48:57,637 Training Epoch [29/40] Iter[124/312]		Loss: 0.1041
2019-10-29 00:48:57,759 Training Epoch [29/40] Iter[125/312]		Loss: 0.1038
2019-10-29 00:48:57,881 Training Epoch [29/40] Iter[126/312]		Loss: 0.1038
2019-10-29 00:48:58,002 Training Epoch [29/40] Iter[127/312]		Loss: 0.1040
2019-10-29 00:48:58,123 Training Epoch [29/40] Iter[128/312]		Loss: 0.1040
2019-10-29 00:48:58,245 Training Epoch [29/40] Iter[129/312]		Loss: 0.1037
2019-10-29 00:48:58,367 Training Epoch [29/40] Iter[130/312]		Loss: 0.1035
2019-10-29 00:48:58,489 Training Epoch [29/40] Iter[131/312]		Loss: 0.1034
2019-10-29 00:48:58,612 Training Epoch [29/40] Iter[132/312]		Loss: 0.1034
2019-10-29 00:48:58,734 Training Epoch [29/40] Iter[133/312]		Loss: 0.1031
2019-10-29 00:48:58,855 Training Epoch [29/40] Iter[134/312]		Loss: 0.1029
2019-10-29 00:48:58,977 Training Epoch [29/40] Iter[135/312]		Loss: 0.1031
2019-10-29 00:48:59,098 Training Epoch [29/40] Iter[136/312]		Loss: 0.1032
2019-10-29 00:48:59,220 Training Epoch [29/40] Iter[137/312]		Loss: 0.1030
2019-10-29 00:48:59,341 Training Epoch [29/40] Iter[138/312]		Loss: 0.1031
2019-10-29 00:48:59,462 Training Epoch [29/40] Iter[139/312]		Loss: 0.1036
2019-10-29 00:48:59,583 Training Epoch [29/40] Iter[140/312]		Loss: 0.1034
2019-10-29 00:48:59,704 Training Epoch [29/40] Iter[141/312]		Loss: 0.1036
2019-10-29 00:48:59,825 Training Epoch [29/40] Iter[142/312]		Loss: 0.1035
2019-10-29 00:48:59,947 Training Epoch [29/40] Iter[143/312]		Loss: 0.1033
2019-10-29 00:49:00,068 Training Epoch [29/40] Iter[144/312]		Loss: 0.1033
2019-10-29 00:49:00,189 Training Epoch [29/40] Iter[145/312]		Loss: 0.1034
2019-10-29 00:49:00,310 Training Epoch [29/40] Iter[146/312]		Loss: 0.1037
2019-10-29 00:49:00,432 Training Epoch [29/40] Iter[147/312]		Loss: 0.1037
2019-10-29 00:49:00,553 Training Epoch [29/40] Iter[148/312]		Loss: 0.1037
2019-10-29 00:49:00,675 Training Epoch [29/40] Iter[149/312]		Loss: 0.1041
2019-10-29 00:49:00,797 Training Epoch [29/40] Iter[150/312]		Loss: 0.1043
2019-10-29 00:49:00,919 Training Epoch [29/40] Iter[151/312]		Loss: 0.1042
2019-10-29 00:49:01,040 Training Epoch [29/40] Iter[152/312]		Loss: 0.1042
2019-10-29 00:49:01,161 Training Epoch [29/40] Iter[153/312]		Loss: 0.1041
2019-10-29 00:49:01,283 Training Epoch [29/40] Iter[154/312]		Loss: 0.1041
2019-10-29 00:49:01,404 Training Epoch [29/40] Iter[155/312]		Loss: 0.1040
2019-10-29 00:49:01,525 Training Epoch [29/40] Iter[156/312]		Loss: 0.1042
2019-10-29 00:49:01,646 Training Epoch [29/40] Iter[157/312]		Loss: 0.1039
2019-10-29 00:49:01,768 Training Epoch [29/40] Iter[158/312]		Loss: 0.1038
2019-10-29 00:49:01,889 Training Epoch [29/40] Iter[159/312]		Loss: 0.1037
2019-10-29 00:49:02,011 Training Epoch [29/40] Iter[160/312]		Loss: 0.1038
2019-10-29 00:49:02,133 Training Epoch [29/40] Iter[161/312]		Loss: 0.1036
2019-10-29 00:49:02,255 Training Epoch [29/40] Iter[162/312]		Loss: 0.1039
2019-10-29 00:49:02,376 Training Epoch [29/40] Iter[163/312]		Loss: 0.1043
2019-10-29 00:49:02,498 Training Epoch [29/40] Iter[164/312]		Loss: 0.1041
2019-10-29 00:49:02,619 Training Epoch [29/40] Iter[165/312]		Loss: 0.1039
2019-10-29 00:49:02,741 Training Epoch [29/40] Iter[166/312]		Loss: 0.1038
2019-10-29 00:49:02,862 Training Epoch [29/40] Iter[167/312]		Loss: 0.1036
2019-10-29 00:49:02,984 Training Epoch [29/40] Iter[168/312]		Loss: 0.1037
2019-10-29 00:49:03,105 Training Epoch [29/40] Iter[169/312]		Loss: 0.1036
2019-10-29 00:49:03,227 Training Epoch [29/40] Iter[170/312]		Loss: 0.1033
2019-10-29 00:49:03,348 Training Epoch [29/40] Iter[171/312]		Loss: 0.1034
2019-10-29 00:49:03,469 Training Epoch [29/40] Iter[172/312]		Loss: 0.1033
2019-10-29 00:49:03,591 Training Epoch [29/40] Iter[173/312]		Loss: 0.1032
2019-10-29 00:49:03,713 Training Epoch [29/40] Iter[174/312]		Loss: 0.1030
2019-10-29 00:49:03,834 Training Epoch [29/40] Iter[175/312]		Loss: 0.1028
2019-10-29 00:49:03,956 Training Epoch [29/40] Iter[176/312]		Loss: 0.1027
2019-10-29 00:49:04,077 Training Epoch [29/40] Iter[177/312]		Loss: 0.1030
2019-10-29 00:49:04,199 Training Epoch [29/40] Iter[178/312]		Loss: 0.1028
2019-10-29 00:49:04,320 Training Epoch [29/40] Iter[179/312]		Loss: 0.1028
2019-10-29 00:49:04,442 Training Epoch [29/40] Iter[180/312]		Loss: 0.1027
2019-10-29 00:49:04,563 Training Epoch [29/40] Iter[181/312]		Loss: 0.1028
2019-10-29 00:49:04,684 Training Epoch [29/40] Iter[182/312]		Loss: 0.1025
2019-10-29 00:49:04,805 Training Epoch [29/40] Iter[183/312]		Loss: 0.1025
2019-10-29 00:49:04,927 Training Epoch [29/40] Iter[184/312]		Loss: 0.1028
2019-10-29 00:49:05,048 Training Epoch [29/40] Iter[185/312]		Loss: 0.1028
2019-10-29 00:49:05,169 Training Epoch [29/40] Iter[186/312]		Loss: 0.1027
2019-10-29 00:49:05,290 Training Epoch [29/40] Iter[187/312]		Loss: 0.1026
2019-10-29 00:49:05,412 Training Epoch [29/40] Iter[188/312]		Loss: 0.1025
2019-10-29 00:49:05,533 Training Epoch [29/40] Iter[189/312]		Loss: 0.1023
2019-10-29 00:49:05,654 Training Epoch [29/40] Iter[190/312]		Loss: 0.1024
2019-10-29 00:49:05,775 Training Epoch [29/40] Iter[191/312]		Loss: 0.1022
2019-10-29 00:49:05,897 Training Epoch [29/40] Iter[192/312]		Loss: 0.1023
2019-10-29 00:49:06,019 Training Epoch [29/40] Iter[193/312]		Loss: 0.1024
2019-10-29 00:49:06,140 Training Epoch [29/40] Iter[194/312]		Loss: 0.1024
2019-10-29 00:49:06,262 Training Epoch [29/40] Iter[195/312]		Loss: 0.1024
2019-10-29 00:49:06,383 Training Epoch [29/40] Iter[196/312]		Loss: 0.1023
2019-10-29 00:49:06,505 Training Epoch [29/40] Iter[197/312]		Loss: 0.1022
2019-10-29 00:49:06,627 Training Epoch [29/40] Iter[198/312]		Loss: 0.1022
2019-10-29 00:49:06,748 Training Epoch [29/40] Iter[199/312]		Loss: 0.1022
2019-10-29 00:49:06,869 Training Epoch [29/40] Iter[200/312]		Loss: 0.1023
2019-10-29 00:49:06,991 Training Epoch [29/40] Iter[201/312]		Loss: 0.1022
2019-10-29 00:49:07,113 Training Epoch [29/40] Iter[202/312]		Loss: 0.1022
2019-10-29 00:49:07,235 Training Epoch [29/40] Iter[203/312]		Loss: 0.1022
2019-10-29 00:49:07,357 Training Epoch [29/40] Iter[204/312]		Loss: 0.1023
2019-10-29 00:49:07,478 Training Epoch [29/40] Iter[205/312]		Loss: 0.1021
2019-10-29 00:49:07,600 Training Epoch [29/40] Iter[206/312]		Loss: 0.1021
2019-10-29 00:49:07,721 Training Epoch [29/40] Iter[207/312]		Loss: 0.1020
2019-10-29 00:49:07,842 Training Epoch [29/40] Iter[208/312]		Loss: 0.1019
2019-10-29 00:49:07,964 Training Epoch [29/40] Iter[209/312]		Loss: 0.1019
2019-10-29 00:49:08,085 Training Epoch [29/40] Iter[210/312]		Loss: 0.1019
2019-10-29 00:49:08,206 Training Epoch [29/40] Iter[211/312]		Loss: 0.1020
2019-10-29 00:49:08,328 Training Epoch [29/40] Iter[212/312]		Loss: 0.1019
2019-10-29 00:49:08,449 Training Epoch [29/40] Iter[213/312]		Loss: 0.1019
2019-10-29 00:49:08,570 Training Epoch [29/40] Iter[214/312]		Loss: 0.1020
2019-10-29 00:49:08,692 Training Epoch [29/40] Iter[215/312]		Loss: 0.1021
2019-10-29 00:49:08,813 Training Epoch [29/40] Iter[216/312]		Loss: 0.1020
2019-10-29 00:49:08,934 Training Epoch [29/40] Iter[217/312]		Loss: 0.1020
2019-10-29 00:49:09,056 Training Epoch [29/40] Iter[218/312]		Loss: 0.1019
2019-10-29 00:49:09,177 Training Epoch [29/40] Iter[219/312]		Loss: 0.1021
2019-10-29 00:49:09,300 Training Epoch [29/40] Iter[220/312]		Loss: 0.1022
2019-10-29 00:49:09,421 Training Epoch [29/40] Iter[221/312]		Loss: 0.1020
2019-10-29 00:49:09,543 Training Epoch [29/40] Iter[222/312]		Loss: 0.1022
2019-10-29 00:49:09,665 Training Epoch [29/40] Iter[223/312]		Loss: 0.1026
2019-10-29 00:49:09,787 Training Epoch [29/40] Iter[224/312]		Loss: 0.1028
2019-10-29 00:49:09,908 Training Epoch [29/40] Iter[225/312]		Loss: 0.1028
2019-10-29 00:49:10,030 Training Epoch [29/40] Iter[226/312]		Loss: 0.1029
2019-10-29 00:49:10,151 Training Epoch [29/40] Iter[227/312]		Loss: 0.1029
2019-10-29 00:49:10,273 Training Epoch [29/40] Iter[228/312]		Loss: 0.1028
2019-10-29 00:49:10,395 Training Epoch [29/40] Iter[229/312]		Loss: 0.1028
2019-10-29 00:49:10,517 Training Epoch [29/40] Iter[230/312]		Loss: 0.1027
2019-10-29 00:49:10,638 Training Epoch [29/40] Iter[231/312]		Loss: 0.1029
2019-10-29 00:49:10,760 Training Epoch [29/40] Iter[232/312]		Loss: 0.1029
2019-10-29 00:49:10,881 Training Epoch [29/40] Iter[233/312]		Loss: 0.1029
2019-10-29 00:49:11,003 Training Epoch [29/40] Iter[234/312]		Loss: 0.1029
2019-10-29 00:49:11,124 Training Epoch [29/40] Iter[235/312]		Loss: 0.1029
2019-10-29 00:49:11,246 Training Epoch [29/40] Iter[236/312]		Loss: 0.1030
2019-10-29 00:49:11,367 Training Epoch [29/40] Iter[237/312]		Loss: 0.1030
2019-10-29 00:49:11,488 Training Epoch [29/40] Iter[238/312]		Loss: 0.1031
2019-10-29 00:49:11,610 Training Epoch [29/40] Iter[239/312]		Loss: 0.1031
2019-10-29 00:49:11,732 Training Epoch [29/40] Iter[240/312]		Loss: 0.1030
2019-10-29 00:49:11,853 Training Epoch [29/40] Iter[241/312]		Loss: 0.1030
2019-10-29 00:49:11,974 Training Epoch [29/40] Iter[242/312]		Loss: 0.1033
2019-10-29 00:49:12,096 Training Epoch [29/40] Iter[243/312]		Loss: 0.1032
2019-10-29 00:49:12,217 Training Epoch [29/40] Iter[244/312]		Loss: 0.1032
2019-10-29 00:49:12,339 Training Epoch [29/40] Iter[245/312]		Loss: 0.1032
2019-10-29 00:49:12,461 Training Epoch [29/40] Iter[246/312]		Loss: 0.1033
2019-10-29 00:49:12,582 Training Epoch [29/40] Iter[247/312]		Loss: 0.1031
2019-10-29 00:49:12,704 Training Epoch [29/40] Iter[248/312]		Loss: 0.1032
2019-10-29 00:49:12,825 Training Epoch [29/40] Iter[249/312]		Loss: 0.1031
2019-10-29 00:49:12,947 Training Epoch [29/40] Iter[250/312]		Loss: 0.1031
2019-10-29 00:49:13,068 Training Epoch [29/40] Iter[251/312]		Loss: 0.1030
2019-10-29 00:49:13,189 Training Epoch [29/40] Iter[252/312]		Loss: 0.1029
2019-10-29 00:49:13,310 Training Epoch [29/40] Iter[253/312]		Loss: 0.1028
2019-10-29 00:49:13,431 Training Epoch [29/40] Iter[254/312]		Loss: 0.1029
2019-10-29 00:49:13,552 Training Epoch [29/40] Iter[255/312]		Loss: 0.1028
2019-10-29 00:49:13,674 Training Epoch [29/40] Iter[256/312]		Loss: 0.1028
2019-10-29 00:49:13,795 Training Epoch [29/40] Iter[257/312]		Loss: 0.1028
2019-10-29 00:49:13,916 Training Epoch [29/40] Iter[258/312]		Loss: 0.1026
2019-10-29 00:49:14,039 Training Epoch [29/40] Iter[259/312]		Loss: 0.1026
2019-10-29 00:49:14,161 Training Epoch [29/40] Iter[260/312]		Loss: 0.1026
2019-10-29 00:49:14,283 Training Epoch [29/40] Iter[261/312]		Loss: 0.1026
2019-10-29 00:49:14,404 Training Epoch [29/40] Iter[262/312]		Loss: 0.1025
2019-10-29 00:49:14,526 Training Epoch [29/40] Iter[263/312]		Loss: 0.1025
2019-10-29 00:49:14,648 Training Epoch [29/40] Iter[264/312]		Loss: 0.1028
2019-10-29 00:49:14,769 Training Epoch [29/40] Iter[265/312]		Loss: 0.1030
2019-10-29 00:49:14,890 Training Epoch [29/40] Iter[266/312]		Loss: 0.1030
2019-10-29 00:49:15,012 Training Epoch [29/40] Iter[267/312]		Loss: 0.1030
2019-10-29 00:49:15,133 Training Epoch [29/40] Iter[268/312]		Loss: 0.1030
2019-10-29 00:49:15,255 Training Epoch [29/40] Iter[269/312]		Loss: 0.1032
2019-10-29 00:49:15,376 Training Epoch [29/40] Iter[270/312]		Loss: 0.1031
2019-10-29 00:49:15,498 Training Epoch [29/40] Iter[271/312]		Loss: 0.1031
2019-10-29 00:49:15,620 Training Epoch [29/40] Iter[272/312]		Loss: 0.1032
2019-10-29 00:49:15,742 Training Epoch [29/40] Iter[273/312]		Loss: 0.1031
2019-10-29 00:49:15,864 Training Epoch [29/40] Iter[274/312]		Loss: 0.1030
2019-10-29 00:49:15,985 Training Epoch [29/40] Iter[275/312]		Loss: 0.1029
2019-10-29 00:49:16,107 Training Epoch [29/40] Iter[276/312]		Loss: 0.1029
2019-10-29 00:49:16,228 Training Epoch [29/40] Iter[277/312]		Loss: 0.1027
2019-10-29 00:49:16,350 Training Epoch [29/40] Iter[278/312]		Loss: 0.1028
2019-10-29 00:49:16,471 Training Epoch [29/40] Iter[279/312]		Loss: 0.1027
2019-10-29 00:49:16,592 Training Epoch [29/40] Iter[280/312]		Loss: 0.1027
2019-10-29 00:49:16,713 Training Epoch [29/40] Iter[281/312]		Loss: 0.1028
2019-10-29 00:49:16,834 Training Epoch [29/40] Iter[282/312]		Loss: 0.1027
2019-10-29 00:49:16,956 Training Epoch [29/40] Iter[283/312]		Loss: 0.1026
2019-10-29 00:49:17,077 Training Epoch [29/40] Iter[284/312]		Loss: 0.1025
2019-10-29 00:49:17,198 Training Epoch [29/40] Iter[285/312]		Loss: 0.1026
2019-10-29 00:49:17,320 Training Epoch [29/40] Iter[286/312]		Loss: 0.1027
2019-10-29 00:49:17,441 Training Epoch [29/40] Iter[287/312]		Loss: 0.1028
2019-10-29 00:49:17,563 Training Epoch [29/40] Iter[288/312]		Loss: 0.1028
2019-10-29 00:49:17,685 Training Epoch [29/40] Iter[289/312]		Loss: 0.1028
2019-10-29 00:49:17,806 Training Epoch [29/40] Iter[290/312]		Loss: 0.1027
2019-10-29 00:49:17,927 Training Epoch [29/40] Iter[291/312]		Loss: 0.1027
2019-10-29 00:49:18,049 Training Epoch [29/40] Iter[292/312]		Loss: 0.1028
2019-10-29 00:49:18,170 Training Epoch [29/40] Iter[293/312]		Loss: 0.1027
2019-10-29 00:49:18,292 Training Epoch [29/40] Iter[294/312]		Loss: 0.1030
2019-10-29 00:49:18,414 Training Epoch [29/40] Iter[295/312]		Loss: 0.1030
2019-10-29 00:49:18,535 Training Epoch [29/40] Iter[296/312]		Loss: 0.1029
2019-10-29 00:49:18,657 Training Epoch [29/40] Iter[297/312]		Loss: 0.1029
2019-10-29 00:49:18,778 Training Epoch [29/40] Iter[298/312]		Loss: 0.1029
2019-10-29 00:49:18,900 Training Epoch [29/40] Iter[299/312]		Loss: 0.1030
2019-10-29 00:49:19,022 Training Epoch [29/40] Iter[300/312]		Loss: 0.1028
2019-10-29 00:49:19,145 Training Epoch [29/40] Iter[301/312]		Loss: 0.1030
2019-10-29 00:49:19,267 Training Epoch [29/40] Iter[302/312]		Loss: 0.1030
2019-10-29 00:49:19,388 Training Epoch [29/40] Iter[303/312]		Loss: 0.1029
2019-10-29 00:49:19,510 Training Epoch [29/40] Iter[304/312]		Loss: 0.1029
2019-10-29 00:49:19,631 Training Epoch [29/40] Iter[305/312]		Loss: 0.1028
2019-10-29 00:49:19,751 Training Epoch [29/40] Iter[306/312]		Loss: 0.1028
2019-10-29 00:49:19,872 Training Epoch [29/40] Iter[307/312]		Loss: 0.1028
2019-10-29 00:49:19,993 Training Epoch [29/40] Iter[308/312]		Loss: 0.1029
2019-10-29 00:49:20,114 Training Epoch [29/40] Iter[309/312]		Loss: 0.1029
2019-10-29 00:49:20,235 Training Epoch [29/40] Iter[310/312]		Loss: 0.1028
2019-10-29 00:49:20,356 Training Epoch [29/40] Iter[311/312]		Loss: 0.1028
2019-10-29 00:49:20,416 Training Epoch [29/40] Iter[312/312]		Loss: 0.1029
2019-10-29 00:49:20,817 Testing Epoch [29/40] Iter[0/62]		Loss: 0.0880
2019-10-29 00:49:20,859 Testing Epoch [29/40] Iter[1/62]		Loss: 0.1227
2019-10-29 00:49:20,902 Testing Epoch [29/40] Iter[2/62]		Loss: 0.1149
2019-10-29 00:49:20,935 Testing Epoch [29/40] Iter[3/62]		Loss: 0.1141
2019-10-29 00:49:20,967 Testing Epoch [29/40] Iter[4/62]		Loss: 0.1096
2019-10-29 00:49:20,997 Testing Epoch [29/40] Iter[5/62]		Loss: 0.1065
2019-10-29 00:49:21,030 Testing Epoch [29/40] Iter[6/62]		Loss: 0.1068
2019-10-29 00:49:21,060 Testing Epoch [29/40] Iter[7/62]		Loss: 0.1138
2019-10-29 00:49:21,092 Testing Epoch [29/40] Iter[8/62]		Loss: 0.1202
2019-10-29 00:49:21,126 Testing Epoch [29/40] Iter[9/62]		Loss: 0.1176
2019-10-29 00:49:21,157 Testing Epoch [29/40] Iter[10/62]		Loss: 0.1161
2019-10-29 00:49:21,188 Testing Epoch [29/40] Iter[11/62]		Loss: 0.1205
2019-10-29 00:49:21,218 Testing Epoch [29/40] Iter[12/62]		Loss: 0.1208
2019-10-29 00:49:21,249 Testing Epoch [29/40] Iter[13/62]		Loss: 0.1229
2019-10-29 00:49:21,280 Testing Epoch [29/40] Iter[14/62]		Loss: 0.1351
2019-10-29 00:49:21,311 Testing Epoch [29/40] Iter[15/62]		Loss: 0.1370
2019-10-29 00:49:21,342 Testing Epoch [29/40] Iter[16/62]		Loss: 0.1351
2019-10-29 00:49:21,373 Testing Epoch [29/40] Iter[17/62]		Loss: 0.1342
2019-10-29 00:49:21,404 Testing Epoch [29/40] Iter[18/62]		Loss: 0.1311
2019-10-29 00:49:21,434 Testing Epoch [29/40] Iter[19/62]		Loss: 0.1290
2019-10-29 00:49:21,465 Testing Epoch [29/40] Iter[20/62]		Loss: 0.1307
2019-10-29 00:49:21,496 Testing Epoch [29/40] Iter[21/62]		Loss: 0.1288
2019-10-29 00:49:21,527 Testing Epoch [29/40] Iter[22/62]		Loss: 0.1283
2019-10-29 00:49:21,558 Testing Epoch [29/40] Iter[23/62]		Loss: 0.1284
2019-10-29 00:49:21,589 Testing Epoch [29/40] Iter[24/62]		Loss: 0.1304
2019-10-29 00:49:21,619 Testing Epoch [29/40] Iter[25/62]		Loss: 0.1296
2019-10-29 00:49:21,650 Testing Epoch [29/40] Iter[26/62]		Loss: 0.1286
2019-10-29 00:49:21,681 Testing Epoch [29/40] Iter[27/62]		Loss: 0.1332
2019-10-29 00:49:21,711 Testing Epoch [29/40] Iter[28/62]		Loss: 0.1349
2019-10-29 00:49:21,742 Testing Epoch [29/40] Iter[29/62]		Loss: 0.1349
2019-10-29 00:49:21,773 Testing Epoch [29/40] Iter[30/62]		Loss: 0.1367
2019-10-29 00:49:21,803 Testing Epoch [29/40] Iter[31/62]		Loss: 0.1360
2019-10-29 00:49:21,834 Testing Epoch [29/40] Iter[32/62]		Loss: 0.1375
2019-10-29 00:49:21,865 Testing Epoch [29/40] Iter[33/62]		Loss: 0.1357
2019-10-29 00:49:21,896 Testing Epoch [29/40] Iter[34/62]		Loss: 0.1373
2019-10-29 00:49:21,926 Testing Epoch [29/40] Iter[35/62]		Loss: 0.1377
2019-10-29 00:49:21,957 Testing Epoch [29/40] Iter[36/62]		Loss: 0.1359
2019-10-29 00:49:21,988 Testing Epoch [29/40] Iter[37/62]		Loss: 0.1356
2019-10-29 00:49:22,019 Testing Epoch [29/40] Iter[38/62]		Loss: 0.1357
2019-10-29 00:49:22,050 Testing Epoch [29/40] Iter[39/62]		Loss: 0.1361
2019-10-29 00:49:22,081 Testing Epoch [29/40] Iter[40/62]		Loss: 0.1365
2019-10-29 00:49:22,112 Testing Epoch [29/40] Iter[41/62]		Loss: 0.1366
2019-10-29 00:49:22,142 Testing Epoch [29/40] Iter[42/62]		Loss: 0.1354
2019-10-29 00:49:22,173 Testing Epoch [29/40] Iter[43/62]		Loss: 0.1349
2019-10-29 00:49:22,204 Testing Epoch [29/40] Iter[44/62]		Loss: 0.1337
2019-10-29 00:49:22,234 Testing Epoch [29/40] Iter[45/62]		Loss: 0.1347
2019-10-29 00:49:22,265 Testing Epoch [29/40] Iter[46/62]		Loss: 0.1349
2019-10-29 00:49:22,295 Testing Epoch [29/40] Iter[47/62]		Loss: 0.1399
2019-10-29 00:49:22,326 Testing Epoch [29/40] Iter[48/62]		Loss: 0.1389
2019-10-29 00:49:22,357 Testing Epoch [29/40] Iter[49/62]		Loss: 0.1403
2019-10-29 00:49:22,388 Testing Epoch [29/40] Iter[50/62]		Loss: 0.1399
2019-10-29 00:49:22,418 Testing Epoch [29/40] Iter[51/62]		Loss: 0.1400
2019-10-29 00:49:22,449 Testing Epoch [29/40] Iter[52/62]		Loss: 0.1388
2019-10-29 00:49:22,480 Testing Epoch [29/40] Iter[53/62]		Loss: 0.1385
2019-10-29 00:49:22,510 Testing Epoch [29/40] Iter[54/62]		Loss: 0.1379
2019-10-29 00:49:22,541 Testing Epoch [29/40] Iter[55/62]		Loss: 0.1380
2019-10-29 00:49:22,571 Testing Epoch [29/40] Iter[56/62]		Loss: 0.1378
2019-10-29 00:49:22,601 Testing Epoch [29/40] Iter[57/62]		Loss: 0.1377
2019-10-29 00:49:22,631 Testing Epoch [29/40] Iter[58/62]		Loss: 0.1372
2019-10-29 00:49:22,662 Testing Epoch [29/40] Iter[59/62]		Loss: 0.1372
2019-10-29 00:49:22,692 Testing Epoch [29/40] Iter[60/62]		Loss: 0.1366
2019-10-29 00:49:22,722 Testing Epoch [29/40] Iter[61/62]		Loss: 0.1363
2019-10-29 00:49:22,739 Testing Epoch [29/40] Iter[62/62]		Loss: 0.1371
2019-10-29 00:49:22,803 Saving the Model
2019-10-29 00:49:23,248 Training Epoch [30/40] Iter[0/312]		Loss: 0.0762
2019-10-29 00:49:23,374 Training Epoch [30/40] Iter[1/312]		Loss: 0.0839
2019-10-29 00:49:23,494 Training Epoch [30/40] Iter[2/312]		Loss: 0.0945
2019-10-29 00:49:23,614 Training Epoch [30/40] Iter[3/312]		Loss: 0.1063
2019-10-29 00:49:23,736 Training Epoch [30/40] Iter[4/312]		Loss: 0.1016
2019-10-29 00:49:23,860 Training Epoch [30/40] Iter[5/312]		Loss: 0.0971
2019-10-29 00:49:23,980 Training Epoch [30/40] Iter[6/312]		Loss: 0.0952
2019-10-29 00:49:24,101 Training Epoch [30/40] Iter[7/312]		Loss: 0.0944
2019-10-29 00:49:24,221 Training Epoch [30/40] Iter[8/312]		Loss: 0.0970
2019-10-29 00:49:24,345 Training Epoch [30/40] Iter[9/312]		Loss: 0.0960
2019-10-29 00:49:24,467 Training Epoch [30/40] Iter[10/312]		Loss: 0.0985
2019-10-29 00:49:24,588 Training Epoch [30/40] Iter[11/312]		Loss: 0.0951
2019-10-29 00:49:24,710 Training Epoch [30/40] Iter[12/312]		Loss: 0.0976
2019-10-29 00:49:24,831 Training Epoch [30/40] Iter[13/312]		Loss: 0.1000
2019-10-29 00:49:24,953 Training Epoch [30/40] Iter[14/312]		Loss: 0.0985
2019-10-29 00:49:25,074 Training Epoch [30/40] Iter[15/312]		Loss: 0.0992
2019-10-29 00:49:25,196 Training Epoch [30/40] Iter[16/312]		Loss: 0.1059
2019-10-29 00:49:25,317 Training Epoch [30/40] Iter[17/312]		Loss: 0.1037
2019-10-29 00:49:25,438 Training Epoch [30/40] Iter[18/312]		Loss: 0.1051
2019-10-29 00:49:25,560 Training Epoch [30/40] Iter[19/312]		Loss: 0.1042
2019-10-29 00:49:25,681 Training Epoch [30/40] Iter[20/312]		Loss: 0.1034
2019-10-29 00:49:25,803 Training Epoch [30/40] Iter[21/312]		Loss: 0.1025
2019-10-29 00:49:25,924 Training Epoch [30/40] Iter[22/312]		Loss: 0.1041
2019-10-29 00:49:26,046 Training Epoch [30/40] Iter[23/312]		Loss: 0.1028
2019-10-29 00:49:26,167 Training Epoch [30/40] Iter[24/312]		Loss: 0.1027
2019-10-29 00:49:26,289 Training Epoch [30/40] Iter[25/312]		Loss: 0.1014
2019-10-29 00:49:26,411 Training Epoch [30/40] Iter[26/312]		Loss: 0.1016
2019-10-29 00:49:26,532 Training Epoch [30/40] Iter[27/312]		Loss: 0.1011
2019-10-29 00:49:26,654 Training Epoch [30/40] Iter[28/312]		Loss: 0.1005
2019-10-29 00:49:26,775 Training Epoch [30/40] Iter[29/312]		Loss: 0.0990
2019-10-29 00:49:26,897 Training Epoch [30/40] Iter[30/312]		Loss: 0.0994
2019-10-29 00:49:27,018 Training Epoch [30/40] Iter[31/312]		Loss: 0.0987
2019-10-29 00:49:27,140 Training Epoch [30/40] Iter[32/312]		Loss: 0.0997
2019-10-29 00:49:27,261 Training Epoch [30/40] Iter[33/312]		Loss: 0.0994
2019-10-29 00:49:27,383 Training Epoch [30/40] Iter[34/312]		Loss: 0.0989
2019-10-29 00:49:27,504 Training Epoch [30/40] Iter[35/312]		Loss: 0.1008
2019-10-29 00:49:27,626 Training Epoch [30/40] Iter[36/312]		Loss: 0.1006
2019-10-29 00:49:27,748 Training Epoch [30/40] Iter[37/312]		Loss: 0.1015
2019-10-29 00:49:27,870 Training Epoch [30/40] Iter[38/312]		Loss: 0.1009
2019-10-29 00:49:27,991 Training Epoch [30/40] Iter[39/312]		Loss: 0.1004
2019-10-29 00:49:28,113 Training Epoch [30/40] Iter[40/312]		Loss: 0.1005
2019-10-29 00:49:28,234 Training Epoch [30/40] Iter[41/312]		Loss: 0.1005
2019-10-29 00:49:28,356 Training Epoch [30/40] Iter[42/312]		Loss: 0.1010
2019-10-29 00:49:28,477 Training Epoch [30/40] Iter[43/312]		Loss: 0.1006
2019-10-29 00:49:28,599 Training Epoch [30/40] Iter[44/312]		Loss: 0.0999
2019-10-29 00:49:28,720 Training Epoch [30/40] Iter[45/312]		Loss: 0.0993
2019-10-29 00:49:28,842 Training Epoch [30/40] Iter[46/312]		Loss: 0.1009
2019-10-29 00:49:28,963 Training Epoch [30/40] Iter[47/312]		Loss: 0.1004
2019-10-29 00:49:29,084 Training Epoch [30/40] Iter[48/312]		Loss: 0.1008
2019-10-29 00:49:29,206 Training Epoch [30/40] Iter[49/312]		Loss: 0.0999
2019-10-29 00:49:29,327 Training Epoch [30/40] Iter[50/312]		Loss: 0.0994
2019-10-29 00:49:29,449 Training Epoch [30/40] Iter[51/312]		Loss: 0.0990
2019-10-29 00:49:29,571 Training Epoch [30/40] Iter[52/312]		Loss: 0.0995
2019-10-29 00:49:29,692 Training Epoch [30/40] Iter[53/312]		Loss: 0.1001
2019-10-29 00:49:29,814 Training Epoch [30/40] Iter[54/312]		Loss: 0.0998
2019-10-29 00:49:29,936 Training Epoch [30/40] Iter[55/312]		Loss: 0.1003
2019-10-29 00:49:30,057 Training Epoch [30/40] Iter[56/312]		Loss: 0.0997
2019-10-29 00:49:30,179 Training Epoch [30/40] Iter[57/312]		Loss: 0.0995
2019-10-29 00:49:30,300 Training Epoch [30/40] Iter[58/312]		Loss: 0.0996
2019-10-29 00:49:30,421 Training Epoch [30/40] Iter[59/312]		Loss: 0.0991
2019-10-29 00:49:30,542 Training Epoch [30/40] Iter[60/312]		Loss: 0.0991
2019-10-29 00:49:30,664 Training Epoch [30/40] Iter[61/312]		Loss: 0.0995
2019-10-29 00:49:30,785 Training Epoch [30/40] Iter[62/312]		Loss: 0.1000
2019-10-29 00:49:30,906 Training Epoch [30/40] Iter[63/312]		Loss: 0.0997
2019-10-29 00:49:31,027 Training Epoch [30/40] Iter[64/312]		Loss: 0.0994
2019-10-29 00:49:31,148 Training Epoch [30/40] Iter[65/312]		Loss: 0.0997
2019-10-29 00:49:31,269 Training Epoch [30/40] Iter[66/312]		Loss: 0.0992
2019-10-29 00:49:31,391 Training Epoch [30/40] Iter[67/312]		Loss: 0.0997
2019-10-29 00:49:31,512 Training Epoch [30/40] Iter[68/312]		Loss: 0.0997
2019-10-29 00:49:31,634 Training Epoch [30/40] Iter[69/312]		Loss: 0.0992
2019-10-29 00:49:31,756 Training Epoch [30/40] Iter[70/312]		Loss: 0.1008
2019-10-29 00:49:31,877 Training Epoch [30/40] Iter[71/312]		Loss: 0.1011
2019-10-29 00:49:31,999 Training Epoch [30/40] Iter[72/312]		Loss: 0.1006
2019-10-29 00:49:32,121 Training Epoch [30/40] Iter[73/312]		Loss: 0.1002
2019-10-29 00:49:32,242 Training Epoch [30/40] Iter[74/312]		Loss: 0.0997
2019-10-29 00:49:32,364 Training Epoch [30/40] Iter[75/312]		Loss: 0.0993
2019-10-29 00:49:32,485 Training Epoch [30/40] Iter[76/312]		Loss: 0.0991
2019-10-29 00:49:32,607 Training Epoch [30/40] Iter[77/312]		Loss: 0.0987
2019-10-29 00:49:32,729 Training Epoch [30/40] Iter[78/312]		Loss: 0.0992
2019-10-29 00:49:32,850 Training Epoch [30/40] Iter[79/312]		Loss: 0.0988
2019-10-29 00:49:32,972 Training Epoch [30/40] Iter[80/312]		Loss: 0.0988
2019-10-29 00:49:33,094 Training Epoch [30/40] Iter[81/312]		Loss: 0.0986
2019-10-29 00:49:33,215 Training Epoch [30/40] Iter[82/312]		Loss: 0.0990
2019-10-29 00:49:33,337 Training Epoch [30/40] Iter[83/312]		Loss: 0.0989
2019-10-29 00:49:33,458 Training Epoch [30/40] Iter[84/312]		Loss: 0.1001
2019-10-29 00:49:33,579 Training Epoch [30/40] Iter[85/312]		Loss: 0.0999
2019-10-29 00:49:33,701 Training Epoch [30/40] Iter[86/312]		Loss: 0.1001
2019-10-29 00:49:33,822 Training Epoch [30/40] Iter[87/312]		Loss: 0.0997
2019-10-29 00:49:33,943 Training Epoch [30/40] Iter[88/312]		Loss: 0.1001
2019-10-29 00:49:34,064 Training Epoch [30/40] Iter[89/312]		Loss: 0.1001
2019-10-29 00:49:34,185 Training Epoch [30/40] Iter[90/312]		Loss: 0.1000
2019-10-29 00:49:34,306 Training Epoch [30/40] Iter[91/312]		Loss: 0.1006
2019-10-29 00:49:34,428 Training Epoch [30/40] Iter[92/312]		Loss: 0.1007
2019-10-29 00:49:34,549 Training Epoch [30/40] Iter[93/312]		Loss: 0.1006
2019-10-29 00:49:34,671 Training Epoch [30/40] Iter[94/312]		Loss: 0.1005
2019-10-29 00:49:34,797 Training Epoch [30/40] Iter[95/312]		Loss: 0.1006
2019-10-29 00:49:34,919 Training Epoch [30/40] Iter[96/312]		Loss: 0.1012
2019-10-29 00:49:35,041 Training Epoch [30/40] Iter[97/312]		Loss: 0.1013
2019-10-29 00:49:35,162 Training Epoch [30/40] Iter[98/312]		Loss: 0.1012
2019-10-29 00:49:35,284 Training Epoch [30/40] Iter[99/312]		Loss: 0.1008
2019-10-29 00:49:35,406 Training Epoch [30/40] Iter[100/312]		Loss: 0.1005
2019-10-29 00:49:35,527 Training Epoch [30/40] Iter[101/312]		Loss: 0.1006
2019-10-29 00:49:35,648 Training Epoch [30/40] Iter[102/312]		Loss: 0.1005
2019-10-29 00:49:35,769 Training Epoch [30/40] Iter[103/312]		Loss: 0.1004
2019-10-29 00:49:35,891 Training Epoch [30/40] Iter[104/312]		Loss: 0.1009
2019-10-29 00:49:36,012 Training Epoch [30/40] Iter[105/312]		Loss: 0.1006
2019-10-29 00:49:36,134 Training Epoch [30/40] Iter[106/312]		Loss: 0.1007
2019-10-29 00:49:36,255 Training Epoch [30/40] Iter[107/312]		Loss: 0.1004
2019-10-29 00:49:36,377 Training Epoch [30/40] Iter[108/312]		Loss: 0.1003
2019-10-29 00:49:36,498 Training Epoch [30/40] Iter[109/312]		Loss: 0.1008
2019-10-29 00:49:36,620 Training Epoch [30/40] Iter[110/312]		Loss: 0.1005
2019-10-29 00:49:36,742 Training Epoch [30/40] Iter[111/312]		Loss: 0.1003
2019-10-29 00:49:36,863 Training Epoch [30/40] Iter[112/312]		Loss: 0.1005
2019-10-29 00:49:36,985 Training Epoch [30/40] Iter[113/312]		Loss: 0.1008
2019-10-29 00:49:37,106 Training Epoch [30/40] Iter[114/312]		Loss: 0.1009
2019-10-29 00:49:37,227 Training Epoch [30/40] Iter[115/312]		Loss: 0.1010
2019-10-29 00:49:37,349 Training Epoch [30/40] Iter[116/312]		Loss: 0.1009
2019-10-29 00:49:37,470 Training Epoch [30/40] Iter[117/312]		Loss: 0.1008
2019-10-29 00:49:37,592 Training Epoch [30/40] Iter[118/312]		Loss: 0.1013
2019-10-29 00:49:37,713 Training Epoch [30/40] Iter[119/312]		Loss: 0.1010
2019-10-29 00:49:37,835 Training Epoch [30/40] Iter[120/312]		Loss: 0.1009
2019-10-29 00:49:37,956 Training Epoch [30/40] Iter[121/312]		Loss: 0.1007
2019-10-29 00:49:38,077 Training Epoch [30/40] Iter[122/312]		Loss: 0.1006
2019-10-29 00:49:38,199 Training Epoch [30/40] Iter[123/312]		Loss: 0.1008
2019-10-29 00:49:38,320 Training Epoch [30/40] Iter[124/312]		Loss: 0.1009
2019-10-29 00:49:38,442 Training Epoch [30/40] Iter[125/312]		Loss: 0.1010
2019-10-29 00:49:38,563 Training Epoch [30/40] Iter[126/312]		Loss: 0.1009
2019-10-29 00:49:38,684 Training Epoch [30/40] Iter[127/312]		Loss: 0.1011
2019-10-29 00:49:38,806 Training Epoch [30/40] Iter[128/312]		Loss: 0.1015
2019-10-29 00:49:38,926 Training Epoch [30/40] Iter[129/312]		Loss: 0.1024
2019-10-29 00:49:39,047 Training Epoch [30/40] Iter[130/312]		Loss: 0.1021
2019-10-29 00:49:39,168 Training Epoch [30/40] Iter[131/312]		Loss: 0.1019
2019-10-29 00:49:39,289 Training Epoch [30/40] Iter[132/312]		Loss: 0.1019
2019-10-29 00:49:39,411 Training Epoch [30/40] Iter[133/312]		Loss: 0.1016
2019-10-29 00:49:39,532 Training Epoch [30/40] Iter[134/312]		Loss: 0.1014
2019-10-29 00:49:39,653 Training Epoch [30/40] Iter[135/312]		Loss: 0.1011
2019-10-29 00:49:39,775 Training Epoch [30/40] Iter[136/312]		Loss: 0.1010
2019-10-29 00:49:39,896 Training Epoch [30/40] Iter[137/312]		Loss: 0.1008
2019-10-29 00:49:40,017 Training Epoch [30/40] Iter[138/312]		Loss: 0.1009
2019-10-29 00:49:40,139 Training Epoch [30/40] Iter[139/312]		Loss: 0.1006
2019-10-29 00:49:40,261 Training Epoch [30/40] Iter[140/312]		Loss: 0.1004
2019-10-29 00:49:40,382 Training Epoch [30/40] Iter[141/312]		Loss: 0.1006
2019-10-29 00:49:40,504 Training Epoch [30/40] Iter[142/312]		Loss: 0.1006
2019-10-29 00:49:40,626 Training Epoch [30/40] Iter[143/312]		Loss: 0.1005
2019-10-29 00:49:40,747 Training Epoch [30/40] Iter[144/312]		Loss: 0.1008
2019-10-29 00:49:40,868 Training Epoch [30/40] Iter[145/312]		Loss: 0.1007
2019-10-29 00:49:40,990 Training Epoch [30/40] Iter[146/312]		Loss: 0.1007
2019-10-29 00:49:41,111 Training Epoch [30/40] Iter[147/312]		Loss: 0.1007
2019-10-29 00:49:41,233 Training Epoch [30/40] Iter[148/312]		Loss: 0.1009
2019-10-29 00:49:41,354 Training Epoch [30/40] Iter[149/312]		Loss: 0.1006
2019-10-29 00:49:41,476 Training Epoch [30/40] Iter[150/312]		Loss: 0.1005
2019-10-29 00:49:41,598 Training Epoch [30/40] Iter[151/312]		Loss: 0.1007
2019-10-29 00:49:41,719 Training Epoch [30/40] Iter[152/312]		Loss: 0.1006
2019-10-29 00:49:41,841 Training Epoch [30/40] Iter[153/312]		Loss: 0.1003
2019-10-29 00:49:41,962 Training Epoch [30/40] Iter[154/312]		Loss: 0.1006
2019-10-29 00:49:42,083 Training Epoch [30/40] Iter[155/312]		Loss: 0.1006
2019-10-29 00:49:42,204 Training Epoch [30/40] Iter[156/312]		Loss: 0.1005
2019-10-29 00:49:42,326 Training Epoch [30/40] Iter[157/312]		Loss: 0.1007
2019-10-29 00:49:42,447 Training Epoch [30/40] Iter[158/312]		Loss: 0.1006
2019-10-29 00:49:42,568 Training Epoch [30/40] Iter[159/312]		Loss: 0.1009
2019-10-29 00:49:42,689 Training Epoch [30/40] Iter[160/312]		Loss: 0.1008
2019-10-29 00:49:42,810 Training Epoch [30/40] Iter[161/312]		Loss: 0.1007
2019-10-29 00:49:42,932 Training Epoch [30/40] Iter[162/312]		Loss: 0.1006
2019-10-29 00:49:43,053 Training Epoch [30/40] Iter[163/312]		Loss: 0.1004
2019-10-29 00:49:43,174 Training Epoch [30/40] Iter[164/312]		Loss: 0.1005
2019-10-29 00:49:43,296 Training Epoch [30/40] Iter[165/312]		Loss: 0.1003
2019-10-29 00:49:43,418 Training Epoch [30/40] Iter[166/312]		Loss: 0.1001
2019-10-29 00:49:43,540 Training Epoch [30/40] Iter[167/312]		Loss: 0.0999
2019-10-29 00:49:43,661 Training Epoch [30/40] Iter[168/312]		Loss: 0.0998
2019-10-29 00:49:43,782 Training Epoch [30/40] Iter[169/312]		Loss: 0.0996
2019-10-29 00:49:43,904 Training Epoch [30/40] Iter[170/312]		Loss: 0.0998
2019-10-29 00:49:44,025 Training Epoch [30/40] Iter[171/312]		Loss: 0.0999
2019-10-29 00:49:44,146 Training Epoch [30/40] Iter[172/312]		Loss: 0.0998
2019-10-29 00:49:44,267 Training Epoch [30/40] Iter[173/312]		Loss: 0.0998
2019-10-29 00:49:44,389 Training Epoch [30/40] Iter[174/312]		Loss: 0.0999
2019-10-29 00:49:44,511 Training Epoch [30/40] Iter[175/312]		Loss: 0.0998
2019-10-29 00:49:44,633 Training Epoch [30/40] Iter[176/312]		Loss: 0.1000
2019-10-29 00:49:44,754 Training Epoch [30/40] Iter[177/312]		Loss: 0.0999
2019-10-29 00:49:44,876 Training Epoch [30/40] Iter[178/312]		Loss: 0.0998
2019-10-29 00:49:44,997 Training Epoch [30/40] Iter[179/312]		Loss: 0.0997
2019-10-29 00:49:45,118 Training Epoch [30/40] Iter[180/312]		Loss: 0.0996
2019-10-29 00:49:45,239 Training Epoch [30/40] Iter[181/312]		Loss: 0.0997
2019-10-29 00:49:45,361 Training Epoch [30/40] Iter[182/312]		Loss: 0.0996
2019-10-29 00:49:45,483 Training Epoch [30/40] Iter[183/312]		Loss: 0.0995
2019-10-29 00:49:45,604 Training Epoch [30/40] Iter[184/312]		Loss: 0.0995
2019-10-29 00:49:45,726 Training Epoch [30/40] Iter[185/312]		Loss: 0.0993
2019-10-29 00:49:45,847 Training Epoch [30/40] Iter[186/312]		Loss: 0.0993
2019-10-29 00:49:45,968 Training Epoch [30/40] Iter[187/312]		Loss: 0.0991
2019-10-29 00:49:46,092 Training Epoch [30/40] Iter[188/312]		Loss: 0.0991
2019-10-29 00:49:46,214 Training Epoch [30/40] Iter[189/312]		Loss: 0.0992
2019-10-29 00:49:46,335 Training Epoch [30/40] Iter[190/312]		Loss: 0.0992
2019-10-29 00:49:46,456 Training Epoch [30/40] Iter[191/312]		Loss: 0.0992
2019-10-29 00:49:46,578 Training Epoch [30/40] Iter[192/312]		Loss: 0.0991
2019-10-29 00:49:46,699 Training Epoch [30/40] Iter[193/312]		Loss: 0.0990
2019-10-29 00:49:46,821 Training Epoch [30/40] Iter[194/312]		Loss: 0.0991
2019-10-29 00:49:46,942 Training Epoch [30/40] Iter[195/312]		Loss: 0.0994
2019-10-29 00:49:47,064 Training Epoch [30/40] Iter[196/312]		Loss: 0.0992
2019-10-29 00:49:47,185 Training Epoch [30/40] Iter[197/312]		Loss: 0.0991
2019-10-29 00:49:47,306 Training Epoch [30/40] Iter[198/312]		Loss: 0.0990
2019-10-29 00:49:47,427 Training Epoch [30/40] Iter[199/312]		Loss: 0.0989
2019-10-29 00:49:47,548 Training Epoch [30/40] Iter[200/312]		Loss: 0.0990
2019-10-29 00:49:47,669 Training Epoch [30/40] Iter[201/312]		Loss: 0.0990
2019-10-29 00:49:47,791 Training Epoch [30/40] Iter[202/312]		Loss: 0.0991
2019-10-29 00:49:47,912 Training Epoch [30/40] Iter[203/312]		Loss: 0.0991
2019-10-29 00:49:48,033 Training Epoch [30/40] Iter[204/312]		Loss: 0.0991
2019-10-29 00:49:48,154 Training Epoch [30/40] Iter[205/312]		Loss: 0.0995
2019-10-29 00:49:48,275 Training Epoch [30/40] Iter[206/312]		Loss: 0.0995
2019-10-29 00:49:48,397 Training Epoch [30/40] Iter[207/312]		Loss: 0.0996
2019-10-29 00:49:48,518 Training Epoch [30/40] Iter[208/312]		Loss: 0.0996
2019-10-29 00:49:48,640 Training Epoch [30/40] Iter[209/312]		Loss: 0.0996
2019-10-29 00:49:48,762 Training Epoch [30/40] Iter[210/312]		Loss: 0.0995
2019-10-29 00:49:48,883 Training Epoch [30/40] Iter[211/312]		Loss: 0.0994
2019-10-29 00:49:49,005 Training Epoch [30/40] Iter[212/312]		Loss: 0.0994
2019-10-29 00:49:49,126 Training Epoch [30/40] Iter[213/312]		Loss: 0.0996
2019-10-29 00:49:49,248 Training Epoch [30/40] Iter[214/312]		Loss: 0.0999
2019-10-29 00:49:49,369 Training Epoch [30/40] Iter[215/312]		Loss: 0.1002
2019-10-29 00:49:49,490 Training Epoch [30/40] Iter[216/312]		Loss: 0.1002
2019-10-29 00:49:49,612 Training Epoch [30/40] Iter[217/312]		Loss: 0.1003
2019-10-29 00:49:49,734 Training Epoch [30/40] Iter[218/312]		Loss: 0.1002
2019-10-29 00:49:49,855 Training Epoch [30/40] Iter[219/312]		Loss: 0.1003
2019-10-29 00:49:49,977 Training Epoch [30/40] Iter[220/312]		Loss: 0.1004
2019-10-29 00:49:50,099 Training Epoch [30/40] Iter[221/312]		Loss: 0.1004
2019-10-29 00:49:50,221 Training Epoch [30/40] Iter[222/312]		Loss: 0.1004
2019-10-29 00:49:50,342 Training Epoch [30/40] Iter[223/312]		Loss: 0.1004
2019-10-29 00:49:50,464 Training Epoch [30/40] Iter[224/312]		Loss: 0.1004
2019-10-29 00:49:50,585 Training Epoch [30/40] Iter[225/312]		Loss: 0.1004
2019-10-29 00:49:50,706 Training Epoch [30/40] Iter[226/312]		Loss: 0.1008
2019-10-29 00:49:50,828 Training Epoch [30/40] Iter[227/312]		Loss: 0.1006
2019-10-29 00:49:50,949 Training Epoch [30/40] Iter[228/312]		Loss: 0.1006
2019-10-29 00:49:51,070 Training Epoch [30/40] Iter[229/312]		Loss: 0.1004
2019-10-29 00:49:51,192 Training Epoch [30/40] Iter[230/312]		Loss: 0.1007
2019-10-29 00:49:51,313 Training Epoch [30/40] Iter[231/312]		Loss: 0.1007
2019-10-29 00:49:51,434 Training Epoch [30/40] Iter[232/312]		Loss: 0.1007
2019-10-29 00:49:51,556 Training Epoch [30/40] Iter[233/312]		Loss: 0.1007
2019-10-29 00:49:51,677 Training Epoch [30/40] Iter[234/312]		Loss: 0.1010
2019-10-29 00:49:51,799 Training Epoch [30/40] Iter[235/312]		Loss: 0.1011
2019-10-29 00:49:51,921 Training Epoch [30/40] Iter[236/312]		Loss: 0.1010
2019-10-29 00:49:52,042 Training Epoch [30/40] Iter[237/312]		Loss: 0.1009
2019-10-29 00:49:52,164 Training Epoch [30/40] Iter[238/312]		Loss: 0.1008
2019-10-29 00:49:52,285 Training Epoch [30/40] Iter[239/312]		Loss: 0.1009
2019-10-29 00:49:52,407 Training Epoch [30/40] Iter[240/312]		Loss: 0.1011
2019-10-29 00:49:52,529 Training Epoch [30/40] Iter[241/312]		Loss: 0.1010
2019-10-29 00:49:52,650 Training Epoch [30/40] Iter[242/312]		Loss: 0.1011
2019-10-29 00:49:52,771 Training Epoch [30/40] Iter[243/312]		Loss: 0.1011
2019-10-29 00:49:52,893 Training Epoch [30/40] Iter[244/312]		Loss: 0.1012
2019-10-29 00:49:53,014 Training Epoch [30/40] Iter[245/312]		Loss: 0.1011
2019-10-29 00:49:53,136 Training Epoch [30/40] Iter[246/312]		Loss: 0.1010
2019-10-29 00:49:53,258 Training Epoch [30/40] Iter[247/312]		Loss: 0.1009
2019-10-29 00:49:53,380 Training Epoch [30/40] Iter[248/312]		Loss: 0.1009
2019-10-29 00:49:53,501 Training Epoch [30/40] Iter[249/312]		Loss: 0.1009
2019-10-29 00:49:53,622 Training Epoch [30/40] Iter[250/312]		Loss: 0.1008
2019-10-29 00:49:53,744 Training Epoch [30/40] Iter[251/312]		Loss: 0.1008
2019-10-29 00:49:53,865 Training Epoch [30/40] Iter[252/312]		Loss: 0.1008
2019-10-29 00:49:53,987 Training Epoch [30/40] Iter[253/312]		Loss: 0.1008
2019-10-29 00:49:54,113 Training Epoch [30/40] Iter[254/312]		Loss: 0.1010
2019-10-29 00:49:54,234 Training Epoch [30/40] Iter[255/312]		Loss: 0.1010
2019-10-29 00:49:54,356 Training Epoch [30/40] Iter[256/312]		Loss: 0.1009
2019-10-29 00:49:54,477 Training Epoch [30/40] Iter[257/312]		Loss: 0.1008
2019-10-29 00:49:54,599 Training Epoch [30/40] Iter[258/312]		Loss: 0.1007
2019-10-29 00:49:54,721 Training Epoch [30/40] Iter[259/312]		Loss: 0.1009
2019-10-29 00:49:54,842 Training Epoch [30/40] Iter[260/312]		Loss: 0.1012
2019-10-29 00:49:54,964 Training Epoch [30/40] Iter[261/312]		Loss: 0.1013
2019-10-29 00:49:55,088 Training Epoch [30/40] Iter[262/312]		Loss: 0.1013
2019-10-29 00:49:55,211 Training Epoch [30/40] Iter[263/312]		Loss: 0.1014
2019-10-29 00:49:55,333 Training Epoch [30/40] Iter[264/312]		Loss: 0.1013
2019-10-29 00:49:55,454 Training Epoch [30/40] Iter[265/312]		Loss: 0.1012
2019-10-29 00:49:55,576 Training Epoch [30/40] Iter[266/312]		Loss: 0.1012
2019-10-29 00:49:55,698 Training Epoch [30/40] Iter[267/312]		Loss: 0.1013
2019-10-29 00:49:55,819 Training Epoch [30/40] Iter[268/312]		Loss: 0.1012
2019-10-29 00:49:55,940 Training Epoch [30/40] Iter[269/312]		Loss: 0.1012
2019-10-29 00:49:56,061 Training Epoch [30/40] Iter[270/312]		Loss: 0.1014
2019-10-29 00:49:56,182 Training Epoch [30/40] Iter[271/312]		Loss: 0.1014
2019-10-29 00:49:56,303 Training Epoch [30/40] Iter[272/312]		Loss: 0.1014
2019-10-29 00:49:56,425 Training Epoch [30/40] Iter[273/312]		Loss: 0.1016
2019-10-29 00:49:56,546 Training Epoch [30/40] Iter[274/312]		Loss: 0.1015
2019-10-29 00:49:56,667 Training Epoch [30/40] Iter[275/312]		Loss: 0.1014
2019-10-29 00:49:56,788 Training Epoch [30/40] Iter[276/312]		Loss: 0.1015
2019-10-29 00:49:56,910 Training Epoch [30/40] Iter[277/312]		Loss: 0.1015
2019-10-29 00:49:57,031 Training Epoch [30/40] Iter[278/312]		Loss: 0.1017
2019-10-29 00:49:57,153 Training Epoch [30/40] Iter[279/312]		Loss: 0.1017
2019-10-29 00:49:57,275 Training Epoch [30/40] Iter[280/312]		Loss: 0.1018
2019-10-29 00:49:57,397 Training Epoch [30/40] Iter[281/312]		Loss: 0.1018
2019-10-29 00:49:57,519 Training Epoch [30/40] Iter[282/312]		Loss: 0.1019
2019-10-29 00:49:57,640 Training Epoch [30/40] Iter[283/312]		Loss: 0.1018
2019-10-29 00:49:57,762 Training Epoch [30/40] Iter[284/312]		Loss: 0.1018
2019-10-29 00:49:57,883 Training Epoch [30/40] Iter[285/312]		Loss: 0.1018
2019-10-29 00:49:58,005 Training Epoch [30/40] Iter[286/312]		Loss: 0.1018
2019-10-29 00:49:58,126 Training Epoch [30/40] Iter[287/312]		Loss: 0.1017
2019-10-29 00:49:58,249 Training Epoch [30/40] Iter[288/312]		Loss: 0.1018
2019-10-29 00:49:58,370 Training Epoch [30/40] Iter[289/312]		Loss: 0.1017
2019-10-29 00:49:58,492 Training Epoch [30/40] Iter[290/312]		Loss: 0.1017
2019-10-29 00:49:58,614 Training Epoch [30/40] Iter[291/312]		Loss: 0.1018
2019-10-29 00:49:58,735 Training Epoch [30/40] Iter[292/312]		Loss: 0.1018
2019-10-29 00:49:58,856 Training Epoch [30/40] Iter[293/312]		Loss: 0.1018
2019-10-29 00:49:58,977 Training Epoch [30/40] Iter[294/312]		Loss: 0.1018
2019-10-29 00:49:59,099 Training Epoch [30/40] Iter[295/312]		Loss: 0.1019
2019-10-29 00:49:59,220 Training Epoch [30/40] Iter[296/312]		Loss: 0.1020
2019-10-29 00:49:59,341 Training Epoch [30/40] Iter[297/312]		Loss: 0.1019
2019-10-29 00:49:59,462 Training Epoch [30/40] Iter[298/312]		Loss: 0.1020
2019-10-29 00:49:59,583 Training Epoch [30/40] Iter[299/312]		Loss: 0.1019
2019-10-29 00:49:59,704 Training Epoch [30/40] Iter[300/312]		Loss: 0.1020
2019-10-29 00:49:59,825 Training Epoch [30/40] Iter[301/312]		Loss: 0.1019
2019-10-29 00:49:59,947 Training Epoch [30/40] Iter[302/312]		Loss: 0.1020
2019-10-29 00:50:00,068 Training Epoch [30/40] Iter[303/312]		Loss: 0.1020
2019-10-29 00:50:00,190 Training Epoch [30/40] Iter[304/312]		Loss: 0.1023
2019-10-29 00:50:00,312 Training Epoch [30/40] Iter[305/312]		Loss: 0.1022
2019-10-29 00:50:00,433 Training Epoch [30/40] Iter[306/312]		Loss: 0.1021
2019-10-29 00:50:00,554 Training Epoch [30/40] Iter[307/312]		Loss: 0.1020
2019-10-29 00:50:00,675 Training Epoch [30/40] Iter[308/312]		Loss: 0.1021
2019-10-29 00:50:00,796 Training Epoch [30/40] Iter[309/312]		Loss: 0.1022
2019-10-29 00:50:00,917 Training Epoch [30/40] Iter[310/312]		Loss: 0.1020
2019-10-29 00:50:01,037 Training Epoch [30/40] Iter[311/312]		Loss: 0.1021
2019-10-29 00:50:01,097 Training Epoch [30/40] Iter[312/312]		Loss: 0.1021
2019-10-29 00:50:01,482 Testing Epoch [30/40] Iter[0/62]		Loss: 0.0932
2019-10-29 00:50:01,514 Testing Epoch [30/40] Iter[1/62]		Loss: 0.1283
2019-10-29 00:50:01,555 Testing Epoch [30/40] Iter[2/62]		Loss: 0.1204
2019-10-29 00:50:01,587 Testing Epoch [30/40] Iter[3/62]		Loss: 0.1181
2019-10-29 00:50:01,618 Testing Epoch [30/40] Iter[4/62]		Loss: 0.1131
2019-10-29 00:50:01,648 Testing Epoch [30/40] Iter[5/62]		Loss: 0.1102
2019-10-29 00:50:01,680 Testing Epoch [30/40] Iter[6/62]		Loss: 0.1111
2019-10-29 00:50:01,711 Testing Epoch [30/40] Iter[7/62]		Loss: 0.1173
2019-10-29 00:50:01,742 Testing Epoch [30/40] Iter[8/62]		Loss: 0.1232
2019-10-29 00:50:01,774 Testing Epoch [30/40] Iter[9/62]		Loss: 0.1203
2019-10-29 00:50:01,806 Testing Epoch [30/40] Iter[10/62]		Loss: 0.1185
2019-10-29 00:50:01,837 Testing Epoch [30/40] Iter[11/62]		Loss: 0.1233
2019-10-29 00:50:01,868 Testing Epoch [30/40] Iter[12/62]		Loss: 0.1243
2019-10-29 00:50:01,905 Testing Epoch [30/40] Iter[13/62]		Loss: 0.1261
2019-10-29 00:50:01,936 Testing Epoch [30/40] Iter[14/62]		Loss: 0.1388
2019-10-29 00:50:01,967 Testing Epoch [30/40] Iter[15/62]		Loss: 0.1403
2019-10-29 00:50:01,998 Testing Epoch [30/40] Iter[16/62]		Loss: 0.1381
2019-10-29 00:50:02,029 Testing Epoch [30/40] Iter[17/62]		Loss: 0.1371
2019-10-29 00:50:02,060 Testing Epoch [30/40] Iter[18/62]		Loss: 0.1334
2019-10-29 00:50:02,091 Testing Epoch [30/40] Iter[19/62]		Loss: 0.1317
2019-10-29 00:50:02,122 Testing Epoch [30/40] Iter[20/62]		Loss: 0.1330
2019-10-29 00:50:02,153 Testing Epoch [30/40] Iter[21/62]		Loss: 0.1310
2019-10-29 00:50:02,184 Testing Epoch [30/40] Iter[22/62]		Loss: 0.1304
2019-10-29 00:50:02,215 Testing Epoch [30/40] Iter[23/62]		Loss: 0.1300
2019-10-29 00:50:02,246 Testing Epoch [30/40] Iter[24/62]		Loss: 0.1321
2019-10-29 00:50:02,277 Testing Epoch [30/40] Iter[25/62]		Loss: 0.1313
2019-10-29 00:50:02,308 Testing Epoch [30/40] Iter[26/62]		Loss: 0.1302
2019-10-29 00:50:02,339 Testing Epoch [30/40] Iter[27/62]		Loss: 0.1348
2019-10-29 00:50:02,370 Testing Epoch [30/40] Iter[28/62]		Loss: 0.1367
2019-10-29 00:50:02,401 Testing Epoch [30/40] Iter[29/62]		Loss: 0.1364
2019-10-29 00:50:02,431 Testing Epoch [30/40] Iter[30/62]		Loss: 0.1380
2019-10-29 00:50:02,462 Testing Epoch [30/40] Iter[31/62]		Loss: 0.1373
2019-10-29 00:50:02,493 Testing Epoch [30/40] Iter[32/62]		Loss: 0.1390
2019-10-29 00:50:02,524 Testing Epoch [30/40] Iter[33/62]		Loss: 0.1373
2019-10-29 00:50:02,555 Testing Epoch [30/40] Iter[34/62]		Loss: 0.1390
2019-10-29 00:50:02,586 Testing Epoch [30/40] Iter[35/62]		Loss: 0.1395
2019-10-29 00:50:02,616 Testing Epoch [30/40] Iter[36/62]		Loss: 0.1378
2019-10-29 00:50:02,647 Testing Epoch [30/40] Iter[37/62]		Loss: 0.1375
2019-10-29 00:50:02,678 Testing Epoch [30/40] Iter[38/62]		Loss: 0.1377
2019-10-29 00:50:02,709 Testing Epoch [30/40] Iter[39/62]		Loss: 0.1381
2019-10-29 00:50:02,740 Testing Epoch [30/40] Iter[40/62]		Loss: 0.1385
2019-10-29 00:50:02,771 Testing Epoch [30/40] Iter[41/62]		Loss: 0.1387
2019-10-29 00:50:02,801 Testing Epoch [30/40] Iter[42/62]		Loss: 0.1373
2019-10-29 00:50:02,832 Testing Epoch [30/40] Iter[43/62]		Loss: 0.1369
2019-10-29 00:50:02,863 Testing Epoch [30/40] Iter[44/62]		Loss: 0.1356
2019-10-29 00:50:02,893 Testing Epoch [30/40] Iter[45/62]		Loss: 0.1367
2019-10-29 00:50:02,924 Testing Epoch [30/40] Iter[46/62]		Loss: 0.1369
2019-10-29 00:50:02,955 Testing Epoch [30/40] Iter[47/62]		Loss: 0.1419
2019-10-29 00:50:02,986 Testing Epoch [30/40] Iter[48/62]		Loss: 0.1409
2019-10-29 00:50:03,017 Testing Epoch [30/40] Iter[49/62]		Loss: 0.1423
2019-10-29 00:50:03,047 Testing Epoch [30/40] Iter[50/62]		Loss: 0.1420
2019-10-29 00:50:03,078 Testing Epoch [30/40] Iter[51/62]		Loss: 0.1422
2019-10-29 00:50:03,109 Testing Epoch [30/40] Iter[52/62]		Loss: 0.1410
2019-10-29 00:50:03,140 Testing Epoch [30/40] Iter[53/62]		Loss: 0.1409
2019-10-29 00:50:03,171 Testing Epoch [30/40] Iter[54/62]		Loss: 0.1403
2019-10-29 00:50:03,201 Testing Epoch [30/40] Iter[55/62]		Loss: 0.1404
2019-10-29 00:50:03,232 Testing Epoch [30/40] Iter[56/62]		Loss: 0.1402
2019-10-29 00:50:03,262 Testing Epoch [30/40] Iter[57/62]		Loss: 0.1400
2019-10-29 00:50:03,292 Testing Epoch [30/40] Iter[58/62]		Loss: 0.1395
2019-10-29 00:50:03,323 Testing Epoch [30/40] Iter[59/62]		Loss: 0.1396
2019-10-29 00:50:03,353 Testing Epoch [30/40] Iter[60/62]		Loss: 0.1390
2019-10-29 00:50:03,384 Testing Epoch [30/40] Iter[61/62]		Loss: 0.1387
2019-10-29 00:50:03,401 Testing Epoch [30/40] Iter[62/62]		Loss: 0.1394
2019-10-29 00:50:03,878 Training Epoch [31/40] Iter[0/312]		Loss: 0.1242
2019-10-29 00:50:04,000 Training Epoch [31/40] Iter[1/312]		Loss: 0.1116
2019-10-29 00:50:04,122 Training Epoch [31/40] Iter[2/312]		Loss: 0.1187
2019-10-29 00:50:04,243 Training Epoch [31/40] Iter[3/312]		Loss: 0.1094
2019-10-29 00:50:04,366 Training Epoch [31/40] Iter[4/312]		Loss: 0.1089
2019-10-29 00:50:04,487 Training Epoch [31/40] Iter[5/312]		Loss: 0.1031
2019-10-29 00:50:04,607 Training Epoch [31/40] Iter[6/312]		Loss: 0.1103
2019-10-29 00:50:04,728 Training Epoch [31/40] Iter[7/312]		Loss: 0.1159
2019-10-29 00:50:04,849 Training Epoch [31/40] Iter[8/312]		Loss: 0.1184
2019-10-29 00:50:04,970 Training Epoch [31/40] Iter[9/312]		Loss: 0.1203
2019-10-29 00:50:05,091 Training Epoch [31/40] Iter[10/312]		Loss: 0.1161
2019-10-29 00:50:05,212 Training Epoch [31/40] Iter[11/312]		Loss: 0.1114
2019-10-29 00:50:05,335 Training Epoch [31/40] Iter[12/312]		Loss: 0.1089
2019-10-29 00:50:05,457 Training Epoch [31/40] Iter[13/312]		Loss: 0.1051
2019-10-29 00:50:05,578 Training Epoch [31/40] Iter[14/312]		Loss: 0.1039
2019-10-29 00:50:05,699 Training Epoch [31/40] Iter[15/312]		Loss: 0.1015
2019-10-29 00:50:05,821 Training Epoch [31/40] Iter[16/312]		Loss: 0.1003
2019-10-29 00:50:05,942 Training Epoch [31/40] Iter[17/312]		Loss: 0.1012
2019-10-29 00:50:06,064 Training Epoch [31/40] Iter[18/312]		Loss: 0.1016
2019-10-29 00:50:06,188 Training Epoch [31/40] Iter[19/312]		Loss: 0.1027
2019-10-29 00:50:06,309 Training Epoch [31/40] Iter[20/312]		Loss: 0.1024
2019-10-29 00:50:06,431 Training Epoch [31/40] Iter[21/312]		Loss: 0.1032
2019-10-29 00:50:06,552 Training Epoch [31/40] Iter[22/312]		Loss: 0.1053
2019-10-29 00:50:06,673 Training Epoch [31/40] Iter[23/312]		Loss: 0.1031
2019-10-29 00:50:06,795 Training Epoch [31/40] Iter[24/312]		Loss: 0.1069
2019-10-29 00:50:06,917 Training Epoch [31/40] Iter[25/312]		Loss: 0.1073
2019-10-29 00:50:07,038 Training Epoch [31/40] Iter[26/312]		Loss: 0.1092
2019-10-29 00:50:07,160 Training Epoch [31/40] Iter[27/312]		Loss: 0.1104
2019-10-29 00:50:07,281 Training Epoch [31/40] Iter[28/312]		Loss: 0.1100
2019-10-29 00:50:07,403 Training Epoch [31/40] Iter[29/312]		Loss: 0.1107
2019-10-29 00:50:07,524 Training Epoch [31/40] Iter[30/312]		Loss: 0.1098
2019-10-29 00:50:07,645 Training Epoch [31/40] Iter[31/312]		Loss: 0.1089
2019-10-29 00:50:07,766 Training Epoch [31/40] Iter[32/312]		Loss: 0.1087
2019-10-29 00:50:07,887 Training Epoch [31/40] Iter[33/312]		Loss: 0.1090
2019-10-29 00:50:08,008 Training Epoch [31/40] Iter[34/312]		Loss: 0.1090
2019-10-29 00:50:08,129 Training Epoch [31/40] Iter[35/312]		Loss: 0.1094
2019-10-29 00:50:08,250 Training Epoch [31/40] Iter[36/312]		Loss: 0.1091
2019-10-29 00:50:08,372 Training Epoch [31/40] Iter[37/312]		Loss: 0.1087
2019-10-29 00:50:08,493 Training Epoch [31/40] Iter[38/312]		Loss: 0.1075
2019-10-29 00:50:08,614 Training Epoch [31/40] Iter[39/312]		Loss: 0.1067
2019-10-29 00:50:08,735 Training Epoch [31/40] Iter[40/312]		Loss: 0.1071
2019-10-29 00:50:08,856 Training Epoch [31/40] Iter[41/312]		Loss: 0.1066
2019-10-29 00:50:08,978 Training Epoch [31/40] Iter[42/312]		Loss: 0.1060
2019-10-29 00:50:09,099 Training Epoch [31/40] Iter[43/312]		Loss: 0.1056
2019-10-29 00:50:09,221 Training Epoch [31/40] Iter[44/312]		Loss: 0.1053
2019-10-29 00:50:09,342 Training Epoch [31/40] Iter[45/312]		Loss: 0.1053
2019-10-29 00:50:09,464 Training Epoch [31/40] Iter[46/312]		Loss: 0.1055
2019-10-29 00:50:09,586 Training Epoch [31/40] Iter[47/312]		Loss: 0.1061
2019-10-29 00:50:09,707 Training Epoch [31/40] Iter[48/312]		Loss: 0.1062
2019-10-29 00:50:09,829 Training Epoch [31/40] Iter[49/312]		Loss: 0.1058
2019-10-29 00:50:09,950 Training Epoch [31/40] Iter[50/312]		Loss: 0.1058
2019-10-29 00:50:10,071 Training Epoch [31/40] Iter[51/312]		Loss: 0.1056
2019-10-29 00:50:10,193 Training Epoch [31/40] Iter[52/312]		Loss: 0.1061
2019-10-29 00:50:10,314 Training Epoch [31/40] Iter[53/312]		Loss: 0.1056
2019-10-29 00:50:10,436 Training Epoch [31/40] Iter[54/312]		Loss: 0.1055
2019-10-29 00:50:10,558 Training Epoch [31/40] Iter[55/312]		Loss: 0.1048
2019-10-29 00:50:10,679 Training Epoch [31/40] Iter[56/312]		Loss: 0.1046
2019-10-29 00:50:10,800 Training Epoch [31/40] Iter[57/312]		Loss: 0.1050
2019-10-29 00:50:10,922 Training Epoch [31/40] Iter[58/312]		Loss: 0.1051
2019-10-29 00:50:11,043 Training Epoch [31/40] Iter[59/312]		Loss: 0.1061
2019-10-29 00:50:11,165 Training Epoch [31/40] Iter[60/312]		Loss: 0.1063
2019-10-29 00:50:11,286 Training Epoch [31/40] Iter[61/312]		Loss: 0.1063
2019-10-29 00:50:11,407 Training Epoch [31/40] Iter[62/312]		Loss: 0.1059
2019-10-29 00:50:11,529 Training Epoch [31/40] Iter[63/312]		Loss: 0.1063
2019-10-29 00:50:11,650 Training Epoch [31/40] Iter[64/312]		Loss: 0.1071
2019-10-29 00:50:11,771 Training Epoch [31/40] Iter[65/312]		Loss: 0.1066
2019-10-29 00:50:11,893 Training Epoch [31/40] Iter[66/312]		Loss: 0.1068
2019-10-29 00:50:12,014 Training Epoch [31/40] Iter[67/312]		Loss: 0.1066
2019-10-29 00:50:12,135 Training Epoch [31/40] Iter[68/312]		Loss: 0.1065
2019-10-29 00:50:12,256 Training Epoch [31/40] Iter[69/312]		Loss: 0.1063
2019-10-29 00:50:12,377 Training Epoch [31/40] Iter[70/312]		Loss: 0.1056
2019-10-29 00:50:12,499 Training Epoch [31/40] Iter[71/312]		Loss: 0.1057
2019-10-29 00:50:12,620 Training Epoch [31/40] Iter[72/312]		Loss: 0.1059
2019-10-29 00:50:12,742 Training Epoch [31/40] Iter[73/312]		Loss: 0.1054
2019-10-29 00:50:12,863 Training Epoch [31/40] Iter[74/312]		Loss: 0.1060
2019-10-29 00:50:12,985 Training Epoch [31/40] Iter[75/312]		Loss: 0.1061
2019-10-29 00:50:13,106 Training Epoch [31/40] Iter[76/312]		Loss: 0.1056
2019-10-29 00:50:13,227 Training Epoch [31/40] Iter[77/312]		Loss: 0.1052
2019-10-29 00:50:13,348 Training Epoch [31/40] Iter[78/312]		Loss: 0.1048
2019-10-29 00:50:13,469 Training Epoch [31/40] Iter[79/312]		Loss: 0.1055
2019-10-29 00:50:13,591 Training Epoch [31/40] Iter[80/312]		Loss: 0.1054
2019-10-29 00:50:13,712 Training Epoch [31/40] Iter[81/312]		Loss: 0.1056
2019-10-29 00:50:13,833 Training Epoch [31/40] Iter[82/312]		Loss: 0.1059
2019-10-29 00:50:13,954 Training Epoch [31/40] Iter[83/312]		Loss: 0.1063
2019-10-29 00:50:14,075 Training Epoch [31/40] Iter[84/312]		Loss: 0.1062
2019-10-29 00:50:14,196 Training Epoch [31/40] Iter[85/312]		Loss: 0.1057
2019-10-29 00:50:14,318 Training Epoch [31/40] Iter[86/312]		Loss: 0.1056
2019-10-29 00:50:14,439 Training Epoch [31/40] Iter[87/312]		Loss: 0.1052
2019-10-29 00:50:14,561 Training Epoch [31/40] Iter[88/312]		Loss: 0.1048
2019-10-29 00:50:14,682 Training Epoch [31/40] Iter[89/312]		Loss: 0.1045
2019-10-29 00:50:14,804 Training Epoch [31/40] Iter[90/312]		Loss: 0.1047
2019-10-29 00:50:14,925 Training Epoch [31/40] Iter[91/312]		Loss: 0.1049
2019-10-29 00:50:15,046 Training Epoch [31/40] Iter[92/312]		Loss: 0.1048
2019-10-29 00:50:15,168 Training Epoch [31/40] Iter[93/312]		Loss: 0.1048
2019-10-29 00:50:15,290 Training Epoch [31/40] Iter[94/312]		Loss: 0.1049
2019-10-29 00:50:15,411 Training Epoch [31/40] Iter[95/312]		Loss: 0.1052
2019-10-29 00:50:15,533 Training Epoch [31/40] Iter[96/312]		Loss: 0.1050
2019-10-29 00:50:15,656 Training Epoch [31/40] Iter[97/312]		Loss: 0.1050
2019-10-29 00:50:15,777 Training Epoch [31/40] Iter[98/312]		Loss: 0.1050
2019-10-29 00:50:15,899 Training Epoch [31/40] Iter[99/312]		Loss: 0.1052
2019-10-29 00:50:16,020 Training Epoch [31/40] Iter[100/312]		Loss: 0.1050
2019-10-29 00:50:16,141 Training Epoch [31/40] Iter[101/312]		Loss: 0.1047
2019-10-29 00:50:16,262 Training Epoch [31/40] Iter[102/312]		Loss: 0.1048
2019-10-29 00:50:16,384 Training Epoch [31/40] Iter[103/312]		Loss: 0.1044
2019-10-29 00:50:16,505 Training Epoch [31/40] Iter[104/312]		Loss: 0.1043
2019-10-29 00:50:16,626 Training Epoch [31/40] Iter[105/312]		Loss: 0.1047
2019-10-29 00:50:16,748 Training Epoch [31/40] Iter[106/312]		Loss: 0.1044
2019-10-29 00:50:16,869 Training Epoch [31/40] Iter[107/312]		Loss: 0.1044
2019-10-29 00:50:16,989 Training Epoch [31/40] Iter[108/312]		Loss: 0.1043
2019-10-29 00:50:17,111 Training Epoch [31/40] Iter[109/312]		Loss: 0.1046
2019-10-29 00:50:17,232 Training Epoch [31/40] Iter[110/312]		Loss: 0.1046
2019-10-29 00:50:17,353 Training Epoch [31/40] Iter[111/312]		Loss: 0.1046
2019-10-29 00:50:17,474 Training Epoch [31/40] Iter[112/312]		Loss: 0.1046
2019-10-29 00:50:17,596 Training Epoch [31/40] Iter[113/312]		Loss: 0.1048
2019-10-29 00:50:17,717 Training Epoch [31/40] Iter[114/312]		Loss: 0.1047
2019-10-29 00:50:17,838 Training Epoch [31/40] Iter[115/312]		Loss: 0.1048
2019-10-29 00:50:17,960 Training Epoch [31/40] Iter[116/312]		Loss: 0.1049
2019-10-29 00:50:18,081 Training Epoch [31/40] Iter[117/312]		Loss: 0.1049
2019-10-29 00:50:18,203 Training Epoch [31/40] Iter[118/312]		Loss: 0.1049
2019-10-29 00:50:18,324 Training Epoch [31/40] Iter[119/312]		Loss: 0.1046
2019-10-29 00:50:18,446 Training Epoch [31/40] Iter[120/312]		Loss: 0.1046
2019-10-29 00:50:18,567 Training Epoch [31/40] Iter[121/312]		Loss: 0.1047
2019-10-29 00:50:18,688 Training Epoch [31/40] Iter[122/312]		Loss: 0.1047
2019-10-29 00:50:18,810 Training Epoch [31/40] Iter[123/312]		Loss: 0.1044
2019-10-29 00:50:18,931 Training Epoch [31/40] Iter[124/312]		Loss: 0.1044
2019-10-29 00:50:19,052 Training Epoch [31/40] Iter[125/312]		Loss: 0.1042
2019-10-29 00:50:19,174 Training Epoch [31/40] Iter[126/312]		Loss: 0.1042
2019-10-29 00:50:19,295 Training Epoch [31/40] Iter[127/312]		Loss: 0.1040
2019-10-29 00:50:19,416 Training Epoch [31/40] Iter[128/312]		Loss: 0.1038
2019-10-29 00:50:19,538 Training Epoch [31/40] Iter[129/312]		Loss: 0.1037
2019-10-29 00:50:19,659 Training Epoch [31/40] Iter[130/312]		Loss: 0.1040
2019-10-29 00:50:19,781 Training Epoch [31/40] Iter[131/312]		Loss: 0.1040
2019-10-29 00:50:19,902 Training Epoch [31/40] Iter[132/312]		Loss: 0.1038
2019-10-29 00:50:20,023 Training Epoch [31/40] Iter[133/312]		Loss: 0.1040
2019-10-29 00:50:20,144 Training Epoch [31/40] Iter[134/312]		Loss: 0.1039
2019-10-29 00:50:20,266 Training Epoch [31/40] Iter[135/312]		Loss: 0.1036
2019-10-29 00:50:20,387 Training Epoch [31/40] Iter[136/312]		Loss: 0.1038
2019-10-29 00:50:20,508 Training Epoch [31/40] Iter[137/312]		Loss: 0.1040
2019-10-29 00:50:20,630 Training Epoch [31/40] Iter[138/312]		Loss: 0.1040
2019-10-29 00:50:20,751 Training Epoch [31/40] Iter[139/312]		Loss: 0.1038
2019-10-29 00:50:20,873 Training Epoch [31/40] Iter[140/312]		Loss: 0.1037
2019-10-29 00:50:20,994 Training Epoch [31/40] Iter[141/312]		Loss: 0.1034
2019-10-29 00:50:21,116 Training Epoch [31/40] Iter[142/312]		Loss: 0.1034
2019-10-29 00:50:21,237 Training Epoch [31/40] Iter[143/312]		Loss: 0.1032
2019-10-29 00:50:21,359 Training Epoch [31/40] Iter[144/312]		Loss: 0.1031
2019-10-29 00:50:21,480 Training Epoch [31/40] Iter[145/312]		Loss: 0.1032
2019-10-29 00:50:21,601 Training Epoch [31/40] Iter[146/312]		Loss: 0.1033
2019-10-29 00:50:21,722 Training Epoch [31/40] Iter[147/312]		Loss: 0.1031
2019-10-29 00:50:21,844 Training Epoch [31/40] Iter[148/312]		Loss: 0.1030
2019-10-29 00:50:21,965 Training Epoch [31/40] Iter[149/312]		Loss: 0.1029
2019-10-29 00:50:22,087 Training Epoch [31/40] Iter[150/312]		Loss: 0.1031
2019-10-29 00:50:22,208 Training Epoch [31/40] Iter[151/312]		Loss: 0.1030
2019-10-29 00:50:22,330 Training Epoch [31/40] Iter[152/312]		Loss: 0.1028
2019-10-29 00:50:22,451 Training Epoch [31/40] Iter[153/312]		Loss: 0.1027
2019-10-29 00:50:22,572 Training Epoch [31/40] Iter[154/312]		Loss: 0.1029
2019-10-29 00:50:22,693 Training Epoch [31/40] Iter[155/312]		Loss: 0.1032
2019-10-29 00:50:22,815 Training Epoch [31/40] Iter[156/312]		Loss: 0.1035
2019-10-29 00:50:22,937 Training Epoch [31/40] Iter[157/312]		Loss: 0.1033
2019-10-29 00:50:23,059 Training Epoch [31/40] Iter[158/312]		Loss: 0.1035
2019-10-29 00:50:23,185 Training Epoch [31/40] Iter[159/312]		Loss: 0.1037
2019-10-29 00:50:23,307 Training Epoch [31/40] Iter[160/312]		Loss: 0.1037
2019-10-29 00:50:23,428 Training Epoch [31/40] Iter[161/312]		Loss: 0.1035
2019-10-29 00:50:23,550 Training Epoch [31/40] Iter[162/312]		Loss: 0.1038
2019-10-29 00:50:23,671 Training Epoch [31/40] Iter[163/312]		Loss: 0.1038
2019-10-29 00:50:23,793 Training Epoch [31/40] Iter[164/312]		Loss: 0.1038
2019-10-29 00:50:23,915 Training Epoch [31/40] Iter[165/312]		Loss: 0.1038
2019-10-29 00:50:24,036 Training Epoch [31/40] Iter[166/312]		Loss: 0.1038
2019-10-29 00:50:24,158 Training Epoch [31/40] Iter[167/312]		Loss: 0.1038
2019-10-29 00:50:24,279 Training Epoch [31/40] Iter[168/312]		Loss: 0.1040
2019-10-29 00:50:24,401 Training Epoch [31/40] Iter[169/312]		Loss: 0.1037
2019-10-29 00:50:24,522 Training Epoch [31/40] Iter[170/312]		Loss: 0.1038
2019-10-29 00:50:24,643 Training Epoch [31/40] Iter[171/312]		Loss: 0.1038
2019-10-29 00:50:24,764 Training Epoch [31/40] Iter[172/312]		Loss: 0.1035
2019-10-29 00:50:24,886 Training Epoch [31/40] Iter[173/312]		Loss: 0.1036
2019-10-29 00:50:25,007 Training Epoch [31/40] Iter[174/312]		Loss: 0.1033
2019-10-29 00:50:25,128 Training Epoch [31/40] Iter[175/312]		Loss: 0.1032
2019-10-29 00:50:25,250 Training Epoch [31/40] Iter[176/312]		Loss: 0.1031
2019-10-29 00:50:25,371 Training Epoch [31/40] Iter[177/312]		Loss: 0.1031
2019-10-29 00:50:25,492 Training Epoch [31/40] Iter[178/312]		Loss: 0.1029
2019-10-29 00:50:25,613 Training Epoch [31/40] Iter[179/312]		Loss: 0.1028
2019-10-29 00:50:25,734 Training Epoch [31/40] Iter[180/312]		Loss: 0.1026
2019-10-29 00:50:25,856 Training Epoch [31/40] Iter[181/312]		Loss: 0.1024
2019-10-29 00:50:25,979 Training Epoch [31/40] Iter[182/312]		Loss: 0.1024
2019-10-29 00:50:26,100 Training Epoch [31/40] Iter[183/312]		Loss: 0.1024
2019-10-29 00:50:26,222 Training Epoch [31/40] Iter[184/312]		Loss: 0.1023
2019-10-29 00:50:26,344 Training Epoch [31/40] Iter[185/312]		Loss: 0.1025
2019-10-29 00:50:26,465 Training Epoch [31/40] Iter[186/312]		Loss: 0.1025
2019-10-29 00:50:26,587 Training Epoch [31/40] Iter[187/312]		Loss: 0.1025
2019-10-29 00:50:26,709 Training Epoch [31/40] Iter[188/312]		Loss: 0.1025
2019-10-29 00:50:26,830 Training Epoch [31/40] Iter[189/312]		Loss: 0.1025
2019-10-29 00:50:26,951 Training Epoch [31/40] Iter[190/312]		Loss: 0.1025
2019-10-29 00:50:27,073 Training Epoch [31/40] Iter[191/312]		Loss: 0.1025
2019-10-29 00:50:27,195 Training Epoch [31/40] Iter[192/312]		Loss: 0.1027
2019-10-29 00:50:27,316 Training Epoch [31/40] Iter[193/312]		Loss: 0.1027
2019-10-29 00:50:27,438 Training Epoch [31/40] Iter[194/312]		Loss: 0.1028
2019-10-29 00:50:27,559 Training Epoch [31/40] Iter[195/312]		Loss: 0.1027
2019-10-29 00:50:27,681 Training Epoch [31/40] Iter[196/312]		Loss: 0.1027
2019-10-29 00:50:27,802 Training Epoch [31/40] Iter[197/312]		Loss: 0.1027
2019-10-29 00:50:27,923 Training Epoch [31/40] Iter[198/312]		Loss: 0.1028
2019-10-29 00:50:28,045 Training Epoch [31/40] Iter[199/312]		Loss: 0.1027
2019-10-29 00:50:28,166 Training Epoch [31/40] Iter[200/312]		Loss: 0.1027
2019-10-29 00:50:28,288 Training Epoch [31/40] Iter[201/312]		Loss: 0.1029
2019-10-29 00:50:28,409 Training Epoch [31/40] Iter[202/312]		Loss: 0.1030
2019-10-29 00:50:28,530 Training Epoch [31/40] Iter[203/312]		Loss: 0.1029
2019-10-29 00:50:28,651 Training Epoch [31/40] Iter[204/312]		Loss: 0.1030
2019-10-29 00:50:28,773 Training Epoch [31/40] Iter[205/312]		Loss: 0.1030
2019-10-29 00:50:28,894 Training Epoch [31/40] Iter[206/312]		Loss: 0.1030
2019-10-29 00:50:29,015 Training Epoch [31/40] Iter[207/312]		Loss: 0.1029
2019-10-29 00:50:29,137 Training Epoch [31/40] Iter[208/312]		Loss: 0.1032
2019-10-29 00:50:29,258 Training Epoch [31/40] Iter[209/312]		Loss: 0.1031
2019-10-29 00:50:29,380 Training Epoch [31/40] Iter[210/312]		Loss: 0.1030
2019-10-29 00:50:29,501 Training Epoch [31/40] Iter[211/312]		Loss: 0.1032
2019-10-29 00:50:29,623 Training Epoch [31/40] Iter[212/312]		Loss: 0.1032
2019-10-29 00:50:29,744 Training Epoch [31/40] Iter[213/312]		Loss: 0.1032
2019-10-29 00:50:29,866 Training Epoch [31/40] Iter[214/312]		Loss: 0.1035
2019-10-29 00:50:29,987 Training Epoch [31/40] Iter[215/312]		Loss: 0.1035
2019-10-29 00:50:30,108 Training Epoch [31/40] Iter[216/312]		Loss: 0.1035
2019-10-29 00:50:30,229 Training Epoch [31/40] Iter[217/312]		Loss: 0.1033
2019-10-29 00:50:30,350 Training Epoch [31/40] Iter[218/312]		Loss: 0.1032
2019-10-29 00:50:30,472 Training Epoch [31/40] Iter[219/312]		Loss: 0.1032
2019-10-29 00:50:30,593 Training Epoch [31/40] Iter[220/312]		Loss: 0.1032
2019-10-29 00:50:30,714 Training Epoch [31/40] Iter[221/312]		Loss: 0.1031
2019-10-29 00:50:30,835 Training Epoch [31/40] Iter[222/312]		Loss: 0.1030
2019-10-29 00:50:30,956 Training Epoch [31/40] Iter[223/312]		Loss: 0.1030
2019-10-29 00:50:31,078 Training Epoch [31/40] Iter[224/312]		Loss: 0.1030
2019-10-29 00:50:31,199 Training Epoch [31/40] Iter[225/312]		Loss: 0.1029
2019-10-29 00:50:31,321 Training Epoch [31/40] Iter[226/312]		Loss: 0.1030
2019-10-29 00:50:31,442 Training Epoch [31/40] Iter[227/312]		Loss: 0.1028
2019-10-29 00:50:31,564 Training Epoch [31/40] Iter[228/312]		Loss: 0.1027
2019-10-29 00:50:31,686 Training Epoch [31/40] Iter[229/312]		Loss: 0.1026
2019-10-29 00:50:31,807 Training Epoch [31/40] Iter[230/312]		Loss: 0.1025
2019-10-29 00:50:31,929 Training Epoch [31/40] Iter[231/312]		Loss: 0.1024
2019-10-29 00:50:32,050 Training Epoch [31/40] Iter[232/312]		Loss: 0.1028
2019-10-29 00:50:32,171 Training Epoch [31/40] Iter[233/312]		Loss: 0.1027
2019-10-29 00:50:32,293 Training Epoch [31/40] Iter[234/312]		Loss: 0.1027
2019-10-29 00:50:32,415 Training Epoch [31/40] Iter[235/312]		Loss: 0.1026
2019-10-29 00:50:32,536 Training Epoch [31/40] Iter[236/312]		Loss: 0.1026
2019-10-29 00:50:32,658 Training Epoch [31/40] Iter[237/312]		Loss: 0.1026
2019-10-29 00:50:32,780 Training Epoch [31/40] Iter[238/312]		Loss: 0.1025
2019-10-29 00:50:32,901 Training Epoch [31/40] Iter[239/312]		Loss: 0.1024
2019-10-29 00:50:33,023 Training Epoch [31/40] Iter[240/312]		Loss: 0.1023
2019-10-29 00:50:33,144 Training Epoch [31/40] Iter[241/312]		Loss: 0.1023
2019-10-29 00:50:33,265 Training Epoch [31/40] Iter[242/312]		Loss: 0.1022
2019-10-29 00:50:33,387 Training Epoch [31/40] Iter[243/312]		Loss: 0.1022
2019-10-29 00:50:33,508 Training Epoch [31/40] Iter[244/312]		Loss: 0.1022
2019-10-29 00:50:33,630 Training Epoch [31/40] Iter[245/312]		Loss: 0.1024
2019-10-29 00:50:33,751 Training Epoch [31/40] Iter[246/312]		Loss: 0.1023
2019-10-29 00:50:33,872 Training Epoch [31/40] Iter[247/312]		Loss: 0.1023
2019-10-29 00:50:33,993 Training Epoch [31/40] Iter[248/312]		Loss: 0.1024
2019-10-29 00:50:34,115 Training Epoch [31/40] Iter[249/312]		Loss: 0.1026
2019-10-29 00:50:34,236 Training Epoch [31/40] Iter[250/312]		Loss: 0.1028
2019-10-29 00:50:34,357 Training Epoch [31/40] Iter[251/312]		Loss: 0.1027
2019-10-29 00:50:34,479 Training Epoch [31/40] Iter[252/312]		Loss: 0.1025
2019-10-29 00:50:34,605 Training Epoch [31/40] Iter[253/312]		Loss: 0.1024
2019-10-29 00:50:34,727 Training Epoch [31/40] Iter[254/312]		Loss: 0.1024
2019-10-29 00:50:34,849 Training Epoch [31/40] Iter[255/312]		Loss: 0.1023
2019-10-29 00:50:34,971 Training Epoch [31/40] Iter[256/312]		Loss: 0.1021
2019-10-29 00:50:35,092 Training Epoch [31/40] Iter[257/312]		Loss: 0.1020
2019-10-29 00:50:35,214 Training Epoch [31/40] Iter[258/312]		Loss: 0.1020
2019-10-29 00:50:35,336 Training Epoch [31/40] Iter[259/312]		Loss: 0.1023
2019-10-29 00:50:35,457 Training Epoch [31/40] Iter[260/312]		Loss: 0.1025
2019-10-29 00:50:35,578 Training Epoch [31/40] Iter[261/312]		Loss: 0.1024
2019-10-29 00:50:35,699 Training Epoch [31/40] Iter[262/312]		Loss: 0.1024
2019-10-29 00:50:35,821 Training Epoch [31/40] Iter[263/312]		Loss: 0.1023
2019-10-29 00:50:35,943 Training Epoch [31/40] Iter[264/312]		Loss: 0.1025
2019-10-29 00:50:36,064 Training Epoch [31/40] Iter[265/312]		Loss: 0.1026
2019-10-29 00:50:36,185 Training Epoch [31/40] Iter[266/312]		Loss: 0.1027
2019-10-29 00:50:36,308 Training Epoch [31/40] Iter[267/312]		Loss: 0.1026
2019-10-29 00:50:36,430 Training Epoch [31/40] Iter[268/312]		Loss: 0.1027
2019-10-29 00:50:36,551 Training Epoch [31/40] Iter[269/312]		Loss: 0.1026
2019-10-29 00:50:36,672 Training Epoch [31/40] Iter[270/312]		Loss: 0.1025
2019-10-29 00:50:36,794 Training Epoch [31/40] Iter[271/312]		Loss: 0.1028
2019-10-29 00:50:36,915 Training Epoch [31/40] Iter[272/312]		Loss: 0.1027
2019-10-29 00:50:37,036 Training Epoch [31/40] Iter[273/312]		Loss: 0.1027
2019-10-29 00:50:37,158 Training Epoch [31/40] Iter[274/312]		Loss: 0.1026
2019-10-29 00:50:37,279 Training Epoch [31/40] Iter[275/312]		Loss: 0.1026
2019-10-29 00:50:37,401 Training Epoch [31/40] Iter[276/312]		Loss: 0.1025
2019-10-29 00:50:37,522 Training Epoch [31/40] Iter[277/312]		Loss: 0.1025
2019-10-29 00:50:37,644 Training Epoch [31/40] Iter[278/312]		Loss: 0.1024
2019-10-29 00:50:37,765 Training Epoch [31/40] Iter[279/312]		Loss: 0.1025
2019-10-29 00:50:37,886 Training Epoch [31/40] Iter[280/312]		Loss: 0.1024
2019-10-29 00:50:38,008 Training Epoch [31/40] Iter[281/312]		Loss: 0.1023
2019-10-29 00:50:38,130 Training Epoch [31/40] Iter[282/312]		Loss: 0.1023
2019-10-29 00:50:38,251 Training Epoch [31/40] Iter[283/312]		Loss: 0.1022
2019-10-29 00:50:38,373 Training Epoch [31/40] Iter[284/312]		Loss: 0.1023
2019-10-29 00:50:38,494 Training Epoch [31/40] Iter[285/312]		Loss: 0.1023
2019-10-29 00:50:38,615 Training Epoch [31/40] Iter[286/312]		Loss: 0.1022
2019-10-29 00:50:38,737 Training Epoch [31/40] Iter[287/312]		Loss: 0.1022
2019-10-29 00:50:38,858 Training Epoch [31/40] Iter[288/312]		Loss: 0.1025
2019-10-29 00:50:38,979 Training Epoch [31/40] Iter[289/312]		Loss: 0.1025
2019-10-29 00:50:39,100 Training Epoch [31/40] Iter[290/312]		Loss: 0.1026
2019-10-29 00:50:39,221 Training Epoch [31/40] Iter[291/312]		Loss: 0.1026
2019-10-29 00:50:39,343 Training Epoch [31/40] Iter[292/312]		Loss: 0.1025
2019-10-29 00:50:39,464 Training Epoch [31/40] Iter[293/312]		Loss: 0.1025
2019-10-29 00:50:39,585 Training Epoch [31/40] Iter[294/312]		Loss: 0.1024
2019-10-29 00:50:39,706 Training Epoch [31/40] Iter[295/312]		Loss: 0.1026
2019-10-29 00:50:39,828 Training Epoch [31/40] Iter[296/312]		Loss: 0.1027
2019-10-29 00:50:39,950 Training Epoch [31/40] Iter[297/312]		Loss: 0.1028
2019-10-29 00:50:40,072 Training Epoch [31/40] Iter[298/312]		Loss: 0.1026
2019-10-29 00:50:40,193 Training Epoch [31/40] Iter[299/312]		Loss: 0.1028
2019-10-29 00:50:40,315 Training Epoch [31/40] Iter[300/312]		Loss: 0.1030
2019-10-29 00:50:40,441 Training Epoch [31/40] Iter[301/312]		Loss: 0.1032
2019-10-29 00:50:40,563 Training Epoch [31/40] Iter[302/312]		Loss: 0.1031
2019-10-29 00:50:40,684 Training Epoch [31/40] Iter[303/312]		Loss: 0.1029
2019-10-29 00:50:40,806 Training Epoch [31/40] Iter[304/312]		Loss: 0.1028
2019-10-29 00:50:40,927 Training Epoch [31/40] Iter[305/312]		Loss: 0.1028
2019-10-29 00:50:41,049 Training Epoch [31/40] Iter[306/312]		Loss: 0.1028
2019-10-29 00:50:41,171 Training Epoch [31/40] Iter[307/312]		Loss: 0.1026
2019-10-29 00:50:41,292 Training Epoch [31/40] Iter[308/312]		Loss: 0.1027
2019-10-29 00:50:41,413 Training Epoch [31/40] Iter[309/312]		Loss: 0.1027
2019-10-29 00:50:41,533 Training Epoch [31/40] Iter[310/312]		Loss: 0.1027
2019-10-29 00:50:41,654 Training Epoch [31/40] Iter[311/312]		Loss: 0.1026
2019-10-29 00:50:41,714 Training Epoch [31/40] Iter[312/312]		Loss: 0.1025
2019-10-29 00:50:42,095 Testing Epoch [31/40] Iter[0/62]		Loss: 0.0911
2019-10-29 00:50:42,133 Testing Epoch [31/40] Iter[1/62]		Loss: 0.1251
2019-10-29 00:50:42,174 Testing Epoch [31/40] Iter[2/62]		Loss: 0.1172
2019-10-29 00:50:42,208 Testing Epoch [31/40] Iter[3/62]		Loss: 0.1159
2019-10-29 00:50:42,242 Testing Epoch [31/40] Iter[4/62]		Loss: 0.1113
2019-10-29 00:50:42,272 Testing Epoch [31/40] Iter[5/62]		Loss: 0.1087
2019-10-29 00:50:42,301 Testing Epoch [31/40] Iter[6/62]		Loss: 0.1093
2019-10-29 00:50:42,341 Testing Epoch [31/40] Iter[7/62]		Loss: 0.1159
2019-10-29 00:50:42,371 Testing Epoch [31/40] Iter[8/62]		Loss: 0.1226
2019-10-29 00:50:42,401 Testing Epoch [31/40] Iter[9/62]		Loss: 0.1196
2019-10-29 00:50:42,432 Testing Epoch [31/40] Iter[10/62]		Loss: 0.1174
2019-10-29 00:50:42,462 Testing Epoch [31/40] Iter[11/62]		Loss: 0.1221
2019-10-29 00:50:42,493 Testing Epoch [31/40] Iter[12/62]		Loss: 0.1225
2019-10-29 00:50:42,524 Testing Epoch [31/40] Iter[13/62]		Loss: 0.1245
2019-10-29 00:50:42,554 Testing Epoch [31/40] Iter[14/62]		Loss: 0.1370
2019-10-29 00:50:42,585 Testing Epoch [31/40] Iter[15/62]		Loss: 0.1389
2019-10-29 00:50:42,616 Testing Epoch [31/40] Iter[16/62]		Loss: 0.1367
2019-10-29 00:50:42,647 Testing Epoch [31/40] Iter[17/62]		Loss: 0.1359
2019-10-29 00:50:42,677 Testing Epoch [31/40] Iter[18/62]		Loss: 0.1325
2019-10-29 00:50:42,708 Testing Epoch [31/40] Iter[19/62]		Loss: 0.1304
2019-10-29 00:50:42,739 Testing Epoch [31/40] Iter[20/62]		Loss: 0.1318
2019-10-29 00:50:42,770 Testing Epoch [31/40] Iter[21/62]		Loss: 0.1301
2019-10-29 00:50:42,801 Testing Epoch [31/40] Iter[22/62]		Loss: 0.1296
2019-10-29 00:50:42,831 Testing Epoch [31/40] Iter[23/62]		Loss: 0.1294
2019-10-29 00:50:42,862 Testing Epoch [31/40] Iter[24/62]		Loss: 0.1311
2019-10-29 00:50:42,893 Testing Epoch [31/40] Iter[25/62]		Loss: 0.1303
2019-10-29 00:50:42,924 Testing Epoch [31/40] Iter[26/62]		Loss: 0.1291
2019-10-29 00:50:42,955 Testing Epoch [31/40] Iter[27/62]		Loss: 0.1338
2019-10-29 00:50:42,986 Testing Epoch [31/40] Iter[28/62]		Loss: 0.1355
2019-10-29 00:50:43,017 Testing Epoch [31/40] Iter[29/62]		Loss: 0.1354
2019-10-29 00:50:43,047 Testing Epoch [31/40] Iter[30/62]		Loss: 0.1370
2019-10-29 00:50:43,078 Testing Epoch [31/40] Iter[31/62]		Loss: 0.1362
2019-10-29 00:50:43,109 Testing Epoch [31/40] Iter[32/62]		Loss: 0.1376
2019-10-29 00:50:43,140 Testing Epoch [31/40] Iter[33/62]		Loss: 0.1358
2019-10-29 00:50:43,171 Testing Epoch [31/40] Iter[34/62]		Loss: 0.1374
2019-10-29 00:50:43,202 Testing Epoch [31/40] Iter[35/62]		Loss: 0.1378
2019-10-29 00:50:43,233 Testing Epoch [31/40] Iter[36/62]		Loss: 0.1360
2019-10-29 00:50:43,263 Testing Epoch [31/40] Iter[37/62]		Loss: 0.1359
2019-10-29 00:50:43,294 Testing Epoch [31/40] Iter[38/62]		Loss: 0.1360
2019-10-29 00:50:43,325 Testing Epoch [31/40] Iter[39/62]		Loss: 0.1363
2019-10-29 00:50:43,356 Testing Epoch [31/40] Iter[40/62]		Loss: 0.1368
2019-10-29 00:50:43,387 Testing Epoch [31/40] Iter[41/62]		Loss: 0.1368
2019-10-29 00:50:43,418 Testing Epoch [31/40] Iter[42/62]		Loss: 0.1355
2019-10-29 00:50:43,449 Testing Epoch [31/40] Iter[43/62]		Loss: 0.1351
2019-10-29 00:50:43,480 Testing Epoch [31/40] Iter[44/62]		Loss: 0.1338
2019-10-29 00:50:43,511 Testing Epoch [31/40] Iter[45/62]		Loss: 0.1350
2019-10-29 00:50:43,541 Testing Epoch [31/40] Iter[46/62]		Loss: 0.1352
2019-10-29 00:50:43,572 Testing Epoch [31/40] Iter[47/62]		Loss: 0.1400
2019-10-29 00:50:43,603 Testing Epoch [31/40] Iter[48/62]		Loss: 0.1390
2019-10-29 00:50:43,634 Testing Epoch [31/40] Iter[49/62]		Loss: 0.1406
2019-10-29 00:50:43,664 Testing Epoch [31/40] Iter[50/62]		Loss: 0.1402
2019-10-29 00:50:43,695 Testing Epoch [31/40] Iter[51/62]		Loss: 0.1403
2019-10-29 00:50:43,726 Testing Epoch [31/40] Iter[52/62]		Loss: 0.1392
2019-10-29 00:50:43,757 Testing Epoch [31/40] Iter[53/62]		Loss: 0.1390
2019-10-29 00:50:43,788 Testing Epoch [31/40] Iter[54/62]		Loss: 0.1384
2019-10-29 00:50:43,818 Testing Epoch [31/40] Iter[55/62]		Loss: 0.1387
2019-10-29 00:50:43,848 Testing Epoch [31/40] Iter[56/62]		Loss: 0.1385
2019-10-29 00:50:43,879 Testing Epoch [31/40] Iter[57/62]		Loss: 0.1384
2019-10-29 00:50:43,909 Testing Epoch [31/40] Iter[58/62]		Loss: 0.1379
2019-10-29 00:50:43,939 Testing Epoch [31/40] Iter[59/62]		Loss: 0.1379
2019-10-29 00:50:43,970 Testing Epoch [31/40] Iter[60/62]		Loss: 0.1373
2019-10-29 00:50:44,000 Testing Epoch [31/40] Iter[61/62]		Loss: 0.1370
2019-10-29 00:50:44,017 Testing Epoch [31/40] Iter[62/62]		Loss: 0.1377
2019-10-29 00:50:44,501 Training Epoch [32/40] Iter[0/312]		Loss: 0.1108
2019-10-29 00:50:44,622 Training Epoch [32/40] Iter[1/312]		Loss: 0.0999
2019-10-29 00:50:44,745 Training Epoch [32/40] Iter[2/312]		Loss: 0.1139
2019-10-29 00:50:44,868 Training Epoch [32/40] Iter[3/312]		Loss: 0.1073
2019-10-29 00:50:44,988 Training Epoch [32/40] Iter[4/312]		Loss: 0.1012
2019-10-29 00:50:45,108 Training Epoch [32/40] Iter[5/312]		Loss: 0.1015
2019-10-29 00:50:45,229 Training Epoch [32/40] Iter[6/312]		Loss: 0.1029
2019-10-29 00:50:45,351 Training Epoch [32/40] Iter[7/312]		Loss: 0.1011
2019-10-29 00:50:45,471 Training Epoch [32/40] Iter[8/312]		Loss: 0.0996
2019-10-29 00:50:45,593 Training Epoch [32/40] Iter[9/312]		Loss: 0.1000
2019-10-29 00:50:45,714 Training Epoch [32/40] Iter[10/312]		Loss: 0.1006
2019-10-29 00:50:45,836 Training Epoch [32/40] Iter[11/312]		Loss: 0.0978
2019-10-29 00:50:45,957 Training Epoch [32/40] Iter[12/312]		Loss: 0.0958
2019-10-29 00:50:46,079 Training Epoch [32/40] Iter[13/312]		Loss: 0.0955
2019-10-29 00:50:46,200 Training Epoch [32/40] Iter[14/312]		Loss: 0.0965
2019-10-29 00:50:46,321 Training Epoch [32/40] Iter[15/312]		Loss: 0.0958
2019-10-29 00:50:46,443 Training Epoch [32/40] Iter[16/312]		Loss: 0.0960
2019-10-29 00:50:46,565 Training Epoch [32/40] Iter[17/312]		Loss: 0.0961
2019-10-29 00:50:46,687 Training Epoch [32/40] Iter[18/312]		Loss: 0.0958
2019-10-29 00:50:46,808 Training Epoch [32/40] Iter[19/312]		Loss: 0.0984
2019-10-29 00:50:46,929 Training Epoch [32/40] Iter[20/312]		Loss: 0.0983
2019-10-29 00:50:47,051 Training Epoch [32/40] Iter[21/312]		Loss: 0.0974
2019-10-29 00:50:47,172 Training Epoch [32/40] Iter[22/312]		Loss: 0.0963
2019-10-29 00:50:47,293 Training Epoch [32/40] Iter[23/312]		Loss: 0.0998
2019-10-29 00:50:47,414 Training Epoch [32/40] Iter[24/312]		Loss: 0.0998
2019-10-29 00:50:47,535 Training Epoch [32/40] Iter[25/312]		Loss: 0.0999
2019-10-29 00:50:47,656 Training Epoch [32/40] Iter[26/312]		Loss: 0.1000
2019-10-29 00:50:47,777 Training Epoch [32/40] Iter[27/312]		Loss: 0.0995
2019-10-29 00:50:47,898 Training Epoch [32/40] Iter[28/312]		Loss: 0.0981
2019-10-29 00:50:48,019 Training Epoch [32/40] Iter[29/312]		Loss: 0.0987
2019-10-29 00:50:48,140 Training Epoch [32/40] Iter[30/312]		Loss: 0.0982
2019-10-29 00:50:48,262 Training Epoch [32/40] Iter[31/312]		Loss: 0.0985
2019-10-29 00:50:48,384 Training Epoch [32/40] Iter[32/312]		Loss: 0.0987
2019-10-29 00:50:48,505 Training Epoch [32/40] Iter[33/312]		Loss: 0.0984
2019-10-29 00:50:48,627 Training Epoch [32/40] Iter[34/312]		Loss: 0.0990
2019-10-29 00:50:48,748 Training Epoch [32/40] Iter[35/312]		Loss: 0.0982
2019-10-29 00:50:48,870 Training Epoch [32/40] Iter[36/312]		Loss: 0.0975
2019-10-29 00:50:48,991 Training Epoch [32/40] Iter[37/312]		Loss: 0.0976
2019-10-29 00:50:49,112 Training Epoch [32/40] Iter[38/312]		Loss: 0.0978
2019-10-29 00:50:49,234 Training Epoch [32/40] Iter[39/312]		Loss: 0.0973
2019-10-29 00:50:49,356 Training Epoch [32/40] Iter[40/312]		Loss: 0.0977
2019-10-29 00:50:49,477 Training Epoch [32/40] Iter[41/312]		Loss: 0.0979
2019-10-29 00:50:49,599 Training Epoch [32/40] Iter[42/312]		Loss: 0.0982
2019-10-29 00:50:49,720 Training Epoch [32/40] Iter[43/312]		Loss: 0.0983
2019-10-29 00:50:49,842 Training Epoch [32/40] Iter[44/312]		Loss: 0.0974
2019-10-29 00:50:49,963 Training Epoch [32/40] Iter[45/312]		Loss: 0.0969
2019-10-29 00:50:50,084 Training Epoch [32/40] Iter[46/312]		Loss: 0.0964
2019-10-29 00:50:50,205 Training Epoch [32/40] Iter[47/312]		Loss: 0.0975
2019-10-29 00:50:50,327 Training Epoch [32/40] Iter[48/312]		Loss: 0.0979
2019-10-29 00:50:50,448 Training Epoch [32/40] Iter[49/312]		Loss: 0.0982
2019-10-29 00:50:50,569 Training Epoch [32/40] Iter[50/312]		Loss: 0.0978
2019-10-29 00:50:50,690 Training Epoch [32/40] Iter[51/312]		Loss: 0.0984
2019-10-29 00:50:50,812 Training Epoch [32/40] Iter[52/312]		Loss: 0.0989
2019-10-29 00:50:50,933 Training Epoch [32/40] Iter[53/312]		Loss: 0.0993
2019-10-29 00:50:51,054 Training Epoch [32/40] Iter[54/312]		Loss: 0.0997
2019-10-29 00:50:51,175 Training Epoch [32/40] Iter[55/312]		Loss: 0.0991
2019-10-29 00:50:51,297 Training Epoch [32/40] Iter[56/312]		Loss: 0.0997
2019-10-29 00:50:51,418 Training Epoch [32/40] Iter[57/312]		Loss: 0.0992
2019-10-29 00:50:51,540 Training Epoch [32/40] Iter[58/312]		Loss: 0.0997
2019-10-29 00:50:51,661 Training Epoch [32/40] Iter[59/312]		Loss: 0.0994
2019-10-29 00:50:51,782 Training Epoch [32/40] Iter[60/312]		Loss: 0.0991
2019-10-29 00:50:51,904 Training Epoch [32/40] Iter[61/312]		Loss: 0.0990
2019-10-29 00:50:52,025 Training Epoch [32/40] Iter[62/312]		Loss: 0.0991
2019-10-29 00:50:52,147 Training Epoch [32/40] Iter[63/312]		Loss: 0.0988
2019-10-29 00:50:52,269 Training Epoch [32/40] Iter[64/312]		Loss: 0.0990
2019-10-29 00:50:52,390 Training Epoch [32/40] Iter[65/312]		Loss: 0.0987
2019-10-29 00:50:52,511 Training Epoch [32/40] Iter[66/312]		Loss: 0.0983
2019-10-29 00:50:52,633 Training Epoch [32/40] Iter[67/312]		Loss: 0.0984
2019-10-29 00:50:52,754 Training Epoch [32/40] Iter[68/312]		Loss: 0.0984
2019-10-29 00:50:52,876 Training Epoch [32/40] Iter[69/312]		Loss: 0.0984
2019-10-29 00:50:52,998 Training Epoch [32/40] Iter[70/312]		Loss: 0.0979
2019-10-29 00:50:53,124 Training Epoch [32/40] Iter[71/312]		Loss: 0.0975
2019-10-29 00:50:53,246 Training Epoch [32/40] Iter[72/312]		Loss: 0.0973
2019-10-29 00:50:53,367 Training Epoch [32/40] Iter[73/312]		Loss: 0.0970
2019-10-29 00:50:53,492 Training Epoch [32/40] Iter[74/312]		Loss: 0.0977
2019-10-29 00:50:53,614 Training Epoch [32/40] Iter[75/312]		Loss: 0.0978
2019-10-29 00:50:53,735 Training Epoch [32/40] Iter[76/312]		Loss: 0.0983
2019-10-29 00:50:53,856 Training Epoch [32/40] Iter[77/312]		Loss: 0.0982
2019-10-29 00:50:53,977 Training Epoch [32/40] Iter[78/312]		Loss: 0.0990
2019-10-29 00:50:54,098 Training Epoch [32/40] Iter[79/312]		Loss: 0.0995
2019-10-29 00:50:54,219 Training Epoch [32/40] Iter[80/312]		Loss: 0.1001
2019-10-29 00:50:54,341 Training Epoch [32/40] Iter[81/312]		Loss: 0.1001
2019-10-29 00:50:54,462 Training Epoch [32/40] Iter[82/312]		Loss: 0.1000
2019-10-29 00:50:54,584 Training Epoch [32/40] Iter[83/312]		Loss: 0.0996
2019-10-29 00:50:54,705 Training Epoch [32/40] Iter[84/312]		Loss: 0.0997
2019-10-29 00:50:54,827 Training Epoch [32/40] Iter[85/312]		Loss: 0.0997
2019-10-29 00:50:54,948 Training Epoch [32/40] Iter[86/312]		Loss: 0.0996
2019-10-29 00:50:55,070 Training Epoch [32/40] Iter[87/312]		Loss: 0.0996
2019-10-29 00:50:55,191 Training Epoch [32/40] Iter[88/312]		Loss: 0.0997
2019-10-29 00:50:55,313 Training Epoch [32/40] Iter[89/312]		Loss: 0.0994
2019-10-29 00:50:55,434 Training Epoch [32/40] Iter[90/312]		Loss: 0.0993
2019-10-29 00:50:55,555 Training Epoch [32/40] Iter[91/312]		Loss: 0.0998
2019-10-29 00:50:55,676 Training Epoch [32/40] Iter[92/312]		Loss: 0.1003
2019-10-29 00:50:55,797 Training Epoch [32/40] Iter[93/312]		Loss: 0.1001
2019-10-29 00:50:55,918 Training Epoch [32/40] Iter[94/312]		Loss: 0.1002
2019-10-29 00:50:56,040 Training Epoch [32/40] Iter[95/312]		Loss: 0.1004
2019-10-29 00:50:56,161 Training Epoch [32/40] Iter[96/312]		Loss: 0.1001
2019-10-29 00:50:56,282 Training Epoch [32/40] Iter[97/312]		Loss: 0.1002
2019-10-29 00:50:56,403 Training Epoch [32/40] Iter[98/312]		Loss: 0.1001
2019-10-29 00:50:56,524 Training Epoch [32/40] Iter[99/312]		Loss: 0.1004
2019-10-29 00:50:56,645 Training Epoch [32/40] Iter[100/312]		Loss: 0.1005
2019-10-29 00:50:56,767 Training Epoch [32/40] Iter[101/312]		Loss: 0.1011
2019-10-29 00:50:56,889 Training Epoch [32/40] Iter[102/312]		Loss: 0.1011
2019-10-29 00:50:57,011 Training Epoch [32/40] Iter[103/312]		Loss: 0.1007
2019-10-29 00:50:57,132 Training Epoch [32/40] Iter[104/312]		Loss: 0.1006
2019-10-29 00:50:57,254 Training Epoch [32/40] Iter[105/312]		Loss: 0.1007
2019-10-29 00:50:57,375 Training Epoch [32/40] Iter[106/312]		Loss: 0.1011
2019-10-29 00:50:57,497 Training Epoch [32/40] Iter[107/312]		Loss: 0.1014
2019-10-29 00:50:57,618 Training Epoch [32/40] Iter[108/312]		Loss: 0.1011
2019-10-29 00:50:57,739 Training Epoch [32/40] Iter[109/312]		Loss: 0.1012
2019-10-29 00:50:57,861 Training Epoch [32/40] Iter[110/312]		Loss: 0.1014
2019-10-29 00:50:57,983 Training Epoch [32/40] Iter[111/312]		Loss: 0.1011
2019-10-29 00:50:58,104 Training Epoch [32/40] Iter[112/312]		Loss: 0.1018
2019-10-29 00:50:58,225 Training Epoch [32/40] Iter[113/312]		Loss: 0.1015
2019-10-29 00:50:58,347 Training Epoch [32/40] Iter[114/312]		Loss: 0.1014
2019-10-29 00:50:58,469 Training Epoch [32/40] Iter[115/312]		Loss: 0.1014
2019-10-29 00:50:58,590 Training Epoch [32/40] Iter[116/312]		Loss: 0.1012
2019-10-29 00:50:58,711 Training Epoch [32/40] Iter[117/312]		Loss: 0.1013
2019-10-29 00:50:58,832 Training Epoch [32/40] Iter[118/312]		Loss: 0.1013
2019-10-29 00:50:58,953 Training Epoch [32/40] Iter[119/312]		Loss: 0.1011
2019-10-29 00:50:59,075 Training Epoch [32/40] Iter[120/312]		Loss: 0.1014
2019-10-29 00:50:59,196 Training Epoch [32/40] Iter[121/312]		Loss: 0.1016
2019-10-29 00:50:59,316 Training Epoch [32/40] Iter[122/312]		Loss: 0.1014
2019-10-29 00:50:59,438 Training Epoch [32/40] Iter[123/312]		Loss: 0.1011
2019-10-29 00:50:59,559 Training Epoch [32/40] Iter[124/312]		Loss: 0.1012
2019-10-29 00:50:59,680 Training Epoch [32/40] Iter[125/312]		Loss: 0.1011
2019-10-29 00:50:59,802 Training Epoch [32/40] Iter[126/312]		Loss: 0.1011
2019-10-29 00:50:59,923 Training Epoch [32/40] Iter[127/312]		Loss: 0.1010
2019-10-29 00:51:00,045 Training Epoch [32/40] Iter[128/312]		Loss: 0.1006
2019-10-29 00:51:00,167 Training Epoch [32/40] Iter[129/312]		Loss: 0.1007
2019-10-29 00:51:00,288 Training Epoch [32/40] Iter[130/312]		Loss: 0.1005
2019-10-29 00:51:00,410 Training Epoch [32/40] Iter[131/312]		Loss: 0.1006
2019-10-29 00:51:00,531 Training Epoch [32/40] Iter[132/312]		Loss: 0.1006
2019-10-29 00:51:00,653 Training Epoch [32/40] Iter[133/312]		Loss: 0.1008
2019-10-29 00:51:00,774 Training Epoch [32/40] Iter[134/312]		Loss: 0.1010
2019-10-29 00:51:00,896 Training Epoch [32/40] Iter[135/312]		Loss: 0.1011
2019-10-29 00:51:01,017 Training Epoch [32/40] Iter[136/312]		Loss: 0.1008
2019-10-29 00:51:01,139 Training Epoch [32/40] Iter[137/312]		Loss: 0.1008
2019-10-29 00:51:01,261 Training Epoch [32/40] Iter[138/312]		Loss: 0.1004
2019-10-29 00:51:01,382 Training Epoch [32/40] Iter[139/312]		Loss: 0.1006
2019-10-29 00:51:01,504 Training Epoch [32/40] Iter[140/312]		Loss: 0.1005
2019-10-29 00:51:01,625 Training Epoch [32/40] Iter[141/312]		Loss: 0.1003
2019-10-29 00:51:01,746 Training Epoch [32/40] Iter[142/312]		Loss: 0.1001
2019-10-29 00:51:01,868 Training Epoch [32/40] Iter[143/312]		Loss: 0.1001
2019-10-29 00:51:01,989 Training Epoch [32/40] Iter[144/312]		Loss: 0.1004
2019-10-29 00:51:02,111 Training Epoch [32/40] Iter[145/312]		Loss: 0.1004
2019-10-29 00:51:02,232 Training Epoch [32/40] Iter[146/312]		Loss: 0.1004
2019-10-29 00:51:02,354 Training Epoch [32/40] Iter[147/312]		Loss: 0.1004
2019-10-29 00:51:02,475 Training Epoch [32/40] Iter[148/312]		Loss: 0.1004
2019-10-29 00:51:02,597 Training Epoch [32/40] Iter[149/312]		Loss: 0.1007
2019-10-29 00:51:02,718 Training Epoch [32/40] Iter[150/312]		Loss: 0.1005
2019-10-29 00:51:02,839 Training Epoch [32/40] Iter[151/312]		Loss: 0.1004
2019-10-29 00:51:02,961 Training Epoch [32/40] Iter[152/312]		Loss: 0.1007
2019-10-29 00:51:03,082 Training Epoch [32/40] Iter[153/312]		Loss: 0.1009
2019-10-29 00:51:03,203 Training Epoch [32/40] Iter[154/312]		Loss: 0.1008
2019-10-29 00:51:03,325 Training Epoch [32/40] Iter[155/312]		Loss: 0.1009
2019-10-29 00:51:03,447 Training Epoch [32/40] Iter[156/312]		Loss: 0.1008
2019-10-29 00:51:03,568 Training Epoch [32/40] Iter[157/312]		Loss: 0.1009
2019-10-29 00:51:03,690 Training Epoch [32/40] Iter[158/312]		Loss: 0.1012
2019-10-29 00:51:03,811 Training Epoch [32/40] Iter[159/312]		Loss: 0.1011
2019-10-29 00:51:03,933 Training Epoch [32/40] Iter[160/312]		Loss: 0.1009
2019-10-29 00:51:04,053 Training Epoch [32/40] Iter[161/312]		Loss: 0.1008
2019-10-29 00:51:04,175 Training Epoch [32/40] Iter[162/312]		Loss: 0.1015
2019-10-29 00:51:04,296 Training Epoch [32/40] Iter[163/312]		Loss: 0.1013
2019-10-29 00:51:04,417 Training Epoch [32/40] Iter[164/312]		Loss: 0.1014
2019-10-29 00:51:04,538 Training Epoch [32/40] Iter[165/312]		Loss: 0.1013
2019-10-29 00:51:04,659 Training Epoch [32/40] Iter[166/312]		Loss: 0.1011
2019-10-29 00:51:04,780 Training Epoch [32/40] Iter[167/312]		Loss: 0.1012
2019-10-29 00:51:04,901 Training Epoch [32/40] Iter[168/312]		Loss: 0.1011
2019-10-29 00:51:05,022 Training Epoch [32/40] Iter[169/312]		Loss: 0.1012
2019-10-29 00:51:05,143 Training Epoch [32/40] Iter[170/312]		Loss: 0.1011
2019-10-29 00:51:05,265 Training Epoch [32/40] Iter[171/312]		Loss: 0.1008
2019-10-29 00:51:05,387 Training Epoch [32/40] Iter[172/312]		Loss: 0.1011
2019-10-29 00:51:05,508 Training Epoch [32/40] Iter[173/312]		Loss: 0.1010
2019-10-29 00:51:05,630 Training Epoch [32/40] Iter[174/312]		Loss: 0.1010
2019-10-29 00:51:05,752 Training Epoch [32/40] Iter[175/312]		Loss: 0.1014
2019-10-29 00:51:05,873 Training Epoch [32/40] Iter[176/312]		Loss: 0.1013
2019-10-29 00:51:05,994 Training Epoch [32/40] Iter[177/312]		Loss: 0.1012
2019-10-29 00:51:06,116 Training Epoch [32/40] Iter[178/312]		Loss: 0.1011
2019-10-29 00:51:06,237 Training Epoch [32/40] Iter[179/312]		Loss: 0.1011
2019-10-29 00:51:06,359 Training Epoch [32/40] Iter[180/312]		Loss: 0.1014
2019-10-29 00:51:06,481 Training Epoch [32/40] Iter[181/312]		Loss: 0.1014
2019-10-29 00:51:06,603 Training Epoch [32/40] Iter[182/312]		Loss: 0.1012
2019-10-29 00:51:06,724 Training Epoch [32/40] Iter[183/312]		Loss: 0.1013
2019-10-29 00:51:06,846 Training Epoch [32/40] Iter[184/312]		Loss: 0.1012
2019-10-29 00:51:06,974 Training Epoch [32/40] Iter[185/312]		Loss: 0.1010
2019-10-29 00:51:07,095 Training Epoch [32/40] Iter[186/312]		Loss: 0.1010
2019-10-29 00:51:07,217 Training Epoch [32/40] Iter[187/312]		Loss: 0.1010
2019-10-29 00:51:07,338 Training Epoch [32/40] Iter[188/312]		Loss: 0.1010
2019-10-29 00:51:07,460 Training Epoch [32/40] Iter[189/312]		Loss: 0.1009
2019-10-29 00:51:07,581 Training Epoch [32/40] Iter[190/312]		Loss: 0.1007
2019-10-29 00:51:07,702 Training Epoch [32/40] Iter[191/312]		Loss: 0.1007
2019-10-29 00:51:07,823 Training Epoch [32/40] Iter[192/312]		Loss: 0.1008
2019-10-29 00:51:07,944 Training Epoch [32/40] Iter[193/312]		Loss: 0.1012
2019-10-29 00:51:08,065 Training Epoch [32/40] Iter[194/312]		Loss: 0.1011
2019-10-29 00:51:08,186 Training Epoch [32/40] Iter[195/312]		Loss: 0.1011
2019-10-29 00:51:08,307 Training Epoch [32/40] Iter[196/312]		Loss: 0.1011
2019-10-29 00:51:08,428 Training Epoch [32/40] Iter[197/312]		Loss: 0.1010
2019-10-29 00:51:08,550 Training Epoch [32/40] Iter[198/312]		Loss: 0.1010
2019-10-29 00:51:08,672 Training Epoch [32/40] Iter[199/312]		Loss: 0.1009
2019-10-29 00:51:08,793 Training Epoch [32/40] Iter[200/312]		Loss: 0.1009
2019-10-29 00:51:08,914 Training Epoch [32/40] Iter[201/312]		Loss: 0.1008
2019-10-29 00:51:09,036 Training Epoch [32/40] Iter[202/312]		Loss: 0.1008
2019-10-29 00:51:09,157 Training Epoch [32/40] Iter[203/312]		Loss: 0.1010
2019-10-29 00:51:09,279 Training Epoch [32/40] Iter[204/312]		Loss: 0.1011
2019-10-29 00:51:09,400 Training Epoch [32/40] Iter[205/312]		Loss: 0.1013
2019-10-29 00:51:09,522 Training Epoch [32/40] Iter[206/312]		Loss: 0.1012
2019-10-29 00:51:09,643 Training Epoch [32/40] Iter[207/312]		Loss: 0.1012
2019-10-29 00:51:09,764 Training Epoch [32/40] Iter[208/312]		Loss: 0.1012
2019-10-29 00:51:09,886 Training Epoch [32/40] Iter[209/312]		Loss: 0.1012
2019-10-29 00:51:10,008 Training Epoch [32/40] Iter[210/312]		Loss: 0.1013
2019-10-29 00:51:10,129 Training Epoch [32/40] Iter[211/312]		Loss: 0.1011
2019-10-29 00:51:10,250 Training Epoch [32/40] Iter[212/312]		Loss: 0.1010
2019-10-29 00:51:10,375 Training Epoch [32/40] Iter[213/312]		Loss: 0.1010
2019-10-29 00:51:10,497 Training Epoch [32/40] Iter[214/312]		Loss: 0.1008
2019-10-29 00:51:10,618 Training Epoch [32/40] Iter[215/312]		Loss: 0.1007
2019-10-29 00:51:10,739 Training Epoch [32/40] Iter[216/312]		Loss: 0.1007
2019-10-29 00:51:10,860 Training Epoch [32/40] Iter[217/312]		Loss: 0.1007
2019-10-29 00:51:10,981 Training Epoch [32/40] Iter[218/312]		Loss: 0.1006
2019-10-29 00:51:11,102 Training Epoch [32/40] Iter[219/312]		Loss: 0.1006
2019-10-29 00:51:11,224 Training Epoch [32/40] Iter[220/312]		Loss: 0.1009
2019-10-29 00:51:11,345 Training Epoch [32/40] Iter[221/312]		Loss: 0.1012
2019-10-29 00:51:11,466 Training Epoch [32/40] Iter[222/312]		Loss: 0.1013
2019-10-29 00:51:11,588 Training Epoch [32/40] Iter[223/312]		Loss: 0.1013
2019-10-29 00:51:11,709 Training Epoch [32/40] Iter[224/312]		Loss: 0.1012
2019-10-29 00:51:11,830 Training Epoch [32/40] Iter[225/312]		Loss: 0.1011
2019-10-29 00:51:11,952 Training Epoch [32/40] Iter[226/312]		Loss: 0.1012
2019-10-29 00:51:12,073 Training Epoch [32/40] Iter[227/312]		Loss: 0.1011
2019-10-29 00:51:12,195 Training Epoch [32/40] Iter[228/312]		Loss: 0.1013
2019-10-29 00:51:12,316 Training Epoch [32/40] Iter[229/312]		Loss: 0.1013
2019-10-29 00:51:12,437 Training Epoch [32/40] Iter[230/312]		Loss: 0.1011
2019-10-29 00:51:12,558 Training Epoch [32/40] Iter[231/312]		Loss: 0.1013
2019-10-29 00:51:12,680 Training Epoch [32/40] Iter[232/312]		Loss: 0.1012
2019-10-29 00:51:12,801 Training Epoch [32/40] Iter[233/312]		Loss: 0.1011
2019-10-29 00:51:12,922 Training Epoch [32/40] Iter[234/312]		Loss: 0.1012
2019-10-29 00:51:13,043 Training Epoch [32/40] Iter[235/312]		Loss: 0.1012
2019-10-29 00:51:13,164 Training Epoch [32/40] Iter[236/312]		Loss: 0.1013
2019-10-29 00:51:13,285 Training Epoch [32/40] Iter[237/312]		Loss: 0.1014
2019-10-29 00:51:13,407 Training Epoch [32/40] Iter[238/312]		Loss: 0.1016
2019-10-29 00:51:13,528 Training Epoch [32/40] Iter[239/312]		Loss: 0.1016
2019-10-29 00:51:13,650 Training Epoch [32/40] Iter[240/312]		Loss: 0.1018
2019-10-29 00:51:13,771 Training Epoch [32/40] Iter[241/312]		Loss: 0.1019
2019-10-29 00:51:13,893 Training Epoch [32/40] Iter[242/312]		Loss: 0.1020
2019-10-29 00:51:14,014 Training Epoch [32/40] Iter[243/312]		Loss: 0.1021
2019-10-29 00:51:14,141 Training Epoch [32/40] Iter[244/312]		Loss: 0.1023
2019-10-29 00:51:14,263 Training Epoch [32/40] Iter[245/312]		Loss: 0.1022
2019-10-29 00:51:14,384 Training Epoch [32/40] Iter[246/312]		Loss: 0.1021
2019-10-29 00:51:14,505 Training Epoch [32/40] Iter[247/312]		Loss: 0.1023
2019-10-29 00:51:14,627 Training Epoch [32/40] Iter[248/312]		Loss: 0.1021
2019-10-29 00:51:14,749 Training Epoch [32/40] Iter[249/312]		Loss: 0.1020
2019-10-29 00:51:14,870 Training Epoch [32/40] Iter[250/312]		Loss: 0.1019
2019-10-29 00:51:14,992 Training Epoch [32/40] Iter[251/312]		Loss: 0.1018
2019-10-29 00:51:15,113 Training Epoch [32/40] Iter[252/312]		Loss: 0.1017
2019-10-29 00:51:15,235 Training Epoch [32/40] Iter[253/312]		Loss: 0.1018
2019-10-29 00:51:15,356 Training Epoch [32/40] Iter[254/312]		Loss: 0.1018
2019-10-29 00:51:15,477 Training Epoch [32/40] Iter[255/312]		Loss: 0.1018
2019-10-29 00:51:15,599 Training Epoch [32/40] Iter[256/312]		Loss: 0.1018
2019-10-29 00:51:15,720 Training Epoch [32/40] Iter[257/312]		Loss: 0.1017
2019-10-29 00:51:15,841 Training Epoch [32/40] Iter[258/312]		Loss: 0.1017
2019-10-29 00:51:15,962 Training Epoch [32/40] Iter[259/312]		Loss: 0.1017
2019-10-29 00:51:16,084 Training Epoch [32/40] Iter[260/312]		Loss: 0.1019
2019-10-29 00:51:16,205 Training Epoch [32/40] Iter[261/312]		Loss: 0.1019
2019-10-29 00:51:16,326 Training Epoch [32/40] Iter[262/312]		Loss: 0.1020
2019-10-29 00:51:16,447 Training Epoch [32/40] Iter[263/312]		Loss: 0.1020
2019-10-29 00:51:16,569 Training Epoch [32/40] Iter[264/312]		Loss: 0.1019
2019-10-29 00:51:16,690 Training Epoch [32/40] Iter[265/312]		Loss: 0.1021
2019-10-29 00:51:16,811 Training Epoch [32/40] Iter[266/312]		Loss: 0.1021
2019-10-29 00:51:16,932 Training Epoch [32/40] Iter[267/312]		Loss: 0.1021
2019-10-29 00:51:17,054 Training Epoch [32/40] Iter[268/312]		Loss: 0.1021
2019-10-29 00:51:17,175 Training Epoch [32/40] Iter[269/312]		Loss: 0.1022
2019-10-29 00:51:17,297 Training Epoch [32/40] Iter[270/312]		Loss: 0.1022
2019-10-29 00:51:17,418 Training Epoch [32/40] Iter[271/312]		Loss: 0.1023
2019-10-29 00:51:17,540 Training Epoch [32/40] Iter[272/312]		Loss: 0.1022
2019-10-29 00:51:17,661 Training Epoch [32/40] Iter[273/312]		Loss: 0.1021
2019-10-29 00:51:17,783 Training Epoch [32/40] Iter[274/312]		Loss: 0.1021
2019-10-29 00:51:17,905 Training Epoch [32/40] Iter[275/312]		Loss: 0.1019
2019-10-29 00:51:18,026 Training Epoch [32/40] Iter[276/312]		Loss: 0.1020
2019-10-29 00:51:18,148 Training Epoch [32/40] Iter[277/312]		Loss: 0.1019
2019-10-29 00:51:18,270 Training Epoch [32/40] Iter[278/312]		Loss: 0.1020
2019-10-29 00:51:18,392 Training Epoch [32/40] Iter[279/312]		Loss: 0.1021
2019-10-29 00:51:18,513 Training Epoch [32/40] Iter[280/312]		Loss: 0.1021
2019-10-29 00:51:18,634 Training Epoch [32/40] Iter[281/312]		Loss: 0.1020
2019-10-29 00:51:18,756 Training Epoch [32/40] Iter[282/312]		Loss: 0.1020
2019-10-29 00:51:18,877 Training Epoch [32/40] Iter[283/312]		Loss: 0.1021
2019-10-29 00:51:18,998 Training Epoch [32/40] Iter[284/312]		Loss: 0.1021
2019-10-29 00:51:19,120 Training Epoch [32/40] Iter[285/312]		Loss: 0.1020
2019-10-29 00:51:19,241 Training Epoch [32/40] Iter[286/312]		Loss: 0.1021
2019-10-29 00:51:19,363 Training Epoch [32/40] Iter[287/312]		Loss: 0.1021
2019-10-29 00:51:19,484 Training Epoch [32/40] Iter[288/312]		Loss: 0.1021
2019-10-29 00:51:19,605 Training Epoch [32/40] Iter[289/312]		Loss: 0.1021
2019-10-29 00:51:19,727 Training Epoch [32/40] Iter[290/312]		Loss: 0.1021
2019-10-29 00:51:19,848 Training Epoch [32/40] Iter[291/312]		Loss: 0.1020
2019-10-29 00:51:19,969 Training Epoch [32/40] Iter[292/312]		Loss: 0.1019
2019-10-29 00:51:20,090 Training Epoch [32/40] Iter[293/312]		Loss: 0.1020
2019-10-29 00:51:20,212 Training Epoch [32/40] Iter[294/312]		Loss: 0.1018
2019-10-29 00:51:20,333 Training Epoch [32/40] Iter[295/312]		Loss: 0.1018
2019-10-29 00:51:20,455 Training Epoch [32/40] Iter[296/312]		Loss: 0.1019
2019-10-29 00:51:20,576 Training Epoch [32/40] Iter[297/312]		Loss: 0.1018
2019-10-29 00:51:20,698 Training Epoch [32/40] Iter[298/312]		Loss: 0.1019
2019-10-29 00:51:20,819 Training Epoch [32/40] Iter[299/312]		Loss: 0.1019
2019-10-29 00:51:20,940 Training Epoch [32/40] Iter[300/312]		Loss: 0.1018
2019-10-29 00:51:21,062 Training Epoch [32/40] Iter[301/312]		Loss: 0.1016
2019-10-29 00:51:21,182 Training Epoch [32/40] Iter[302/312]		Loss: 0.1017
2019-10-29 00:51:21,304 Training Epoch [32/40] Iter[303/312]		Loss: 0.1016
2019-10-29 00:51:21,425 Training Epoch [32/40] Iter[304/312]		Loss: 0.1017
2019-10-29 00:51:21,546 Training Epoch [32/40] Iter[305/312]		Loss: 0.1016
2019-10-29 00:51:21,666 Training Epoch [32/40] Iter[306/312]		Loss: 0.1015
2019-10-29 00:51:21,786 Training Epoch [32/40] Iter[307/312]		Loss: 0.1016
2019-10-29 00:51:21,907 Training Epoch [32/40] Iter[308/312]		Loss: 0.1018
2019-10-29 00:51:22,028 Training Epoch [32/40] Iter[309/312]		Loss: 0.1020
2019-10-29 00:51:22,148 Training Epoch [32/40] Iter[310/312]		Loss: 0.1019
2019-10-29 00:51:22,269 Training Epoch [32/40] Iter[311/312]		Loss: 0.1020
2019-10-29 00:51:22,330 Training Epoch [32/40] Iter[312/312]		Loss: 0.1020
2019-10-29 00:51:22,720 Testing Epoch [32/40] Iter[0/62]		Loss: 0.0907
2019-10-29 00:51:22,759 Testing Epoch [32/40] Iter[1/62]		Loss: 0.1259
2019-10-29 00:51:22,789 Testing Epoch [32/40] Iter[2/62]		Loss: 0.1162
2019-10-29 00:51:22,826 Testing Epoch [32/40] Iter[3/62]		Loss: 0.1139
2019-10-29 00:51:22,858 Testing Epoch [32/40] Iter[4/62]		Loss: 0.1091
2019-10-29 00:51:22,890 Testing Epoch [32/40] Iter[5/62]		Loss: 0.1061
2019-10-29 00:51:22,921 Testing Epoch [32/40] Iter[6/62]		Loss: 0.1073
2019-10-29 00:51:22,950 Testing Epoch [32/40] Iter[7/62]		Loss: 0.1136
2019-10-29 00:51:22,986 Testing Epoch [32/40] Iter[8/62]		Loss: 0.1199
2019-10-29 00:51:23,017 Testing Epoch [32/40] Iter[9/62]		Loss: 0.1178
2019-10-29 00:51:23,047 Testing Epoch [32/40] Iter[10/62]		Loss: 0.1160
2019-10-29 00:51:23,082 Testing Epoch [32/40] Iter[11/62]		Loss: 0.1207
2019-10-29 00:51:23,113 Testing Epoch [32/40] Iter[12/62]		Loss: 0.1211
2019-10-29 00:51:23,146 Testing Epoch [32/40] Iter[13/62]		Loss: 0.1231
2019-10-29 00:51:23,177 Testing Epoch [32/40] Iter[14/62]		Loss: 0.1353
2019-10-29 00:51:23,210 Testing Epoch [32/40] Iter[15/62]		Loss: 0.1368
2019-10-29 00:51:23,241 Testing Epoch [32/40] Iter[16/62]		Loss: 0.1349
2019-10-29 00:51:23,271 Testing Epoch [32/40] Iter[17/62]		Loss: 0.1342
2019-10-29 00:51:23,306 Testing Epoch [32/40] Iter[18/62]		Loss: 0.1311
2019-10-29 00:51:23,337 Testing Epoch [32/40] Iter[19/62]		Loss: 0.1290
2019-10-29 00:51:23,368 Testing Epoch [32/40] Iter[20/62]		Loss: 0.1307
2019-10-29 00:51:23,402 Testing Epoch [32/40] Iter[21/62]		Loss: 0.1288
2019-10-29 00:51:23,433 Testing Epoch [32/40] Iter[22/62]		Loss: 0.1284
2019-10-29 00:51:23,463 Testing Epoch [32/40] Iter[23/62]		Loss: 0.1285
2019-10-29 00:51:23,498 Testing Epoch [32/40] Iter[24/62]		Loss: 0.1304
2019-10-29 00:51:23,529 Testing Epoch [32/40] Iter[25/62]		Loss: 0.1298
2019-10-29 00:51:23,560 Testing Epoch [32/40] Iter[26/62]		Loss: 0.1287
2019-10-29 00:51:23,591 Testing Epoch [32/40] Iter[27/62]		Loss: 0.1331
2019-10-29 00:51:23,621 Testing Epoch [32/40] Iter[28/62]		Loss: 0.1348
2019-10-29 00:51:23,652 Testing Epoch [32/40] Iter[29/62]		Loss: 0.1347
2019-10-29 00:51:23,683 Testing Epoch [32/40] Iter[30/62]		Loss: 0.1364
2019-10-29 00:51:23,714 Testing Epoch [32/40] Iter[31/62]		Loss: 0.1358
2019-10-29 00:51:23,745 Testing Epoch [32/40] Iter[32/62]		Loss: 0.1374
2019-10-29 00:51:23,776 Testing Epoch [32/40] Iter[33/62]		Loss: 0.1354
2019-10-29 00:51:23,807 Testing Epoch [32/40] Iter[34/62]		Loss: 0.1369
2019-10-29 00:51:23,838 Testing Epoch [32/40] Iter[35/62]		Loss: 0.1374
2019-10-29 00:51:23,868 Testing Epoch [32/40] Iter[36/62]		Loss: 0.1355
2019-10-29 00:51:23,899 Testing Epoch [32/40] Iter[37/62]		Loss: 0.1352
2019-10-29 00:51:23,930 Testing Epoch [32/40] Iter[38/62]		Loss: 0.1354
2019-10-29 00:51:23,961 Testing Epoch [32/40] Iter[39/62]		Loss: 0.1358
2019-10-29 00:51:23,991 Testing Epoch [32/40] Iter[40/62]		Loss: 0.1362
2019-10-29 00:51:24,023 Testing Epoch [32/40] Iter[41/62]		Loss: 0.1362
2019-10-29 00:51:24,053 Testing Epoch [32/40] Iter[42/62]		Loss: 0.1349
2019-10-29 00:51:24,084 Testing Epoch [32/40] Iter[43/62]		Loss: 0.1344
2019-10-29 00:51:24,115 Testing Epoch [32/40] Iter[44/62]		Loss: 0.1332
2019-10-29 00:51:24,146 Testing Epoch [32/40] Iter[45/62]		Loss: 0.1342
2019-10-29 00:51:24,177 Testing Epoch [32/40] Iter[46/62]		Loss: 0.1345
2019-10-29 00:51:24,208 Testing Epoch [32/40] Iter[47/62]		Loss: 0.1395
2019-10-29 00:51:24,239 Testing Epoch [32/40] Iter[48/62]		Loss: 0.1385
2019-10-29 00:51:24,270 Testing Epoch [32/40] Iter[49/62]		Loss: 0.1399
2019-10-29 00:51:24,300 Testing Epoch [32/40] Iter[50/62]		Loss: 0.1395
2019-10-29 00:51:24,331 Testing Epoch [32/40] Iter[51/62]		Loss: 0.1396
2019-10-29 00:51:24,362 Testing Epoch [32/40] Iter[52/62]		Loss: 0.1386
2019-10-29 00:51:24,392 Testing Epoch [32/40] Iter[53/62]		Loss: 0.1383
2019-10-29 00:51:24,423 Testing Epoch [32/40] Iter[54/62]		Loss: 0.1377
2019-10-29 00:51:24,453 Testing Epoch [32/40] Iter[55/62]		Loss: 0.1378
2019-10-29 00:51:24,484 Testing Epoch [32/40] Iter[56/62]		Loss: 0.1376
2019-10-29 00:51:24,514 Testing Epoch [32/40] Iter[57/62]		Loss: 0.1374
2019-10-29 00:51:24,544 Testing Epoch [32/40] Iter[58/62]		Loss: 0.1370
2019-10-29 00:51:24,575 Testing Epoch [32/40] Iter[59/62]		Loss: 0.1370
2019-10-29 00:51:24,605 Testing Epoch [32/40] Iter[60/62]		Loss: 0.1363
2019-10-29 00:51:24,635 Testing Epoch [32/40] Iter[61/62]		Loss: 0.1361
2019-10-29 00:51:24,652 Testing Epoch [32/40] Iter[62/62]		Loss: 0.1369
2019-10-29 00:51:24,721 Saving the Model
2019-10-29 00:51:25,112 Training Epoch [33/40] Iter[0/312]		Loss: 0.1076
2019-10-29 00:51:25,240 Training Epoch [33/40] Iter[1/312]		Loss: 0.1024
2019-10-29 00:51:25,360 Training Epoch [33/40] Iter[2/312]		Loss: 0.1088
2019-10-29 00:51:25,482 Training Epoch [33/40] Iter[3/312]		Loss: 0.1065
2019-10-29 00:51:25,602 Training Epoch [33/40] Iter[4/312]		Loss: 0.0988
2019-10-29 00:51:25,725 Training Epoch [33/40] Iter[5/312]		Loss: 0.1034
2019-10-29 00:51:25,846 Training Epoch [33/40] Iter[6/312]		Loss: 0.1029
2019-10-29 00:51:25,967 Training Epoch [33/40] Iter[7/312]		Loss: 0.1057
2019-10-29 00:51:26,088 Training Epoch [33/40] Iter[8/312]		Loss: 0.1079
2019-10-29 00:51:26,210 Training Epoch [33/40] Iter[9/312]		Loss: 0.1075
2019-10-29 00:51:26,331 Training Epoch [33/40] Iter[10/312]		Loss: 0.1092
2019-10-29 00:51:26,453 Training Epoch [33/40] Iter[11/312]		Loss: 0.1060
2019-10-29 00:51:26,574 Training Epoch [33/40] Iter[12/312]		Loss: 0.1078
2019-10-29 00:51:26,695 Training Epoch [33/40] Iter[13/312]		Loss: 0.1067
2019-10-29 00:51:26,817 Training Epoch [33/40] Iter[14/312]		Loss: 0.1057
2019-10-29 00:51:26,938 Training Epoch [33/40] Iter[15/312]		Loss: 0.1083
2019-10-29 00:51:27,064 Training Epoch [33/40] Iter[16/312]		Loss: 0.1103
2019-10-29 00:51:27,186 Training Epoch [33/40] Iter[17/312]		Loss: 0.1113
2019-10-29 00:51:27,308 Training Epoch [33/40] Iter[18/312]		Loss: 0.1103
2019-10-29 00:51:27,429 Training Epoch [33/40] Iter[19/312]		Loss: 0.1107
2019-10-29 00:51:27,551 Training Epoch [33/40] Iter[20/312]		Loss: 0.1105
2019-10-29 00:51:27,672 Training Epoch [33/40] Iter[21/312]		Loss: 0.1084
2019-10-29 00:51:27,794 Training Epoch [33/40] Iter[22/312]		Loss: 0.1097
2019-10-29 00:51:27,917 Training Epoch [33/40] Iter[23/312]		Loss: 0.1091
2019-10-29 00:51:28,038 Training Epoch [33/40] Iter[24/312]		Loss: 0.1070
2019-10-29 00:51:28,159 Training Epoch [33/40] Iter[25/312]		Loss: 0.1062
2019-10-29 00:51:28,280 Training Epoch [33/40] Iter[26/312]		Loss: 0.1065
2019-10-29 00:51:28,402 Training Epoch [33/40] Iter[27/312]		Loss: 0.1061
2019-10-29 00:51:28,523 Training Epoch [33/40] Iter[28/312]		Loss: 0.1055
2019-10-29 00:51:28,644 Training Epoch [33/40] Iter[29/312]		Loss: 0.1050
2019-10-29 00:51:28,765 Training Epoch [33/40] Iter[30/312]		Loss: 0.1042
2019-10-29 00:51:28,887 Training Epoch [33/40] Iter[31/312]		Loss: 0.1047
2019-10-29 00:51:29,008 Training Epoch [33/40] Iter[32/312]		Loss: 0.1035
2019-10-29 00:51:29,130 Training Epoch [33/40] Iter[33/312]		Loss: 0.1030
2019-10-29 00:51:29,252 Training Epoch [33/40] Iter[34/312]		Loss: 0.1019
2019-10-29 00:51:29,373 Training Epoch [33/40] Iter[35/312]		Loss: 0.1017
2019-10-29 00:51:29,494 Training Epoch [33/40] Iter[36/312]		Loss: 0.1007
2019-10-29 00:51:29,616 Training Epoch [33/40] Iter[37/312]		Loss: 0.0997
2019-10-29 00:51:29,736 Training Epoch [33/40] Iter[38/312]		Loss: 0.0993
2019-10-29 00:51:29,857 Training Epoch [33/40] Iter[39/312]		Loss: 0.0983
2019-10-29 00:51:29,978 Training Epoch [33/40] Iter[40/312]		Loss: 0.1001
2019-10-29 00:51:30,099 Training Epoch [33/40] Iter[41/312]		Loss: 0.0994
2019-10-29 00:51:30,221 Training Epoch [33/40] Iter[42/312]		Loss: 0.0999
2019-10-29 00:51:30,342 Training Epoch [33/40] Iter[43/312]		Loss: 0.1003
2019-10-29 00:51:30,463 Training Epoch [33/40] Iter[44/312]		Loss: 0.1007
2019-10-29 00:51:30,585 Training Epoch [33/40] Iter[45/312]		Loss: 0.1006
2019-10-29 00:51:30,706 Training Epoch [33/40] Iter[46/312]		Loss: 0.1004
2019-10-29 00:51:30,828 Training Epoch [33/40] Iter[47/312]		Loss: 0.1002
2019-10-29 00:51:30,950 Training Epoch [33/40] Iter[48/312]		Loss: 0.1013
2019-10-29 00:51:31,071 Training Epoch [33/40] Iter[49/312]		Loss: 0.1013
2019-10-29 00:51:31,193 Training Epoch [33/40] Iter[50/312]		Loss: 0.1005
2019-10-29 00:51:31,314 Training Epoch [33/40] Iter[51/312]		Loss: 0.1002
2019-10-29 00:51:31,436 Training Epoch [33/40] Iter[52/312]		Loss: 0.1002
2019-10-29 00:51:31,557 Training Epoch [33/40] Iter[53/312]		Loss: 0.0998
2019-10-29 00:51:31,678 Training Epoch [33/40] Iter[54/312]		Loss: 0.1001
2019-10-29 00:51:31,800 Training Epoch [33/40] Iter[55/312]		Loss: 0.1002
2019-10-29 00:51:31,921 Training Epoch [33/40] Iter[56/312]		Loss: 0.1004
2019-10-29 00:51:32,043 Training Epoch [33/40] Iter[57/312]		Loss: 0.1006
2019-10-29 00:51:32,164 Training Epoch [33/40] Iter[58/312]		Loss: 0.1011
2019-10-29 00:51:32,286 Training Epoch [33/40] Iter[59/312]		Loss: 0.1009
2019-10-29 00:51:32,407 Training Epoch [33/40] Iter[60/312]		Loss: 0.1005
2019-10-29 00:51:32,529 Training Epoch [33/40] Iter[61/312]		Loss: 0.1003
2019-10-29 00:51:32,650 Training Epoch [33/40] Iter[62/312]		Loss: 0.1005
2019-10-29 00:51:32,771 Training Epoch [33/40] Iter[63/312]		Loss: 0.0999
2019-10-29 00:51:32,893 Training Epoch [33/40] Iter[64/312]		Loss: 0.1000
2019-10-29 00:51:33,016 Training Epoch [33/40] Iter[65/312]		Loss: 0.0999
2019-10-29 00:51:33,137 Training Epoch [33/40] Iter[66/312]		Loss: 0.0999
2019-10-29 00:51:33,259 Training Epoch [33/40] Iter[67/312]		Loss: 0.1001
2019-10-29 00:51:33,380 Training Epoch [33/40] Iter[68/312]		Loss: 0.1010
2019-10-29 00:51:33,502 Training Epoch [33/40] Iter[69/312]		Loss: 0.1029
2019-10-29 00:51:33,622 Training Epoch [33/40] Iter[70/312]		Loss: 0.1025
2019-10-29 00:51:33,743 Training Epoch [33/40] Iter[71/312]		Loss: 0.1022
2019-10-29 00:51:33,865 Training Epoch [33/40] Iter[72/312]		Loss: 0.1019
2019-10-29 00:51:33,986 Training Epoch [33/40] Iter[73/312]		Loss: 0.1015
2019-10-29 00:51:34,107 Training Epoch [33/40] Iter[74/312]		Loss: 0.1015
2019-10-29 00:51:34,228 Training Epoch [33/40] Iter[75/312]		Loss: 0.1017
2019-10-29 00:51:34,350 Training Epoch [33/40] Iter[76/312]		Loss: 0.1015
2019-10-29 00:51:34,472 Training Epoch [33/40] Iter[77/312]		Loss: 0.1022
2019-10-29 00:51:34,593 Training Epoch [33/40] Iter[78/312]		Loss: 0.1022
2019-10-29 00:51:34,715 Training Epoch [33/40] Iter[79/312]		Loss: 0.1027
2019-10-29 00:51:34,836 Training Epoch [33/40] Iter[80/312]		Loss: 0.1023
2019-10-29 00:51:34,958 Training Epoch [33/40] Iter[81/312]		Loss: 0.1020
2019-10-29 00:51:35,079 Training Epoch [33/40] Iter[82/312]		Loss: 0.1029
2019-10-29 00:51:35,200 Training Epoch [33/40] Iter[83/312]		Loss: 0.1030
2019-10-29 00:51:35,322 Training Epoch [33/40] Iter[84/312]		Loss: 0.1031
2019-10-29 00:51:35,443 Training Epoch [33/40] Iter[85/312]		Loss: 0.1028
2019-10-29 00:51:35,565 Training Epoch [33/40] Iter[86/312]		Loss: 0.1029
2019-10-29 00:51:35,687 Training Epoch [33/40] Iter[87/312]		Loss: 0.1028
2019-10-29 00:51:35,808 Training Epoch [33/40] Iter[88/312]		Loss: 0.1036
2019-10-29 00:51:35,930 Training Epoch [33/40] Iter[89/312]		Loss: 0.1036
2019-10-29 00:51:36,051 Training Epoch [33/40] Iter[90/312]		Loss: 0.1033
2019-10-29 00:51:36,177 Training Epoch [33/40] Iter[91/312]		Loss: 0.1036
2019-10-29 00:51:36,299 Training Epoch [33/40] Iter[92/312]		Loss: 0.1035
2019-10-29 00:51:36,420 Training Epoch [33/40] Iter[93/312]		Loss: 0.1033
2019-10-29 00:51:36,541 Training Epoch [33/40] Iter[94/312]		Loss: 0.1033
2019-10-29 00:51:36,662 Training Epoch [33/40] Iter[95/312]		Loss: 0.1031
2019-10-29 00:51:36,784 Training Epoch [33/40] Iter[96/312]		Loss: 0.1034
2019-10-29 00:51:36,905 Training Epoch [33/40] Iter[97/312]		Loss: 0.1030
2019-10-29 00:51:37,026 Training Epoch [33/40] Iter[98/312]		Loss: 0.1026
2019-10-29 00:51:37,148 Training Epoch [33/40] Iter[99/312]		Loss: 0.1026
2019-10-29 00:51:37,269 Training Epoch [33/40] Iter[100/312]		Loss: 0.1024
2019-10-29 00:51:37,391 Training Epoch [33/40] Iter[101/312]		Loss: 0.1021
2019-10-29 00:51:37,512 Training Epoch [33/40] Iter[102/312]		Loss: 0.1019
2019-10-29 00:51:37,633 Training Epoch [33/40] Iter[103/312]		Loss: 0.1021
2019-10-29 00:51:37,755 Training Epoch [33/40] Iter[104/312]		Loss: 0.1017
2019-10-29 00:51:37,877 Training Epoch [33/40] Iter[105/312]		Loss: 0.1021
2019-10-29 00:51:37,998 Training Epoch [33/40] Iter[106/312]		Loss: 0.1019
2019-10-29 00:51:38,119 Training Epoch [33/40] Iter[107/312]		Loss: 0.1017
2019-10-29 00:51:38,242 Training Epoch [33/40] Iter[108/312]		Loss: 0.1016
2019-10-29 00:51:38,363 Training Epoch [33/40] Iter[109/312]		Loss: 0.1016
2019-10-29 00:51:38,484 Training Epoch [33/40] Iter[110/312]		Loss: 0.1014
2019-10-29 00:51:38,605 Training Epoch [33/40] Iter[111/312]		Loss: 0.1018
2019-10-29 00:51:38,726 Training Epoch [33/40] Iter[112/312]		Loss: 0.1019
2019-10-29 00:51:38,847 Training Epoch [33/40] Iter[113/312]		Loss: 0.1017
2019-10-29 00:51:38,968 Training Epoch [33/40] Iter[114/312]		Loss: 0.1018
2019-10-29 00:51:39,089 Training Epoch [33/40] Iter[115/312]		Loss: 0.1017
2019-10-29 00:51:39,210 Training Epoch [33/40] Iter[116/312]		Loss: 0.1018
2019-10-29 00:51:39,331 Training Epoch [33/40] Iter[117/312]		Loss: 0.1015
2019-10-29 00:51:39,453 Training Epoch [33/40] Iter[118/312]		Loss: 0.1015
2019-10-29 00:51:39,574 Training Epoch [33/40] Iter[119/312]		Loss: 0.1020
2019-10-29 00:51:39,696 Training Epoch [33/40] Iter[120/312]		Loss: 0.1020
2019-10-29 00:51:39,817 Training Epoch [33/40] Iter[121/312]		Loss: 0.1021
2019-10-29 00:51:39,939 Training Epoch [33/40] Iter[122/312]		Loss: 0.1018
2019-10-29 00:51:40,060 Training Epoch [33/40] Iter[123/312]		Loss: 0.1018
2019-10-29 00:51:40,181 Training Epoch [33/40] Iter[124/312]		Loss: 0.1018
2019-10-29 00:51:40,303 Training Epoch [33/40] Iter[125/312]		Loss: 0.1017
2019-10-29 00:51:40,424 Training Epoch [33/40] Iter[126/312]		Loss: 0.1014
2019-10-29 00:51:40,546 Training Epoch [33/40] Iter[127/312]		Loss: 0.1013
2019-10-29 00:51:40,668 Training Epoch [33/40] Iter[128/312]		Loss: 0.1010
2019-10-29 00:51:40,790 Training Epoch [33/40] Iter[129/312]		Loss: 0.1012
2019-10-29 00:51:40,912 Training Epoch [33/40] Iter[130/312]		Loss: 0.1009
2019-10-29 00:51:41,033 Training Epoch [33/40] Iter[131/312]		Loss: 0.1009
2019-10-29 00:51:41,154 Training Epoch [33/40] Iter[132/312]		Loss: 0.1006
2019-10-29 00:51:41,276 Training Epoch [33/40] Iter[133/312]		Loss: 0.1008
2019-10-29 00:51:41,397 Training Epoch [33/40] Iter[134/312]		Loss: 0.1009
2019-10-29 00:51:41,518 Training Epoch [33/40] Iter[135/312]		Loss: 0.1006
2019-10-29 00:51:41,639 Training Epoch [33/40] Iter[136/312]		Loss: 0.1009
2019-10-29 00:51:41,761 Training Epoch [33/40] Iter[137/312]		Loss: 0.1007
2019-10-29 00:51:41,882 Training Epoch [33/40] Iter[138/312]		Loss: 0.1007
2019-10-29 00:51:42,003 Training Epoch [33/40] Iter[139/312]		Loss: 0.1008
2019-10-29 00:51:42,124 Training Epoch [33/40] Iter[140/312]		Loss: 0.1010
2019-10-29 00:51:42,245 Training Epoch [33/40] Iter[141/312]		Loss: 0.1014
2019-10-29 00:51:42,367 Training Epoch [33/40] Iter[142/312]		Loss: 0.1015
2019-10-29 00:51:42,488 Training Epoch [33/40] Iter[143/312]		Loss: 0.1017
2019-10-29 00:51:42,609 Training Epoch [33/40] Iter[144/312]		Loss: 0.1015
2019-10-29 00:51:42,730 Training Epoch [33/40] Iter[145/312]		Loss: 0.1014
2019-10-29 00:51:42,851 Training Epoch [33/40] Iter[146/312]		Loss: 0.1013
2019-10-29 00:51:42,973 Training Epoch [33/40] Iter[147/312]		Loss: 0.1012
2019-10-29 00:51:43,094 Training Epoch [33/40] Iter[148/312]		Loss: 0.1013
2019-10-29 00:51:43,215 Training Epoch [33/40] Iter[149/312]		Loss: 0.1011
2019-10-29 00:51:43,338 Training Epoch [33/40] Iter[150/312]		Loss: 0.1010
2019-10-29 00:51:43,459 Training Epoch [33/40] Iter[151/312]		Loss: 0.1011
2019-10-29 00:51:43,581 Training Epoch [33/40] Iter[152/312]		Loss: 0.1009
2019-10-29 00:51:43,702 Training Epoch [33/40] Iter[153/312]		Loss: 0.1009
2019-10-29 00:51:43,823 Training Epoch [33/40] Iter[154/312]		Loss: 0.1009
2019-10-29 00:51:43,944 Training Epoch [33/40] Iter[155/312]		Loss: 0.1011
2019-10-29 00:51:44,065 Training Epoch [33/40] Iter[156/312]		Loss: 0.1009
2019-10-29 00:51:44,187 Training Epoch [33/40] Iter[157/312]		Loss: 0.1009
2019-10-29 00:51:44,309 Training Epoch [33/40] Iter[158/312]		Loss: 0.1010
2019-10-29 00:51:44,431 Training Epoch [33/40] Iter[159/312]		Loss: 0.1011
2019-10-29 00:51:44,553 Training Epoch [33/40] Iter[160/312]		Loss: 0.1009
2019-10-29 00:51:44,674 Training Epoch [33/40] Iter[161/312]		Loss: 0.1010
2019-10-29 00:51:44,795 Training Epoch [33/40] Iter[162/312]		Loss: 0.1009
2019-10-29 00:51:44,917 Training Epoch [33/40] Iter[163/312]		Loss: 0.1009
2019-10-29 00:51:45,038 Training Epoch [33/40] Iter[164/312]		Loss: 0.1009
2019-10-29 00:51:45,159 Training Epoch [33/40] Iter[165/312]		Loss: 0.1011
2019-10-29 00:51:45,281 Training Epoch [33/40] Iter[166/312]		Loss: 0.1012
2019-10-29 00:51:45,402 Training Epoch [33/40] Iter[167/312]		Loss: 0.1011
2019-10-29 00:51:45,524 Training Epoch [33/40] Iter[168/312]		Loss: 0.1009
2019-10-29 00:51:45,645 Training Epoch [33/40] Iter[169/312]		Loss: 0.1007
2019-10-29 00:51:45,767 Training Epoch [33/40] Iter[170/312]		Loss: 0.1007
2019-10-29 00:51:45,888 Training Epoch [33/40] Iter[171/312]		Loss: 0.1013
2019-10-29 00:51:46,010 Training Epoch [33/40] Iter[172/312]		Loss: 0.1016
2019-10-29 00:51:46,131 Training Epoch [33/40] Iter[173/312]		Loss: 0.1013
2019-10-29 00:51:46,253 Training Epoch [33/40] Iter[174/312]		Loss: 0.1013
2019-10-29 00:51:46,374 Training Epoch [33/40] Iter[175/312]		Loss: 0.1012
2019-10-29 00:51:46,496 Training Epoch [33/40] Iter[176/312]		Loss: 0.1015
2019-10-29 00:51:46,617 Training Epoch [33/40] Iter[177/312]		Loss: 0.1015
2019-10-29 00:51:46,739 Training Epoch [33/40] Iter[178/312]		Loss: 0.1015
2019-10-29 00:51:46,860 Training Epoch [33/40] Iter[179/312]		Loss: 0.1015
2019-10-29 00:51:46,981 Training Epoch [33/40] Iter[180/312]		Loss: 0.1013
2019-10-29 00:51:47,102 Training Epoch [33/40] Iter[181/312]		Loss: 0.1012
2019-10-29 00:51:47,223 Training Epoch [33/40] Iter[182/312]		Loss: 0.1011
2019-10-29 00:51:47,344 Training Epoch [33/40] Iter[183/312]		Loss: 0.1013
2019-10-29 00:51:47,465 Training Epoch [33/40] Iter[184/312]		Loss: 0.1012
2019-10-29 00:51:47,586 Training Epoch [33/40] Iter[185/312]		Loss: 0.1012
2019-10-29 00:51:47,707 Training Epoch [33/40] Iter[186/312]		Loss: 0.1013
2019-10-29 00:51:47,828 Training Epoch [33/40] Iter[187/312]		Loss: 0.1013
2019-10-29 00:51:47,950 Training Epoch [33/40] Iter[188/312]		Loss: 0.1014
2019-10-29 00:51:48,072 Training Epoch [33/40] Iter[189/312]		Loss: 0.1016
2019-10-29 00:51:48,193 Training Epoch [33/40] Iter[190/312]		Loss: 0.1018
2019-10-29 00:51:48,315 Training Epoch [33/40] Iter[191/312]		Loss: 0.1015
2019-10-29 00:51:48,436 Training Epoch [33/40] Iter[192/312]		Loss: 0.1018
2019-10-29 00:51:48,557 Training Epoch [33/40] Iter[193/312]		Loss: 0.1019
2019-10-29 00:51:48,678 Training Epoch [33/40] Iter[194/312]		Loss: 0.1020
2019-10-29 00:51:48,799 Training Epoch [33/40] Iter[195/312]		Loss: 0.1020
2019-10-29 00:51:48,921 Training Epoch [33/40] Iter[196/312]		Loss: 0.1019
2019-10-29 00:51:49,042 Training Epoch [33/40] Iter[197/312]		Loss: 0.1017
2019-10-29 00:51:49,164 Training Epoch [33/40] Iter[198/312]		Loss: 0.1017
2019-10-29 00:51:49,286 Training Epoch [33/40] Iter[199/312]		Loss: 0.1015
2019-10-29 00:51:49,408 Training Epoch [33/40] Iter[200/312]		Loss: 0.1014
2019-10-29 00:51:49,529 Training Epoch [33/40] Iter[201/312]		Loss: 0.1014
2019-10-29 00:51:49,651 Training Epoch [33/40] Iter[202/312]		Loss: 0.1015
2019-10-29 00:51:49,772 Training Epoch [33/40] Iter[203/312]		Loss: 0.1016
2019-10-29 00:51:49,893 Training Epoch [33/40] Iter[204/312]		Loss: 0.1019
2019-10-29 00:51:50,014 Training Epoch [33/40] Iter[205/312]		Loss: 0.1019
2019-10-29 00:51:50,136 Training Epoch [33/40] Iter[206/312]		Loss: 0.1017
2019-10-29 00:51:50,257 Training Epoch [33/40] Iter[207/312]		Loss: 0.1017
2019-10-29 00:51:50,378 Training Epoch [33/40] Iter[208/312]		Loss: 0.1018
2019-10-29 00:51:50,500 Training Epoch [33/40] Iter[209/312]		Loss: 0.1019
2019-10-29 00:51:50,621 Training Epoch [33/40] Iter[210/312]		Loss: 0.1019
2019-10-29 00:51:50,742 Training Epoch [33/40] Iter[211/312]		Loss: 0.1019
2019-10-29 00:51:50,864 Training Epoch [33/40] Iter[212/312]		Loss: 0.1018
2019-10-29 00:51:50,985 Training Epoch [33/40] Iter[213/312]		Loss: 0.1020
2019-10-29 00:51:51,107 Training Epoch [33/40] Iter[214/312]		Loss: 0.1019
2019-10-29 00:51:51,228 Training Epoch [33/40] Iter[215/312]		Loss: 0.1018
2019-10-29 00:51:51,350 Training Epoch [33/40] Iter[216/312]		Loss: 0.1018
2019-10-29 00:51:51,472 Training Epoch [33/40] Iter[217/312]		Loss: 0.1018
2019-10-29 00:51:51,593 Training Epoch [33/40] Iter[218/312]		Loss: 0.1019
2019-10-29 00:51:51,715 Training Epoch [33/40] Iter[219/312]		Loss: 0.1018
2019-10-29 00:51:51,836 Training Epoch [33/40] Iter[220/312]		Loss: 0.1021
2019-10-29 00:51:51,957 Training Epoch [33/40] Iter[221/312]		Loss: 0.1020
2019-10-29 00:51:52,079 Training Epoch [33/40] Iter[222/312]		Loss: 0.1018
2019-10-29 00:51:52,200 Training Epoch [33/40] Iter[223/312]		Loss: 0.1018
2019-10-29 00:51:52,321 Training Epoch [33/40] Iter[224/312]		Loss: 0.1020
2019-10-29 00:51:52,443 Training Epoch [33/40] Iter[225/312]		Loss: 0.1019
2019-10-29 00:51:52,565 Training Epoch [33/40] Iter[226/312]		Loss: 0.1019
2019-10-29 00:51:52,687 Training Epoch [33/40] Iter[227/312]		Loss: 0.1018
2019-10-29 00:51:52,808 Training Epoch [33/40] Iter[228/312]		Loss: 0.1018
2019-10-29 00:51:52,930 Training Epoch [33/40] Iter[229/312]		Loss: 0.1017
2019-10-29 00:51:53,051 Training Epoch [33/40] Iter[230/312]		Loss: 0.1016
2019-10-29 00:51:53,172 Training Epoch [33/40] Iter[231/312]		Loss: 0.1017
2019-10-29 00:51:53,294 Training Epoch [33/40] Iter[232/312]		Loss: 0.1018
2019-10-29 00:51:53,415 Training Epoch [33/40] Iter[233/312]		Loss: 0.1018
2019-10-29 00:51:53,537 Training Epoch [33/40] Iter[234/312]		Loss: 0.1019
2019-10-29 00:51:53,660 Training Epoch [33/40] Iter[235/312]		Loss: 0.1017
2019-10-29 00:51:53,781 Training Epoch [33/40] Iter[236/312]		Loss: 0.1018
2019-10-29 00:51:53,902 Training Epoch [33/40] Iter[237/312]		Loss: 0.1019
2019-10-29 00:51:54,024 Training Epoch [33/40] Iter[238/312]		Loss: 0.1019
2019-10-29 00:51:54,145 Training Epoch [33/40] Iter[239/312]		Loss: 0.1019
2019-10-29 00:51:54,267 Training Epoch [33/40] Iter[240/312]		Loss: 0.1018
2019-10-29 00:51:54,388 Training Epoch [33/40] Iter[241/312]		Loss: 0.1018
2019-10-29 00:51:54,510 Training Epoch [33/40] Iter[242/312]		Loss: 0.1021
2019-10-29 00:51:54,631 Training Epoch [33/40] Iter[243/312]		Loss: 0.1021
2019-10-29 00:51:54,752 Training Epoch [33/40] Iter[244/312]		Loss: 0.1020
2019-10-29 00:51:54,874 Training Epoch [33/40] Iter[245/312]		Loss: 0.1020
2019-10-29 00:51:54,996 Training Epoch [33/40] Iter[246/312]		Loss: 0.1020
2019-10-29 00:51:55,117 Training Epoch [33/40] Iter[247/312]		Loss: 0.1019
2019-10-29 00:51:55,239 Training Epoch [33/40] Iter[248/312]		Loss: 0.1020
2019-10-29 00:51:55,360 Training Epoch [33/40] Iter[249/312]		Loss: 0.1019
2019-10-29 00:51:55,481 Training Epoch [33/40] Iter[250/312]		Loss: 0.1019
2019-10-29 00:51:55,602 Training Epoch [33/40] Iter[251/312]		Loss: 0.1018
2019-10-29 00:51:55,723 Training Epoch [33/40] Iter[252/312]		Loss: 0.1018
2019-10-29 00:51:55,845 Training Epoch [33/40] Iter[253/312]		Loss: 0.1018
2019-10-29 00:51:55,966 Training Epoch [33/40] Iter[254/312]		Loss: 0.1017
2019-10-29 00:51:56,087 Training Epoch [33/40] Iter[255/312]		Loss: 0.1017
2019-10-29 00:51:56,208 Training Epoch [33/40] Iter[256/312]		Loss: 0.1017
2019-10-29 00:51:56,330 Training Epoch [33/40] Iter[257/312]		Loss: 0.1018
2019-10-29 00:51:56,452 Training Epoch [33/40] Iter[258/312]		Loss: 0.1017
2019-10-29 00:51:56,573 Training Epoch [33/40] Iter[259/312]		Loss: 0.1015
2019-10-29 00:51:56,695 Training Epoch [33/40] Iter[260/312]		Loss: 0.1015
2019-10-29 00:51:56,816 Training Epoch [33/40] Iter[261/312]		Loss: 0.1017
2019-10-29 00:51:56,938 Training Epoch [33/40] Iter[262/312]		Loss: 0.1016
2019-10-29 00:51:57,059 Training Epoch [33/40] Iter[263/312]		Loss: 0.1017
2019-10-29 00:51:57,180 Training Epoch [33/40] Iter[264/312]		Loss: 0.1020
2019-10-29 00:51:57,302 Training Epoch [33/40] Iter[265/312]		Loss: 0.1018
2019-10-29 00:51:57,423 Training Epoch [33/40] Iter[266/312]		Loss: 0.1017
2019-10-29 00:51:57,546 Training Epoch [33/40] Iter[267/312]		Loss: 0.1016
2019-10-29 00:51:57,667 Training Epoch [33/40] Iter[268/312]		Loss: 0.1015
2019-10-29 00:51:57,789 Training Epoch [33/40] Iter[269/312]		Loss: 0.1014
2019-10-29 00:51:57,910 Training Epoch [33/40] Iter[270/312]		Loss: 0.1012
2019-10-29 00:51:58,032 Training Epoch [33/40] Iter[271/312]		Loss: 0.1011
2019-10-29 00:51:58,154 Training Epoch [33/40] Iter[272/312]		Loss: 0.1011
2019-10-29 00:51:58,275 Training Epoch [33/40] Iter[273/312]		Loss: 0.1013
2019-10-29 00:51:58,397 Training Epoch [33/40] Iter[274/312]		Loss: 0.1013
2019-10-29 00:51:58,518 Training Epoch [33/40] Iter[275/312]		Loss: 0.1012
2019-10-29 00:51:58,639 Training Epoch [33/40] Iter[276/312]		Loss: 0.1011
2019-10-29 00:51:58,762 Training Epoch [33/40] Iter[277/312]		Loss: 0.1010
2019-10-29 00:51:58,883 Training Epoch [33/40] Iter[278/312]		Loss: 0.1010
2019-10-29 00:51:59,004 Training Epoch [33/40] Iter[279/312]		Loss: 0.1012
2019-10-29 00:51:59,126 Training Epoch [33/40] Iter[280/312]		Loss: 0.1012
2019-10-29 00:51:59,247 Training Epoch [33/40] Iter[281/312]		Loss: 0.1014
2019-10-29 00:51:59,368 Training Epoch [33/40] Iter[282/312]		Loss: 0.1012
2019-10-29 00:51:59,490 Training Epoch [33/40] Iter[283/312]		Loss: 0.1012
2019-10-29 00:51:59,611 Training Epoch [33/40] Iter[284/312]		Loss: 0.1013
2019-10-29 00:51:59,733 Training Epoch [33/40] Iter[285/312]		Loss: 0.1014
2019-10-29 00:51:59,854 Training Epoch [33/40] Iter[286/312]		Loss: 0.1014
2019-10-29 00:51:59,976 Training Epoch [33/40] Iter[287/312]		Loss: 0.1015
2019-10-29 00:52:00,097 Training Epoch [33/40] Iter[288/312]		Loss: 0.1014
2019-10-29 00:52:00,218 Training Epoch [33/40] Iter[289/312]		Loss: 0.1014
2019-10-29 00:52:00,339 Training Epoch [33/40] Iter[290/312]		Loss: 0.1016
2019-10-29 00:52:00,461 Training Epoch [33/40] Iter[291/312]		Loss: 0.1015
2019-10-29 00:52:00,583 Training Epoch [33/40] Iter[292/312]		Loss: 0.1014
2019-10-29 00:52:00,705 Training Epoch [33/40] Iter[293/312]		Loss: 0.1013
2019-10-29 00:52:00,826 Training Epoch [33/40] Iter[294/312]		Loss: 0.1013
2019-10-29 00:52:00,948 Training Epoch [33/40] Iter[295/312]		Loss: 0.1013
2019-10-29 00:52:01,070 Training Epoch [33/40] Iter[296/312]		Loss: 0.1012
2019-10-29 00:52:01,192 Training Epoch [33/40] Iter[297/312]		Loss: 0.1012
2019-10-29 00:52:01,314 Training Epoch [33/40] Iter[298/312]		Loss: 0.1012
2019-10-29 00:52:01,435 Training Epoch [33/40] Iter[299/312]		Loss: 0.1012
2019-10-29 00:52:01,557 Training Epoch [33/40] Iter[300/312]		Loss: 0.1012
2019-10-29 00:52:01,678 Training Epoch [33/40] Iter[301/312]		Loss: 0.1013
2019-10-29 00:52:01,800 Training Epoch [33/40] Iter[302/312]		Loss: 0.1013
2019-10-29 00:52:01,921 Training Epoch [33/40] Iter[303/312]		Loss: 0.1012
2019-10-29 00:52:02,043 Training Epoch [33/40] Iter[304/312]		Loss: 0.1012
2019-10-29 00:52:02,163 Training Epoch [33/40] Iter[305/312]		Loss: 0.1013
2019-10-29 00:52:02,284 Training Epoch [33/40] Iter[306/312]		Loss: 0.1013
2019-10-29 00:52:02,405 Training Epoch [33/40] Iter[307/312]		Loss: 0.1014
2019-10-29 00:52:02,526 Training Epoch [33/40] Iter[308/312]		Loss: 0.1013
2019-10-29 00:52:02,647 Training Epoch [33/40] Iter[309/312]		Loss: 0.1014
2019-10-29 00:52:02,768 Training Epoch [33/40] Iter[310/312]		Loss: 0.1015
2019-10-29 00:52:02,888 Training Epoch [33/40] Iter[311/312]		Loss: 0.1015
2019-10-29 00:52:02,949 Training Epoch [33/40] Iter[312/312]		Loss: 0.1014
2019-10-29 00:52:03,237 Testing Epoch [33/40] Iter[0/62]		Loss: 0.0910
2019-10-29 00:52:03,386 Testing Epoch [33/40] Iter[1/62]		Loss: 0.1239
2019-10-29 00:52:03,422 Testing Epoch [33/40] Iter[2/62]		Loss: 0.1165
2019-10-29 00:52:03,452 Testing Epoch [33/40] Iter[3/62]		Loss: 0.1142
2019-10-29 00:52:03,482 Testing Epoch [33/40] Iter[4/62]		Loss: 0.1101
2019-10-29 00:52:03,518 Testing Epoch [33/40] Iter[5/62]		Loss: 0.1077
2019-10-29 00:52:03,548 Testing Epoch [33/40] Iter[6/62]		Loss: 0.1086
2019-10-29 00:52:03,577 Testing Epoch [33/40] Iter[7/62]		Loss: 0.1152
2019-10-29 00:52:03,610 Testing Epoch [33/40] Iter[8/62]		Loss: 0.1217
2019-10-29 00:52:03,641 Testing Epoch [33/40] Iter[9/62]		Loss: 0.1188
2019-10-29 00:52:03,674 Testing Epoch [33/40] Iter[10/62]		Loss: 0.1169
2019-10-29 00:52:03,706 Testing Epoch [33/40] Iter[11/62]		Loss: 0.1215
2019-10-29 00:52:03,737 Testing Epoch [33/40] Iter[12/62]		Loss: 0.1222
2019-10-29 00:52:03,768 Testing Epoch [33/40] Iter[13/62]		Loss: 0.1241
2019-10-29 00:52:03,802 Testing Epoch [33/40] Iter[14/62]		Loss: 0.1367
2019-10-29 00:52:03,832 Testing Epoch [33/40] Iter[15/62]		Loss: 0.1383
2019-10-29 00:52:03,869 Testing Epoch [33/40] Iter[16/62]		Loss: 0.1362
2019-10-29 00:52:03,906 Testing Epoch [33/40] Iter[17/62]		Loss: 0.1354
2019-10-29 00:52:03,942 Testing Epoch [33/40] Iter[18/62]		Loss: 0.1320
2019-10-29 00:52:03,972 Testing Epoch [33/40] Iter[19/62]		Loss: 0.1300
2019-10-29 00:52:04,003 Testing Epoch [33/40] Iter[20/62]		Loss: 0.1314
2019-10-29 00:52:04,034 Testing Epoch [33/40] Iter[21/62]		Loss: 0.1296
2019-10-29 00:52:04,065 Testing Epoch [33/40] Iter[22/62]		Loss: 0.1289
2019-10-29 00:52:04,095 Testing Epoch [33/40] Iter[23/62]		Loss: 0.1288
2019-10-29 00:52:04,126 Testing Epoch [33/40] Iter[24/62]		Loss: 0.1306
2019-10-29 00:52:04,157 Testing Epoch [33/40] Iter[25/62]		Loss: 0.1298
2019-10-29 00:52:04,187 Testing Epoch [33/40] Iter[26/62]		Loss: 0.1287
2019-10-29 00:52:04,218 Testing Epoch [33/40] Iter[27/62]		Loss: 0.1332
2019-10-29 00:52:04,249 Testing Epoch [33/40] Iter[28/62]		Loss: 0.1351
2019-10-29 00:52:04,280 Testing Epoch [33/40] Iter[29/62]		Loss: 0.1349
2019-10-29 00:52:04,311 Testing Epoch [33/40] Iter[30/62]		Loss: 0.1366
2019-10-29 00:52:04,341 Testing Epoch [33/40] Iter[31/62]		Loss: 0.1358
2019-10-29 00:52:04,372 Testing Epoch [33/40] Iter[32/62]		Loss: 0.1373
2019-10-29 00:52:04,403 Testing Epoch [33/40] Iter[33/62]		Loss: 0.1356
2019-10-29 00:52:04,434 Testing Epoch [33/40] Iter[34/62]		Loss: 0.1372
2019-10-29 00:52:04,465 Testing Epoch [33/40] Iter[35/62]		Loss: 0.1376
2019-10-29 00:52:04,495 Testing Epoch [33/40] Iter[36/62]		Loss: 0.1358
2019-10-29 00:52:04,526 Testing Epoch [33/40] Iter[37/62]		Loss: 0.1356
2019-10-29 00:52:04,557 Testing Epoch [33/40] Iter[38/62]		Loss: 0.1357
2019-10-29 00:52:04,587 Testing Epoch [33/40] Iter[39/62]		Loss: 0.1360
2019-10-29 00:52:04,618 Testing Epoch [33/40] Iter[40/62]		Loss: 0.1363
2019-10-29 00:52:04,649 Testing Epoch [33/40] Iter[41/62]		Loss: 0.1365
2019-10-29 00:52:04,679 Testing Epoch [33/40] Iter[42/62]		Loss: 0.1351
2019-10-29 00:52:04,710 Testing Epoch [33/40] Iter[43/62]		Loss: 0.1347
2019-10-29 00:52:04,741 Testing Epoch [33/40] Iter[44/62]		Loss: 0.1334
2019-10-29 00:52:04,771 Testing Epoch [33/40] Iter[45/62]		Loss: 0.1344
2019-10-29 00:52:04,802 Testing Epoch [33/40] Iter[46/62]		Loss: 0.1346
2019-10-29 00:52:04,833 Testing Epoch [33/40] Iter[47/62]		Loss: 0.1396
2019-10-29 00:52:04,863 Testing Epoch [33/40] Iter[48/62]		Loss: 0.1385
2019-10-29 00:52:04,894 Testing Epoch [33/40] Iter[49/62]		Loss: 0.1400
2019-10-29 00:52:04,925 Testing Epoch [33/40] Iter[50/62]		Loss: 0.1396
2019-10-29 00:52:04,956 Testing Epoch [33/40] Iter[51/62]		Loss: 0.1397
2019-10-29 00:52:04,987 Testing Epoch [33/40] Iter[52/62]		Loss: 0.1386
2019-10-29 00:52:05,018 Testing Epoch [33/40] Iter[53/62]		Loss: 0.1385
2019-10-29 00:52:05,049 Testing Epoch [33/40] Iter[54/62]		Loss: 0.1379
2019-10-29 00:52:05,080 Testing Epoch [33/40] Iter[55/62]		Loss: 0.1381
2019-10-29 00:52:05,110 Testing Epoch [33/40] Iter[56/62]		Loss: 0.1379
2019-10-29 00:52:05,140 Testing Epoch [33/40] Iter[57/62]		Loss: 0.1377
2019-10-29 00:52:05,171 Testing Epoch [33/40] Iter[58/62]		Loss: 0.1372
2019-10-29 00:52:05,201 Testing Epoch [33/40] Iter[59/62]		Loss: 0.1373
2019-10-29 00:52:05,231 Testing Epoch [33/40] Iter[60/62]		Loss: 0.1367
2019-10-29 00:52:05,262 Testing Epoch [33/40] Iter[61/62]		Loss: 0.1364
2019-10-29 00:52:05,279 Testing Epoch [33/40] Iter[62/62]		Loss: 0.1372
2019-10-29 00:52:05,749 Training Epoch [34/40] Iter[0/312]		Loss: 0.1241
2019-10-29 00:52:05,872 Training Epoch [34/40] Iter[1/312]		Loss: 0.1031
2019-10-29 00:52:05,996 Training Epoch [34/40] Iter[2/312]		Loss: 0.1070
2019-10-29 00:52:06,120 Training Epoch [34/40] Iter[3/312]		Loss: 0.1015
2019-10-29 00:52:06,241 Training Epoch [34/40] Iter[4/312]		Loss: 0.0980
2019-10-29 00:52:06,362 Training Epoch [34/40] Iter[5/312]		Loss: 0.0978
2019-10-29 00:52:06,486 Training Epoch [34/40] Iter[6/312]		Loss: 0.0956
2019-10-29 00:52:06,606 Training Epoch [34/40] Iter[7/312]		Loss: 0.0931
2019-10-29 00:52:06,727 Training Epoch [34/40] Iter[8/312]		Loss: 0.0908
2019-10-29 00:52:06,848 Training Epoch [34/40] Iter[9/312]		Loss: 0.0888
2019-10-29 00:52:06,969 Training Epoch [34/40] Iter[10/312]		Loss: 0.0886
2019-10-29 00:52:07,091 Training Epoch [34/40] Iter[11/312]		Loss: 0.0886
2019-10-29 00:52:07,213 Training Epoch [34/40] Iter[12/312]		Loss: 0.0865
2019-10-29 00:52:07,334 Training Epoch [34/40] Iter[13/312]		Loss: 0.0856
2019-10-29 00:52:07,455 Training Epoch [34/40] Iter[14/312]		Loss: 0.0876
2019-10-29 00:52:07,576 Training Epoch [34/40] Iter[15/312]		Loss: 0.0873
2019-10-29 00:52:07,698 Training Epoch [34/40] Iter[16/312]		Loss: 0.0873
2019-10-29 00:52:07,819 Training Epoch [34/40] Iter[17/312]		Loss: 0.0890
2019-10-29 00:52:07,940 Training Epoch [34/40] Iter[18/312]		Loss: 0.0913
2019-10-29 00:52:08,061 Training Epoch [34/40] Iter[19/312]		Loss: 0.0911
2019-10-29 00:52:08,182 Training Epoch [34/40] Iter[20/312]		Loss: 0.0931
2019-10-29 00:52:08,303 Training Epoch [34/40] Iter[21/312]		Loss: 0.0931
2019-10-29 00:52:08,425 Training Epoch [34/40] Iter[22/312]		Loss: 0.0926
2019-10-29 00:52:08,547 Training Epoch [34/40] Iter[23/312]		Loss: 0.0913
2019-10-29 00:52:08,668 Training Epoch [34/40] Iter[24/312]		Loss: 0.0930
2019-10-29 00:52:08,790 Training Epoch [34/40] Iter[25/312]		Loss: 0.0922
2019-10-29 00:52:08,911 Training Epoch [34/40] Iter[26/312]		Loss: 0.0916
2019-10-29 00:52:09,032 Training Epoch [34/40] Iter[27/312]		Loss: 0.0911
2019-10-29 00:52:09,154 Training Epoch [34/40] Iter[28/312]		Loss: 0.0916
2019-10-29 00:52:09,275 Training Epoch [34/40] Iter[29/312]		Loss: 0.0905
2019-10-29 00:52:09,397 Training Epoch [34/40] Iter[30/312]		Loss: 0.0922
2019-10-29 00:52:09,518 Training Epoch [34/40] Iter[31/312]		Loss: 0.0919
2019-10-29 00:52:09,639 Training Epoch [34/40] Iter[32/312]		Loss: 0.0922
2019-10-29 00:52:09,761 Training Epoch [34/40] Iter[33/312]		Loss: 0.0915
2019-10-29 00:52:09,883 Training Epoch [34/40] Iter[34/312]		Loss: 0.0912
2019-10-29 00:52:10,004 Training Epoch [34/40] Iter[35/312]		Loss: 0.0911
2019-10-29 00:52:10,126 Training Epoch [34/40] Iter[36/312]		Loss: 0.0917
2019-10-29 00:52:10,247 Training Epoch [34/40] Iter[37/312]		Loss: 0.0922
2019-10-29 00:52:10,372 Training Epoch [34/40] Iter[38/312]		Loss: 0.0927
2019-10-29 00:52:10,494 Training Epoch [34/40] Iter[39/312]		Loss: 0.0921
2019-10-29 00:52:10,620 Training Epoch [34/40] Iter[40/312]		Loss: 0.0916
2019-10-29 00:52:10,741 Training Epoch [34/40] Iter[41/312]		Loss: 0.0917
2019-10-29 00:52:10,862 Training Epoch [34/40] Iter[42/312]		Loss: 0.0912
2019-10-29 00:52:10,983 Training Epoch [34/40] Iter[43/312]		Loss: 0.0914
2019-10-29 00:52:11,105 Training Epoch [34/40] Iter[44/312]		Loss: 0.0913
2019-10-29 00:52:11,226 Training Epoch [34/40] Iter[45/312]		Loss: 0.0914
2019-10-29 00:52:11,348 Training Epoch [34/40] Iter[46/312]		Loss: 0.0909
2019-10-29 00:52:11,470 Training Epoch [34/40] Iter[47/312]		Loss: 0.0918
2019-10-29 00:52:11,591 Training Epoch [34/40] Iter[48/312]		Loss: 0.0922
2019-10-29 00:52:11,712 Training Epoch [34/40] Iter[49/312]		Loss: 0.0916
2019-10-29 00:52:11,834 Training Epoch [34/40] Iter[50/312]		Loss: 0.0915
2019-10-29 00:52:11,955 Training Epoch [34/40] Iter[51/312]		Loss: 0.0911
2019-10-29 00:52:12,077 Training Epoch [34/40] Iter[52/312]		Loss: 0.0905
2019-10-29 00:52:12,198 Training Epoch [34/40] Iter[53/312]		Loss: 0.0911
2019-10-29 00:52:12,319 Training Epoch [34/40] Iter[54/312]		Loss: 0.0916
2019-10-29 00:52:12,440 Training Epoch [34/40] Iter[55/312]		Loss: 0.0918
2019-10-29 00:52:12,561 Training Epoch [34/40] Iter[56/312]		Loss: 0.0920
2019-10-29 00:52:12,682 Training Epoch [34/40] Iter[57/312]		Loss: 0.0923
2019-10-29 00:52:12,803 Training Epoch [34/40] Iter[58/312]		Loss: 0.0924
2019-10-29 00:52:12,925 Training Epoch [34/40] Iter[59/312]		Loss: 0.0932
2019-10-29 00:52:13,046 Training Epoch [34/40] Iter[60/312]		Loss: 0.0931
2019-10-29 00:52:13,168 Training Epoch [34/40] Iter[61/312]		Loss: 0.0934
2019-10-29 00:52:13,290 Training Epoch [34/40] Iter[62/312]		Loss: 0.0941
2019-10-29 00:52:13,411 Training Epoch [34/40] Iter[63/312]		Loss: 0.0947
2019-10-29 00:52:13,533 Training Epoch [34/40] Iter[64/312]		Loss: 0.0950
2019-10-29 00:52:13,655 Training Epoch [34/40] Iter[65/312]		Loss: 0.0952
2019-10-29 00:52:13,776 Training Epoch [34/40] Iter[66/312]		Loss: 0.0955
2019-10-29 00:52:13,898 Training Epoch [34/40] Iter[67/312]		Loss: 0.0961
2019-10-29 00:52:14,019 Training Epoch [34/40] Iter[68/312]		Loss: 0.0961
2019-10-29 00:52:14,141 Training Epoch [34/40] Iter[69/312]		Loss: 0.0961
2019-10-29 00:52:14,262 Training Epoch [34/40] Iter[70/312]		Loss: 0.0961
2019-10-29 00:52:14,384 Training Epoch [34/40] Iter[71/312]		Loss: 0.0964
2019-10-29 00:52:14,506 Training Epoch [34/40] Iter[72/312]		Loss: 0.0969
2019-10-29 00:52:14,627 Training Epoch [34/40] Iter[73/312]		Loss: 0.0970
2019-10-29 00:52:14,749 Training Epoch [34/40] Iter[74/312]		Loss: 0.0972
2019-10-29 00:52:14,871 Training Epoch [34/40] Iter[75/312]		Loss: 0.0970
2019-10-29 00:52:14,993 Training Epoch [34/40] Iter[76/312]		Loss: 0.0967
2019-10-29 00:52:15,115 Training Epoch [34/40] Iter[77/312]		Loss: 0.0968
2019-10-29 00:52:15,237 Training Epoch [34/40] Iter[78/312]		Loss: 0.0967
2019-10-29 00:52:15,359 Training Epoch [34/40] Iter[79/312]		Loss: 0.0967
2019-10-29 00:52:15,480 Training Epoch [34/40] Iter[80/312]		Loss: 0.0973
2019-10-29 00:52:15,602 Training Epoch [34/40] Iter[81/312]		Loss: 0.0971
2019-10-29 00:52:15,723 Training Epoch [34/40] Iter[82/312]		Loss: 0.0967
2019-10-29 00:52:15,845 Training Epoch [34/40] Iter[83/312]		Loss: 0.0971
2019-10-29 00:52:15,966 Training Epoch [34/40] Iter[84/312]		Loss: 0.0969
2019-10-29 00:52:16,092 Training Epoch [34/40] Iter[85/312]		Loss: 0.0969
2019-10-29 00:52:16,213 Training Epoch [34/40] Iter[86/312]		Loss: 0.0970
2019-10-29 00:52:16,335 Training Epoch [34/40] Iter[87/312]		Loss: 0.0971
2019-10-29 00:52:16,456 Training Epoch [34/40] Iter[88/312]		Loss: 0.0973
2019-10-29 00:52:16,578 Training Epoch [34/40] Iter[89/312]		Loss: 0.0977
2019-10-29 00:52:16,699 Training Epoch [34/40] Iter[90/312]		Loss: 0.0977
2019-10-29 00:52:16,821 Training Epoch [34/40] Iter[91/312]		Loss: 0.0977
2019-10-29 00:52:16,943 Training Epoch [34/40] Iter[92/312]		Loss: 0.0975
2019-10-29 00:52:17,064 Training Epoch [34/40] Iter[93/312]		Loss: 0.0976
2019-10-29 00:52:17,187 Training Epoch [34/40] Iter[94/312]		Loss: 0.0977
2019-10-29 00:52:17,308 Training Epoch [34/40] Iter[95/312]		Loss: 0.0977
2019-10-29 00:52:17,430 Training Epoch [34/40] Iter[96/312]		Loss: 0.0974
2019-10-29 00:52:17,552 Training Epoch [34/40] Iter[97/312]		Loss: 0.0972
2019-10-29 00:52:17,673 Training Epoch [34/40] Iter[98/312]		Loss: 0.0974
2019-10-29 00:52:17,795 Training Epoch [34/40] Iter[99/312]		Loss: 0.0973
2019-10-29 00:52:17,917 Training Epoch [34/40] Iter[100/312]		Loss: 0.0975
2019-10-29 00:52:18,039 Training Epoch [34/40] Iter[101/312]		Loss: 0.0975
2019-10-29 00:52:18,160 Training Epoch [34/40] Iter[102/312]		Loss: 0.0974
2019-10-29 00:52:18,282 Training Epoch [34/40] Iter[103/312]		Loss: 0.0974
2019-10-29 00:52:18,404 Training Epoch [34/40] Iter[104/312]		Loss: 0.0977
2019-10-29 00:52:18,525 Training Epoch [34/40] Iter[105/312]		Loss: 0.0975
2019-10-29 00:52:18,647 Training Epoch [34/40] Iter[106/312]		Loss: 0.0975
2019-10-29 00:52:18,768 Training Epoch [34/40] Iter[107/312]		Loss: 0.0975
2019-10-29 00:52:18,889 Training Epoch [34/40] Iter[108/312]		Loss: 0.0979
2019-10-29 00:52:19,011 Training Epoch [34/40] Iter[109/312]		Loss: 0.0977
2019-10-29 00:52:19,132 Training Epoch [34/40] Iter[110/312]		Loss: 0.0976
2019-10-29 00:52:19,254 Training Epoch [34/40] Iter[111/312]		Loss: 0.0981
2019-10-29 00:52:19,375 Training Epoch [34/40] Iter[112/312]		Loss: 0.0986
2019-10-29 00:52:19,497 Training Epoch [34/40] Iter[113/312]		Loss: 0.0983
2019-10-29 00:52:19,618 Training Epoch [34/40] Iter[114/312]		Loss: 0.0986
2019-10-29 00:52:19,739 Training Epoch [34/40] Iter[115/312]		Loss: 0.0989
2019-10-29 00:52:19,861 Training Epoch [34/40] Iter[116/312]		Loss: 0.0986
2019-10-29 00:52:19,982 Training Epoch [34/40] Iter[117/312]		Loss: 0.0986
2019-10-29 00:52:20,103 Training Epoch [34/40] Iter[118/312]		Loss: 0.0986
2019-10-29 00:52:20,224 Training Epoch [34/40] Iter[119/312]		Loss: 0.0991
2019-10-29 00:52:20,345 Training Epoch [34/40] Iter[120/312]		Loss: 0.0992
2019-10-29 00:52:20,467 Training Epoch [34/40] Iter[121/312]		Loss: 0.0992
2019-10-29 00:52:20,588 Training Epoch [34/40] Iter[122/312]		Loss: 0.0991
2019-10-29 00:52:20,710 Training Epoch [34/40] Iter[123/312]		Loss: 0.0992
2019-10-29 00:52:20,831 Training Epoch [34/40] Iter[124/312]		Loss: 0.0995
2019-10-29 00:52:20,953 Training Epoch [34/40] Iter[125/312]		Loss: 0.0993
2019-10-29 00:52:21,073 Training Epoch [34/40] Iter[126/312]		Loss: 0.0992
2019-10-29 00:52:21,195 Training Epoch [34/40] Iter[127/312]		Loss: 0.0996
2019-10-29 00:52:21,316 Training Epoch [34/40] Iter[128/312]		Loss: 0.0999
2019-10-29 00:52:21,437 Training Epoch [34/40] Iter[129/312]		Loss: 0.1001
2019-10-29 00:52:21,558 Training Epoch [34/40] Iter[130/312]		Loss: 0.1001
2019-10-29 00:52:21,679 Training Epoch [34/40] Iter[131/312]		Loss: 0.1000
2019-10-29 00:52:21,800 Training Epoch [34/40] Iter[132/312]		Loss: 0.0996
2019-10-29 00:52:21,920 Training Epoch [34/40] Iter[133/312]		Loss: 0.0994
2019-10-29 00:52:22,041 Training Epoch [34/40] Iter[134/312]		Loss: 0.0996
2019-10-29 00:52:22,164 Training Epoch [34/40] Iter[135/312]		Loss: 0.0999
2019-10-29 00:52:22,285 Training Epoch [34/40] Iter[136/312]		Loss: 0.1003
2019-10-29 00:52:22,407 Training Epoch [34/40] Iter[137/312]		Loss: 0.1003
2019-10-29 00:52:22,528 Training Epoch [34/40] Iter[138/312]		Loss: 0.1005
2019-10-29 00:52:22,650 Training Epoch [34/40] Iter[139/312]		Loss: 0.1003
2019-10-29 00:52:22,771 Training Epoch [34/40] Iter[140/312]		Loss: 0.1001
2019-10-29 00:52:22,892 Training Epoch [34/40] Iter[141/312]		Loss: 0.1000
2019-10-29 00:52:23,014 Training Epoch [34/40] Iter[142/312]		Loss: 0.0999
2019-10-29 00:52:23,135 Training Epoch [34/40] Iter[143/312]		Loss: 0.0997
2019-10-29 00:52:23,257 Training Epoch [34/40] Iter[144/312]		Loss: 0.0994
2019-10-29 00:52:23,378 Training Epoch [34/40] Iter[145/312]		Loss: 0.0997
2019-10-29 00:52:23,500 Training Epoch [34/40] Iter[146/312]		Loss: 0.0995
2019-10-29 00:52:23,622 Training Epoch [34/40] Iter[147/312]		Loss: 0.0993
2019-10-29 00:52:23,743 Training Epoch [34/40] Iter[148/312]		Loss: 0.0991
2019-10-29 00:52:23,864 Training Epoch [34/40] Iter[149/312]		Loss: 0.0991
2019-10-29 00:52:23,985 Training Epoch [34/40] Iter[150/312]		Loss: 0.0991
2019-10-29 00:52:24,106 Training Epoch [34/40] Iter[151/312]		Loss: 0.0994
2019-10-29 00:52:24,228 Training Epoch [34/40] Iter[152/312]		Loss: 0.0992
2019-10-29 00:52:24,349 Training Epoch [34/40] Iter[153/312]		Loss: 0.0992
2019-10-29 00:52:24,471 Training Epoch [34/40] Iter[154/312]		Loss: 0.0992
2019-10-29 00:52:24,592 Training Epoch [34/40] Iter[155/312]		Loss: 0.0992
2019-10-29 00:52:24,713 Training Epoch [34/40] Iter[156/312]		Loss: 0.0990
2019-10-29 00:52:24,835 Training Epoch [34/40] Iter[157/312]		Loss: 0.0989
2019-10-29 00:52:24,956 Training Epoch [34/40] Iter[158/312]		Loss: 0.0988
2019-10-29 00:52:25,077 Training Epoch [34/40] Iter[159/312]		Loss: 0.0988
2019-10-29 00:52:25,199 Training Epoch [34/40] Iter[160/312]		Loss: 0.0987
2019-10-29 00:52:25,320 Training Epoch [34/40] Iter[161/312]		Loss: 0.0986
2019-10-29 00:52:25,442 Training Epoch [34/40] Iter[162/312]		Loss: 0.0985
2019-10-29 00:52:25,564 Training Epoch [34/40] Iter[163/312]		Loss: 0.0989
2019-10-29 00:52:25,685 Training Epoch [34/40] Iter[164/312]		Loss: 0.0988
2019-10-29 00:52:25,806 Training Epoch [34/40] Iter[165/312]		Loss: 0.0988
2019-10-29 00:52:25,928 Training Epoch [34/40] Iter[166/312]		Loss: 0.0986
2019-10-29 00:52:26,049 Training Epoch [34/40] Iter[167/312]		Loss: 0.0986
2019-10-29 00:52:26,170 Training Epoch [34/40] Iter[168/312]		Loss: 0.0985
2019-10-29 00:52:26,291 Training Epoch [34/40] Iter[169/312]		Loss: 0.0984
2019-10-29 00:52:26,413 Training Epoch [34/40] Iter[170/312]		Loss: 0.0990
2019-10-29 00:52:26,534 Training Epoch [34/40] Iter[171/312]		Loss: 0.0990
2019-10-29 00:52:26,656 Training Epoch [34/40] Iter[172/312]		Loss: 0.0990
2019-10-29 00:52:26,778 Training Epoch [34/40] Iter[173/312]		Loss: 0.0994
2019-10-29 00:52:26,899 Training Epoch [34/40] Iter[174/312]		Loss: 0.0994
2019-10-29 00:52:27,021 Training Epoch [34/40] Iter[175/312]		Loss: 0.0996
2019-10-29 00:52:27,142 Training Epoch [34/40] Iter[176/312]		Loss: 0.0994
2019-10-29 00:52:27,263 Training Epoch [34/40] Iter[177/312]		Loss: 0.0994
2019-10-29 00:52:27,385 Training Epoch [34/40] Iter[178/312]		Loss: 0.0992
2019-10-29 00:52:27,506 Training Epoch [34/40] Iter[179/312]		Loss: 0.0992
2019-10-29 00:52:27,628 Training Epoch [34/40] Iter[180/312]		Loss: 0.0994
2019-10-29 00:52:27,749 Training Epoch [34/40] Iter[181/312]		Loss: 0.0995
2019-10-29 00:52:27,871 Training Epoch [34/40] Iter[182/312]		Loss: 0.0993
2019-10-29 00:52:27,993 Training Epoch [34/40] Iter[183/312]		Loss: 0.0994
2019-10-29 00:52:28,115 Training Epoch [34/40] Iter[184/312]		Loss: 0.0993
2019-10-29 00:52:28,237 Training Epoch [34/40] Iter[185/312]		Loss: 0.0993
2019-10-29 00:52:28,358 Training Epoch [34/40] Iter[186/312]		Loss: 0.0992
2019-10-29 00:52:28,480 Training Epoch [34/40] Iter[187/312]		Loss: 0.0991
2019-10-29 00:52:28,602 Training Epoch [34/40] Iter[188/312]		Loss: 0.0993
2019-10-29 00:52:28,723 Training Epoch [34/40] Iter[189/312]		Loss: 0.0994
2019-10-29 00:52:28,845 Training Epoch [34/40] Iter[190/312]		Loss: 0.0994
2019-10-29 00:52:28,967 Training Epoch [34/40] Iter[191/312]		Loss: 0.0993
2019-10-29 00:52:29,088 Training Epoch [34/40] Iter[192/312]		Loss: 0.0994
2019-10-29 00:52:29,210 Training Epoch [34/40] Iter[193/312]		Loss: 0.0992
2019-10-29 00:52:29,331 Training Epoch [34/40] Iter[194/312]		Loss: 0.0991
2019-10-29 00:52:29,452 Training Epoch [34/40] Iter[195/312]		Loss: 0.0991
2019-10-29 00:52:29,573 Training Epoch [34/40] Iter[196/312]		Loss: 0.0992
2019-10-29 00:52:29,694 Training Epoch [34/40] Iter[197/312]		Loss: 0.0991
2019-10-29 00:52:29,816 Training Epoch [34/40] Iter[198/312]		Loss: 0.0994
2019-10-29 00:52:29,937 Training Epoch [34/40] Iter[199/312]		Loss: 0.0992
2019-10-29 00:52:30,058 Training Epoch [34/40] Iter[200/312]		Loss: 0.0993
2019-10-29 00:52:30,179 Training Epoch [34/40] Iter[201/312]		Loss: 0.0993
2019-10-29 00:52:30,300 Training Epoch [34/40] Iter[202/312]		Loss: 0.0992
2019-10-29 00:52:30,421 Training Epoch [34/40] Iter[203/312]		Loss: 0.0990
2019-10-29 00:52:30,543 Training Epoch [34/40] Iter[204/312]		Loss: 0.0992
2019-10-29 00:52:30,665 Training Epoch [34/40] Iter[205/312]		Loss: 0.0992
2019-10-29 00:52:30,787 Training Epoch [34/40] Iter[206/312]		Loss: 0.0991
2019-10-29 00:52:30,908 Training Epoch [34/40] Iter[207/312]		Loss: 0.0992
2019-10-29 00:52:31,030 Training Epoch [34/40] Iter[208/312]		Loss: 0.0990
2019-10-29 00:52:31,151 Training Epoch [34/40] Iter[209/312]		Loss: 0.0989
2019-10-29 00:52:31,272 Training Epoch [34/40] Iter[210/312]		Loss: 0.0989
2019-10-29 00:52:31,394 Training Epoch [34/40] Iter[211/312]		Loss: 0.0988
2019-10-29 00:52:31,515 Training Epoch [34/40] Iter[212/312]		Loss: 0.0988
2019-10-29 00:52:31,637 Training Epoch [34/40] Iter[213/312]		Loss: 0.0991
2019-10-29 00:52:31,759 Training Epoch [34/40] Iter[214/312]		Loss: 0.0991
2019-10-29 00:52:31,881 Training Epoch [34/40] Iter[215/312]		Loss: 0.0990
2019-10-29 00:52:32,002 Training Epoch [34/40] Iter[216/312]		Loss: 0.0991
2019-10-29 00:52:32,124 Training Epoch [34/40] Iter[217/312]		Loss: 0.0990
2019-10-29 00:52:32,246 Training Epoch [34/40] Iter[218/312]		Loss: 0.0991
2019-10-29 00:52:32,367 Training Epoch [34/40] Iter[219/312]		Loss: 0.0990
2019-10-29 00:52:32,488 Training Epoch [34/40] Iter[220/312]		Loss: 0.0991
2019-10-29 00:52:32,610 Training Epoch [34/40] Iter[221/312]		Loss: 0.0993
2019-10-29 00:52:32,731 Training Epoch [34/40] Iter[222/312]		Loss: 0.0993
2019-10-29 00:52:32,852 Training Epoch [34/40] Iter[223/312]		Loss: 0.0995
2019-10-29 00:52:32,973 Training Epoch [34/40] Iter[224/312]		Loss: 0.0993
2019-10-29 00:52:33,094 Training Epoch [34/40] Iter[225/312]		Loss: 0.0996
2019-10-29 00:52:33,216 Training Epoch [34/40] Iter[226/312]		Loss: 0.0995
2019-10-29 00:52:33,337 Training Epoch [34/40] Iter[227/312]		Loss: 0.0995
2019-10-29 00:52:33,458 Training Epoch [34/40] Iter[228/312]		Loss: 0.0995
2019-10-29 00:52:33,580 Training Epoch [34/40] Iter[229/312]		Loss: 0.0998
2019-10-29 00:52:33,701 Training Epoch [34/40] Iter[230/312]		Loss: 0.0999
2019-10-29 00:52:33,822 Training Epoch [34/40] Iter[231/312]		Loss: 0.0998
2019-10-29 00:52:33,944 Training Epoch [34/40] Iter[232/312]		Loss: 0.0997
2019-10-29 00:52:34,066 Training Epoch [34/40] Iter[233/312]		Loss: 0.0997
2019-10-29 00:52:34,187 Training Epoch [34/40] Iter[234/312]		Loss: 0.0996
2019-10-29 00:52:34,309 Training Epoch [34/40] Iter[235/312]		Loss: 0.0997
2019-10-29 00:52:34,430 Training Epoch [34/40] Iter[236/312]		Loss: 0.0997
2019-10-29 00:52:34,552 Training Epoch [34/40] Iter[237/312]		Loss: 0.0998
2019-10-29 00:52:34,673 Training Epoch [34/40] Iter[238/312]		Loss: 0.0997
2019-10-29 00:52:34,795 Training Epoch [34/40] Iter[239/312]		Loss: 0.0996
2019-10-29 00:52:34,917 Training Epoch [34/40] Iter[240/312]		Loss: 0.0995
2019-10-29 00:52:35,038 Training Epoch [34/40] Iter[241/312]		Loss: 0.0995
2019-10-29 00:52:35,160 Training Epoch [34/40] Iter[242/312]		Loss: 0.0994
2019-10-29 00:52:35,281 Training Epoch [34/40] Iter[243/312]		Loss: 0.0994
2019-10-29 00:52:35,403 Training Epoch [34/40] Iter[244/312]		Loss: 0.0993
2019-10-29 00:52:35,524 Training Epoch [34/40] Iter[245/312]		Loss: 0.0992
2019-10-29 00:52:35,646 Training Epoch [34/40] Iter[246/312]		Loss: 0.0990
2019-10-29 00:52:35,768 Training Epoch [34/40] Iter[247/312]		Loss: 0.0990
2019-10-29 00:52:35,889 Training Epoch [34/40] Iter[248/312]		Loss: 0.0991
2019-10-29 00:52:36,011 Training Epoch [34/40] Iter[249/312]		Loss: 0.0993
2019-10-29 00:52:36,132 Training Epoch [34/40] Iter[250/312]		Loss: 0.0994
2019-10-29 00:52:36,253 Training Epoch [34/40] Iter[251/312]		Loss: 0.0994
2019-10-29 00:52:36,375 Training Epoch [34/40] Iter[252/312]		Loss: 0.0994
2019-10-29 00:52:36,497 Training Epoch [34/40] Iter[253/312]		Loss: 0.0993
2019-10-29 00:52:36,618 Training Epoch [34/40] Iter[254/312]		Loss: 0.0992
2019-10-29 00:52:36,740 Training Epoch [34/40] Iter[255/312]		Loss: 0.0992
2019-10-29 00:52:36,861 Training Epoch [34/40] Iter[256/312]		Loss: 0.0991
2019-10-29 00:52:36,982 Training Epoch [34/40] Iter[257/312]		Loss: 0.0989
2019-10-29 00:52:37,104 Training Epoch [34/40] Iter[258/312]		Loss: 0.0988
2019-10-29 00:52:37,225 Training Epoch [34/40] Iter[259/312]		Loss: 0.0989
2019-10-29 00:52:37,346 Training Epoch [34/40] Iter[260/312]		Loss: 0.0989
2019-10-29 00:52:37,468 Training Epoch [34/40] Iter[261/312]		Loss: 0.0987
2019-10-29 00:52:37,589 Training Epoch [34/40] Iter[262/312]		Loss: 0.0990
2019-10-29 00:52:37,711 Training Epoch [34/40] Iter[263/312]		Loss: 0.0990
2019-10-29 00:52:37,832 Training Epoch [34/40] Iter[264/312]		Loss: 0.0990
2019-10-29 00:52:37,953 Training Epoch [34/40] Iter[265/312]		Loss: 0.0989
2019-10-29 00:52:38,074 Training Epoch [34/40] Iter[266/312]		Loss: 0.0990
2019-10-29 00:52:38,195 Training Epoch [34/40] Iter[267/312]		Loss: 0.0992
2019-10-29 00:52:38,316 Training Epoch [34/40] Iter[268/312]		Loss: 0.0992
2019-10-29 00:52:38,437 Training Epoch [34/40] Iter[269/312]		Loss: 0.0992
2019-10-29 00:52:38,558 Training Epoch [34/40] Iter[270/312]		Loss: 0.0992
2019-10-29 00:52:38,680 Training Epoch [34/40] Iter[271/312]		Loss: 0.0991
2019-10-29 00:52:38,800 Training Epoch [34/40] Iter[272/312]		Loss: 0.0991
2019-10-29 00:52:38,921 Training Epoch [34/40] Iter[273/312]		Loss: 0.0989
2019-10-29 00:52:39,042 Training Epoch [34/40] Iter[274/312]		Loss: 0.0991
2019-10-29 00:52:39,164 Training Epoch [34/40] Iter[275/312]		Loss: 0.0991
2019-10-29 00:52:39,286 Training Epoch [34/40] Iter[276/312]		Loss: 0.0993
2019-10-29 00:52:39,408 Training Epoch [34/40] Iter[277/312]		Loss: 0.0993
2019-10-29 00:52:39,530 Training Epoch [34/40] Iter[278/312]		Loss: 0.0993
2019-10-29 00:52:39,651 Training Epoch [34/40] Iter[279/312]		Loss: 0.0993
2019-10-29 00:52:39,772 Training Epoch [34/40] Iter[280/312]		Loss: 0.0993
2019-10-29 00:52:39,893 Training Epoch [34/40] Iter[281/312]		Loss: 0.0993
2019-10-29 00:52:40,015 Training Epoch [34/40] Iter[282/312]		Loss: 0.0994
2019-10-29 00:52:40,136 Training Epoch [34/40] Iter[283/312]		Loss: 0.0994
2019-10-29 00:52:40,258 Training Epoch [34/40] Iter[284/312]		Loss: 0.0994
2019-10-29 00:52:40,380 Training Epoch [34/40] Iter[285/312]		Loss: 0.0994
2019-10-29 00:52:40,501 Training Epoch [34/40] Iter[286/312]		Loss: 0.0994
2019-10-29 00:52:40,623 Training Epoch [34/40] Iter[287/312]		Loss: 0.0995
2019-10-29 00:52:40,744 Training Epoch [34/40] Iter[288/312]		Loss: 0.0995
2019-10-29 00:52:40,865 Training Epoch [34/40] Iter[289/312]		Loss: 0.0994
2019-10-29 00:52:40,986 Training Epoch [34/40] Iter[290/312]		Loss: 0.0994
2019-10-29 00:52:41,107 Training Epoch [34/40] Iter[291/312]		Loss: 0.0994
2019-10-29 00:52:41,229 Training Epoch [34/40] Iter[292/312]		Loss: 0.0997
2019-10-29 00:52:41,350 Training Epoch [34/40] Iter[293/312]		Loss: 0.0996
2019-10-29 00:52:41,471 Training Epoch [34/40] Iter[294/312]		Loss: 0.0997
2019-10-29 00:52:41,592 Training Epoch [34/40] Iter[295/312]		Loss: 0.0996
2019-10-29 00:52:41,713 Training Epoch [34/40] Iter[296/312]		Loss: 0.0995
2019-10-29 00:52:41,834 Training Epoch [34/40] Iter[297/312]		Loss: 0.0997
2019-10-29 00:52:41,956 Training Epoch [34/40] Iter[298/312]		Loss: 0.0996
2019-10-29 00:52:42,077 Training Epoch [34/40] Iter[299/312]		Loss: 0.0996
2019-10-29 00:52:42,197 Training Epoch [34/40] Iter[300/312]		Loss: 0.0996
2019-10-29 00:52:42,318 Training Epoch [34/40] Iter[301/312]		Loss: 0.0996
2019-10-29 00:52:42,440 Training Epoch [34/40] Iter[302/312]		Loss: 0.0998
2019-10-29 00:52:42,562 Training Epoch [34/40] Iter[303/312]		Loss: 0.0999
2019-10-29 00:52:42,683 Training Epoch [34/40] Iter[304/312]		Loss: 0.0998
2019-10-29 00:52:42,804 Training Epoch [34/40] Iter[305/312]		Loss: 0.0999
2019-10-29 00:52:42,925 Training Epoch [34/40] Iter[306/312]		Loss: 0.0998
2019-10-29 00:52:43,046 Training Epoch [34/40] Iter[307/312]		Loss: 0.0997
2019-10-29 00:52:43,167 Training Epoch [34/40] Iter[308/312]		Loss: 0.0997
2019-10-29 00:52:43,288 Training Epoch [34/40] Iter[309/312]		Loss: 0.0997
2019-10-29 00:52:43,409 Training Epoch [34/40] Iter[310/312]		Loss: 0.0996
2019-10-29 00:52:43,530 Training Epoch [34/40] Iter[311/312]		Loss: 0.0997
2019-10-29 00:52:43,591 Training Epoch [34/40] Iter[312/312]		Loss: 0.0997
2019-10-29 00:52:43,964 Testing Epoch [34/40] Iter[0/62]		Loss: 0.0913
2019-10-29 00:52:44,011 Testing Epoch [34/40] Iter[1/62]		Loss: 0.1253
2019-10-29 00:52:44,042 Testing Epoch [34/40] Iter[2/62]		Loss: 0.1177
2019-10-29 00:52:44,073 Testing Epoch [34/40] Iter[3/62]		Loss: 0.1148
2019-10-29 00:52:44,106 Testing Epoch [34/40] Iter[4/62]		Loss: 0.1104
2019-10-29 00:52:44,137 Testing Epoch [34/40] Iter[5/62]		Loss: 0.1084
2019-10-29 00:52:44,169 Testing Epoch [34/40] Iter[6/62]		Loss: 0.1094
2019-10-29 00:52:44,202 Testing Epoch [34/40] Iter[7/62]		Loss: 0.1161
2019-10-29 00:52:44,232 Testing Epoch [34/40] Iter[8/62]		Loss: 0.1226
2019-10-29 00:52:44,263 Testing Epoch [34/40] Iter[9/62]		Loss: 0.1194
2019-10-29 00:52:44,298 Testing Epoch [34/40] Iter[10/62]		Loss: 0.1175
2019-10-29 00:52:44,329 Testing Epoch [34/40] Iter[11/62]		Loss: 0.1226
2019-10-29 00:52:44,360 Testing Epoch [34/40] Iter[12/62]		Loss: 0.1237
2019-10-29 00:52:44,397 Testing Epoch [34/40] Iter[13/62]		Loss: 0.1258
2019-10-29 00:52:44,428 Testing Epoch [34/40] Iter[14/62]		Loss: 0.1380
2019-10-29 00:52:44,459 Testing Epoch [34/40] Iter[15/62]		Loss: 0.1396
2019-10-29 00:52:44,490 Testing Epoch [34/40] Iter[16/62]		Loss: 0.1374
2019-10-29 00:52:44,520 Testing Epoch [34/40] Iter[17/62]		Loss: 0.1367
2019-10-29 00:52:44,551 Testing Epoch [34/40] Iter[18/62]		Loss: 0.1333
2019-10-29 00:52:44,582 Testing Epoch [34/40] Iter[19/62]		Loss: 0.1313
2019-10-29 00:52:44,613 Testing Epoch [34/40] Iter[20/62]		Loss: 0.1326
2019-10-29 00:52:44,643 Testing Epoch [34/40] Iter[21/62]		Loss: 0.1307
2019-10-29 00:52:44,674 Testing Epoch [34/40] Iter[22/62]		Loss: 0.1300
2019-10-29 00:52:44,705 Testing Epoch [34/40] Iter[23/62]		Loss: 0.1298
2019-10-29 00:52:44,735 Testing Epoch [34/40] Iter[24/62]		Loss: 0.1316
2019-10-29 00:52:44,766 Testing Epoch [34/40] Iter[25/62]		Loss: 0.1308
2019-10-29 00:52:44,797 Testing Epoch [34/40] Iter[26/62]		Loss: 0.1297
2019-10-29 00:52:44,828 Testing Epoch [34/40] Iter[27/62]		Loss: 0.1342
2019-10-29 00:52:44,858 Testing Epoch [34/40] Iter[28/62]		Loss: 0.1361
2019-10-29 00:52:44,889 Testing Epoch [34/40] Iter[29/62]		Loss: 0.1358
2019-10-29 00:52:44,920 Testing Epoch [34/40] Iter[30/62]		Loss: 0.1374
2019-10-29 00:52:44,950 Testing Epoch [34/40] Iter[31/62]		Loss: 0.1366
2019-10-29 00:52:44,981 Testing Epoch [34/40] Iter[32/62]		Loss: 0.1382
2019-10-29 00:52:45,012 Testing Epoch [34/40] Iter[33/62]		Loss: 0.1365
2019-10-29 00:52:45,042 Testing Epoch [34/40] Iter[34/62]		Loss: 0.1381
2019-10-29 00:52:45,073 Testing Epoch [34/40] Iter[35/62]		Loss: 0.1385
2019-10-29 00:52:45,104 Testing Epoch [34/40] Iter[36/62]		Loss: 0.1367
2019-10-29 00:52:45,134 Testing Epoch [34/40] Iter[37/62]		Loss: 0.1364
2019-10-29 00:52:45,165 Testing Epoch [34/40] Iter[38/62]		Loss: 0.1365
2019-10-29 00:52:45,196 Testing Epoch [34/40] Iter[39/62]		Loss: 0.1368
2019-10-29 00:52:45,227 Testing Epoch [34/40] Iter[40/62]		Loss: 0.1372
2019-10-29 00:52:45,257 Testing Epoch [34/40] Iter[41/62]		Loss: 0.1373
2019-10-29 00:52:45,288 Testing Epoch [34/40] Iter[42/62]		Loss: 0.1359
2019-10-29 00:52:45,319 Testing Epoch [34/40] Iter[43/62]		Loss: 0.1354
2019-10-29 00:52:45,350 Testing Epoch [34/40] Iter[44/62]		Loss: 0.1342
2019-10-29 00:52:45,381 Testing Epoch [34/40] Iter[45/62]		Loss: 0.1353
2019-10-29 00:52:45,411 Testing Epoch [34/40] Iter[46/62]		Loss: 0.1354
2019-10-29 00:52:45,442 Testing Epoch [34/40] Iter[47/62]		Loss: 0.1402
2019-10-29 00:52:45,473 Testing Epoch [34/40] Iter[48/62]		Loss: 0.1392
2019-10-29 00:52:45,503 Testing Epoch [34/40] Iter[49/62]		Loss: 0.1406
2019-10-29 00:52:45,534 Testing Epoch [34/40] Iter[50/62]		Loss: 0.1403
2019-10-29 00:52:45,565 Testing Epoch [34/40] Iter[51/62]		Loss: 0.1404
2019-10-29 00:52:45,595 Testing Epoch [34/40] Iter[52/62]		Loss: 0.1392
2019-10-29 00:52:45,626 Testing Epoch [34/40] Iter[53/62]		Loss: 0.1391
2019-10-29 00:52:45,657 Testing Epoch [34/40] Iter[54/62]		Loss: 0.1385
2019-10-29 00:52:45,688 Testing Epoch [34/40] Iter[55/62]		Loss: 0.1386
2019-10-29 00:52:45,718 Testing Epoch [34/40] Iter[56/62]		Loss: 0.1383
2019-10-29 00:52:45,748 Testing Epoch [34/40] Iter[57/62]		Loss: 0.1381
2019-10-29 00:52:45,779 Testing Epoch [34/40] Iter[58/62]		Loss: 0.1377
2019-10-29 00:52:45,809 Testing Epoch [34/40] Iter[59/62]		Loss: 0.1378
2019-10-29 00:52:45,839 Testing Epoch [34/40] Iter[60/62]		Loss: 0.1373
2019-10-29 00:52:45,870 Testing Epoch [34/40] Iter[61/62]		Loss: 0.1370
2019-10-29 00:52:45,887 Testing Epoch [34/40] Iter[62/62]		Loss: 0.1377
2019-10-29 00:52:46,371 Training Epoch [35/40] Iter[0/312]		Loss: 0.1463
2019-10-29 00:52:46,493 Training Epoch [35/40] Iter[1/312]		Loss: 0.1228
2019-10-29 00:52:46,613 Training Epoch [35/40] Iter[2/312]		Loss: 0.1063
2019-10-29 00:52:46,734 Training Epoch [35/40] Iter[3/312]		Loss: 0.0993
2019-10-29 00:52:46,860 Training Epoch [35/40] Iter[4/312]		Loss: 0.0951
2019-10-29 00:52:46,980 Training Epoch [35/40] Iter[5/312]		Loss: 0.0868
2019-10-29 00:52:47,104 Training Epoch [35/40] Iter[6/312]		Loss: 0.0889
2019-10-29 00:52:47,226 Training Epoch [35/40] Iter[7/312]		Loss: 0.0892
2019-10-29 00:52:47,346 Training Epoch [35/40] Iter[8/312]		Loss: 0.0895
2019-10-29 00:52:47,467 Training Epoch [35/40] Iter[9/312]		Loss: 0.0896
2019-10-29 00:52:47,589 Training Epoch [35/40] Iter[10/312]		Loss: 0.0970
2019-10-29 00:52:47,710 Training Epoch [35/40] Iter[11/312]		Loss: 0.0957
2019-10-29 00:52:47,831 Training Epoch [35/40] Iter[12/312]		Loss: 0.0937
2019-10-29 00:52:47,953 Training Epoch [35/40] Iter[13/312]		Loss: 0.0924
2019-10-29 00:52:48,074 Training Epoch [35/40] Iter[14/312]		Loss: 0.0930
2019-10-29 00:52:48,195 Training Epoch [35/40] Iter[15/312]		Loss: 0.0929
2019-10-29 00:52:48,316 Training Epoch [35/40] Iter[16/312]		Loss: 0.0956
2019-10-29 00:52:48,438 Training Epoch [35/40] Iter[17/312]		Loss: 0.0969
2019-10-29 00:52:48,559 Training Epoch [35/40] Iter[18/312]		Loss: 0.0960
2019-10-29 00:52:48,680 Training Epoch [35/40] Iter[19/312]		Loss: 0.0949
2019-10-29 00:52:48,801 Training Epoch [35/40] Iter[20/312]		Loss: 0.0966
2019-10-29 00:52:48,923 Training Epoch [35/40] Iter[21/312]		Loss: 0.0962
2019-10-29 00:52:49,044 Training Epoch [35/40] Iter[22/312]		Loss: 0.0963
2019-10-29 00:52:49,166 Training Epoch [35/40] Iter[23/312]		Loss: 0.0969
2019-10-29 00:52:49,288 Training Epoch [35/40] Iter[24/312]		Loss: 0.0958
2019-10-29 00:52:49,410 Training Epoch [35/40] Iter[25/312]		Loss: 0.0967
2019-10-29 00:52:49,531 Training Epoch [35/40] Iter[26/312]		Loss: 0.0979
2019-10-29 00:52:49,652 Training Epoch [35/40] Iter[27/312]		Loss: 0.0974
2019-10-29 00:52:49,773 Training Epoch [35/40] Iter[28/312]		Loss: 0.0968
2019-10-29 00:52:49,894 Training Epoch [35/40] Iter[29/312]		Loss: 0.0992
2019-10-29 00:52:50,015 Training Epoch [35/40] Iter[30/312]		Loss: 0.0990
2019-10-29 00:52:50,138 Training Epoch [35/40] Iter[31/312]		Loss: 0.0997
2019-10-29 00:52:50,259 Training Epoch [35/40] Iter[32/312]		Loss: 0.0994
2019-10-29 00:52:50,381 Training Epoch [35/40] Iter[33/312]		Loss: 0.0989
2019-10-29 00:52:50,502 Training Epoch [35/40] Iter[34/312]		Loss: 0.0982
2019-10-29 00:52:50,623 Training Epoch [35/40] Iter[35/312]		Loss: 0.1004
2019-10-29 00:52:50,744 Training Epoch [35/40] Iter[36/312]		Loss: 0.1019
2019-10-29 00:52:50,865 Training Epoch [35/40] Iter[37/312]		Loss: 0.1030
2019-10-29 00:52:50,987 Training Epoch [35/40] Iter[38/312]		Loss: 0.1025
2019-10-29 00:52:51,109 Training Epoch [35/40] Iter[39/312]		Loss: 0.1027
2019-10-29 00:52:51,233 Training Epoch [35/40] Iter[40/312]		Loss: 0.1023
2019-10-29 00:52:51,354 Training Epoch [35/40] Iter[41/312]		Loss: 0.1020
2019-10-29 00:52:51,475 Training Epoch [35/40] Iter[42/312]		Loss: 0.1025
2019-10-29 00:52:51,600 Training Epoch [35/40] Iter[43/312]		Loss: 0.1027
2019-10-29 00:52:51,721 Training Epoch [35/40] Iter[44/312]		Loss: 0.1028
2019-10-29 00:52:51,844 Training Epoch [35/40] Iter[45/312]		Loss: 0.1046
2019-10-29 00:52:51,965 Training Epoch [35/40] Iter[46/312]		Loss: 0.1040
2019-10-29 00:52:52,089 Training Epoch [35/40] Iter[47/312]		Loss: 0.1049
2019-10-29 00:52:52,210 Training Epoch [35/40] Iter[48/312]		Loss: 0.1050
2019-10-29 00:52:52,332 Training Epoch [35/40] Iter[49/312]		Loss: 0.1067
2019-10-29 00:52:52,454 Training Epoch [35/40] Iter[50/312]		Loss: 0.1058
2019-10-29 00:52:52,580 Training Epoch [35/40] Iter[51/312]		Loss: 0.1056
2019-10-29 00:52:52,701 Training Epoch [35/40] Iter[52/312]		Loss: 0.1058
2019-10-29 00:52:52,828 Training Epoch [35/40] Iter[53/312]		Loss: 0.1049
2019-10-29 00:52:52,949 Training Epoch [35/40] Iter[54/312]		Loss: 0.1056
2019-10-29 00:52:53,072 Training Epoch [35/40] Iter[55/312]		Loss: 0.1064
2019-10-29 00:52:53,193 Training Epoch [35/40] Iter[56/312]		Loss: 0.1058
2019-10-29 00:52:53,316 Training Epoch [35/40] Iter[57/312]		Loss: 0.1055
2019-10-29 00:52:53,437 Training Epoch [35/40] Iter[58/312]		Loss: 0.1053
2019-10-29 00:52:53,560 Training Epoch [35/40] Iter[59/312]		Loss: 0.1047
2019-10-29 00:52:53,681 Training Epoch [35/40] Iter[60/312]		Loss: 0.1045
2019-10-29 00:52:53,804 Training Epoch [35/40] Iter[61/312]		Loss: 0.1042
2019-10-29 00:52:53,926 Training Epoch [35/40] Iter[62/312]		Loss: 0.1042
2019-10-29 00:52:54,048 Training Epoch [35/40] Iter[63/312]		Loss: 0.1035
2019-10-29 00:52:54,169 Training Epoch [35/40] Iter[64/312]		Loss: 0.1033
2019-10-29 00:52:54,292 Training Epoch [35/40] Iter[65/312]		Loss: 0.1027
2019-10-29 00:52:54,414 Training Epoch [35/40] Iter[66/312]		Loss: 0.1026
2019-10-29 00:52:54,536 Training Epoch [35/40] Iter[67/312]		Loss: 0.1034
2019-10-29 00:52:54,657 Training Epoch [35/40] Iter[68/312]		Loss: 0.1037
2019-10-29 00:52:54,784 Training Epoch [35/40] Iter[69/312]		Loss: 0.1041
2019-10-29 00:52:54,906 Training Epoch [35/40] Iter[70/312]		Loss: 0.1036
2019-10-29 00:52:55,028 Training Epoch [35/40] Iter[71/312]		Loss: 0.1033
2019-10-29 00:52:55,149 Training Epoch [35/40] Iter[72/312]		Loss: 0.1035
2019-10-29 00:52:55,272 Training Epoch [35/40] Iter[73/312]		Loss: 0.1033
2019-10-29 00:52:55,393 Training Epoch [35/40] Iter[74/312]		Loss: 0.1035
2019-10-29 00:52:55,520 Training Epoch [35/40] Iter[75/312]		Loss: 0.1033
2019-10-29 00:52:55,641 Training Epoch [35/40] Iter[76/312]		Loss: 0.1037
2019-10-29 00:52:55,762 Training Epoch [35/40] Iter[77/312]		Loss: 0.1038
2019-10-29 00:52:55,883 Training Epoch [35/40] Iter[78/312]		Loss: 0.1040
2019-10-29 00:52:56,004 Training Epoch [35/40] Iter[79/312]		Loss: 0.1042
2019-10-29 00:52:56,125 Training Epoch [35/40] Iter[80/312]		Loss: 0.1044
2019-10-29 00:52:56,246 Training Epoch [35/40] Iter[81/312]		Loss: 0.1047
2019-10-29 00:52:56,368 Training Epoch [35/40] Iter[82/312]		Loss: 0.1042
2019-10-29 00:52:56,489 Training Epoch [35/40] Iter[83/312]		Loss: 0.1040
2019-10-29 00:52:56,611 Training Epoch [35/40] Iter[84/312]		Loss: 0.1035
2019-10-29 00:52:56,733 Training Epoch [35/40] Iter[85/312]		Loss: 0.1035
2019-10-29 00:52:56,854 Training Epoch [35/40] Iter[86/312]		Loss: 0.1033
2019-10-29 00:52:56,975 Training Epoch [35/40] Iter[87/312]		Loss: 0.1028
2019-10-29 00:52:57,097 Training Epoch [35/40] Iter[88/312]		Loss: 0.1023
2019-10-29 00:52:57,219 Training Epoch [35/40] Iter[89/312]		Loss: 0.1021
2019-10-29 00:52:57,340 Training Epoch [35/40] Iter[90/312]		Loss: 0.1020
2019-10-29 00:52:57,462 Training Epoch [35/40] Iter[91/312]		Loss: 0.1017
2019-10-29 00:52:57,583 Training Epoch [35/40] Iter[92/312]		Loss: 0.1013
2019-10-29 00:52:57,705 Training Epoch [35/40] Iter[93/312]		Loss: 0.1011
2019-10-29 00:52:57,827 Training Epoch [35/40] Iter[94/312]		Loss: 0.1010
2019-10-29 00:52:57,948 Training Epoch [35/40] Iter[95/312]		Loss: 0.1010
2019-10-29 00:52:58,069 Training Epoch [35/40] Iter[96/312]		Loss: 0.1008
2019-10-29 00:52:58,190 Training Epoch [35/40] Iter[97/312]		Loss: 0.1008
2019-10-29 00:52:58,312 Training Epoch [35/40] Iter[98/312]		Loss: 0.1016
2019-10-29 00:52:58,433 Training Epoch [35/40] Iter[99/312]		Loss: 0.1013
2019-10-29 00:52:58,554 Training Epoch [35/40] Iter[100/312]		Loss: 0.1020
2019-10-29 00:52:58,675 Training Epoch [35/40] Iter[101/312]		Loss: 0.1024
2019-10-29 00:52:58,796 Training Epoch [35/40] Iter[102/312]		Loss: 0.1021
2019-10-29 00:52:58,917 Training Epoch [35/40] Iter[103/312]		Loss: 0.1015
2019-10-29 00:52:59,039 Training Epoch [35/40] Iter[104/312]		Loss: 0.1015
2019-10-29 00:52:59,160 Training Epoch [35/40] Iter[105/312]		Loss: 0.1014
2019-10-29 00:52:59,281 Training Epoch [35/40] Iter[106/312]		Loss: 0.1011
2019-10-29 00:52:59,403 Training Epoch [35/40] Iter[107/312]		Loss: 0.1008
2019-10-29 00:52:59,525 Training Epoch [35/40] Iter[108/312]		Loss: 0.1010
2019-10-29 00:52:59,647 Training Epoch [35/40] Iter[109/312]		Loss: 0.1007
2019-10-29 00:52:59,768 Training Epoch [35/40] Iter[110/312]		Loss: 0.1006
2019-10-29 00:52:59,889 Training Epoch [35/40] Iter[111/312]		Loss: 0.1006
2019-10-29 00:53:00,010 Training Epoch [35/40] Iter[112/312]		Loss: 0.1007
2019-10-29 00:53:00,132 Training Epoch [35/40] Iter[113/312]		Loss: 0.1009
2019-10-29 00:53:00,254 Training Epoch [35/40] Iter[114/312]		Loss: 0.1009
2019-10-29 00:53:00,375 Training Epoch [35/40] Iter[115/312]		Loss: 0.1008
2019-10-29 00:53:00,497 Training Epoch [35/40] Iter[116/312]		Loss: 0.1012
2019-10-29 00:53:00,618 Training Epoch [35/40] Iter[117/312]		Loss: 0.1010
2019-10-29 00:53:00,740 Training Epoch [35/40] Iter[118/312]		Loss: 0.1008
2019-10-29 00:53:00,862 Training Epoch [35/40] Iter[119/312]		Loss: 0.1011
2019-10-29 00:53:00,983 Training Epoch [35/40] Iter[120/312]		Loss: 0.1010
2019-10-29 00:53:01,105 Training Epoch [35/40] Iter[121/312]		Loss: 0.1012
2019-10-29 00:53:01,226 Training Epoch [35/40] Iter[122/312]		Loss: 0.1013
2019-10-29 00:53:01,347 Training Epoch [35/40] Iter[123/312]		Loss: 0.1011
2019-10-29 00:53:01,469 Training Epoch [35/40] Iter[124/312]		Loss: 0.1009
2019-10-29 00:53:01,590 Training Epoch [35/40] Iter[125/312]		Loss: 0.1010
2019-10-29 00:53:01,712 Training Epoch [35/40] Iter[126/312]		Loss: 0.1011
2019-10-29 00:53:01,833 Training Epoch [35/40] Iter[127/312]		Loss: 0.1012
2019-10-29 00:53:01,955 Training Epoch [35/40] Iter[128/312]		Loss: 0.1014
2019-10-29 00:53:02,076 Training Epoch [35/40] Iter[129/312]		Loss: 0.1011
2019-10-29 00:53:02,197 Training Epoch [35/40] Iter[130/312]		Loss: 0.1009
2019-10-29 00:53:02,319 Training Epoch [35/40] Iter[131/312]		Loss: 0.1008
2019-10-29 00:53:02,440 Training Epoch [35/40] Iter[132/312]		Loss: 0.1006
2019-10-29 00:53:02,562 Training Epoch [35/40] Iter[133/312]		Loss: 0.1004
2019-10-29 00:53:02,683 Training Epoch [35/40] Iter[134/312]		Loss: 0.1007
2019-10-29 00:53:02,804 Training Epoch [35/40] Iter[135/312]		Loss: 0.1005
2019-10-29 00:53:02,925 Training Epoch [35/40] Iter[136/312]		Loss: 0.1007
2019-10-29 00:53:03,047 Training Epoch [35/40] Iter[137/312]		Loss: 0.1005
2019-10-29 00:53:03,168 Training Epoch [35/40] Iter[138/312]		Loss: 0.1004
2019-10-29 00:53:03,290 Training Epoch [35/40] Iter[139/312]		Loss: 0.1004
2019-10-29 00:53:03,411 Training Epoch [35/40] Iter[140/312]		Loss: 0.1004
2019-10-29 00:53:03,533 Training Epoch [35/40] Iter[141/312]		Loss: 0.1004
2019-10-29 00:53:03,654 Training Epoch [35/40] Iter[142/312]		Loss: 0.1001
2019-10-29 00:53:03,775 Training Epoch [35/40] Iter[143/312]		Loss: 0.0999
2019-10-29 00:53:03,896 Training Epoch [35/40] Iter[144/312]		Loss: 0.0998
2019-10-29 00:53:04,017 Training Epoch [35/40] Iter[145/312]		Loss: 0.0999
2019-10-29 00:53:04,138 Training Epoch [35/40] Iter[146/312]		Loss: 0.0997
2019-10-29 00:53:04,259 Training Epoch [35/40] Iter[147/312]		Loss: 0.1001
2019-10-29 00:53:04,380 Training Epoch [35/40] Iter[148/312]		Loss: 0.1003
2019-10-29 00:53:04,501 Training Epoch [35/40] Iter[149/312]		Loss: 0.1005
2019-10-29 00:53:04,622 Training Epoch [35/40] Iter[150/312]		Loss: 0.1008
2019-10-29 00:53:04,743 Training Epoch [35/40] Iter[151/312]		Loss: 0.1007
2019-10-29 00:53:04,865 Training Epoch [35/40] Iter[152/312]		Loss: 0.1007
2019-10-29 00:53:04,986 Training Epoch [35/40] Iter[153/312]		Loss: 0.1009
2019-10-29 00:53:05,108 Training Epoch [35/40] Iter[154/312]		Loss: 0.1011
2019-10-29 00:53:05,229 Training Epoch [35/40] Iter[155/312]		Loss: 0.1009
2019-10-29 00:53:05,351 Training Epoch [35/40] Iter[156/312]		Loss: 0.1009
2019-10-29 00:53:05,472 Training Epoch [35/40] Iter[157/312]		Loss: 0.1008
2019-10-29 00:53:05,594 Training Epoch [35/40] Iter[158/312]		Loss: 0.1009
2019-10-29 00:53:05,716 Training Epoch [35/40] Iter[159/312]		Loss: 0.1008
2019-10-29 00:53:05,838 Training Epoch [35/40] Iter[160/312]		Loss: 0.1006
2019-10-29 00:53:05,960 Training Epoch [35/40] Iter[161/312]		Loss: 0.1004
2019-10-29 00:53:06,081 Training Epoch [35/40] Iter[162/312]		Loss: 0.1002
2019-10-29 00:53:06,203 Training Epoch [35/40] Iter[163/312]		Loss: 0.1001
2019-10-29 00:53:06,324 Training Epoch [35/40] Iter[164/312]		Loss: 0.1003
2019-10-29 00:53:06,446 Training Epoch [35/40] Iter[165/312]		Loss: 0.1002
2019-10-29 00:53:06,567 Training Epoch [35/40] Iter[166/312]		Loss: 0.1001
2019-10-29 00:53:06,689 Training Epoch [35/40] Iter[167/312]		Loss: 0.1000
2019-10-29 00:53:06,810 Training Epoch [35/40] Iter[168/312]		Loss: 0.0997
2019-10-29 00:53:06,931 Training Epoch [35/40] Iter[169/312]		Loss: 0.0998
2019-10-29 00:53:07,052 Training Epoch [35/40] Iter[170/312]		Loss: 0.0997
2019-10-29 00:53:07,174 Training Epoch [35/40] Iter[171/312]		Loss: 0.0998
2019-10-29 00:53:07,295 Training Epoch [35/40] Iter[172/312]		Loss: 0.1001
2019-10-29 00:53:07,416 Training Epoch [35/40] Iter[173/312]		Loss: 0.0999
2019-10-29 00:53:07,537 Training Epoch [35/40] Iter[174/312]		Loss: 0.0999
2019-10-29 00:53:07,659 Training Epoch [35/40] Iter[175/312]		Loss: 0.0999
2019-10-29 00:53:07,780 Training Epoch [35/40] Iter[176/312]		Loss: 0.0999
2019-10-29 00:53:07,902 Training Epoch [35/40] Iter[177/312]		Loss: 0.0999
2019-10-29 00:53:08,023 Training Epoch [35/40] Iter[178/312]		Loss: 0.1000
2019-10-29 00:53:08,145 Training Epoch [35/40] Iter[179/312]		Loss: 0.1002
2019-10-29 00:53:08,266 Training Epoch [35/40] Iter[180/312]		Loss: 0.1002
2019-10-29 00:53:08,388 Training Epoch [35/40] Iter[181/312]		Loss: 0.1002
2019-10-29 00:53:08,510 Training Epoch [35/40] Iter[182/312]		Loss: 0.1001
2019-10-29 00:53:08,631 Training Epoch [35/40] Iter[183/312]		Loss: 0.1001
2019-10-29 00:53:08,753 Training Epoch [35/40] Iter[184/312]		Loss: 0.1001
2019-10-29 00:53:08,874 Training Epoch [35/40] Iter[185/312]		Loss: 0.1002
2019-10-29 00:53:08,995 Training Epoch [35/40] Iter[186/312]		Loss: 0.1002
2019-10-29 00:53:09,117 Training Epoch [35/40] Iter[187/312]		Loss: 0.1003
2019-10-29 00:53:09,238 Training Epoch [35/40] Iter[188/312]		Loss: 0.1003
2019-10-29 00:53:09,360 Training Epoch [35/40] Iter[189/312]		Loss: 0.1001
2019-10-29 00:53:09,482 Training Epoch [35/40] Iter[190/312]		Loss: 0.1002
2019-10-29 00:53:09,604 Training Epoch [35/40] Iter[191/312]		Loss: 0.1004
2019-10-29 00:53:09,725 Training Epoch [35/40] Iter[192/312]		Loss: 0.1004
2019-10-29 00:53:09,846 Training Epoch [35/40] Iter[193/312]		Loss: 0.1004
2019-10-29 00:53:09,968 Training Epoch [35/40] Iter[194/312]		Loss: 0.1002
2019-10-29 00:53:10,089 Training Epoch [35/40] Iter[195/312]		Loss: 0.1001
2019-10-29 00:53:10,210 Training Epoch [35/40] Iter[196/312]		Loss: 0.1001
2019-10-29 00:53:10,332 Training Epoch [35/40] Iter[197/312]		Loss: 0.1003
2019-10-29 00:53:10,454 Training Epoch [35/40] Iter[198/312]		Loss: 0.1001
2019-10-29 00:53:10,575 Training Epoch [35/40] Iter[199/312]		Loss: 0.1001
2019-10-29 00:53:10,697 Training Epoch [35/40] Iter[200/312]		Loss: 0.0999
2019-10-29 00:53:10,818 Training Epoch [35/40] Iter[201/312]		Loss: 0.0999
2019-10-29 00:53:10,939 Training Epoch [35/40] Iter[202/312]		Loss: 0.0998
2019-10-29 00:53:11,061 Training Epoch [35/40] Iter[203/312]		Loss: 0.0997
2019-10-29 00:53:11,183 Training Epoch [35/40] Iter[204/312]		Loss: 0.0997
2019-10-29 00:53:11,304 Training Epoch [35/40] Iter[205/312]		Loss: 0.0996
2019-10-29 00:53:11,426 Training Epoch [35/40] Iter[206/312]		Loss: 0.0995
2019-10-29 00:53:11,547 Training Epoch [35/40] Iter[207/312]		Loss: 0.0995
2019-10-29 00:53:11,669 Training Epoch [35/40] Iter[208/312]		Loss: 0.0995
2019-10-29 00:53:11,790 Training Epoch [35/40] Iter[209/312]		Loss: 0.0993
2019-10-29 00:53:11,911 Training Epoch [35/40] Iter[210/312]		Loss: 0.0992
2019-10-29 00:53:12,032 Training Epoch [35/40] Iter[211/312]		Loss: 0.0992
2019-10-29 00:53:12,153 Training Epoch [35/40] Iter[212/312]		Loss: 0.0991
2019-10-29 00:53:12,275 Training Epoch [35/40] Iter[213/312]		Loss: 0.0990
2019-10-29 00:53:12,396 Training Epoch [35/40] Iter[214/312]		Loss: 0.0989
2019-10-29 00:53:12,517 Training Epoch [35/40] Iter[215/312]		Loss: 0.0988
2019-10-29 00:53:12,638 Training Epoch [35/40] Iter[216/312]		Loss: 0.0991
2019-10-29 00:53:12,759 Training Epoch [35/40] Iter[217/312]		Loss: 0.0991
2019-10-29 00:53:12,880 Training Epoch [35/40] Iter[218/312]		Loss: 0.0988
2019-10-29 00:53:13,001 Training Epoch [35/40] Iter[219/312]		Loss: 0.0990
2019-10-29 00:53:13,122 Training Epoch [35/40] Iter[220/312]		Loss: 0.0990
2019-10-29 00:53:13,244 Training Epoch [35/40] Iter[221/312]		Loss: 0.0989
2019-10-29 00:53:13,366 Training Epoch [35/40] Iter[222/312]		Loss: 0.0989
2019-10-29 00:53:13,487 Training Epoch [35/40] Iter[223/312]		Loss: 0.0990
2019-10-29 00:53:13,609 Training Epoch [35/40] Iter[224/312]		Loss: 0.0990
2019-10-29 00:53:13,731 Training Epoch [35/40] Iter[225/312]		Loss: 0.0988
2019-10-29 00:53:13,853 Training Epoch [35/40] Iter[226/312]		Loss: 0.0988
2019-10-29 00:53:13,974 Training Epoch [35/40] Iter[227/312]		Loss: 0.0988
2019-10-29 00:53:14,095 Training Epoch [35/40] Iter[228/312]		Loss: 0.0987
2019-10-29 00:53:14,217 Training Epoch [35/40] Iter[229/312]		Loss: 0.0987
2019-10-29 00:53:14,338 Training Epoch [35/40] Iter[230/312]		Loss: 0.0988
2019-10-29 00:53:14,460 Training Epoch [35/40] Iter[231/312]		Loss: 0.0986
2019-10-29 00:53:14,582 Training Epoch [35/40] Iter[232/312]		Loss: 0.0987
2019-10-29 00:53:14,703 Training Epoch [35/40] Iter[233/312]		Loss: 0.0988
2019-10-29 00:53:14,825 Training Epoch [35/40] Iter[234/312]		Loss: 0.0988
2019-10-29 00:53:14,946 Training Epoch [35/40] Iter[235/312]		Loss: 0.0986
2019-10-29 00:53:15,068 Training Epoch [35/40] Iter[236/312]		Loss: 0.0985
2019-10-29 00:53:15,189 Training Epoch [35/40] Iter[237/312]		Loss: 0.0984
2019-10-29 00:53:15,310 Training Epoch [35/40] Iter[238/312]		Loss: 0.0985
2019-10-29 00:53:15,432 Training Epoch [35/40] Iter[239/312]		Loss: 0.0985
2019-10-29 00:53:15,553 Training Epoch [35/40] Iter[240/312]		Loss: 0.0984
2019-10-29 00:53:15,674 Training Epoch [35/40] Iter[241/312]		Loss: 0.0987
2019-10-29 00:53:15,796 Training Epoch [35/40] Iter[242/312]		Loss: 0.0987
2019-10-29 00:53:15,918 Training Epoch [35/40] Iter[243/312]		Loss: 0.0988
2019-10-29 00:53:16,039 Training Epoch [35/40] Iter[244/312]		Loss: 0.0988
2019-10-29 00:53:16,160 Training Epoch [35/40] Iter[245/312]		Loss: 0.0987
2019-10-29 00:53:16,282 Training Epoch [35/40] Iter[246/312]		Loss: 0.0987
2019-10-29 00:53:16,404 Training Epoch [35/40] Iter[247/312]		Loss: 0.0987
2019-10-29 00:53:16,525 Training Epoch [35/40] Iter[248/312]		Loss: 0.0986
2019-10-29 00:53:16,646 Training Epoch [35/40] Iter[249/312]		Loss: 0.0984
2019-10-29 00:53:16,769 Training Epoch [35/40] Iter[250/312]		Loss: 0.0986
2019-10-29 00:53:16,890 Training Epoch [35/40] Iter[251/312]		Loss: 0.0987
2019-10-29 00:53:17,012 Training Epoch [35/40] Iter[252/312]		Loss: 0.0988
2019-10-29 00:53:17,134 Training Epoch [35/40] Iter[253/312]		Loss: 0.0989
2019-10-29 00:53:17,256 Training Epoch [35/40] Iter[254/312]		Loss: 0.0989
2019-10-29 00:53:17,377 Training Epoch [35/40] Iter[255/312]		Loss: 0.0989
2019-10-29 00:53:17,499 Training Epoch [35/40] Iter[256/312]		Loss: 0.0988
2019-10-29 00:53:17,621 Training Epoch [35/40] Iter[257/312]		Loss: 0.0988
2019-10-29 00:53:17,743 Training Epoch [35/40] Iter[258/312]		Loss: 0.0988
2019-10-29 00:53:17,864 Training Epoch [35/40] Iter[259/312]		Loss: 0.0988
2019-10-29 00:53:17,987 Training Epoch [35/40] Iter[260/312]		Loss: 0.0990
2019-10-29 00:53:18,109 Training Epoch [35/40] Iter[261/312]		Loss: 0.0990
2019-10-29 00:53:18,231 Training Epoch [35/40] Iter[262/312]		Loss: 0.0991
2019-10-29 00:53:18,352 Training Epoch [35/40] Iter[263/312]		Loss: 0.0991
2019-10-29 00:53:18,475 Training Epoch [35/40] Iter[264/312]		Loss: 0.0991
2019-10-29 00:53:18,597 Training Epoch [35/40] Iter[265/312]		Loss: 0.0992
2019-10-29 00:53:18,719 Training Epoch [35/40] Iter[266/312]		Loss: 0.0993
2019-10-29 00:53:18,840 Training Epoch [35/40] Iter[267/312]		Loss: 0.0993
2019-10-29 00:53:18,961 Training Epoch [35/40] Iter[268/312]		Loss: 0.0993
2019-10-29 00:53:19,083 Training Epoch [35/40] Iter[269/312]		Loss: 0.0994
2019-10-29 00:53:19,205 Training Epoch [35/40] Iter[270/312]		Loss: 0.0992
2019-10-29 00:53:19,327 Training Epoch [35/40] Iter[271/312]		Loss: 0.0995
2019-10-29 00:53:19,449 Training Epoch [35/40] Iter[272/312]		Loss: 0.0995
2019-10-29 00:53:19,571 Training Epoch [35/40] Iter[273/312]		Loss: 0.0994
2019-10-29 00:53:19,693 Training Epoch [35/40] Iter[274/312]		Loss: 0.0994
2019-10-29 00:53:19,814 Training Epoch [35/40] Iter[275/312]		Loss: 0.0994
2019-10-29 00:53:19,936 Training Epoch [35/40] Iter[276/312]		Loss: 0.0996
2019-10-29 00:53:20,058 Training Epoch [35/40] Iter[277/312]		Loss: 0.0996
2019-10-29 00:53:20,180 Training Epoch [35/40] Iter[278/312]		Loss: 0.0997
2019-10-29 00:53:20,303 Training Epoch [35/40] Iter[279/312]		Loss: 0.0996
2019-10-29 00:53:20,425 Training Epoch [35/40] Iter[280/312]		Loss: 0.0997
2019-10-29 00:53:20,547 Training Epoch [35/40] Iter[281/312]		Loss: 0.0997
2019-10-29 00:53:20,669 Training Epoch [35/40] Iter[282/312]		Loss: 0.0997
2019-10-29 00:53:20,790 Training Epoch [35/40] Iter[283/312]		Loss: 0.0998
2019-10-29 00:53:20,912 Training Epoch [35/40] Iter[284/312]		Loss: 0.0998
2019-10-29 00:53:21,033 Training Epoch [35/40] Iter[285/312]		Loss: 0.0997
2019-10-29 00:53:21,154 Training Epoch [35/40] Iter[286/312]		Loss: 0.0998
2019-10-29 00:53:21,276 Training Epoch [35/40] Iter[287/312]		Loss: 0.0997
2019-10-29 00:53:21,397 Training Epoch [35/40] Iter[288/312]		Loss: 0.0997
2019-10-29 00:53:21,518 Training Epoch [35/40] Iter[289/312]		Loss: 0.0997
2019-10-29 00:53:21,640 Training Epoch [35/40] Iter[290/312]		Loss: 0.0997
2019-10-29 00:53:21,761 Training Epoch [35/40] Iter[291/312]		Loss: 0.0999
2019-10-29 00:53:21,883 Training Epoch [35/40] Iter[292/312]		Loss: 0.0999
2019-10-29 00:53:22,006 Training Epoch [35/40] Iter[293/312]		Loss: 0.0999
2019-10-29 00:53:22,128 Training Epoch [35/40] Iter[294/312]		Loss: 0.0998
2019-10-29 00:53:22,250 Training Epoch [35/40] Iter[295/312]		Loss: 0.0998
2019-10-29 00:53:22,372 Training Epoch [35/40] Iter[296/312]		Loss: 0.1001
2019-10-29 00:53:22,494 Training Epoch [35/40] Iter[297/312]		Loss: 0.1000
2019-10-29 00:53:22,616 Training Epoch [35/40] Iter[298/312]		Loss: 0.0999
2019-10-29 00:53:22,738 Training Epoch [35/40] Iter[299/312]		Loss: 0.1000
2019-10-29 00:53:22,860 Training Epoch [35/40] Iter[300/312]		Loss: 0.1000
2019-10-29 00:53:22,982 Training Epoch [35/40] Iter[301/312]		Loss: 0.0999
2019-10-29 00:53:23,104 Training Epoch [35/40] Iter[302/312]		Loss: 0.0998
2019-10-29 00:53:23,226 Training Epoch [35/40] Iter[303/312]		Loss: 0.0998
2019-10-29 00:53:23,349 Training Epoch [35/40] Iter[304/312]		Loss: 0.0998
2019-10-29 00:53:23,470 Training Epoch [35/40] Iter[305/312]		Loss: 0.0997
2019-10-29 00:53:23,592 Training Epoch [35/40] Iter[306/312]		Loss: 0.0997
2019-10-29 00:53:23,712 Training Epoch [35/40] Iter[307/312]		Loss: 0.0998
2019-10-29 00:53:23,834 Training Epoch [35/40] Iter[308/312]		Loss: 0.0998
2019-10-29 00:53:23,955 Training Epoch [35/40] Iter[309/312]		Loss: 0.0997
2019-10-29 00:53:24,076 Training Epoch [35/40] Iter[310/312]		Loss: 0.0998
2019-10-29 00:53:24,197 Training Epoch [35/40] Iter[311/312]		Loss: 0.0997
2019-10-29 00:53:24,257 Training Epoch [35/40] Iter[312/312]		Loss: 0.0998
2019-10-29 00:53:24,645 Testing Epoch [35/40] Iter[0/62]		Loss: 0.0931
2019-10-29 00:53:24,678 Testing Epoch [35/40] Iter[1/62]		Loss: 0.1281
2019-10-29 00:53:24,711 Testing Epoch [35/40] Iter[2/62]		Loss: 0.1177
2019-10-29 00:53:24,743 Testing Epoch [35/40] Iter[3/62]		Loss: 0.1151
2019-10-29 00:53:24,774 Testing Epoch [35/40] Iter[4/62]		Loss: 0.1113
2019-10-29 00:53:24,806 Testing Epoch [35/40] Iter[5/62]		Loss: 0.1080
2019-10-29 00:53:24,837 Testing Epoch [35/40] Iter[6/62]		Loss: 0.1099
2019-10-29 00:53:24,868 Testing Epoch [35/40] Iter[7/62]		Loss: 0.1153
2019-10-29 00:53:24,902 Testing Epoch [35/40] Iter[8/62]		Loss: 0.1216
2019-10-29 00:53:24,933 Testing Epoch [35/40] Iter[9/62]		Loss: 0.1196
2019-10-29 00:53:24,964 Testing Epoch [35/40] Iter[10/62]		Loss: 0.1179
2019-10-29 00:53:24,998 Testing Epoch [35/40] Iter[11/62]		Loss: 0.1226
2019-10-29 00:53:25,029 Testing Epoch [35/40] Iter[12/62]		Loss: 0.1236
2019-10-29 00:53:25,060 Testing Epoch [35/40] Iter[13/62]		Loss: 0.1256
2019-10-29 00:53:25,097 Testing Epoch [35/40] Iter[14/62]		Loss: 0.1377
2019-10-29 00:53:25,128 Testing Epoch [35/40] Iter[15/62]		Loss: 0.1389
2019-10-29 00:53:25,159 Testing Epoch [35/40] Iter[16/62]		Loss: 0.1370
2019-10-29 00:53:25,191 Testing Epoch [35/40] Iter[17/62]		Loss: 0.1363
2019-10-29 00:53:25,222 Testing Epoch [35/40] Iter[18/62]		Loss: 0.1331
2019-10-29 00:53:25,253 Testing Epoch [35/40] Iter[19/62]		Loss: 0.1309
2019-10-29 00:53:25,284 Testing Epoch [35/40] Iter[20/62]		Loss: 0.1324
2019-10-29 00:53:25,315 Testing Epoch [35/40] Iter[21/62]		Loss: 0.1302
2019-10-29 00:53:25,346 Testing Epoch [35/40] Iter[22/62]		Loss: 0.1296
2019-10-29 00:53:25,378 Testing Epoch [35/40] Iter[23/62]		Loss: 0.1297
2019-10-29 00:53:25,409 Testing Epoch [35/40] Iter[24/62]		Loss: 0.1315
2019-10-29 00:53:25,440 Testing Epoch [35/40] Iter[25/62]		Loss: 0.1309
2019-10-29 00:53:25,470 Testing Epoch [35/40] Iter[26/62]		Loss: 0.1298
2019-10-29 00:53:25,501 Testing Epoch [35/40] Iter[27/62]		Loss: 0.1341
2019-10-29 00:53:25,532 Testing Epoch [35/40] Iter[28/62]		Loss: 0.1360
2019-10-29 00:53:25,563 Testing Epoch [35/40] Iter[29/62]		Loss: 0.1358
2019-10-29 00:53:25,594 Testing Epoch [35/40] Iter[30/62]		Loss: 0.1375
2019-10-29 00:53:25,625 Testing Epoch [35/40] Iter[31/62]		Loss: 0.1368
2019-10-29 00:53:25,656 Testing Epoch [35/40] Iter[32/62]		Loss: 0.1384
2019-10-29 00:53:25,687 Testing Epoch [35/40] Iter[33/62]		Loss: 0.1366
2019-10-29 00:53:25,718 Testing Epoch [35/40] Iter[34/62]		Loss: 0.1382
2019-10-29 00:53:25,749 Testing Epoch [35/40] Iter[35/62]		Loss: 0.1387
2019-10-29 00:53:25,780 Testing Epoch [35/40] Iter[36/62]		Loss: 0.1369
2019-10-29 00:53:25,811 Testing Epoch [35/40] Iter[37/62]		Loss: 0.1364
2019-10-29 00:53:25,842 Testing Epoch [35/40] Iter[38/62]		Loss: 0.1367
2019-10-29 00:53:25,874 Testing Epoch [35/40] Iter[39/62]		Loss: 0.1371
2019-10-29 00:53:25,905 Testing Epoch [35/40] Iter[40/62]		Loss: 0.1374
2019-10-29 00:53:25,936 Testing Epoch [35/40] Iter[41/62]		Loss: 0.1375
2019-10-29 00:53:25,967 Testing Epoch [35/40] Iter[42/62]		Loss: 0.1362
2019-10-29 00:53:25,998 Testing Epoch [35/40] Iter[43/62]		Loss: 0.1356
2019-10-29 00:53:26,029 Testing Epoch [35/40] Iter[44/62]		Loss: 0.1345
2019-10-29 00:53:26,060 Testing Epoch [35/40] Iter[45/62]		Loss: 0.1356
2019-10-29 00:53:26,091 Testing Epoch [35/40] Iter[46/62]		Loss: 0.1356
2019-10-29 00:53:26,122 Testing Epoch [35/40] Iter[47/62]		Loss: 0.1405
2019-10-29 00:53:26,153 Testing Epoch [35/40] Iter[48/62]		Loss: 0.1396
2019-10-29 00:53:26,187 Testing Epoch [35/40] Iter[49/62]		Loss: 0.1410
2019-10-29 00:53:26,218 Testing Epoch [35/40] Iter[50/62]		Loss: 0.1406
2019-10-29 00:53:26,249 Testing Epoch [35/40] Iter[51/62]		Loss: 0.1407
2019-10-29 00:53:26,280 Testing Epoch [35/40] Iter[52/62]		Loss: 0.1397
2019-10-29 00:53:26,311 Testing Epoch [35/40] Iter[53/62]		Loss: 0.1395
2019-10-29 00:53:26,342 Testing Epoch [35/40] Iter[54/62]		Loss: 0.1390
2019-10-29 00:53:26,373 Testing Epoch [35/40] Iter[55/62]		Loss: 0.1391
2019-10-29 00:53:26,404 Testing Epoch [35/40] Iter[56/62]		Loss: 0.1389
2019-10-29 00:53:26,435 Testing Epoch [35/40] Iter[57/62]		Loss: 0.1386
2019-10-29 00:53:26,465 Testing Epoch [35/40] Iter[58/62]		Loss: 0.1382
2019-10-29 00:53:26,497 Testing Epoch [35/40] Iter[59/62]		Loss: 0.1382
2019-10-29 00:53:26,527 Testing Epoch [35/40] Iter[60/62]		Loss: 0.1376
2019-10-29 00:53:26,558 Testing Epoch [35/40] Iter[61/62]		Loss: 0.1373
2019-10-29 00:53:26,576 Testing Epoch [35/40] Iter[62/62]		Loss: 0.1381
2019-10-29 00:53:27,080 Training Epoch [36/40] Iter[0/312]		Loss: 0.0582
2019-10-29 00:53:27,202 Training Epoch [36/40] Iter[1/312]		Loss: 0.0961
2019-10-29 00:53:27,324 Training Epoch [36/40] Iter[2/312]		Loss: 0.0997
2019-10-29 00:53:27,445 Training Epoch [36/40] Iter[3/312]		Loss: 0.0955
2019-10-29 00:53:27,570 Training Epoch [36/40] Iter[4/312]		Loss: 0.0961
2019-10-29 00:53:27,691 Training Epoch [36/40] Iter[5/312]		Loss: 0.0950
2019-10-29 00:53:27,816 Training Epoch [36/40] Iter[6/312]		Loss: 0.0947
2019-10-29 00:53:27,936 Training Epoch [36/40] Iter[7/312]		Loss: 0.0925
2019-10-29 00:53:28,061 Training Epoch [36/40] Iter[8/312]		Loss: 0.0941
2019-10-29 00:53:28,184 Training Epoch [36/40] Iter[9/312]		Loss: 0.0936
2019-10-29 00:53:28,306 Training Epoch [36/40] Iter[10/312]		Loss: 0.0933
2019-10-29 00:53:28,429 Training Epoch [36/40] Iter[11/312]		Loss: 0.0923
2019-10-29 00:53:28,551 Training Epoch [36/40] Iter[12/312]		Loss: 0.0915
2019-10-29 00:53:28,672 Training Epoch [36/40] Iter[13/312]		Loss: 0.0925
2019-10-29 00:53:28,794 Training Epoch [36/40] Iter[14/312]		Loss: 0.0932
2019-10-29 00:53:28,915 Training Epoch [36/40] Iter[15/312]		Loss: 0.0940
2019-10-29 00:53:29,037 Training Epoch [36/40] Iter[16/312]		Loss: 0.0962
2019-10-29 00:53:29,158 Training Epoch [36/40] Iter[17/312]		Loss: 0.0967
2019-10-29 00:53:29,280 Training Epoch [36/40] Iter[18/312]		Loss: 0.0974
2019-10-29 00:53:29,401 Training Epoch [36/40] Iter[19/312]		Loss: 0.0965
2019-10-29 00:53:29,522 Training Epoch [36/40] Iter[20/312]		Loss: 0.0963
2019-10-29 00:53:29,644 Training Epoch [36/40] Iter[21/312]		Loss: 0.0992
2019-10-29 00:53:29,765 Training Epoch [36/40] Iter[22/312]		Loss: 0.0993
2019-10-29 00:53:29,886 Training Epoch [36/40] Iter[23/312]		Loss: 0.0988
2019-10-29 00:53:30,008 Training Epoch [36/40] Iter[24/312]		Loss: 0.0987
2019-10-29 00:53:30,129 Training Epoch [36/40] Iter[25/312]		Loss: 0.1001
2019-10-29 00:53:30,250 Training Epoch [36/40] Iter[26/312]		Loss: 0.0995
2019-10-29 00:53:30,372 Training Epoch [36/40] Iter[27/312]		Loss: 0.0987
2019-10-29 00:53:30,494 Training Epoch [36/40] Iter[28/312]		Loss: 0.0999
2019-10-29 00:53:30,615 Training Epoch [36/40] Iter[29/312]		Loss: 0.1000
2019-10-29 00:53:30,737 Training Epoch [36/40] Iter[30/312]		Loss: 0.0993
2019-10-29 00:53:30,859 Training Epoch [36/40] Iter[31/312]		Loss: 0.0993
2019-10-29 00:53:30,981 Training Epoch [36/40] Iter[32/312]		Loss: 0.0991
2019-10-29 00:53:31,103 Training Epoch [36/40] Iter[33/312]		Loss: 0.0982
2019-10-29 00:53:31,224 Training Epoch [36/40] Iter[34/312]		Loss: 0.0976
2019-10-29 00:53:31,346 Training Epoch [36/40] Iter[35/312]		Loss: 0.0977
2019-10-29 00:53:31,468 Training Epoch [36/40] Iter[36/312]		Loss: 0.0973
2019-10-29 00:53:31,589 Training Epoch [36/40] Iter[37/312]		Loss: 0.0969
2019-10-29 00:53:31,711 Training Epoch [36/40] Iter[38/312]		Loss: 0.0965
2019-10-29 00:53:31,833 Training Epoch [36/40] Iter[39/312]		Loss: 0.0960
2019-10-29 00:53:31,955 Training Epoch [36/40] Iter[40/312]		Loss: 0.0965
2019-10-29 00:53:32,077 Training Epoch [36/40] Iter[41/312]		Loss: 0.0957
2019-10-29 00:53:32,199 Training Epoch [36/40] Iter[42/312]		Loss: 0.0956
2019-10-29 00:53:32,321 Training Epoch [36/40] Iter[43/312]		Loss: 0.0956
2019-10-29 00:53:32,443 Training Epoch [36/40] Iter[44/312]		Loss: 0.0954
2019-10-29 00:53:32,564 Training Epoch [36/40] Iter[45/312]		Loss: 0.0962
2019-10-29 00:53:32,686 Training Epoch [36/40] Iter[46/312]		Loss: 0.0959
2019-10-29 00:53:32,807 Training Epoch [36/40] Iter[47/312]		Loss: 0.0957
2019-10-29 00:53:32,929 Training Epoch [36/40] Iter[48/312]		Loss: 0.0981
2019-10-29 00:53:33,050 Training Epoch [36/40] Iter[49/312]		Loss: 0.0990
2019-10-29 00:53:33,171 Training Epoch [36/40] Iter[50/312]		Loss: 0.0987
2019-10-29 00:53:33,293 Training Epoch [36/40] Iter[51/312]		Loss: 0.0986
2019-10-29 00:53:33,415 Training Epoch [36/40] Iter[52/312]		Loss: 0.0988
2019-10-29 00:53:33,536 Training Epoch [36/40] Iter[53/312]		Loss: 0.0983
2019-10-29 00:53:33,658 Training Epoch [36/40] Iter[54/312]		Loss: 0.0983
2019-10-29 00:53:33,780 Training Epoch [36/40] Iter[55/312]		Loss: 0.0980
2019-10-29 00:53:33,901 Training Epoch [36/40] Iter[56/312]		Loss: 0.0985
2019-10-29 00:53:34,023 Training Epoch [36/40] Iter[57/312]		Loss: 0.0994
2019-10-29 00:53:34,145 Training Epoch [36/40] Iter[58/312]		Loss: 0.0987
2019-10-29 00:53:34,267 Training Epoch [36/40] Iter[59/312]		Loss: 0.0987
2019-10-29 00:53:34,389 Training Epoch [36/40] Iter[60/312]		Loss: 0.0988
2019-10-29 00:53:34,511 Training Epoch [36/40] Iter[61/312]		Loss: 0.0996
2019-10-29 00:53:34,633 Training Epoch [36/40] Iter[62/312]		Loss: 0.1005
2019-10-29 00:53:34,754 Training Epoch [36/40] Iter[63/312]		Loss: 0.1001
2019-10-29 00:53:34,876 Training Epoch [36/40] Iter[64/312]		Loss: 0.1007
2019-10-29 00:53:34,997 Training Epoch [36/40] Iter[65/312]		Loss: 0.1004
2019-10-29 00:53:35,119 Training Epoch [36/40] Iter[66/312]		Loss: 0.1002
2019-10-29 00:53:35,241 Training Epoch [36/40] Iter[67/312]		Loss: 0.1001
2019-10-29 00:53:35,363 Training Epoch [36/40] Iter[68/312]		Loss: 0.1003
2019-10-29 00:53:35,485 Training Epoch [36/40] Iter[69/312]		Loss: 0.1000
2019-10-29 00:53:35,608 Training Epoch [36/40] Iter[70/312]		Loss: 0.1001
2019-10-29 00:53:35,729 Training Epoch [36/40] Iter[71/312]		Loss: 0.0999
2019-10-29 00:53:35,851 Training Epoch [36/40] Iter[72/312]		Loss: 0.0996
2019-10-29 00:53:35,972 Training Epoch [36/40] Iter[73/312]		Loss: 0.0996
2019-10-29 00:53:36,097 Training Epoch [36/40] Iter[74/312]		Loss: 0.0997
2019-10-29 00:53:36,218 Training Epoch [36/40] Iter[75/312]		Loss: 0.1003
2019-10-29 00:53:36,339 Training Epoch [36/40] Iter[76/312]		Loss: 0.1000
2019-10-29 00:53:36,461 Training Epoch [36/40] Iter[77/312]		Loss: 0.0994
2019-10-29 00:53:36,584 Training Epoch [36/40] Iter[78/312]		Loss: 0.0997
2019-10-29 00:53:36,705 Training Epoch [36/40] Iter[79/312]		Loss: 0.1007
2019-10-29 00:53:36,826 Training Epoch [36/40] Iter[80/312]		Loss: 0.1003
2019-10-29 00:53:36,947 Training Epoch [36/40] Iter[81/312]		Loss: 0.1000
2019-10-29 00:53:37,069 Training Epoch [36/40] Iter[82/312]		Loss: 0.0998
2019-10-29 00:53:37,190 Training Epoch [36/40] Iter[83/312]		Loss: 0.1000
2019-10-29 00:53:37,312 Training Epoch [36/40] Iter[84/312]		Loss: 0.1006
2019-10-29 00:53:37,433 Training Epoch [36/40] Iter[85/312]		Loss: 0.1003
2019-10-29 00:53:37,555 Training Epoch [36/40] Iter[86/312]		Loss: 0.1005
2019-10-29 00:53:37,676 Training Epoch [36/40] Iter[87/312]		Loss: 0.1003
2019-10-29 00:53:37,797 Training Epoch [36/40] Iter[88/312]		Loss: 0.0999
2019-10-29 00:53:37,918 Training Epoch [36/40] Iter[89/312]		Loss: 0.1001
2019-10-29 00:53:38,040 Training Epoch [36/40] Iter[90/312]		Loss: 0.1003
2019-10-29 00:53:38,161 Training Epoch [36/40] Iter[91/312]		Loss: 0.1000
2019-10-29 00:53:38,282 Training Epoch [36/40] Iter[92/312]		Loss: 0.0997
2019-10-29 00:53:38,404 Training Epoch [36/40] Iter[93/312]		Loss: 0.0995
2019-10-29 00:53:38,525 Training Epoch [36/40] Iter[94/312]		Loss: 0.0999
2019-10-29 00:53:38,646 Training Epoch [36/40] Iter[95/312]		Loss: 0.0998
2019-10-29 00:53:38,767 Training Epoch [36/40] Iter[96/312]		Loss: 0.0999
2019-10-29 00:53:38,888 Training Epoch [36/40] Iter[97/312]		Loss: 0.0998
2019-10-29 00:53:39,009 Training Epoch [36/40] Iter[98/312]		Loss: 0.0997
2019-10-29 00:53:39,130 Training Epoch [36/40] Iter[99/312]		Loss: 0.0999
2019-10-29 00:53:39,252 Training Epoch [36/40] Iter[100/312]		Loss: 0.0996
2019-10-29 00:53:39,374 Training Epoch [36/40] Iter[101/312]		Loss: 0.0996
2019-10-29 00:53:39,496 Training Epoch [36/40] Iter[102/312]		Loss: 0.0994
2019-10-29 00:53:39,617 Training Epoch [36/40] Iter[103/312]		Loss: 0.0992
2019-10-29 00:53:39,740 Training Epoch [36/40] Iter[104/312]		Loss: 0.0992
2019-10-29 00:53:39,862 Training Epoch [36/40] Iter[105/312]		Loss: 0.0995
2019-10-29 00:53:39,983 Training Epoch [36/40] Iter[106/312]		Loss: 0.0994
2019-10-29 00:53:40,104 Training Epoch [36/40] Iter[107/312]		Loss: 0.0996
2019-10-29 00:53:40,225 Training Epoch [36/40] Iter[108/312]		Loss: 0.0995
2019-10-29 00:53:40,347 Training Epoch [36/40] Iter[109/312]		Loss: 0.0997
2019-10-29 00:53:40,469 Training Epoch [36/40] Iter[110/312]		Loss: 0.0994
2019-10-29 00:53:40,591 Training Epoch [36/40] Iter[111/312]		Loss: 0.0997
2019-10-29 00:53:40,712 Training Epoch [36/40] Iter[112/312]		Loss: 0.0995
2019-10-29 00:53:40,833 Training Epoch [36/40] Iter[113/312]		Loss: 0.0994
2019-10-29 00:53:40,955 Training Epoch [36/40] Iter[114/312]		Loss: 0.0997
2019-10-29 00:53:41,077 Training Epoch [36/40] Iter[115/312]		Loss: 0.0995
2019-10-29 00:53:41,199 Training Epoch [36/40] Iter[116/312]		Loss: 0.0996
2019-10-29 00:53:41,320 Training Epoch [36/40] Iter[117/312]		Loss: 0.0999
2019-10-29 00:53:41,441 Training Epoch [36/40] Iter[118/312]		Loss: 0.1000
2019-10-29 00:53:41,563 Training Epoch [36/40] Iter[119/312]		Loss: 0.1000
2019-10-29 00:53:41,685 Training Epoch [36/40] Iter[120/312]		Loss: 0.1004
2019-10-29 00:53:41,807 Training Epoch [36/40] Iter[121/312]		Loss: 0.1004
2019-10-29 00:53:41,929 Training Epoch [36/40] Iter[122/312]		Loss: 0.1005
2019-10-29 00:53:42,050 Training Epoch [36/40] Iter[123/312]		Loss: 0.1003
2019-10-29 00:53:42,172 Training Epoch [36/40] Iter[124/312]		Loss: 0.1006
2019-10-29 00:53:42,293 Training Epoch [36/40] Iter[125/312]		Loss: 0.1005
2019-10-29 00:53:42,414 Training Epoch [36/40] Iter[126/312]		Loss: 0.1002
2019-10-29 00:53:42,535 Training Epoch [36/40] Iter[127/312]		Loss: 0.1001
2019-10-29 00:53:42,657 Training Epoch [36/40] Iter[128/312]		Loss: 0.1004
2019-10-29 00:53:42,778 Training Epoch [36/40] Iter[129/312]		Loss: 0.1002
2019-10-29 00:53:42,900 Training Epoch [36/40] Iter[130/312]		Loss: 0.0999
2019-10-29 00:53:43,021 Training Epoch [36/40] Iter[131/312]		Loss: 0.0998
2019-10-29 00:53:43,142 Training Epoch [36/40] Iter[132/312]		Loss: 0.0999
2019-10-29 00:53:43,264 Training Epoch [36/40] Iter[133/312]		Loss: 0.1001
2019-10-29 00:53:43,386 Training Epoch [36/40] Iter[134/312]		Loss: 0.0999
2019-10-29 00:53:43,507 Training Epoch [36/40] Iter[135/312]		Loss: 0.0999
2019-10-29 00:53:43,628 Training Epoch [36/40] Iter[136/312]		Loss: 0.0999
2019-10-29 00:53:43,750 Training Epoch [36/40] Iter[137/312]		Loss: 0.0998
2019-10-29 00:53:43,871 Training Epoch [36/40] Iter[138/312]		Loss: 0.0999
2019-10-29 00:53:43,993 Training Epoch [36/40] Iter[139/312]		Loss: 0.1000
2019-10-29 00:53:44,115 Training Epoch [36/40] Iter[140/312]		Loss: 0.1001
2019-10-29 00:53:44,237 Training Epoch [36/40] Iter[141/312]		Loss: 0.1001
2019-10-29 00:53:44,359 Training Epoch [36/40] Iter[142/312]		Loss: 0.1003
2019-10-29 00:53:44,481 Training Epoch [36/40] Iter[143/312]		Loss: 0.1008
2019-10-29 00:53:44,603 Training Epoch [36/40] Iter[144/312]		Loss: 0.1006
2019-10-29 00:53:44,724 Training Epoch [36/40] Iter[145/312]		Loss: 0.1006
2019-10-29 00:53:44,846 Training Epoch [36/40] Iter[146/312]		Loss: 0.1004
2019-10-29 00:53:44,968 Training Epoch [36/40] Iter[147/312]		Loss: 0.1002
2019-10-29 00:53:45,089 Training Epoch [36/40] Iter[148/312]		Loss: 0.1004
2019-10-29 00:53:45,210 Training Epoch [36/40] Iter[149/312]		Loss: 0.1003
2019-10-29 00:53:45,332 Training Epoch [36/40] Iter[150/312]		Loss: 0.1001
2019-10-29 00:53:45,454 Training Epoch [36/40] Iter[151/312]		Loss: 0.1002
2019-10-29 00:53:45,575 Training Epoch [36/40] Iter[152/312]		Loss: 0.1000
2019-10-29 00:53:45,697 Training Epoch [36/40] Iter[153/312]		Loss: 0.1001
2019-10-29 00:53:45,819 Training Epoch [36/40] Iter[154/312]		Loss: 0.1003
2019-10-29 00:53:45,940 Training Epoch [36/40] Iter[155/312]		Loss: 0.1003
2019-10-29 00:53:46,061 Training Epoch [36/40] Iter[156/312]		Loss: 0.1002
2019-10-29 00:53:46,183 Training Epoch [36/40] Iter[157/312]		Loss: 0.1003
2019-10-29 00:53:46,304 Training Epoch [36/40] Iter[158/312]		Loss: 0.1011
2019-10-29 00:53:46,426 Training Epoch [36/40] Iter[159/312]		Loss: 0.1010
2019-10-29 00:53:46,547 Training Epoch [36/40] Iter[160/312]		Loss: 0.1014
2019-10-29 00:53:46,668 Training Epoch [36/40] Iter[161/312]		Loss: 0.1012
2019-10-29 00:53:46,790 Training Epoch [36/40] Iter[162/312]		Loss: 0.1012
2019-10-29 00:53:46,911 Training Epoch [36/40] Iter[163/312]		Loss: 0.1010
2019-10-29 00:53:47,032 Training Epoch [36/40] Iter[164/312]		Loss: 0.1008
2019-10-29 00:53:47,153 Training Epoch [36/40] Iter[165/312]		Loss: 0.1005
2019-10-29 00:53:47,274 Training Epoch [36/40] Iter[166/312]		Loss: 0.1005
2019-10-29 00:53:47,396 Training Epoch [36/40] Iter[167/312]		Loss: 0.1003
2019-10-29 00:53:47,518 Training Epoch [36/40] Iter[168/312]		Loss: 0.1003
2019-10-29 00:53:47,640 Training Epoch [36/40] Iter[169/312]		Loss: 0.1000
2019-10-29 00:53:47,762 Training Epoch [36/40] Iter[170/312]		Loss: 0.1001
2019-10-29 00:53:47,884 Training Epoch [36/40] Iter[171/312]		Loss: 0.1000
2019-10-29 00:53:48,006 Training Epoch [36/40] Iter[172/312]		Loss: 0.1000
2019-10-29 00:53:48,129 Training Epoch [36/40] Iter[173/312]		Loss: 0.0998
2019-10-29 00:53:48,251 Training Epoch [36/40] Iter[174/312]		Loss: 0.1000
2019-10-29 00:53:48,373 Training Epoch [36/40] Iter[175/312]		Loss: 0.1001
2019-10-29 00:53:48,495 Training Epoch [36/40] Iter[176/312]		Loss: 0.1000
2019-10-29 00:53:48,616 Training Epoch [36/40] Iter[177/312]		Loss: 0.0999
2019-10-29 00:53:48,737 Training Epoch [36/40] Iter[178/312]		Loss: 0.0998
2019-10-29 00:53:48,859 Training Epoch [36/40] Iter[179/312]		Loss: 0.0995
2019-10-29 00:53:48,980 Training Epoch [36/40] Iter[180/312]		Loss: 0.0995
2019-10-29 00:53:49,102 Training Epoch [36/40] Iter[181/312]		Loss: 0.0998
2019-10-29 00:53:49,224 Training Epoch [36/40] Iter[182/312]		Loss: 0.1000
2019-10-29 00:53:49,347 Training Epoch [36/40] Iter[183/312]		Loss: 0.1000
2019-10-29 00:53:49,468 Training Epoch [36/40] Iter[184/312]		Loss: 0.0998
2019-10-29 00:53:49,589 Training Epoch [36/40] Iter[185/312]		Loss: 0.0997
2019-10-29 00:53:49,711 Training Epoch [36/40] Iter[186/312]		Loss: 0.0999
2019-10-29 00:53:49,832 Training Epoch [36/40] Iter[187/312]		Loss: 0.1000
2019-10-29 00:53:49,954 Training Epoch [36/40] Iter[188/312]		Loss: 0.1001
2019-10-29 00:53:50,075 Training Epoch [36/40] Iter[189/312]		Loss: 0.1001
2019-10-29 00:53:50,196 Training Epoch [36/40] Iter[190/312]		Loss: 0.1001
2019-10-29 00:53:50,318 Training Epoch [36/40] Iter[191/312]		Loss: 0.1002
2019-10-29 00:53:50,440 Training Epoch [36/40] Iter[192/312]		Loss: 0.1002
2019-10-29 00:53:50,561 Training Epoch [36/40] Iter[193/312]		Loss: 0.1001
2019-10-29 00:53:50,683 Training Epoch [36/40] Iter[194/312]		Loss: 0.1003
2019-10-29 00:53:50,804 Training Epoch [36/40] Iter[195/312]		Loss: 0.1006
2019-10-29 00:53:50,926 Training Epoch [36/40] Iter[196/312]		Loss: 0.1005
2019-10-29 00:53:51,047 Training Epoch [36/40] Iter[197/312]		Loss: 0.1004
2019-10-29 00:53:51,169 Training Epoch [36/40] Iter[198/312]		Loss: 0.1005
2019-10-29 00:53:51,291 Training Epoch [36/40] Iter[199/312]		Loss: 0.1006
2019-10-29 00:53:51,413 Training Epoch [36/40] Iter[200/312]		Loss: 0.1005
2019-10-29 00:53:51,534 Training Epoch [36/40] Iter[201/312]		Loss: 0.1006
2019-10-29 00:53:51,661 Training Epoch [36/40] Iter[202/312]		Loss: 0.1005
2019-10-29 00:53:51,783 Training Epoch [36/40] Iter[203/312]		Loss: 0.1005
2019-10-29 00:53:51,905 Training Epoch [36/40] Iter[204/312]		Loss: 0.1005
2019-10-29 00:53:52,026 Training Epoch [36/40] Iter[205/312]		Loss: 0.1006
2019-10-29 00:53:52,148 Training Epoch [36/40] Iter[206/312]		Loss: 0.1005
2019-10-29 00:53:52,269 Training Epoch [36/40] Iter[207/312]		Loss: 0.1004
2019-10-29 00:53:52,391 Training Epoch [36/40] Iter[208/312]		Loss: 0.1005
2019-10-29 00:53:52,513 Training Epoch [36/40] Iter[209/312]		Loss: 0.1005
2019-10-29 00:53:52,635 Training Epoch [36/40] Iter[210/312]		Loss: 0.1004
2019-10-29 00:53:52,757 Training Epoch [36/40] Iter[211/312]		Loss: 0.1002
2019-10-29 00:53:52,879 Training Epoch [36/40] Iter[212/312]		Loss: 0.1003
2019-10-29 00:53:53,005 Training Epoch [36/40] Iter[213/312]		Loss: 0.1004
2019-10-29 00:53:53,127 Training Epoch [36/40] Iter[214/312]		Loss: 0.1005
2019-10-29 00:53:53,249 Training Epoch [36/40] Iter[215/312]		Loss: 0.1005
2019-10-29 00:53:53,371 Training Epoch [36/40] Iter[216/312]		Loss: 0.1004
2019-10-29 00:53:53,492 Training Epoch [36/40] Iter[217/312]		Loss: 0.1004
2019-10-29 00:53:53,614 Training Epoch [36/40] Iter[218/312]		Loss: 0.1002
2019-10-29 00:53:53,736 Training Epoch [36/40] Iter[219/312]		Loss: 0.1003
2019-10-29 00:53:53,858 Training Epoch [36/40] Iter[220/312]		Loss: 0.1002
2019-10-29 00:53:53,979 Training Epoch [36/40] Iter[221/312]		Loss: 0.1003
2019-10-29 00:53:54,101 Training Epoch [36/40] Iter[222/312]		Loss: 0.1003
2019-10-29 00:53:54,223 Training Epoch [36/40] Iter[223/312]		Loss: 0.1002
2019-10-29 00:53:54,345 Training Epoch [36/40] Iter[224/312]		Loss: 0.1002
2019-10-29 00:53:54,467 Training Epoch [36/40] Iter[225/312]		Loss: 0.1001
2019-10-29 00:53:54,588 Training Epoch [36/40] Iter[226/312]		Loss: 0.1001
2019-10-29 00:53:54,710 Training Epoch [36/40] Iter[227/312]		Loss: 0.1001
2019-10-29 00:53:54,831 Training Epoch [36/40] Iter[228/312]		Loss: 0.1000
2019-10-29 00:53:54,953 Training Epoch [36/40] Iter[229/312]		Loss: 0.0999
2019-10-29 00:53:55,075 Training Epoch [36/40] Iter[230/312]		Loss: 0.1000
2019-10-29 00:53:55,196 Training Epoch [36/40] Iter[231/312]		Loss: 0.0999
2019-10-29 00:53:55,317 Training Epoch [36/40] Iter[232/312]		Loss: 0.1001
2019-10-29 00:53:55,439 Training Epoch [36/40] Iter[233/312]		Loss: 0.1001
2019-10-29 00:53:55,560 Training Epoch [36/40] Iter[234/312]		Loss: 0.1001
2019-10-29 00:53:55,681 Training Epoch [36/40] Iter[235/312]		Loss: 0.1003
2019-10-29 00:53:55,803 Training Epoch [36/40] Iter[236/312]		Loss: 0.1001
2019-10-29 00:53:55,923 Training Epoch [36/40] Iter[237/312]		Loss: 0.1002
2019-10-29 00:53:56,045 Training Epoch [36/40] Iter[238/312]		Loss: 0.1004
2019-10-29 00:53:56,166 Training Epoch [36/40] Iter[239/312]		Loss: 0.1003
2019-10-29 00:53:56,288 Training Epoch [36/40] Iter[240/312]		Loss: 0.1004
2019-10-29 00:53:56,409 Training Epoch [36/40] Iter[241/312]		Loss: 0.1005
2019-10-29 00:53:56,530 Training Epoch [36/40] Iter[242/312]		Loss: 0.1004
2019-10-29 00:53:56,652 Training Epoch [36/40] Iter[243/312]		Loss: 0.1005
2019-10-29 00:53:56,773 Training Epoch [36/40] Iter[244/312]		Loss: 0.1005
2019-10-29 00:53:56,895 Training Epoch [36/40] Iter[245/312]		Loss: 0.1007
2019-10-29 00:53:57,017 Training Epoch [36/40] Iter[246/312]		Loss: 0.1006
2019-10-29 00:53:57,138 Training Epoch [36/40] Iter[247/312]		Loss: 0.1004
2019-10-29 00:53:57,260 Training Epoch [36/40] Iter[248/312]		Loss: 0.1004
2019-10-29 00:53:57,383 Training Epoch [36/40] Iter[249/312]		Loss: 0.1005
2019-10-29 00:53:57,504 Training Epoch [36/40] Iter[250/312]		Loss: 0.1004
2019-10-29 00:53:57,626 Training Epoch [36/40] Iter[251/312]		Loss: 0.1004
2019-10-29 00:53:57,748 Training Epoch [36/40] Iter[252/312]		Loss: 0.1004
2019-10-29 00:53:57,869 Training Epoch [36/40] Iter[253/312]		Loss: 0.1002
2019-10-29 00:53:57,991 Training Epoch [36/40] Iter[254/312]		Loss: 0.1002
2019-10-29 00:53:58,113 Training Epoch [36/40] Iter[255/312]		Loss: 0.1003
2019-10-29 00:53:58,236 Training Epoch [36/40] Iter[256/312]		Loss: 0.1001
2019-10-29 00:53:58,357 Training Epoch [36/40] Iter[257/312]		Loss: 0.1002
2019-10-29 00:53:58,479 Training Epoch [36/40] Iter[258/312]		Loss: 0.1002
2019-10-29 00:53:58,600 Training Epoch [36/40] Iter[259/312]		Loss: 0.1002
2019-10-29 00:53:58,721 Training Epoch [36/40] Iter[260/312]		Loss: 0.1002
2019-10-29 00:53:58,842 Training Epoch [36/40] Iter[261/312]		Loss: 0.1000
2019-10-29 00:53:58,964 Training Epoch [36/40] Iter[262/312]		Loss: 0.1000
2019-10-29 00:53:59,085 Training Epoch [36/40] Iter[263/312]		Loss: 0.0999
2019-10-29 00:53:59,207 Training Epoch [36/40] Iter[264/312]		Loss: 0.1000
2019-10-29 00:53:59,333 Training Epoch [36/40] Iter[265/312]		Loss: 0.1000
2019-10-29 00:53:59,455 Training Epoch [36/40] Iter[266/312]		Loss: 0.1001
2019-10-29 00:53:59,576 Training Epoch [36/40] Iter[267/312]		Loss: 0.1002
2019-10-29 00:53:59,697 Training Epoch [36/40] Iter[268/312]		Loss: 0.1002
2019-10-29 00:53:59,818 Training Epoch [36/40] Iter[269/312]		Loss: 0.1002
2019-10-29 00:53:59,940 Training Epoch [36/40] Iter[270/312]		Loss: 0.1001
2019-10-29 00:54:00,062 Training Epoch [36/40] Iter[271/312]		Loss: 0.1000
2019-10-29 00:54:00,184 Training Epoch [36/40] Iter[272/312]		Loss: 0.0999
2019-10-29 00:54:00,306 Training Epoch [36/40] Iter[273/312]		Loss: 0.1000
2019-10-29 00:54:00,427 Training Epoch [36/40] Iter[274/312]		Loss: 0.1003
2019-10-29 00:54:00,549 Training Epoch [36/40] Iter[275/312]		Loss: 0.1002
2019-10-29 00:54:00,671 Training Epoch [36/40] Iter[276/312]		Loss: 0.1001
2019-10-29 00:54:00,793 Training Epoch [36/40] Iter[277/312]		Loss: 0.1003
2019-10-29 00:54:00,915 Training Epoch [36/40] Iter[278/312]		Loss: 0.1002
2019-10-29 00:54:01,036 Training Epoch [36/40] Iter[279/312]		Loss: 0.1002
2019-10-29 00:54:01,158 Training Epoch [36/40] Iter[280/312]		Loss: 0.1002
2019-10-29 00:54:01,280 Training Epoch [36/40] Iter[281/312]		Loss: 0.1003
2019-10-29 00:54:01,402 Training Epoch [36/40] Iter[282/312]		Loss: 0.1002
2019-10-29 00:54:01,524 Training Epoch [36/40] Iter[283/312]		Loss: 0.1001
2019-10-29 00:54:01,646 Training Epoch [36/40] Iter[284/312]		Loss: 0.1000
2019-10-29 00:54:01,767 Training Epoch [36/40] Iter[285/312]		Loss: 0.1001
2019-10-29 00:54:01,889 Training Epoch [36/40] Iter[286/312]		Loss: 0.1001
2019-10-29 00:54:02,011 Training Epoch [36/40] Iter[287/312]		Loss: 0.1001
2019-10-29 00:54:02,136 Training Epoch [36/40] Iter[288/312]		Loss: 0.1002
2019-10-29 00:54:02,258 Training Epoch [36/40] Iter[289/312]		Loss: 0.1003
2019-10-29 00:54:02,379 Training Epoch [36/40] Iter[290/312]		Loss: 0.1003
2019-10-29 00:54:02,501 Training Epoch [36/40] Iter[291/312]		Loss: 0.1002
2019-10-29 00:54:02,623 Training Epoch [36/40] Iter[292/312]		Loss: 0.1002
2019-10-29 00:54:02,744 Training Epoch [36/40] Iter[293/312]		Loss: 0.1001
2019-10-29 00:54:02,865 Training Epoch [36/40] Iter[294/312]		Loss: 0.1004
2019-10-29 00:54:02,987 Training Epoch [36/40] Iter[295/312]		Loss: 0.1003
2019-10-29 00:54:03,108 Training Epoch [36/40] Iter[296/312]		Loss: 0.1003
2019-10-29 00:54:03,230 Training Epoch [36/40] Iter[297/312]		Loss: 0.1003
2019-10-29 00:54:03,351 Training Epoch [36/40] Iter[298/312]		Loss: 0.1005
2019-10-29 00:54:03,473 Training Epoch [36/40] Iter[299/312]		Loss: 0.1005
2019-10-29 00:54:03,595 Training Epoch [36/40] Iter[300/312]		Loss: 0.1005
2019-10-29 00:54:03,716 Training Epoch [36/40] Iter[301/312]		Loss: 0.1005
2019-10-29 00:54:03,838 Training Epoch [36/40] Iter[302/312]		Loss: 0.1004
2019-10-29 00:54:03,959 Training Epoch [36/40] Iter[303/312]		Loss: 0.1004
2019-10-29 00:54:04,081 Training Epoch [36/40] Iter[304/312]		Loss: 0.1003
2019-10-29 00:54:04,202 Training Epoch [36/40] Iter[305/312]		Loss: 0.1001
2019-10-29 00:54:04,322 Training Epoch [36/40] Iter[306/312]		Loss: 0.1004
2019-10-29 00:54:04,443 Training Epoch [36/40] Iter[307/312]		Loss: 0.1004
2019-10-29 00:54:04,564 Training Epoch [36/40] Iter[308/312]		Loss: 0.1004
2019-10-29 00:54:04,685 Training Epoch [36/40] Iter[309/312]		Loss: 0.1004
2019-10-29 00:54:04,805 Training Epoch [36/40] Iter[310/312]		Loss: 0.1003
2019-10-29 00:54:04,926 Training Epoch [36/40] Iter[311/312]		Loss: 0.1004
2019-10-29 00:54:04,986 Training Epoch [36/40] Iter[312/312]		Loss: 0.1002
2019-10-29 00:54:05,374 Testing Epoch [36/40] Iter[0/62]		Loss: 0.0891
2019-10-29 00:54:05,414 Testing Epoch [36/40] Iter[1/62]		Loss: 0.1259
2019-10-29 00:54:05,446 Testing Epoch [36/40] Iter[2/62]		Loss: 0.1165
2019-10-29 00:54:05,476 Testing Epoch [36/40] Iter[3/62]		Loss: 0.1149
2019-10-29 00:54:05,510 Testing Epoch [36/40] Iter[4/62]		Loss: 0.1108
2019-10-29 00:54:05,540 Testing Epoch [36/40] Iter[5/62]		Loss: 0.1084
2019-10-29 00:54:05,570 Testing Epoch [36/40] Iter[6/62]		Loss: 0.1089
2019-10-29 00:54:05,602 Testing Epoch [36/40] Iter[7/62]		Loss: 0.1150
2019-10-29 00:54:05,633 Testing Epoch [36/40] Iter[8/62]		Loss: 0.1207
2019-10-29 00:54:05,664 Testing Epoch [36/40] Iter[9/62]		Loss: 0.1182
2019-10-29 00:54:05,701 Testing Epoch [36/40] Iter[10/62]		Loss: 0.1165
2019-10-29 00:54:05,733 Testing Epoch [36/40] Iter[11/62]		Loss: 0.1214
2019-10-29 00:54:05,764 Testing Epoch [36/40] Iter[12/62]		Loss: 0.1220
2019-10-29 00:54:05,795 Testing Epoch [36/40] Iter[13/62]		Loss: 0.1241
2019-10-29 00:54:05,826 Testing Epoch [36/40] Iter[14/62]		Loss: 0.1360
2019-10-29 00:54:05,857 Testing Epoch [36/40] Iter[15/62]		Loss: 0.1375
2019-10-29 00:54:05,889 Testing Epoch [36/40] Iter[16/62]		Loss: 0.1354
2019-10-29 00:54:05,919 Testing Epoch [36/40] Iter[17/62]		Loss: 0.1346
2019-10-29 00:54:05,950 Testing Epoch [36/40] Iter[18/62]		Loss: 0.1313
2019-10-29 00:54:05,981 Testing Epoch [36/40] Iter[19/62]		Loss: 0.1293
2019-10-29 00:54:06,012 Testing Epoch [36/40] Iter[20/62]		Loss: 0.1309
2019-10-29 00:54:06,043 Testing Epoch [36/40] Iter[21/62]		Loss: 0.1288
2019-10-29 00:54:06,074 Testing Epoch [36/40] Iter[22/62]		Loss: 0.1284
2019-10-29 00:54:06,105 Testing Epoch [36/40] Iter[23/62]		Loss: 0.1282
2019-10-29 00:54:06,136 Testing Epoch [36/40] Iter[24/62]		Loss: 0.1302
2019-10-29 00:54:06,167 Testing Epoch [36/40] Iter[25/62]		Loss: 0.1296
2019-10-29 00:54:06,198 Testing Epoch [36/40] Iter[26/62]		Loss: 0.1286
2019-10-29 00:54:06,229 Testing Epoch [36/40] Iter[27/62]		Loss: 0.1329
2019-10-29 00:54:06,260 Testing Epoch [36/40] Iter[28/62]		Loss: 0.1346
2019-10-29 00:54:06,291 Testing Epoch [36/40] Iter[29/62]		Loss: 0.1344
2019-10-29 00:54:06,323 Testing Epoch [36/40] Iter[30/62]		Loss: 0.1362
2019-10-29 00:54:06,354 Testing Epoch [36/40] Iter[31/62]		Loss: 0.1354
2019-10-29 00:54:06,390 Testing Epoch [36/40] Iter[32/62]		Loss: 0.1369
2019-10-29 00:54:06,422 Testing Epoch [36/40] Iter[33/62]		Loss: 0.1351
2019-10-29 00:54:06,453 Testing Epoch [36/40] Iter[34/62]		Loss: 0.1367
2019-10-29 00:54:06,486 Testing Epoch [36/40] Iter[35/62]		Loss: 0.1373
2019-10-29 00:54:06,518 Testing Epoch [36/40] Iter[36/62]		Loss: 0.1354
2019-10-29 00:54:06,549 Testing Epoch [36/40] Iter[37/62]		Loss: 0.1349
2019-10-29 00:54:06,581 Testing Epoch [36/40] Iter[38/62]		Loss: 0.1352
2019-10-29 00:54:06,614 Testing Epoch [36/40] Iter[39/62]		Loss: 0.1355
2019-10-29 00:54:06,645 Testing Epoch [36/40] Iter[40/62]		Loss: 0.1360
2019-10-29 00:54:06,676 Testing Epoch [36/40] Iter[41/62]		Loss: 0.1360
2019-10-29 00:54:06,713 Testing Epoch [36/40] Iter[42/62]		Loss: 0.1347
2019-10-29 00:54:06,745 Testing Epoch [36/40] Iter[43/62]		Loss: 0.1343
2019-10-29 00:54:06,776 Testing Epoch [36/40] Iter[44/62]		Loss: 0.1331
2019-10-29 00:54:06,808 Testing Epoch [36/40] Iter[45/62]		Loss: 0.1341
2019-10-29 00:54:06,839 Testing Epoch [36/40] Iter[46/62]		Loss: 0.1343
2019-10-29 00:54:06,871 Testing Epoch [36/40] Iter[47/62]		Loss: 0.1393
2019-10-29 00:54:06,902 Testing Epoch [36/40] Iter[48/62]		Loss: 0.1383
2019-10-29 00:54:06,933 Testing Epoch [36/40] Iter[49/62]		Loss: 0.1397
2019-10-29 00:54:06,964 Testing Epoch [36/40] Iter[50/62]		Loss: 0.1394
2019-10-29 00:54:06,995 Testing Epoch [36/40] Iter[51/62]		Loss: 0.1396
2019-10-29 00:54:07,026 Testing Epoch [36/40] Iter[52/62]		Loss: 0.1385
2019-10-29 00:54:07,057 Testing Epoch [36/40] Iter[53/62]		Loss: 0.1382
2019-10-29 00:54:07,088 Testing Epoch [36/40] Iter[54/62]		Loss: 0.1377
2019-10-29 00:54:07,118 Testing Epoch [36/40] Iter[55/62]		Loss: 0.1378
2019-10-29 00:54:07,149 Testing Epoch [36/40] Iter[56/62]		Loss: 0.1377
2019-10-29 00:54:07,180 Testing Epoch [36/40] Iter[57/62]		Loss: 0.1375
2019-10-29 00:54:07,210 Testing Epoch [36/40] Iter[58/62]		Loss: 0.1371
2019-10-29 00:54:07,241 Testing Epoch [36/40] Iter[59/62]		Loss: 0.1371
2019-10-29 00:54:07,271 Testing Epoch [36/40] Iter[60/62]		Loss: 0.1365
2019-10-29 00:54:07,302 Testing Epoch [36/40] Iter[61/62]		Loss: 0.1361
2019-10-29 00:54:07,319 Testing Epoch [36/40] Iter[62/62]		Loss: 0.1369
2019-10-29 00:54:07,816 Training Epoch [37/40] Iter[0/312]		Loss: 0.0981
2019-10-29 00:54:07,940 Training Epoch [37/40] Iter[1/312]		Loss: 0.0884
2019-10-29 00:54:08,061 Training Epoch [37/40] Iter[2/312]		Loss: 0.0866
2019-10-29 00:54:08,182 Training Epoch [37/40] Iter[3/312]		Loss: 0.0935
2019-10-29 00:54:08,305 Training Epoch [37/40] Iter[4/312]		Loss: 0.0894
2019-10-29 00:54:08,425 Training Epoch [37/40] Iter[5/312]		Loss: 0.0866
2019-10-29 00:54:08,547 Training Epoch [37/40] Iter[6/312]		Loss: 0.0881
2019-10-29 00:54:08,668 Training Epoch [37/40] Iter[7/312]		Loss: 0.0908
2019-10-29 00:54:08,790 Training Epoch [37/40] Iter[8/312]		Loss: 0.0925
2019-10-29 00:54:08,911 Training Epoch [37/40] Iter[9/312]		Loss: 0.0910
2019-10-29 00:54:09,032 Training Epoch [37/40] Iter[10/312]		Loss: 0.0906
2019-10-29 00:54:09,154 Training Epoch [37/40] Iter[11/312]		Loss: 0.0880
2019-10-29 00:54:09,275 Training Epoch [37/40] Iter[12/312]		Loss: 0.0890
2019-10-29 00:54:09,397 Training Epoch [37/40] Iter[13/312]		Loss: 0.0900
2019-10-29 00:54:09,518 Training Epoch [37/40] Iter[14/312]		Loss: 0.0883
2019-10-29 00:54:09,640 Training Epoch [37/40] Iter[15/312]		Loss: 0.0877
2019-10-29 00:54:09,761 Training Epoch [37/40] Iter[16/312]		Loss: 0.0938
2019-10-29 00:54:09,883 Training Epoch [37/40] Iter[17/312]		Loss: 0.0946
2019-10-29 00:54:10,004 Training Epoch [37/40] Iter[18/312]		Loss: 0.0953
2019-10-29 00:54:10,125 Training Epoch [37/40] Iter[19/312]		Loss: 0.0950
2019-10-29 00:54:10,247 Training Epoch [37/40] Iter[20/312]		Loss: 0.0973
2019-10-29 00:54:10,369 Training Epoch [37/40] Iter[21/312]		Loss: 0.0970
2019-10-29 00:54:10,492 Training Epoch [37/40] Iter[22/312]		Loss: 0.0954
2019-10-29 00:54:10,614 Training Epoch [37/40] Iter[23/312]		Loss: 0.0939
2019-10-29 00:54:10,736 Training Epoch [37/40] Iter[24/312]		Loss: 0.0942
2019-10-29 00:54:10,857 Training Epoch [37/40] Iter[25/312]		Loss: 0.0924
2019-10-29 00:54:10,978 Training Epoch [37/40] Iter[26/312]		Loss: 0.0943
2019-10-29 00:54:11,100 Training Epoch [37/40] Iter[27/312]		Loss: 0.0942
2019-10-29 00:54:11,222 Training Epoch [37/40] Iter[28/312]		Loss: 0.0944
2019-10-29 00:54:11,344 Training Epoch [37/40] Iter[29/312]		Loss: 0.0944
2019-10-29 00:54:11,466 Training Epoch [37/40] Iter[30/312]		Loss: 0.0970
2019-10-29 00:54:11,588 Training Epoch [37/40] Iter[31/312]		Loss: 0.0977
2019-10-29 00:54:11,710 Training Epoch [37/40] Iter[32/312]		Loss: 0.0977
2019-10-29 00:54:11,832 Training Epoch [37/40] Iter[33/312]		Loss: 0.0990
2019-10-29 00:54:11,953 Training Epoch [37/40] Iter[34/312]		Loss: 0.0983
2019-10-29 00:54:12,075 Training Epoch [37/40] Iter[35/312]		Loss: 0.0976
2019-10-29 00:54:12,197 Training Epoch [37/40] Iter[36/312]		Loss: 0.0974
2019-10-29 00:54:12,318 Training Epoch [37/40] Iter[37/312]		Loss: 0.0968
2019-10-29 00:54:12,439 Training Epoch [37/40] Iter[38/312]		Loss: 0.0964
2019-10-29 00:54:12,561 Training Epoch [37/40] Iter[39/312]		Loss: 0.0961
2019-10-29 00:54:12,682 Training Epoch [37/40] Iter[40/312]		Loss: 0.0960
2019-10-29 00:54:12,804 Training Epoch [37/40] Iter[41/312]		Loss: 0.0960
2019-10-29 00:54:12,926 Training Epoch [37/40] Iter[42/312]		Loss: 0.0980
2019-10-29 00:54:13,047 Training Epoch [37/40] Iter[43/312]		Loss: 0.0976
2019-10-29 00:54:13,168 Training Epoch [37/40] Iter[44/312]		Loss: 0.0973
2019-10-29 00:54:13,290 Training Epoch [37/40] Iter[45/312]		Loss: 0.0965
2019-10-29 00:54:13,412 Training Epoch [37/40] Iter[46/312]		Loss: 0.0968
2019-10-29 00:54:13,533 Training Epoch [37/40] Iter[47/312]		Loss: 0.0962
2019-10-29 00:54:13,656 Training Epoch [37/40] Iter[48/312]		Loss: 0.0957
2019-10-29 00:54:13,777 Training Epoch [37/40] Iter[49/312]		Loss: 0.0957
2019-10-29 00:54:13,898 Training Epoch [37/40] Iter[50/312]		Loss: 0.0954
2019-10-29 00:54:14,019 Training Epoch [37/40] Iter[51/312]		Loss: 0.0962
2019-10-29 00:54:14,140 Training Epoch [37/40] Iter[52/312]		Loss: 0.0964
2019-10-29 00:54:14,261 Training Epoch [37/40] Iter[53/312]		Loss: 0.0972
2019-10-29 00:54:14,383 Training Epoch [37/40] Iter[54/312]		Loss: 0.0977
2019-10-29 00:54:14,503 Training Epoch [37/40] Iter[55/312]		Loss: 0.0976
2019-10-29 00:54:14,624 Training Epoch [37/40] Iter[56/312]		Loss: 0.0975
2019-10-29 00:54:14,745 Training Epoch [37/40] Iter[57/312]		Loss: 0.0972
2019-10-29 00:54:14,866 Training Epoch [37/40] Iter[58/312]		Loss: 0.0972
2019-10-29 00:54:14,987 Training Epoch [37/40] Iter[59/312]		Loss: 0.0969
2019-10-29 00:54:15,112 Training Epoch [37/40] Iter[60/312]		Loss: 0.0963
2019-10-29 00:54:15,234 Training Epoch [37/40] Iter[61/312]		Loss: 0.0960
2019-10-29 00:54:15,355 Training Epoch [37/40] Iter[62/312]		Loss: 0.0963
2019-10-29 00:54:15,477 Training Epoch [37/40] Iter[63/312]		Loss: 0.0964
2019-10-29 00:54:15,598 Training Epoch [37/40] Iter[64/312]		Loss: 0.0968
2019-10-29 00:54:15,719 Training Epoch [37/40] Iter[65/312]		Loss: 0.0974
2019-10-29 00:54:15,841 Training Epoch [37/40] Iter[66/312]		Loss: 0.0976
2019-10-29 00:54:15,962 Training Epoch [37/40] Iter[67/312]		Loss: 0.0980
2019-10-29 00:54:16,085 Training Epoch [37/40] Iter[68/312]		Loss: 0.0978
2019-10-29 00:54:16,207 Training Epoch [37/40] Iter[69/312]		Loss: 0.0985
2019-10-29 00:54:16,329 Training Epoch [37/40] Iter[70/312]		Loss: 0.0989
2019-10-29 00:54:16,452 Training Epoch [37/40] Iter[71/312]		Loss: 0.0987
2019-10-29 00:54:16,576 Training Epoch [37/40] Iter[72/312]		Loss: 0.0998
2019-10-29 00:54:16,698 Training Epoch [37/40] Iter[73/312]		Loss: 0.1002
2019-10-29 00:54:16,820 Training Epoch [37/40] Iter[74/312]		Loss: 0.0999
2019-10-29 00:54:16,942 Training Epoch [37/40] Iter[75/312]		Loss: 0.1005
2019-10-29 00:54:17,068 Training Epoch [37/40] Iter[76/312]		Loss: 0.0999
2019-10-29 00:54:17,190 Training Epoch [37/40] Iter[77/312]		Loss: 0.1002
2019-10-29 00:54:17,312 Training Epoch [37/40] Iter[78/312]		Loss: 0.1005
2019-10-29 00:54:17,433 Training Epoch [37/40] Iter[79/312]		Loss: 0.1003
2019-10-29 00:54:17,555 Training Epoch [37/40] Iter[80/312]		Loss: 0.1002
2019-10-29 00:54:17,676 Training Epoch [37/40] Iter[81/312]		Loss: 0.1004
2019-10-29 00:54:17,797 Training Epoch [37/40] Iter[82/312]		Loss: 0.1004
2019-10-29 00:54:17,918 Training Epoch [37/40] Iter[83/312]		Loss: 0.1008
2019-10-29 00:54:18,040 Training Epoch [37/40] Iter[84/312]		Loss: 0.1009
2019-10-29 00:54:18,161 Training Epoch [37/40] Iter[85/312]		Loss: 0.1010
2019-10-29 00:54:18,283 Training Epoch [37/40] Iter[86/312]		Loss: 0.1012
2019-10-29 00:54:18,404 Training Epoch [37/40] Iter[87/312]		Loss: 0.1015
2019-10-29 00:54:18,526 Training Epoch [37/40] Iter[88/312]		Loss: 0.1011
2019-10-29 00:54:18,648 Training Epoch [37/40] Iter[89/312]		Loss: 0.1011
2019-10-29 00:54:18,769 Training Epoch [37/40] Iter[90/312]		Loss: 0.1012
2019-10-29 00:54:18,891 Training Epoch [37/40] Iter[91/312]		Loss: 0.1010
2019-10-29 00:54:19,012 Training Epoch [37/40] Iter[92/312]		Loss: 0.1009
2019-10-29 00:54:19,133 Training Epoch [37/40] Iter[93/312]		Loss: 0.1008
2019-10-29 00:54:19,254 Training Epoch [37/40] Iter[94/312]		Loss: 0.1008
2019-10-29 00:54:19,376 Training Epoch [37/40] Iter[95/312]		Loss: 0.1009
2019-10-29 00:54:19,498 Training Epoch [37/40] Iter[96/312]		Loss: 0.1010
2019-10-29 00:54:19,619 Training Epoch [37/40] Iter[97/312]		Loss: 0.1009
2019-10-29 00:54:19,741 Training Epoch [37/40] Iter[98/312]		Loss: 0.1010
2019-10-29 00:54:19,863 Training Epoch [37/40] Iter[99/312]		Loss: 0.1007
2019-10-29 00:54:19,984 Training Epoch [37/40] Iter[100/312]		Loss: 0.1004
2019-10-29 00:54:20,106 Training Epoch [37/40] Iter[101/312]		Loss: 0.1008
2019-10-29 00:54:20,227 Training Epoch [37/40] Iter[102/312]		Loss: 0.1005
2019-10-29 00:54:20,348 Training Epoch [37/40] Iter[103/312]		Loss: 0.1009
2019-10-29 00:54:20,470 Training Epoch [37/40] Iter[104/312]		Loss: 0.1013
2019-10-29 00:54:20,591 Training Epoch [37/40] Iter[105/312]		Loss: 0.1015
2019-10-29 00:54:20,712 Training Epoch [37/40] Iter[106/312]		Loss: 0.1024
2019-10-29 00:54:20,833 Training Epoch [37/40] Iter[107/312]		Loss: 0.1022
2019-10-29 00:54:20,954 Training Epoch [37/40] Iter[108/312]		Loss: 0.1019
2019-10-29 00:54:21,076 Training Epoch [37/40] Iter[109/312]		Loss: 0.1018
2019-10-29 00:54:21,197 Training Epoch [37/40] Iter[110/312]		Loss: 0.1015
2019-10-29 00:54:21,319 Training Epoch [37/40] Iter[111/312]		Loss: 0.1013
2019-10-29 00:54:21,441 Training Epoch [37/40] Iter[112/312]		Loss: 0.1012
2019-10-29 00:54:21,563 Training Epoch [37/40] Iter[113/312]		Loss: 0.1011
2019-10-29 00:54:21,684 Training Epoch [37/40] Iter[114/312]		Loss: 0.1020
2019-10-29 00:54:21,805 Training Epoch [37/40] Iter[115/312]		Loss: 0.1020
2019-10-29 00:54:21,927 Training Epoch [37/40] Iter[116/312]		Loss: 0.1019
2019-10-29 00:54:22,048 Training Epoch [37/40] Iter[117/312]		Loss: 0.1019
2019-10-29 00:54:22,170 Training Epoch [37/40] Iter[118/312]		Loss: 0.1018
2019-10-29 00:54:22,291 Training Epoch [37/40] Iter[119/312]		Loss: 0.1018
2019-10-29 00:54:22,412 Training Epoch [37/40] Iter[120/312]		Loss: 0.1020
2019-10-29 00:54:22,533 Training Epoch [37/40] Iter[121/312]		Loss: 0.1020
2019-10-29 00:54:22,655 Training Epoch [37/40] Iter[122/312]		Loss: 0.1017
2019-10-29 00:54:22,776 Training Epoch [37/40] Iter[123/312]		Loss: 0.1017
2019-10-29 00:54:22,896 Training Epoch [37/40] Iter[124/312]		Loss: 0.1018
2019-10-29 00:54:23,017 Training Epoch [37/40] Iter[125/312]		Loss: 0.1023
2019-10-29 00:54:23,138 Training Epoch [37/40] Iter[126/312]		Loss: 0.1021
2019-10-29 00:54:23,260 Training Epoch [37/40] Iter[127/312]		Loss: 0.1020
2019-10-29 00:54:23,382 Training Epoch [37/40] Iter[128/312]		Loss: 0.1020
2019-10-29 00:54:23,504 Training Epoch [37/40] Iter[129/312]		Loss: 0.1020
2019-10-29 00:54:23,626 Training Epoch [37/40] Iter[130/312]		Loss: 0.1019
2019-10-29 00:54:23,747 Training Epoch [37/40] Iter[131/312]		Loss: 0.1019
2019-10-29 00:54:23,869 Training Epoch [37/40] Iter[132/312]		Loss: 0.1017
2019-10-29 00:54:23,991 Training Epoch [37/40] Iter[133/312]		Loss: 0.1018
2019-10-29 00:54:24,112 Training Epoch [37/40] Iter[134/312]		Loss: 0.1017
2019-10-29 00:54:24,233 Training Epoch [37/40] Iter[135/312]		Loss: 0.1017
2019-10-29 00:54:24,354 Training Epoch [37/40] Iter[136/312]		Loss: 0.1014
2019-10-29 00:54:24,476 Training Epoch [37/40] Iter[137/312]		Loss: 0.1017
2019-10-29 00:54:24,598 Training Epoch [37/40] Iter[138/312]		Loss: 0.1015
2019-10-29 00:54:24,720 Training Epoch [37/40] Iter[139/312]		Loss: 0.1015
2019-10-29 00:54:24,841 Training Epoch [37/40] Iter[140/312]		Loss: 0.1013
2019-10-29 00:54:24,963 Training Epoch [37/40] Iter[141/312]		Loss: 0.1015
2019-10-29 00:54:25,085 Training Epoch [37/40] Iter[142/312]		Loss: 0.1016
2019-10-29 00:54:25,206 Training Epoch [37/40] Iter[143/312]		Loss: 0.1017
2019-10-29 00:54:25,328 Training Epoch [37/40] Iter[144/312]		Loss: 0.1017
2019-10-29 00:54:25,449 Training Epoch [37/40] Iter[145/312]		Loss: 0.1020
2019-10-29 00:54:25,570 Training Epoch [37/40] Iter[146/312]		Loss: 0.1020
2019-10-29 00:54:25,691 Training Epoch [37/40] Iter[147/312]		Loss: 0.1023
2019-10-29 00:54:25,812 Training Epoch [37/40] Iter[148/312]		Loss: 0.1021
2019-10-29 00:54:25,934 Training Epoch [37/40] Iter[149/312]		Loss: 0.1020
2019-10-29 00:54:26,055 Training Epoch [37/40] Iter[150/312]		Loss: 0.1019
2019-10-29 00:54:26,177 Training Epoch [37/40] Iter[151/312]		Loss: 0.1017
2019-10-29 00:54:26,298 Training Epoch [37/40] Iter[152/312]		Loss: 0.1017
2019-10-29 00:54:26,419 Training Epoch [37/40] Iter[153/312]		Loss: 0.1016
2019-10-29 00:54:26,541 Training Epoch [37/40] Iter[154/312]		Loss: 0.1014
2019-10-29 00:54:26,662 Training Epoch [37/40] Iter[155/312]		Loss: 0.1013
2019-10-29 00:54:26,783 Training Epoch [37/40] Iter[156/312]		Loss: 0.1012
2019-10-29 00:54:26,905 Training Epoch [37/40] Iter[157/312]		Loss: 0.1012
2019-10-29 00:54:27,027 Training Epoch [37/40] Iter[158/312]		Loss: 0.1012
2019-10-29 00:54:27,148 Training Epoch [37/40] Iter[159/312]		Loss: 0.1010
2019-10-29 00:54:27,269 Training Epoch [37/40] Iter[160/312]		Loss: 0.1013
2019-10-29 00:54:27,391 Training Epoch [37/40] Iter[161/312]		Loss: 0.1021
2019-10-29 00:54:27,512 Training Epoch [37/40] Iter[162/312]		Loss: 0.1022
2019-10-29 00:54:27,634 Training Epoch [37/40] Iter[163/312]		Loss: 0.1020
2019-10-29 00:54:27,755 Training Epoch [37/40] Iter[164/312]		Loss: 0.1018
2019-10-29 00:54:27,877 Training Epoch [37/40] Iter[165/312]		Loss: 0.1018
2019-10-29 00:54:27,998 Training Epoch [37/40] Iter[166/312]		Loss: 0.1019
2019-10-29 00:54:28,120 Training Epoch [37/40] Iter[167/312]		Loss: 0.1019
2019-10-29 00:54:28,242 Training Epoch [37/40] Iter[168/312]		Loss: 0.1017
2019-10-29 00:54:28,365 Training Epoch [37/40] Iter[169/312]		Loss: 0.1019
2019-10-29 00:54:28,487 Training Epoch [37/40] Iter[170/312]		Loss: 0.1017
2019-10-29 00:54:28,608 Training Epoch [37/40] Iter[171/312]		Loss: 0.1019
2019-10-29 00:54:28,729 Training Epoch [37/40] Iter[172/312]		Loss: 0.1019
2019-10-29 00:54:28,851 Training Epoch [37/40] Iter[173/312]		Loss: 0.1018
2019-10-29 00:54:28,972 Training Epoch [37/40] Iter[174/312]		Loss: 0.1016
2019-10-29 00:54:29,094 Training Epoch [37/40] Iter[175/312]		Loss: 0.1018
2019-10-29 00:54:29,215 Training Epoch [37/40] Iter[176/312]		Loss: 0.1018
2019-10-29 00:54:29,337 Training Epoch [37/40] Iter[177/312]		Loss: 0.1016
2019-10-29 00:54:29,459 Training Epoch [37/40] Iter[178/312]		Loss: 0.1015
2019-10-29 00:54:29,580 Training Epoch [37/40] Iter[179/312]		Loss: 0.1015
2019-10-29 00:54:29,701 Training Epoch [37/40] Iter[180/312]		Loss: 0.1014
2019-10-29 00:54:29,822 Training Epoch [37/40] Iter[181/312]		Loss: 0.1017
2019-10-29 00:54:29,944 Training Epoch [37/40] Iter[182/312]		Loss: 0.1018
2019-10-29 00:54:30,065 Training Epoch [37/40] Iter[183/312]		Loss: 0.1020
2019-10-29 00:54:30,186 Training Epoch [37/40] Iter[184/312]		Loss: 0.1020
2019-10-29 00:54:30,307 Training Epoch [37/40] Iter[185/312]		Loss: 0.1021
2019-10-29 00:54:30,429 Training Epoch [37/40] Iter[186/312]		Loss: 0.1019
2019-10-29 00:54:30,550 Training Epoch [37/40] Iter[187/312]		Loss: 0.1018
2019-10-29 00:54:30,672 Training Epoch [37/40] Iter[188/312]		Loss: 0.1016
2019-10-29 00:54:30,794 Training Epoch [37/40] Iter[189/312]		Loss: 0.1016
2019-10-29 00:54:30,915 Training Epoch [37/40] Iter[190/312]		Loss: 0.1016
2019-10-29 00:54:31,036 Training Epoch [37/40] Iter[191/312]		Loss: 0.1014
2019-10-29 00:54:31,157 Training Epoch [37/40] Iter[192/312]		Loss: 0.1012
2019-10-29 00:54:31,278 Training Epoch [37/40] Iter[193/312]		Loss: 0.1012
2019-10-29 00:54:31,399 Training Epoch [37/40] Iter[194/312]		Loss: 0.1010
2019-10-29 00:54:31,520 Training Epoch [37/40] Iter[195/312]		Loss: 0.1010
2019-10-29 00:54:31,641 Training Epoch [37/40] Iter[196/312]		Loss: 0.1009
2019-10-29 00:54:31,762 Training Epoch [37/40] Iter[197/312]		Loss: 0.1006
2019-10-29 00:54:31,884 Training Epoch [37/40] Iter[198/312]		Loss: 0.1007
2019-10-29 00:54:32,005 Training Epoch [37/40] Iter[199/312]		Loss: 0.1010
2019-10-29 00:54:32,127 Training Epoch [37/40] Iter[200/312]		Loss: 0.1009
2019-10-29 00:54:32,249 Training Epoch [37/40] Iter[201/312]		Loss: 0.1010
2019-10-29 00:54:32,370 Training Epoch [37/40] Iter[202/312]		Loss: 0.1009
2019-10-29 00:54:32,492 Training Epoch [37/40] Iter[203/312]		Loss: 0.1006
2019-10-29 00:54:32,613 Training Epoch [37/40] Iter[204/312]		Loss: 0.1006
2019-10-29 00:54:32,734 Training Epoch [37/40] Iter[205/312]		Loss: 0.1004
2019-10-29 00:54:32,856 Training Epoch [37/40] Iter[206/312]		Loss: 0.1006
2019-10-29 00:54:32,977 Training Epoch [37/40] Iter[207/312]		Loss: 0.1004
2019-10-29 00:54:33,099 Training Epoch [37/40] Iter[208/312]		Loss: 0.1002
2019-10-29 00:54:33,220 Training Epoch [37/40] Iter[209/312]		Loss: 0.1003
2019-10-29 00:54:33,342 Training Epoch [37/40] Iter[210/312]		Loss: 0.1003
2019-10-29 00:54:33,464 Training Epoch [37/40] Iter[211/312]		Loss: 0.1004
2019-10-29 00:54:33,587 Training Epoch [37/40] Iter[212/312]		Loss: 0.1003
2019-10-29 00:54:33,709 Training Epoch [37/40] Iter[213/312]		Loss: 0.1004
2019-10-29 00:54:33,831 Training Epoch [37/40] Iter[214/312]		Loss: 0.1004
2019-10-29 00:54:33,952 Training Epoch [37/40] Iter[215/312]		Loss: 0.1003
2019-10-29 00:54:34,074 Training Epoch [37/40] Iter[216/312]		Loss: 0.1004
2019-10-29 00:54:34,195 Training Epoch [37/40] Iter[217/312]		Loss: 0.1004
2019-10-29 00:54:34,317 Training Epoch [37/40] Iter[218/312]		Loss: 0.1003
2019-10-29 00:54:34,438 Training Epoch [37/40] Iter[219/312]		Loss: 0.1005
2019-10-29 00:54:34,560 Training Epoch [37/40] Iter[220/312]		Loss: 0.1004
2019-10-29 00:54:34,681 Training Epoch [37/40] Iter[221/312]		Loss: 0.1004
2019-10-29 00:54:34,802 Training Epoch [37/40] Iter[222/312]		Loss: 0.1003
2019-10-29 00:54:34,923 Training Epoch [37/40] Iter[223/312]		Loss: 0.1002
2019-10-29 00:54:35,045 Training Epoch [37/40] Iter[224/312]		Loss: 0.1005
2019-10-29 00:54:35,166 Training Epoch [37/40] Iter[225/312]		Loss: 0.1003
2019-10-29 00:54:35,288 Training Epoch [37/40] Iter[226/312]		Loss: 0.1003
2019-10-29 00:54:35,410 Training Epoch [37/40] Iter[227/312]		Loss: 0.1002
2019-10-29 00:54:35,531 Training Epoch [37/40] Iter[228/312]		Loss: 0.1005
2019-10-29 00:54:35,653 Training Epoch [37/40] Iter[229/312]		Loss: 0.1007
2019-10-29 00:54:35,775 Training Epoch [37/40] Iter[230/312]		Loss: 0.1008
2019-10-29 00:54:35,896 Training Epoch [37/40] Iter[231/312]		Loss: 0.1008
2019-10-29 00:54:36,017 Training Epoch [37/40] Iter[232/312]		Loss: 0.1008
2019-10-29 00:54:36,138 Training Epoch [37/40] Iter[233/312]		Loss: 0.1010
2019-10-29 00:54:36,259 Training Epoch [37/40] Iter[234/312]		Loss: 0.1009
2019-10-29 00:54:36,381 Training Epoch [37/40] Iter[235/312]		Loss: 0.1010
2019-10-29 00:54:36,502 Training Epoch [37/40] Iter[236/312]		Loss: 0.1008
2019-10-29 00:54:36,624 Training Epoch [37/40] Iter[237/312]		Loss: 0.1008
2019-10-29 00:54:36,746 Training Epoch [37/40] Iter[238/312]		Loss: 0.1009
2019-10-29 00:54:36,867 Training Epoch [37/40] Iter[239/312]		Loss: 0.1008
2019-10-29 00:54:36,989 Training Epoch [37/40] Iter[240/312]		Loss: 0.1008
2019-10-29 00:54:37,110 Training Epoch [37/40] Iter[241/312]		Loss: 0.1008
2019-10-29 00:54:37,231 Training Epoch [37/40] Iter[242/312]		Loss: 0.1007
2019-10-29 00:54:37,352 Training Epoch [37/40] Iter[243/312]		Loss: 0.1009
2019-10-29 00:54:37,473 Training Epoch [37/40] Iter[244/312]		Loss: 0.1007
2019-10-29 00:54:37,594 Training Epoch [37/40] Iter[245/312]		Loss: 0.1008
2019-10-29 00:54:37,716 Training Epoch [37/40] Iter[246/312]		Loss: 0.1007
2019-10-29 00:54:37,837 Training Epoch [37/40] Iter[247/312]		Loss: 0.1007
2019-10-29 00:54:37,958 Training Epoch [37/40] Iter[248/312]		Loss: 0.1008
2019-10-29 00:54:38,080 Training Epoch [37/40] Iter[249/312]		Loss: 0.1008
2019-10-29 00:54:38,201 Training Epoch [37/40] Iter[250/312]		Loss: 0.1008
2019-10-29 00:54:38,322 Training Epoch [37/40] Iter[251/312]		Loss: 0.1008
2019-10-29 00:54:38,444 Training Epoch [37/40] Iter[252/312]		Loss: 0.1010
2019-10-29 00:54:38,565 Training Epoch [37/40] Iter[253/312]		Loss: 0.1009
2019-10-29 00:54:38,687 Training Epoch [37/40] Iter[254/312]		Loss: 0.1011
2019-10-29 00:54:38,808 Training Epoch [37/40] Iter[255/312]		Loss: 0.1012
2019-10-29 00:54:38,930 Training Epoch [37/40] Iter[256/312]		Loss: 0.1010
2019-10-29 00:54:39,051 Training Epoch [37/40] Iter[257/312]		Loss: 0.1010
2019-10-29 00:54:39,172 Training Epoch [37/40] Iter[258/312]		Loss: 0.1009
2019-10-29 00:54:39,294 Training Epoch [37/40] Iter[259/312]		Loss: 0.1008
2019-10-29 00:54:39,415 Training Epoch [37/40] Iter[260/312]		Loss: 0.1007
2019-10-29 00:54:39,536 Training Epoch [37/40] Iter[261/312]		Loss: 0.1006
2019-10-29 00:54:39,657 Training Epoch [37/40] Iter[262/312]		Loss: 0.1006
2019-10-29 00:54:39,778 Training Epoch [37/40] Iter[263/312]		Loss: 0.1006
2019-10-29 00:54:39,899 Training Epoch [37/40] Iter[264/312]		Loss: 0.1007
2019-10-29 00:54:40,020 Training Epoch [37/40] Iter[265/312]		Loss: 0.1006
2019-10-29 00:54:40,142 Training Epoch [37/40] Iter[266/312]		Loss: 0.1006
2019-10-29 00:54:40,263 Training Epoch [37/40] Iter[267/312]		Loss: 0.1006
2019-10-29 00:54:40,384 Training Epoch [37/40] Iter[268/312]		Loss: 0.1006
2019-10-29 00:54:40,506 Training Epoch [37/40] Iter[269/312]		Loss: 0.1006
2019-10-29 00:54:40,628 Training Epoch [37/40] Iter[270/312]		Loss: 0.1005
2019-10-29 00:54:40,749 Training Epoch [37/40] Iter[271/312]		Loss: 0.1006
2019-10-29 00:54:40,871 Training Epoch [37/40] Iter[272/312]		Loss: 0.1004
2019-10-29 00:54:40,993 Training Epoch [37/40] Iter[273/312]		Loss: 0.1005
2019-10-29 00:54:41,114 Training Epoch [37/40] Iter[274/312]		Loss: 0.1006
2019-10-29 00:54:41,236 Training Epoch [37/40] Iter[275/312]		Loss: 0.1005
2019-10-29 00:54:41,358 Training Epoch [37/40] Iter[276/312]		Loss: 0.1004
2019-10-29 00:54:41,479 Training Epoch [37/40] Iter[277/312]		Loss: 0.1004
2019-10-29 00:54:41,600 Training Epoch [37/40] Iter[278/312]		Loss: 0.1004
2019-10-29 00:54:41,722 Training Epoch [37/40] Iter[279/312]		Loss: 0.1004
2019-10-29 00:54:41,844 Training Epoch [37/40] Iter[280/312]		Loss: 0.1003
2019-10-29 00:54:41,966 Training Epoch [37/40] Iter[281/312]		Loss: 0.1002
2019-10-29 00:54:42,088 Training Epoch [37/40] Iter[282/312]		Loss: 0.1002
2019-10-29 00:54:42,210 Training Epoch [37/40] Iter[283/312]		Loss: 0.1001
2019-10-29 00:54:42,331 Training Epoch [37/40] Iter[284/312]		Loss: 0.1001
2019-10-29 00:54:42,453 Training Epoch [37/40] Iter[285/312]		Loss: 0.1000
2019-10-29 00:54:42,574 Training Epoch [37/40] Iter[286/312]		Loss: 0.1000
2019-10-29 00:54:42,695 Training Epoch [37/40] Iter[287/312]		Loss: 0.1001
2019-10-29 00:54:42,817 Training Epoch [37/40] Iter[288/312]		Loss: 0.1001
2019-10-29 00:54:42,938 Training Epoch [37/40] Iter[289/312]		Loss: 0.1001
2019-10-29 00:54:43,060 Training Epoch [37/40] Iter[290/312]		Loss: 0.1001
2019-10-29 00:54:43,182 Training Epoch [37/40] Iter[291/312]		Loss: 0.1002
2019-10-29 00:54:43,303 Training Epoch [37/40] Iter[292/312]		Loss: 0.1001
2019-10-29 00:54:43,425 Training Epoch [37/40] Iter[293/312]		Loss: 0.1001
2019-10-29 00:54:43,546 Training Epoch [37/40] Iter[294/312]		Loss: 0.1001
2019-10-29 00:54:43,668 Training Epoch [37/40] Iter[295/312]		Loss: 0.1000
2019-10-29 00:54:43,790 Training Epoch [37/40] Iter[296/312]		Loss: 0.0999
2019-10-29 00:54:43,912 Training Epoch [37/40] Iter[297/312]		Loss: 0.0999
2019-10-29 00:54:44,033 Training Epoch [37/40] Iter[298/312]		Loss: 0.0999
2019-10-29 00:54:44,155 Training Epoch [37/40] Iter[299/312]		Loss: 0.1000
2019-10-29 00:54:44,277 Training Epoch [37/40] Iter[300/312]		Loss: 0.0999
2019-10-29 00:54:44,398 Training Epoch [37/40] Iter[301/312]		Loss: 0.0998
2019-10-29 00:54:44,520 Training Epoch [37/40] Iter[302/312]		Loss: 0.0997
2019-10-29 00:54:44,642 Training Epoch [37/40] Iter[303/312]		Loss: 0.0997
2019-10-29 00:54:44,763 Training Epoch [37/40] Iter[304/312]		Loss: 0.0996
2019-10-29 00:54:44,884 Training Epoch [37/40] Iter[305/312]		Loss: 0.0996
2019-10-29 00:54:45,005 Training Epoch [37/40] Iter[306/312]		Loss: 0.0995
2019-10-29 00:54:45,127 Training Epoch [37/40] Iter[307/312]		Loss: 0.0996
2019-10-29 00:54:45,248 Training Epoch [37/40] Iter[308/312]		Loss: 0.0995
2019-10-29 00:54:45,370 Training Epoch [37/40] Iter[309/312]		Loss: 0.0994
2019-10-29 00:54:45,491 Training Epoch [37/40] Iter[310/312]		Loss: 0.0996
2019-10-29 00:54:45,612 Training Epoch [37/40] Iter[311/312]		Loss: 0.0996
2019-10-29 00:54:45,673 Training Epoch [37/40] Iter[312/312]		Loss: 0.0995
2019-10-29 00:54:46,061 Testing Epoch [37/40] Iter[0/62]		Loss: 0.0912
2019-10-29 00:54:46,104 Testing Epoch [37/40] Iter[1/62]		Loss: 0.1273
2019-10-29 00:54:46,135 Testing Epoch [37/40] Iter[2/62]		Loss: 0.1179
2019-10-29 00:54:46,166 Testing Epoch [37/40] Iter[3/62]		Loss: 0.1159
2019-10-29 00:54:46,205 Testing Epoch [37/40] Iter[4/62]		Loss: 0.1112
2019-10-29 00:54:46,236 Testing Epoch [37/40] Iter[5/62]		Loss: 0.1081
2019-10-29 00:54:46,267 Testing Epoch [37/40] Iter[6/62]		Loss: 0.1084
2019-10-29 00:54:46,297 Testing Epoch [37/40] Iter[7/62]		Loss: 0.1147
2019-10-29 00:54:46,328 Testing Epoch [37/40] Iter[8/62]		Loss: 0.1204
2019-10-29 00:54:46,359 Testing Epoch [37/40] Iter[9/62]		Loss: 0.1179
2019-10-29 00:54:46,390 Testing Epoch [37/40] Iter[10/62]		Loss: 0.1163
2019-10-29 00:54:46,421 Testing Epoch [37/40] Iter[11/62]		Loss: 0.1208
2019-10-29 00:54:46,452 Testing Epoch [37/40] Iter[12/62]		Loss: 0.1215
2019-10-29 00:54:46,482 Testing Epoch [37/40] Iter[13/62]		Loss: 0.1236
2019-10-29 00:54:46,513 Testing Epoch [37/40] Iter[14/62]		Loss: 0.1355
2019-10-29 00:54:46,544 Testing Epoch [37/40] Iter[15/62]		Loss: 0.1368
2019-10-29 00:54:46,575 Testing Epoch [37/40] Iter[16/62]		Loss: 0.1349
2019-10-29 00:54:46,606 Testing Epoch [37/40] Iter[17/62]		Loss: 0.1339
2019-10-29 00:54:46,637 Testing Epoch [37/40] Iter[18/62]		Loss: 0.1306
2019-10-29 00:54:46,669 Testing Epoch [37/40] Iter[19/62]		Loss: 0.1287
2019-10-29 00:54:46,699 Testing Epoch [37/40] Iter[20/62]		Loss: 0.1305
2019-10-29 00:54:46,730 Testing Epoch [37/40] Iter[21/62]		Loss: 0.1284
2019-10-29 00:54:46,761 Testing Epoch [37/40] Iter[22/62]		Loss: 0.1280
2019-10-29 00:54:46,792 Testing Epoch [37/40] Iter[23/62]		Loss: 0.1282
2019-10-29 00:54:46,823 Testing Epoch [37/40] Iter[24/62]		Loss: 0.1301
2019-10-29 00:54:46,854 Testing Epoch [37/40] Iter[25/62]		Loss: 0.1295
2019-10-29 00:54:46,885 Testing Epoch [37/40] Iter[26/62]		Loss: 0.1283
2019-10-29 00:54:46,916 Testing Epoch [37/40] Iter[27/62]		Loss: 0.1327
2019-10-29 00:54:46,947 Testing Epoch [37/40] Iter[28/62]		Loss: 0.1345
2019-10-29 00:54:46,978 Testing Epoch [37/40] Iter[29/62]		Loss: 0.1341
2019-10-29 00:54:47,009 Testing Epoch [37/40] Iter[30/62]		Loss: 0.1360
2019-10-29 00:54:47,040 Testing Epoch [37/40] Iter[31/62]		Loss: 0.1353
2019-10-29 00:54:47,071 Testing Epoch [37/40] Iter[32/62]		Loss: 0.1368
2019-10-29 00:54:47,102 Testing Epoch [37/40] Iter[33/62]		Loss: 0.1350
2019-10-29 00:54:47,133 Testing Epoch [37/40] Iter[34/62]		Loss: 0.1365
2019-10-29 00:54:47,164 Testing Epoch [37/40] Iter[35/62]		Loss: 0.1370
2019-10-29 00:54:47,195 Testing Epoch [37/40] Iter[36/62]		Loss: 0.1351
2019-10-29 00:54:47,226 Testing Epoch [37/40] Iter[37/62]		Loss: 0.1347
2019-10-29 00:54:47,257 Testing Epoch [37/40] Iter[38/62]		Loss: 0.1350
2019-10-29 00:54:47,288 Testing Epoch [37/40] Iter[39/62]		Loss: 0.1354
2019-10-29 00:54:47,319 Testing Epoch [37/40] Iter[40/62]		Loss: 0.1358
2019-10-29 00:54:47,350 Testing Epoch [37/40] Iter[41/62]		Loss: 0.1358
2019-10-29 00:54:47,381 Testing Epoch [37/40] Iter[42/62]		Loss: 0.1346
2019-10-29 00:54:47,412 Testing Epoch [37/40] Iter[43/62]		Loss: 0.1340
2019-10-29 00:54:47,443 Testing Epoch [37/40] Iter[44/62]		Loss: 0.1329
2019-10-29 00:54:47,475 Testing Epoch [37/40] Iter[45/62]		Loss: 0.1339
2019-10-29 00:54:47,506 Testing Epoch [37/40] Iter[46/62]		Loss: 0.1340
2019-10-29 00:54:47,537 Testing Epoch [37/40] Iter[47/62]		Loss: 0.1391
2019-10-29 00:54:47,568 Testing Epoch [37/40] Iter[48/62]		Loss: 0.1381
2019-10-29 00:54:47,599 Testing Epoch [37/40] Iter[49/62]		Loss: 0.1395
2019-10-29 00:54:47,630 Testing Epoch [37/40] Iter[50/62]		Loss: 0.1390
2019-10-29 00:54:47,660 Testing Epoch [37/40] Iter[51/62]		Loss: 0.1391
2019-10-29 00:54:47,691 Testing Epoch [37/40] Iter[52/62]		Loss: 0.1381
2019-10-29 00:54:47,722 Testing Epoch [37/40] Iter[53/62]		Loss: 0.1378
2019-10-29 00:54:47,753 Testing Epoch [37/40] Iter[54/62]		Loss: 0.1373
2019-10-29 00:54:47,783 Testing Epoch [37/40] Iter[55/62]		Loss: 0.1374
2019-10-29 00:54:47,814 Testing Epoch [37/40] Iter[56/62]		Loss: 0.1372
2019-10-29 00:54:47,844 Testing Epoch [37/40] Iter[57/62]		Loss: 0.1371
2019-10-29 00:54:47,875 Testing Epoch [37/40] Iter[58/62]		Loss: 0.1366
2019-10-29 00:54:47,905 Testing Epoch [37/40] Iter[59/62]		Loss: 0.1366
2019-10-29 00:54:47,935 Testing Epoch [37/40] Iter[60/62]		Loss: 0.1359
2019-10-29 00:54:47,965 Testing Epoch [37/40] Iter[61/62]		Loss: 0.1357
2019-10-29 00:54:47,983 Testing Epoch [37/40] Iter[62/62]		Loss: 0.1365
2019-10-29 00:54:48,049 Saving the Model
2019-10-29 00:54:48,474 Training Epoch [38/40] Iter[0/312]		Loss: 0.0649
2019-10-29 00:54:48,600 Training Epoch [38/40] Iter[1/312]		Loss: 0.0727
2019-10-29 00:54:48,722 Training Epoch [38/40] Iter[2/312]		Loss: 0.0663
2019-10-29 00:54:48,844 Training Epoch [38/40] Iter[3/312]		Loss: 0.0953
2019-10-29 00:54:48,966 Training Epoch [38/40] Iter[4/312]		Loss: 0.0973
2019-10-29 00:54:49,087 Training Epoch [38/40] Iter[5/312]		Loss: 0.0915
2019-10-29 00:54:49,208 Training Epoch [38/40] Iter[6/312]		Loss: 0.0995
2019-10-29 00:54:49,329 Training Epoch [38/40] Iter[7/312]		Loss: 0.1005
2019-10-29 00:54:49,451 Training Epoch [38/40] Iter[8/312]		Loss: 0.1040
2019-10-29 00:54:49,573 Training Epoch [38/40] Iter[9/312]		Loss: 0.1069
2019-10-29 00:54:49,695 Training Epoch [38/40] Iter[10/312]		Loss: 0.1062
2019-10-29 00:54:49,817 Training Epoch [38/40] Iter[11/312]		Loss: 0.1054
2019-10-29 00:54:49,939 Training Epoch [38/40] Iter[12/312]		Loss: 0.1038
2019-10-29 00:54:50,060 Training Epoch [38/40] Iter[13/312]		Loss: 0.1058
2019-10-29 00:54:50,183 Training Epoch [38/40] Iter[14/312]		Loss: 0.1079
2019-10-29 00:54:50,305 Training Epoch [38/40] Iter[15/312]		Loss: 0.1066
2019-10-29 00:54:50,426 Training Epoch [38/40] Iter[16/312]		Loss: 0.1079
2019-10-29 00:54:50,548 Training Epoch [38/40] Iter[17/312]		Loss: 0.1074
2019-10-29 00:54:50,670 Training Epoch [38/40] Iter[18/312]		Loss: 0.1059
2019-10-29 00:54:50,792 Training Epoch [38/40] Iter[19/312]		Loss: 0.1047
2019-10-29 00:54:50,914 Training Epoch [38/40] Iter[20/312]		Loss: 0.1043
2019-10-29 00:54:51,035 Training Epoch [38/40] Iter[21/312]		Loss: 0.1020
2019-10-29 00:54:51,157 Training Epoch [38/40] Iter[22/312]		Loss: 0.1004
2019-10-29 00:54:51,278 Training Epoch [38/40] Iter[23/312]		Loss: 0.1000
2019-10-29 00:54:51,400 Training Epoch [38/40] Iter[24/312]		Loss: 0.1007
2019-10-29 00:54:51,521 Training Epoch [38/40] Iter[25/312]		Loss: 0.1001
2019-10-29 00:54:51,642 Training Epoch [38/40] Iter[26/312]		Loss: 0.0993
2019-10-29 00:54:51,763 Training Epoch [38/40] Iter[27/312]		Loss: 0.0998
2019-10-29 00:54:51,884 Training Epoch [38/40] Iter[28/312]		Loss: 0.0990
2019-10-29 00:54:52,005 Training Epoch [38/40] Iter[29/312]		Loss: 0.0978
2019-10-29 00:54:52,126 Training Epoch [38/40] Iter[30/312]		Loss: 0.0988
2019-10-29 00:54:52,248 Training Epoch [38/40] Iter[31/312]		Loss: 0.1001
2019-10-29 00:54:52,369 Training Epoch [38/40] Iter[32/312]		Loss: 0.1007
2019-10-29 00:54:52,490 Training Epoch [38/40] Iter[33/312]		Loss: 0.1003
2019-10-29 00:54:52,611 Training Epoch [38/40] Iter[34/312]		Loss: 0.1000
2019-10-29 00:54:52,733 Training Epoch [38/40] Iter[35/312]		Loss: 0.1004
2019-10-29 00:54:52,854 Training Epoch [38/40] Iter[36/312]		Loss: 0.1007
2019-10-29 00:54:52,976 Training Epoch [38/40] Iter[37/312]		Loss: 0.1015
2019-10-29 00:54:53,097 Training Epoch [38/40] Iter[38/312]		Loss: 0.1005
2019-10-29 00:54:53,219 Training Epoch [38/40] Iter[39/312]		Loss: 0.1013
2019-10-29 00:54:53,340 Training Epoch [38/40] Iter[40/312]		Loss: 0.1021
2019-10-29 00:54:53,462 Training Epoch [38/40] Iter[41/312]		Loss: 0.1020
2019-10-29 00:54:53,583 Training Epoch [38/40] Iter[42/312]		Loss: 0.1031
2019-10-29 00:54:53,705 Training Epoch [38/40] Iter[43/312]		Loss: 0.1023
2019-10-29 00:54:53,826 Training Epoch [38/40] Iter[44/312]		Loss: 0.1031
2019-10-29 00:54:53,947 Training Epoch [38/40] Iter[45/312]		Loss: 0.1049
2019-10-29 00:54:54,069 Training Epoch [38/40] Iter[46/312]		Loss: 0.1057
2019-10-29 00:54:54,191 Training Epoch [38/40] Iter[47/312]		Loss: 0.1051
2019-10-29 00:54:54,313 Training Epoch [38/40] Iter[48/312]		Loss: 0.1043
2019-10-29 00:54:54,434 Training Epoch [38/40] Iter[49/312]		Loss: 0.1043
2019-10-29 00:54:54,555 Training Epoch [38/40] Iter[50/312]		Loss: 0.1033
2019-10-29 00:54:54,677 Training Epoch [38/40] Iter[51/312]		Loss: 0.1035
2019-10-29 00:54:54,798 Training Epoch [38/40] Iter[52/312]		Loss: 0.1026
2019-10-29 00:54:54,920 Training Epoch [38/40] Iter[53/312]		Loss: 0.1026
2019-10-29 00:54:55,041 Training Epoch [38/40] Iter[54/312]		Loss: 0.1019
2019-10-29 00:54:55,162 Training Epoch [38/40] Iter[55/312]		Loss: 0.1014
2019-10-29 00:54:55,284 Training Epoch [38/40] Iter[56/312]		Loss: 0.1014
2019-10-29 00:54:55,405 Training Epoch [38/40] Iter[57/312]		Loss: 0.1008
2019-10-29 00:54:55,526 Training Epoch [38/40] Iter[58/312]		Loss: 0.1005
2019-10-29 00:54:55,648 Training Epoch [38/40] Iter[59/312]		Loss: 0.1005
2019-10-29 00:54:55,769 Training Epoch [38/40] Iter[60/312]		Loss: 0.1019
2019-10-29 00:54:55,891 Training Epoch [38/40] Iter[61/312]		Loss: 0.1012
2019-10-29 00:54:56,012 Training Epoch [38/40] Iter[62/312]		Loss: 0.1010
2019-10-29 00:54:56,134 Training Epoch [38/40] Iter[63/312]		Loss: 0.1013
2019-10-29 00:54:56,255 Training Epoch [38/40] Iter[64/312]		Loss: 0.1011
2019-10-29 00:54:56,377 Training Epoch [38/40] Iter[65/312]		Loss: 0.1013
2019-10-29 00:54:56,499 Training Epoch [38/40] Iter[66/312]		Loss: 0.1017
2019-10-29 00:54:56,620 Training Epoch [38/40] Iter[67/312]		Loss: 0.1023
2019-10-29 00:54:56,741 Training Epoch [38/40] Iter[68/312]		Loss: 0.1018
2019-10-29 00:54:56,862 Training Epoch [38/40] Iter[69/312]		Loss: 0.1016
2019-10-29 00:54:56,983 Training Epoch [38/40] Iter[70/312]		Loss: 0.1013
2019-10-29 00:54:57,104 Training Epoch [38/40] Iter[71/312]		Loss: 0.1017
2019-10-29 00:54:57,225 Training Epoch [38/40] Iter[72/312]		Loss: 0.1015
2019-10-29 00:54:57,347 Training Epoch [38/40] Iter[73/312]		Loss: 0.1012
2019-10-29 00:54:57,468 Training Epoch [38/40] Iter[74/312]		Loss: 0.1007
2019-10-29 00:54:57,589 Training Epoch [38/40] Iter[75/312]		Loss: 0.1004
2019-10-29 00:54:57,710 Training Epoch [38/40] Iter[76/312]		Loss: 0.1000
2019-10-29 00:54:57,831 Training Epoch [38/40] Iter[77/312]		Loss: 0.1000
2019-10-29 00:54:57,953 Training Epoch [38/40] Iter[78/312]		Loss: 0.0997
2019-10-29 00:54:58,075 Training Epoch [38/40] Iter[79/312]		Loss: 0.0995
2019-10-29 00:54:58,196 Training Epoch [38/40] Iter[80/312]		Loss: 0.0992
2019-10-29 00:54:58,319 Training Epoch [38/40] Iter[81/312]		Loss: 0.0991
2019-10-29 00:54:58,440 Training Epoch [38/40] Iter[82/312]		Loss: 0.0986
2019-10-29 00:54:58,561 Training Epoch [38/40] Iter[83/312]		Loss: 0.0986
2019-10-29 00:54:58,682 Training Epoch [38/40] Iter[84/312]		Loss: 0.0985
2019-10-29 00:54:58,803 Training Epoch [38/40] Iter[85/312]		Loss: 0.0986
2019-10-29 00:54:58,925 Training Epoch [38/40] Iter[86/312]		Loss: 0.0987
2019-10-29 00:54:59,048 Training Epoch [38/40] Iter[87/312]		Loss: 0.0988
2019-10-29 00:54:59,170 Training Epoch [38/40] Iter[88/312]		Loss: 0.0986
2019-10-29 00:54:59,292 Training Epoch [38/40] Iter[89/312]		Loss: 0.0984
2019-10-29 00:54:59,414 Training Epoch [38/40] Iter[90/312]		Loss: 0.0983
2019-10-29 00:54:59,536 Training Epoch [38/40] Iter[91/312]		Loss: 0.0983
2019-10-29 00:54:59,658 Training Epoch [38/40] Iter[92/312]		Loss: 0.0984
2019-10-29 00:54:59,781 Training Epoch [38/40] Iter[93/312]		Loss: 0.0982
2019-10-29 00:54:59,902 Training Epoch [38/40] Iter[94/312]		Loss: 0.0981
2019-10-29 00:55:00,025 Training Epoch [38/40] Iter[95/312]		Loss: 0.0983
2019-10-29 00:55:00,147 Training Epoch [38/40] Iter[96/312]		Loss: 0.0983
2019-10-29 00:55:00,269 Training Epoch [38/40] Iter[97/312]		Loss: 0.0984
2019-10-29 00:55:00,391 Training Epoch [38/40] Iter[98/312]		Loss: 0.0986
2019-10-29 00:55:00,512 Training Epoch [38/40] Iter[99/312]		Loss: 0.0984
2019-10-29 00:55:00,633 Training Epoch [38/40] Iter[100/312]		Loss: 0.0988
2019-10-29 00:55:00,755 Training Epoch [38/40] Iter[101/312]		Loss: 0.0986
2019-10-29 00:55:00,876 Training Epoch [38/40] Iter[102/312]		Loss: 0.0986
2019-10-29 00:55:00,998 Training Epoch [38/40] Iter[103/312]		Loss: 0.0983
2019-10-29 00:55:01,119 Training Epoch [38/40] Iter[104/312]		Loss: 0.0985
2019-10-29 00:55:01,240 Training Epoch [38/40] Iter[105/312]		Loss: 0.0985
2019-10-29 00:55:01,362 Training Epoch [38/40] Iter[106/312]		Loss: 0.0985
2019-10-29 00:55:01,484 Training Epoch [38/40] Iter[107/312]		Loss: 0.0984
2019-10-29 00:55:01,605 Training Epoch [38/40] Iter[108/312]		Loss: 0.0990
2019-10-29 00:55:01,727 Training Epoch [38/40] Iter[109/312]		Loss: 0.0990
2019-10-29 00:55:01,848 Training Epoch [38/40] Iter[110/312]		Loss: 0.0990
2019-10-29 00:55:01,970 Training Epoch [38/40] Iter[111/312]		Loss: 0.0994
2019-10-29 00:55:02,091 Training Epoch [38/40] Iter[112/312]		Loss: 0.0991
2019-10-29 00:55:02,212 Training Epoch [38/40] Iter[113/312]		Loss: 0.0990
2019-10-29 00:55:02,334 Training Epoch [38/40] Iter[114/312]		Loss: 0.0989
2019-10-29 00:55:02,456 Training Epoch [38/40] Iter[115/312]		Loss: 0.0988
2019-10-29 00:55:02,578 Training Epoch [38/40] Iter[116/312]		Loss: 0.0989
2019-10-29 00:55:02,699 Training Epoch [38/40] Iter[117/312]		Loss: 0.0986
2019-10-29 00:55:02,821 Training Epoch [38/40] Iter[118/312]		Loss: 0.0984
2019-10-29 00:55:02,942 Training Epoch [38/40] Iter[119/312]		Loss: 0.0983
2019-10-29 00:55:03,063 Training Epoch [38/40] Iter[120/312]		Loss: 0.0983
2019-10-29 00:55:03,185 Training Epoch [38/40] Iter[121/312]		Loss: 0.0981
2019-10-29 00:55:03,307 Training Epoch [38/40] Iter[122/312]		Loss: 0.0979
2019-10-29 00:55:03,428 Training Epoch [38/40] Iter[123/312]		Loss: 0.0978
2019-10-29 00:55:03,550 Training Epoch [38/40] Iter[124/312]		Loss: 0.0976
2019-10-29 00:55:03,671 Training Epoch [38/40] Iter[125/312]		Loss: 0.0976
2019-10-29 00:55:03,793 Training Epoch [38/40] Iter[126/312]		Loss: 0.0974
2019-10-29 00:55:03,914 Training Epoch [38/40] Iter[127/312]		Loss: 0.0972
2019-10-29 00:55:04,036 Training Epoch [38/40] Iter[128/312]		Loss: 0.0972
2019-10-29 00:55:04,158 Training Epoch [38/40] Iter[129/312]		Loss: 0.0972
2019-10-29 00:55:04,280 Training Epoch [38/40] Iter[130/312]		Loss: 0.0973
2019-10-29 00:55:04,403 Training Epoch [38/40] Iter[131/312]		Loss: 0.0971
2019-10-29 00:55:04,524 Training Epoch [38/40] Iter[132/312]		Loss: 0.0971
2019-10-29 00:55:04,646 Training Epoch [38/40] Iter[133/312]		Loss: 0.0971
2019-10-29 00:55:04,767 Training Epoch [38/40] Iter[134/312]		Loss: 0.0972
2019-10-29 00:55:04,889 Training Epoch [38/40] Iter[135/312]		Loss: 0.0974
2019-10-29 00:55:05,010 Training Epoch [38/40] Iter[136/312]		Loss: 0.0975
2019-10-29 00:55:05,131 Training Epoch [38/40] Iter[137/312]		Loss: 0.0974
2019-10-29 00:55:05,253 Training Epoch [38/40] Iter[138/312]		Loss: 0.0975
2019-10-29 00:55:05,374 Training Epoch [38/40] Iter[139/312]		Loss: 0.0976
2019-10-29 00:55:05,495 Training Epoch [38/40] Iter[140/312]		Loss: 0.0976
2019-10-29 00:55:05,616 Training Epoch [38/40] Iter[141/312]		Loss: 0.0974
2019-10-29 00:55:05,738 Training Epoch [38/40] Iter[142/312]		Loss: 0.0977
2019-10-29 00:55:05,859 Training Epoch [38/40] Iter[143/312]		Loss: 0.0975
2019-10-29 00:55:05,980 Training Epoch [38/40] Iter[144/312]		Loss: 0.0977
2019-10-29 00:55:06,101 Training Epoch [38/40] Iter[145/312]		Loss: 0.0977
2019-10-29 00:55:06,222 Training Epoch [38/40] Iter[146/312]		Loss: 0.0979
2019-10-29 00:55:06,343 Training Epoch [38/40] Iter[147/312]		Loss: 0.0978
2019-10-29 00:55:06,464 Training Epoch [38/40] Iter[148/312]		Loss: 0.0978
2019-10-29 00:55:06,586 Training Epoch [38/40] Iter[149/312]		Loss: 0.0976
2019-10-29 00:55:06,708 Training Epoch [38/40] Iter[150/312]		Loss: 0.0976
2019-10-29 00:55:06,829 Training Epoch [38/40] Iter[151/312]		Loss: 0.0976
2019-10-29 00:55:06,951 Training Epoch [38/40] Iter[152/312]		Loss: 0.0975
2019-10-29 00:55:07,072 Training Epoch [38/40] Iter[153/312]		Loss: 0.0975
2019-10-29 00:55:07,194 Training Epoch [38/40] Iter[154/312]		Loss: 0.0972
2019-10-29 00:55:07,315 Training Epoch [38/40] Iter[155/312]		Loss: 0.0973
2019-10-29 00:55:07,437 Training Epoch [38/40] Iter[156/312]		Loss: 0.0975
2019-10-29 00:55:07,558 Training Epoch [38/40] Iter[157/312]		Loss: 0.0975
2019-10-29 00:55:07,680 Training Epoch [38/40] Iter[158/312]		Loss: 0.0975
2019-10-29 00:55:07,802 Training Epoch [38/40] Iter[159/312]		Loss: 0.0975
2019-10-29 00:55:07,923 Training Epoch [38/40] Iter[160/312]		Loss: 0.0974
2019-10-29 00:55:08,045 Training Epoch [38/40] Iter[161/312]		Loss: 0.0973
2019-10-29 00:55:08,167 Training Epoch [38/40] Iter[162/312]		Loss: 0.0973
2019-10-29 00:55:08,288 Training Epoch [38/40] Iter[163/312]		Loss: 0.0974
2019-10-29 00:55:08,409 Training Epoch [38/40] Iter[164/312]		Loss: 0.0976
2019-10-29 00:55:08,530 Training Epoch [38/40] Iter[165/312]		Loss: 0.0975
2019-10-29 00:55:08,651 Training Epoch [38/40] Iter[166/312]		Loss: 0.0975
2019-10-29 00:55:08,773 Training Epoch [38/40] Iter[167/312]		Loss: 0.0974
2019-10-29 00:55:08,894 Training Epoch [38/40] Iter[168/312]		Loss: 0.0975
2019-10-29 00:55:09,015 Training Epoch [38/40] Iter[169/312]		Loss: 0.0976
2019-10-29 00:55:09,137 Training Epoch [38/40] Iter[170/312]		Loss: 0.0976
2019-10-29 00:55:09,258 Training Epoch [38/40] Iter[171/312]		Loss: 0.0974
2019-10-29 00:55:09,379 Training Epoch [38/40] Iter[172/312]		Loss: 0.0976
2019-10-29 00:55:09,500 Training Epoch [38/40] Iter[173/312]		Loss: 0.0976
2019-10-29 00:55:09,622 Training Epoch [38/40] Iter[174/312]		Loss: 0.0975
2019-10-29 00:55:09,744 Training Epoch [38/40] Iter[175/312]		Loss: 0.0973
2019-10-29 00:55:09,865 Training Epoch [38/40] Iter[176/312]		Loss: 0.0973
2019-10-29 00:55:09,987 Training Epoch [38/40] Iter[177/312]		Loss: 0.0971
2019-10-29 00:55:10,108 Training Epoch [38/40] Iter[178/312]		Loss: 0.0971
2019-10-29 00:55:10,229 Training Epoch [38/40] Iter[179/312]		Loss: 0.0973
2019-10-29 00:55:10,351 Training Epoch [38/40] Iter[180/312]		Loss: 0.0975
2019-10-29 00:55:10,473 Training Epoch [38/40] Iter[181/312]		Loss: 0.0974
2019-10-29 00:55:10,594 Training Epoch [38/40] Iter[182/312]		Loss: 0.0978
2019-10-29 00:55:10,715 Training Epoch [38/40] Iter[183/312]		Loss: 0.0978
2019-10-29 00:55:10,836 Training Epoch [38/40] Iter[184/312]		Loss: 0.0979
2019-10-29 00:55:10,957 Training Epoch [38/40] Iter[185/312]		Loss: 0.0977
2019-10-29 00:55:11,078 Training Epoch [38/40] Iter[186/312]		Loss: 0.0976
2019-10-29 00:55:11,200 Training Epoch [38/40] Iter[187/312]		Loss: 0.0974
2019-10-29 00:55:11,322 Training Epoch [38/40] Iter[188/312]		Loss: 0.0973
2019-10-29 00:55:11,444 Training Epoch [38/40] Iter[189/312]		Loss: 0.0973
2019-10-29 00:55:11,565 Training Epoch [38/40] Iter[190/312]		Loss: 0.0971
2019-10-29 00:55:11,686 Training Epoch [38/40] Iter[191/312]		Loss: 0.0971
2019-10-29 00:55:11,807 Training Epoch [38/40] Iter[192/312]		Loss: 0.0974
2019-10-29 00:55:11,929 Training Epoch [38/40] Iter[193/312]		Loss: 0.0975
2019-10-29 00:55:12,050 Training Epoch [38/40] Iter[194/312]		Loss: 0.0977
2019-10-29 00:55:12,172 Training Epoch [38/40] Iter[195/312]		Loss: 0.0980
2019-10-29 00:55:12,294 Training Epoch [38/40] Iter[196/312]		Loss: 0.0980
2019-10-29 00:55:12,415 Training Epoch [38/40] Iter[197/312]		Loss: 0.0980
2019-10-29 00:55:12,537 Training Epoch [38/40] Iter[198/312]		Loss: 0.0979
2019-10-29 00:55:12,658 Training Epoch [38/40] Iter[199/312]		Loss: 0.0982
2019-10-29 00:55:12,780 Training Epoch [38/40] Iter[200/312]		Loss: 0.0983
2019-10-29 00:55:12,901 Training Epoch [38/40] Iter[201/312]		Loss: 0.0982
2019-10-29 00:55:13,022 Training Epoch [38/40] Iter[202/312]		Loss: 0.0983
2019-10-29 00:55:13,144 Training Epoch [38/40] Iter[203/312]		Loss: 0.0984
2019-10-29 00:55:13,265 Training Epoch [38/40] Iter[204/312]		Loss: 0.0985
2019-10-29 00:55:13,386 Training Epoch [38/40] Iter[205/312]		Loss: 0.0984
2019-10-29 00:55:13,508 Training Epoch [38/40] Iter[206/312]		Loss: 0.0983
2019-10-29 00:55:13,629 Training Epoch [38/40] Iter[207/312]		Loss: 0.0981
2019-10-29 00:55:13,751 Training Epoch [38/40] Iter[208/312]		Loss: 0.0981
2019-10-29 00:55:13,872 Training Epoch [38/40] Iter[209/312]		Loss: 0.0979
2019-10-29 00:55:13,993 Training Epoch [38/40] Iter[210/312]		Loss: 0.0980
2019-10-29 00:55:14,114 Training Epoch [38/40] Iter[211/312]		Loss: 0.0980
2019-10-29 00:55:14,235 Training Epoch [38/40] Iter[212/312]		Loss: 0.0979
2019-10-29 00:55:14,356 Training Epoch [38/40] Iter[213/312]		Loss: 0.0981
2019-10-29 00:55:14,477 Training Epoch [38/40] Iter[214/312]		Loss: 0.0982
2019-10-29 00:55:14,598 Training Epoch [38/40] Iter[215/312]		Loss: 0.0981
2019-10-29 00:55:14,720 Training Epoch [38/40] Iter[216/312]		Loss: 0.0980
2019-10-29 00:55:14,841 Training Epoch [38/40] Iter[217/312]		Loss: 0.0982
2019-10-29 00:55:14,963 Training Epoch [38/40] Iter[218/312]		Loss: 0.0982
2019-10-29 00:55:15,084 Training Epoch [38/40] Iter[219/312]		Loss: 0.0981
2019-10-29 00:55:15,205 Training Epoch [38/40] Iter[220/312]		Loss: 0.0980
2019-10-29 00:55:15,327 Training Epoch [38/40] Iter[221/312]		Loss: 0.0980
2019-10-29 00:55:15,448 Training Epoch [38/40] Iter[222/312]		Loss: 0.0979
2019-10-29 00:55:15,570 Training Epoch [38/40] Iter[223/312]		Loss: 0.0980
2019-10-29 00:55:15,692 Training Epoch [38/40] Iter[224/312]		Loss: 0.0980
2019-10-29 00:55:15,813 Training Epoch [38/40] Iter[225/312]		Loss: 0.0980
2019-10-29 00:55:15,935 Training Epoch [38/40] Iter[226/312]		Loss: 0.0979
2019-10-29 00:55:16,056 Training Epoch [38/40] Iter[227/312]		Loss: 0.0980
2019-10-29 00:55:16,178 Training Epoch [38/40] Iter[228/312]		Loss: 0.0980
2019-10-29 00:55:16,299 Training Epoch [38/40] Iter[229/312]		Loss: 0.0980
2019-10-29 00:55:16,421 Training Epoch [38/40] Iter[230/312]		Loss: 0.0981
2019-10-29 00:55:16,543 Training Epoch [38/40] Iter[231/312]		Loss: 0.0981
2019-10-29 00:55:16,664 Training Epoch [38/40] Iter[232/312]		Loss: 0.0983
2019-10-29 00:55:16,786 Training Epoch [38/40] Iter[233/312]		Loss: 0.0982
2019-10-29 00:55:16,907 Training Epoch [38/40] Iter[234/312]		Loss: 0.0985
2019-10-29 00:55:17,028 Training Epoch [38/40] Iter[235/312]		Loss: 0.0985
2019-10-29 00:55:17,149 Training Epoch [38/40] Iter[236/312]		Loss: 0.0986
2019-10-29 00:55:17,271 Training Epoch [38/40] Iter[237/312]		Loss: 0.0987
2019-10-29 00:55:17,392 Training Epoch [38/40] Iter[238/312]		Loss: 0.0989
2019-10-29 00:55:17,513 Training Epoch [38/40] Iter[239/312]		Loss: 0.0989
2019-10-29 00:55:17,634 Training Epoch [38/40] Iter[240/312]		Loss: 0.0989
2019-10-29 00:55:17,755 Training Epoch [38/40] Iter[241/312]		Loss: 0.0990
2019-10-29 00:55:17,877 Training Epoch [38/40] Iter[242/312]		Loss: 0.0989
2019-10-29 00:55:17,998 Training Epoch [38/40] Iter[243/312]		Loss: 0.0988
2019-10-29 00:55:18,119 Training Epoch [38/40] Iter[244/312]		Loss: 0.0988
2019-10-29 00:55:18,241 Training Epoch [38/40] Iter[245/312]		Loss: 0.0987
2019-10-29 00:55:18,362 Training Epoch [38/40] Iter[246/312]		Loss: 0.0986
2019-10-29 00:55:18,484 Training Epoch [38/40] Iter[247/312]		Loss: 0.0986
2019-10-29 00:55:18,605 Training Epoch [38/40] Iter[248/312]		Loss: 0.0985
2019-10-29 00:55:18,727 Training Epoch [38/40] Iter[249/312]		Loss: 0.0985
2019-10-29 00:55:18,848 Training Epoch [38/40] Iter[250/312]		Loss: 0.0985
2019-10-29 00:55:18,969 Training Epoch [38/40] Iter[251/312]		Loss: 0.0985
2019-10-29 00:55:19,092 Training Epoch [38/40] Iter[252/312]		Loss: 0.0985
2019-10-29 00:55:19,213 Training Epoch [38/40] Iter[253/312]		Loss: 0.0983
2019-10-29 00:55:19,334 Training Epoch [38/40] Iter[254/312]		Loss: 0.0983
2019-10-29 00:55:19,456 Training Epoch [38/40] Iter[255/312]		Loss: 0.0983
2019-10-29 00:55:19,577 Training Epoch [38/40] Iter[256/312]		Loss: 0.0981
2019-10-29 00:55:19,699 Training Epoch [38/40] Iter[257/312]		Loss: 0.0981
2019-10-29 00:55:19,822 Training Epoch [38/40] Iter[258/312]		Loss: 0.0981
2019-10-29 00:55:19,944 Training Epoch [38/40] Iter[259/312]		Loss: 0.0984
2019-10-29 00:55:20,065 Training Epoch [38/40] Iter[260/312]		Loss: 0.0987
2019-10-29 00:55:20,186 Training Epoch [38/40] Iter[261/312]		Loss: 0.0987
2019-10-29 00:55:20,308 Training Epoch [38/40] Iter[262/312]		Loss: 0.0991
2019-10-29 00:55:20,429 Training Epoch [38/40] Iter[263/312]		Loss: 0.0992
2019-10-29 00:55:20,551 Training Epoch [38/40] Iter[264/312]		Loss: 0.0992
2019-10-29 00:55:20,672 Training Epoch [38/40] Iter[265/312]		Loss: 0.0991
2019-10-29 00:55:20,793 Training Epoch [38/40] Iter[266/312]		Loss: 0.0990
2019-10-29 00:55:20,914 Training Epoch [38/40] Iter[267/312]		Loss: 0.0991
2019-10-29 00:55:21,035 Training Epoch [38/40] Iter[268/312]		Loss: 0.0991
2019-10-29 00:55:21,157 Training Epoch [38/40] Iter[269/312]		Loss: 0.0992
2019-10-29 00:55:21,278 Training Epoch [38/40] Iter[270/312]		Loss: 0.0990
2019-10-29 00:55:21,400 Training Epoch [38/40] Iter[271/312]		Loss: 0.0991
2019-10-29 00:55:21,521 Training Epoch [38/40] Iter[272/312]		Loss: 0.0991
2019-10-29 00:55:21,642 Training Epoch [38/40] Iter[273/312]		Loss: 0.0992
2019-10-29 00:55:21,764 Training Epoch [38/40] Iter[274/312]		Loss: 0.0991
2019-10-29 00:55:21,885 Training Epoch [38/40] Iter[275/312]		Loss: 0.0989
2019-10-29 00:55:22,006 Training Epoch [38/40] Iter[276/312]		Loss: 0.0988
2019-10-29 00:55:22,127 Training Epoch [38/40] Iter[277/312]		Loss: 0.0990
2019-10-29 00:55:22,249 Training Epoch [38/40] Iter[278/312]		Loss: 0.0991
2019-10-29 00:55:22,370 Training Epoch [38/40] Iter[279/312]		Loss: 0.0991
2019-10-29 00:55:22,492 Training Epoch [38/40] Iter[280/312]		Loss: 0.0990
2019-10-29 00:55:22,613 Training Epoch [38/40] Iter[281/312]		Loss: 0.0991
2019-10-29 00:55:22,734 Training Epoch [38/40] Iter[282/312]		Loss: 0.0991
2019-10-29 00:55:22,855 Training Epoch [38/40] Iter[283/312]		Loss: 0.0990
2019-10-29 00:55:22,976 Training Epoch [38/40] Iter[284/312]		Loss: 0.0990
2019-10-29 00:55:23,097 Training Epoch [38/40] Iter[285/312]		Loss: 0.0990
2019-10-29 00:55:23,218 Training Epoch [38/40] Iter[286/312]		Loss: 0.0990
2019-10-29 00:55:23,339 Training Epoch [38/40] Iter[287/312]		Loss: 0.0989
2019-10-29 00:55:23,460 Training Epoch [38/40] Iter[288/312]		Loss: 0.0990
2019-10-29 00:55:23,581 Training Epoch [38/40] Iter[289/312]		Loss: 0.0990
2019-10-29 00:55:23,701 Training Epoch [38/40] Iter[290/312]		Loss: 0.0991
2019-10-29 00:55:23,822 Training Epoch [38/40] Iter[291/312]		Loss: 0.0993
2019-10-29 00:55:23,943 Training Epoch [38/40] Iter[292/312]		Loss: 0.0992
2019-10-29 00:55:24,064 Training Epoch [38/40] Iter[293/312]		Loss: 0.0993
2019-10-29 00:55:24,185 Training Epoch [38/40] Iter[294/312]		Loss: 0.0993
2019-10-29 00:55:24,306 Training Epoch [38/40] Iter[295/312]		Loss: 0.0995
2019-10-29 00:55:24,428 Training Epoch [38/40] Iter[296/312]		Loss: 0.0995
2019-10-29 00:55:24,549 Training Epoch [38/40] Iter[297/312]		Loss: 0.0998
2019-10-29 00:55:24,670 Training Epoch [38/40] Iter[298/312]		Loss: 0.0998
2019-10-29 00:55:24,792 Training Epoch [38/40] Iter[299/312]		Loss: 0.0999
2019-10-29 00:55:24,914 Training Epoch [38/40] Iter[300/312]		Loss: 0.0998
2019-10-29 00:55:25,035 Training Epoch [38/40] Iter[301/312]		Loss: 0.0999
2019-10-29 00:55:25,157 Training Epoch [38/40] Iter[302/312]		Loss: 0.1000
2019-10-29 00:55:25,278 Training Epoch [38/40] Iter[303/312]		Loss: 0.0999
2019-10-29 00:55:25,400 Training Epoch [38/40] Iter[304/312]		Loss: 0.0998
2019-10-29 00:55:25,521 Training Epoch [38/40] Iter[305/312]		Loss: 0.0997
2019-10-29 00:55:25,641 Training Epoch [38/40] Iter[306/312]		Loss: 0.0997
2019-10-29 00:55:25,762 Training Epoch [38/40] Iter[307/312]		Loss: 0.0996
2019-10-29 00:55:25,883 Training Epoch [38/40] Iter[308/312]		Loss: 0.0997
2019-10-29 00:55:26,005 Training Epoch [38/40] Iter[309/312]		Loss: 0.0997
2019-10-29 00:55:26,126 Training Epoch [38/40] Iter[310/312]		Loss: 0.0995
2019-10-29 00:55:26,247 Training Epoch [38/40] Iter[311/312]		Loss: 0.0996
2019-10-29 00:55:26,307 Training Epoch [38/40] Iter[312/312]		Loss: 0.0996
2019-10-29 00:55:26,677 Testing Epoch [38/40] Iter[0/62]		Loss: 0.0908
2019-10-29 00:55:26,715 Testing Epoch [38/40] Iter[1/62]		Loss: 0.1233
2019-10-29 00:55:26,762 Testing Epoch [38/40] Iter[2/62]		Loss: 0.1149
2019-10-29 00:55:26,792 Testing Epoch [38/40] Iter[3/62]		Loss: 0.1126
2019-10-29 00:55:26,826 Testing Epoch [38/40] Iter[4/62]		Loss: 0.1093
2019-10-29 00:55:26,858 Testing Epoch [38/40] Iter[5/62]		Loss: 0.1064
2019-10-29 00:55:26,894 Testing Epoch [38/40] Iter[6/62]		Loss: 0.1071
2019-10-29 00:55:26,923 Testing Epoch [38/40] Iter[7/62]		Loss: 0.1135
2019-10-29 00:55:26,953 Testing Epoch [38/40] Iter[8/62]		Loss: 0.1203
2019-10-29 00:55:26,990 Testing Epoch [38/40] Iter[9/62]		Loss: 0.1177
2019-10-29 00:55:27,020 Testing Epoch [38/40] Iter[10/62]		Loss: 0.1156
2019-10-29 00:55:27,051 Testing Epoch [38/40] Iter[11/62]		Loss: 0.1197
2019-10-29 00:55:27,086 Testing Epoch [38/40] Iter[12/62]		Loss: 0.1204
2019-10-29 00:55:27,117 Testing Epoch [38/40] Iter[13/62]		Loss: 0.1225
2019-10-29 00:55:27,148 Testing Epoch [38/40] Iter[14/62]		Loss: 0.1349
2019-10-29 00:55:27,182 Testing Epoch [38/40] Iter[15/62]		Loss: 0.1365
2019-10-29 00:55:27,218 Testing Epoch [38/40] Iter[16/62]		Loss: 0.1344
2019-10-29 00:55:27,249 Testing Epoch [38/40] Iter[17/62]		Loss: 0.1337
2019-10-29 00:55:27,279 Testing Epoch [38/40] Iter[18/62]		Loss: 0.1307
2019-10-29 00:55:27,314 Testing Epoch [38/40] Iter[19/62]		Loss: 0.1287
2019-10-29 00:55:27,344 Testing Epoch [38/40] Iter[20/62]		Loss: 0.1303
2019-10-29 00:55:27,375 Testing Epoch [38/40] Iter[21/62]		Loss: 0.1282
2019-10-29 00:55:27,410 Testing Epoch [38/40] Iter[22/62]		Loss: 0.1277
2019-10-29 00:55:27,441 Testing Epoch [38/40] Iter[23/62]		Loss: 0.1280
2019-10-29 00:55:27,472 Testing Epoch [38/40] Iter[24/62]		Loss: 0.1296
2019-10-29 00:55:27,510 Testing Epoch [38/40] Iter[25/62]		Loss: 0.1290
2019-10-29 00:55:27,541 Testing Epoch [38/40] Iter[26/62]		Loss: 0.1278
2019-10-29 00:55:27,571 Testing Epoch [38/40] Iter[27/62]		Loss: 0.1325
2019-10-29 00:55:27,602 Testing Epoch [38/40] Iter[28/62]		Loss: 0.1341
2019-10-29 00:55:27,633 Testing Epoch [38/40] Iter[29/62]		Loss: 0.1342
2019-10-29 00:55:27,664 Testing Epoch [38/40] Iter[30/62]		Loss: 0.1358
2019-10-29 00:55:27,694 Testing Epoch [38/40] Iter[31/62]		Loss: 0.1350
2019-10-29 00:55:27,725 Testing Epoch [38/40] Iter[32/62]		Loss: 0.1364
2019-10-29 00:55:27,756 Testing Epoch [38/40] Iter[33/62]		Loss: 0.1344
2019-10-29 00:55:27,787 Testing Epoch [38/40] Iter[34/62]		Loss: 0.1359
2019-10-29 00:55:27,817 Testing Epoch [38/40] Iter[35/62]		Loss: 0.1363
2019-10-29 00:55:27,848 Testing Epoch [38/40] Iter[36/62]		Loss: 0.1345
2019-10-29 00:55:27,879 Testing Epoch [38/40] Iter[37/62]		Loss: 0.1342
2019-10-29 00:55:27,910 Testing Epoch [38/40] Iter[38/62]		Loss: 0.1343
2019-10-29 00:55:27,941 Testing Epoch [38/40] Iter[39/62]		Loss: 0.1347
2019-10-29 00:55:27,971 Testing Epoch [38/40] Iter[40/62]		Loss: 0.1350
2019-10-29 00:55:28,002 Testing Epoch [38/40] Iter[41/62]		Loss: 0.1351
2019-10-29 00:55:28,033 Testing Epoch [38/40] Iter[42/62]		Loss: 0.1338
2019-10-29 00:55:28,064 Testing Epoch [38/40] Iter[43/62]		Loss: 0.1332
2019-10-29 00:55:28,095 Testing Epoch [38/40] Iter[44/62]		Loss: 0.1320
2019-10-29 00:55:28,126 Testing Epoch [38/40] Iter[45/62]		Loss: 0.1330
2019-10-29 00:55:28,157 Testing Epoch [38/40] Iter[46/62]		Loss: 0.1332
2019-10-29 00:55:28,187 Testing Epoch [38/40] Iter[47/62]		Loss: 0.1379
2019-10-29 00:55:28,218 Testing Epoch [38/40] Iter[48/62]		Loss: 0.1370
2019-10-29 00:55:28,249 Testing Epoch [38/40] Iter[49/62]		Loss: 0.1385
2019-10-29 00:55:28,279 Testing Epoch [38/40] Iter[50/62]		Loss: 0.1382
2019-10-29 00:55:28,310 Testing Epoch [38/40] Iter[51/62]		Loss: 0.1383
2019-10-29 00:55:28,341 Testing Epoch [38/40] Iter[52/62]		Loss: 0.1372
2019-10-29 00:55:28,372 Testing Epoch [38/40] Iter[53/62]		Loss: 0.1370
2019-10-29 00:55:28,403 Testing Epoch [38/40] Iter[54/62]		Loss: 0.1365
2019-10-29 00:55:28,433 Testing Epoch [38/40] Iter[55/62]		Loss: 0.1366
2019-10-29 00:55:28,464 Testing Epoch [38/40] Iter[56/62]		Loss: 0.1364
2019-10-29 00:55:28,494 Testing Epoch [38/40] Iter[57/62]		Loss: 0.1363
2019-10-29 00:55:28,525 Testing Epoch [38/40] Iter[58/62]		Loss: 0.1358
2019-10-29 00:55:28,555 Testing Epoch [38/40] Iter[59/62]		Loss: 0.1358
2019-10-29 00:55:28,585 Testing Epoch [38/40] Iter[60/62]		Loss: 0.1351
2019-10-29 00:55:28,616 Testing Epoch [38/40] Iter[61/62]		Loss: 0.1348
2019-10-29 00:55:28,633 Testing Epoch [38/40] Iter[62/62]		Loss: 0.1355
2019-10-29 00:55:28,696 Saving the Model
2019-10-29 00:55:29,113 Training Epoch [39/40] Iter[0/312]		Loss: 0.0626
2019-10-29 00:55:29,234 Training Epoch [39/40] Iter[1/312]		Loss: 0.0967
2019-10-29 00:55:29,361 Training Epoch [39/40] Iter[2/312]		Loss: 0.1034
2019-10-29 00:55:29,483 Training Epoch [39/40] Iter[3/312]		Loss: 0.1158
2019-10-29 00:55:29,606 Training Epoch [39/40] Iter[4/312]		Loss: 0.1136
2019-10-29 00:55:29,728 Training Epoch [39/40] Iter[5/312]		Loss: 0.1087
2019-10-29 00:55:29,848 Training Epoch [39/40] Iter[6/312]		Loss: 0.1053
2019-10-29 00:55:29,970 Training Epoch [39/40] Iter[7/312]		Loss: 0.1018
2019-10-29 00:55:30,092 Training Epoch [39/40] Iter[8/312]		Loss: 0.1070
2019-10-29 00:55:30,213 Training Epoch [39/40] Iter[9/312]		Loss: 0.1068
2019-10-29 00:55:30,334 Training Epoch [39/40] Iter[10/312]		Loss: 0.1074
2019-10-29 00:55:30,456 Training Epoch [39/40] Iter[11/312]		Loss: 0.1103
2019-10-29 00:55:30,577 Training Epoch [39/40] Iter[12/312]		Loss: 0.1108
2019-10-29 00:55:30,699 Training Epoch [39/40] Iter[13/312]		Loss: 0.1100
2019-10-29 00:55:30,820 Training Epoch [39/40] Iter[14/312]		Loss: 0.1081
2019-10-29 00:55:30,942 Training Epoch [39/40] Iter[15/312]		Loss: 0.1068
2019-10-29 00:55:31,063 Training Epoch [39/40] Iter[16/312]		Loss: 0.1052
2019-10-29 00:55:31,184 Training Epoch [39/40] Iter[17/312]		Loss: 0.1054
2019-10-29 00:55:31,306 Training Epoch [39/40] Iter[18/312]		Loss: 0.1038
2019-10-29 00:55:31,427 Training Epoch [39/40] Iter[19/312]		Loss: 0.1042
2019-10-29 00:55:31,549 Training Epoch [39/40] Iter[20/312]		Loss: 0.1029
2019-10-29 00:55:31,670 Training Epoch [39/40] Iter[21/312]		Loss: 0.1027
2019-10-29 00:55:31,791 Training Epoch [39/40] Iter[22/312]		Loss: 0.1018
2019-10-29 00:55:31,912 Training Epoch [39/40] Iter[23/312]		Loss: 0.1030
2019-10-29 00:55:32,033 Training Epoch [39/40] Iter[24/312]		Loss: 0.1033
2019-10-29 00:55:32,154 Training Epoch [39/40] Iter[25/312]		Loss: 0.1053
2019-10-29 00:55:32,276 Training Epoch [39/40] Iter[26/312]		Loss: 0.1042
2019-10-29 00:55:32,397 Training Epoch [39/40] Iter[27/312]		Loss: 0.1037
2019-10-29 00:55:32,518 Training Epoch [39/40] Iter[28/312]		Loss: 0.1039
2019-10-29 00:55:32,639 Training Epoch [39/40] Iter[29/312]		Loss: 0.1036
2019-10-29 00:55:32,760 Training Epoch [39/40] Iter[30/312]		Loss: 0.1042
2019-10-29 00:55:32,882 Training Epoch [39/40] Iter[31/312]		Loss: 0.1032
2019-10-29 00:55:33,003 Training Epoch [39/40] Iter[32/312]		Loss: 0.1048
2019-10-29 00:55:33,129 Training Epoch [39/40] Iter[33/312]		Loss: 0.1044
2019-10-29 00:55:33,250 Training Epoch [39/40] Iter[34/312]		Loss: 0.1040
2019-10-29 00:55:33,372 Training Epoch [39/40] Iter[35/312]		Loss: 0.1049
2019-10-29 00:55:33,493 Training Epoch [39/40] Iter[36/312]		Loss: 0.1041
2019-10-29 00:55:33,615 Training Epoch [39/40] Iter[37/312]		Loss: 0.1042
2019-10-29 00:55:33,736 Training Epoch [39/40] Iter[38/312]		Loss: 0.1045
2019-10-29 00:55:33,858 Training Epoch [39/40] Iter[39/312]		Loss: 0.1040
2019-10-29 00:55:33,980 Training Epoch [39/40] Iter[40/312]		Loss: 0.1037
2019-10-29 00:55:34,101 Training Epoch [39/40] Iter[41/312]		Loss: 0.1031
2019-10-29 00:55:34,222 Training Epoch [39/40] Iter[42/312]		Loss: 0.1048
2019-10-29 00:55:34,343 Training Epoch [39/40] Iter[43/312]		Loss: 0.1038
2019-10-29 00:55:34,464 Training Epoch [39/40] Iter[44/312]		Loss: 0.1031
2019-10-29 00:55:34,586 Training Epoch [39/40] Iter[45/312]		Loss: 0.1030
2019-10-29 00:55:34,707 Training Epoch [39/40] Iter[46/312]		Loss: 0.1022
2019-10-29 00:55:34,828 Training Epoch [39/40] Iter[47/312]		Loss: 0.1025
2019-10-29 00:55:34,950 Training Epoch [39/40] Iter[48/312]		Loss: 0.1020
2019-10-29 00:55:35,071 Training Epoch [39/40] Iter[49/312]		Loss: 0.1015
2019-10-29 00:55:35,193 Training Epoch [39/40] Iter[50/312]		Loss: 0.1011
2019-10-29 00:55:35,316 Training Epoch [39/40] Iter[51/312]		Loss: 0.1014
2019-10-29 00:55:35,437 Training Epoch [39/40] Iter[52/312]		Loss: 0.1014
2019-10-29 00:55:35,559 Training Epoch [39/40] Iter[53/312]		Loss: 0.1020
2019-10-29 00:55:35,680 Training Epoch [39/40] Iter[54/312]		Loss: 0.1021
2019-10-29 00:55:35,801 Training Epoch [39/40] Iter[55/312]		Loss: 0.1021
2019-10-29 00:55:35,922 Training Epoch [39/40] Iter[56/312]		Loss: 0.1029
2019-10-29 00:55:36,044 Training Epoch [39/40] Iter[57/312]		Loss: 0.1029
2019-10-29 00:55:36,165 Training Epoch [39/40] Iter[58/312]		Loss: 0.1029
2019-10-29 00:55:36,286 Training Epoch [39/40] Iter[59/312]		Loss: 0.1024
2019-10-29 00:55:36,407 Training Epoch [39/40] Iter[60/312]		Loss: 0.1022
2019-10-29 00:55:36,528 Training Epoch [39/40] Iter[61/312]		Loss: 0.1017
2019-10-29 00:55:36,649 Training Epoch [39/40] Iter[62/312]		Loss: 0.1018
2019-10-29 00:55:36,771 Training Epoch [39/40] Iter[63/312]		Loss: 0.1016
2019-10-29 00:55:36,892 Training Epoch [39/40] Iter[64/312]		Loss: 0.1012
2019-10-29 00:55:37,014 Training Epoch [39/40] Iter[65/312]		Loss: 0.1012
2019-10-29 00:55:37,172 Training Epoch [39/40] Iter[66/312]		Loss: 0.1015
2019-10-29 00:55:37,293 Training Epoch [39/40] Iter[67/312]		Loss: 0.1019
2019-10-29 00:55:37,415 Training Epoch [39/40] Iter[68/312]		Loss: 0.1021
2019-10-29 00:55:37,536 Training Epoch [39/40] Iter[69/312]		Loss: 0.1017
2019-10-29 00:55:37,658 Training Epoch [39/40] Iter[70/312]		Loss: 0.1012
2019-10-29 00:55:37,779 Training Epoch [39/40] Iter[71/312]		Loss: 0.1014
2019-10-29 00:55:37,900 Training Epoch [39/40] Iter[72/312]		Loss: 0.1011
2019-10-29 00:55:38,021 Training Epoch [39/40] Iter[73/312]		Loss: 0.1017
2019-10-29 00:55:38,142 Training Epoch [39/40] Iter[74/312]		Loss: 0.1014
2019-10-29 00:55:38,264 Training Epoch [39/40] Iter[75/312]		Loss: 0.1010
2019-10-29 00:55:38,386 Training Epoch [39/40] Iter[76/312]		Loss: 0.1010
2019-10-29 00:55:38,508 Training Epoch [39/40] Iter[77/312]		Loss: 0.1007
2019-10-29 00:55:38,629 Training Epoch [39/40] Iter[78/312]		Loss: 0.1005
2019-10-29 00:55:38,751 Training Epoch [39/40] Iter[79/312]		Loss: 0.1007
2019-10-29 00:55:38,872 Training Epoch [39/40] Iter[80/312]		Loss: 0.1004
2019-10-29 00:55:38,993 Training Epoch [39/40] Iter[81/312]		Loss: 0.1006
2019-10-29 00:55:39,115 Training Epoch [39/40] Iter[82/312]		Loss: 0.1006
2019-10-29 00:55:39,236 Training Epoch [39/40] Iter[83/312]		Loss: 0.1010
2019-10-29 00:55:39,358 Training Epoch [39/40] Iter[84/312]		Loss: 0.1008
2019-10-29 00:55:39,479 Training Epoch [39/40] Iter[85/312]		Loss: 0.1006
2019-10-29 00:55:39,601 Training Epoch [39/40] Iter[86/312]		Loss: 0.1006
2019-10-29 00:55:39,722 Training Epoch [39/40] Iter[87/312]		Loss: 0.1004
2019-10-29 00:55:39,843 Training Epoch [39/40] Iter[88/312]		Loss: 0.1005
2019-10-29 00:55:39,965 Training Epoch [39/40] Iter[89/312]		Loss: 0.1004
2019-10-29 00:55:40,086 Training Epoch [39/40] Iter[90/312]		Loss: 0.1010
2019-10-29 00:55:40,208 Training Epoch [39/40] Iter[91/312]		Loss: 0.1006
2019-10-29 00:55:40,331 Training Epoch [39/40] Iter[92/312]		Loss: 0.1006
2019-10-29 00:55:40,453 Training Epoch [39/40] Iter[93/312]		Loss: 0.1002
2019-10-29 00:55:40,574 Training Epoch [39/40] Iter[94/312]		Loss: 0.1000
2019-10-29 00:55:40,696 Training Epoch [39/40] Iter[95/312]		Loss: 0.0999
2019-10-29 00:55:40,817 Training Epoch [39/40] Iter[96/312]		Loss: 0.0999
2019-10-29 00:55:40,938 Training Epoch [39/40] Iter[97/312]		Loss: 0.1000
2019-10-29 00:55:41,059 Training Epoch [39/40] Iter[98/312]		Loss: 0.0998
2019-10-29 00:55:41,180 Training Epoch [39/40] Iter[99/312]		Loss: 0.0995
2019-10-29 00:55:41,302 Training Epoch [39/40] Iter[100/312]		Loss: 0.0999
2019-10-29 00:55:41,423 Training Epoch [39/40] Iter[101/312]		Loss: 0.1001
2019-10-29 00:55:41,544 Training Epoch [39/40] Iter[102/312]		Loss: 0.1006
2019-10-29 00:55:41,665 Training Epoch [39/40] Iter[103/312]		Loss: 0.1007
2019-10-29 00:55:41,786 Training Epoch [39/40] Iter[104/312]		Loss: 0.1010
2019-10-29 00:55:41,907 Training Epoch [39/40] Iter[105/312]		Loss: 0.1010
2019-10-29 00:55:42,028 Training Epoch [39/40] Iter[106/312]		Loss: 0.1011
2019-10-29 00:55:42,150 Training Epoch [39/40] Iter[107/312]		Loss: 0.1009
2019-10-29 00:55:42,272 Training Epoch [39/40] Iter[108/312]		Loss: 0.1010
2019-10-29 00:55:42,393 Training Epoch [39/40] Iter[109/312]		Loss: 0.1009
2019-10-29 00:55:42,515 Training Epoch [39/40] Iter[110/312]		Loss: 0.1009
2019-10-29 00:55:42,636 Training Epoch [39/40] Iter[111/312]		Loss: 0.1009
2019-10-29 00:55:42,758 Training Epoch [39/40] Iter[112/312]		Loss: 0.1007
2019-10-29 00:55:42,879 Training Epoch [39/40] Iter[113/312]		Loss: 0.1005
2019-10-29 00:55:43,001 Training Epoch [39/40] Iter[114/312]		Loss: 0.1003
2019-10-29 00:55:43,123 Training Epoch [39/40] Iter[115/312]		Loss: 0.1005
2019-10-29 00:55:43,244 Training Epoch [39/40] Iter[116/312]		Loss: 0.1006
2019-10-29 00:55:43,366 Training Epoch [39/40] Iter[117/312]		Loss: 0.1005
2019-10-29 00:55:43,488 Training Epoch [39/40] Iter[118/312]		Loss: 0.1015
2019-10-29 00:55:43,610 Training Epoch [39/40] Iter[119/312]		Loss: 0.1016
2019-10-29 00:55:43,731 Training Epoch [39/40] Iter[120/312]		Loss: 0.1013
2019-10-29 00:55:43,853 Training Epoch [39/40] Iter[121/312]		Loss: 0.1012
2019-10-29 00:55:43,974 Training Epoch [39/40] Iter[122/312]		Loss: 0.1012
2019-10-29 00:55:44,095 Training Epoch [39/40] Iter[123/312]		Loss: 0.1012
2019-10-29 00:55:44,216 Training Epoch [39/40] Iter[124/312]		Loss: 0.1010
2019-10-29 00:55:44,338 Training Epoch [39/40] Iter[125/312]		Loss: 0.1010
2019-10-29 00:55:44,459 Training Epoch [39/40] Iter[126/312]		Loss: 0.1011
2019-10-29 00:55:44,581 Training Epoch [39/40] Iter[127/312]		Loss: 0.1010
2019-10-29 00:55:44,702 Training Epoch [39/40] Iter[128/312]		Loss: 0.1007
2019-10-29 00:55:44,823 Training Epoch [39/40] Iter[129/312]		Loss: 0.1006
2019-10-29 00:55:44,944 Training Epoch [39/40] Iter[130/312]		Loss: 0.1005
2019-10-29 00:55:45,065 Training Epoch [39/40] Iter[131/312]		Loss: 0.1005
2019-10-29 00:55:45,187 Training Epoch [39/40] Iter[132/312]		Loss: 0.1003
2019-10-29 00:55:45,308 Training Epoch [39/40] Iter[133/312]		Loss: 0.1008
2019-10-29 00:55:45,430 Training Epoch [39/40] Iter[134/312]		Loss: 0.1006
2019-10-29 00:55:45,551 Training Epoch [39/40] Iter[135/312]		Loss: 0.1004
2019-10-29 00:55:45,673 Training Epoch [39/40] Iter[136/312]		Loss: 0.1005
2019-10-29 00:55:45,794 Training Epoch [39/40] Iter[137/312]		Loss: 0.1006
2019-10-29 00:55:45,916 Training Epoch [39/40] Iter[138/312]		Loss: 0.1005
2019-10-29 00:55:46,038 Training Epoch [39/40] Iter[139/312]		Loss: 0.1007
2019-10-29 00:55:46,159 Training Epoch [39/40] Iter[140/312]		Loss: 0.1005
2019-10-29 00:55:46,281 Training Epoch [39/40] Iter[141/312]		Loss: 0.1006
2019-10-29 00:55:46,402 Training Epoch [39/40] Iter[142/312]		Loss: 0.1005
2019-10-29 00:55:46,524 Training Epoch [39/40] Iter[143/312]		Loss: 0.1003
2019-10-29 00:55:46,645 Training Epoch [39/40] Iter[144/312]		Loss: 0.1004
2019-10-29 00:55:46,766 Training Epoch [39/40] Iter[145/312]		Loss: 0.1004
2019-10-29 00:55:46,888 Training Epoch [39/40] Iter[146/312]		Loss: 0.1004
2019-10-29 00:55:47,010 Training Epoch [39/40] Iter[147/312]		Loss: 0.1001
2019-10-29 00:55:47,132 Training Epoch [39/40] Iter[148/312]		Loss: 0.1000
2019-10-29 00:55:47,253 Training Epoch [39/40] Iter[149/312]		Loss: 0.0998
2019-10-29 00:55:47,374 Training Epoch [39/40] Iter[150/312]		Loss: 0.0997
2019-10-29 00:55:47,496 Training Epoch [39/40] Iter[151/312]		Loss: 0.1000
2019-10-29 00:55:47,617 Training Epoch [39/40] Iter[152/312]		Loss: 0.0998
2019-10-29 00:55:47,739 Training Epoch [39/40] Iter[153/312]		Loss: 0.0995
2019-10-29 00:55:47,859 Training Epoch [39/40] Iter[154/312]		Loss: 0.0995
2019-10-29 00:55:47,981 Training Epoch [39/40] Iter[155/312]		Loss: 0.0994
2019-10-29 00:55:48,102 Training Epoch [39/40] Iter[156/312]		Loss: 0.0994
2019-10-29 00:55:48,223 Training Epoch [39/40] Iter[157/312]		Loss: 0.0993
2019-10-29 00:55:48,344 Training Epoch [39/40] Iter[158/312]		Loss: 0.0993
2019-10-29 00:55:48,465 Training Epoch [39/40] Iter[159/312]		Loss: 0.0992
2019-10-29 00:55:48,587 Training Epoch [39/40] Iter[160/312]		Loss: 0.0991
2019-10-29 00:55:48,708 Training Epoch [39/40] Iter[161/312]		Loss: 0.0991
2019-10-29 00:55:48,829 Training Epoch [39/40] Iter[162/312]		Loss: 0.0990
2019-10-29 00:55:48,951 Training Epoch [39/40] Iter[163/312]		Loss: 0.0993
2019-10-29 00:55:49,072 Training Epoch [39/40] Iter[164/312]		Loss: 0.0994
2019-10-29 00:55:49,194 Training Epoch [39/40] Iter[165/312]		Loss: 0.0995
2019-10-29 00:55:49,315 Training Epoch [39/40] Iter[166/312]		Loss: 0.0995
2019-10-29 00:55:49,437 Training Epoch [39/40] Iter[167/312]		Loss: 0.0996
2019-10-29 00:55:49,558 Training Epoch [39/40] Iter[168/312]		Loss: 0.0994
2019-10-29 00:55:49,679 Training Epoch [39/40] Iter[169/312]		Loss: 0.0992
2019-10-29 00:55:49,800 Training Epoch [39/40] Iter[170/312]		Loss: 0.0991
2019-10-29 00:55:49,921 Training Epoch [39/40] Iter[171/312]		Loss: 0.0994
2019-10-29 00:55:50,042 Training Epoch [39/40] Iter[172/312]		Loss: 0.0995
2019-10-29 00:55:50,163 Training Epoch [39/40] Iter[173/312]		Loss: 0.0994
2019-10-29 00:55:50,284 Training Epoch [39/40] Iter[174/312]		Loss: 0.0995
2019-10-29 00:55:50,405 Training Epoch [39/40] Iter[175/312]		Loss: 0.0998
2019-10-29 00:55:50,526 Training Epoch [39/40] Iter[176/312]		Loss: 0.0998
2019-10-29 00:55:50,648 Training Epoch [39/40] Iter[177/312]		Loss: 0.0999
2019-10-29 00:55:50,770 Training Epoch [39/40] Iter[178/312]		Loss: 0.0998
2019-10-29 00:55:50,891 Training Epoch [39/40] Iter[179/312]		Loss: 0.0996
2019-10-29 00:55:51,013 Training Epoch [39/40] Iter[180/312]		Loss: 0.0998
2019-10-29 00:55:51,135 Training Epoch [39/40] Iter[181/312]		Loss: 0.0998
2019-10-29 00:55:51,256 Training Epoch [39/40] Iter[182/312]		Loss: 0.0999
2019-10-29 00:55:51,378 Training Epoch [39/40] Iter[183/312]		Loss: 0.1000
2019-10-29 00:55:51,500 Training Epoch [39/40] Iter[184/312]		Loss: 0.1000
2019-10-29 00:55:51,621 Training Epoch [39/40] Iter[185/312]		Loss: 0.0999
2019-10-29 00:55:51,743 Training Epoch [39/40] Iter[186/312]		Loss: 0.0997
2019-10-29 00:55:51,865 Training Epoch [39/40] Iter[187/312]		Loss: 0.1001
2019-10-29 00:55:51,986 Training Epoch [39/40] Iter[188/312]		Loss: 0.1000
2019-10-29 00:55:52,108 Training Epoch [39/40] Iter[189/312]		Loss: 0.0999
2019-10-29 00:55:52,230 Training Epoch [39/40] Iter[190/312]		Loss: 0.1001
2019-10-29 00:55:52,351 Training Epoch [39/40] Iter[191/312]		Loss: 0.0999
2019-10-29 00:55:52,472 Training Epoch [39/40] Iter[192/312]		Loss: 0.0997
2019-10-29 00:55:52,594 Training Epoch [39/40] Iter[193/312]		Loss: 0.0995
2019-10-29 00:55:52,716 Training Epoch [39/40] Iter[194/312]		Loss: 0.0996
2019-10-29 00:55:52,837 Training Epoch [39/40] Iter[195/312]		Loss: 0.0995
2019-10-29 00:55:52,958 Training Epoch [39/40] Iter[196/312]		Loss: 0.0996
2019-10-29 00:55:53,080 Training Epoch [39/40] Iter[197/312]		Loss: 0.0994
2019-10-29 00:55:53,201 Training Epoch [39/40] Iter[198/312]		Loss: 0.0994
2019-10-29 00:55:53,322 Training Epoch [39/40] Iter[199/312]		Loss: 0.0995
2019-10-29 00:55:53,443 Training Epoch [39/40] Iter[200/312]		Loss: 0.0993
2019-10-29 00:55:53,564 Training Epoch [39/40] Iter[201/312]		Loss: 0.0993
2019-10-29 00:55:53,686 Training Epoch [39/40] Iter[202/312]		Loss: 0.0995
2019-10-29 00:55:53,807 Training Epoch [39/40] Iter[203/312]		Loss: 0.0993
2019-10-29 00:55:53,929 Training Epoch [39/40] Iter[204/312]		Loss: 0.0992
2019-10-29 00:55:54,051 Training Epoch [39/40] Iter[205/312]		Loss: 0.0992
2019-10-29 00:55:54,172 Training Epoch [39/40] Iter[206/312]		Loss: 0.0994
2019-10-29 00:55:54,293 Training Epoch [39/40] Iter[207/312]		Loss: 0.0995
2019-10-29 00:55:54,415 Training Epoch [39/40] Iter[208/312]		Loss: 0.0995
2019-10-29 00:55:54,536 Training Epoch [39/40] Iter[209/312]		Loss: 0.0993
2019-10-29 00:55:54,658 Training Epoch [39/40] Iter[210/312]		Loss: 0.0995
2019-10-29 00:55:54,779 Training Epoch [39/40] Iter[211/312]		Loss: 0.0995
2019-10-29 00:55:54,900 Training Epoch [39/40] Iter[212/312]		Loss: 0.0995
2019-10-29 00:55:55,022 Training Epoch [39/40] Iter[213/312]		Loss: 0.0994
2019-10-29 00:55:55,144 Training Epoch [39/40] Iter[214/312]		Loss: 0.0998
2019-10-29 00:55:55,266 Training Epoch [39/40] Iter[215/312]		Loss: 0.1000
2019-10-29 00:55:55,388 Training Epoch [39/40] Iter[216/312]		Loss: 0.0999
2019-10-29 00:55:55,510 Training Epoch [39/40] Iter[217/312]		Loss: 0.1000
2019-10-29 00:55:55,632 Training Epoch [39/40] Iter[218/312]		Loss: 0.1001
2019-10-29 00:55:55,753 Training Epoch [39/40] Iter[219/312]		Loss: 0.1001
2019-10-29 00:55:55,875 Training Epoch [39/40] Iter[220/312]		Loss: 0.1003
2019-10-29 00:55:55,997 Training Epoch [39/40] Iter[221/312]		Loss: 0.1003
2019-10-29 00:55:56,119 Training Epoch [39/40] Iter[222/312]		Loss: 0.1002
2019-10-29 00:55:56,240 Training Epoch [39/40] Iter[223/312]		Loss: 0.1002
2019-10-29 00:55:56,362 Training Epoch [39/40] Iter[224/312]		Loss: 0.1001
2019-10-29 00:55:56,483 Training Epoch [39/40] Iter[225/312]		Loss: 0.1003
2019-10-29 00:55:56,605 Training Epoch [39/40] Iter[226/312]		Loss: 0.1002
2019-10-29 00:55:56,726 Training Epoch [39/40] Iter[227/312]		Loss: 0.1002
2019-10-29 00:55:56,847 Training Epoch [39/40] Iter[228/312]		Loss: 0.1002
2019-10-29 00:55:56,969 Training Epoch [39/40] Iter[229/312]		Loss: 0.1002
2019-10-29 00:55:57,090 Training Epoch [39/40] Iter[230/312]		Loss: 0.1000
2019-10-29 00:55:57,212 Training Epoch [39/40] Iter[231/312]		Loss: 0.1000
2019-10-29 00:55:57,333 Training Epoch [39/40] Iter[232/312]		Loss: 0.1000
2019-10-29 00:55:57,455 Training Epoch [39/40] Iter[233/312]		Loss: 0.1000
2019-10-29 00:55:57,577 Training Epoch [39/40] Iter[234/312]		Loss: 0.1002
2019-10-29 00:55:57,698 Training Epoch [39/40] Iter[235/312]		Loss: 0.1001
2019-10-29 00:55:57,819 Training Epoch [39/40] Iter[236/312]		Loss: 0.1001
2019-10-29 00:55:57,940 Training Epoch [39/40] Iter[237/312]		Loss: 0.1000
2019-10-29 00:55:58,061 Training Epoch [39/40] Iter[238/312]		Loss: 0.1000
2019-10-29 00:55:58,183 Training Epoch [39/40] Iter[239/312]		Loss: 0.1000
2019-10-29 00:55:58,305 Training Epoch [39/40] Iter[240/312]		Loss: 0.0999
2019-10-29 00:55:58,427 Training Epoch [39/40] Iter[241/312]		Loss: 0.0998
2019-10-29 00:55:58,548 Training Epoch [39/40] Iter[242/312]		Loss: 0.0999
2019-10-29 00:55:58,669 Training Epoch [39/40] Iter[243/312]		Loss: 0.1001
2019-10-29 00:55:58,790 Training Epoch [39/40] Iter[244/312]		Loss: 0.1002
2019-10-29 00:55:58,911 Training Epoch [39/40] Iter[245/312]		Loss: 0.1001
2019-10-29 00:55:59,033 Training Epoch [39/40] Iter[246/312]		Loss: 0.1001
2019-10-29 00:55:59,155 Training Epoch [39/40] Iter[247/312]		Loss: 0.1001
2019-10-29 00:55:59,277 Training Epoch [39/40] Iter[248/312]		Loss: 0.1000
2019-10-29 00:55:59,399 Training Epoch [39/40] Iter[249/312]		Loss: 0.1000
2019-10-29 00:55:59,521 Training Epoch [39/40] Iter[250/312]		Loss: 0.0998
2019-10-29 00:55:59,642 Training Epoch [39/40] Iter[251/312]		Loss: 0.0997
2019-10-29 00:55:59,763 Training Epoch [39/40] Iter[252/312]		Loss: 0.0996
2019-10-29 00:55:59,885 Training Epoch [39/40] Iter[253/312]		Loss: 0.0996
2019-10-29 00:56:00,006 Training Epoch [39/40] Iter[254/312]		Loss: 0.0995
2019-10-29 00:56:00,127 Training Epoch [39/40] Iter[255/312]		Loss: 0.0995
2019-10-29 00:56:00,249 Training Epoch [39/40] Iter[256/312]		Loss: 0.0995
2019-10-29 00:56:00,371 Training Epoch [39/40] Iter[257/312]		Loss: 0.0995
2019-10-29 00:56:00,493 Training Epoch [39/40] Iter[258/312]		Loss: 0.0994
2019-10-29 00:56:00,615 Training Epoch [39/40] Iter[259/312]		Loss: 0.0993
2019-10-29 00:56:00,736 Training Epoch [39/40] Iter[260/312]		Loss: 0.0994
2019-10-29 00:56:00,858 Training Epoch [39/40] Iter[261/312]		Loss: 0.0992
2019-10-29 00:56:00,979 Training Epoch [39/40] Iter[262/312]		Loss: 0.0992
2019-10-29 00:56:01,101 Training Epoch [39/40] Iter[263/312]		Loss: 0.0991
2019-10-29 00:56:01,222 Training Epoch [39/40] Iter[264/312]		Loss: 0.0992
2019-10-29 00:56:01,343 Training Epoch [39/40] Iter[265/312]		Loss: 0.0990
2019-10-29 00:56:01,465 Training Epoch [39/40] Iter[266/312]		Loss: 0.0989
2019-10-29 00:56:01,586 Training Epoch [39/40] Iter[267/312]		Loss: 0.0988
2019-10-29 00:56:01,707 Training Epoch [39/40] Iter[268/312]		Loss: 0.0987
2019-10-29 00:56:01,829 Training Epoch [39/40] Iter[269/312]		Loss: 0.0987
2019-10-29 00:56:01,950 Training Epoch [39/40] Iter[270/312]		Loss: 0.0988
2019-10-29 00:56:02,071 Training Epoch [39/40] Iter[271/312]		Loss: 0.0987
2019-10-29 00:56:02,192 Training Epoch [39/40] Iter[272/312]		Loss: 0.0987
2019-10-29 00:56:02,314 Training Epoch [39/40] Iter[273/312]		Loss: 0.0988
2019-10-29 00:56:02,435 Training Epoch [39/40] Iter[274/312]		Loss: 0.0987
2019-10-29 00:56:02,557 Training Epoch [39/40] Iter[275/312]		Loss: 0.0990
2019-10-29 00:56:02,678 Training Epoch [39/40] Iter[276/312]		Loss: 0.0992
2019-10-29 00:56:02,799 Training Epoch [39/40] Iter[277/312]		Loss: 0.0992
2019-10-29 00:56:02,923 Training Epoch [39/40] Iter[278/312]		Loss: 0.0993
2019-10-29 00:56:03,045 Training Epoch [39/40] Iter[279/312]		Loss: 0.0993
2019-10-29 00:56:03,167 Training Epoch [39/40] Iter[280/312]		Loss: 0.0994
2019-10-29 00:56:03,289 Training Epoch [39/40] Iter[281/312]		Loss: 0.0993
2019-10-29 00:56:03,410 Training Epoch [39/40] Iter[282/312]		Loss: 0.0992
2019-10-29 00:56:03,532 Training Epoch [39/40] Iter[283/312]		Loss: 0.0993
2019-10-29 00:56:03,653 Training Epoch [39/40] Iter[284/312]		Loss: 0.0994
2019-10-29 00:56:03,775 Training Epoch [39/40] Iter[285/312]		Loss: 0.0995
2019-10-29 00:56:03,897 Training Epoch [39/40] Iter[286/312]		Loss: 0.0995
2019-10-29 00:56:04,019 Training Epoch [39/40] Iter[287/312]		Loss: 0.0998
2019-10-29 00:56:04,140 Training Epoch [39/40] Iter[288/312]		Loss: 0.0998
2019-10-29 00:56:04,262 Training Epoch [39/40] Iter[289/312]		Loss: 0.0998
2019-10-29 00:56:04,384 Training Epoch [39/40] Iter[290/312]		Loss: 0.0997
2019-10-29 00:56:04,505 Training Epoch [39/40] Iter[291/312]		Loss: 0.0997
2019-10-29 00:56:04,627 Training Epoch [39/40] Iter[292/312]		Loss: 0.0997
2019-10-29 00:56:04,748 Training Epoch [39/40] Iter[293/312]		Loss: 0.0997
2019-10-29 00:56:04,869 Training Epoch [39/40] Iter[294/312]		Loss: 0.0996
2019-10-29 00:56:04,991 Training Epoch [39/40] Iter[295/312]		Loss: 0.0995
2019-10-29 00:56:05,112 Training Epoch [39/40] Iter[296/312]		Loss: 0.0997
2019-10-29 00:56:05,234 Training Epoch [39/40] Iter[297/312]		Loss: 0.0996
2019-10-29 00:56:05,355 Training Epoch [39/40] Iter[298/312]		Loss: 0.0996
2019-10-29 00:56:05,477 Training Epoch [39/40] Iter[299/312]		Loss: 0.0995
2019-10-29 00:56:05,598 Training Epoch [39/40] Iter[300/312]		Loss: 0.0995
2019-10-29 00:56:05,719 Training Epoch [39/40] Iter[301/312]		Loss: 0.0994
2019-10-29 00:56:05,841 Training Epoch [39/40] Iter[302/312]		Loss: 0.0996
2019-10-29 00:56:05,962 Training Epoch [39/40] Iter[303/312]		Loss: 0.0995
2019-10-29 00:56:06,084 Training Epoch [39/40] Iter[304/312]		Loss: 0.0995
2019-10-29 00:56:06,205 Training Epoch [39/40] Iter[305/312]		Loss: 0.0995
2019-10-29 00:56:06,326 Training Epoch [39/40] Iter[306/312]		Loss: 0.0995
2019-10-29 00:56:06,447 Training Epoch [39/40] Iter[307/312]		Loss: 0.0994
2019-10-29 00:56:06,568 Training Epoch [39/40] Iter[308/312]		Loss: 0.0993
2019-10-29 00:56:06,689 Training Epoch [39/40] Iter[309/312]		Loss: 0.0993
2019-10-29 00:56:06,810 Training Epoch [39/40] Iter[310/312]		Loss: 0.0994
2019-10-29 00:56:06,930 Training Epoch [39/40] Iter[311/312]		Loss: 0.0994
2019-10-29 00:56:06,990 Training Epoch [39/40] Iter[312/312]		Loss: 0.0995
2019-10-29 00:56:07,241 Testing Epoch [39/40] Iter[0/62]		Loss: 0.0898
2019-10-29 00:56:07,293 Testing Epoch [39/40] Iter[1/62]		Loss: 0.1254
2019-10-29 00:56:07,327 Testing Epoch [39/40] Iter[2/62]		Loss: 0.1177
2019-10-29 00:56:07,359 Testing Epoch [39/40] Iter[3/62]		Loss: 0.1148
2019-10-29 00:56:07,389 Testing Epoch [39/40] Iter[4/62]		Loss: 0.1110
2019-10-29 00:56:07,419 Testing Epoch [39/40] Iter[5/62]		Loss: 0.1086
2019-10-29 00:56:07,450 Testing Epoch [39/40] Iter[6/62]		Loss: 0.1098
2019-10-29 00:56:07,482 Testing Epoch [39/40] Iter[7/62]		Loss: 0.1161
2019-10-29 00:56:07,513 Testing Epoch [39/40] Iter[8/62]		Loss: 0.1220
2019-10-29 00:56:07,543 Testing Epoch [39/40] Iter[9/62]		Loss: 0.1190
2019-10-29 00:56:07,574 Testing Epoch [39/40] Iter[10/62]		Loss: 0.1173
2019-10-29 00:56:07,605 Testing Epoch [39/40] Iter[11/62]		Loss: 0.1225
2019-10-29 00:56:07,636 Testing Epoch [39/40] Iter[12/62]		Loss: 0.1237
2019-10-29 00:56:07,666 Testing Epoch [39/40] Iter[13/62]		Loss: 0.1259
2019-10-29 00:56:07,697 Testing Epoch [39/40] Iter[14/62]		Loss: 0.1377
2019-10-29 00:56:07,728 Testing Epoch [39/40] Iter[15/62]		Loss: 0.1391
2019-10-29 00:56:07,759 Testing Epoch [39/40] Iter[16/62]		Loss: 0.1368
2019-10-29 00:56:07,789 Testing Epoch [39/40] Iter[17/62]		Loss: 0.1361
2019-10-29 00:56:07,820 Testing Epoch [39/40] Iter[18/62]		Loss: 0.1327
2019-10-29 00:56:07,851 Testing Epoch [39/40] Iter[19/62]		Loss: 0.1310
2019-10-29 00:56:07,881 Testing Epoch [39/40] Iter[20/62]		Loss: 0.1321
2019-10-29 00:56:07,912 Testing Epoch [39/40] Iter[21/62]		Loss: 0.1299
2019-10-29 00:56:07,943 Testing Epoch [39/40] Iter[22/62]		Loss: 0.1293
2019-10-29 00:56:07,974 Testing Epoch [39/40] Iter[23/62]		Loss: 0.1288
2019-10-29 00:56:08,004 Testing Epoch [39/40] Iter[24/62]		Loss: 0.1307
2019-10-29 00:56:08,035 Testing Epoch [39/40] Iter[25/62]		Loss: 0.1301
2019-10-29 00:56:08,066 Testing Epoch [39/40] Iter[26/62]		Loss: 0.1290
2019-10-29 00:56:08,097 Testing Epoch [39/40] Iter[27/62]		Loss: 0.1335
2019-10-29 00:56:08,128 Testing Epoch [39/40] Iter[28/62]		Loss: 0.1353
2019-10-29 00:56:08,159 Testing Epoch [39/40] Iter[29/62]		Loss: 0.1350
2019-10-29 00:56:08,190 Testing Epoch [39/40] Iter[30/62]		Loss: 0.1368
2019-10-29 00:56:08,221 Testing Epoch [39/40] Iter[31/62]		Loss: 0.1359
2019-10-29 00:56:08,252 Testing Epoch [39/40] Iter[32/62]		Loss: 0.1374
2019-10-29 00:56:08,283 Testing Epoch [39/40] Iter[33/62]		Loss: 0.1357
2019-10-29 00:56:08,314 Testing Epoch [39/40] Iter[34/62]		Loss: 0.1373
2019-10-29 00:56:08,345 Testing Epoch [39/40] Iter[35/62]		Loss: 0.1378
2019-10-29 00:56:08,376 Testing Epoch [39/40] Iter[36/62]		Loss: 0.1362
2019-10-29 00:56:08,406 Testing Epoch [39/40] Iter[37/62]		Loss: 0.1358
2019-10-29 00:56:08,438 Testing Epoch [39/40] Iter[38/62]		Loss: 0.1360
2019-10-29 00:56:08,469 Testing Epoch [39/40] Iter[39/62]		Loss: 0.1363
2019-10-29 00:56:08,499 Testing Epoch [39/40] Iter[40/62]		Loss: 0.1367
2019-10-29 00:56:08,530 Testing Epoch [39/40] Iter[41/62]		Loss: 0.1368
2019-10-29 00:56:08,561 Testing Epoch [39/40] Iter[42/62]		Loss: 0.1354
2019-10-29 00:56:08,592 Testing Epoch [39/40] Iter[43/62]		Loss: 0.1350
2019-10-29 00:56:08,623 Testing Epoch [39/40] Iter[44/62]		Loss: 0.1338
2019-10-29 00:56:08,654 Testing Epoch [39/40] Iter[45/62]		Loss: 0.1349
2019-10-29 00:56:08,685 Testing Epoch [39/40] Iter[46/62]		Loss: 0.1351
2019-10-29 00:56:08,715 Testing Epoch [39/40] Iter[47/62]		Loss: 0.1399
2019-10-29 00:56:08,746 Testing Epoch [39/40] Iter[48/62]		Loss: 0.1389
2019-10-29 00:56:08,777 Testing Epoch [39/40] Iter[49/62]		Loss: 0.1403
2019-10-29 00:56:08,807 Testing Epoch [39/40] Iter[50/62]		Loss: 0.1400
2019-10-29 00:56:08,838 Testing Epoch [39/40] Iter[51/62]		Loss: 0.1402
2019-10-29 00:56:08,869 Testing Epoch [39/40] Iter[52/62]		Loss: 0.1391
2019-10-29 00:56:08,900 Testing Epoch [39/40] Iter[53/62]		Loss: 0.1389
2019-10-29 00:56:08,931 Testing Epoch [39/40] Iter[54/62]		Loss: 0.1384
2019-10-29 00:56:08,961 Testing Epoch [39/40] Iter[55/62]		Loss: 0.1385
2019-10-29 00:56:08,991 Testing Epoch [39/40] Iter[56/62]		Loss: 0.1383
2019-10-29 00:56:09,022 Testing Epoch [39/40] Iter[57/62]		Loss: 0.1381
2019-10-29 00:56:09,052 Testing Epoch [39/40] Iter[58/62]		Loss: 0.1377
2019-10-29 00:56:09,082 Testing Epoch [39/40] Iter[59/62]		Loss: 0.1377
2019-10-29 00:56:09,113 Testing Epoch [39/40] Iter[60/62]		Loss: 0.1371
2019-10-29 00:56:09,143 Testing Epoch [39/40] Iter[61/62]		Loss: 0.1368
2019-10-29 00:56:09,160 Testing Epoch [39/40] Iter[62/62]		Loss: 0.1374
2019-10-29 00:56:09,508 Training Epoch [40/40] Iter[0/312]		Loss: 0.0913
2019-10-29 00:56:09,633 Training Epoch [40/40] Iter[1/312]		Loss: 0.0847
2019-10-29 00:56:09,753 Training Epoch [40/40] Iter[2/312]		Loss: 0.0890
2019-10-29 00:56:09,873 Training Epoch [40/40] Iter[3/312]		Loss: 0.0847
2019-10-29 00:56:09,995 Training Epoch [40/40] Iter[4/312]		Loss: 0.1013
2019-10-29 00:56:10,117 Training Epoch [40/40] Iter[5/312]		Loss: 0.0968
2019-10-29 00:56:10,237 Training Epoch [40/40] Iter[6/312]		Loss: 0.0923
2019-10-29 00:56:10,357 Training Epoch [40/40] Iter[7/312]		Loss: 0.0922
2019-10-29 00:56:10,479 Training Epoch [40/40] Iter[8/312]		Loss: 0.0924
2019-10-29 00:56:10,601 Training Epoch [40/40] Iter[9/312]		Loss: 0.0936
2019-10-29 00:56:10,722 Training Epoch [40/40] Iter[10/312]		Loss: 0.0930
2019-10-29 00:56:10,843 Training Epoch [40/40] Iter[11/312]		Loss: 0.0943
2019-10-29 00:56:10,964 Training Epoch [40/40] Iter[12/312]		Loss: 0.0940
2019-10-29 00:56:11,086 Training Epoch [40/40] Iter[13/312]		Loss: 0.0946
2019-10-29 00:56:11,207 Training Epoch [40/40] Iter[14/312]		Loss: 0.0932
2019-10-29 00:56:11,329 Training Epoch [40/40] Iter[15/312]		Loss: 0.0932
2019-10-29 00:56:11,452 Training Epoch [40/40] Iter[16/312]		Loss: 0.0939
2019-10-29 00:56:11,574 Training Epoch [40/40] Iter[17/312]		Loss: 0.0955
2019-10-29 00:56:11,695 Training Epoch [40/40] Iter[18/312]		Loss: 0.0957
2019-10-29 00:56:11,820 Training Epoch [40/40] Iter[19/312]		Loss: 0.0947
2019-10-29 00:56:11,941 Training Epoch [40/40] Iter[20/312]		Loss: 0.0952
2019-10-29 00:56:12,063 Training Epoch [40/40] Iter[21/312]		Loss: 0.0960
2019-10-29 00:56:12,184 Training Epoch [40/40] Iter[22/312]		Loss: 0.0959
2019-10-29 00:56:12,305 Training Epoch [40/40] Iter[23/312]		Loss: 0.0960
2019-10-29 00:56:12,426 Training Epoch [40/40] Iter[24/312]		Loss: 0.0955
2019-10-29 00:56:12,548 Training Epoch [40/40] Iter[25/312]		Loss: 0.0955
2019-10-29 00:56:12,669 Training Epoch [40/40] Iter[26/312]		Loss: 0.0948
2019-10-29 00:56:12,791 Training Epoch [40/40] Iter[27/312]		Loss: 0.0957
2019-10-29 00:56:12,912 Training Epoch [40/40] Iter[28/312]		Loss: 0.0958
2019-10-29 00:56:13,034 Training Epoch [40/40] Iter[29/312]		Loss: 0.0950
2019-10-29 00:56:13,155 Training Epoch [40/40] Iter[30/312]		Loss: 0.0962
2019-10-29 00:56:13,277 Training Epoch [40/40] Iter[31/312]		Loss: 0.0969
2019-10-29 00:56:13,399 Training Epoch [40/40] Iter[32/312]		Loss: 0.0961
2019-10-29 00:56:13,520 Training Epoch [40/40] Iter[33/312]		Loss: 0.0957
2019-10-29 00:56:13,641 Training Epoch [40/40] Iter[34/312]		Loss: 0.0951
2019-10-29 00:56:13,763 Training Epoch [40/40] Iter[35/312]		Loss: 0.0950
2019-10-29 00:56:13,884 Training Epoch [40/40] Iter[36/312]		Loss: 0.0952
2019-10-29 00:56:14,005 Training Epoch [40/40] Iter[37/312]		Loss: 0.0947
2019-10-29 00:56:14,126 Training Epoch [40/40] Iter[38/312]		Loss: 0.0951
2019-10-29 00:56:14,248 Training Epoch [40/40] Iter[39/312]		Loss: 0.0948
2019-10-29 00:56:14,369 Training Epoch [40/40] Iter[40/312]		Loss: 0.0946
2019-10-29 00:56:14,492 Training Epoch [40/40] Iter[41/312]		Loss: 0.0944
2019-10-29 00:56:14,616 Training Epoch [40/40] Iter[42/312]		Loss: 0.0941
2019-10-29 00:56:14,737 Training Epoch [40/40] Iter[43/312]		Loss: 0.0942
2019-10-29 00:56:14,858 Training Epoch [40/40] Iter[44/312]		Loss: 0.0940
2019-10-29 00:56:14,980 Training Epoch [40/40] Iter[45/312]		Loss: 0.0946
2019-10-29 00:56:15,101 Training Epoch [40/40] Iter[46/312]		Loss: 0.0942
2019-10-29 00:56:15,222 Training Epoch [40/40] Iter[47/312]		Loss: 0.0943
2019-10-29 00:56:15,343 Training Epoch [40/40] Iter[48/312]		Loss: 0.0943
2019-10-29 00:56:15,465 Training Epoch [40/40] Iter[49/312]		Loss: 0.0948
2019-10-29 00:56:15,586 Training Epoch [40/40] Iter[50/312]		Loss: 0.0948
2019-10-29 00:56:15,707 Training Epoch [40/40] Iter[51/312]		Loss: 0.0951
2019-10-29 00:56:15,829 Training Epoch [40/40] Iter[52/312]		Loss: 0.0950
2019-10-29 00:56:15,950 Training Epoch [40/40] Iter[53/312]		Loss: 0.0943
2019-10-29 00:56:16,071 Training Epoch [40/40] Iter[54/312]		Loss: 0.0942
2019-10-29 00:56:16,192 Training Epoch [40/40] Iter[55/312]		Loss: 0.0940
2019-10-29 00:56:16,320 Training Epoch [40/40] Iter[56/312]		Loss: 0.0936
2019-10-29 00:56:16,444 Training Epoch [40/40] Iter[57/312]		Loss: 0.0940
2019-10-29 00:56:16,565 Training Epoch [40/40] Iter[58/312]		Loss: 0.0933
2019-10-29 00:56:16,688 Training Epoch [40/40] Iter[59/312]		Loss: 0.0927
2019-10-29 00:56:16,812 Training Epoch [40/40] Iter[60/312]		Loss: 0.0925
2019-10-29 00:56:16,936 Training Epoch [40/40] Iter[61/312]		Loss: 0.0929
2019-10-29 00:56:17,058 Training Epoch [40/40] Iter[62/312]		Loss: 0.0929
2019-10-29 00:56:17,179 Training Epoch [40/40] Iter[63/312]		Loss: 0.0939
2019-10-29 00:56:17,304 Training Epoch [40/40] Iter[64/312]		Loss: 0.0938
2019-10-29 00:56:17,428 Training Epoch [40/40] Iter[65/312]		Loss: 0.0937
2019-10-29 00:56:17,550 Training Epoch [40/40] Iter[66/312]		Loss: 0.0936
2019-10-29 00:56:17,671 Training Epoch [40/40] Iter[67/312]		Loss: 0.0937
2019-10-29 00:56:17,796 Training Epoch [40/40] Iter[68/312]		Loss: 0.0936
2019-10-29 00:56:17,921 Training Epoch [40/40] Iter[69/312]		Loss: 0.0932
2019-10-29 00:56:18,042 Training Epoch [40/40] Iter[70/312]		Loss: 0.0932
2019-10-29 00:56:18,163 Training Epoch [40/40] Iter[71/312]		Loss: 0.0931
2019-10-29 00:56:18,288 Training Epoch [40/40] Iter[72/312]		Loss: 0.0931
2019-10-29 00:56:18,416 Training Epoch [40/40] Iter[73/312]		Loss: 0.0932
2019-10-29 00:56:18,540 Training Epoch [40/40] Iter[74/312]		Loss: 0.0931
2019-10-29 00:56:18,661 Training Epoch [40/40] Iter[75/312]		Loss: 0.0930
2019-10-29 00:56:18,782 Training Epoch [40/40] Iter[76/312]		Loss: 0.0929
2019-10-29 00:56:18,904 Training Epoch [40/40] Iter[77/312]		Loss: 0.0928
2019-10-29 00:56:19,025 Training Epoch [40/40] Iter[78/312]		Loss: 0.0925
2019-10-29 00:56:19,146 Training Epoch [40/40] Iter[79/312]		Loss: 0.0922
2019-10-29 00:56:19,267 Training Epoch [40/40] Iter[80/312]		Loss: 0.0923
2019-10-29 00:56:19,389 Training Epoch [40/40] Iter[81/312]		Loss: 0.0924
2019-10-29 00:56:19,510 Training Epoch [40/40] Iter[82/312]		Loss: 0.0926
2019-10-29 00:56:19,631 Training Epoch [40/40] Iter[83/312]		Loss: 0.0931
2019-10-29 00:56:19,752 Training Epoch [40/40] Iter[84/312]		Loss: 0.0931
2019-10-29 00:56:19,874 Training Epoch [40/40] Iter[85/312]		Loss: 0.0929
2019-10-29 00:56:19,996 Training Epoch [40/40] Iter[86/312]		Loss: 0.0928
2019-10-29 00:56:20,117 Training Epoch [40/40] Iter[87/312]		Loss: 0.0927
2019-10-29 00:56:20,239 Training Epoch [40/40] Iter[88/312]		Loss: 0.0932
2019-10-29 00:56:20,360 Training Epoch [40/40] Iter[89/312]		Loss: 0.0940
2019-10-29 00:56:20,482 Training Epoch [40/40] Iter[90/312]		Loss: 0.0940
2019-10-29 00:56:20,603 Training Epoch [40/40] Iter[91/312]		Loss: 0.0939
2019-10-29 00:56:20,724 Training Epoch [40/40] Iter[92/312]		Loss: 0.0939
2019-10-29 00:56:20,846 Training Epoch [40/40] Iter[93/312]		Loss: 0.0941
2019-10-29 00:56:20,967 Training Epoch [40/40] Iter[94/312]		Loss: 0.0940
2019-10-29 00:56:21,089 Training Epoch [40/40] Iter[95/312]		Loss: 0.0940
2019-10-29 00:56:21,211 Training Epoch [40/40] Iter[96/312]		Loss: 0.0943
2019-10-29 00:56:21,332 Training Epoch [40/40] Iter[97/312]		Loss: 0.0943
2019-10-29 00:56:21,454 Training Epoch [40/40] Iter[98/312]		Loss: 0.0940
2019-10-29 00:56:21,576 Training Epoch [40/40] Iter[99/312]		Loss: 0.0939
2019-10-29 00:56:21,697 Training Epoch [40/40] Iter[100/312]		Loss: 0.0937
2019-10-29 00:56:21,818 Training Epoch [40/40] Iter[101/312]		Loss: 0.0937
2019-10-29 00:56:21,940 Training Epoch [40/40] Iter[102/312]		Loss: 0.0938
2019-10-29 00:56:22,061 Training Epoch [40/40] Iter[103/312]		Loss: 0.0936
2019-10-29 00:56:22,182 Training Epoch [40/40] Iter[104/312]		Loss: 0.0934
2019-10-29 00:56:22,304 Training Epoch [40/40] Iter[105/312]		Loss: 0.0933
2019-10-29 00:56:22,425 Training Epoch [40/40] Iter[106/312]		Loss: 0.0943
2019-10-29 00:56:22,546 Training Epoch [40/40] Iter[107/312]		Loss: 0.0942
2019-10-29 00:56:22,668 Training Epoch [40/40] Iter[108/312]		Loss: 0.0943
2019-10-29 00:56:22,789 Training Epoch [40/40] Iter[109/312]		Loss: 0.0942
2019-10-29 00:56:22,910 Training Epoch [40/40] Iter[110/312]		Loss: 0.0941
2019-10-29 00:56:23,032 Training Epoch [40/40] Iter[111/312]		Loss: 0.0942
2019-10-29 00:56:23,153 Training Epoch [40/40] Iter[112/312]		Loss: 0.0942
2019-10-29 00:56:23,275 Training Epoch [40/40] Iter[113/312]		Loss: 0.0940
2019-10-29 00:56:23,397 Training Epoch [40/40] Iter[114/312]		Loss: 0.0938
2019-10-29 00:56:23,518 Training Epoch [40/40] Iter[115/312]		Loss: 0.0937
2019-10-29 00:56:23,639 Training Epoch [40/40] Iter[116/312]		Loss: 0.0934
2019-10-29 00:56:23,761 Training Epoch [40/40] Iter[117/312]		Loss: 0.0933
2019-10-29 00:56:23,882 Training Epoch [40/40] Iter[118/312]		Loss: 0.0933
2019-10-29 00:56:24,003 Training Epoch [40/40] Iter[119/312]		Loss: 0.0931
2019-10-29 00:56:24,124 Training Epoch [40/40] Iter[120/312]		Loss: 0.0931
2019-10-29 00:56:24,245 Training Epoch [40/40] Iter[121/312]		Loss: 0.0930
2019-10-29 00:56:24,366 Training Epoch [40/40] Iter[122/312]		Loss: 0.0933
2019-10-29 00:56:24,487 Training Epoch [40/40] Iter[123/312]		Loss: 0.0932
2019-10-29 00:56:24,608 Training Epoch [40/40] Iter[124/312]		Loss: 0.0933
2019-10-29 00:56:24,729 Training Epoch [40/40] Iter[125/312]		Loss: 0.0933
2019-10-29 00:56:24,850 Training Epoch [40/40] Iter[126/312]		Loss: 0.0932
2019-10-29 00:56:24,972 Training Epoch [40/40] Iter[127/312]		Loss: 0.0934
2019-10-29 00:56:25,094 Training Epoch [40/40] Iter[128/312]		Loss: 0.0935
2019-10-29 00:56:25,216 Training Epoch [40/40] Iter[129/312]		Loss: 0.0935
2019-10-29 00:56:25,337 Training Epoch [40/40] Iter[130/312]		Loss: 0.0934
2019-10-29 00:56:25,459 Training Epoch [40/40] Iter[131/312]		Loss: 0.0936
2019-10-29 00:56:25,581 Training Epoch [40/40] Iter[132/312]		Loss: 0.0941
2019-10-29 00:56:25,702 Training Epoch [40/40] Iter[133/312]		Loss: 0.0942
2019-10-29 00:56:25,824 Training Epoch [40/40] Iter[134/312]		Loss: 0.0943
2019-10-29 00:56:25,945 Training Epoch [40/40] Iter[135/312]		Loss: 0.0943
2019-10-29 00:56:26,066 Training Epoch [40/40] Iter[136/312]		Loss: 0.0948
2019-10-29 00:56:26,188 Training Epoch [40/40] Iter[137/312]		Loss: 0.0950
2019-10-29 00:56:26,309 Training Epoch [40/40] Iter[138/312]		Loss: 0.0947
2019-10-29 00:56:26,431 Training Epoch [40/40] Iter[139/312]		Loss: 0.0951
2019-10-29 00:56:26,553 Training Epoch [40/40] Iter[140/312]		Loss: 0.0952
2019-10-29 00:56:26,674 Training Epoch [40/40] Iter[141/312]		Loss: 0.0951
2019-10-29 00:56:26,796 Training Epoch [40/40] Iter[142/312]		Loss: 0.0952
2019-10-29 00:56:26,919 Training Epoch [40/40] Iter[143/312]		Loss: 0.0954
2019-10-29 00:56:27,040 Training Epoch [40/40] Iter[144/312]		Loss: 0.0955
2019-10-29 00:56:27,161 Training Epoch [40/40] Iter[145/312]		Loss: 0.0958
2019-10-29 00:56:27,283 Training Epoch [40/40] Iter[146/312]		Loss: 0.0959
2019-10-29 00:56:27,404 Training Epoch [40/40] Iter[147/312]		Loss: 0.0957
2019-10-29 00:56:27,525 Training Epoch [40/40] Iter[148/312]		Loss: 0.0958
2019-10-29 00:56:27,646 Training Epoch [40/40] Iter[149/312]		Loss: 0.0960
2019-10-29 00:56:27,767 Training Epoch [40/40] Iter[150/312]		Loss: 0.0961
2019-10-29 00:56:27,888 Training Epoch [40/40] Iter[151/312]		Loss: 0.0962
2019-10-29 00:56:28,010 Training Epoch [40/40] Iter[152/312]		Loss: 0.0960
2019-10-29 00:56:28,131 Training Epoch [40/40] Iter[153/312]		Loss: 0.0961
2019-10-29 00:56:28,252 Training Epoch [40/40] Iter[154/312]		Loss: 0.0961
2019-10-29 00:56:28,373 Training Epoch [40/40] Iter[155/312]		Loss: 0.0966
2019-10-29 00:56:28,495 Training Epoch [40/40] Iter[156/312]		Loss: 0.0965
2019-10-29 00:56:28,617 Training Epoch [40/40] Iter[157/312]		Loss: 0.0964
2019-10-29 00:56:28,738 Training Epoch [40/40] Iter[158/312]		Loss: 0.0963
2019-10-29 00:56:28,860 Training Epoch [40/40] Iter[159/312]		Loss: 0.0963
2019-10-29 00:56:28,981 Training Epoch [40/40] Iter[160/312]		Loss: 0.0962
2019-10-29 00:56:29,103 Training Epoch [40/40] Iter[161/312]		Loss: 0.0961
2019-10-29 00:56:29,224 Training Epoch [40/40] Iter[162/312]		Loss: 0.0960
2019-10-29 00:56:29,346 Training Epoch [40/40] Iter[163/312]		Loss: 0.0960
2019-10-29 00:56:29,467 Training Epoch [40/40] Iter[164/312]		Loss: 0.0958
2019-10-29 00:56:29,588 Training Epoch [40/40] Iter[165/312]		Loss: 0.0959
2019-10-29 00:56:29,709 Training Epoch [40/40] Iter[166/312]		Loss: 0.0959
2019-10-29 00:56:29,832 Training Epoch [40/40] Iter[167/312]		Loss: 0.0960
2019-10-29 00:56:29,953 Training Epoch [40/40] Iter[168/312]		Loss: 0.0960
2019-10-29 00:56:30,075 Training Epoch [40/40] Iter[169/312]		Loss: 0.0960
2019-10-29 00:56:30,196 Training Epoch [40/40] Iter[170/312]		Loss: 0.0959
2019-10-29 00:56:30,318 Training Epoch [40/40] Iter[171/312]		Loss: 0.0961
2019-10-29 00:56:30,439 Training Epoch [40/40] Iter[172/312]		Loss: 0.0961
2019-10-29 00:56:30,560 Training Epoch [40/40] Iter[173/312]		Loss: 0.0961
2019-10-29 00:56:30,682 Training Epoch [40/40] Iter[174/312]		Loss: 0.0962
2019-10-29 00:56:30,803 Training Epoch [40/40] Iter[175/312]		Loss: 0.0961
2019-10-29 00:56:30,924 Training Epoch [40/40] Iter[176/312]		Loss: 0.0962
2019-10-29 00:56:31,046 Training Epoch [40/40] Iter[177/312]		Loss: 0.0964
2019-10-29 00:56:31,167 Training Epoch [40/40] Iter[178/312]		Loss: 0.0963
2019-10-29 00:56:31,289 Training Epoch [40/40] Iter[179/312]		Loss: 0.0966
2019-10-29 00:56:31,410 Training Epoch [40/40] Iter[180/312]		Loss: 0.0968
2019-10-29 00:56:31,531 Training Epoch [40/40] Iter[181/312]		Loss: 0.0966
2019-10-29 00:56:31,653 Training Epoch [40/40] Iter[182/312]		Loss: 0.0965
2019-10-29 00:56:31,774 Training Epoch [40/40] Iter[183/312]		Loss: 0.0967
2019-10-29 00:56:31,895 Training Epoch [40/40] Iter[184/312]		Loss: 0.0966
2019-10-29 00:56:32,017 Training Epoch [40/40] Iter[185/312]		Loss: 0.0964
2019-10-29 00:56:32,138 Training Epoch [40/40] Iter[186/312]		Loss: 0.0965
2019-10-29 00:56:32,260 Training Epoch [40/40] Iter[187/312]		Loss: 0.0968
2019-10-29 00:56:32,381 Training Epoch [40/40] Iter[188/312]		Loss: 0.0965
2019-10-29 00:56:32,502 Training Epoch [40/40] Iter[189/312]		Loss: 0.0964
2019-10-29 00:56:32,623 Training Epoch [40/40] Iter[190/312]		Loss: 0.0964
2019-10-29 00:56:32,744 Training Epoch [40/40] Iter[191/312]		Loss: 0.0965
2019-10-29 00:56:32,865 Training Epoch [40/40] Iter[192/312]		Loss: 0.0965
2019-10-29 00:56:32,986 Training Epoch [40/40] Iter[193/312]		Loss: 0.0965
2019-10-29 00:56:33,107 Training Epoch [40/40] Iter[194/312]		Loss: 0.0966
2019-10-29 00:56:33,228 Training Epoch [40/40] Iter[195/312]		Loss: 0.0965
2019-10-29 00:56:33,350 Training Epoch [40/40] Iter[196/312]		Loss: 0.0964
2019-10-29 00:56:33,471 Training Epoch [40/40] Iter[197/312]		Loss: 0.0965
2019-10-29 00:56:33,593 Training Epoch [40/40] Iter[198/312]		Loss: 0.0965
2019-10-29 00:56:33,714 Training Epoch [40/40] Iter[199/312]		Loss: 0.0964
2019-10-29 00:56:33,836 Training Epoch [40/40] Iter[200/312]		Loss: 0.0965
2019-10-29 00:56:33,957 Training Epoch [40/40] Iter[201/312]		Loss: 0.0966
2019-10-29 00:56:34,079 Training Epoch [40/40] Iter[202/312]		Loss: 0.0964
2019-10-29 00:56:34,200 Training Epoch [40/40] Iter[203/312]		Loss: 0.0964
2019-10-29 00:56:34,322 Training Epoch [40/40] Iter[204/312]		Loss: 0.0964
2019-10-29 00:56:34,443 Training Epoch [40/40] Iter[205/312]		Loss: 0.0964
2019-10-29 00:56:34,564 Training Epoch [40/40] Iter[206/312]		Loss: 0.0964
2019-10-29 00:56:34,686 Training Epoch [40/40] Iter[207/312]		Loss: 0.0965
2019-10-29 00:56:34,807 Training Epoch [40/40] Iter[208/312]		Loss: 0.0966
2019-10-29 00:56:34,929 Training Epoch [40/40] Iter[209/312]		Loss: 0.0965
2019-10-29 00:56:35,050 Training Epoch [40/40] Iter[210/312]		Loss: 0.0963
2019-10-29 00:56:35,172 Training Epoch [40/40] Iter[211/312]		Loss: 0.0962
2019-10-29 00:56:35,293 Training Epoch [40/40] Iter[212/312]		Loss: 0.0961
2019-10-29 00:56:35,414 Training Epoch [40/40] Iter[213/312]		Loss: 0.0960
2019-10-29 00:56:35,535 Training Epoch [40/40] Iter[214/312]		Loss: 0.0959
2019-10-29 00:56:35,657 Training Epoch [40/40] Iter[215/312]		Loss: 0.0960
2019-10-29 00:56:35,778 Training Epoch [40/40] Iter[216/312]		Loss: 0.0960
2019-10-29 00:56:35,899 Training Epoch [40/40] Iter[217/312]		Loss: 0.0961
2019-10-29 00:56:36,020 Training Epoch [40/40] Iter[218/312]		Loss: 0.0961
2019-10-29 00:56:36,141 Training Epoch [40/40] Iter[219/312]		Loss: 0.0961
2019-10-29 00:56:36,262 Training Epoch [40/40] Iter[220/312]		Loss: 0.0960
2019-10-29 00:56:36,383 Training Epoch [40/40] Iter[221/312]		Loss: 0.0960
2019-10-29 00:56:36,504 Training Epoch [40/40] Iter[222/312]		Loss: 0.0959
2019-10-29 00:56:36,625 Training Epoch [40/40] Iter[223/312]		Loss: 0.0962
2019-10-29 00:56:36,747 Training Epoch [40/40] Iter[224/312]		Loss: 0.0966
2019-10-29 00:56:36,869 Training Epoch [40/40] Iter[225/312]		Loss: 0.0969
2019-10-29 00:56:36,990 Training Epoch [40/40] Iter[226/312]		Loss: 0.0968
2019-10-29 00:56:37,112 Training Epoch [40/40] Iter[227/312]		Loss: 0.0968
2019-10-29 00:56:37,235 Training Epoch [40/40] Iter[228/312]		Loss: 0.0968
2019-10-29 00:56:37,357 Training Epoch [40/40] Iter[229/312]		Loss: 0.0968
2019-10-29 00:56:37,478 Training Epoch [40/40] Iter[230/312]		Loss: 0.0967
2019-10-29 00:56:37,599 Training Epoch [40/40] Iter[231/312]		Loss: 0.0967
2019-10-29 00:56:37,721 Training Epoch [40/40] Iter[232/312]		Loss: 0.0967
2019-10-29 00:56:37,842 Training Epoch [40/40] Iter[233/312]		Loss: 0.0967
2019-10-29 00:56:37,964 Training Epoch [40/40] Iter[234/312]		Loss: 0.0966
2019-10-29 00:56:38,085 Training Epoch [40/40] Iter[235/312]		Loss: 0.0965
2019-10-29 00:56:38,207 Training Epoch [40/40] Iter[236/312]		Loss: 0.0964
2019-10-29 00:56:38,329 Training Epoch [40/40] Iter[237/312]		Loss: 0.0964
2019-10-29 00:56:38,451 Training Epoch [40/40] Iter[238/312]		Loss: 0.0965
2019-10-29 00:56:38,572 Training Epoch [40/40] Iter[239/312]		Loss: 0.0966
2019-10-29 00:56:38,694 Training Epoch [40/40] Iter[240/312]		Loss: 0.0967
2019-10-29 00:56:38,815 Training Epoch [40/40] Iter[241/312]		Loss: 0.0967
2019-10-29 00:56:38,937 Training Epoch [40/40] Iter[242/312]		Loss: 0.0968
2019-10-29 00:56:39,058 Training Epoch [40/40] Iter[243/312]		Loss: 0.0968
2019-10-29 00:56:39,180 Training Epoch [40/40] Iter[244/312]		Loss: 0.0967
2019-10-29 00:56:39,301 Training Epoch [40/40] Iter[245/312]		Loss: 0.0969
2019-10-29 00:56:39,423 Training Epoch [40/40] Iter[246/312]		Loss: 0.0970
2019-10-29 00:56:39,544 Training Epoch [40/40] Iter[247/312]		Loss: 0.0969
2019-10-29 00:56:39,665 Training Epoch [40/40] Iter[248/312]		Loss: 0.0970
2019-10-29 00:56:39,787 Training Epoch [40/40] Iter[249/312]		Loss: 0.0970
2019-10-29 00:56:39,908 Training Epoch [40/40] Iter[250/312]		Loss: 0.0969
2019-10-29 00:56:40,029 Training Epoch [40/40] Iter[251/312]		Loss: 0.0971
2019-10-29 00:56:40,151 Training Epoch [40/40] Iter[252/312]		Loss: 0.0971
2019-10-29 00:56:40,273 Training Epoch [40/40] Iter[253/312]		Loss: 0.0972
2019-10-29 00:56:40,394 Training Epoch [40/40] Iter[254/312]		Loss: 0.0975
2019-10-29 00:56:40,516 Training Epoch [40/40] Iter[255/312]		Loss: 0.0976
2019-10-29 00:56:40,637 Training Epoch [40/40] Iter[256/312]		Loss: 0.0974
2019-10-29 00:56:40,759 Training Epoch [40/40] Iter[257/312]		Loss: 0.0975
2019-10-29 00:56:40,880 Training Epoch [40/40] Iter[258/312]		Loss: 0.0975
2019-10-29 00:56:41,001 Training Epoch [40/40] Iter[259/312]		Loss: 0.0975
2019-10-29 00:56:41,122 Training Epoch [40/40] Iter[260/312]		Loss: 0.0975
2019-10-29 00:56:41,243 Training Epoch [40/40] Iter[261/312]		Loss: 0.0977
2019-10-29 00:56:41,364 Training Epoch [40/40] Iter[262/312]		Loss: 0.0978
2019-10-29 00:56:41,485 Training Epoch [40/40] Iter[263/312]		Loss: 0.0978
2019-10-29 00:56:41,606 Training Epoch [40/40] Iter[264/312]		Loss: 0.0979
2019-10-29 00:56:41,727 Training Epoch [40/40] Iter[265/312]		Loss: 0.0981
2019-10-29 00:56:41,848 Training Epoch [40/40] Iter[266/312]		Loss: 0.0981
2019-10-29 00:56:41,969 Training Epoch [40/40] Iter[267/312]		Loss: 0.0982
2019-10-29 00:56:42,091 Training Epoch [40/40] Iter[268/312]		Loss: 0.0981
2019-10-29 00:56:42,213 Training Epoch [40/40] Iter[269/312]		Loss: 0.0980
2019-10-29 00:56:42,335 Training Epoch [40/40] Iter[270/312]		Loss: 0.0980
2019-10-29 00:56:42,456 Training Epoch [40/40] Iter[271/312]		Loss: 0.0979
2019-10-29 00:56:42,578 Training Epoch [40/40] Iter[272/312]		Loss: 0.0978
2019-10-29 00:56:42,700 Training Epoch [40/40] Iter[273/312]		Loss: 0.0978
2019-10-29 00:56:42,821 Training Epoch [40/40] Iter[274/312]		Loss: 0.0978
2019-10-29 00:56:42,942 Training Epoch [40/40] Iter[275/312]		Loss: 0.0978
2019-10-29 00:56:43,064 Training Epoch [40/40] Iter[276/312]		Loss: 0.0979
2019-10-29 00:56:43,185 Training Epoch [40/40] Iter[277/312]		Loss: 0.0980
2019-10-29 00:56:43,307 Training Epoch [40/40] Iter[278/312]		Loss: 0.0981
2019-10-29 00:56:43,429 Training Epoch [40/40] Iter[279/312]		Loss: 0.0981
2019-10-29 00:56:43,551 Training Epoch [40/40] Iter[280/312]		Loss: 0.0981
2019-10-29 00:56:43,672 Training Epoch [40/40] Iter[281/312]		Loss: 0.0981
2019-10-29 00:56:43,793 Training Epoch [40/40] Iter[282/312]		Loss: 0.0980
2019-10-29 00:56:43,914 Training Epoch [40/40] Iter[283/312]		Loss: 0.0980
2019-10-29 00:56:44,036 Training Epoch [40/40] Iter[284/312]		Loss: 0.0980
2019-10-29 00:56:44,157 Training Epoch [40/40] Iter[285/312]		Loss: 0.0981
2019-10-29 00:56:44,278 Training Epoch [40/40] Iter[286/312]		Loss: 0.0981
2019-10-29 00:56:44,399 Training Epoch [40/40] Iter[287/312]		Loss: 0.0981
2019-10-29 00:56:44,520 Training Epoch [40/40] Iter[288/312]		Loss: 0.0981
2019-10-29 00:56:44,641 Training Epoch [40/40] Iter[289/312]		Loss: 0.0984
2019-10-29 00:56:44,762 Training Epoch [40/40] Iter[290/312]		Loss: 0.0984
2019-10-29 00:56:44,883 Training Epoch [40/40] Iter[291/312]		Loss: 0.0984
2019-10-29 00:56:45,004 Training Epoch [40/40] Iter[292/312]		Loss: 0.0983
2019-10-29 00:56:45,126 Training Epoch [40/40] Iter[293/312]		Loss: 0.0982
2019-10-29 00:56:45,248 Training Epoch [40/40] Iter[294/312]		Loss: 0.0982
2019-10-29 00:56:45,370 Training Epoch [40/40] Iter[295/312]		Loss: 0.0982
2019-10-29 00:56:45,491 Training Epoch [40/40] Iter[296/312]		Loss: 0.0981
2019-10-29 00:56:45,612 Training Epoch [40/40] Iter[297/312]		Loss: 0.0981
2019-10-29 00:56:45,734 Training Epoch [40/40] Iter[298/312]		Loss: 0.0980
2019-10-29 00:56:45,856 Training Epoch [40/40] Iter[299/312]		Loss: 0.0982
2019-10-29 00:56:45,977 Training Epoch [40/40] Iter[300/312]		Loss: 0.0982
2019-10-29 00:56:46,099 Training Epoch [40/40] Iter[301/312]		Loss: 0.0982
2019-10-29 00:56:46,220 Training Epoch [40/40] Iter[302/312]		Loss: 0.0983
2019-10-29 00:56:46,342 Training Epoch [40/40] Iter[303/312]		Loss: 0.0982
2019-10-29 00:56:46,463 Training Epoch [40/40] Iter[304/312]		Loss: 0.0982
2019-10-29 00:56:46,584 Training Epoch [40/40] Iter[305/312]		Loss: 0.0984
2019-10-29 00:56:46,705 Training Epoch [40/40] Iter[306/312]		Loss: 0.0985
2019-10-29 00:56:46,826 Training Epoch [40/40] Iter[307/312]		Loss: 0.0984
2019-10-29 00:56:46,947 Training Epoch [40/40] Iter[308/312]		Loss: 0.0984
2019-10-29 00:56:47,068 Training Epoch [40/40] Iter[309/312]		Loss: 0.0984
2019-10-29 00:56:47,188 Training Epoch [40/40] Iter[310/312]		Loss: 0.0984
2019-10-29 00:56:47,309 Training Epoch [40/40] Iter[311/312]		Loss: 0.0983
2019-10-29 00:56:47,370 Training Epoch [40/40] Iter[312/312]		Loss: 0.0982
2019-10-29 00:56:47,615 Testing Epoch [40/40] Iter[0/62]		Loss: 0.0885
2019-10-29 00:56:47,652 Testing Epoch [40/40] Iter[1/62]		Loss: 0.1248
2019-10-29 00:56:47,692 Testing Epoch [40/40] Iter[2/62]		Loss: 0.1157
2019-10-29 00:56:47,726 Testing Epoch [40/40] Iter[3/62]		Loss: 0.1128
2019-10-29 00:56:47,756 Testing Epoch [40/40] Iter[4/62]		Loss: 0.1093
2019-10-29 00:56:47,790 Testing Epoch [40/40] Iter[5/62]		Loss: 0.1065
2019-10-29 00:56:47,821 Testing Epoch [40/40] Iter[6/62]		Loss: 0.1084
2019-10-29 00:56:47,850 Testing Epoch [40/40] Iter[7/62]		Loss: 0.1142
2019-10-29 00:56:47,882 Testing Epoch [40/40] Iter[8/62]		Loss: 0.1200
2019-10-29 00:56:47,913 Testing Epoch [40/40] Iter[9/62]		Loss: 0.1178
2019-10-29 00:56:47,943 Testing Epoch [40/40] Iter[10/62]		Loss: 0.1160
2019-10-29 00:56:47,978 Testing Epoch [40/40] Iter[11/62]		Loss: 0.1206
2019-10-29 00:56:48,009 Testing Epoch [40/40] Iter[12/62]		Loss: 0.1215
2019-10-29 00:56:48,040 Testing Epoch [40/40] Iter[13/62]		Loss: 0.1237
2019-10-29 00:56:48,074 Testing Epoch [40/40] Iter[14/62]		Loss: 0.1352
2019-10-29 00:56:48,104 Testing Epoch [40/40] Iter[15/62]		Loss: 0.1367
2019-10-29 00:56:48,135 Testing Epoch [40/40] Iter[16/62]		Loss: 0.1346
2019-10-29 00:56:48,170 Testing Epoch [40/40] Iter[17/62]		Loss: 0.1340
2019-10-29 00:56:48,201 Testing Epoch [40/40] Iter[18/62]		Loss: 0.1310
2019-10-29 00:56:48,231 Testing Epoch [40/40] Iter[19/62]		Loss: 0.1289
2019-10-29 00:56:48,266 Testing Epoch [40/40] Iter[20/62]		Loss: 0.1305
2019-10-29 00:56:48,297 Testing Epoch [40/40] Iter[21/62]		Loss: 0.1282
2019-10-29 00:56:48,328 Testing Epoch [40/40] Iter[22/62]		Loss: 0.1276
2019-10-29 00:56:48,366 Testing Epoch [40/40] Iter[23/62]		Loss: 0.1277
2019-10-29 00:56:48,396 Testing Epoch [40/40] Iter[24/62]		Loss: 0.1294
2019-10-29 00:56:48,427 Testing Epoch [40/40] Iter[25/62]		Loss: 0.1289
2019-10-29 00:56:48,458 Testing Epoch [40/40] Iter[26/62]		Loss: 0.1278
2019-10-29 00:56:48,489 Testing Epoch [40/40] Iter[27/62]		Loss: 0.1321
2019-10-29 00:56:48,520 Testing Epoch [40/40] Iter[28/62]		Loss: 0.1337
2019-10-29 00:56:48,551 Testing Epoch [40/40] Iter[29/62]		Loss: 0.1336
2019-10-29 00:56:48,581 Testing Epoch [40/40] Iter[30/62]		Loss: 0.1354
2019-10-29 00:56:48,612 Testing Epoch [40/40] Iter[31/62]		Loss: 0.1346
2019-10-29 00:56:48,643 Testing Epoch [40/40] Iter[32/62]		Loss: 0.1361
2019-10-29 00:56:48,674 Testing Epoch [40/40] Iter[33/62]		Loss: 0.1341
2019-10-29 00:56:48,705 Testing Epoch [40/40] Iter[34/62]		Loss: 0.1357
2019-10-29 00:56:48,736 Testing Epoch [40/40] Iter[35/62]		Loss: 0.1362
2019-10-29 00:56:48,766 Testing Epoch [40/40] Iter[36/62]		Loss: 0.1344
2019-10-29 00:56:48,797 Testing Epoch [40/40] Iter[37/62]		Loss: 0.1339
2019-10-29 00:56:48,828 Testing Epoch [40/40] Iter[38/62]		Loss: 0.1342
2019-10-29 00:56:48,859 Testing Epoch [40/40] Iter[39/62]		Loss: 0.1346
2019-10-29 00:56:48,890 Testing Epoch [40/40] Iter[40/62]		Loss: 0.1349
2019-10-29 00:56:48,921 Testing Epoch [40/40] Iter[41/62]		Loss: 0.1350
2019-10-29 00:56:48,952 Testing Epoch [40/40] Iter[42/62]		Loss: 0.1337
2019-10-29 00:56:48,982 Testing Epoch [40/40] Iter[43/62]		Loss: 0.1332
2019-10-29 00:56:49,013 Testing Epoch [40/40] Iter[44/62]		Loss: 0.1320
2019-10-29 00:56:49,044 Testing Epoch [40/40] Iter[45/62]		Loss: 0.1331
2019-10-29 00:56:49,075 Testing Epoch [40/40] Iter[46/62]		Loss: 0.1332
2019-10-29 00:56:49,106 Testing Epoch [40/40] Iter[47/62]		Loss: 0.1381
2019-10-29 00:56:49,137 Testing Epoch [40/40] Iter[48/62]		Loss: 0.1372
2019-10-29 00:56:49,168 Testing Epoch [40/40] Iter[49/62]		Loss: 0.1385
2019-10-29 00:56:49,198 Testing Epoch [40/40] Iter[50/62]		Loss: 0.1381
2019-10-29 00:56:49,229 Testing Epoch [40/40] Iter[51/62]		Loss: 0.1382
2019-10-29 00:56:49,260 Testing Epoch [40/40] Iter[52/62]		Loss: 0.1372
2019-10-29 00:56:49,290 Testing Epoch [40/40] Iter[53/62]		Loss: 0.1369
2019-10-29 00:56:49,321 Testing Epoch [40/40] Iter[54/62]		Loss: 0.1364
2019-10-29 00:56:49,351 Testing Epoch [40/40] Iter[55/62]		Loss: 0.1365
2019-10-29 00:56:49,382 Testing Epoch [40/40] Iter[56/62]		Loss: 0.1364
2019-10-29 00:56:49,412 Testing Epoch [40/40] Iter[57/62]		Loss: 0.1362
2019-10-29 00:56:49,442 Testing Epoch [40/40] Iter[58/62]		Loss: 0.1357
2019-10-29 00:56:49,472 Testing Epoch [40/40] Iter[59/62]		Loss: 0.1357
2019-10-29 00:56:49,502 Testing Epoch [40/40] Iter[60/62]		Loss: 0.1351
2019-10-29 00:56:49,533 Testing Epoch [40/40] Iter[61/62]		Loss: 0.1348
2019-10-29 00:56:49,550 Testing Epoch [40/40] Iter[62/62]		Loss: 0.1355
2019-10-29 00:56:49,603 Min Loss@1: 0.1366
