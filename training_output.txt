2019-10-28 17:15:47,227 Training Epoch [1/40] Iter[0/312]		Loss: 5.3387
2019-10-28 17:15:47,464 Training Epoch [1/40] Iter[1/312]		Loss: 4.5405
2019-10-28 17:15:47,702 Training Epoch [1/40] Iter[2/312]		Loss: 4.0881
2019-10-28 17:15:47,945 Training Epoch [1/40] Iter[3/312]		Loss: 3.7191
2019-10-28 17:15:48,183 Training Epoch [1/40] Iter[4/312]		Loss: 3.5096
2019-10-28 17:15:48,418 Training Epoch [1/40] Iter[5/312]		Loss: 3.3354
2019-10-28 17:15:48,656 Training Epoch [1/40] Iter[6/312]		Loss: 3.2497
2019-10-28 17:15:48,893 Training Epoch [1/40] Iter[7/312]		Loss: 3.1533
2019-10-28 17:15:49,134 Training Epoch [1/40] Iter[8/312]		Loss: 3.0271
2019-10-28 17:15:49,373 Training Epoch [1/40] Iter[9/312]		Loss: 2.9717
2019-10-28 17:15:49,610 Training Epoch [1/40] Iter[10/312]		Loss: 2.8951
2019-10-28 17:15:49,848 Training Epoch [1/40] Iter[11/312]		Loss: 2.8244
2019-10-28 17:15:50,086 Training Epoch [1/40] Iter[12/312]		Loss: 2.7660
2019-10-28 17:15:50,324 Training Epoch [1/40] Iter[13/312]		Loss: 2.7643
2019-10-28 17:15:50,560 Training Epoch [1/40] Iter[14/312]		Loss: 2.7340
2019-10-28 17:15:50,796 Training Epoch [1/40] Iter[15/312]		Loss: 2.7035
2019-10-28 17:15:51,032 Training Epoch [1/40] Iter[16/312]		Loss: 2.7042
2019-10-28 17:15:51,273 Training Epoch [1/40] Iter[17/312]		Loss: 2.6794
2019-10-28 17:15:51,511 Training Epoch [1/40] Iter[18/312]		Loss: 2.6656
2019-10-28 17:15:51,749 Training Epoch [1/40] Iter[19/312]		Loss: 2.6473
2019-10-28 17:15:51,987 Training Epoch [1/40] Iter[20/312]		Loss: 2.6284
2019-10-28 17:15:52,222 Training Epoch [1/40] Iter[21/312]		Loss: 2.5845
2019-10-28 17:15:52,458 Training Epoch [1/40] Iter[22/312]		Loss: 2.5763
2019-10-28 17:15:52,697 Training Epoch [1/40] Iter[23/312]		Loss: 2.5747
2019-10-28 17:15:52,944 Training Epoch [1/40] Iter[24/312]		Loss: 2.5674
2019-10-28 17:15:53,184 Training Epoch [1/40] Iter[25/312]		Loss: 2.5586
2019-10-28 17:15:53,421 Training Epoch [1/40] Iter[26/312]		Loss: 2.5526
2019-10-28 17:15:53,659 Training Epoch [1/40] Iter[27/312]		Loss: 2.5383
2019-10-28 17:15:53,895 Training Epoch [1/40] Iter[28/312]		Loss: 2.5327
2019-10-28 17:15:54,131 Training Epoch [1/40] Iter[29/312]		Loss: 2.5347
2019-10-28 17:15:54,368 Training Epoch [1/40] Iter[30/312]		Loss: 2.5372
2019-10-28 17:15:54,614 Training Epoch [1/40] Iter[31/312]		Loss: 2.5293
2019-10-28 17:15:54,853 Training Epoch [1/40] Iter[32/312]		Loss: 2.5257
2019-10-28 17:15:55,092 Training Epoch [1/40] Iter[33/312]		Loss: 2.5286
2019-10-28 17:15:55,333 Training Epoch [1/40] Iter[34/312]		Loss: 2.5259
2019-10-28 17:15:55,571 Training Epoch [1/40] Iter[35/312]		Loss: 2.5188
2019-10-28 17:15:55,812 Training Epoch [1/40] Iter[36/312]		Loss: 2.5178
2019-10-28 17:15:56,049 Training Epoch [1/40] Iter[37/312]		Loss: 2.5084
2019-10-28 17:15:56,291 Training Epoch [1/40] Iter[38/312]		Loss: 2.4942
2019-10-28 17:15:56,532 Training Epoch [1/40] Iter[39/312]		Loss: 2.4846
2019-10-28 17:15:56,771 Training Epoch [1/40] Iter[40/312]		Loss: 2.4752
2019-10-28 17:15:57,012 Training Epoch [1/40] Iter[41/312]		Loss: 2.4747
2019-10-28 17:15:57,250 Training Epoch [1/40] Iter[42/312]		Loss: 2.4622
2019-10-28 17:15:57,487 Training Epoch [1/40] Iter[43/312]		Loss: 2.4647
2019-10-28 17:15:57,724 Training Epoch [1/40] Iter[44/312]		Loss: 2.4598
2019-10-28 17:15:57,965 Training Epoch [1/40] Iter[45/312]		Loss: 2.4602
2019-10-28 17:15:58,206 Training Epoch [1/40] Iter[46/312]		Loss: 2.4563
2019-10-28 17:15:58,444 Training Epoch [1/40] Iter[47/312]		Loss: 2.4495
2019-10-28 17:15:58,681 Training Epoch [1/40] Iter[48/312]		Loss: 2.4559
2019-10-28 17:15:58,918 Training Epoch [1/40] Iter[49/312]		Loss: 2.4419
2019-10-28 17:15:59,158 Training Epoch [1/40] Iter[50/312]		Loss: 2.4399
2019-10-28 17:15:59,396 Training Epoch [1/40] Iter[51/312]		Loss: 2.4394
2019-10-28 17:15:59,636 Training Epoch [1/40] Iter[52/312]		Loss: 2.4365
2019-10-28 17:15:59,875 Training Epoch [1/40] Iter[53/312]		Loss: 2.4312
2019-10-28 17:16:00,111 Training Epoch [1/40] Iter[54/312]		Loss: 2.4302
2019-10-28 17:16:00,351 Training Epoch [1/40] Iter[55/312]		Loss: 2.4292
2019-10-28 17:16:00,587 Training Epoch [1/40] Iter[56/312]		Loss: 2.4215
2019-10-28 17:16:00,829 Training Epoch [1/40] Iter[57/312]		Loss: 2.4160
2019-10-28 17:16:01,066 Training Epoch [1/40] Iter[58/312]		Loss: 2.4110
2019-10-28 17:16:01,304 Training Epoch [1/40] Iter[59/312]		Loss: 2.4112
2019-10-28 17:16:01,542 Training Epoch [1/40] Iter[60/312]		Loss: 2.4023
2019-10-28 17:16:01,778 Training Epoch [1/40] Iter[61/312]		Loss: 2.4038
2019-10-28 17:16:02,018 Training Epoch [1/40] Iter[62/312]		Loss: 2.4043
2019-10-28 17:16:02,255 Training Epoch [1/40] Iter[63/312]		Loss: 2.4033
2019-10-28 17:16:02,493 Training Epoch [1/40] Iter[64/312]		Loss: 2.4073
2019-10-28 17:16:02,731 Training Epoch [1/40] Iter[65/312]		Loss: 2.4118
2019-10-28 17:16:02,969 Training Epoch [1/40] Iter[66/312]		Loss: 2.4123
2019-10-28 17:16:03,209 Training Epoch [1/40] Iter[67/312]		Loss: 2.4066
2019-10-28 17:16:03,448 Training Epoch [1/40] Iter[68/312]		Loss: 2.4021
2019-10-28 17:16:03,686 Training Epoch [1/40] Iter[69/312]		Loss: 2.4044
2019-10-28 17:16:03,927 Training Epoch [1/40] Iter[70/312]		Loss: 2.4068
2019-10-28 17:16:04,166 Training Epoch [1/40] Iter[71/312]		Loss: 2.4074
2019-10-28 17:16:04,406 Training Epoch [1/40] Iter[72/312]		Loss: 2.3989
2019-10-28 17:16:04,651 Training Epoch [1/40] Iter[73/312]		Loss: 2.3933
2019-10-28 17:16:04,889 Training Epoch [1/40] Iter[74/312]		Loss: 2.3907
2019-10-28 17:16:05,129 Training Epoch [1/40] Iter[75/312]		Loss: 2.3957
2019-10-28 17:16:05,368 Training Epoch [1/40] Iter[76/312]		Loss: 2.3924
2019-10-28 17:16:05,605 Training Epoch [1/40] Iter[77/312]		Loss: 2.3906
2019-10-28 17:16:05,843 Training Epoch [1/40] Iter[78/312]		Loss: 2.3918
2019-10-28 17:16:06,085 Training Epoch [1/40] Iter[79/312]		Loss: 2.3888
2019-10-28 17:16:06,325 Training Epoch [1/40] Iter[80/312]		Loss: 2.3896
2019-10-28 17:16:06,564 Training Epoch [1/40] Iter[81/312]		Loss: 2.3899
2019-10-28 17:16:06,803 Training Epoch [1/40] Iter[82/312]		Loss: 2.3862
2019-10-28 17:16:07,042 Training Epoch [1/40] Iter[83/312]		Loss: 2.3820
2019-10-28 17:16:07,281 Training Epoch [1/40] Iter[84/312]		Loss: 2.3771
2019-10-28 17:16:07,522 Training Epoch [1/40] Iter[85/312]		Loss: 2.3777
2019-10-28 17:16:07,766 Training Epoch [1/40] Iter[86/312]		Loss: 2.3787
2019-10-28 17:16:08,009 Training Epoch [1/40] Iter[87/312]		Loss: 2.3800
2019-10-28 17:16:08,249 Training Epoch [1/40] Iter[88/312]		Loss: 2.3803
2019-10-28 17:16:08,488 Training Epoch [1/40] Iter[89/312]		Loss: 2.3797
2019-10-28 17:16:08,725 Training Epoch [1/40] Iter[90/312]		Loss: 2.3756
2019-10-28 17:16:08,962 Training Epoch [1/40] Iter[91/312]		Loss: 2.3727
2019-10-28 17:16:09,202 Training Epoch [1/40] Iter[92/312]		Loss: 2.3721
2019-10-28 17:16:09,442 Training Epoch [1/40] Iter[93/312]		Loss: 2.3686
2019-10-28 17:16:09,680 Training Epoch [1/40] Iter[94/312]		Loss: 2.3706
2019-10-28 17:16:09,919 Training Epoch [1/40] Iter[95/312]		Loss: 2.3686
2019-10-28 17:16:10,157 Training Epoch [1/40] Iter[96/312]		Loss: 2.3698
2019-10-28 17:16:10,402 Training Epoch [1/40] Iter[97/312]		Loss: 2.3725
2019-10-28 17:16:10,643 Training Epoch [1/40] Iter[98/312]		Loss: 2.3730
2019-10-28 17:16:10,885 Training Epoch [1/40] Iter[99/312]		Loss: 2.3753
2019-10-28 17:16:11,124 Training Epoch [1/40] Iter[100/312]		Loss: 2.3771
2019-10-28 17:16:11,365 Training Epoch [1/40] Iter[101/312]		Loss: 2.3735
2019-10-28 17:16:11,605 Training Epoch [1/40] Iter[102/312]		Loss: 2.3723
2019-10-28 17:16:11,848 Training Epoch [1/40] Iter[103/312]		Loss: 2.3710
2019-10-28 17:16:12,086 Training Epoch [1/40] Iter[104/312]		Loss: 2.3691
2019-10-28 17:16:12,325 Training Epoch [1/40] Iter[105/312]		Loss: 2.3705
2019-10-28 17:16:12,571 Training Epoch [1/40] Iter[106/312]		Loss: 2.3709
2019-10-28 17:16:12,811 Training Epoch [1/40] Iter[107/312]		Loss: 2.3712
2019-10-28 17:16:13,050 Training Epoch [1/40] Iter[108/312]		Loss: 2.3734
2019-10-28 17:16:13,291 Training Epoch [1/40] Iter[109/312]		Loss: 2.3742
2019-10-28 17:16:13,532 Training Epoch [1/40] Iter[110/312]		Loss: 2.3720
2019-10-28 17:16:13,769 Training Epoch [1/40] Iter[111/312]		Loss: 2.3677
2019-10-28 17:16:14,008 Training Epoch [1/40] Iter[112/312]		Loss: 2.3609
2019-10-28 17:16:14,256 Training Epoch [1/40] Iter[113/312]		Loss: 2.3619
2019-10-28 17:16:14,497 Training Epoch [1/40] Iter[114/312]		Loss: 2.3627
2019-10-28 17:16:14,735 Training Epoch [1/40] Iter[115/312]		Loss: 2.3624
2019-10-28 17:16:14,975 Training Epoch [1/40] Iter[116/312]		Loss: 2.3588
2019-10-28 17:16:15,214 Training Epoch [1/40] Iter[117/312]		Loss: 2.3571
2019-10-28 17:16:15,455 Training Epoch [1/40] Iter[118/312]		Loss: 2.3550
2019-10-28 17:16:15,692 Training Epoch [1/40] Iter[119/312]		Loss: 2.3553
2019-10-28 17:16:15,932 Training Epoch [1/40] Iter[120/312]		Loss: 2.3523
2019-10-28 17:16:16,171 Training Epoch [1/40] Iter[121/312]		Loss: 2.3552
2019-10-28 17:16:16,410 Training Epoch [1/40] Iter[122/312]		Loss: 2.3539
2019-10-28 17:16:16,654 Training Epoch [1/40] Iter[123/312]		Loss: 2.3524
2019-10-28 17:16:16,895 Training Epoch [1/40] Iter[124/312]		Loss: 2.3522
2019-10-28 17:16:17,133 Training Epoch [1/40] Iter[125/312]		Loss: 2.3528
2019-10-28 17:16:17,372 Training Epoch [1/40] Iter[126/312]		Loss: 2.3527
2019-10-28 17:16:17,612 Training Epoch [1/40] Iter[127/312]		Loss: 2.3537
2019-10-28 17:16:17,849 Training Epoch [1/40] Iter[128/312]		Loss: 2.3516
2019-10-28 17:16:18,091 Training Epoch [1/40] Iter[129/312]		Loss: 2.3475
2019-10-28 17:16:18,331 Training Epoch [1/40] Iter[130/312]		Loss: 2.3467
2019-10-28 17:16:18,572 Training Epoch [1/40] Iter[131/312]		Loss: 2.3439
2019-10-28 17:16:18,814 Training Epoch [1/40] Iter[132/312]		Loss: 2.3464
2019-10-28 17:16:19,057 Training Epoch [1/40] Iter[133/312]		Loss: 2.3453
2019-10-28 17:16:19,302 Training Epoch [1/40] Iter[134/312]		Loss: 2.3452
2019-10-28 17:16:19,549 Training Epoch [1/40] Iter[135/312]		Loss: 2.3452
2019-10-28 17:16:19,788 Training Epoch [1/40] Iter[136/312]		Loss: 2.3437
2019-10-28 17:16:20,030 Training Epoch [1/40] Iter[137/312]		Loss: 2.3423
2019-10-28 17:16:20,270 Training Epoch [1/40] Iter[138/312]		Loss: 2.3401
2019-10-28 17:16:20,509 Training Epoch [1/40] Iter[139/312]		Loss: 2.3426
2019-10-28 17:16:20,748 Training Epoch [1/40] Iter[140/312]		Loss: 2.3420
2019-10-28 17:16:20,989 Training Epoch [1/40] Iter[141/312]		Loss: 2.3408
2019-10-28 17:16:21,225 Training Epoch [1/40] Iter[142/312]		Loss: 2.3412
2019-10-28 17:16:21,466 Training Epoch [1/40] Iter[143/312]		Loss: 2.3403
2019-10-28 17:16:21,705 Training Epoch [1/40] Iter[144/312]		Loss: 2.3425
2019-10-28 17:16:21,946 Training Epoch [1/40] Iter[145/312]		Loss: 2.3413
2019-10-28 17:16:22,189 Training Epoch [1/40] Iter[146/312]		Loss: 2.3404
2019-10-28 17:16:22,433 Training Epoch [1/40] Iter[147/312]		Loss: 2.3409
2019-10-28 17:16:22,670 Training Epoch [1/40] Iter[148/312]		Loss: 2.3411
2019-10-28 17:16:22,909 Training Epoch [1/40] Iter[149/312]		Loss: 2.3421
2019-10-28 17:16:23,149 Training Epoch [1/40] Iter[150/312]		Loss: 2.3407
2019-10-28 17:16:23,386 Training Epoch [1/40] Iter[151/312]		Loss: 2.3376
2019-10-28 17:16:23,623 Training Epoch [1/40] Iter[152/312]		Loss: 2.3348
2019-10-28 17:16:23,861 Training Epoch [1/40] Iter[153/312]		Loss: 2.3353
2019-10-28 17:16:24,101 Training Epoch [1/40] Iter[154/312]		Loss: 2.3331
2019-10-28 17:16:24,339 Training Epoch [1/40] Iter[155/312]		Loss: 2.3305
2019-10-28 17:16:24,577 Training Epoch [1/40] Iter[156/312]		Loss: 2.3297
2019-10-28 17:16:24,815 Training Epoch [1/40] Iter[157/312]		Loss: 2.3263
2019-10-28 17:16:25,053 Training Epoch [1/40] Iter[158/312]		Loss: 2.3227
2019-10-28 17:16:25,291 Training Epoch [1/40] Iter[159/312]		Loss: 2.3231
2019-10-28 17:16:25,533 Training Epoch [1/40] Iter[160/312]		Loss: 2.3203
2019-10-28 17:16:25,772 Training Epoch [1/40] Iter[161/312]		Loss: 2.3176
2019-10-28 17:16:26,010 Training Epoch [1/40] Iter[162/312]		Loss: 2.3139
2019-10-28 17:16:26,252 Training Epoch [1/40] Iter[163/312]		Loss: 2.3118
2019-10-28 17:16:26,501 Training Epoch [1/40] Iter[164/312]		Loss: 2.3084
2019-10-28 17:16:26,742 Training Epoch [1/40] Iter[165/312]		Loss: 2.3047
2019-10-28 17:16:26,988 Training Epoch [1/40] Iter[166/312]		Loss: 2.2993
2019-10-28 17:16:27,226 Training Epoch [1/40] Iter[167/312]		Loss: 2.2932
2019-10-28 17:16:27,466 Training Epoch [1/40] Iter[168/312]		Loss: 2.2877
2019-10-28 17:16:27,706 Training Epoch [1/40] Iter[169/312]		Loss: 2.2832
2019-10-28 17:16:27,945 Training Epoch [1/40] Iter[170/312]		Loss: 2.2804
2019-10-28 17:16:28,186 Training Epoch [1/40] Iter[171/312]		Loss: 2.2750
2019-10-28 17:16:28,425 Training Epoch [1/40] Iter[172/312]		Loss: 2.2712
2019-10-28 17:16:28,667 Training Epoch [1/40] Iter[173/312]		Loss: 2.2673
2019-10-28 17:16:28,906 Training Epoch [1/40] Iter[174/312]		Loss: 2.2646
2019-10-28 17:16:29,152 Training Epoch [1/40] Iter[175/312]		Loss: 2.2625
2019-10-28 17:16:29,391 Training Epoch [1/40] Iter[176/312]		Loss: 2.2572
2019-10-28 17:16:29,630 Training Epoch [1/40] Iter[177/312]		Loss: 2.2537
2019-10-28 17:16:29,870 Training Epoch [1/40] Iter[178/312]		Loss: 2.2496
2019-10-28 17:16:30,110 Training Epoch [1/40] Iter[179/312]		Loss: 2.2463
2019-10-28 17:16:30,352 Training Epoch [1/40] Iter[180/312]		Loss: 2.2422
2019-10-28 17:16:30,593 Training Epoch [1/40] Iter[181/312]		Loss: 2.2377
2019-10-28 17:16:30,837 Training Epoch [1/40] Iter[182/312]		Loss: 2.2341
2019-10-28 17:16:31,079 Training Epoch [1/40] Iter[183/312]		Loss: 2.2302
2019-10-28 17:16:31,316 Training Epoch [1/40] Iter[184/312]		Loss: 2.2251
2019-10-28 17:16:31,554 Training Epoch [1/40] Iter[185/312]		Loss: 2.2196
2019-10-28 17:16:31,792 Training Epoch [1/40] Iter[186/312]		Loss: 2.2155
2019-10-28 17:16:32,031 Training Epoch [1/40] Iter[187/312]		Loss: 2.2114
2019-10-28 17:16:32,269 Training Epoch [1/40] Iter[188/312]		Loss: 2.2064
2019-10-28 17:16:32,507 Training Epoch [1/40] Iter[189/312]		Loss: 2.2023
2019-10-28 17:16:32,751 Training Epoch [1/40] Iter[190/312]		Loss: 2.1987
2019-10-28 17:16:32,989 Training Epoch [1/40] Iter[191/312]		Loss: 2.1931
2019-10-28 17:16:33,229 Training Epoch [1/40] Iter[192/312]		Loss: 2.1888
2019-10-28 17:16:33,469 Training Epoch [1/40] Iter[193/312]		Loss: 2.1849
2019-10-28 17:16:33,707 Training Epoch [1/40] Iter[194/312]		Loss: 2.1804
2019-10-28 17:16:33,947 Training Epoch [1/40] Iter[195/312]		Loss: 2.1754
2019-10-28 17:16:34,194 Training Epoch [1/40] Iter[196/312]		Loss: 2.1717
2019-10-28 17:16:34,437 Training Epoch [1/40] Iter[197/312]		Loss: 2.1665
2019-10-28 17:16:34,679 Training Epoch [1/40] Iter[198/312]		Loss: 2.1612
2019-10-28 17:16:34,917 Training Epoch [1/40] Iter[199/312]		Loss: 2.1570
2019-10-28 17:16:35,166 Training Epoch [1/40] Iter[200/312]		Loss: 2.1529
2019-10-28 17:16:35,406 Training Epoch [1/40] Iter[201/312]		Loss: 2.1471
2019-10-28 17:16:35,646 Training Epoch [1/40] Iter[202/312]		Loss: 2.1423
2019-10-28 17:16:35,900 Training Epoch [1/40] Iter[203/312]		Loss: 2.1384
2019-10-28 17:16:36,151 Training Epoch [1/40] Iter[204/312]		Loss: 2.1332
2019-10-28 17:16:36,391 Training Epoch [1/40] Iter[205/312]		Loss: 2.1292
2019-10-28 17:16:36,634 Training Epoch [1/40] Iter[206/312]		Loss: 2.1244
2019-10-28 17:16:36,874 Training Epoch [1/40] Iter[207/312]		Loss: 2.1188
2019-10-28 17:16:37,113 Training Epoch [1/40] Iter[208/312]		Loss: 2.1135
2019-10-28 17:16:37,354 Training Epoch [1/40] Iter[209/312]		Loss: 2.1090
2019-10-28 17:16:37,596 Training Epoch [1/40] Iter[210/312]		Loss: 2.1039
2019-10-28 17:16:37,847 Training Epoch [1/40] Iter[211/312]		Loss: 2.0998
2019-10-28 17:16:38,094 Training Epoch [1/40] Iter[212/312]		Loss: 2.0959
2019-10-28 17:16:38,341 Training Epoch [1/40] Iter[213/312]		Loss: 2.0913
2019-10-28 17:16:38,600 Training Epoch [1/40] Iter[214/312]		Loss: 2.0872
2019-10-28 17:16:38,849 Training Epoch [1/40] Iter[215/312]		Loss: 2.0815
2019-10-28 17:16:39,107 Training Epoch [1/40] Iter[216/312]		Loss: 2.0754
2019-10-28 17:16:39,352 Training Epoch [1/40] Iter[217/312]		Loss: 2.0703
2019-10-28 17:16:39,593 Training Epoch [1/40] Iter[218/312]		Loss: 2.0659
2019-10-28 17:16:39,839 Training Epoch [1/40] Iter[219/312]		Loss: 2.0599
2019-10-28 17:16:40,089 Training Epoch [1/40] Iter[220/312]		Loss: 2.0552
2019-10-28 17:16:40,348 Training Epoch [1/40] Iter[221/312]		Loss: 2.0519
2019-10-28 17:16:40,610 Training Epoch [1/40] Iter[222/312]		Loss: 2.0483
2019-10-28 17:16:40,866 Training Epoch [1/40] Iter[223/312]		Loss: 2.0425
2019-10-28 17:16:41,115 Training Epoch [1/40] Iter[224/312]		Loss: 2.0393
2019-10-28 17:16:41,359 Training Epoch [1/40] Iter[225/312]		Loss: 2.0351
2019-10-28 17:16:41,608 Training Epoch [1/40] Iter[226/312]		Loss: 2.0302
2019-10-28 17:16:41,847 Training Epoch [1/40] Iter[227/312]		Loss: 2.0251
2019-10-28 17:16:42,084 Training Epoch [1/40] Iter[228/312]		Loss: 2.0223
2019-10-28 17:16:42,322 Training Epoch [1/40] Iter[229/312]		Loss: 2.0187
2019-10-28 17:16:42,560 Training Epoch [1/40] Iter[230/312]		Loss: 2.0139
2019-10-28 17:16:42,800 Training Epoch [1/40] Iter[231/312]		Loss: 2.0095
2019-10-28 17:16:43,036 Training Epoch [1/40] Iter[232/312]		Loss: 2.0059
2019-10-28 17:16:43,281 Training Epoch [1/40] Iter[233/312]		Loss: 2.0011
2019-10-28 17:16:43,524 Training Epoch [1/40] Iter[234/312]		Loss: 1.9975
2019-10-28 17:16:43,766 Training Epoch [1/40] Iter[235/312]		Loss: 1.9939
2019-10-28 17:16:44,004 Training Epoch [1/40] Iter[236/312]		Loss: 1.9904
2019-10-28 17:16:44,245 Training Epoch [1/40] Iter[237/312]		Loss: 1.9864
2019-10-28 17:16:44,485 Training Epoch [1/40] Iter[238/312]		Loss: 1.9823
2019-10-28 17:16:44,725 Training Epoch [1/40] Iter[239/312]		Loss: 1.9773
2019-10-28 17:16:44,967 Training Epoch [1/40] Iter[240/312]		Loss: 1.9749
2019-10-28 17:16:45,207 Training Epoch [1/40] Iter[241/312]		Loss: 1.9703
2019-10-28 17:16:45,446 Training Epoch [1/40] Iter[242/312]		Loss: 1.9664
2019-10-28 17:16:45,687 Training Epoch [1/40] Iter[243/312]		Loss: 1.9625
2019-10-28 17:16:45,925 Training Epoch [1/40] Iter[244/312]		Loss: 1.9592
2019-10-28 17:16:46,171 Training Epoch [1/40] Iter[245/312]		Loss: 1.9549
2019-10-28 17:16:46,418 Training Epoch [1/40] Iter[246/312]		Loss: 1.9504
2019-10-28 17:16:46,659 Training Epoch [1/40] Iter[247/312]		Loss: 1.9454
2019-10-28 17:16:46,904 Training Epoch [1/40] Iter[248/312]		Loss: 1.9420
2019-10-28 17:16:47,143 Training Epoch [1/40] Iter[249/312]		Loss: 1.9386
2019-10-28 17:16:47,384 Training Epoch [1/40] Iter[250/312]		Loss: 1.9343
2019-10-28 17:16:47,624 Training Epoch [1/40] Iter[251/312]		Loss: 1.9290
2019-10-28 17:16:47,873 Training Epoch [1/40] Iter[252/312]		Loss: 1.9253
2019-10-28 17:16:48,118 Training Epoch [1/40] Iter[253/312]		Loss: 1.9210
2019-10-28 17:16:48,358 Training Epoch [1/40] Iter[254/312]		Loss: 1.9187
2019-10-28 17:16:48,599 Training Epoch [1/40] Iter[255/312]		Loss: 1.9152
2019-10-28 17:16:48,839 Training Epoch [1/40] Iter[256/312]		Loss: 1.9108
2019-10-28 17:16:49,081 Training Epoch [1/40] Iter[257/312]		Loss: 1.9087
2019-10-28 17:16:49,324 Training Epoch [1/40] Iter[258/312]		Loss: 1.9054
2019-10-28 17:16:49,570 Training Epoch [1/40] Iter[259/312]		Loss: 1.9023
2019-10-28 17:16:49,808 Training Epoch [1/40] Iter[260/312]		Loss: 1.8988
2019-10-28 17:16:50,048 Training Epoch [1/40] Iter[261/312]		Loss: 1.8958
2019-10-28 17:16:50,291 Training Epoch [1/40] Iter[262/312]		Loss: 1.8922
2019-10-28 17:16:50,533 Training Epoch [1/40] Iter[263/312]		Loss: 1.8885
2019-10-28 17:16:50,777 Training Epoch [1/40] Iter[264/312]		Loss: 1.8851
2019-10-28 17:16:51,017 Training Epoch [1/40] Iter[265/312]		Loss: 1.8818
2019-10-28 17:16:51,256 Training Epoch [1/40] Iter[266/312]		Loss: 1.8787
2019-10-28 17:16:51,494 Training Epoch [1/40] Iter[267/312]		Loss: 1.8758
2019-10-28 17:16:51,734 Training Epoch [1/40] Iter[268/312]		Loss: 1.8720
2019-10-28 17:16:51,975 Training Epoch [1/40] Iter[269/312]		Loss: 1.8678
2019-10-28 17:16:52,221 Training Epoch [1/40] Iter[270/312]		Loss: 1.8641
2019-10-28 17:16:52,464 Training Epoch [1/40] Iter[271/312]		Loss: 1.8604
2019-10-28 17:16:52,705 Training Epoch [1/40] Iter[272/312]		Loss: 1.8573
2019-10-28 17:16:52,953 Training Epoch [1/40] Iter[273/312]		Loss: 1.8545
2019-10-28 17:16:53,196 Training Epoch [1/40] Iter[274/312]		Loss: 1.8509
2019-10-28 17:16:53,435 Training Epoch [1/40] Iter[275/312]		Loss: 1.8473
2019-10-28 17:16:53,674 Training Epoch [1/40] Iter[276/312]		Loss: 1.8443
2019-10-28 17:16:53,913 Training Epoch [1/40] Iter[277/312]		Loss: 1.8413
2019-10-28 17:16:54,152 Training Epoch [1/40] Iter[278/312]		Loss: 1.8384
2019-10-28 17:16:54,393 Training Epoch [1/40] Iter[279/312]		Loss: 1.8355
2019-10-28 17:16:54,636 Training Epoch [1/40] Iter[280/312]		Loss: 1.8334
2019-10-28 17:16:54,881 Training Epoch [1/40] Iter[281/312]		Loss: 1.8299
2019-10-28 17:16:55,123 Training Epoch [1/40] Iter[282/312]		Loss: 1.8263
2019-10-28 17:16:55,365 Training Epoch [1/40] Iter[283/312]		Loss: 1.8228
2019-10-28 17:16:55,611 Training Epoch [1/40] Iter[284/312]		Loss: 1.8196
2019-10-28 17:16:55,858 Training Epoch [1/40] Iter[285/312]		Loss: 1.8165
2019-10-28 17:16:56,104 Training Epoch [1/40] Iter[286/312]		Loss: 1.8145
2019-10-28 17:16:56,359 Training Epoch [1/40] Iter[287/312]		Loss: 1.8117
2019-10-28 17:16:56,616 Training Epoch [1/40] Iter[288/312]		Loss: 1.8081
2019-10-28 17:16:56,874 Training Epoch [1/40] Iter[289/312]		Loss: 1.8048
2019-10-28 17:16:57,135 Training Epoch [1/40] Iter[290/312]		Loss: 1.8030
2019-10-28 17:16:57,388 Training Epoch [1/40] Iter[291/312]		Loss: 1.7990
2019-10-28 17:16:57,645 Training Epoch [1/40] Iter[292/312]		Loss: 1.7964
2019-10-28 17:16:57,910 Training Epoch [1/40] Iter[293/312]		Loss: 1.7938
2019-10-28 17:16:58,151 Training Epoch [1/40] Iter[294/312]		Loss: 1.7907
2019-10-28 17:16:58,417 Training Epoch [1/40] Iter[295/312]		Loss: 1.7874
2019-10-28 17:16:58,666 Training Epoch [1/40] Iter[296/312]		Loss: 1.7845
2019-10-28 17:16:58,911 Training Epoch [1/40] Iter[297/312]		Loss: 1.7814
2019-10-28 17:16:59,158 Training Epoch [1/40] Iter[298/312]		Loss: 1.7789
2019-10-28 17:16:59,398 Training Epoch [1/40] Iter[299/312]		Loss: 1.7755
2019-10-28 17:16:59,663 Training Epoch [1/40] Iter[300/312]		Loss: 1.7731
2019-10-28 17:16:59,901 Training Epoch [1/40] Iter[301/312]		Loss: 1.7704
2019-10-28 17:17:00,151 Training Epoch [1/40] Iter[302/312]		Loss: 1.7673
2019-10-28 17:17:00,389 Training Epoch [1/40] Iter[303/312]		Loss: 1.7648
2019-10-28 17:17:00,628 Training Epoch [1/40] Iter[304/312]		Loss: 1.7617
2019-10-28 17:17:00,867 Training Epoch [1/40] Iter[305/312]		Loss: 1.7589
2019-10-28 17:17:01,104 Training Epoch [1/40] Iter[306/312]		Loss: 1.7564
2019-10-28 17:17:01,343 Training Epoch [1/40] Iter[307/312]		Loss: 1.7542
2019-10-28 17:17:01,583 Training Epoch [1/40] Iter[308/312]		Loss: 1.7518
2019-10-28 17:17:01,825 Training Epoch [1/40] Iter[309/312]		Loss: 1.7494
2019-10-28 17:17:02,064 Training Epoch [1/40] Iter[310/312]		Loss: 1.7462
2019-10-28 17:17:02,303 Training Epoch [1/40] Iter[311/312]		Loss: 1.7440
2019-10-28 17:17:02,438 Training Epoch [1/40] Iter[312/312]		Loss: 1.7420
2019-10-28 17:17:02,623 Testing Epoch [1/40] Iter[0/62]		Loss: 0.7964
2019-10-28 17:17:02,698 Testing Epoch [1/40] Iter[1/62]		Loss: 0.8414
2019-10-28 17:17:02,772 Testing Epoch [1/40] Iter[2/62]		Loss: 0.9470
2019-10-28 17:17:02,846 Testing Epoch [1/40] Iter[3/62]		Loss: 0.9959
2019-10-28 17:17:02,922 Testing Epoch [1/40] Iter[4/62]		Loss: 1.0221
2019-10-28 17:17:02,996 Testing Epoch [1/40] Iter[5/62]		Loss: 1.0826
2019-10-28 17:17:03,070 Testing Epoch [1/40] Iter[6/62]		Loss: 1.0850
2019-10-28 17:17:03,144 Testing Epoch [1/40] Iter[7/62]		Loss: 1.0622
2019-10-28 17:17:03,219 Testing Epoch [1/40] Iter[8/62]		Loss: 1.0675
2019-10-28 17:17:03,294 Testing Epoch [1/40] Iter[9/62]		Loss: 1.0383
2019-10-28 17:17:03,370 Testing Epoch [1/40] Iter[10/62]		Loss: 1.0361
2019-10-28 17:17:03,445 Testing Epoch [1/40] Iter[11/62]		Loss: 1.0236
2019-10-28 17:17:03,520 Testing Epoch [1/40] Iter[12/62]		Loss: 1.0438
2019-10-28 17:17:03,594 Testing Epoch [1/40] Iter[13/62]		Loss: 1.0413
2019-10-28 17:17:03,670 Testing Epoch [1/40] Iter[14/62]		Loss: 1.0353
2019-10-28 17:17:03,744 Testing Epoch [1/40] Iter[15/62]		Loss: 1.0489
2019-10-28 17:17:03,821 Testing Epoch [1/40] Iter[16/62]		Loss: 1.0401
2019-10-28 17:17:03,897 Testing Epoch [1/40] Iter[17/62]		Loss: 1.0483
2019-10-28 17:17:03,973 Testing Epoch [1/40] Iter[18/62]		Loss: 1.0647
2019-10-28 17:17:04,048 Testing Epoch [1/40] Iter[19/62]		Loss: 1.0534
2019-10-28 17:17:04,125 Testing Epoch [1/40] Iter[20/62]		Loss: 1.0507
2019-10-28 17:17:04,202 Testing Epoch [1/40] Iter[21/62]		Loss: 1.0672
2019-10-28 17:17:04,278 Testing Epoch [1/40] Iter[22/62]		Loss: 1.0616
2019-10-28 17:17:04,353 Testing Epoch [1/40] Iter[23/62]		Loss: 1.0532
2019-10-28 17:17:04,430 Testing Epoch [1/40] Iter[24/62]		Loss: 1.0557
2019-10-28 17:17:04,504 Testing Epoch [1/40] Iter[25/62]		Loss: 1.0423
2019-10-28 17:17:04,579 Testing Epoch [1/40] Iter[26/62]		Loss: 1.0476
2019-10-28 17:17:04,655 Testing Epoch [1/40] Iter[27/62]		Loss: 1.0491
2019-10-28 17:17:04,735 Testing Epoch [1/40] Iter[28/62]		Loss: 1.0474
2019-10-28 17:17:04,809 Testing Epoch [1/40] Iter[29/62]		Loss: 1.0475
2019-10-28 17:17:04,887 Testing Epoch [1/40] Iter[30/62]		Loss: 1.0410
2019-10-28 17:17:04,962 Testing Epoch [1/40] Iter[31/62]		Loss: 1.0355
2019-10-28 17:17:05,037 Testing Epoch [1/40] Iter[32/62]		Loss: 1.0372
2019-10-28 17:17:05,114 Testing Epoch [1/40] Iter[33/62]		Loss: 1.0389
2019-10-28 17:17:05,188 Testing Epoch [1/40] Iter[34/62]		Loss: 1.0436
2019-10-28 17:17:05,264 Testing Epoch [1/40] Iter[35/62]		Loss: 1.0513
2019-10-28 17:17:05,338 Testing Epoch [1/40] Iter[36/62]		Loss: 1.0480
2019-10-28 17:17:05,416 Testing Epoch [1/40] Iter[37/62]		Loss: 1.0521
2019-10-28 17:17:05,490 Testing Epoch [1/40] Iter[38/62]		Loss: 1.0541
2019-10-28 17:17:05,565 Testing Epoch [1/40] Iter[39/62]		Loss: 1.0601
2019-10-28 17:17:05,640 Testing Epoch [1/40] Iter[40/62]		Loss: 1.0612
2019-10-28 17:17:05,715 Testing Epoch [1/40] Iter[41/62]		Loss: 1.0641
2019-10-28 17:17:05,790 Testing Epoch [1/40] Iter[42/62]		Loss: 1.0658
2019-10-28 17:17:05,864 Testing Epoch [1/40] Iter[43/62]		Loss: 1.0602
2019-10-28 17:17:05,941 Testing Epoch [1/40] Iter[44/62]		Loss: 1.0563
2019-10-28 17:17:06,016 Testing Epoch [1/40] Iter[45/62]		Loss: 1.0563
2019-10-28 17:17:06,090 Testing Epoch [1/40] Iter[46/62]		Loss: 1.0575
2019-10-28 17:17:06,165 Testing Epoch [1/40] Iter[47/62]		Loss: 1.0574
2019-10-28 17:17:06,241 Testing Epoch [1/40] Iter[48/62]		Loss: 1.0534
2019-10-28 17:17:06,316 Testing Epoch [1/40] Iter[49/62]		Loss: 1.0540
2019-10-28 17:17:06,391 Testing Epoch [1/40] Iter[50/62]		Loss: 1.0585
2019-10-28 17:17:06,466 Testing Epoch [1/40] Iter[51/62]		Loss: 1.0599
2019-10-28 17:17:06,542 Testing Epoch [1/40] Iter[52/62]		Loss: 1.0665
2019-10-28 17:17:06,617 Testing Epoch [1/40] Iter[53/62]		Loss: 1.0665
2019-10-28 17:17:06,691 Testing Epoch [1/40] Iter[54/62]		Loss: 1.0621
2019-10-28 17:17:06,766 Testing Epoch [1/40] Iter[55/62]		Loss: 1.0630
2019-10-28 17:17:06,843 Testing Epoch [1/40] Iter[56/62]		Loss: 1.0605
2019-10-28 17:17:06,923 Testing Epoch [1/40] Iter[57/62]		Loss: 1.0600
2019-10-28 17:17:06,998 Testing Epoch [1/40] Iter[58/62]		Loss: 1.0582
2019-10-28 17:17:07,072 Testing Epoch [1/40] Iter[59/62]		Loss: 1.0567
2019-10-28 17:17:07,149 Testing Epoch [1/40] Iter[60/62]		Loss: 1.0583
2019-10-28 17:17:07,225 Testing Epoch [1/40] Iter[61/62]		Loss: 1.0626
2019-10-28 17:17:07,264 Testing Epoch [1/40] Iter[62/62]		Loss: 1.0593
2019-10-28 17:17:07,302 Saving the Model
2019-10-28 17:17:07,639 Training Epoch [2/40] Iter[0/312]		Loss: 0.7037
2019-10-28 17:17:07,880 Training Epoch [2/40] Iter[1/312]		Loss: 0.8417
2019-10-28 17:17:08,124 Training Epoch [2/40] Iter[2/312]		Loss: 0.8762
2019-10-28 17:17:08,369 Training Epoch [2/40] Iter[3/312]		Loss: 0.8823
2019-10-28 17:17:08,610 Training Epoch [2/40] Iter[4/312]		Loss: 0.9395
2019-10-28 17:17:08,850 Training Epoch [2/40] Iter[5/312]		Loss: 0.9372
2019-10-28 17:17:09,098 Training Epoch [2/40] Iter[6/312]		Loss: 0.9373
2019-10-28 17:17:09,344 Training Epoch [2/40] Iter[7/312]		Loss: 0.9638
2019-10-28 17:17:09,589 Training Epoch [2/40] Iter[8/312]		Loss: 0.9784
2019-10-28 17:17:09,828 Training Epoch [2/40] Iter[9/312]		Loss: 0.9728
2019-10-28 17:17:10,071 Training Epoch [2/40] Iter[10/312]		Loss: 0.9766
2019-10-28 17:17:10,314 Training Epoch [2/40] Iter[11/312]		Loss: 0.9711
2019-10-28 17:17:10,562 Training Epoch [2/40] Iter[12/312]		Loss: 0.9735
2019-10-28 17:17:10,814 Training Epoch [2/40] Iter[13/312]		Loss: 0.9630
2019-10-28 17:17:11,056 Training Epoch [2/40] Iter[14/312]		Loss: 0.9589
2019-10-28 17:17:11,296 Training Epoch [2/40] Iter[15/312]		Loss: 0.9686
2019-10-28 17:17:11,538 Training Epoch [2/40] Iter[16/312]		Loss: 0.9460
2019-10-28 17:17:11,782 Training Epoch [2/40] Iter[17/312]		Loss: 0.9465
2019-10-28 17:17:12,024 Training Epoch [2/40] Iter[18/312]		Loss: 0.9400
2019-10-28 17:17:12,272 Training Epoch [2/40] Iter[19/312]		Loss: 0.9349
2019-10-28 17:17:12,521 Training Epoch [2/40] Iter[20/312]		Loss: 0.9289
2019-10-28 17:17:12,765 Training Epoch [2/40] Iter[21/312]		Loss: 0.9308
2019-10-28 17:17:13,008 Training Epoch [2/40] Iter[22/312]		Loss: 0.9429
2019-10-28 17:17:13,252 Training Epoch [2/40] Iter[23/312]		Loss: 0.9383
2019-10-28 17:17:13,495 Training Epoch [2/40] Iter[24/312]		Loss: 0.9392
2019-10-28 17:17:13,739 Training Epoch [2/40] Iter[25/312]		Loss: 0.9312
2019-10-28 17:17:13,982 Training Epoch [2/40] Iter[26/312]		Loss: 0.9237
2019-10-28 17:17:14,224 Training Epoch [2/40] Iter[27/312]		Loss: 0.9169
2019-10-28 17:17:14,475 Training Epoch [2/40] Iter[28/312]		Loss: 0.9158
2019-10-28 17:17:14,722 Training Epoch [2/40] Iter[29/312]		Loss: 0.9146
2019-10-28 17:17:14,976 Training Epoch [2/40] Iter[30/312]		Loss: 0.9146
2019-10-28 17:17:15,216 Training Epoch [2/40] Iter[31/312]		Loss: 0.9197
2019-10-28 17:17:15,456 Training Epoch [2/40] Iter[32/312]		Loss: 0.9128
2019-10-28 17:17:15,698 Training Epoch [2/40] Iter[33/312]		Loss: 0.9102
2019-10-28 17:17:15,942 Training Epoch [2/40] Iter[34/312]		Loss: 0.9107
2019-10-28 17:17:16,181 Training Epoch [2/40] Iter[35/312]		Loss: 0.9138
2019-10-28 17:17:16,424 Training Epoch [2/40] Iter[36/312]		Loss: 0.9161
2019-10-28 17:17:16,664 Training Epoch [2/40] Iter[37/312]		Loss: 0.9123
2019-10-28 17:17:16,905 Training Epoch [2/40] Iter[38/312]		Loss: 0.9061
2019-10-28 17:17:17,143 Training Epoch [2/40] Iter[39/312]		Loss: 0.9015
2019-10-28 17:17:17,381 Training Epoch [2/40] Iter[40/312]		Loss: 0.8979
2019-10-28 17:17:17,623 Training Epoch [2/40] Iter[41/312]		Loss: 0.9000
2019-10-28 17:17:17,868 Training Epoch [2/40] Iter[42/312]		Loss: 0.8952
2019-10-28 17:17:18,110 Training Epoch [2/40] Iter[43/312]		Loss: 0.8958
2019-10-28 17:17:18,355 Training Epoch [2/40] Iter[44/312]		Loss: 0.8989
2019-10-28 17:17:18,598 Training Epoch [2/40] Iter[45/312]		Loss: 0.8974
2019-10-28 17:17:18,840 Training Epoch [2/40] Iter[46/312]		Loss: 0.8987
2019-10-28 17:17:19,084 Training Epoch [2/40] Iter[47/312]		Loss: 0.9020
2019-10-28 17:17:19,332 Training Epoch [2/40] Iter[48/312]		Loss: 0.9037
2019-10-28 17:17:19,573 Training Epoch [2/40] Iter[49/312]		Loss: 0.9053
2019-10-28 17:17:19,814 Training Epoch [2/40] Iter[50/312]		Loss: 0.9089
2019-10-28 17:17:20,054 Training Epoch [2/40] Iter[51/312]		Loss: 0.9125
2019-10-28 17:17:20,298 Training Epoch [2/40] Iter[52/312]		Loss: 0.9105
2019-10-28 17:17:20,541 Training Epoch [2/40] Iter[53/312]		Loss: 0.9045
2019-10-28 17:17:20,781 Training Epoch [2/40] Iter[54/312]		Loss: 0.9050
2019-10-28 17:17:21,023 Training Epoch [2/40] Iter[55/312]		Loss: 0.9044
2019-10-28 17:17:21,267 Training Epoch [2/40] Iter[56/312]		Loss: 0.9040
2019-10-28 17:17:21,509 Training Epoch [2/40] Iter[57/312]		Loss: 0.9044
2019-10-28 17:17:21,752 Training Epoch [2/40] Iter[58/312]		Loss: 0.9054
2019-10-28 17:17:21,997 Training Epoch [2/40] Iter[59/312]		Loss: 0.9044
2019-10-28 17:17:22,238 Training Epoch [2/40] Iter[60/312]		Loss: 0.9053
2019-10-28 17:17:22,480 Training Epoch [2/40] Iter[61/312]		Loss: 0.9057
2019-10-28 17:17:22,721 Training Epoch [2/40] Iter[62/312]		Loss: 0.9076
2019-10-28 17:17:22,963 Training Epoch [2/40] Iter[63/312]		Loss: 0.9062
2019-10-28 17:17:23,203 Training Epoch [2/40] Iter[64/312]		Loss: 0.9043
2019-10-28 17:17:23,445 Training Epoch [2/40] Iter[65/312]		Loss: 0.9047
2019-10-28 17:17:23,687 Training Epoch [2/40] Iter[66/312]		Loss: 0.9032
2019-10-28 17:17:23,927 Training Epoch [2/40] Iter[67/312]		Loss: 0.9068
2019-10-28 17:17:24,169 Training Epoch [2/40] Iter[68/312]		Loss: 0.9081
2019-10-28 17:17:24,408 Training Epoch [2/40] Iter[69/312]		Loss: 0.9067
2019-10-28 17:17:24,651 Training Epoch [2/40] Iter[70/312]		Loss: 0.9083
2019-10-28 17:17:24,892 Training Epoch [2/40] Iter[71/312]		Loss: 0.9098
2019-10-28 17:17:25,132 Training Epoch [2/40] Iter[72/312]		Loss: 0.9065
2019-10-28 17:17:25,375 Training Epoch [2/40] Iter[73/312]		Loss: 0.9074
2019-10-28 17:17:25,620 Training Epoch [2/40] Iter[74/312]		Loss: 0.9079
2019-10-28 17:17:25,861 Training Epoch [2/40] Iter[75/312]		Loss: 0.9087
2019-10-28 17:17:26,102 Training Epoch [2/40] Iter[76/312]		Loss: 0.9070
2019-10-28 17:17:26,342 Training Epoch [2/40] Iter[77/312]		Loss: 0.9049
2019-10-28 17:17:26,584 Training Epoch [2/40] Iter[78/312]		Loss: 0.9072
2019-10-28 17:17:26,827 Training Epoch [2/40] Iter[79/312]		Loss: 0.9060
2019-10-28 17:17:27,071 Training Epoch [2/40] Iter[80/312]		Loss: 0.9066
2019-10-28 17:17:27,317 Training Epoch [2/40] Iter[81/312]		Loss: 0.9066
2019-10-28 17:17:27,558 Training Epoch [2/40] Iter[82/312]		Loss: 0.9102
2019-10-28 17:17:27,802 Training Epoch [2/40] Iter[83/312]		Loss: 0.9075
2019-10-28 17:17:28,041 Training Epoch [2/40] Iter[84/312]		Loss: 0.9080
2019-10-28 17:17:28,280 Training Epoch [2/40] Iter[85/312]		Loss: 0.9064
2019-10-28 17:17:28,521 Training Epoch [2/40] Iter[86/312]		Loss: 0.9066
2019-10-28 17:17:28,763 Training Epoch [2/40] Iter[87/312]		Loss: 0.9078
2019-10-28 17:17:29,007 Training Epoch [2/40] Iter[88/312]		Loss: 0.9088
2019-10-28 17:17:29,248 Training Epoch [2/40] Iter[89/312]		Loss: 0.9115
2019-10-28 17:17:29,490 Training Epoch [2/40] Iter[90/312]		Loss: 0.9113
2019-10-28 17:17:29,732 Training Epoch [2/40] Iter[91/312]		Loss: 0.9100
2019-10-28 17:17:29,973 Training Epoch [2/40] Iter[92/312]		Loss: 0.9086
2019-10-28 17:17:30,215 Training Epoch [2/40] Iter[93/312]		Loss: 0.9075
2019-10-28 17:17:30,462 Training Epoch [2/40] Iter[94/312]		Loss: 0.9061
2019-10-28 17:17:30,704 Training Epoch [2/40] Iter[95/312]		Loss: 0.9068
2019-10-28 17:17:30,946 Training Epoch [2/40] Iter[96/312]		Loss: 0.9079
2019-10-28 17:17:31,184 Training Epoch [2/40] Iter[97/312]		Loss: 0.9093
2019-10-28 17:17:31,424 Training Epoch [2/40] Iter[98/312]		Loss: 0.9078
2019-10-28 17:17:31,665 Training Epoch [2/40] Iter[99/312]		Loss: 0.9067
2019-10-28 17:17:31,907 Training Epoch [2/40] Iter[100/312]		Loss: 0.9085
2019-10-28 17:17:32,152 Training Epoch [2/40] Iter[101/312]		Loss: 0.9096
2019-10-28 17:17:32,394 Training Epoch [2/40] Iter[102/312]		Loss: 0.9078
2019-10-28 17:17:32,633 Training Epoch [2/40] Iter[103/312]		Loss: 0.9071
2019-10-28 17:17:32,876 Training Epoch [2/40] Iter[104/312]		Loss: 0.9060
2019-10-28 17:17:33,116 Training Epoch [2/40] Iter[105/312]		Loss: 0.9057
2019-10-28 17:17:33,356 Training Epoch [2/40] Iter[106/312]		Loss: 0.9048
2019-10-28 17:17:33,601 Training Epoch [2/40] Iter[107/312]		Loss: 0.9056
2019-10-28 17:17:33,843 Training Epoch [2/40] Iter[108/312]		Loss: 0.9038
2019-10-28 17:17:34,084 Training Epoch [2/40] Iter[109/312]		Loss: 0.9037
2019-10-28 17:17:34,325 Training Epoch [2/40] Iter[110/312]		Loss: 0.9018
2019-10-28 17:17:34,569 Training Epoch [2/40] Iter[111/312]		Loss: 0.9022
2019-10-28 17:17:34,813 Training Epoch [2/40] Iter[112/312]		Loss: 0.9011
2019-10-28 17:17:35,053 Training Epoch [2/40] Iter[113/312]		Loss: 0.9011
2019-10-28 17:17:35,298 Training Epoch [2/40] Iter[114/312]		Loss: 0.9041
2019-10-28 17:17:35,541 Training Epoch [2/40] Iter[115/312]		Loss: 0.9045
2019-10-28 17:17:35,781 Training Epoch [2/40] Iter[116/312]		Loss: 0.9058
2019-10-28 17:17:36,023 Training Epoch [2/40] Iter[117/312]		Loss: 0.9058
2019-10-28 17:17:36,263 Training Epoch [2/40] Iter[118/312]		Loss: 0.9043
2019-10-28 17:17:36,504 Training Epoch [2/40] Iter[119/312]		Loss: 0.9048
2019-10-28 17:17:36,747 Training Epoch [2/40] Iter[120/312]		Loss: 0.9039
2019-10-28 17:17:36,988 Training Epoch [2/40] Iter[121/312]		Loss: 0.9027
2019-10-28 17:17:37,234 Training Epoch [2/40] Iter[122/312]		Loss: 0.9039
2019-10-28 17:17:37,476 Training Epoch [2/40] Iter[123/312]		Loss: 0.9033
2019-10-28 17:17:37,718 Training Epoch [2/40] Iter[124/312]		Loss: 0.9022
2019-10-28 17:17:37,967 Training Epoch [2/40] Iter[125/312]		Loss: 0.9018
2019-10-28 17:17:38,208 Training Epoch [2/40] Iter[126/312]		Loss: 0.9036
2019-10-28 17:17:38,449 Training Epoch [2/40] Iter[127/312]		Loss: 0.9025
2019-10-28 17:17:38,692 Training Epoch [2/40] Iter[128/312]		Loss: 0.9016
2019-10-28 17:17:38,932 Training Epoch [2/40] Iter[129/312]		Loss: 0.9011
2019-10-28 17:17:39,171 Training Epoch [2/40] Iter[130/312]		Loss: 0.8994
2019-10-28 17:17:39,412 Training Epoch [2/40] Iter[131/312]		Loss: 0.8995
2019-10-28 17:17:39,653 Training Epoch [2/40] Iter[132/312]		Loss: 0.8976
2019-10-28 17:17:39,894 Training Epoch [2/40] Iter[133/312]		Loss: 0.8983
2019-10-28 17:17:40,133 Training Epoch [2/40] Iter[134/312]		Loss: 0.8981
2019-10-28 17:17:40,378 Training Epoch [2/40] Iter[135/312]		Loss: 0.8986
2019-10-28 17:17:40,620 Training Epoch [2/40] Iter[136/312]		Loss: 0.8996
2019-10-28 17:17:40,862 Training Epoch [2/40] Iter[137/312]		Loss: 0.8987
2019-10-28 17:17:41,103 Training Epoch [2/40] Iter[138/312]		Loss: 0.8989
2019-10-28 17:17:41,343 Training Epoch [2/40] Iter[139/312]		Loss: 0.8990
2019-10-28 17:17:41,585 Training Epoch [2/40] Iter[140/312]		Loss: 0.9001
2019-10-28 17:17:41,826 Training Epoch [2/40] Iter[141/312]		Loss: 0.9001
2019-10-28 17:17:42,066 Training Epoch [2/40] Iter[142/312]		Loss: 0.9014
2019-10-28 17:17:42,310 Training Epoch [2/40] Iter[143/312]		Loss: 0.9005
2019-10-28 17:17:42,552 Training Epoch [2/40] Iter[144/312]		Loss: 0.9002
2019-10-28 17:17:42,797 Training Epoch [2/40] Iter[145/312]		Loss: 0.9002
2019-10-28 17:17:43,044 Training Epoch [2/40] Iter[146/312]		Loss: 0.9011
2019-10-28 17:17:43,285 Training Epoch [2/40] Iter[147/312]		Loss: 0.9020
2019-10-28 17:17:43,528 Training Epoch [2/40] Iter[148/312]		Loss: 0.9014
2019-10-28 17:17:43,770 Training Epoch [2/40] Iter[149/312]		Loss: 0.9005
2019-10-28 17:17:44,010 Training Epoch [2/40] Iter[150/312]		Loss: 0.9005
2019-10-28 17:17:44,249 Training Epoch [2/40] Iter[151/312]		Loss: 0.8986
2019-10-28 17:17:44,490 Training Epoch [2/40] Iter[152/312]		Loss: 0.8976
2019-10-28 17:17:44,732 Training Epoch [2/40] Iter[153/312]		Loss: 0.8963
2019-10-28 17:17:44,973 Training Epoch [2/40] Iter[154/312]		Loss: 0.8946
2019-10-28 17:17:45,216 Training Epoch [2/40] Iter[155/312]		Loss: 0.8946
2019-10-28 17:17:45,458 Training Epoch [2/40] Iter[156/312]		Loss: 0.8952
2019-10-28 17:17:45,707 Training Epoch [2/40] Iter[157/312]		Loss: 0.8949
2019-10-28 17:17:45,949 Training Epoch [2/40] Iter[158/312]		Loss: 0.8949
2019-10-28 17:17:46,188 Training Epoch [2/40] Iter[159/312]		Loss: 0.8949
2019-10-28 17:17:46,428 Training Epoch [2/40] Iter[160/312]		Loss: 0.8940
2019-10-28 17:17:46,668 Training Epoch [2/40] Iter[161/312]		Loss: 0.8937
2019-10-28 17:17:46,909 Training Epoch [2/40] Iter[162/312]		Loss: 0.8924
2019-10-28 17:17:47,151 Training Epoch [2/40] Iter[163/312]		Loss: 0.8951
2019-10-28 17:17:47,399 Training Epoch [2/40] Iter[164/312]		Loss: 0.8962
2019-10-28 17:17:47,641 Training Epoch [2/40] Iter[165/312]		Loss: 0.8978
2019-10-28 17:17:47,881 Training Epoch [2/40] Iter[166/312]		Loss: 0.8977
2019-10-28 17:17:48,122 Training Epoch [2/40] Iter[167/312]		Loss: 0.8979
2019-10-28 17:17:48,372 Training Epoch [2/40] Iter[168/312]		Loss: 0.8967
2019-10-28 17:17:48,616 Training Epoch [2/40] Iter[169/312]		Loss: 0.8968
2019-10-28 17:17:48,856 Training Epoch [2/40] Iter[170/312]		Loss: 0.8979
2019-10-28 17:17:49,094 Training Epoch [2/40] Iter[171/312]		Loss: 0.8989
2019-10-28 17:17:49,334 Training Epoch [2/40] Iter[172/312]		Loss: 0.8987
2019-10-28 17:17:49,575 Training Epoch [2/40] Iter[173/312]		Loss: 0.8983
2019-10-28 17:17:49,815 Training Epoch [2/40] Iter[174/312]		Loss: 0.8983
2019-10-28 17:17:50,055 Training Epoch [2/40] Iter[175/312]		Loss: 0.8970
2019-10-28 17:17:50,294 Training Epoch [2/40] Iter[176/312]		Loss: 0.8995
2019-10-28 17:17:50,535 Training Epoch [2/40] Iter[177/312]		Loss: 0.8999
2019-10-28 17:17:50,776 Training Epoch [2/40] Iter[178/312]		Loss: 0.8985
2019-10-28 17:17:51,019 Training Epoch [2/40] Iter[179/312]		Loss: 0.8976
2019-10-28 17:17:51,265 Training Epoch [2/40] Iter[180/312]		Loss: 0.8982
2019-10-28 17:17:51,505 Training Epoch [2/40] Iter[181/312]		Loss: 0.8980
2019-10-28 17:17:51,745 Training Epoch [2/40] Iter[182/312]		Loss: 0.8974
2019-10-28 17:17:51,986 Training Epoch [2/40] Iter[183/312]		Loss: 0.8976
2019-10-28 17:17:52,227 Training Epoch [2/40] Iter[184/312]		Loss: 0.8992
2019-10-28 17:17:52,467 Training Epoch [2/40] Iter[185/312]		Loss: 0.8984
2019-10-28 17:17:52,707 Training Epoch [2/40] Iter[186/312]		Loss: 0.8979
2019-10-28 17:17:52,949 Training Epoch [2/40] Iter[187/312]		Loss: 0.8984
2019-10-28 17:17:53,188 Training Epoch [2/40] Iter[188/312]		Loss: 0.8994
2019-10-28 17:17:53,429 Training Epoch [2/40] Iter[189/312]		Loss: 0.9000
2019-10-28 17:17:53,670 Training Epoch [2/40] Iter[190/312]		Loss: 0.8998
2019-10-28 17:17:53,920 Training Epoch [2/40] Iter[191/312]		Loss: 0.9004
2019-10-28 17:17:54,163 Training Epoch [2/40] Iter[192/312]		Loss: 0.8989
2019-10-28 17:17:54,403 Training Epoch [2/40] Iter[193/312]		Loss: 0.8994
2019-10-28 17:17:54,646 Training Epoch [2/40] Iter[194/312]		Loss: 0.8995
2019-10-28 17:17:54,886 Training Epoch [2/40] Iter[195/312]		Loss: 0.8992
2019-10-28 17:17:55,128 Training Epoch [2/40] Iter[196/312]		Loss: 0.8995
2019-10-28 17:17:55,375 Training Epoch [2/40] Iter[197/312]		Loss: 0.8999
2019-10-28 17:17:55,615 Training Epoch [2/40] Iter[198/312]		Loss: 0.8990
2019-10-28 17:17:55,853 Training Epoch [2/40] Iter[199/312]		Loss: 0.8986
2019-10-28 17:17:56,094 Training Epoch [2/40] Iter[200/312]		Loss: 0.8983
2019-10-28 17:17:56,332 Training Epoch [2/40] Iter[201/312]		Loss: 0.8968
2019-10-28 17:17:56,576 Training Epoch [2/40] Iter[202/312]		Loss: 0.8962
2019-10-28 17:17:56,823 Training Epoch [2/40] Iter[203/312]		Loss: 0.8961
2019-10-28 17:17:57,064 Training Epoch [2/40] Iter[204/312]		Loss: 0.8966
2019-10-28 17:17:57,304 Training Epoch [2/40] Iter[205/312]		Loss: 0.8959
2019-10-28 17:17:57,551 Training Epoch [2/40] Iter[206/312]		Loss: 0.8953
2019-10-28 17:17:57,797 Training Epoch [2/40] Iter[207/312]		Loss: 0.8948
2019-10-28 17:17:58,037 Training Epoch [2/40] Iter[208/312]		Loss: 0.8953
2019-10-28 17:17:58,281 Training Epoch [2/40] Iter[209/312]		Loss: 0.8948
2019-10-28 17:17:58,522 Training Epoch [2/40] Iter[210/312]		Loss: 0.8961
2019-10-28 17:17:58,759 Training Epoch [2/40] Iter[211/312]		Loss: 0.8959
2019-10-28 17:17:59,000 Training Epoch [2/40] Iter[212/312]		Loss: 0.8959
2019-10-28 17:17:59,239 Training Epoch [2/40] Iter[213/312]		Loss: 0.8954
2019-10-28 17:17:59,481 Training Epoch [2/40] Iter[214/312]		Loss: 0.8960
2019-10-28 17:17:59,721 Training Epoch [2/40] Iter[215/312]		Loss: 0.8964
2019-10-28 17:17:59,963 Training Epoch [2/40] Iter[216/312]		Loss: 0.8957
2019-10-28 17:18:00,205 Training Epoch [2/40] Iter[217/312]		Loss: 0.8964
2019-10-28 17:18:00,443 Training Epoch [2/40] Iter[218/312]		Loss: 0.8954
2019-10-28 17:18:00,685 Training Epoch [2/40] Iter[219/312]		Loss: 0.8949
2019-10-28 17:18:00,925 Training Epoch [2/40] Iter[220/312]		Loss: 0.8955
2019-10-28 17:18:01,161 Training Epoch [2/40] Iter[221/312]		Loss: 0.8962
2019-10-28 17:18:01,404 Training Epoch [2/40] Iter[222/312]		Loss: 0.8967
2019-10-28 17:18:01,643 Training Epoch [2/40] Iter[223/312]		Loss: 0.8964
2019-10-28 17:18:01,882 Training Epoch [2/40] Iter[224/312]		Loss: 0.8962
2019-10-28 17:18:02,121 Training Epoch [2/40] Iter[225/312]		Loss: 0.8954
2019-10-28 17:18:02,368 Training Epoch [2/40] Iter[226/312]		Loss: 0.8955
2019-10-28 17:18:02,612 Training Epoch [2/40] Iter[227/312]		Loss: 0.8950
2019-10-28 17:18:02,855 Training Epoch [2/40] Iter[228/312]		Loss: 0.8939
2019-10-28 17:18:03,100 Training Epoch [2/40] Iter[229/312]		Loss: 0.8940
2019-10-28 17:18:03,340 Training Epoch [2/40] Iter[230/312]		Loss: 0.8933
2019-10-28 17:18:03,579 Training Epoch [2/40] Iter[231/312]		Loss: 0.8928
2019-10-28 17:18:03,820 Training Epoch [2/40] Iter[232/312]		Loss: 0.8927
2019-10-28 17:18:04,059 Training Epoch [2/40] Iter[233/312]		Loss: 0.8923
2019-10-28 17:18:04,306 Training Epoch [2/40] Iter[234/312]		Loss: 0.8917
2019-10-28 17:18:04,557 Training Epoch [2/40] Iter[235/312]		Loss: 0.8922
2019-10-28 17:18:04,802 Training Epoch [2/40] Iter[236/312]		Loss: 0.8912
2019-10-28 17:18:05,042 Training Epoch [2/40] Iter[237/312]		Loss: 0.8919
2019-10-28 17:18:05,284 Training Epoch [2/40] Iter[238/312]		Loss: 0.8927
2019-10-28 17:18:05,527 Training Epoch [2/40] Iter[239/312]		Loss: 0.8933
2019-10-28 17:18:05,769 Training Epoch [2/40] Iter[240/312]		Loss: 0.8937
2019-10-28 17:18:06,010 Training Epoch [2/40] Iter[241/312]		Loss: 0.8933
2019-10-28 17:18:06,252 Training Epoch [2/40] Iter[242/312]		Loss: 0.8930
2019-10-28 17:18:06,494 Training Epoch [2/40] Iter[243/312]		Loss: 0.8919
2019-10-28 17:18:06,733 Training Epoch [2/40] Iter[244/312]		Loss: 0.8908
2019-10-28 17:18:06,975 Training Epoch [2/40] Iter[245/312]		Loss: 0.8907
2019-10-28 17:18:07,217 Training Epoch [2/40] Iter[246/312]		Loss: 0.8910
2019-10-28 17:18:07,458 Training Epoch [2/40] Iter[247/312]		Loss: 0.8906
2019-10-28 17:18:07,699 Training Epoch [2/40] Iter[248/312]		Loss: 0.8908
2019-10-28 17:18:07,941 Training Epoch [2/40] Iter[249/312]		Loss: 0.8903
2019-10-28 17:18:08,187 Training Epoch [2/40] Iter[250/312]		Loss: 0.8910
2019-10-28 17:18:08,438 Training Epoch [2/40] Iter[251/312]		Loss: 0.8905
2019-10-28 17:18:08,680 Training Epoch [2/40] Iter[252/312]		Loss: 0.8901
2019-10-28 17:18:08,919 Training Epoch [2/40] Iter[253/312]		Loss: 0.8907
2019-10-28 17:18:09,159 Training Epoch [2/40] Iter[254/312]		Loss: 0.8914
2019-10-28 17:18:09,405 Training Epoch [2/40] Iter[255/312]		Loss: 0.8910
2019-10-28 17:18:09,648 Training Epoch [2/40] Iter[256/312]		Loss: 0.8908
2019-10-28 17:18:09,890 Training Epoch [2/40] Iter[257/312]		Loss: 0.8915
2019-10-28 17:18:10,130 Training Epoch [2/40] Iter[258/312]		Loss: 0.8909
2019-10-28 17:18:10,370 Training Epoch [2/40] Iter[259/312]		Loss: 0.8901
2019-10-28 17:18:10,614 Training Epoch [2/40] Iter[260/312]		Loss: 0.8902
2019-10-28 17:18:10,857 Training Epoch [2/40] Iter[261/312]		Loss: 0.8896
2019-10-28 17:18:11,102 Training Epoch [2/40] Iter[262/312]		Loss: 0.8897
2019-10-28 17:18:11,342 Training Epoch [2/40] Iter[263/312]		Loss: 0.8896
2019-10-28 17:18:11,582 Training Epoch [2/40] Iter[264/312]		Loss: 0.8884
2019-10-28 17:18:11,822 Training Epoch [2/40] Iter[265/312]		Loss: 0.8876
2019-10-28 17:18:12,064 Training Epoch [2/40] Iter[266/312]		Loss: 0.8879
2019-10-28 17:18:12,304 Training Epoch [2/40] Iter[267/312]		Loss: 0.8873
2019-10-28 17:18:12,558 Training Epoch [2/40] Iter[268/312]		Loss: 0.8871
2019-10-28 17:18:12,806 Training Epoch [2/40] Iter[269/312]		Loss: 0.8876
2019-10-28 17:18:13,048 Training Epoch [2/40] Iter[270/312]		Loss: 0.8880
2019-10-28 17:18:13,290 Training Epoch [2/40] Iter[271/312]		Loss: 0.8878
2019-10-28 17:18:13,532 Training Epoch [2/40] Iter[272/312]		Loss: 0.8873
2019-10-28 17:18:13,774 Training Epoch [2/40] Iter[273/312]		Loss: 0.8872
2019-10-28 17:18:14,016 Training Epoch [2/40] Iter[274/312]		Loss: 0.8871
2019-10-28 17:18:14,258 Training Epoch [2/40] Iter[275/312]		Loss: 0.8870
2019-10-28 17:18:14,498 Training Epoch [2/40] Iter[276/312]		Loss: 0.8877
2019-10-28 17:18:14,739 Training Epoch [2/40] Iter[277/312]		Loss: 0.8873
2019-10-28 17:18:14,984 Training Epoch [2/40] Iter[278/312]		Loss: 0.8865
2019-10-28 17:18:15,233 Training Epoch [2/40] Iter[279/312]		Loss: 0.8868
2019-10-28 17:18:15,474 Training Epoch [2/40] Iter[280/312]		Loss: 0.8872
2019-10-28 17:18:15,715 Training Epoch [2/40] Iter[281/312]		Loss: 0.8867
2019-10-28 17:18:15,955 Training Epoch [2/40] Iter[282/312]		Loss: 0.8869
2019-10-28 17:18:16,193 Training Epoch [2/40] Iter[283/312]		Loss: 0.8877
2019-10-28 17:18:16,432 Training Epoch [2/40] Iter[284/312]		Loss: 0.8879
2019-10-28 17:18:16,675 Training Epoch [2/40] Iter[285/312]		Loss: 0.8884
2019-10-28 17:18:16,920 Training Epoch [2/40] Iter[286/312]		Loss: 0.8893
2019-10-28 17:18:17,163 Training Epoch [2/40] Iter[287/312]		Loss: 0.8890
2019-10-28 17:18:17,401 Training Epoch [2/40] Iter[288/312]		Loss: 0.8889
2019-10-28 17:18:17,642 Training Epoch [2/40] Iter[289/312]		Loss: 0.8893
2019-10-28 17:18:17,883 Training Epoch [2/40] Iter[290/312]		Loss: 0.8890
2019-10-28 17:18:18,123 Training Epoch [2/40] Iter[291/312]		Loss: 0.8888
2019-10-28 17:18:18,369 Training Epoch [2/40] Iter[292/312]		Loss: 0.8887
2019-10-28 17:18:18,618 Training Epoch [2/40] Iter[293/312]		Loss: 0.8883
2019-10-28 17:18:18,863 Training Epoch [2/40] Iter[294/312]		Loss: 0.8875
2019-10-28 17:18:19,105 Training Epoch [2/40] Iter[295/312]		Loss: 0.8867
2019-10-28 17:18:19,349 Training Epoch [2/40] Iter[296/312]		Loss: 0.8866
2019-10-28 17:18:19,590 Training Epoch [2/40] Iter[297/312]		Loss: 0.8866
2019-10-28 17:18:19,832 Training Epoch [2/40] Iter[298/312]		Loss: 0.8864
2019-10-28 17:18:20,077 Training Epoch [2/40] Iter[299/312]		Loss: 0.8861
2019-10-28 17:18:20,318 Training Epoch [2/40] Iter[300/312]		Loss: 0.8856
2019-10-28 17:18:20,563 Training Epoch [2/40] Iter[301/312]		Loss: 0.8847
2019-10-28 17:18:20,803 Training Epoch [2/40] Iter[302/312]		Loss: 0.8843
2019-10-28 17:18:21,043 Training Epoch [2/40] Iter[303/312]		Loss: 0.8840
2019-10-28 17:18:21,286 Training Epoch [2/40] Iter[304/312]		Loss: 0.8838
2019-10-28 17:18:21,526 Training Epoch [2/40] Iter[305/312]		Loss: 0.8833
2019-10-28 17:18:21,765 Training Epoch [2/40] Iter[306/312]		Loss: 0.8827
2019-10-28 17:18:22,006 Training Epoch [2/40] Iter[307/312]		Loss: 0.8828
2019-10-28 17:18:22,254 Training Epoch [2/40] Iter[308/312]		Loss: 0.8833
2019-10-28 17:18:22,499 Training Epoch [2/40] Iter[309/312]		Loss: 0.8831
2019-10-28 17:18:22,740 Training Epoch [2/40] Iter[310/312]		Loss: 0.8827
2019-10-28 17:18:22,982 Training Epoch [2/40] Iter[311/312]		Loss: 0.8829
2019-10-28 17:18:23,105 Training Epoch [2/40] Iter[312/312]		Loss: 0.8825
2019-10-28 17:18:23,296 Testing Epoch [2/40] Iter[0/62]		Loss: 1.0169
2019-10-28 17:18:23,369 Testing Epoch [2/40] Iter[1/62]		Loss: 1.0143
2019-10-28 17:18:23,445 Testing Epoch [2/40] Iter[2/62]		Loss: 1.1078
2019-10-28 17:18:23,520 Testing Epoch [2/40] Iter[3/62]		Loss: 1.1776
2019-10-28 17:18:23,597 Testing Epoch [2/40] Iter[4/62]		Loss: 1.1980
2019-10-28 17:18:23,670 Testing Epoch [2/40] Iter[5/62]		Loss: 1.2836
2019-10-28 17:18:23,746 Testing Epoch [2/40] Iter[6/62]		Loss: 1.2749
2019-10-28 17:18:23,820 Testing Epoch [2/40] Iter[7/62]		Loss: 1.2396
2019-10-28 17:18:23,897 Testing Epoch [2/40] Iter[8/62]		Loss: 1.2497
2019-10-28 17:18:23,971 Testing Epoch [2/40] Iter[9/62]		Loss: 1.2128
2019-10-28 17:18:24,046 Testing Epoch [2/40] Iter[10/62]		Loss: 1.2116
2019-10-28 17:18:24,124 Testing Epoch [2/40] Iter[11/62]		Loss: 1.2076
2019-10-28 17:18:24,199 Testing Epoch [2/40] Iter[12/62]		Loss: 1.2272
2019-10-28 17:18:24,273 Testing Epoch [2/40] Iter[13/62]		Loss: 1.2138
2019-10-28 17:18:24,350 Testing Epoch [2/40] Iter[14/62]		Loss: 1.2153
2019-10-28 17:18:24,425 Testing Epoch [2/40] Iter[15/62]		Loss: 1.2235
2019-10-28 17:18:24,500 Testing Epoch [2/40] Iter[16/62]		Loss: 1.2085
2019-10-28 17:18:24,578 Testing Epoch [2/40] Iter[17/62]		Loss: 1.2136
2019-10-28 17:18:24,655 Testing Epoch [2/40] Iter[18/62]		Loss: 1.2280
2019-10-28 17:18:24,732 Testing Epoch [2/40] Iter[19/62]		Loss: 1.2244
2019-10-28 17:18:24,808 Testing Epoch [2/40] Iter[20/62]		Loss: 1.2262
2019-10-28 17:18:24,884 Testing Epoch [2/40] Iter[21/62]		Loss: 1.2402
2019-10-28 17:18:24,960 Testing Epoch [2/40] Iter[22/62]		Loss: 1.2311
2019-10-28 17:18:25,034 Testing Epoch [2/40] Iter[23/62]		Loss: 1.2260
2019-10-28 17:18:25,110 Testing Epoch [2/40] Iter[24/62]		Loss: 1.2316
2019-10-28 17:18:25,184 Testing Epoch [2/40] Iter[25/62]		Loss: 1.2149
2019-10-28 17:18:25,260 Testing Epoch [2/40] Iter[26/62]		Loss: 1.2135
2019-10-28 17:18:25,334 Testing Epoch [2/40] Iter[27/62]		Loss: 1.2053
2019-10-28 17:18:25,410 Testing Epoch [2/40] Iter[28/62]		Loss: 1.2090
2019-10-28 17:18:25,484 Testing Epoch [2/40] Iter[29/62]		Loss: 1.2077
2019-10-28 17:18:25,561 Testing Epoch [2/40] Iter[30/62]		Loss: 1.1982
2019-10-28 17:18:25,636 Testing Epoch [2/40] Iter[31/62]		Loss: 1.1974
2019-10-28 17:18:25,711 Testing Epoch [2/40] Iter[32/62]		Loss: 1.1962
2019-10-28 17:18:25,785 Testing Epoch [2/40] Iter[33/62]		Loss: 1.1995
2019-10-28 17:18:25,862 Testing Epoch [2/40] Iter[34/62]		Loss: 1.2062
2019-10-28 17:18:25,937 Testing Epoch [2/40] Iter[35/62]		Loss: 1.2130
2019-10-28 17:18:26,013 Testing Epoch [2/40] Iter[36/62]		Loss: 1.2112
2019-10-28 17:18:26,087 Testing Epoch [2/40] Iter[37/62]		Loss: 1.2156
2019-10-28 17:18:26,167 Testing Epoch [2/40] Iter[38/62]		Loss: 1.2210
2019-10-28 17:18:26,242 Testing Epoch [2/40] Iter[39/62]		Loss: 1.2288
2019-10-28 17:18:26,317 Testing Epoch [2/40] Iter[40/62]		Loss: 1.2344
2019-10-28 17:18:26,391 Testing Epoch [2/40] Iter[41/62]		Loss: 1.2407
2019-10-28 17:18:26,466 Testing Epoch [2/40] Iter[42/62]		Loss: 1.2402
2019-10-28 17:18:26,544 Testing Epoch [2/40] Iter[43/62]		Loss: 1.2315
2019-10-28 17:18:26,619 Testing Epoch [2/40] Iter[44/62]		Loss: 1.2277
2019-10-28 17:18:26,695 Testing Epoch [2/40] Iter[45/62]		Loss: 1.2270
2019-10-28 17:18:26,770 Testing Epoch [2/40] Iter[46/62]		Loss: 1.2303
2019-10-28 17:18:26,848 Testing Epoch [2/40] Iter[47/62]		Loss: 1.2282
2019-10-28 17:18:26,926 Testing Epoch [2/40] Iter[48/62]		Loss: 1.2250
2019-10-28 17:18:27,003 Testing Epoch [2/40] Iter[49/62]		Loss: 1.2230
2019-10-28 17:18:27,082 Testing Epoch [2/40] Iter[50/62]		Loss: 1.2302
2019-10-28 17:18:27,157 Testing Epoch [2/40] Iter[51/62]		Loss: 1.2313
2019-10-28 17:18:27,233 Testing Epoch [2/40] Iter[52/62]		Loss: 1.2375
2019-10-28 17:18:27,307 Testing Epoch [2/40] Iter[53/62]		Loss: 1.2365
2019-10-28 17:18:27,382 Testing Epoch [2/40] Iter[54/62]		Loss: 1.2356
2019-10-28 17:18:27,457 Testing Epoch [2/40] Iter[55/62]		Loss: 1.2337
2019-10-28 17:18:27,533 Testing Epoch [2/40] Iter[56/62]		Loss: 1.2324
2019-10-28 17:18:27,609 Testing Epoch [2/40] Iter[57/62]		Loss: 1.2338
2019-10-28 17:18:27,685 Testing Epoch [2/40] Iter[58/62]		Loss: 1.2299
2019-10-28 17:18:27,759 Testing Epoch [2/40] Iter[59/62]		Loss: 1.2264
2019-10-28 17:18:27,836 Testing Epoch [2/40] Iter[60/62]		Loss: 1.2286
2019-10-28 17:18:27,910 Testing Epoch [2/40] Iter[61/62]		Loss: 1.2311
2019-10-28 17:18:27,948 Testing Epoch [2/40] Iter[62/62]		Loss: 1.2229
2019-10-28 17:18:28,301 Training Epoch [3/40] Iter[0/312]		Loss: 0.8430
2019-10-28 17:18:28,541 Training Epoch [3/40] Iter[1/312]		Loss: 0.8622
2019-10-28 17:18:28,781 Training Epoch [3/40] Iter[2/312]		Loss: 0.8630
2019-10-28 17:18:29,020 Training Epoch [3/40] Iter[3/312]		Loss: 0.8885
2019-10-28 17:18:29,264 Training Epoch [3/40] Iter[4/312]		Loss: 0.9000
2019-10-28 17:18:29,503 Training Epoch [3/40] Iter[5/312]		Loss: 0.8737
2019-10-28 17:18:29,744 Training Epoch [3/40] Iter[6/312]		Loss: 0.8495
2019-10-28 17:18:29,989 Training Epoch [3/40] Iter[7/312]		Loss: 0.8246
2019-10-28 17:18:30,230 Training Epoch [3/40] Iter[8/312]		Loss: 0.8237
2019-10-28 17:18:30,472 Training Epoch [3/40] Iter[9/312]		Loss: 0.8364
2019-10-28 17:18:30,716 Training Epoch [3/40] Iter[10/312]		Loss: 0.8236
2019-10-28 17:18:30,957 Training Epoch [3/40] Iter[11/312]		Loss: 0.8418
2019-10-28 17:18:31,199 Training Epoch [3/40] Iter[12/312]		Loss: 0.8478
2019-10-28 17:18:31,439 Training Epoch [3/40] Iter[13/312]		Loss: 0.8439
2019-10-28 17:18:31,686 Training Epoch [3/40] Iter[14/312]		Loss: 0.8476
2019-10-28 17:18:31,925 Training Epoch [3/40] Iter[15/312]		Loss: 0.8563
2019-10-28 17:18:32,165 Training Epoch [3/40] Iter[16/312]		Loss: 0.8522
2019-10-28 17:18:32,405 Training Epoch [3/40] Iter[17/312]		Loss: 0.8414
2019-10-28 17:18:32,655 Training Epoch [3/40] Iter[18/312]		Loss: 0.8332
2019-10-28 17:18:32,897 Training Epoch [3/40] Iter[19/312]		Loss: 0.8213
2019-10-28 17:18:33,137 Training Epoch [3/40] Iter[20/312]		Loss: 0.8236
2019-10-28 17:18:33,378 Training Epoch [3/40] Iter[21/312]		Loss: 0.8240
2019-10-28 17:18:33,618 Training Epoch [3/40] Iter[22/312]		Loss: 0.8365
2019-10-28 17:18:33,860 Training Epoch [3/40] Iter[23/312]		Loss: 0.8339
2019-10-28 17:18:34,103 Training Epoch [3/40] Iter[24/312]		Loss: 0.8354
2019-10-28 17:18:34,349 Training Epoch [3/40] Iter[25/312]		Loss: 0.8397
2019-10-28 17:18:34,589 Training Epoch [3/40] Iter[26/312]		Loss: 0.8321
2019-10-28 17:18:34,833 Training Epoch [3/40] Iter[27/312]		Loss: 0.8325
2019-10-28 17:18:35,074 Training Epoch [3/40] Iter[28/312]		Loss: 0.8394
2019-10-28 17:18:35,319 Training Epoch [3/40] Iter[29/312]		Loss: 0.8397
2019-10-28 17:18:35,559 Training Epoch [3/40] Iter[30/312]		Loss: 0.8352
2019-10-28 17:18:35,805 Training Epoch [3/40] Iter[31/312]		Loss: 0.8376
2019-10-28 17:18:36,052 Training Epoch [3/40] Iter[32/312]		Loss: 0.8336
2019-10-28 17:18:36,297 Training Epoch [3/40] Iter[33/312]		Loss: 0.8288
2019-10-28 17:18:36,544 Training Epoch [3/40] Iter[34/312]		Loss: 0.8286
2019-10-28 17:18:36,787 Training Epoch [3/40] Iter[35/312]		Loss: 0.8361
2019-10-28 17:18:37,028 Training Epoch [3/40] Iter[36/312]		Loss: 0.8458
2019-10-28 17:18:37,269 Training Epoch [3/40] Iter[37/312]		Loss: 0.8475
2019-10-28 17:18:37,510 Training Epoch [3/40] Iter[38/312]		Loss: 0.8492
2019-10-28 17:18:37,753 Training Epoch [3/40] Iter[39/312]		Loss: 0.8435
2019-10-28 17:18:37,993 Training Epoch [3/40] Iter[40/312]		Loss: 0.8399
2019-10-28 17:18:38,234 Training Epoch [3/40] Iter[41/312]		Loss: 0.8337
2019-10-28 17:18:38,475 Training Epoch [3/40] Iter[42/312]		Loss: 0.8319
2019-10-28 17:18:38,720 Training Epoch [3/40] Iter[43/312]		Loss: 0.8344
2019-10-28 17:18:38,966 Training Epoch [3/40] Iter[44/312]		Loss: 0.8315
2019-10-28 17:18:39,210 Training Epoch [3/40] Iter[45/312]		Loss: 0.8292
2019-10-28 17:18:39,452 Training Epoch [3/40] Iter[46/312]		Loss: 0.8255
2019-10-28 17:18:39,691 Training Epoch [3/40] Iter[47/312]		Loss: 0.8234
2019-10-28 17:18:39,933 Training Epoch [3/40] Iter[48/312]		Loss: 0.8255
2019-10-28 17:18:40,172 Training Epoch [3/40] Iter[49/312]		Loss: 0.8274
2019-10-28 17:18:40,412 Training Epoch [3/40] Iter[50/312]		Loss: 0.8265
2019-10-28 17:18:40,650 Training Epoch [3/40] Iter[51/312]		Loss: 0.8312
2019-10-28 17:18:40,890 Training Epoch [3/40] Iter[52/312]		Loss: 0.8311
2019-10-28 17:18:41,134 Training Epoch [3/40] Iter[53/312]		Loss: 0.8318
2019-10-28 17:18:41,377 Training Epoch [3/40] Iter[54/312]		Loss: 0.8270
2019-10-28 17:18:41,619 Training Epoch [3/40] Iter[55/312]		Loss: 0.8270
2019-10-28 17:18:41,859 Training Epoch [3/40] Iter[56/312]		Loss: 0.8270
2019-10-28 17:18:42,098 Training Epoch [3/40] Iter[57/312]		Loss: 0.8284
2019-10-28 17:18:42,339 Training Epoch [3/40] Iter[58/312]		Loss: 0.8273
2019-10-28 17:18:42,580 Training Epoch [3/40] Iter[59/312]		Loss: 0.8269
2019-10-28 17:18:42,820 Training Epoch [3/40] Iter[60/312]		Loss: 0.8262
2019-10-28 17:18:43,059 Training Epoch [3/40] Iter[61/312]		Loss: 0.8264
2019-10-28 17:18:43,300 Training Epoch [3/40] Iter[62/312]		Loss: 0.8236
2019-10-28 17:18:43,541 Training Epoch [3/40] Iter[63/312]		Loss: 0.8180
2019-10-28 17:18:43,788 Training Epoch [3/40] Iter[64/312]		Loss: 0.8159
2019-10-28 17:18:44,024 Training Epoch [3/40] Iter[65/312]		Loss: 0.8188
2019-10-28 17:18:44,270 Training Epoch [3/40] Iter[66/312]		Loss: 0.8174
2019-10-28 17:18:44,519 Training Epoch [3/40] Iter[67/312]		Loss: 0.8169
2019-10-28 17:18:44,768 Training Epoch [3/40] Iter[68/312]		Loss: 0.8184
2019-10-28 17:18:45,009 Training Epoch [3/40] Iter[69/312]		Loss: 0.8186
2019-10-28 17:18:45,249 Training Epoch [3/40] Iter[70/312]		Loss: 0.8203
2019-10-28 17:18:45,487 Training Epoch [3/40] Iter[71/312]		Loss: 0.8227
2019-10-28 17:18:45,730 Training Epoch [3/40] Iter[72/312]		Loss: 0.8233
2019-10-28 17:18:45,974 Training Epoch [3/40] Iter[73/312]		Loss: 0.8213
2019-10-28 17:18:46,218 Training Epoch [3/40] Iter[74/312]		Loss: 0.8198
2019-10-28 17:18:46,467 Training Epoch [3/40] Iter[75/312]		Loss: 0.8200
2019-10-28 17:18:46,705 Training Epoch [3/40] Iter[76/312]		Loss: 0.8174
2019-10-28 17:18:46,944 Training Epoch [3/40] Iter[77/312]		Loss: 0.8179
2019-10-28 17:18:47,184 Training Epoch [3/40] Iter[78/312]		Loss: 0.8190
2019-10-28 17:18:47,426 Training Epoch [3/40] Iter[79/312]		Loss: 0.8238
2019-10-28 17:18:47,666 Training Epoch [3/40] Iter[80/312]		Loss: 0.8250
2019-10-28 17:18:47,908 Training Epoch [3/40] Iter[81/312]		Loss: 0.8277
2019-10-28 17:18:48,146 Training Epoch [3/40] Iter[82/312]		Loss: 0.8261
2019-10-28 17:18:48,386 Training Epoch [3/40] Iter[83/312]		Loss: 0.8248
2019-10-28 17:18:48,626 Training Epoch [3/40] Iter[84/312]		Loss: 0.8249
2019-10-28 17:18:48,865 Training Epoch [3/40] Iter[85/312]		Loss: 0.8273
2019-10-28 17:18:49,110 Training Epoch [3/40] Iter[86/312]		Loss: 0.8281
2019-10-28 17:18:49,350 Training Epoch [3/40] Iter[87/312]		Loss: 0.8270
2019-10-28 17:18:49,591 Training Epoch [3/40] Iter[88/312]		Loss: 0.8282
2019-10-28 17:18:49,830 Training Epoch [3/40] Iter[89/312]		Loss: 0.8283
2019-10-28 17:18:50,071 Training Epoch [3/40] Iter[90/312]		Loss: 0.8298
2019-10-28 17:18:50,316 Training Epoch [3/40] Iter[91/312]		Loss: 0.8317
2019-10-28 17:18:50,562 Training Epoch [3/40] Iter[92/312]		Loss: 0.8337
2019-10-28 17:18:50,803 Training Epoch [3/40] Iter[93/312]		Loss: 0.8336
2019-10-28 17:18:51,042 Training Epoch [3/40] Iter[94/312]		Loss: 0.8331
2019-10-28 17:18:51,281 Training Epoch [3/40] Iter[95/312]		Loss: 0.8317
2019-10-28 17:18:51,519 Training Epoch [3/40] Iter[96/312]		Loss: 0.8341
2019-10-28 17:18:51,760 Training Epoch [3/40] Iter[97/312]		Loss: 0.8363
2019-10-28 17:18:51,997 Training Epoch [3/40] Iter[98/312]		Loss: 0.8343
2019-10-28 17:18:52,241 Training Epoch [3/40] Iter[99/312]		Loss: 0.8343
2019-10-28 17:18:52,486 Training Epoch [3/40] Iter[100/312]		Loss: 0.8348
2019-10-28 17:18:52,725 Training Epoch [3/40] Iter[101/312]		Loss: 0.8372
2019-10-28 17:18:52,966 Training Epoch [3/40] Iter[102/312]		Loss: 0.8370
2019-10-28 17:18:53,208 Training Epoch [3/40] Iter[103/312]		Loss: 0.8373
2019-10-28 17:18:53,447 Training Epoch [3/40] Iter[104/312]		Loss: 0.8386
2019-10-28 17:18:53,692 Training Epoch [3/40] Iter[105/312]		Loss: 0.8388
2019-10-28 17:18:53,936 Training Epoch [3/40] Iter[106/312]		Loss: 0.8394
2019-10-28 17:18:54,176 Training Epoch [3/40] Iter[107/312]		Loss: 0.8384
2019-10-28 17:18:54,418 Training Epoch [3/40] Iter[108/312]		Loss: 0.8374
2019-10-28 17:18:54,662 Training Epoch [3/40] Iter[109/312]		Loss: 0.8360
2019-10-28 17:18:54,906 Training Epoch [3/40] Iter[110/312]		Loss: 0.8366
2019-10-28 17:18:55,148 Training Epoch [3/40] Iter[111/312]		Loss: 0.8371
2019-10-28 17:18:55,389 Training Epoch [3/40] Iter[112/312]		Loss: 0.8384
2019-10-28 17:18:55,630 Training Epoch [3/40] Iter[113/312]		Loss: 0.8379
2019-10-28 17:18:55,870 Training Epoch [3/40] Iter[114/312]		Loss: 0.8358
2019-10-28 17:18:56,112 Training Epoch [3/40] Iter[115/312]		Loss: 0.8344
2019-10-28 17:18:56,362 Training Epoch [3/40] Iter[116/312]		Loss: 0.8352
2019-10-28 17:18:56,602 Training Epoch [3/40] Iter[117/312]		Loss: 0.8348
2019-10-28 17:18:56,854 Training Epoch [3/40] Iter[118/312]		Loss: 0.8332
2019-10-28 17:18:57,095 Training Epoch [3/40] Iter[119/312]		Loss: 0.8326
2019-10-28 17:18:57,335 Training Epoch [3/40] Iter[120/312]		Loss: 0.8328
2019-10-28 17:18:57,577 Training Epoch [3/40] Iter[121/312]		Loss: 0.8336
2019-10-28 17:18:57,820 Training Epoch [3/40] Iter[122/312]		Loss: 0.8341
2019-10-28 17:18:58,063 Training Epoch [3/40] Iter[123/312]		Loss: 0.8333
2019-10-28 17:18:58,305 Training Epoch [3/40] Iter[124/312]		Loss: 0.8316
2019-10-28 17:18:58,546 Training Epoch [3/40] Iter[125/312]		Loss: 0.8325
2019-10-28 17:18:58,787 Training Epoch [3/40] Iter[126/312]		Loss: 0.8319
2019-10-28 17:18:59,028 Training Epoch [3/40] Iter[127/312]		Loss: 0.8320
2019-10-28 17:18:59,269 Training Epoch [3/40] Iter[128/312]		Loss: 0.8295
2019-10-28 17:18:59,512 Training Epoch [3/40] Iter[129/312]		Loss: 0.8293
2019-10-28 17:18:59,753 Training Epoch [3/40] Iter[130/312]		Loss: 0.8309
2019-10-28 17:18:59,994 Training Epoch [3/40] Iter[131/312]		Loss: 0.8310
2019-10-28 17:19:00,234 Training Epoch [3/40] Iter[132/312]		Loss: 0.8295
2019-10-28 17:19:00,474 Training Epoch [3/40] Iter[133/312]		Loss: 0.8293
2019-10-28 17:19:00,718 Training Epoch [3/40] Iter[134/312]		Loss: 0.8310
2019-10-28 17:19:00,961 Training Epoch [3/40] Iter[135/312]		Loss: 0.8288
2019-10-28 17:19:01,201 Training Epoch [3/40] Iter[136/312]		Loss: 0.8281
2019-10-28 17:19:01,440 Training Epoch [3/40] Iter[137/312]		Loss: 0.8263
2019-10-28 17:19:01,682 Training Epoch [3/40] Iter[138/312]		Loss: 0.8268
2019-10-28 17:19:01,922 Training Epoch [3/40] Iter[139/312]		Loss: 0.8259
2019-10-28 17:19:02,161 Training Epoch [3/40] Iter[140/312]		Loss: 0.8265
2019-10-28 17:19:02,403 Training Epoch [3/40] Iter[141/312]		Loss: 0.8252
2019-10-28 17:19:02,643 Training Epoch [3/40] Iter[142/312]		Loss: 0.8256
2019-10-28 17:19:02,882 Training Epoch [3/40] Iter[143/312]		Loss: 0.8265
2019-10-28 17:19:03,121 Training Epoch [3/40] Iter[144/312]		Loss: 0.8262
2019-10-28 17:19:03,360 Training Epoch [3/40] Iter[145/312]		Loss: 0.8261
2019-10-28 17:19:03,600 Training Epoch [3/40] Iter[146/312]		Loss: 0.8257
2019-10-28 17:19:03,845 Training Epoch [3/40] Iter[147/312]		Loss: 0.8248
2019-10-28 17:19:04,087 Training Epoch [3/40] Iter[148/312]		Loss: 0.8251
2019-10-28 17:19:04,329 Training Epoch [3/40] Iter[149/312]		Loss: 0.8242
2019-10-28 17:19:04,571 Training Epoch [3/40] Iter[150/312]		Loss: 0.8240
2019-10-28 17:19:04,814 Training Epoch [3/40] Iter[151/312]		Loss: 0.8233
2019-10-28 17:19:05,056 Training Epoch [3/40] Iter[152/312]		Loss: 0.8241
2019-10-28 17:19:05,301 Training Epoch [3/40] Iter[153/312]		Loss: 0.8229
2019-10-28 17:19:05,545 Training Epoch [3/40] Iter[154/312]		Loss: 0.8216
2019-10-28 17:19:05,786 Training Epoch [3/40] Iter[155/312]		Loss: 0.8203
2019-10-28 17:19:06,025 Training Epoch [3/40] Iter[156/312]		Loss: 0.8196
2019-10-28 17:19:06,265 Training Epoch [3/40] Iter[157/312]		Loss: 0.8208
2019-10-28 17:19:06,507 Training Epoch [3/40] Iter[158/312]		Loss: 0.8199
2019-10-28 17:19:06,747 Training Epoch [3/40] Iter[159/312]		Loss: 0.8202
2019-10-28 17:19:06,986 Training Epoch [3/40] Iter[160/312]		Loss: 0.8202
2019-10-28 17:19:07,225 Training Epoch [3/40] Iter[161/312]		Loss: 0.8190
2019-10-28 17:19:07,463 Training Epoch [3/40] Iter[162/312]		Loss: 0.8194
2019-10-28 17:19:07,705 Training Epoch [3/40] Iter[163/312]		Loss: 0.8184
2019-10-28 17:19:07,945 Training Epoch [3/40] Iter[164/312]		Loss: 0.8188
2019-10-28 17:19:08,185 Training Epoch [3/40] Iter[165/312]		Loss: 0.8195
2019-10-28 17:19:08,424 Training Epoch [3/40] Iter[166/312]		Loss: 0.8180
2019-10-28 17:19:08,670 Training Epoch [3/40] Iter[167/312]		Loss: 0.8184
2019-10-28 17:19:08,917 Training Epoch [3/40] Iter[168/312]		Loss: 0.8180
2019-10-28 17:19:09,162 Training Epoch [3/40] Iter[169/312]		Loss: 0.8183
2019-10-28 17:19:09,402 Training Epoch [3/40] Iter[170/312]		Loss: 0.8189
2019-10-28 17:19:09,644 Training Epoch [3/40] Iter[171/312]		Loss: 0.8187
2019-10-28 17:19:09,885 Training Epoch [3/40] Iter[172/312]		Loss: 0.8178
2019-10-28 17:19:10,128 Training Epoch [3/40] Iter[173/312]		Loss: 0.8170
2019-10-28 17:19:10,368 Training Epoch [3/40] Iter[174/312]		Loss: 0.8178
2019-10-28 17:19:10,609 Training Epoch [3/40] Iter[175/312]		Loss: 0.8181
2019-10-28 17:19:10,853 Training Epoch [3/40] Iter[176/312]		Loss: 0.8182
2019-10-28 17:19:11,098 Training Epoch [3/40] Iter[177/312]		Loss: 0.8192
2019-10-28 17:19:11,346 Training Epoch [3/40] Iter[178/312]		Loss: 0.8185
2019-10-28 17:19:11,588 Training Epoch [3/40] Iter[179/312]		Loss: 0.8180
2019-10-28 17:19:11,829 Training Epoch [3/40] Iter[180/312]		Loss: 0.8180
2019-10-28 17:19:12,073 Training Epoch [3/40] Iter[181/312]		Loss: 0.8198
2019-10-28 17:19:12,314 Training Epoch [3/40] Iter[182/312]		Loss: 0.8205
2019-10-28 17:19:12,555 Training Epoch [3/40] Iter[183/312]		Loss: 0.8209
2019-10-28 17:19:12,800 Training Epoch [3/40] Iter[184/312]		Loss: 0.8216
2019-10-28 17:19:13,046 Training Epoch [3/40] Iter[185/312]		Loss: 0.8212
2019-10-28 17:19:13,284 Training Epoch [3/40] Iter[186/312]		Loss: 0.8208
2019-10-28 17:19:13,524 Training Epoch [3/40] Iter[187/312]		Loss: 0.8210
2019-10-28 17:19:13,763 Training Epoch [3/40] Iter[188/312]		Loss: 0.8192
2019-10-28 17:19:14,004 Training Epoch [3/40] Iter[189/312]		Loss: 0.8184
2019-10-28 17:19:14,248 Training Epoch [3/40] Iter[190/312]		Loss: 0.8186
2019-10-28 17:19:14,488 Training Epoch [3/40] Iter[191/312]		Loss: 0.8184
2019-10-28 17:19:14,729 Training Epoch [3/40] Iter[192/312]		Loss: 0.8194
2019-10-28 17:19:14,969 Training Epoch [3/40] Iter[193/312]		Loss: 0.8184
2019-10-28 17:19:15,211 Training Epoch [3/40] Iter[194/312]		Loss: 0.8184
2019-10-28 17:19:15,450 Training Epoch [3/40] Iter[195/312]		Loss: 0.8183
2019-10-28 17:19:15,696 Training Epoch [3/40] Iter[196/312]		Loss: 0.8167
2019-10-28 17:19:15,939 Training Epoch [3/40] Iter[197/312]		Loss: 0.8155
2019-10-28 17:19:16,182 Training Epoch [3/40] Iter[198/312]		Loss: 0.8157
2019-10-28 17:19:16,422 Training Epoch [3/40] Iter[199/312]		Loss: 0.8152
2019-10-28 17:19:16,664 Training Epoch [3/40] Iter[200/312]		Loss: 0.8155
2019-10-28 17:19:16,905 Training Epoch [3/40] Iter[201/312]		Loss: 0.8161
2019-10-28 17:19:17,147 Training Epoch [3/40] Iter[202/312]		Loss: 0.8151
2019-10-28 17:19:17,386 Training Epoch [3/40] Iter[203/312]		Loss: 0.8147
2019-10-28 17:19:17,628 Training Epoch [3/40] Iter[204/312]		Loss: 0.8138
2019-10-28 17:19:17,870 Training Epoch [3/40] Iter[205/312]		Loss: 0.8135
2019-10-28 17:19:18,113 Training Epoch [3/40] Iter[206/312]		Loss: 0.8130
2019-10-28 17:19:18,353 Training Epoch [3/40] Iter[207/312]		Loss: 0.8124
2019-10-28 17:19:18,596 Training Epoch [3/40] Iter[208/312]		Loss: 0.8127
2019-10-28 17:19:18,841 Training Epoch [3/40] Iter[209/312]		Loss: 0.8121
2019-10-28 17:19:19,082 Training Epoch [3/40] Iter[210/312]		Loss: 0.8108
2019-10-28 17:19:19,325 Training Epoch [3/40] Iter[211/312]		Loss: 0.8093
2019-10-28 17:19:19,568 Training Epoch [3/40] Iter[212/312]		Loss: 0.8090
2019-10-28 17:19:19,818 Training Epoch [3/40] Iter[213/312]		Loss: 0.8088
2019-10-28 17:19:20,065 Training Epoch [3/40] Iter[214/312]		Loss: 0.8095
2019-10-28 17:19:20,304 Training Epoch [3/40] Iter[215/312]		Loss: 0.8089
2019-10-28 17:19:20,546 Training Epoch [3/40] Iter[216/312]		Loss: 0.8094
2019-10-28 17:19:20,786 Training Epoch [3/40] Iter[217/312]		Loss: 0.8086
2019-10-28 17:19:21,033 Training Epoch [3/40] Iter[218/312]		Loss: 0.8092
2019-10-28 17:19:21,273 Training Epoch [3/40] Iter[219/312]		Loss: 0.8101
2019-10-28 17:19:21,512 Training Epoch [3/40] Iter[220/312]		Loss: 0.8098
2019-10-28 17:19:21,754 Training Epoch [3/40] Iter[221/312]		Loss: 0.8097
2019-10-28 17:19:21,997 Training Epoch [3/40] Iter[222/312]		Loss: 0.8087
2019-10-28 17:19:22,240 Training Epoch [3/40] Iter[223/312]		Loss: 0.8085
2019-10-28 17:19:22,483 Training Epoch [3/40] Iter[224/312]		Loss: 0.8080
2019-10-28 17:19:22,729 Training Epoch [3/40] Iter[225/312]		Loss: 0.8071
2019-10-28 17:19:22,969 Training Epoch [3/40] Iter[226/312]		Loss: 0.8083
2019-10-28 17:19:23,211 Training Epoch [3/40] Iter[227/312]		Loss: 0.8073
2019-10-28 17:19:23,450 Training Epoch [3/40] Iter[228/312]		Loss: 0.8067
2019-10-28 17:19:23,693 Training Epoch [3/40] Iter[229/312]		Loss: 0.8055
2019-10-28 17:19:23,932 Training Epoch [3/40] Iter[230/312]		Loss: 0.8052
2019-10-28 17:19:24,172 Training Epoch [3/40] Iter[231/312]		Loss: 0.8046
2019-10-28 17:19:24,411 Training Epoch [3/40] Iter[232/312]		Loss: 0.8045
2019-10-28 17:19:24,651 Training Epoch [3/40] Iter[233/312]		Loss: 0.8049
2019-10-28 17:19:24,893 Training Epoch [3/40] Iter[234/312]		Loss: 0.8046
2019-10-28 17:19:25,132 Training Epoch [3/40] Iter[235/312]		Loss: 0.8044
2019-10-28 17:19:25,372 Training Epoch [3/40] Iter[236/312]		Loss: 0.8033
