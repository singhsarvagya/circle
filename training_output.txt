2019-10-28 15:28:26,115 Training Epoch [1/40] Iter[0/312]		Loss: 4.6377
2019-10-28 15:28:26,199 Training Epoch [1/40] Iter[1/312]		Loss: 4.3734
2019-10-28 15:28:26,284 Training Epoch [1/40] Iter[2/312]		Loss: 4.2548
2019-10-28 15:28:26,362 Training Epoch [1/40] Iter[3/312]		Loss: 4.1410
2019-10-28 15:28:26,447 Training Epoch [1/40] Iter[4/312]		Loss: 3.8749
2019-10-28 15:28:26,525 Training Epoch [1/40] Iter[5/312]		Loss: 3.6242
2019-10-28 15:28:26,604 Training Epoch [1/40] Iter[6/312]		Loss: 3.5500
2019-10-28 15:28:26,682 Training Epoch [1/40] Iter[7/312]		Loss: 3.3688
2019-10-28 15:28:26,761 Training Epoch [1/40] Iter[8/312]		Loss: 3.2607
2019-10-28 15:28:26,840 Training Epoch [1/40] Iter[9/312]		Loss: 3.2140
2019-10-28 15:28:26,919 Training Epoch [1/40] Iter[10/312]		Loss: 3.1660
2019-10-28 15:28:26,998 Training Epoch [1/40] Iter[11/312]		Loss: 3.1201
2019-10-28 15:28:27,077 Training Epoch [1/40] Iter[12/312]		Loss: 3.0531
2019-10-28 15:28:27,156 Training Epoch [1/40] Iter[13/312]		Loss: 3.0016
2019-10-28 15:28:27,235 Training Epoch [1/40] Iter[14/312]		Loss: 2.9550
2019-10-28 15:28:27,314 Training Epoch [1/40] Iter[15/312]		Loss: 2.8914
2019-10-28 15:28:27,393 Training Epoch [1/40] Iter[16/312]		Loss: 2.8603
2019-10-28 15:28:27,472 Training Epoch [1/40] Iter[17/312]		Loss: 2.8399
2019-10-28 15:28:27,551 Training Epoch [1/40] Iter[18/312]		Loss: 2.8062
2019-10-28 15:28:27,630 Training Epoch [1/40] Iter[19/312]		Loss: 2.7807
2019-10-28 15:28:27,709 Training Epoch [1/40] Iter[20/312]		Loss: 2.7462
2019-10-28 15:28:27,788 Training Epoch [1/40] Iter[21/312]		Loss: 2.7349
2019-10-28 15:28:27,866 Training Epoch [1/40] Iter[22/312]		Loss: 2.7033
2019-10-28 15:28:27,945 Training Epoch [1/40] Iter[23/312]		Loss: 2.6874
2019-10-28 15:28:28,024 Training Epoch [1/40] Iter[24/312]		Loss: 2.6696
2019-10-28 15:28:28,103 Training Epoch [1/40] Iter[25/312]		Loss: 2.6664
2019-10-28 15:28:28,182 Training Epoch [1/40] Iter[26/312]		Loss: 2.6521
2019-10-28 15:28:28,261 Training Epoch [1/40] Iter[27/312]		Loss: 2.6307
2019-10-28 15:28:28,340 Training Epoch [1/40] Iter[28/312]		Loss: 2.6195
2019-10-28 15:28:28,420 Training Epoch [1/40] Iter[29/312]		Loss: 2.6083
2019-10-28 15:28:28,503 Training Epoch [1/40] Iter[30/312]		Loss: 2.6107
2019-10-28 15:28:28,587 Training Epoch [1/40] Iter[31/312]		Loss: 2.6125
2019-10-28 15:28:28,667 Training Epoch [1/40] Iter[32/312]		Loss: 2.6003
2019-10-28 15:28:28,745 Training Epoch [1/40] Iter[33/312]		Loss: 2.5911
2019-10-28 15:28:28,824 Training Epoch [1/40] Iter[34/312]		Loss: 2.5788
2019-10-28 15:28:28,903 Training Epoch [1/40] Iter[35/312]		Loss: 2.5758
2019-10-28 15:28:28,983 Training Epoch [1/40] Iter[36/312]		Loss: 2.5775
2019-10-28 15:28:29,062 Training Epoch [1/40] Iter[37/312]		Loss: 2.5813
2019-10-28 15:28:29,141 Training Epoch [1/40] Iter[38/312]		Loss: 2.5701
2019-10-28 15:28:29,220 Training Epoch [1/40] Iter[39/312]		Loss: 2.5702
2019-10-28 15:28:29,300 Training Epoch [1/40] Iter[40/312]		Loss: 2.5613
2019-10-28 15:28:29,379 Training Epoch [1/40] Iter[41/312]		Loss: 2.5543
2019-10-28 15:28:29,458 Training Epoch [1/40] Iter[42/312]		Loss: 2.5514
2019-10-28 15:28:29,537 Training Epoch [1/40] Iter[43/312]		Loss: 2.5498
2019-10-28 15:28:29,616 Training Epoch [1/40] Iter[44/312]		Loss: 2.5466
2019-10-28 15:28:29,695 Training Epoch [1/40] Iter[45/312]		Loss: 2.5440
2019-10-28 15:28:29,774 Training Epoch [1/40] Iter[46/312]		Loss: 2.5379
2019-10-28 15:28:29,852 Training Epoch [1/40] Iter[47/312]		Loss: 2.5349
2019-10-28 15:28:29,931 Training Epoch [1/40] Iter[48/312]		Loss: 2.5278
2019-10-28 15:28:30,010 Training Epoch [1/40] Iter[49/312]		Loss: 2.5259
2019-10-28 15:28:30,089 Training Epoch [1/40] Iter[50/312]		Loss: 2.5288
2019-10-28 15:28:30,168 Training Epoch [1/40] Iter[51/312]		Loss: 2.5167
2019-10-28 15:28:30,248 Training Epoch [1/40] Iter[52/312]		Loss: 2.5162
2019-10-28 15:28:30,327 Training Epoch [1/40] Iter[53/312]		Loss: 2.5108
2019-10-28 15:28:30,406 Training Epoch [1/40] Iter[54/312]		Loss: 2.5068
2019-10-28 15:28:30,485 Training Epoch [1/40] Iter[55/312]		Loss: 2.5010
2019-10-28 15:28:30,564 Training Epoch [1/40] Iter[56/312]		Loss: 2.4956
2019-10-28 15:28:30,643 Training Epoch [1/40] Iter[57/312]		Loss: 2.4973
2019-10-28 15:28:30,722 Training Epoch [1/40] Iter[58/312]		Loss: 2.4957
2019-10-28 15:28:30,802 Training Epoch [1/40] Iter[59/312]		Loss: 2.4895
2019-10-28 15:28:30,881 Training Epoch [1/40] Iter[60/312]		Loss: 2.4856
2019-10-28 15:28:30,960 Training Epoch [1/40] Iter[61/312]		Loss: 2.4820
2019-10-28 15:28:31,039 Training Epoch [1/40] Iter[62/312]		Loss: 2.4832
2019-10-28 15:28:31,118 Training Epoch [1/40] Iter[63/312]		Loss: 2.4822
2019-10-28 15:28:31,198 Training Epoch [1/40] Iter[64/312]		Loss: 2.4799
2019-10-28 15:28:31,277 Training Epoch [1/40] Iter[65/312]		Loss: 2.4741
2019-10-28 15:28:31,356 Training Epoch [1/40] Iter[66/312]		Loss: 2.4735
2019-10-28 15:28:31,436 Training Epoch [1/40] Iter[67/312]		Loss: 2.4746
2019-10-28 15:28:31,515 Training Epoch [1/40] Iter[68/312]		Loss: 2.4750
2019-10-28 15:28:31,593 Training Epoch [1/40] Iter[69/312]		Loss: 2.4730
2019-10-28 15:28:31,672 Training Epoch [1/40] Iter[70/312]		Loss: 2.4764
2019-10-28 15:28:31,751 Training Epoch [1/40] Iter[71/312]		Loss: 2.4758
2019-10-28 15:28:31,830 Training Epoch [1/40] Iter[72/312]		Loss: 2.4716
2019-10-28 15:28:31,910 Training Epoch [1/40] Iter[73/312]		Loss: 2.4672
2019-10-28 15:28:31,989 Training Epoch [1/40] Iter[74/312]		Loss: 2.4619
2019-10-28 15:28:32,067 Training Epoch [1/40] Iter[75/312]		Loss: 2.4595
2019-10-28 15:28:32,147 Training Epoch [1/40] Iter[76/312]		Loss: 2.4576
2019-10-28 15:28:32,227 Training Epoch [1/40] Iter[77/312]		Loss: 2.4548
2019-10-28 15:28:32,306 Training Epoch [1/40] Iter[78/312]		Loss: 2.4514
2019-10-28 15:28:32,386 Training Epoch [1/40] Iter[79/312]		Loss: 2.4496
2019-10-28 15:28:32,465 Training Epoch [1/40] Iter[80/312]		Loss: 2.4515
2019-10-28 15:28:32,544 Training Epoch [1/40] Iter[81/312]		Loss: 2.4450
2019-10-28 15:28:32,623 Training Epoch [1/40] Iter[82/312]		Loss: 2.4411
2019-10-28 15:28:32,703 Training Epoch [1/40] Iter[83/312]		Loss: 2.4307
2019-10-28 15:28:32,782 Training Epoch [1/40] Iter[84/312]		Loss: 2.4315
2019-10-28 15:28:32,861 Training Epoch [1/40] Iter[85/312]		Loss: 2.4286
2019-10-28 15:28:32,941 Training Epoch [1/40] Iter[86/312]		Loss: 2.4247
2019-10-28 15:28:33,020 Training Epoch [1/40] Iter[87/312]		Loss: 2.4207
2019-10-28 15:28:33,099 Training Epoch [1/40] Iter[88/312]		Loss: 2.4177
2019-10-28 15:28:33,179 Training Epoch [1/40] Iter[89/312]		Loss: 2.4095
2019-10-28 15:28:33,258 Training Epoch [1/40] Iter[90/312]		Loss: 2.4062
2019-10-28 15:28:33,338 Training Epoch [1/40] Iter[91/312]		Loss: 2.4052
2019-10-28 15:28:33,417 Training Epoch [1/40] Iter[92/312]		Loss: 2.4041
2019-10-28 15:28:33,497 Training Epoch [1/40] Iter[93/312]		Loss: 2.4041
2019-10-28 15:28:33,577 Training Epoch [1/40] Iter[94/312]		Loss: 2.3963
2019-10-28 15:28:33,656 Training Epoch [1/40] Iter[95/312]		Loss: 2.3982
2019-10-28 15:28:33,735 Training Epoch [1/40] Iter[96/312]		Loss: 2.3943
2019-10-28 15:28:33,814 Training Epoch [1/40] Iter[97/312]		Loss: 2.3881
2019-10-28 15:28:33,893 Training Epoch [1/40] Iter[98/312]		Loss: 2.3804
2019-10-28 15:28:33,973 Training Epoch [1/40] Iter[99/312]		Loss: 2.3796
2019-10-28 15:28:34,052 Training Epoch [1/40] Iter[100/312]		Loss: 2.3743
2019-10-28 15:28:34,131 Training Epoch [1/40] Iter[101/312]		Loss: 2.3662
2019-10-28 15:28:34,211 Training Epoch [1/40] Iter[102/312]		Loss: 2.3586
2019-10-28 15:28:34,291 Training Epoch [1/40] Iter[103/312]		Loss: 2.3500
2019-10-28 15:28:34,370 Training Epoch [1/40] Iter[104/312]		Loss: 2.3446
2019-10-28 15:28:34,449 Training Epoch [1/40] Iter[105/312]		Loss: 2.3331
2019-10-28 15:28:34,529 Training Epoch [1/40] Iter[106/312]		Loss: 2.3254
2019-10-28 15:28:34,608 Training Epoch [1/40] Iter[107/312]		Loss: 2.3155
2019-10-28 15:28:34,687 Training Epoch [1/40] Iter[108/312]		Loss: 2.3066
2019-10-28 15:28:34,767 Training Epoch [1/40] Iter[109/312]		Loss: 2.2985
2019-10-28 15:28:34,846 Training Epoch [1/40] Iter[110/312]		Loss: 2.2911
2019-10-28 15:28:34,925 Training Epoch [1/40] Iter[111/312]		Loss: 2.2813
2019-10-28 15:28:35,004 Training Epoch [1/40] Iter[112/312]		Loss: 2.2712
2019-10-28 15:28:35,083 Training Epoch [1/40] Iter[113/312]		Loss: 2.2601
2019-10-28 15:28:35,162 Training Epoch [1/40] Iter[114/312]		Loss: 2.2509
2019-10-28 15:28:35,242 Training Epoch [1/40] Iter[115/312]		Loss: 2.2413
2019-10-28 15:28:35,321 Training Epoch [1/40] Iter[116/312]		Loss: 2.2318
2019-10-28 15:28:35,401 Training Epoch [1/40] Iter[117/312]		Loss: 2.2228
2019-10-28 15:28:35,480 Training Epoch [1/40] Iter[118/312]		Loss: 2.2121
2019-10-28 15:28:35,560 Training Epoch [1/40] Iter[119/312]		Loss: 2.2037
2019-10-28 15:28:35,639 Training Epoch [1/40] Iter[120/312]		Loss: 2.1954
2019-10-28 15:28:35,719 Training Epoch [1/40] Iter[121/312]		Loss: 2.1897
2019-10-28 15:28:35,799 Training Epoch [1/40] Iter[122/312]		Loss: 2.1803
2019-10-28 15:28:35,878 Training Epoch [1/40] Iter[123/312]		Loss: 2.1718
2019-10-28 15:28:35,957 Training Epoch [1/40] Iter[124/312]		Loss: 2.1639
2019-10-28 15:28:36,037 Training Epoch [1/40] Iter[125/312]		Loss: 2.1552
2019-10-28 15:28:36,116 Training Epoch [1/40] Iter[126/312]		Loss: 2.1457
2019-10-28 15:28:36,196 Training Epoch [1/40] Iter[127/312]		Loss: 2.1394
2019-10-28 15:28:36,275 Training Epoch [1/40] Iter[128/312]		Loss: 2.1317
2019-10-28 15:28:36,354 Training Epoch [1/40] Iter[129/312]		Loss: 2.1290
2019-10-28 15:28:36,434 Training Epoch [1/40] Iter[130/312]		Loss: 2.1232
2019-10-28 15:28:36,513 Training Epoch [1/40] Iter[131/312]		Loss: 2.1146
2019-10-28 15:28:36,593 Training Epoch [1/40] Iter[132/312]		Loss: 2.1059
2019-10-28 15:28:36,672 Training Epoch [1/40] Iter[133/312]		Loss: 2.0977
2019-10-28 15:28:36,751 Training Epoch [1/40] Iter[134/312]		Loss: 2.0921
2019-10-28 15:28:36,830 Training Epoch [1/40] Iter[135/312]		Loss: 2.0846
2019-10-28 15:28:36,909 Training Epoch [1/40] Iter[136/312]		Loss: 2.0774
2019-10-28 15:28:36,989 Training Epoch [1/40] Iter[137/312]		Loss: 2.0722
2019-10-28 15:28:37,068 Training Epoch [1/40] Iter[138/312]		Loss: 2.0660
2019-10-28 15:28:37,148 Training Epoch [1/40] Iter[139/312]		Loss: 2.0605
2019-10-28 15:28:37,227 Training Epoch [1/40] Iter[140/312]		Loss: 2.0533
2019-10-28 15:28:37,312 Training Epoch [1/40] Iter[141/312]		Loss: 2.0481
2019-10-28 15:28:37,392 Training Epoch [1/40] Iter[142/312]		Loss: 2.0411
2019-10-28 15:28:37,471 Training Epoch [1/40] Iter[143/312]		Loss: 2.0350
2019-10-28 15:28:37,550 Training Epoch [1/40] Iter[144/312]		Loss: 2.0292
2019-10-28 15:28:37,629 Training Epoch [1/40] Iter[145/312]		Loss: 2.0249
2019-10-28 15:28:37,709 Training Epoch [1/40] Iter[146/312]		Loss: 2.0195
2019-10-28 15:28:37,788 Training Epoch [1/40] Iter[147/312]		Loss: 2.0139
2019-10-28 15:28:37,867 Training Epoch [1/40] Iter[148/312]		Loss: 2.0085
2019-10-28 15:28:37,946 Training Epoch [1/40] Iter[149/312]		Loss: 2.0008
2019-10-28 15:28:38,025 Training Epoch [1/40] Iter[150/312]		Loss: 1.9932
2019-10-28 15:28:38,105 Training Epoch [1/40] Iter[151/312]		Loss: 1.9871
2019-10-28 15:28:38,184 Training Epoch [1/40] Iter[152/312]		Loss: 1.9812
2019-10-28 15:28:38,263 Training Epoch [1/40] Iter[153/312]		Loss: 1.9762
2019-10-28 15:28:38,343 Training Epoch [1/40] Iter[154/312]		Loss: 1.9704
2019-10-28 15:28:38,422 Training Epoch [1/40] Iter[155/312]		Loss: 1.9647
2019-10-28 15:28:38,502 Training Epoch [1/40] Iter[156/312]		Loss: 1.9595
2019-10-28 15:28:38,582 Training Epoch [1/40] Iter[157/312]		Loss: 1.9548
2019-10-28 15:28:38,661 Training Epoch [1/40] Iter[158/312]		Loss: 1.9497
2019-10-28 15:28:38,740 Training Epoch [1/40] Iter[159/312]		Loss: 1.9472
2019-10-28 15:28:38,820 Training Epoch [1/40] Iter[160/312]		Loss: 1.9414
2019-10-28 15:28:38,899 Training Epoch [1/40] Iter[161/312]		Loss: 1.9348
2019-10-28 15:28:38,979 Training Epoch [1/40] Iter[162/312]		Loss: 1.9297
2019-10-28 15:28:39,058 Training Epoch [1/40] Iter[163/312]		Loss: 1.9257
2019-10-28 15:28:39,137 Training Epoch [1/40] Iter[164/312]		Loss: 1.9216
2019-10-28 15:28:39,217 Training Epoch [1/40] Iter[165/312]		Loss: 1.9161
2019-10-28 15:28:39,296 Training Epoch [1/40] Iter[166/312]		Loss: 1.9109
2019-10-28 15:28:39,376 Training Epoch [1/40] Iter[167/312]		Loss: 1.9051
2019-10-28 15:28:39,456 Training Epoch [1/40] Iter[168/312]		Loss: 1.8992
2019-10-28 15:28:39,535 Training Epoch [1/40] Iter[169/312]		Loss: 1.8938
2019-10-28 15:28:39,615 Training Epoch [1/40] Iter[170/312]		Loss: 1.8883
2019-10-28 15:28:39,694 Training Epoch [1/40] Iter[171/312]		Loss: 1.8829
2019-10-28 15:28:39,773 Training Epoch [1/40] Iter[172/312]		Loss: 1.8790
2019-10-28 15:28:39,853 Training Epoch [1/40] Iter[173/312]		Loss: 1.8744
2019-10-28 15:28:39,932 Training Epoch [1/40] Iter[174/312]		Loss: 1.8700
2019-10-28 15:28:40,011 Training Epoch [1/40] Iter[175/312]		Loss: 1.8646
2019-10-28 15:28:40,090 Training Epoch [1/40] Iter[176/312]		Loss: 1.8626
2019-10-28 15:28:40,169 Training Epoch [1/40] Iter[177/312]		Loss: 1.8597
2019-10-28 15:28:40,249 Training Epoch [1/40] Iter[178/312]		Loss: 1.8551
2019-10-28 15:28:40,328 Training Epoch [1/40] Iter[179/312]		Loss: 1.8514
2019-10-28 15:28:40,407 Training Epoch [1/40] Iter[180/312]		Loss: 1.8457
2019-10-28 15:28:40,492 Training Epoch [1/40] Iter[181/312]		Loss: 1.8407
2019-10-28 15:28:40,571 Training Epoch [1/40] Iter[182/312]		Loss: 1.8353
2019-10-28 15:28:40,651 Training Epoch [1/40] Iter[183/312]		Loss: 1.8306
2019-10-28 15:28:40,730 Training Epoch [1/40] Iter[184/312]		Loss: 1.8252
2019-10-28 15:28:40,815 Training Epoch [1/40] Iter[185/312]		Loss: 1.8217
2019-10-28 15:28:40,894 Training Epoch [1/40] Iter[186/312]		Loss: 1.8175
2019-10-28 15:28:40,973 Training Epoch [1/40] Iter[187/312]		Loss: 1.8137
2019-10-28 15:28:41,053 Training Epoch [1/40] Iter[188/312]		Loss: 1.8095
2019-10-28 15:28:41,138 Training Epoch [1/40] Iter[189/312]		Loss: 1.8055
2019-10-28 15:28:41,218 Training Epoch [1/40] Iter[190/312]		Loss: 1.8019
2019-10-28 15:28:41,297 Training Epoch [1/40] Iter[191/312]		Loss: 1.8016
2019-10-28 15:28:41,376 Training Epoch [1/40] Iter[192/312]		Loss: 1.7976
2019-10-28 15:28:41,456 Training Epoch [1/40] Iter[193/312]		Loss: 1.7939
2019-10-28 15:28:41,535 Training Epoch [1/40] Iter[194/312]		Loss: 1.7896
2019-10-28 15:28:41,615 Training Epoch [1/40] Iter[195/312]		Loss: 1.7844
2019-10-28 15:28:41,694 Training Epoch [1/40] Iter[196/312]		Loss: 1.7802
2019-10-28 15:28:41,774 Training Epoch [1/40] Iter[197/312]		Loss: 1.7772
2019-10-28 15:28:41,853 Training Epoch [1/40] Iter[198/312]		Loss: 1.7746
2019-10-28 15:28:41,932 Training Epoch [1/40] Iter[199/312]		Loss: 1.7702
2019-10-28 15:28:42,011 Training Epoch [1/40] Iter[200/312]		Loss: 1.7666
2019-10-28 15:28:42,091 Training Epoch [1/40] Iter[201/312]		Loss: 1.7625
2019-10-28 15:28:42,170 Training Epoch [1/40] Iter[202/312]		Loss: 1.7593
2019-10-28 15:28:42,249 Training Epoch [1/40] Iter[203/312]		Loss: 1.7563
2019-10-28 15:28:42,328 Training Epoch [1/40] Iter[204/312]		Loss: 1.7525
2019-10-28 15:28:42,407 Training Epoch [1/40] Iter[205/312]		Loss: 1.7496
2019-10-28 15:28:42,486 Training Epoch [1/40] Iter[206/312]		Loss: 1.7463
2019-10-28 15:28:42,565 Training Epoch [1/40] Iter[207/312]		Loss: 1.7435
2019-10-28 15:28:42,644 Training Epoch [1/40] Iter[208/312]		Loss: 1.7405
2019-10-28 15:28:42,722 Training Epoch [1/40] Iter[209/312]		Loss: 1.7381
2019-10-28 15:28:42,802 Training Epoch [1/40] Iter[210/312]		Loss: 1.7340
2019-10-28 15:28:42,880 Training Epoch [1/40] Iter[211/312]		Loss: 1.7318
2019-10-28 15:28:42,959 Training Epoch [1/40] Iter[212/312]		Loss: 1.7281
2019-10-28 15:28:43,039 Training Epoch [1/40] Iter[213/312]		Loss: 1.7250
2019-10-28 15:28:43,117 Training Epoch [1/40] Iter[214/312]		Loss: 1.7211
2019-10-28 15:28:43,196 Training Epoch [1/40] Iter[215/312]		Loss: 1.7171
2019-10-28 15:28:43,275 Training Epoch [1/40] Iter[216/312]		Loss: 1.7142
2019-10-28 15:28:43,354 Training Epoch [1/40] Iter[217/312]		Loss: 1.7124
2019-10-28 15:28:43,433 Training Epoch [1/40] Iter[218/312]		Loss: 1.7091
2019-10-28 15:28:43,512 Training Epoch [1/40] Iter[219/312]		Loss: 1.7050
2019-10-28 15:28:43,592 Training Epoch [1/40] Iter[220/312]		Loss: 1.7008
2019-10-28 15:28:43,672 Training Epoch [1/40] Iter[221/312]		Loss: 1.6980
2019-10-28 15:28:43,751 Training Epoch [1/40] Iter[222/312]		Loss: 1.6960
2019-10-28 15:28:43,830 Training Epoch [1/40] Iter[223/312]		Loss: 1.6933
2019-10-28 15:28:43,911 Training Epoch [1/40] Iter[224/312]		Loss: 1.6912
2019-10-28 15:28:43,990 Training Epoch [1/40] Iter[225/312]		Loss: 1.6878
2019-10-28 15:28:44,069 Training Epoch [1/40] Iter[226/312]		Loss: 1.6848
2019-10-28 15:28:44,149 Training Epoch [1/40] Iter[227/312]		Loss: 1.6814
2019-10-28 15:28:44,228 Training Epoch [1/40] Iter[228/312]		Loss: 1.6790
2019-10-28 15:28:44,308 Training Epoch [1/40] Iter[229/312]		Loss: 1.6757
2019-10-28 15:28:44,387 Training Epoch [1/40] Iter[230/312]		Loss: 1.6739
2019-10-28 15:28:44,467 Training Epoch [1/40] Iter[231/312]		Loss: 1.6708
2019-10-28 15:28:44,547 Training Epoch [1/40] Iter[232/312]		Loss: 1.6675
2019-10-28 15:28:44,626 Training Epoch [1/40] Iter[233/312]		Loss: 1.6639
2019-10-28 15:28:44,715 Training Epoch [1/40] Iter[234/312]		Loss: 1.6617
2019-10-28 15:28:44,794 Training Epoch [1/40] Iter[235/312]		Loss: 1.6586
2019-10-28 15:28:44,873 Training Epoch [1/40] Iter[236/312]		Loss: 1.6561
2019-10-28 15:28:44,953 Training Epoch [1/40] Iter[237/312]		Loss: 1.6542
2019-10-28 15:28:45,032 Training Epoch [1/40] Iter[238/312]		Loss: 1.6505
2019-10-28 15:28:45,111 Training Epoch [1/40] Iter[239/312]		Loss: 1.6478
2019-10-28 15:28:45,190 Training Epoch [1/40] Iter[240/312]		Loss: 1.6443
2019-10-28 15:28:45,269 Training Epoch [1/40] Iter[241/312]		Loss: 1.6417
2019-10-28 15:28:45,348 Training Epoch [1/40] Iter[242/312]		Loss: 1.6382
2019-10-28 15:28:45,427 Training Epoch [1/40] Iter[243/312]		Loss: 1.6350
2019-10-28 15:28:45,506 Training Epoch [1/40] Iter[244/312]		Loss: 1.6322
2019-10-28 15:28:45,585 Training Epoch [1/40] Iter[245/312]		Loss: 1.6295
2019-10-28 15:28:45,664 Training Epoch [1/40] Iter[246/312]		Loss: 1.6270
2019-10-28 15:28:45,743 Training Epoch [1/40] Iter[247/312]		Loss: 1.6244
2019-10-28 15:28:45,822 Training Epoch [1/40] Iter[248/312]		Loss: 1.6230
2019-10-28 15:28:45,901 Training Epoch [1/40] Iter[249/312]		Loss: 1.6205
2019-10-28 15:28:45,980 Training Epoch [1/40] Iter[250/312]		Loss: 1.6180
2019-10-28 15:28:46,059 Training Epoch [1/40] Iter[251/312]		Loss: 1.6147
2019-10-28 15:28:46,138 Training Epoch [1/40] Iter[252/312]		Loss: 1.6117
2019-10-28 15:28:46,217 Training Epoch [1/40] Iter[253/312]		Loss: 1.6090
2019-10-28 15:28:46,296 Training Epoch [1/40] Iter[254/312]		Loss: 1.6074
2019-10-28 15:28:46,375 Training Epoch [1/40] Iter[255/312]		Loss: 1.6045
2019-10-28 15:28:46,455 Training Epoch [1/40] Iter[256/312]		Loss: 1.6016
2019-10-28 15:28:46,534 Training Epoch [1/40] Iter[257/312]		Loss: 1.5990
2019-10-28 15:28:46,612 Training Epoch [1/40] Iter[258/312]		Loss: 1.5959
2019-10-28 15:28:46,691 Training Epoch [1/40] Iter[259/312]		Loss: 1.5936
2019-10-28 15:28:46,770 Training Epoch [1/40] Iter[260/312]		Loss: 1.5903
2019-10-28 15:28:46,848 Training Epoch [1/40] Iter[261/312]		Loss: 1.5874
2019-10-28 15:28:46,927 Training Epoch [1/40] Iter[262/312]		Loss: 1.5853
2019-10-28 15:28:47,006 Training Epoch [1/40] Iter[263/312]		Loss: 1.5825
2019-10-28 15:28:47,085 Training Epoch [1/40] Iter[264/312]		Loss: 1.5797
2019-10-28 15:28:47,164 Training Epoch [1/40] Iter[265/312]		Loss: 1.5774
2019-10-28 15:28:47,242 Training Epoch [1/40] Iter[266/312]		Loss: 1.5750
2019-10-28 15:28:47,321 Training Epoch [1/40] Iter[267/312]		Loss: 1.5718
2019-10-28 15:28:47,400 Training Epoch [1/40] Iter[268/312]		Loss: 1.5692
2019-10-28 15:28:47,479 Training Epoch [1/40] Iter[269/312]		Loss: 1.5671
2019-10-28 15:28:47,558 Training Epoch [1/40] Iter[270/312]		Loss: 1.5651
2019-10-28 15:28:47,637 Training Epoch [1/40] Iter[271/312]		Loss: 1.5624
2019-10-28 15:28:47,716 Training Epoch [1/40] Iter[272/312]		Loss: 1.5606
2019-10-28 15:28:47,795 Training Epoch [1/40] Iter[273/312]		Loss: 1.5581
2019-10-28 15:28:47,873 Training Epoch [1/40] Iter[274/312]		Loss: 1.5561
2019-10-28 15:28:47,952 Training Epoch [1/40] Iter[275/312]		Loss: 1.5540
2019-10-28 15:28:48,031 Training Epoch [1/40] Iter[276/312]		Loss: 1.5505
2019-10-28 15:28:48,110 Training Epoch [1/40] Iter[277/312]		Loss: 1.5487
2019-10-28 15:28:48,189 Training Epoch [1/40] Iter[278/312]		Loss: 1.5461
2019-10-28 15:28:48,268 Training Epoch [1/40] Iter[279/312]		Loss: 1.5445
2019-10-28 15:28:48,346 Training Epoch [1/40] Iter[280/312]		Loss: 1.5421
2019-10-28 15:28:48,426 Training Epoch [1/40] Iter[281/312]		Loss: 1.5392
2019-10-28 15:28:48,505 Training Epoch [1/40] Iter[282/312]		Loss: 1.5361
2019-10-28 15:28:48,584 Training Epoch [1/40] Iter[283/312]		Loss: 1.5348
2019-10-28 15:28:48,667 Training Epoch [1/40] Iter[284/312]		Loss: 1.5320
2019-10-28 15:28:48,746 Training Epoch [1/40] Iter[285/312]		Loss: 1.5294
2019-10-28 15:28:48,824 Training Epoch [1/40] Iter[286/312]		Loss: 1.5285
2019-10-28 15:28:48,903 Training Epoch [1/40] Iter[287/312]		Loss: 1.5267
2019-10-28 15:28:48,982 Training Epoch [1/40] Iter[288/312]		Loss: 1.5240
2019-10-28 15:28:49,061 Training Epoch [1/40] Iter[289/312]		Loss: 1.5214
2019-10-28 15:28:49,140 Training Epoch [1/40] Iter[290/312]		Loss: 1.5190
2019-10-28 15:28:49,219 Training Epoch [1/40] Iter[291/312]		Loss: 1.5171
2019-10-28 15:28:49,298 Training Epoch [1/40] Iter[292/312]		Loss: 1.5151
2019-10-28 15:28:49,377 Training Epoch [1/40] Iter[293/312]		Loss: 1.5128
2019-10-28 15:28:49,456 Training Epoch [1/40] Iter[294/312]		Loss: 1.5112
2019-10-28 15:28:49,536 Training Epoch [1/40] Iter[295/312]		Loss: 1.5093
2019-10-28 15:28:49,615 Training Epoch [1/40] Iter[296/312]		Loss: 1.5070
2019-10-28 15:28:49,693 Training Epoch [1/40] Iter[297/312]		Loss: 1.5045
2019-10-28 15:28:49,772 Training Epoch [1/40] Iter[298/312]		Loss: 1.5020
2019-10-28 15:28:49,851 Training Epoch [1/40] Iter[299/312]		Loss: 1.4997
2019-10-28 15:28:49,930 Training Epoch [1/40] Iter[300/312]		Loss: 1.4976
2019-10-28 15:28:50,009 Training Epoch [1/40] Iter[301/312]		Loss: 1.4955
2019-10-28 15:28:50,088 Training Epoch [1/40] Iter[302/312]		Loss: 1.4926
2019-10-28 15:28:50,167 Training Epoch [1/40] Iter[303/312]		Loss: 1.4902
2019-10-28 15:28:50,246 Training Epoch [1/40] Iter[304/312]		Loss: 1.4885
2019-10-28 15:28:50,324 Training Epoch [1/40] Iter[305/312]		Loss: 1.4857
2019-10-28 15:28:50,402 Training Epoch [1/40] Iter[306/312]		Loss: 1.4833
2019-10-28 15:28:50,480 Training Epoch [1/40] Iter[307/312]		Loss: 1.4817
2019-10-28 15:28:50,558 Training Epoch [1/40] Iter[308/312]		Loss: 1.4799
2019-10-28 15:28:50,636 Training Epoch [1/40] Iter[309/312]		Loss: 1.4775
2019-10-28 15:28:50,714 Training Epoch [1/40] Iter[310/312]		Loss: 1.4754
2019-10-28 15:28:50,792 Training Epoch [1/40] Iter[311/312]		Loss: 1.4743
2019-10-28 15:28:50,831 Training Epoch [1/40] Iter[312/312]		Loss: 1.4726
2019-10-28 15:28:51,119 Testing Epoch [1/40] Iter[0/62]		Loss: 1.0282
2019-10-28 15:28:51,155 Testing Epoch [1/40] Iter[1/62]		Loss: 0.8702
2019-10-28 15:28:51,172 Testing Epoch [1/40] Iter[2/62]		Loss: 0.8169
2019-10-28 15:28:51,202 Testing Epoch [1/40] Iter[3/62]		Loss: 0.8092
2019-10-28 15:28:51,228 Testing Epoch [1/40] Iter[4/62]		Loss: 0.8462
2019-10-28 15:28:51,257 Testing Epoch [1/40] Iter[5/62]		Loss: 0.7977
2019-10-28 15:28:51,277 Testing Epoch [1/40] Iter[6/62]		Loss: 0.8189
2019-10-28 15:28:51,295 Testing Epoch [1/40] Iter[7/62]		Loss: 0.8095
2019-10-28 15:28:51,321 Testing Epoch [1/40] Iter[8/62]		Loss: 0.8294
2019-10-28 15:28:51,338 Testing Epoch [1/40] Iter[9/62]		Loss: 0.8397
2019-10-28 15:28:51,365 Testing Epoch [1/40] Iter[10/62]		Loss: 0.8477
2019-10-28 15:28:51,383 Testing Epoch [1/40] Iter[11/62]		Loss: 0.8501
2019-10-28 15:28:51,413 Testing Epoch [1/40] Iter[12/62]		Loss: 0.8674
2019-10-28 15:28:51,434 Testing Epoch [1/40] Iter[13/62]		Loss: 0.8793
2019-10-28 15:28:51,460 Testing Epoch [1/40] Iter[14/62]		Loss: 0.9081
2019-10-28 15:28:51,478 Testing Epoch [1/40] Iter[15/62]		Loss: 0.9063
2019-10-28 15:28:51,496 Testing Epoch [1/40] Iter[16/62]		Loss: 0.9108
2019-10-28 15:28:51,522 Testing Epoch [1/40] Iter[17/62]		Loss: 0.9023
2019-10-28 15:28:51,549 Testing Epoch [1/40] Iter[18/62]		Loss: 0.8886
2019-10-28 15:28:51,566 Testing Epoch [1/40] Iter[19/62]		Loss: 0.8842
2019-10-28 15:28:51,597 Testing Epoch [1/40] Iter[20/62]		Loss: 0.8902
2019-10-28 15:28:51,615 Testing Epoch [1/40] Iter[21/62]		Loss: 0.8906
2019-10-28 15:28:51,645 Testing Epoch [1/40] Iter[22/62]		Loss: 0.8996
2019-10-28 15:28:51,663 Testing Epoch [1/40] Iter[23/62]		Loss: 0.9021
2019-10-28 15:28:51,680 Testing Epoch [1/40] Iter[24/62]		Loss: 0.9068
2019-10-28 15:28:51,698 Testing Epoch [1/40] Iter[25/62]		Loss: 0.9149
2019-10-28 15:28:51,730 Testing Epoch [1/40] Iter[26/62]		Loss: 0.9017
2019-10-28 15:28:51,757 Testing Epoch [1/40] Iter[27/62]		Loss: 0.9174
2019-10-28 15:28:51,780 Testing Epoch [1/40] Iter[28/62]		Loss: 0.9165
2019-10-28 15:28:51,798 Testing Epoch [1/40] Iter[29/62]		Loss: 0.9143
2019-10-28 15:28:51,825 Testing Epoch [1/40] Iter[30/62]		Loss: 0.9242
2019-10-28 15:28:51,842 Testing Epoch [1/40] Iter[31/62]		Loss: 0.9298
2019-10-28 15:28:51,873 Testing Epoch [1/40] Iter[32/62]		Loss: 0.9315
2019-10-28 15:28:51,893 Testing Epoch [1/40] Iter[33/62]		Loss: 0.9292
2019-10-28 15:28:51,911 Testing Epoch [1/40] Iter[34/62]		Loss: 0.9354
2019-10-28 15:28:51,929 Testing Epoch [1/40] Iter[35/62]		Loss: 0.9352
2019-10-28 15:28:51,946 Testing Epoch [1/40] Iter[36/62]		Loss: 0.9295
2019-10-28 15:28:51,982 Testing Epoch [1/40] Iter[37/62]		Loss: 0.9316
2019-10-28 15:28:52,001 Testing Epoch [1/40] Iter[38/62]		Loss: 0.9309
2019-10-28 15:28:52,019 Testing Epoch [1/40] Iter[39/62]		Loss: 0.9315
2019-10-28 15:28:52,036 Testing Epoch [1/40] Iter[40/62]		Loss: 0.9368
2019-10-28 15:28:52,065 Testing Epoch [1/40] Iter[41/62]		Loss: 0.9369
2019-10-28 15:28:52,083 Testing Epoch [1/40] Iter[42/62]		Loss: 0.9307
2019-10-28 15:28:52,113 Testing Epoch [1/40] Iter[43/62]		Loss: 0.9347
2019-10-28 15:28:52,131 Testing Epoch [1/40] Iter[44/62]		Loss: 0.9294
2019-10-28 15:28:52,148 Testing Epoch [1/40] Iter[45/62]		Loss: 0.9333
2019-10-28 15:28:52,175 Testing Epoch [1/40] Iter[46/62]		Loss: 0.9319
2019-10-28 15:28:52,203 Testing Epoch [1/40] Iter[47/62]		Loss: 0.9380
2019-10-28 15:28:52,219 Testing Epoch [1/40] Iter[48/62]		Loss: 0.9383
2019-10-28 15:28:52,237 Testing Epoch [1/40] Iter[49/62]		Loss: 0.9417
2019-10-28 15:28:52,255 Testing Epoch [1/40] Iter[50/62]		Loss: 0.9413
2019-10-28 15:28:52,290 Testing Epoch [1/40] Iter[51/62]		Loss: 0.9397
2019-10-28 15:28:52,313 Testing Epoch [1/40] Iter[52/62]		Loss: 0.9371
2019-10-28 15:28:52,329 Testing Epoch [1/40] Iter[53/62]		Loss: 0.9394
2019-10-28 15:28:52,347 Testing Epoch [1/40] Iter[54/62]		Loss: 0.9358
2019-10-28 15:28:52,365 Testing Epoch [1/40] Iter[55/62]		Loss: 0.9351
2019-10-28 15:28:52,382 Testing Epoch [1/40] Iter[56/62]		Loss: 0.9330
2019-10-28 15:28:52,398 Testing Epoch [1/40] Iter[57/62]		Loss: 0.9372
2019-10-28 15:28:52,415 Testing Epoch [1/40] Iter[58/62]		Loss: 0.9344
2019-10-28 15:28:52,432 Testing Epoch [1/40] Iter[59/62]		Loss: 0.9355
2019-10-28 15:28:52,449 Testing Epoch [1/40] Iter[60/62]		Loss: 0.9346
2019-10-28 15:28:52,465 Testing Epoch [1/40] Iter[61/62]		Loss: 0.9401
2019-10-28 15:28:52,474 Testing Epoch [1/40] Iter[62/62]		Loss: 0.9392
2019-10-28 15:28:52,541 Saving the Model
2019-10-28 15:28:52,798 Training Epoch [2/40] Iter[0/312]		Loss: 0.9853
2019-10-28 15:28:52,888 Training Epoch [2/40] Iter[1/312]		Loss: 1.0049
2019-10-28 15:28:52,967 Training Epoch [2/40] Iter[2/312]		Loss: 1.0155
2019-10-28 15:28:53,047 Training Epoch [2/40] Iter[3/312]		Loss: 1.0363
2019-10-28 15:28:53,124 Training Epoch [2/40] Iter[4/312]		Loss: 1.0008
2019-10-28 15:28:53,206 Training Epoch [2/40] Iter[5/312]		Loss: 1.0336
2019-10-28 15:28:53,285 Training Epoch [2/40] Iter[6/312]		Loss: 1.0325
2019-10-28 15:28:53,364 Training Epoch [2/40] Iter[7/312]		Loss: 1.0176
2019-10-28 15:28:53,442 Training Epoch [2/40] Iter[8/312]		Loss: 1.0254
2019-10-28 15:28:53,521 Training Epoch [2/40] Iter[9/312]		Loss: 1.0570
2019-10-28 15:28:53,600 Training Epoch [2/40] Iter[10/312]		Loss: 1.0355
2019-10-28 15:28:53,679 Training Epoch [2/40] Iter[11/312]		Loss: 1.0135
2019-10-28 15:28:53,758 Training Epoch [2/40] Iter[12/312]		Loss: 1.0015
2019-10-28 15:28:53,837 Training Epoch [2/40] Iter[13/312]		Loss: 0.9999
2019-10-28 15:28:53,916 Training Epoch [2/40] Iter[14/312]		Loss: 0.9896
2019-10-28 15:28:53,994 Training Epoch [2/40] Iter[15/312]		Loss: 0.9728
2019-10-28 15:28:54,074 Training Epoch [2/40] Iter[16/312]		Loss: 0.9711
2019-10-28 15:28:54,152 Training Epoch [2/40] Iter[17/312]		Loss: 0.9689
2019-10-28 15:28:54,231 Training Epoch [2/40] Iter[18/312]		Loss: 0.9564
2019-10-28 15:28:54,310 Training Epoch [2/40] Iter[19/312]		Loss: 0.9492
2019-10-28 15:28:54,389 Training Epoch [2/40] Iter[20/312]		Loss: 0.9560
2019-10-28 15:28:54,468 Training Epoch [2/40] Iter[21/312]		Loss: 0.9567
2019-10-28 15:28:54,547 Training Epoch [2/40] Iter[22/312]		Loss: 0.9517
2019-10-28 15:28:54,626 Training Epoch [2/40] Iter[23/312]		Loss: 0.9548
2019-10-28 15:28:54,705 Training Epoch [2/40] Iter[24/312]		Loss: 0.9611
2019-10-28 15:28:54,783 Training Epoch [2/40] Iter[25/312]		Loss: 0.9608
2019-10-28 15:28:54,862 Training Epoch [2/40] Iter[26/312]		Loss: 0.9579
2019-10-28 15:28:54,941 Training Epoch [2/40] Iter[27/312]		Loss: 0.9567
2019-10-28 15:28:55,020 Training Epoch [2/40] Iter[28/312]		Loss: 0.9624
2019-10-28 15:28:55,099 Training Epoch [2/40] Iter[29/312]		Loss: 0.9605
2019-10-28 15:28:55,178 Training Epoch [2/40] Iter[30/312]		Loss: 0.9603
2019-10-28 15:28:55,256 Training Epoch [2/40] Iter[31/312]		Loss: 0.9599
2019-10-28 15:28:55,335 Training Epoch [2/40] Iter[32/312]		Loss: 0.9617
2019-10-28 15:28:55,414 Training Epoch [2/40] Iter[33/312]		Loss: 0.9619
2019-10-28 15:28:55,493 Training Epoch [2/40] Iter[34/312]		Loss: 0.9532
2019-10-28 15:28:55,572 Training Epoch [2/40] Iter[35/312]		Loss: 0.9518
2019-10-28 15:28:55,651 Training Epoch [2/40] Iter[36/312]		Loss: 0.9510
2019-10-28 15:28:55,730 Training Epoch [2/40] Iter[37/312]		Loss: 0.9478
2019-10-28 15:28:55,809 Training Epoch [2/40] Iter[38/312]		Loss: 0.9470
2019-10-28 15:28:55,887 Training Epoch [2/40] Iter[39/312]		Loss: 0.9460
2019-10-28 15:28:55,966 Training Epoch [2/40] Iter[40/312]		Loss: 0.9442
2019-10-28 15:28:56,045 Training Epoch [2/40] Iter[41/312]		Loss: 0.9452
2019-10-28 15:28:56,124 Training Epoch [2/40] Iter[42/312]		Loss: 0.9458
2019-10-28 15:28:56,203 Training Epoch [2/40] Iter[43/312]		Loss: 0.9407
2019-10-28 15:28:56,281 Training Epoch [2/40] Iter[44/312]		Loss: 0.9405
2019-10-28 15:28:56,361 Training Epoch [2/40] Iter[45/312]		Loss: 0.9391
2019-10-28 15:28:56,440 Training Epoch [2/40] Iter[46/312]		Loss: 0.9419
2019-10-28 15:28:56,519 Training Epoch [2/40] Iter[47/312]		Loss: 0.9393
2019-10-28 15:28:56,597 Training Epoch [2/40] Iter[48/312]		Loss: 0.9375
2019-10-28 15:28:56,676 Training Epoch [2/40] Iter[49/312]		Loss: 0.9395
2019-10-28 15:28:56,755 Training Epoch [2/40] Iter[50/312]		Loss: 0.9336
2019-10-28 15:28:56,834 Training Epoch [2/40] Iter[51/312]		Loss: 0.9282
2019-10-28 15:28:56,912 Training Epoch [2/40] Iter[52/312]		Loss: 0.9267
2019-10-28 15:28:56,992 Training Epoch [2/40] Iter[53/312]		Loss: 0.9259
2019-10-28 15:28:57,070 Training Epoch [2/40] Iter[54/312]		Loss: 0.9255
2019-10-28 15:28:57,150 Training Epoch [2/40] Iter[55/312]		Loss: 0.9279
2019-10-28 15:28:57,228 Training Epoch [2/40] Iter[56/312]		Loss: 0.9258
2019-10-28 15:28:57,307 Training Epoch [2/40] Iter[57/312]		Loss: 0.9238
2019-10-28 15:28:57,386 Training Epoch [2/40] Iter[58/312]		Loss: 0.9228
2019-10-28 15:28:57,466 Training Epoch [2/40] Iter[59/312]		Loss: 0.9173
2019-10-28 15:28:57,545 Training Epoch [2/40] Iter[60/312]		Loss: 0.9152
2019-10-28 15:28:57,625 Training Epoch [2/40] Iter[61/312]		Loss: 0.9145
2019-10-28 15:28:57,704 Training Epoch [2/40] Iter[62/312]		Loss: 0.9121
2019-10-28 15:28:57,784 Training Epoch [2/40] Iter[63/312]		Loss: 0.9109
2019-10-28 15:28:57,863 Training Epoch [2/40] Iter[64/312]		Loss: 0.9100
2019-10-28 15:28:57,943 Training Epoch [2/40] Iter[65/312]		Loss: 0.9103
2019-10-28 15:28:58,022 Training Epoch [2/40] Iter[66/312]		Loss: 0.9145
2019-10-28 15:28:58,102 Training Epoch [2/40] Iter[67/312]		Loss: 0.9116
2019-10-28 15:28:58,182 Training Epoch [2/40] Iter[68/312]		Loss: 0.9099
2019-10-28 15:28:58,267 Training Epoch [2/40] Iter[69/312]		Loss: 0.9075
2019-10-28 15:28:58,355 Training Epoch [2/40] Iter[70/312]		Loss: 0.9099
2019-10-28 15:28:58,434 Training Epoch [2/40] Iter[71/312]		Loss: 0.9087
2019-10-28 15:28:58,513 Training Epoch [2/40] Iter[72/312]		Loss: 0.9108
2019-10-28 15:28:58,593 Training Epoch [2/40] Iter[73/312]		Loss: 0.9094
2019-10-28 15:28:58,673 Training Epoch [2/40] Iter[74/312]		Loss: 0.9111
2019-10-28 15:28:58,755 Training Epoch [2/40] Iter[75/312]		Loss: 0.9098
2019-10-28 15:28:58,834 Training Epoch [2/40] Iter[76/312]		Loss: 0.9089
2019-10-28 15:28:58,915 Training Epoch [2/40] Iter[77/312]		Loss: 0.9072
2019-10-28 15:28:58,994 Training Epoch [2/40] Iter[78/312]		Loss: 0.9048
2019-10-28 15:28:59,075 Training Epoch [2/40] Iter[79/312]		Loss: 0.9067
2019-10-28 15:28:59,154 Training Epoch [2/40] Iter[80/312]		Loss: 0.9039
2019-10-28 15:28:59,235 Training Epoch [2/40] Iter[81/312]		Loss: 0.9004
2019-10-28 15:28:59,314 Training Epoch [2/40] Iter[82/312]		Loss: 0.8983
2019-10-28 15:28:59,395 Training Epoch [2/40] Iter[83/312]		Loss: 0.8977
2019-10-28 15:28:59,474 Training Epoch [2/40] Iter[84/312]		Loss: 0.8979
2019-10-28 15:28:59,555 Training Epoch [2/40] Iter[85/312]		Loss: 0.8980
2019-10-28 15:28:59,634 Training Epoch [2/40] Iter[86/312]		Loss: 0.8966
2019-10-28 15:28:59,715 Training Epoch [2/40] Iter[87/312]		Loss: 0.8956
2019-10-28 15:28:59,794 Training Epoch [2/40] Iter[88/312]		Loss: 0.8967
2019-10-28 15:28:59,874 Training Epoch [2/40] Iter[89/312]		Loss: 0.8980
2019-10-28 15:28:59,954 Training Epoch [2/40] Iter[90/312]		Loss: 0.8968
2019-10-28 15:29:00,035 Training Epoch [2/40] Iter[91/312]		Loss: 0.8941
2019-10-28 15:29:00,115 Training Epoch [2/40] Iter[92/312]		Loss: 0.8918
2019-10-28 15:29:00,194 Training Epoch [2/40] Iter[93/312]		Loss: 0.8890
2019-10-28 15:29:00,274 Training Epoch [2/40] Iter[94/312]		Loss: 0.8870
2019-10-28 15:29:00,355 Training Epoch [2/40] Iter[95/312]		Loss: 0.8884
2019-10-28 15:29:00,435 Training Epoch [2/40] Iter[96/312]		Loss: 0.8899
2019-10-28 15:29:00,514 Training Epoch [2/40] Iter[97/312]		Loss: 0.8933
2019-10-28 15:29:00,593 Training Epoch [2/40] Iter[98/312]		Loss: 0.8938
2019-10-28 15:29:00,675 Training Epoch [2/40] Iter[99/312]		Loss: 0.8944
2019-10-28 15:29:00,754 Training Epoch [2/40] Iter[100/312]		Loss: 0.8944
2019-10-28 15:29:00,832 Training Epoch [2/40] Iter[101/312]		Loss: 0.8947
2019-10-28 15:29:00,911 Training Epoch [2/40] Iter[102/312]		Loss: 0.8942
2019-10-28 15:29:00,994 Training Epoch [2/40] Iter[103/312]		Loss: 0.8942
2019-10-28 15:29:01,073 Training Epoch [2/40] Iter[104/312]		Loss: 0.8935
2019-10-28 15:29:01,153 Training Epoch [2/40] Iter[105/312]		Loss: 0.8948
2019-10-28 15:29:01,232 Training Epoch [2/40] Iter[106/312]		Loss: 0.8935
2019-10-28 15:29:01,315 Training Epoch [2/40] Iter[107/312]		Loss: 0.8932
2019-10-28 15:29:01,393 Training Epoch [2/40] Iter[108/312]		Loss: 0.8918
2019-10-28 15:29:01,472 Training Epoch [2/40] Iter[109/312]		Loss: 0.8894
2019-10-28 15:29:01,551 Training Epoch [2/40] Iter[110/312]		Loss: 0.8881
2019-10-28 15:29:01,631 Training Epoch [2/40] Iter[111/312]		Loss: 0.8873
2019-10-28 15:29:01,710 Training Epoch [2/40] Iter[112/312]		Loss: 0.8876
2019-10-28 15:29:01,791 Training Epoch [2/40] Iter[113/312]		Loss: 0.8876
2019-10-28 15:29:01,870 Training Epoch [2/40] Iter[114/312]		Loss: 0.8871
2019-10-28 15:29:01,948 Training Epoch [2/40] Iter[115/312]		Loss: 0.8866
2019-10-28 15:29:02,027 Training Epoch [2/40] Iter[116/312]		Loss: 0.8862
2019-10-28 15:29:02,106 Training Epoch [2/40] Iter[117/312]		Loss: 0.8866
2019-10-28 15:29:02,186 Training Epoch [2/40] Iter[118/312]		Loss: 0.8870
2019-10-28 15:29:02,265 Training Epoch [2/40] Iter[119/312]		Loss: 0.8879
2019-10-28 15:29:02,344 Training Epoch [2/40] Iter[120/312]		Loss: 0.8877
2019-10-28 15:29:02,424 Training Epoch [2/40] Iter[121/312]		Loss: 0.8882
2019-10-28 15:29:02,503 Training Epoch [2/40] Iter[122/312]		Loss: 0.8872
2019-10-28 15:29:02,583 Training Epoch [2/40] Iter[123/312]		Loss: 0.8879
2019-10-28 15:29:02,661 Training Epoch [2/40] Iter[124/312]		Loss: 0.8874
2019-10-28 15:29:02,740 Training Epoch [2/40] Iter[125/312]		Loss: 0.8885
2019-10-28 15:29:02,819 Training Epoch [2/40] Iter[126/312]		Loss: 0.8892
2019-10-28 15:29:02,898 Training Epoch [2/40] Iter[127/312]		Loss: 0.8879
2019-10-28 15:29:02,977 Training Epoch [2/40] Iter[128/312]		Loss: 0.8870
2019-10-28 15:29:03,057 Training Epoch [2/40] Iter[129/312]		Loss: 0.8854
2019-10-28 15:29:03,136 Training Epoch [2/40] Iter[130/312]		Loss: 0.8850
2019-10-28 15:29:03,215 Training Epoch [2/40] Iter[131/312]		Loss: 0.8841
2019-10-28 15:29:03,294 Training Epoch [2/40] Iter[132/312]		Loss: 0.8833
2019-10-28 15:29:03,373 Training Epoch [2/40] Iter[133/312]		Loss: 0.8824
2019-10-28 15:29:03,451 Training Epoch [2/40] Iter[134/312]		Loss: 0.8825
2019-10-28 15:29:03,530 Training Epoch [2/40] Iter[135/312]		Loss: 0.8830
2019-10-28 15:29:03,609 Training Epoch [2/40] Iter[136/312]		Loss: 0.8830
2019-10-28 15:29:03,688 Training Epoch [2/40] Iter[137/312]		Loss: 0.8828
2019-10-28 15:29:03,767 Training Epoch [2/40] Iter[138/312]		Loss: 0.8831
2019-10-28 15:29:03,846 Training Epoch [2/40] Iter[139/312]		Loss: 0.8824
2019-10-28 15:29:03,925 Training Epoch [2/40] Iter[140/312]		Loss: 0.8823
2019-10-28 15:29:04,003 Training Epoch [2/40] Iter[141/312]		Loss: 0.8839
2019-10-28 15:29:04,083 Training Epoch [2/40] Iter[142/312]		Loss: 0.8831
2019-10-28 15:29:04,161 Training Epoch [2/40] Iter[143/312]		Loss: 0.8831
2019-10-28 15:29:04,241 Training Epoch [2/40] Iter[144/312]		Loss: 0.8834
2019-10-28 15:29:04,320 Training Epoch [2/40] Iter[145/312]		Loss: 0.8829
2019-10-28 15:29:04,398 Training Epoch [2/40] Iter[146/312]		Loss: 0.8837
2019-10-28 15:29:04,477 Training Epoch [2/40] Iter[147/312]		Loss: 0.8829
2019-10-28 15:29:04,556 Training Epoch [2/40] Iter[148/312]		Loss: 0.8818
2019-10-28 15:29:04,635 Training Epoch [2/40] Iter[149/312]		Loss: 0.8817
2019-10-28 15:29:04,716 Training Epoch [2/40] Iter[150/312]		Loss: 0.8821
2019-10-28 15:29:04,796 Training Epoch [2/40] Iter[151/312]		Loss: 0.8823
2019-10-28 15:29:04,877 Training Epoch [2/40] Iter[152/312]		Loss: 0.8825
2019-10-28 15:29:04,956 Training Epoch [2/40] Iter[153/312]		Loss: 0.8819
2019-10-28 15:29:05,035 Training Epoch [2/40] Iter[154/312]		Loss: 0.8812
2019-10-28 15:29:05,114 Training Epoch [2/40] Iter[155/312]		Loss: 0.8815
2019-10-28 15:29:05,193 Training Epoch [2/40] Iter[156/312]		Loss: 0.8819
2019-10-28 15:29:05,272 Training Epoch [2/40] Iter[157/312]		Loss: 0.8815
2019-10-28 15:29:05,351 Training Epoch [2/40] Iter[158/312]		Loss: 0.8816
2019-10-28 15:29:05,431 Training Epoch [2/40] Iter[159/312]		Loss: 0.8803
2019-10-28 15:29:05,509 Training Epoch [2/40] Iter[160/312]		Loss: 0.8815
2019-10-28 15:29:05,594 Training Epoch [2/40] Iter[161/312]		Loss: 0.8817
2019-10-28 15:29:05,673 Training Epoch [2/40] Iter[162/312]		Loss: 0.8826
2019-10-28 15:29:05,755 Training Epoch [2/40] Iter[163/312]		Loss: 0.8824
2019-10-28 15:29:05,834 Training Epoch [2/40] Iter[164/312]		Loss: 0.8837
2019-10-28 15:29:05,913 Training Epoch [2/40] Iter[165/312]		Loss: 0.8850
2019-10-28 15:29:05,992 Training Epoch [2/40] Iter[166/312]		Loss: 0.8840
2019-10-28 15:29:06,071 Training Epoch [2/40] Iter[167/312]		Loss: 0.8832
2019-10-28 15:29:06,150 Training Epoch [2/40] Iter[168/312]		Loss: 0.8820
2019-10-28 15:29:06,229 Training Epoch [2/40] Iter[169/312]		Loss: 0.8816
2019-10-28 15:29:06,308 Training Epoch [2/40] Iter[170/312]		Loss: 0.8804
2019-10-28 15:29:06,387 Training Epoch [2/40] Iter[171/312]		Loss: 0.8800
2019-10-28 15:29:06,466 Training Epoch [2/40] Iter[172/312]		Loss: 0.8805
2019-10-28 15:29:06,546 Training Epoch [2/40] Iter[173/312]		Loss: 0.8799
2019-10-28 15:29:06,626 Training Epoch [2/40] Iter[174/312]		Loss: 0.8800
2019-10-28 15:29:06,705 Training Epoch [2/40] Iter[175/312]		Loss: 0.8801
2019-10-28 15:29:06,784 Training Epoch [2/40] Iter[176/312]		Loss: 0.8787
2019-10-28 15:29:06,862 Training Epoch [2/40] Iter[177/312]		Loss: 0.8779
2019-10-28 15:29:06,941 Training Epoch [2/40] Iter[178/312]		Loss: 0.8777
2019-10-28 15:29:07,020 Training Epoch [2/40] Iter[179/312]		Loss: 0.8779
2019-10-28 15:29:07,099 Training Epoch [2/40] Iter[180/312]		Loss: 0.8766
2019-10-28 15:29:07,178 Training Epoch [2/40] Iter[181/312]		Loss: 0.8757
2019-10-28 15:29:07,257 Training Epoch [2/40] Iter[182/312]		Loss: 0.8749
2019-10-28 15:29:07,336 Training Epoch [2/40] Iter[183/312]		Loss: 0.8743
2019-10-28 15:29:07,415 Training Epoch [2/40] Iter[184/312]		Loss: 0.8754
2019-10-28 15:29:07,493 Training Epoch [2/40] Iter[185/312]		Loss: 0.8761
2019-10-28 15:29:07,572 Training Epoch [2/40] Iter[186/312]		Loss: 0.8760
2019-10-28 15:29:07,651 Training Epoch [2/40] Iter[187/312]		Loss: 0.8756
2019-10-28 15:29:07,730 Training Epoch [2/40] Iter[188/312]		Loss: 0.8749
2019-10-28 15:29:07,808 Training Epoch [2/40] Iter[189/312]		Loss: 0.8734
2019-10-28 15:29:07,887 Training Epoch [2/40] Iter[190/312]		Loss: 0.8733
2019-10-28 15:29:07,966 Training Epoch [2/40] Iter[191/312]		Loss: 0.8726
2019-10-28 15:29:08,045 Training Epoch [2/40] Iter[192/312]		Loss: 0.8721
2019-10-28 15:29:08,124 Training Epoch [2/40] Iter[193/312]		Loss: 0.8722
2019-10-28 15:29:08,203 Training Epoch [2/40] Iter[194/312]		Loss: 0.8718
2019-10-28 15:29:08,282 Training Epoch [2/40] Iter[195/312]		Loss: 0.8716
2019-10-28 15:29:08,361 Training Epoch [2/40] Iter[196/312]		Loss: 0.8731
2019-10-28 15:29:08,440 Training Epoch [2/40] Iter[197/312]		Loss: 0.8721
2019-10-28 15:29:08,519 Training Epoch [2/40] Iter[198/312]		Loss: 0.8711
2019-10-28 15:29:08,598 Training Epoch [2/40] Iter[199/312]		Loss: 0.8699
2019-10-28 15:29:08,677 Training Epoch [2/40] Iter[200/312]		Loss: 0.8702
2019-10-28 15:29:08,756 Training Epoch [2/40] Iter[201/312]		Loss: 0.8699
2019-10-28 15:29:08,834 Training Epoch [2/40] Iter[202/312]		Loss: 0.8704
2019-10-28 15:29:08,913 Training Epoch [2/40] Iter[203/312]		Loss: 0.8702
2019-10-28 15:29:08,992 Training Epoch [2/40] Iter[204/312]		Loss: 0.8699
2019-10-28 15:29:09,071 Training Epoch [2/40] Iter[205/312]		Loss: 0.8700
2019-10-28 15:29:09,150 Training Epoch [2/40] Iter[206/312]		Loss: 0.8689
2019-10-28 15:29:09,229 Training Epoch [2/40] Iter[207/312]		Loss: 0.8681
2019-10-28 15:29:09,308 Training Epoch [2/40] Iter[208/312]		Loss: 0.8693
2019-10-28 15:29:09,387 Training Epoch [2/40] Iter[209/312]		Loss: 0.8696
2019-10-28 15:29:09,466 Training Epoch [2/40] Iter[210/312]		Loss: 0.8695
2019-10-28 15:29:09,545 Training Epoch [2/40] Iter[211/312]		Loss: 0.8695
2019-10-28 15:29:09,624 Training Epoch [2/40] Iter[212/312]		Loss: 0.8696
2019-10-28 15:29:09,703 Training Epoch [2/40] Iter[213/312]		Loss: 0.8690
2019-10-28 15:29:09,782 Training Epoch [2/40] Iter[214/312]		Loss: 0.8680
2019-10-28 15:29:09,860 Training Epoch [2/40] Iter[215/312]		Loss: 0.8682
2019-10-28 15:29:09,939 Training Epoch [2/40] Iter[216/312]		Loss: 0.8680
2019-10-28 15:29:10,018 Training Epoch [2/40] Iter[217/312]		Loss: 0.8674
2019-10-28 15:29:10,097 Training Epoch [2/40] Iter[218/312]		Loss: 0.8668
2019-10-28 15:29:10,177 Training Epoch [2/40] Iter[219/312]		Loss: 0.8676
2019-10-28 15:29:10,256 Training Epoch [2/40] Iter[220/312]		Loss: 0.8690
2019-10-28 15:29:10,335 Training Epoch [2/40] Iter[221/312]		Loss: 0.8688
2019-10-28 15:29:10,414 Training Epoch [2/40] Iter[222/312]		Loss: 0.8693
2019-10-28 15:29:10,492 Training Epoch [2/40] Iter[223/312]		Loss: 0.8690
2019-10-28 15:29:10,571 Training Epoch [2/40] Iter[224/312]		Loss: 0.8684
2019-10-28 15:29:10,650 Training Epoch [2/40] Iter[225/312]		Loss: 0.8680
2019-10-28 15:29:10,729 Training Epoch [2/40] Iter[226/312]		Loss: 0.8674
2019-10-28 15:29:10,808 Training Epoch [2/40] Iter[227/312]		Loss: 0.8666
2019-10-28 15:29:10,887 Training Epoch [2/40] Iter[228/312]		Loss: 0.8656
2019-10-28 15:29:10,966 Training Epoch [2/40] Iter[229/312]		Loss: 0.8665
2019-10-28 15:29:11,045 Training Epoch [2/40] Iter[230/312]		Loss: 0.8671
2019-10-28 15:29:11,124 Training Epoch [2/40] Iter[231/312]		Loss: 0.8663
2019-10-28 15:29:11,203 Training Epoch [2/40] Iter[232/312]		Loss: 0.8666
2019-10-28 15:29:11,282 Training Epoch [2/40] Iter[233/312]		Loss: 0.8653
2019-10-28 15:29:11,361 Training Epoch [2/40] Iter[234/312]		Loss: 0.8651
2019-10-28 15:29:11,440 Training Epoch [2/40] Iter[235/312]		Loss: 0.8659
2019-10-28 15:29:11,519 Training Epoch [2/40] Iter[236/312]		Loss: 0.8667
2019-10-28 15:29:11,598 Training Epoch [2/40] Iter[237/312]		Loss: 0.8655
2019-10-28 15:29:11,677 Training Epoch [2/40] Iter[238/312]		Loss: 0.8650
2019-10-28 15:29:11,756 Training Epoch [2/40] Iter[239/312]		Loss: 0.8647
2019-10-28 15:29:11,835 Training Epoch [2/40] Iter[240/312]		Loss: 0.8647
2019-10-28 15:29:11,914 Training Epoch [2/40] Iter[241/312]		Loss: 0.8650
2019-10-28 15:29:11,993 Training Epoch [2/40] Iter[242/312]		Loss: 0.8643
2019-10-28 15:29:12,072 Training Epoch [2/40] Iter[243/312]		Loss: 0.8642
2019-10-28 15:29:12,151 Training Epoch [2/40] Iter[244/312]		Loss: 0.8640
2019-10-28 15:29:12,230 Training Epoch [2/40] Iter[245/312]		Loss: 0.8645
2019-10-28 15:29:12,310 Training Epoch [2/40] Iter[246/312]		Loss: 0.8642
2019-10-28 15:29:12,388 Training Epoch [2/40] Iter[247/312]		Loss: 0.8638
2019-10-28 15:29:12,468 Training Epoch [2/40] Iter[248/312]		Loss: 0.8634
2019-10-28 15:29:12,546 Training Epoch [2/40] Iter[249/312]		Loss: 0.8630
2019-10-28 15:29:12,626 Training Epoch [2/40] Iter[250/312]		Loss: 0.8631
2019-10-28 15:29:12,705 Training Epoch [2/40] Iter[251/312]		Loss: 0.8635
2019-10-28 15:29:12,784 Training Epoch [2/40] Iter[252/312]		Loss: 0.8629
2019-10-28 15:29:12,863 Training Epoch [2/40] Iter[253/312]		Loss: 0.8627
2019-10-28 15:29:12,942 Training Epoch [2/40] Iter[254/312]		Loss: 0.8630
2019-10-28 15:29:13,020 Training Epoch [2/40] Iter[255/312]		Loss: 0.8633
2019-10-28 15:29:13,099 Training Epoch [2/40] Iter[256/312]		Loss: 0.8633
2019-10-28 15:29:13,178 Training Epoch [2/40] Iter[257/312]		Loss: 0.8626
2019-10-28 15:29:13,257 Training Epoch [2/40] Iter[258/312]		Loss: 0.8625
2019-10-28 15:29:13,336 Training Epoch [2/40] Iter[259/312]		Loss: 0.8628
2019-10-28 15:29:13,415 Training Epoch [2/40] Iter[260/312]		Loss: 0.8626
2019-10-28 15:29:13,494 Training Epoch [2/40] Iter[261/312]		Loss: 0.8625
2019-10-28 15:29:13,573 Training Epoch [2/40] Iter[262/312]		Loss: 0.8619
2019-10-28 15:29:13,652 Training Epoch [2/40] Iter[263/312]		Loss: 0.8615
2019-10-28 15:29:13,732 Training Epoch [2/40] Iter[264/312]		Loss: 0.8610
2019-10-28 15:29:13,810 Training Epoch [2/40] Iter[265/312]		Loss: 0.8604
2019-10-28 15:29:13,889 Training Epoch [2/40] Iter[266/312]		Loss: 0.8603
2019-10-28 15:29:13,968 Training Epoch [2/40] Iter[267/312]		Loss: 0.8594
2019-10-28 15:29:14,047 Training Epoch [2/40] Iter[268/312]		Loss: 0.8583
2019-10-28 15:29:14,126 Training Epoch [2/40] Iter[269/312]		Loss: 0.8573
2019-10-28 15:29:14,205 Training Epoch [2/40] Iter[270/312]		Loss: 0.8568
2019-10-28 15:29:14,284 Training Epoch [2/40] Iter[271/312]		Loss: 0.8563
2019-10-28 15:29:14,363 Training Epoch [2/40] Iter[272/312]		Loss: 0.8566
2019-10-28 15:29:14,442 Training Epoch [2/40] Iter[273/312]		Loss: 0.8556
2019-10-28 15:29:14,521 Training Epoch [2/40] Iter[274/312]		Loss: 0.8559
2019-10-28 15:29:14,600 Training Epoch [2/40] Iter[275/312]		Loss: 0.8550
2019-10-28 15:29:14,679 Training Epoch [2/40] Iter[276/312]		Loss: 0.8545
2019-10-28 15:29:14,758 Training Epoch [2/40] Iter[277/312]		Loss: 0.8544
2019-10-28 15:29:14,836 Training Epoch [2/40] Iter[278/312]		Loss: 0.8548
2019-10-28 15:29:14,915 Training Epoch [2/40] Iter[279/312]		Loss: 0.8543
2019-10-28 15:29:14,994 Training Epoch [2/40] Iter[280/312]		Loss: 0.8538
2019-10-28 15:29:15,073 Training Epoch [2/40] Iter[281/312]		Loss: 0.8541
2019-10-28 15:29:15,152 Training Epoch [2/40] Iter[282/312]		Loss: 0.8542
2019-10-28 15:29:15,231 Training Epoch [2/40] Iter[283/312]		Loss: 0.8544
2019-10-28 15:29:15,310 Training Epoch [2/40] Iter[284/312]		Loss: 0.8543
2019-10-28 15:29:15,389 Training Epoch [2/40] Iter[285/312]		Loss: 0.8543
2019-10-28 15:29:15,468 Training Epoch [2/40] Iter[286/312]		Loss: 0.8532
2019-10-28 15:29:15,546 Training Epoch [2/40] Iter[287/312]		Loss: 0.8533
2019-10-28 15:29:15,625 Training Epoch [2/40] Iter[288/312]		Loss: 0.8519
2019-10-28 15:29:15,704 Training Epoch [2/40] Iter[289/312]		Loss: 0.8517
2019-10-28 15:29:15,783 Training Epoch [2/40] Iter[290/312]		Loss: 0.8511
2019-10-28 15:29:15,862 Training Epoch [2/40] Iter[291/312]		Loss: 0.8512
2019-10-28 15:29:15,941 Training Epoch [2/40] Iter[292/312]		Loss: 0.8512
2019-10-28 15:29:16,020 Training Epoch [2/40] Iter[293/312]		Loss: 0.8508
2019-10-28 15:29:16,099 Training Epoch [2/40] Iter[294/312]		Loss: 0.8506
2019-10-28 15:29:16,178 Training Epoch [2/40] Iter[295/312]		Loss: 0.8508
2019-10-28 15:29:16,257 Training Epoch [2/40] Iter[296/312]		Loss: 0.8511
2019-10-28 15:29:16,336 Training Epoch [2/40] Iter[297/312]		Loss: 0.8518
2019-10-28 15:29:16,415 Training Epoch [2/40] Iter[298/312]		Loss: 0.8520
2019-10-28 15:29:16,494 Training Epoch [2/40] Iter[299/312]		Loss: 0.8517
2019-10-28 15:29:16,573 Training Epoch [2/40] Iter[300/312]		Loss: 0.8512
2019-10-28 15:29:16,651 Training Epoch [2/40] Iter[301/312]		Loss: 0.8507
2019-10-28 15:29:16,730 Training Epoch [2/40] Iter[302/312]		Loss: 0.8512
2019-10-28 15:29:16,809 Training Epoch [2/40] Iter[303/312]		Loss: 0.8506
2019-10-28 15:29:16,888 Training Epoch [2/40] Iter[304/312]		Loss: 0.8499
2019-10-28 15:29:16,966 Training Epoch [2/40] Iter[305/312]		Loss: 0.8501
2019-10-28 15:29:17,044 Training Epoch [2/40] Iter[306/312]		Loss: 0.8489
2019-10-28 15:29:17,122 Training Epoch [2/40] Iter[307/312]		Loss: 0.8482
2019-10-28 15:29:17,201 Training Epoch [2/40] Iter[308/312]		Loss: 0.8480
2019-10-28 15:29:17,280 Training Epoch [2/40] Iter[309/312]		Loss: 0.8486
2019-10-28 15:29:17,358 Training Epoch [2/40] Iter[310/312]		Loss: 0.8477
2019-10-28 15:29:17,437 Training Epoch [2/40] Iter[311/312]		Loss: 0.8477
2019-10-28 15:29:17,475 Training Epoch [2/40] Iter[312/312]		Loss: 0.8475
2019-10-28 15:29:17,770 Testing Epoch [2/40] Iter[0/62]		Loss: 1.2190
2019-10-28 15:29:17,790 Testing Epoch [2/40] Iter[1/62]		Loss: 1.1903
2019-10-28 15:29:17,825 Testing Epoch [2/40] Iter[2/62]		Loss: 1.0926
2019-10-28 15:29:17,855 Testing Epoch [2/40] Iter[3/62]		Loss: 1.2156
2019-10-28 15:29:17,878 Testing Epoch [2/40] Iter[4/62]		Loss: 1.2466
2019-10-28 15:29:17,901 Testing Epoch [2/40] Iter[5/62]		Loss: 1.2049
2019-10-28 15:29:17,928 Testing Epoch [2/40] Iter[6/62]		Loss: 1.1773
2019-10-28 15:29:17,946 Testing Epoch [2/40] Iter[7/62]		Loss: 1.1664
2019-10-28 15:29:17,973 Testing Epoch [2/40] Iter[8/62]		Loss: 1.1999
2019-10-28 15:29:17,996 Testing Epoch [2/40] Iter[9/62]		Loss: 1.2014
2019-10-28 15:29:18,019 Testing Epoch [2/40] Iter[10/62]		Loss: 1.2160
2019-10-28 15:29:18,037 Testing Epoch [2/40] Iter[11/62]		Loss: 1.2602
2019-10-28 15:29:18,055 Testing Epoch [2/40] Iter[12/62]		Loss: 1.2773
2019-10-28 15:29:18,085 Testing Epoch [2/40] Iter[13/62]		Loss: 1.3172
2019-10-28 15:29:18,118 Testing Epoch [2/40] Iter[14/62]		Loss: 1.3331
2019-10-28 15:29:18,136 Testing Epoch [2/40] Iter[15/62]		Loss: 1.3503
2019-10-28 15:29:18,161 Testing Epoch [2/40] Iter[16/62]		Loss: 1.3261
2019-10-28 15:29:18,187 Testing Epoch [2/40] Iter[17/62]		Loss: 1.3301
2019-10-28 15:29:18,204 Testing Epoch [2/40] Iter[18/62]		Loss: 1.3033
2019-10-28 15:29:18,229 Testing Epoch [2/40] Iter[19/62]		Loss: 1.3098
2019-10-28 15:29:18,255 Testing Epoch [2/40] Iter[20/62]		Loss: 1.3047
2019-10-28 15:29:18,281 Testing Epoch [2/40] Iter[21/62]		Loss: 1.2792
2019-10-28 15:29:18,305 Testing Epoch [2/40] Iter[22/62]		Loss: 1.2821
2019-10-28 15:29:18,322 Testing Epoch [2/40] Iter[23/62]		Loss: 1.2724
2019-10-28 15:29:18,349 Testing Epoch [2/40] Iter[24/62]		Loss: 1.2704
2019-10-28 15:29:18,367 Testing Epoch [2/40] Iter[25/62]		Loss: 1.2733
2019-10-28 15:29:18,385 Testing Epoch [2/40] Iter[26/62]		Loss: 1.2785
2019-10-28 15:29:18,417 Testing Epoch [2/40] Iter[27/62]		Loss: 1.3131
2019-10-28 15:29:18,441 Testing Epoch [2/40] Iter[28/62]		Loss: 1.3050
2019-10-28 15:29:18,458 Testing Epoch [2/40] Iter[29/62]		Loss: 1.2917
2019-10-28 15:29:18,485 Testing Epoch [2/40] Iter[30/62]		Loss: 1.2938
2019-10-28 15:29:18,502 Testing Epoch [2/40] Iter[31/62]		Loss: 1.2883
2019-10-28 15:29:18,530 Testing Epoch [2/40] Iter[32/62]		Loss: 1.2810
2019-10-28 15:29:18,547 Testing Epoch [2/40] Iter[33/62]		Loss: 1.2734
2019-10-28 15:29:18,573 Testing Epoch [2/40] Iter[34/62]		Loss: 1.2773
2019-10-28 15:29:18,590 Testing Epoch [2/40] Iter[35/62]		Loss: 1.2773
2019-10-28 15:29:18,618 Testing Epoch [2/40] Iter[36/62]		Loss: 1.2694
2019-10-28 15:29:18,636 Testing Epoch [2/40] Iter[37/62]		Loss: 1.2616
2019-10-28 15:29:18,662 Testing Epoch [2/40] Iter[38/62]		Loss: 1.2588
2019-10-28 15:29:18,683 Testing Epoch [2/40] Iter[39/62]		Loss: 1.2628
2019-10-28 15:29:18,709 Testing Epoch [2/40] Iter[40/62]		Loss: 1.2680
2019-10-28 15:29:18,726 Testing Epoch [2/40] Iter[41/62]		Loss: 1.2770
2019-10-28 15:29:18,757 Testing Epoch [2/40] Iter[42/62]		Loss: 1.2680
2019-10-28 15:29:18,775 Testing Epoch [2/40] Iter[43/62]		Loss: 1.2775
2019-10-28 15:29:18,801 Testing Epoch [2/40] Iter[44/62]		Loss: 1.2857
2019-10-28 15:29:18,818 Testing Epoch [2/40] Iter[45/62]		Loss: 1.2815
2019-10-28 15:29:18,846 Testing Epoch [2/40] Iter[46/62]		Loss: 1.2835
2019-10-28 15:29:18,863 Testing Epoch [2/40] Iter[47/62]		Loss: 1.2992
2019-10-28 15:29:18,881 Testing Epoch [2/40] Iter[48/62]		Loss: 1.3003
2019-10-28 15:29:18,898 Testing Epoch [2/40] Iter[49/62]		Loss: 1.2999
2019-10-28 15:29:18,926 Testing Epoch [2/40] Iter[50/62]		Loss: 1.2966
2019-10-28 15:29:18,943 Testing Epoch [2/40] Iter[51/62]		Loss: 1.2911
2019-10-28 15:29:18,961 Testing Epoch [2/40] Iter[52/62]		Loss: 1.2870
2019-10-28 15:29:18,978 Testing Epoch [2/40] Iter[53/62]		Loss: 1.2902
2019-10-28 15:29:19,009 Testing Epoch [2/40] Iter[54/62]		Loss: 1.2863
2019-10-28 15:29:19,030 Testing Epoch [2/40] Iter[55/62]		Loss: 1.2825
2019-10-28 15:29:19,047 Testing Epoch [2/40] Iter[56/62]		Loss: 1.2890
2019-10-28 15:29:19,064 Testing Epoch [2/40] Iter[57/62]		Loss: 1.2988
2019-10-28 15:29:19,080 Testing Epoch [2/40] Iter[58/62]		Loss: 1.2933
2019-10-28 15:29:19,096 Testing Epoch [2/40] Iter[59/62]		Loss: 1.2893
2019-10-28 15:29:19,114 Testing Epoch [2/40] Iter[60/62]		Loss: 1.2847
2019-10-28 15:29:19,130 Testing Epoch [2/40] Iter[61/62]		Loss: 1.2994
2019-10-28 15:29:19,139 Testing Epoch [2/40] Iter[62/62]		Loss: 1.2954
2019-10-28 15:29:19,510 Training Epoch [3/40] Iter[0/312]		Loss: 0.7040
2019-10-28 15:29:19,588 Training Epoch [3/40] Iter[1/312]		Loss: 0.9347
2019-10-28 15:29:19,666 Training Epoch [3/40] Iter[2/312]		Loss: 0.9453
2019-10-28 15:29:19,744 Training Epoch [3/40] Iter[3/312]		Loss: 0.9412
2019-10-28 15:29:19,825 Training Epoch [3/40] Iter[4/312]		Loss: 0.9528
2019-10-28 15:29:19,908 Training Epoch [3/40] Iter[5/312]		Loss: 0.9292
2019-10-28 15:29:19,985 Training Epoch [3/40] Iter[6/312]		Loss: 0.9002
2019-10-28 15:29:20,063 Training Epoch [3/40] Iter[7/312]		Loss: 0.8822
2019-10-28 15:29:20,142 Training Epoch [3/40] Iter[8/312]		Loss: 0.8754
2019-10-28 15:29:20,221 Training Epoch [3/40] Iter[9/312]		Loss: 0.8704
2019-10-28 15:29:20,300 Training Epoch [3/40] Iter[10/312]		Loss: 0.8513
2019-10-28 15:29:20,379 Training Epoch [3/40] Iter[11/312]		Loss: 0.8692
2019-10-28 15:29:20,459 Training Epoch [3/40] Iter[12/312]		Loss: 0.8747
2019-10-28 15:29:20,538 Training Epoch [3/40] Iter[13/312]		Loss: 0.8778
2019-10-28 15:29:20,616 Training Epoch [3/40] Iter[14/312]		Loss: 0.8729
2019-10-28 15:29:20,695 Training Epoch [3/40] Iter[15/312]		Loss: 0.8826
2019-10-28 15:29:20,774 Training Epoch [3/40] Iter[16/312]		Loss: 0.8679
2019-10-28 15:29:20,853 Training Epoch [3/40] Iter[17/312]		Loss: 0.8540
2019-10-28 15:29:20,932 Training Epoch [3/40] Iter[18/312]		Loss: 0.8429
2019-10-28 15:29:21,011 Training Epoch [3/40] Iter[19/312]		Loss: 0.8447
2019-10-28 15:29:21,096 Training Epoch [3/40] Iter[20/312]		Loss: 0.8418
2019-10-28 15:29:21,176 Training Epoch [3/40] Iter[21/312]		Loss: 0.8403
2019-10-28 15:29:21,255 Training Epoch [3/40] Iter[22/312]		Loss: 0.8497
2019-10-28 15:29:21,334 Training Epoch [3/40] Iter[23/312]		Loss: 0.8430
2019-10-28 15:29:21,413 Training Epoch [3/40] Iter[24/312]		Loss: 0.8395
2019-10-28 15:29:21,491 Training Epoch [3/40] Iter[25/312]		Loss: 0.8381
2019-10-28 15:29:21,570 Training Epoch [3/40] Iter[26/312]		Loss: 0.8339
2019-10-28 15:29:21,649 Training Epoch [3/40] Iter[27/312]		Loss: 0.8350
2019-10-28 15:29:21,728 Training Epoch [3/40] Iter[28/312]		Loss: 0.8343
2019-10-28 15:29:21,807 Training Epoch [3/40] Iter[29/312]		Loss: 0.8278
2019-10-28 15:29:21,886 Training Epoch [3/40] Iter[30/312]		Loss: 0.8269
2019-10-28 15:29:21,965 Training Epoch [3/40] Iter[31/312]		Loss: 0.8294
2019-10-28 15:29:22,043 Training Epoch [3/40] Iter[32/312]		Loss: 0.8263
2019-10-28 15:29:22,122 Training Epoch [3/40] Iter[33/312]		Loss: 0.8290
2019-10-28 15:29:22,201 Training Epoch [3/40] Iter[34/312]		Loss: 0.8272
2019-10-28 15:29:22,280 Training Epoch [3/40] Iter[35/312]		Loss: 0.8315
2019-10-28 15:29:22,359 Training Epoch [3/40] Iter[36/312]		Loss: 0.8224
2019-10-28 15:29:22,438 Training Epoch [3/40] Iter[37/312]		Loss: 0.8195
2019-10-28 15:29:22,517 Training Epoch [3/40] Iter[38/312]		Loss: 0.8140
2019-10-28 15:29:22,596 Training Epoch [3/40] Iter[39/312]		Loss: 0.8129
2019-10-28 15:29:22,675 Training Epoch [3/40] Iter[40/312]		Loss: 0.8108
2019-10-28 15:29:22,753 Training Epoch [3/40] Iter[41/312]		Loss: 0.8113
2019-10-28 15:29:22,832 Training Epoch [3/40] Iter[42/312]		Loss: 0.8132
2019-10-28 15:29:22,911 Training Epoch [3/40] Iter[43/312]		Loss: 0.8135
2019-10-28 15:29:22,990 Training Epoch [3/40] Iter[44/312]		Loss: 0.8119
2019-10-28 15:29:23,068 Training Epoch [3/40] Iter[45/312]		Loss: 0.8097
2019-10-28 15:29:23,147 Training Epoch [3/40] Iter[46/312]		Loss: 0.8064
2019-10-28 15:29:23,226 Training Epoch [3/40] Iter[47/312]		Loss: 0.8083
2019-10-28 15:29:23,305 Training Epoch [3/40] Iter[48/312]		Loss: 0.8029
2019-10-28 15:29:23,384 Training Epoch [3/40] Iter[49/312]		Loss: 0.8031
2019-10-28 15:29:23,463 Training Epoch [3/40] Iter[50/312]		Loss: 0.8020
2019-10-28 15:29:23,542 Training Epoch [3/40] Iter[51/312]		Loss: 0.8009
2019-10-28 15:29:23,620 Training Epoch [3/40] Iter[52/312]		Loss: 0.8056
2019-10-28 15:29:23,699 Training Epoch [3/40] Iter[53/312]		Loss: 0.8040
2019-10-28 15:29:23,778 Training Epoch [3/40] Iter[54/312]		Loss: 0.8029
2019-10-28 15:29:23,857 Training Epoch [3/40] Iter[55/312]		Loss: 0.8033
2019-10-28 15:29:23,936 Training Epoch [3/40] Iter[56/312]		Loss: 0.8061
2019-10-28 15:29:24,015 Training Epoch [3/40] Iter[57/312]		Loss: 0.8048
2019-10-28 15:29:24,094 Training Epoch [3/40] Iter[58/312]		Loss: 0.8014
2019-10-28 15:29:24,173 Training Epoch [3/40] Iter[59/312]		Loss: 0.8063
2019-10-28 15:29:24,252 Training Epoch [3/40] Iter[60/312]		Loss: 0.8040
2019-10-28 15:29:24,331 Training Epoch [3/40] Iter[61/312]		Loss: 0.8008
2019-10-28 15:29:24,410 Training Epoch [3/40] Iter[62/312]		Loss: 0.8009
2019-10-28 15:29:24,489 Training Epoch [3/40] Iter[63/312]		Loss: 0.8036
2019-10-28 15:29:24,568 Training Epoch [3/40] Iter[64/312]		Loss: 0.8036
2019-10-28 15:29:24,647 Training Epoch [3/40] Iter[65/312]		Loss: 0.8056
2019-10-28 15:29:24,726 Training Epoch [3/40] Iter[66/312]		Loss: 0.8048
2019-10-28 15:29:24,804 Training Epoch [3/40] Iter[67/312]		Loss: 0.8041
2019-10-28 15:29:24,883 Training Epoch [3/40] Iter[68/312]		Loss: 0.8047
2019-10-28 15:29:24,962 Training Epoch [3/40] Iter[69/312]		Loss: 0.8044
2019-10-28 15:29:25,041 Training Epoch [3/40] Iter[70/312]		Loss: 0.8027
2019-10-28 15:29:25,119 Training Epoch [3/40] Iter[71/312]		Loss: 0.8019
2019-10-28 15:29:25,204 Training Epoch [3/40] Iter[72/312]		Loss: 0.8000
2019-10-28 15:29:25,287 Training Epoch [3/40] Iter[73/312]		Loss: 0.8010
2019-10-28 15:29:25,371 Training Epoch [3/40] Iter[74/312]		Loss: 0.8024
2019-10-28 15:29:25,451 Training Epoch [3/40] Iter[75/312]		Loss: 0.8031
2019-10-28 15:29:25,529 Training Epoch [3/40] Iter[76/312]		Loss: 0.8015
2019-10-28 15:29:25,608 Training Epoch [3/40] Iter[77/312]		Loss: 0.8016
2019-10-28 15:29:25,687 Training Epoch [3/40] Iter[78/312]		Loss: 0.8004
2019-10-28 15:29:25,766 Training Epoch [3/40] Iter[79/312]		Loss: 0.7983
2019-10-28 15:29:25,845 Training Epoch [3/40] Iter[80/312]		Loss: 0.7983
2019-10-28 15:29:25,925 Training Epoch [3/40] Iter[81/312]		Loss: 0.7972
2019-10-28 15:29:26,006 Training Epoch [3/40] Iter[82/312]		Loss: 0.7975
2019-10-28 15:29:26,085 Training Epoch [3/40] Iter[83/312]		Loss: 0.7973
2019-10-28 15:29:26,165 Training Epoch [3/40] Iter[84/312]		Loss: 0.7970
2019-10-28 15:29:26,247 Training Epoch [3/40] Iter[85/312]		Loss: 0.7962
2019-10-28 15:29:26,326 Training Epoch [3/40] Iter[86/312]		Loss: 0.7939
2019-10-28 15:29:26,405 Training Epoch [3/40] Iter[87/312]		Loss: 0.7938
2019-10-28 15:29:26,490 Training Epoch [3/40] Iter[88/312]		Loss: 0.7915
2019-10-28 15:29:26,569 Training Epoch [3/40] Iter[89/312]		Loss: 0.7934
2019-10-28 15:29:26,651 Training Epoch [3/40] Iter[90/312]		Loss: 0.7920
2019-10-28 15:29:26,735 Training Epoch [3/40] Iter[91/312]		Loss: 0.7938
2019-10-28 15:29:26,814 Training Epoch [3/40] Iter[92/312]		Loss: 0.7926
2019-10-28 15:29:26,894 Training Epoch [3/40] Iter[93/312]		Loss: 0.7908
2019-10-28 15:29:26,974 Training Epoch [3/40] Iter[94/312]		Loss: 0.7897
2019-10-28 15:29:27,059 Training Epoch [3/40] Iter[95/312]		Loss: 0.7904
2019-10-28 15:29:27,143 Training Epoch [3/40] Iter[96/312]		Loss: 0.7897
2019-10-28 15:29:27,226 Training Epoch [3/40] Iter[97/312]		Loss: 0.7891
2019-10-28 15:29:27,305 Training Epoch [3/40] Iter[98/312]		Loss: 0.7901
2019-10-28 15:29:27,390 Training Epoch [3/40] Iter[99/312]		Loss: 0.7895
2019-10-28 15:29:27,475 Training Epoch [3/40] Iter[100/312]		Loss: 0.7890
2019-10-28 15:29:27,554 Training Epoch [3/40] Iter[101/312]		Loss: 0.7891
2019-10-28 15:29:27,638 Training Epoch [3/40] Iter[102/312]		Loss: 0.7884
2019-10-28 15:29:27,717 Training Epoch [3/40] Iter[103/312]		Loss: 0.7903
2019-10-28 15:29:27,796 Training Epoch [3/40] Iter[104/312]		Loss: 0.7903
2019-10-28 15:29:27,875 Training Epoch [3/40] Iter[105/312]		Loss: 0.7904
2019-10-28 15:29:27,958 Training Epoch [3/40] Iter[106/312]		Loss: 0.7895
2019-10-28 15:29:28,042 Training Epoch [3/40] Iter[107/312]		Loss: 0.7892
2019-10-28 15:29:28,127 Training Epoch [3/40] Iter[108/312]		Loss: 0.7898
2019-10-28 15:29:28,211 Training Epoch [3/40] Iter[109/312]		Loss: 0.7908
2019-10-28 15:29:28,290 Training Epoch [3/40] Iter[110/312]		Loss: 0.7900
2019-10-28 15:29:28,375 Training Epoch [3/40] Iter[111/312]		Loss: 0.7894
2019-10-28 15:29:28,458 Training Epoch [3/40] Iter[112/312]		Loss: 0.7888
2019-10-28 15:29:28,537 Training Epoch [3/40] Iter[113/312]		Loss: 0.7875
2019-10-28 15:29:28,616 Training Epoch [3/40] Iter[114/312]		Loss: 0.7862
2019-10-28 15:29:28,695 Training Epoch [3/40] Iter[115/312]		Loss: 0.7862
2019-10-28 15:29:28,774 Training Epoch [3/40] Iter[116/312]		Loss: 0.7867
2019-10-28 15:29:28,853 Training Epoch [3/40] Iter[117/312]		Loss: 0.7875
2019-10-28 15:29:28,932 Training Epoch [3/40] Iter[118/312]		Loss: 0.7863
2019-10-28 15:29:29,012 Training Epoch [3/40] Iter[119/312]		Loss: 0.7867
2019-10-28 15:29:29,091 Training Epoch [3/40] Iter[120/312]		Loss: 0.7889
2019-10-28 15:29:29,170 Training Epoch [3/40] Iter[121/312]		Loss: 0.7876
2019-10-28 15:29:29,249 Training Epoch [3/40] Iter[122/312]		Loss: 0.7872
2019-10-28 15:29:29,328 Training Epoch [3/40] Iter[123/312]		Loss: 0.7885
2019-10-28 15:29:29,407 Training Epoch [3/40] Iter[124/312]		Loss: 0.7890
2019-10-28 15:29:29,486 Training Epoch [3/40] Iter[125/312]		Loss: 0.7910
2019-10-28 15:29:29,565 Training Epoch [3/40] Iter[126/312]		Loss: 0.7906
2019-10-28 15:29:29,644 Training Epoch [3/40] Iter[127/312]		Loss: 0.7914
2019-10-28 15:29:29,723 Training Epoch [3/40] Iter[128/312]		Loss: 0.7923
2019-10-28 15:29:29,802 Training Epoch [3/40] Iter[129/312]		Loss: 0.7928
2019-10-28 15:29:29,881 Training Epoch [3/40] Iter[130/312]		Loss: 0.7917
2019-10-28 15:29:29,960 Training Epoch [3/40] Iter[131/312]		Loss: 0.7936
2019-10-28 15:29:30,039 Training Epoch [3/40] Iter[132/312]		Loss: 0.7918
2019-10-28 15:29:30,118 Training Epoch [3/40] Iter[133/312]		Loss: 0.7906
2019-10-28 15:29:30,197 Training Epoch [3/40] Iter[134/312]		Loss: 0.7905
2019-10-28 15:29:30,276 Training Epoch [3/40] Iter[135/312]		Loss: 0.7907
2019-10-28 15:29:30,355 Training Epoch [3/40] Iter[136/312]		Loss: 0.7920
2019-10-28 15:29:30,434 Training Epoch [3/40] Iter[137/312]		Loss: 0.7910
2019-10-28 15:29:30,513 Training Epoch [3/40] Iter[138/312]		Loss: 0.7905
2019-10-28 15:29:30,592 Training Epoch [3/40] Iter[139/312]		Loss: 0.7895
2019-10-28 15:29:30,671 Training Epoch [3/40] Iter[140/312]		Loss: 0.7901
2019-10-28 15:29:30,750 Training Epoch [3/40] Iter[141/312]		Loss: 0.7908
2019-10-28 15:29:30,829 Training Epoch [3/40] Iter[142/312]		Loss: 0.7898
2019-10-28 15:29:30,908 Training Epoch [3/40] Iter[143/312]		Loss: 0.7885
2019-10-28 15:29:30,987 Training Epoch [3/40] Iter[144/312]		Loss: 0.7891
2019-10-28 15:29:31,066 Training Epoch [3/40] Iter[145/312]		Loss: 0.7880
2019-10-28 15:29:31,145 Training Epoch [3/40] Iter[146/312]		Loss: 0.7879
2019-10-28 15:29:31,224 Training Epoch [3/40] Iter[147/312]		Loss: 0.7877
2019-10-28 15:29:31,303 Training Epoch [3/40] Iter[148/312]		Loss: 0.7880
2019-10-28 15:29:31,382 Training Epoch [3/40] Iter[149/312]		Loss: 0.7878
2019-10-28 15:29:31,461 Training Epoch [3/40] Iter[150/312]		Loss: 0.7873
2019-10-28 15:29:31,540 Training Epoch [3/40] Iter[151/312]		Loss: 0.7864
2019-10-28 15:29:31,619 Training Epoch [3/40] Iter[152/312]		Loss: 0.7863
2019-10-28 15:29:31,698 Training Epoch [3/40] Iter[153/312]		Loss: 0.7856
2019-10-28 15:29:31,777 Training Epoch [3/40] Iter[154/312]		Loss: 0.7846
2019-10-28 15:29:31,856 Training Epoch [3/40] Iter[155/312]		Loss: 0.7840
2019-10-28 15:29:31,935 Training Epoch [3/40] Iter[156/312]		Loss: 0.7838
2019-10-28 15:29:32,014 Training Epoch [3/40] Iter[157/312]		Loss: 0.7822
2019-10-28 15:29:32,093 Training Epoch [3/40] Iter[158/312]		Loss: 0.7816
2019-10-28 15:29:32,172 Training Epoch [3/40] Iter[159/312]		Loss: 0.7804
2019-10-28 15:29:32,251 Training Epoch [3/40] Iter[160/312]		Loss: 0.7798
2019-10-28 15:29:32,330 Training Epoch [3/40] Iter[161/312]		Loss: 0.7793
2019-10-28 15:29:32,409 Training Epoch [3/40] Iter[162/312]		Loss: 0.7787
2019-10-28 15:29:32,488 Training Epoch [3/40] Iter[163/312]		Loss: 0.7783
2019-10-28 15:29:32,567 Training Epoch [3/40] Iter[164/312]		Loss: 0.7784
2019-10-28 15:29:32,646 Training Epoch [3/40] Iter[165/312]		Loss: 0.7802
2019-10-28 15:29:32,725 Training Epoch [3/40] Iter[166/312]		Loss: 0.7802
2019-10-28 15:29:32,804 Training Epoch [3/40] Iter[167/312]		Loss: 0.7793
2019-10-28 15:29:32,883 Training Epoch [3/40] Iter[168/312]		Loss: 0.7784
2019-10-28 15:29:32,962 Training Epoch [3/40] Iter[169/312]		Loss: 0.7773
2019-10-28 15:29:33,041 Training Epoch [3/40] Iter[170/312]		Loss: 0.7757
2019-10-28 15:29:33,120 Training Epoch [3/40] Iter[171/312]		Loss: 0.7746
2019-10-28 15:29:33,199 Training Epoch [3/40] Iter[172/312]		Loss: 0.7746
2019-10-28 15:29:33,278 Training Epoch [3/40] Iter[173/312]		Loss: 0.7744
2019-10-28 15:29:33,356 Training Epoch [3/40] Iter[174/312]		Loss: 0.7742
2019-10-28 15:29:33,436 Training Epoch [3/40] Iter[175/312]		Loss: 0.7746
2019-10-28 15:29:33,515 Training Epoch [3/40] Iter[176/312]		Loss: 0.7747
2019-10-28 15:29:33,594 Training Epoch [3/40] Iter[177/312]		Loss: 0.7739
2019-10-28 15:29:33,673 Training Epoch [3/40] Iter[178/312]		Loss: 0.7735
2019-10-28 15:29:33,753 Training Epoch [3/40] Iter[179/312]		Loss: 0.7736
2019-10-28 15:29:33,832 Training Epoch [3/40] Iter[180/312]		Loss: 0.7731
2019-10-28 15:29:33,911 Training Epoch [3/40] Iter[181/312]		Loss: 0.7729
2019-10-28 15:29:33,990 Training Epoch [3/40] Iter[182/312]		Loss: 0.7736
2019-10-28 15:29:34,069 Training Epoch [3/40] Iter[183/312]		Loss: 0.7731
2019-10-28 15:29:34,149 Training Epoch [3/40] Iter[184/312]		Loss: 0.7728
2019-10-28 15:29:34,228 Training Epoch [3/40] Iter[185/312]		Loss: 0.7724
2019-10-28 15:29:34,307 Training Epoch [3/40] Iter[186/312]		Loss: 0.7716
2019-10-28 15:29:34,386 Training Epoch [3/40] Iter[187/312]		Loss: 0.7719
2019-10-28 15:29:34,466 Training Epoch [3/40] Iter[188/312]		Loss: 0.7723
2019-10-28 15:29:34,545 Training Epoch [3/40] Iter[189/312]		Loss: 0.7723
2019-10-28 15:29:34,624 Training Epoch [3/40] Iter[190/312]		Loss: 0.7723
2019-10-28 15:29:34,704 Training Epoch [3/40] Iter[191/312]		Loss: 0.7724
2019-10-28 15:29:34,783 Training Epoch [3/40] Iter[192/312]		Loss: 0.7715
2019-10-28 15:29:34,862 Training Epoch [3/40] Iter[193/312]		Loss: 0.7719
2019-10-28 15:29:34,941 Training Epoch [3/40] Iter[194/312]		Loss: 0.7713
2019-10-28 15:29:35,020 Training Epoch [3/40] Iter[195/312]		Loss: 0.7700
2019-10-28 15:29:35,099 Training Epoch [3/40] Iter[196/312]		Loss: 0.7693
2019-10-28 15:29:35,178 Training Epoch [3/40] Iter[197/312]		Loss: 0.7696
2019-10-28 15:29:35,257 Training Epoch [3/40] Iter[198/312]		Loss: 0.7698
2019-10-28 15:29:35,336 Training Epoch [3/40] Iter[199/312]		Loss: 0.7695
2019-10-28 15:29:35,415 Training Epoch [3/40] Iter[200/312]		Loss: 0.7689
2019-10-28 15:29:35,494 Training Epoch [3/40] Iter[201/312]		Loss: 0.7682
2019-10-28 15:29:35,573 Training Epoch [3/40] Iter[202/312]		Loss: 0.7675
2019-10-28 15:29:35,652 Training Epoch [3/40] Iter[203/312]		Loss: 0.7669
2019-10-28 15:29:35,736 Training Epoch [3/40] Iter[204/312]		Loss: 0.7660
2019-10-28 15:29:35,815 Training Epoch [3/40] Iter[205/312]		Loss: 0.7654
2019-10-28 15:29:35,894 Training Epoch [3/40] Iter[206/312]		Loss: 0.7658
2019-10-28 15:29:35,973 Training Epoch [3/40] Iter[207/312]		Loss: 0.7647
2019-10-28 15:29:36,052 Training Epoch [3/40] Iter[208/312]		Loss: 0.7650
2019-10-28 15:29:36,131 Training Epoch [3/40] Iter[209/312]		Loss: 0.7645
2019-10-28 15:29:36,210 Training Epoch [3/40] Iter[210/312]		Loss: 0.7639
2019-10-28 15:29:36,290 Training Epoch [3/40] Iter[211/312]		Loss: 0.7647
2019-10-28 15:29:36,369 Training Epoch [3/40] Iter[212/312]		Loss: 0.7639
2019-10-28 15:29:36,448 Training Epoch [3/40] Iter[213/312]		Loss: 0.7638
2019-10-28 15:29:36,527 Training Epoch [3/40] Iter[214/312]		Loss: 0.7633
2019-10-28 15:29:36,606 Training Epoch [3/40] Iter[215/312]		Loss: 0.7634
2019-10-28 15:29:36,684 Training Epoch [3/40] Iter[216/312]		Loss: 0.7626
2019-10-28 15:29:36,763 Training Epoch [3/40] Iter[217/312]		Loss: 0.7620
2019-10-28 15:29:36,842 Training Epoch [3/40] Iter[218/312]		Loss: 0.7621
2019-10-28 15:29:36,921 Training Epoch [3/40] Iter[219/312]		Loss: 0.7622
2019-10-28 15:29:37,000 Training Epoch [3/40] Iter[220/312]		Loss: 0.7621
2019-10-28 15:29:37,079 Training Epoch [3/40] Iter[221/312]		Loss: 0.7614
2019-10-28 15:29:37,158 Training Epoch [3/40] Iter[222/312]		Loss: 0.7610
2019-10-28 15:29:37,237 Training Epoch [3/40] Iter[223/312]		Loss: 0.7599
2019-10-28 15:29:37,316 Training Epoch [3/40] Iter[224/312]		Loss: 0.7600
2019-10-28 15:29:37,395 Training Epoch [3/40] Iter[225/312]		Loss: 0.7590
2019-10-28 15:29:37,474 Training Epoch [3/40] Iter[226/312]		Loss: 0.7583
2019-10-28 15:29:37,553 Training Epoch [3/40] Iter[227/312]		Loss: 0.7580
2019-10-28 15:29:37,632 Training Epoch [3/40] Iter[228/312]		Loss: 0.7586
2019-10-28 15:29:37,711 Training Epoch [3/40] Iter[229/312]		Loss: 0.7580
2019-10-28 15:29:37,790 Training Epoch [3/40] Iter[230/312]		Loss: 0.7572
2019-10-28 15:29:37,868 Training Epoch [3/40] Iter[231/312]		Loss: 0.7570
2019-10-28 15:29:37,948 Training Epoch [3/40] Iter[232/312]		Loss: 0.7560
2019-10-28 15:29:38,027 Training Epoch [3/40] Iter[233/312]		Loss: 0.7555
2019-10-28 15:29:38,106 Training Epoch [3/40] Iter[234/312]		Loss: 0.7559
2019-10-28 15:29:38,185 Training Epoch [3/40] Iter[235/312]		Loss: 0.7554
2019-10-28 15:29:38,264 Training Epoch [3/40] Iter[236/312]		Loss: 0.7558
2019-10-28 15:29:38,343 Training Epoch [3/40] Iter[237/312]		Loss: 0.7555
2019-10-28 15:29:38,422 Training Epoch [3/40] Iter[238/312]		Loss: 0.7545
2019-10-28 15:29:38,501 Training Epoch [3/40] Iter[239/312]		Loss: 0.7548
2019-10-28 15:29:38,580 Training Epoch [3/40] Iter[240/312]		Loss: 0.7556
2019-10-28 15:29:38,659 Training Epoch [3/40] Iter[241/312]		Loss: 0.7560
2019-10-28 15:29:38,739 Training Epoch [3/40] Iter[242/312]		Loss: 0.7552
2019-10-28 15:29:38,818 Training Epoch [3/40] Iter[243/312]		Loss: 0.7545
2019-10-28 15:29:38,896 Training Epoch [3/40] Iter[244/312]		Loss: 0.7539
2019-10-28 15:29:38,975 Training Epoch [3/40] Iter[245/312]		Loss: 0.7534
2019-10-28 15:29:39,054 Training Epoch [3/40] Iter[246/312]		Loss: 0.7533
2019-10-28 15:29:39,133 Training Epoch [3/40] Iter[247/312]		Loss: 0.7528
2019-10-28 15:29:39,212 Training Epoch [3/40] Iter[248/312]		Loss: 0.7526
2019-10-28 15:29:39,291 Training Epoch [3/40] Iter[249/312]		Loss: 0.7525
2019-10-28 15:29:39,370 Training Epoch [3/40] Iter[250/312]		Loss: 0.7531
2019-10-28 15:29:39,449 Training Epoch [3/40] Iter[251/312]		Loss: 0.7531
2019-10-28 15:29:39,528 Training Epoch [3/40] Iter[252/312]		Loss: 0.7529
2019-10-28 15:29:39,607 Training Epoch [3/40] Iter[253/312]		Loss: 0.7532
2019-10-28 15:29:39,686 Training Epoch [3/40] Iter[254/312]		Loss: 0.7525
2019-10-28 15:29:39,765 Training Epoch [3/40] Iter[255/312]		Loss: 0.7518
2019-10-28 15:29:39,844 Training Epoch [3/40] Iter[256/312]		Loss: 0.7510
2019-10-28 15:29:39,923 Training Epoch [3/40] Iter[257/312]		Loss: 0.7507
2019-10-28 15:29:40,002 Training Epoch [3/40] Iter[258/312]		Loss: 0.7507
2019-10-28 15:29:40,081 Training Epoch [3/40] Iter[259/312]		Loss: 0.7509
2019-10-28 15:29:40,160 Training Epoch [3/40] Iter[260/312]		Loss: 0.7503
2019-10-28 15:29:40,239 Training Epoch [3/40] Iter[261/312]		Loss: 0.7496
2019-10-28 15:29:40,318 Training Epoch [3/40] Iter[262/312]		Loss: 0.7494
2019-10-28 15:29:40,397 Training Epoch [3/40] Iter[263/312]		Loss: 0.7489
2019-10-28 15:29:40,476 Training Epoch [3/40] Iter[264/312]		Loss: 0.7484
2019-10-28 15:29:40,555 Training Epoch [3/40] Iter[265/312]		Loss: 0.7484
2019-10-28 15:29:40,634 Training Epoch [3/40] Iter[266/312]		Loss: 0.7485
2019-10-28 15:29:40,713 Training Epoch [3/40] Iter[267/312]		Loss: 0.7479
2019-10-28 15:29:40,792 Training Epoch [3/40] Iter[268/312]		Loss: 0.7480
2019-10-28 15:29:40,871 Training Epoch [3/40] Iter[269/312]		Loss: 0.7479
2019-10-28 15:29:40,950 Training Epoch [3/40] Iter[270/312]		Loss: 0.7473
2019-10-28 15:29:41,029 Training Epoch [3/40] Iter[271/312]		Loss: 0.7471
2019-10-28 15:29:41,108 Training Epoch [3/40] Iter[272/312]		Loss: 0.7470
2019-10-28 15:29:41,187 Training Epoch [3/40] Iter[273/312]		Loss: 0.7465
2019-10-28 15:29:41,266 Training Epoch [3/40] Iter[274/312]		Loss: 0.7463
2019-10-28 15:29:41,345 Training Epoch [3/40] Iter[275/312]		Loss: 0.7460
2019-10-28 15:29:41,424 Training Epoch [3/40] Iter[276/312]		Loss: 0.7453
2019-10-28 15:29:41,503 Training Epoch [3/40] Iter[277/312]		Loss: 0.7456
2019-10-28 15:29:41,582 Training Epoch [3/40] Iter[278/312]		Loss: 0.7452
2019-10-28 15:29:41,661 Training Epoch [3/40] Iter[279/312]		Loss: 0.7448
2019-10-28 15:29:41,740 Training Epoch [3/40] Iter[280/312]		Loss: 0.7437
2019-10-28 15:29:41,819 Training Epoch [3/40] Iter[281/312]		Loss: 0.7431
2019-10-28 15:29:41,898 Training Epoch [3/40] Iter[282/312]		Loss: 0.7422
2019-10-28 15:29:41,978 Training Epoch [3/40] Iter[283/312]		Loss: 0.7415
2019-10-28 15:29:42,056 Training Epoch [3/40] Iter[284/312]		Loss: 0.7417
2019-10-28 15:29:42,135 Training Epoch [3/40] Iter[285/312]		Loss: 0.7415
2019-10-28 15:29:42,214 Training Epoch [3/40] Iter[286/312]		Loss: 0.7412
2019-10-28 15:29:42,294 Training Epoch [3/40] Iter[287/312]		Loss: 0.7410
2019-10-28 15:29:42,373 Training Epoch [3/40] Iter[288/312]		Loss: 0.7403
2019-10-28 15:29:42,452 Training Epoch [3/40] Iter[289/312]		Loss: 0.7400
2019-10-28 15:29:42,531 Training Epoch [3/40] Iter[290/312]		Loss: 0.7391
2019-10-28 15:29:42,610 Training Epoch [3/40] Iter[291/312]		Loss: 0.7386
2019-10-28 15:29:42,689 Training Epoch [3/40] Iter[292/312]		Loss: 0.7382
2019-10-28 15:29:42,768 Training Epoch [3/40] Iter[293/312]		Loss: 0.7381
2019-10-28 15:29:42,847 Training Epoch [3/40] Iter[294/312]		Loss: 0.7380
2019-10-28 15:29:42,926 Training Epoch [3/40] Iter[295/312]		Loss: 0.7374
2019-10-28 15:29:43,005 Training Epoch [3/40] Iter[296/312]		Loss: 0.7366
2019-10-28 15:29:43,084 Training Epoch [3/40] Iter[297/312]		Loss: 0.7360
2019-10-28 15:29:43,163 Training Epoch [3/40] Iter[298/312]		Loss: 0.7356
2019-10-28 15:29:43,241 Training Epoch [3/40] Iter[299/312]		Loss: 0.7349
2019-10-28 15:29:43,320 Training Epoch [3/40] Iter[300/312]		Loss: 0.7357
2019-10-28 15:29:43,399 Training Epoch [3/40] Iter[301/312]		Loss: 0.7353
2019-10-28 15:29:43,478 Training Epoch [3/40] Iter[302/312]		Loss: 0.7349
2019-10-28 15:29:43,558 Training Epoch [3/40] Iter[303/312]		Loss: 0.7352
2019-10-28 15:29:43,637 Training Epoch [3/40] Iter[304/312]		Loss: 0.7348
2019-10-28 15:29:43,715 Training Epoch [3/40] Iter[305/312]		Loss: 0.7345
2019-10-28 15:29:43,794 Training Epoch [3/40] Iter[306/312]		Loss: 0.7349
2019-10-28 15:29:43,872 Training Epoch [3/40] Iter[307/312]		Loss: 0.7348
2019-10-28 15:29:43,950 Training Epoch [3/40] Iter[308/312]		Loss: 0.7340
2019-10-28 15:29:44,028 Training Epoch [3/40] Iter[309/312]		Loss: 0.7337
2019-10-28 15:29:44,106 Training Epoch [3/40] Iter[310/312]		Loss: 0.7332
2019-10-28 15:29:44,184 Training Epoch [3/40] Iter[311/312]		Loss: 0.7326
2019-10-28 15:29:44,222 Training Epoch [3/40] Iter[312/312]		Loss: 0.7323
2019-10-28 15:29:44,521 Testing Epoch [3/40] Iter[0/62]		Loss: 0.7377
2019-10-28 15:29:44,550 Testing Epoch [3/40] Iter[1/62]		Loss: 0.6137
2019-10-28 15:29:44,578 Testing Epoch [3/40] Iter[2/62]		Loss: 0.5800
2019-10-28 15:29:44,654 Testing Epoch [3/40] Iter[3/62]		Loss: 0.5693
2019-10-28 15:29:44,686 Testing Epoch [3/40] Iter[4/62]		Loss: 0.5700
2019-10-28 15:29:44,702 Testing Epoch [3/40] Iter[5/62]		Loss: 0.5459
2019-10-28 15:29:44,721 Testing Epoch [3/40] Iter[6/62]		Loss: 0.5439
2019-10-28 15:29:44,786 Testing Epoch [3/40] Iter[7/62]		Loss: 0.5496
2019-10-28 15:29:44,810 Testing Epoch [3/40] Iter[8/62]		Loss: 0.5593
2019-10-28 15:29:44,830 Testing Epoch [3/40] Iter[9/62]		Loss: 0.5612
2019-10-28 15:29:44,857 Testing Epoch [3/40] Iter[10/62]		Loss: 0.5568
2019-10-28 15:29:44,878 Testing Epoch [3/40] Iter[11/62]		Loss: 0.5648
2019-10-28 15:29:44,895 Testing Epoch [3/40] Iter[12/62]		Loss: 0.5662
2019-10-28 15:29:44,928 Testing Epoch [3/40] Iter[13/62]		Loss: 0.5711
2019-10-28 15:29:44,949 Testing Epoch [3/40] Iter[14/62]		Loss: 0.6098
2019-10-28 15:29:44,973 Testing Epoch [3/40] Iter[15/62]		Loss: 0.6081
2019-10-28 15:29:44,998 Testing Epoch [3/40] Iter[16/62]		Loss: 0.6120
2019-10-28 15:29:45,015 Testing Epoch [3/40] Iter[17/62]		Loss: 0.6090
2019-10-28 15:29:45,046 Testing Epoch [3/40] Iter[18/62]		Loss: 0.6022
2019-10-28 15:29:45,065 Testing Epoch [3/40] Iter[19/62]		Loss: 0.6028
2019-10-28 15:29:45,089 Testing Epoch [3/40] Iter[20/62]		Loss: 0.6126
2019-10-28 15:29:45,107 Testing Epoch [3/40] Iter[21/62]		Loss: 0.6073
2019-10-28 15:29:45,134 Testing Epoch [3/40] Iter[22/62]		Loss: 0.6169
2019-10-28 15:29:45,151 Testing Epoch [3/40] Iter[23/62]		Loss: 0.6185
2019-10-28 15:29:45,181 Testing Epoch [3/40] Iter[24/62]		Loss: 0.6245
2019-10-28 15:29:45,199 Testing Epoch [3/40] Iter[25/62]		Loss: 0.6235
2019-10-28 15:29:45,224 Testing Epoch [3/40] Iter[26/62]		Loss: 0.6175
2019-10-28 15:29:45,241 Testing Epoch [3/40] Iter[27/62]		Loss: 0.6333
2019-10-28 15:29:45,259 Testing Epoch [3/40] Iter[28/62]		Loss: 0.6358
2019-10-28 15:29:45,290 Testing Epoch [3/40] Iter[29/62]		Loss: 0.6371
2019-10-28 15:29:45,330 Testing Epoch [3/40] Iter[30/62]		Loss: 0.6325
2019-10-28 15:29:45,348 Testing Epoch [3/40] Iter[31/62]		Loss: 0.6340
2019-10-28 15:29:45,371 Testing Epoch [3/40] Iter[32/62]		Loss: 0.6344
2019-10-28 15:29:45,398 Testing Epoch [3/40] Iter[33/62]		Loss: 0.6311
2019-10-28 15:29:45,423 Testing Epoch [3/40] Iter[34/62]		Loss: 0.6326
2019-10-28 15:29:45,443 Testing Epoch [3/40] Iter[35/62]		Loss: 0.6343
2019-10-28 15:29:45,464 Testing Epoch [3/40] Iter[36/62]		Loss: 0.6320
2019-10-28 15:29:45,481 Testing Epoch [3/40] Iter[37/62]		Loss: 0.6338
2019-10-28 15:29:45,506 Testing Epoch [3/40] Iter[38/62]		Loss: 0.6327
2019-10-28 15:29:45,524 Testing Epoch [3/40] Iter[39/62]		Loss: 0.6364
2019-10-28 15:29:45,544 Testing Epoch [3/40] Iter[40/62]		Loss: 0.6402
2019-10-28 15:29:45,570 Testing Epoch [3/40] Iter[41/62]		Loss: 0.6407
2019-10-28 15:29:45,598 Testing Epoch [3/40] Iter[42/62]		Loss: 0.6391
2019-10-28 15:29:45,616 Testing Epoch [3/40] Iter[43/62]		Loss: 0.6397
2019-10-28 15:29:45,645 Testing Epoch [3/40] Iter[44/62]		Loss: 0.6365
2019-10-28 15:29:45,664 Testing Epoch [3/40] Iter[45/62]		Loss: 0.6381
2019-10-28 15:29:45,686 Testing Epoch [3/40] Iter[46/62]		Loss: 0.6379
2019-10-28 15:29:45,717 Testing Epoch [3/40] Iter[47/62]		Loss: 0.6419
2019-10-28 15:29:45,735 Testing Epoch [3/40] Iter[48/62]		Loss: 0.6381
2019-10-28 15:29:45,761 Testing Epoch [3/40] Iter[49/62]		Loss: 0.6409
2019-10-28 15:29:45,779 Testing Epoch [3/40] Iter[50/62]		Loss: 0.6393
2019-10-28 15:29:45,806 Testing Epoch [3/40] Iter[51/62]		Loss: 0.6404
2019-10-28 15:29:45,824 Testing Epoch [3/40] Iter[52/62]		Loss: 0.6398
2019-10-28 15:29:45,853 Testing Epoch [3/40] Iter[53/62]		Loss: 0.6404
2019-10-28 15:29:45,880 Testing Epoch [3/40] Iter[54/62]		Loss: 0.6372
2019-10-28 15:29:45,896 Testing Epoch [3/40] Iter[55/62]		Loss: 0.6367
2019-10-28 15:29:45,913 Testing Epoch [3/40] Iter[56/62]		Loss: 0.6352
2019-10-28 15:29:45,930 Testing Epoch [3/40] Iter[57/62]		Loss: 0.6386
2019-10-28 15:29:45,946 Testing Epoch [3/40] Iter[58/62]		Loss: 0.6358
2019-10-28 15:29:45,963 Testing Epoch [3/40] Iter[59/62]		Loss: 0.6371
2019-10-28 15:29:45,979 Testing Epoch [3/40] Iter[60/62]		Loss: 0.6374
2019-10-28 15:29:45,996 Testing Epoch [3/40] Iter[61/62]		Loss: 0.6391
2019-10-28 15:29:46,005 Testing Epoch [3/40] Iter[62/62]		Loss: 0.6419
2019-10-28 15:29:46,079 Saving the Model
2019-10-28 15:29:46,383 Training Epoch [4/40] Iter[0/312]		Loss: 0.7419
2019-10-28 15:29:46,480 Training Epoch [4/40] Iter[1/312]		Loss: 0.7307
2019-10-28 15:29:46,575 Training Epoch [4/40] Iter[2/312]		Loss: 0.6587
2019-10-28 15:29:46,656 Training Epoch [4/40] Iter[3/312]		Loss: 0.7409
2019-10-28 15:29:46,734 Training Epoch [4/40] Iter[4/312]		Loss: 0.7135
2019-10-28 15:29:46,813 Training Epoch [4/40] Iter[5/312]		Loss: 0.6894
2019-10-28 15:29:46,895 Training Epoch [4/40] Iter[6/312]		Loss: 0.6611
2019-10-28 15:29:46,975 Training Epoch [4/40] Iter[7/312]		Loss: 0.6582
2019-10-28 15:29:47,055 Training Epoch [4/40] Iter[8/312]		Loss: 0.6471
2019-10-28 15:29:47,133 Training Epoch [4/40] Iter[9/312]		Loss: 0.6408
2019-10-28 15:29:47,211 Training Epoch [4/40] Iter[10/312]		Loss: 0.6371
2019-10-28 15:29:47,290 Training Epoch [4/40] Iter[11/312]		Loss: 0.6450
2019-10-28 15:29:47,369 Training Epoch [4/40] Iter[12/312]		Loss: 0.6401
2019-10-28 15:29:47,448 Training Epoch [4/40] Iter[13/312]		Loss: 0.6356
2019-10-28 15:29:47,527 Training Epoch [4/40] Iter[14/312]		Loss: 0.6220
2019-10-28 15:29:47,606 Training Epoch [4/40] Iter[15/312]		Loss: 0.6205
2019-10-28 15:29:47,685 Training Epoch [4/40] Iter[16/312]		Loss: 0.6083
2019-10-28 15:29:47,763 Training Epoch [4/40] Iter[17/312]		Loss: 0.6138
2019-10-28 15:29:47,842 Training Epoch [4/40] Iter[18/312]		Loss: 0.6149
2019-10-28 15:29:47,921 Training Epoch [4/40] Iter[19/312]		Loss: 0.6134
2019-10-28 15:29:47,999 Training Epoch [4/40] Iter[20/312]		Loss: 0.6176
2019-10-28 15:29:48,078 Training Epoch [4/40] Iter[21/312]		Loss: 0.6176
2019-10-28 15:29:48,157 Training Epoch [4/40] Iter[22/312]		Loss: 0.6169
2019-10-28 15:29:48,236 Training Epoch [4/40] Iter[23/312]		Loss: 0.6231
2019-10-28 15:29:48,315 Training Epoch [4/40] Iter[24/312]		Loss: 0.6181
2019-10-28 15:29:48,393 Training Epoch [4/40] Iter[25/312]		Loss: 0.6257
2019-10-28 15:29:48,472 Training Epoch [4/40] Iter[26/312]		Loss: 0.6234
2019-10-28 15:29:48,552 Training Epoch [4/40] Iter[27/312]		Loss: 0.6188
2019-10-28 15:29:48,630 Training Epoch [4/40] Iter[28/312]		Loss: 0.6180
2019-10-28 15:29:48,709 Training Epoch [4/40] Iter[29/312]		Loss: 0.6234
2019-10-28 15:29:48,788 Training Epoch [4/40] Iter[30/312]		Loss: 0.6173
2019-10-28 15:29:48,867 Training Epoch [4/40] Iter[31/312]		Loss: 0.6232
2019-10-28 15:29:48,946 Training Epoch [4/40] Iter[32/312]		Loss: 0.6222
2019-10-28 15:29:49,025 Training Epoch [4/40] Iter[33/312]		Loss: 0.6199
2019-10-28 15:29:49,104 Training Epoch [4/40] Iter[34/312]		Loss: 0.6166
2019-10-28 15:29:49,183 Training Epoch [4/40] Iter[35/312]		Loss: 0.6145
2019-10-28 15:29:49,261 Training Epoch [4/40] Iter[36/312]		Loss: 0.6121
2019-10-28 15:29:49,340 Training Epoch [4/40] Iter[37/312]		Loss: 0.6078
2019-10-28 15:29:49,419 Training Epoch [4/40] Iter[38/312]		Loss: 0.6161
2019-10-28 15:29:49,498 Training Epoch [4/40] Iter[39/312]		Loss: 0.6205
2019-10-28 15:29:49,577 Training Epoch [4/40] Iter[40/312]		Loss: 0.6200
2019-10-28 15:29:49,656 Training Epoch [4/40] Iter[41/312]		Loss: 0.6175
2019-10-28 15:29:49,734 Training Epoch [4/40] Iter[42/312]		Loss: 0.6152
2019-10-28 15:29:49,813 Training Epoch [4/40] Iter[43/312]		Loss: 0.6155
2019-10-28 15:29:49,892 Training Epoch [4/40] Iter[44/312]		Loss: 0.6139
2019-10-28 15:29:49,971 Training Epoch [4/40] Iter[45/312]		Loss: 0.6127
2019-10-28 15:29:50,050 Training Epoch [4/40] Iter[46/312]		Loss: 0.6130
2019-10-28 15:29:50,129 Training Epoch [4/40] Iter[47/312]		Loss: 0.6153
2019-10-28 15:29:50,208 Training Epoch [4/40] Iter[48/312]		Loss: 0.6195
2019-10-28 15:29:50,286 Training Epoch [4/40] Iter[49/312]		Loss: 0.6260
2019-10-28 15:29:50,365 Training Epoch [4/40] Iter[50/312]		Loss: 0.6261
2019-10-28 15:29:50,444 Training Epoch [4/40] Iter[51/312]		Loss: 0.6221
2019-10-28 15:29:50,523 Training Epoch [4/40] Iter[52/312]		Loss: 0.6222
2019-10-28 15:29:50,602 Training Epoch [4/40] Iter[53/312]		Loss: 0.6229
2019-10-28 15:29:50,680 Training Epoch [4/40] Iter[54/312]		Loss: 0.6229
2019-10-28 15:29:50,759 Training Epoch [4/40] Iter[55/312]		Loss: 0.6260
2019-10-28 15:29:50,838 Training Epoch [4/40] Iter[56/312]		Loss: 0.6241
2019-10-28 15:29:50,917 Training Epoch [4/40] Iter[57/312]		Loss: 0.6261
2019-10-28 15:29:50,995 Training Epoch [4/40] Iter[58/312]		Loss: 0.6233
2019-10-28 15:29:51,074 Training Epoch [4/40] Iter[59/312]		Loss: 0.6191
2019-10-28 15:29:51,153 Training Epoch [4/40] Iter[60/312]		Loss: 0.6179
2019-10-28 15:29:51,232 Training Epoch [4/40] Iter[61/312]		Loss: 0.6196
2019-10-28 15:29:51,310 Training Epoch [4/40] Iter[62/312]		Loss: 0.6194
2019-10-28 15:29:51,389 Training Epoch [4/40] Iter[63/312]		Loss: 0.6165
2019-10-28 15:29:51,468 Training Epoch [4/40] Iter[64/312]		Loss: 0.6167
2019-10-28 15:29:51,547 Training Epoch [4/40] Iter[65/312]		Loss: 0.6142
2019-10-28 15:29:51,625 Training Epoch [4/40] Iter[66/312]		Loss: 0.6120
2019-10-28 15:29:51,704 Training Epoch [4/40] Iter[67/312]		Loss: 0.6101
2019-10-28 15:29:51,783 Training Epoch [4/40] Iter[68/312]		Loss: 0.6106
2019-10-28 15:29:51,862 Training Epoch [4/40] Iter[69/312]		Loss: 0.6131
2019-10-28 15:29:51,940 Training Epoch [4/40] Iter[70/312]		Loss: 0.6120
2019-10-28 15:29:52,019 Training Epoch [4/40] Iter[71/312]		Loss: 0.6124
2019-10-28 15:29:52,098 Training Epoch [4/40] Iter[72/312]		Loss: 0.6099
2019-10-28 15:29:52,176 Training Epoch [4/40] Iter[73/312]		Loss: 0.6135
2019-10-28 15:29:52,255 Training Epoch [4/40] Iter[74/312]		Loss: 0.6123
2019-10-28 15:29:52,334 Training Epoch [4/40] Iter[75/312]		Loss: 0.6098
2019-10-28 15:29:52,413 Training Epoch [4/40] Iter[76/312]		Loss: 0.6077
2019-10-28 15:29:52,491 Training Epoch [4/40] Iter[77/312]		Loss: 0.6046
2019-10-28 15:29:52,570 Training Epoch [4/40] Iter[78/312]		Loss: 0.6066
2019-10-28 15:29:52,649 Training Epoch [4/40] Iter[79/312]		Loss: 0.6063
2019-10-28 15:29:52,728 Training Epoch [4/40] Iter[80/312]		Loss: 0.6073
2019-10-28 15:29:52,806 Training Epoch [4/40] Iter[81/312]		Loss: 0.6077
2019-10-28 15:29:52,885 Training Epoch [4/40] Iter[82/312]		Loss: 0.6081
2019-10-28 15:29:52,964 Training Epoch [4/40] Iter[83/312]		Loss: 0.6089
2019-10-28 15:29:53,043 Training Epoch [4/40] Iter[84/312]		Loss: 0.6083
2019-10-28 15:29:53,122 Training Epoch [4/40] Iter[85/312]		Loss: 0.6085
2019-10-28 15:29:53,201 Training Epoch [4/40] Iter[86/312]		Loss: 0.6081
2019-10-28 15:29:53,280 Training Epoch [4/40] Iter[87/312]		Loss: 0.6046
2019-10-28 15:29:53,359 Training Epoch [4/40] Iter[88/312]		Loss: 0.6016
2019-10-28 15:29:53,438 Training Epoch [4/40] Iter[89/312]		Loss: 0.6005
2019-10-28 15:29:53,516 Training Epoch [4/40] Iter[90/312]		Loss: 0.5985
2019-10-28 15:29:53,595 Training Epoch [4/40] Iter[91/312]		Loss: 0.5965
2019-10-28 15:29:53,674 Training Epoch [4/40] Iter[92/312]		Loss: 0.5939
2019-10-28 15:29:53,753 Training Epoch [4/40] Iter[93/312]		Loss: 0.5918
2019-10-28 15:29:53,832 Training Epoch [4/40] Iter[94/312]		Loss: 0.5905
2019-10-28 15:29:53,911 Training Epoch [4/40] Iter[95/312]		Loss: 0.5897
2019-10-28 15:29:53,990 Training Epoch [4/40] Iter[96/312]		Loss: 0.5892
2019-10-28 15:29:54,069 Training Epoch [4/40] Iter[97/312]		Loss: 0.5888
2019-10-28 15:29:54,148 Training Epoch [4/40] Iter[98/312]		Loss: 0.5881
2019-10-28 15:29:54,227 Training Epoch [4/40] Iter[99/312]		Loss: 0.5873
2019-10-28 15:29:54,306 Training Epoch [4/40] Iter[100/312]		Loss: 0.5869
2019-10-28 15:29:54,384 Training Epoch [4/40] Iter[101/312]		Loss: 0.5853
2019-10-28 15:29:54,463 Training Epoch [4/40] Iter[102/312]		Loss: 0.5853
2019-10-28 15:29:54,542 Training Epoch [4/40] Iter[103/312]		Loss: 0.5846
2019-10-28 15:29:54,621 Training Epoch [4/40] Iter[104/312]		Loss: 0.5834
2019-10-28 15:29:54,700 Training Epoch [4/40] Iter[105/312]		Loss: 0.5840
2019-10-28 15:29:54,779 Training Epoch [4/40] Iter[106/312]		Loss: 0.5835
2019-10-28 15:29:54,857 Training Epoch [4/40] Iter[107/312]		Loss: 0.5829
2019-10-28 15:29:54,936 Training Epoch [4/40] Iter[108/312]		Loss: 0.5815
2019-10-28 15:29:55,015 Training Epoch [4/40] Iter[109/312]		Loss: 0.5805
2019-10-28 15:29:55,094 Training Epoch [4/40] Iter[110/312]		Loss: 0.5791
2019-10-28 15:29:55,173 Training Epoch [4/40] Iter[111/312]		Loss: 0.5788
2019-10-28 15:29:55,252 Training Epoch [4/40] Iter[112/312]		Loss: 0.5781
2019-10-28 15:29:55,331 Training Epoch [4/40] Iter[113/312]		Loss: 0.5785
2019-10-28 15:29:55,410 Training Epoch [4/40] Iter[114/312]		Loss: 0.5773
2019-10-28 15:29:55,489 Training Epoch [4/40] Iter[115/312]		Loss: 0.5763
2019-10-28 15:29:55,568 Training Epoch [4/40] Iter[116/312]		Loss: 0.5749
2019-10-28 15:29:55,647 Training Epoch [4/40] Iter[117/312]		Loss: 0.5753
2019-10-28 15:29:55,726 Training Epoch [4/40] Iter[118/312]		Loss: 0.5755
2019-10-28 15:29:55,804 Training Epoch [4/40] Iter[119/312]		Loss: 0.5744
2019-10-28 15:29:55,883 Training Epoch [4/40] Iter[120/312]		Loss: 0.5747
2019-10-28 15:29:55,962 Training Epoch [4/40] Iter[121/312]		Loss: 0.5750
2019-10-28 15:29:56,041 Training Epoch [4/40] Iter[122/312]		Loss: 0.5741
2019-10-28 15:29:56,120 Training Epoch [4/40] Iter[123/312]		Loss: 0.5744
2019-10-28 15:29:56,199 Training Epoch [4/40] Iter[124/312]		Loss: 0.5735
2019-10-28 15:29:56,278 Training Epoch [4/40] Iter[125/312]		Loss: 0.5731
2019-10-28 15:29:56,357 Training Epoch [4/40] Iter[126/312]		Loss: 0.5732
2019-10-28 15:29:56,436 Training Epoch [4/40] Iter[127/312]		Loss: 0.5733
2019-10-28 15:29:56,515 Training Epoch [4/40] Iter[128/312]		Loss: 0.5726
2019-10-28 15:29:56,594 Training Epoch [4/40] Iter[129/312]		Loss: 0.5721
2019-10-28 15:29:56,673 Training Epoch [4/40] Iter[130/312]		Loss: 0.5715
2019-10-28 15:29:56,752 Training Epoch [4/40] Iter[131/312]		Loss: 0.5712
2019-10-28 15:29:56,836 Training Epoch [4/40] Iter[132/312]		Loss: 0.5716
2019-10-28 15:29:56,915 Training Epoch [4/40] Iter[133/312]		Loss: 0.5707
2019-10-28 15:29:56,994 Training Epoch [4/40] Iter[134/312]		Loss: 0.5719
2019-10-28 15:29:57,073 Training Epoch [4/40] Iter[135/312]		Loss: 0.5708
2019-10-28 15:29:57,155 Training Epoch [4/40] Iter[136/312]		Loss: 0.5709
2019-10-28 15:29:57,234 Training Epoch [4/40] Iter[137/312]		Loss: 0.5702
2019-10-28 15:29:57,313 Training Epoch [4/40] Iter[138/312]		Loss: 0.5700
2019-10-28 15:29:57,392 Training Epoch [4/40] Iter[139/312]		Loss: 0.5696
2019-10-28 15:29:57,471 Training Epoch [4/40] Iter[140/312]		Loss: 0.5687
2019-10-28 15:29:57,550 Training Epoch [4/40] Iter[141/312]		Loss: 0.5674
2019-10-28 15:29:57,629 Training Epoch [4/40] Iter[142/312]		Loss: 0.5674
2019-10-28 15:29:57,708 Training Epoch [4/40] Iter[143/312]		Loss: 0.5682
2019-10-28 15:29:57,787 Training Epoch [4/40] Iter[144/312]		Loss: 0.5675
2019-10-28 15:29:57,866 Training Epoch [4/40] Iter[145/312]		Loss: 0.5671
2019-10-28 15:29:57,944 Training Epoch [4/40] Iter[146/312]		Loss: 0.5667
2019-10-28 15:29:58,023 Training Epoch [4/40] Iter[147/312]		Loss: 0.5665
2019-10-28 15:29:58,102 Training Epoch [4/40] Iter[148/312]		Loss: 0.5668
2019-10-28 15:29:58,181 Training Epoch [4/40] Iter[149/312]		Loss: 0.5673
2019-10-28 15:29:58,260 Training Epoch [4/40] Iter[150/312]		Loss: 0.5668
2019-10-28 15:29:58,339 Training Epoch [4/40] Iter[151/312]		Loss: 0.5664
2019-10-28 15:29:58,418 Training Epoch [4/40] Iter[152/312]		Loss: 0.5664
2019-10-28 15:29:58,497 Training Epoch [4/40] Iter[153/312]		Loss: 0.5671
2019-10-28 15:29:58,576 Training Epoch [4/40] Iter[154/312]		Loss: 0.5661
2019-10-28 15:29:58,654 Training Epoch [4/40] Iter[155/312]		Loss: 0.5654
2019-10-28 15:29:58,733 Training Epoch [4/40] Iter[156/312]		Loss: 0.5651
2019-10-28 15:29:58,812 Training Epoch [4/40] Iter[157/312]		Loss: 0.5645
2019-10-28 15:29:58,891 Training Epoch [4/40] Iter[158/312]		Loss: 0.5638
2019-10-28 15:29:58,970 Training Epoch [4/40] Iter[159/312]		Loss: 0.5630
2019-10-28 15:29:59,049 Training Epoch [4/40] Iter[160/312]		Loss: 0.5626
2019-10-28 15:29:59,128 Training Epoch [4/40] Iter[161/312]		Loss: 0.5616
2019-10-28 15:29:59,207 Training Epoch [4/40] Iter[162/312]		Loss: 0.5611
2019-10-28 15:29:59,286 Training Epoch [4/40] Iter[163/312]		Loss: 0.5614
2019-10-28 15:29:59,365 Training Epoch [4/40] Iter[164/312]		Loss: 0.5612
2019-10-28 15:29:59,443 Training Epoch [4/40] Iter[165/312]		Loss: 0.5607
2019-10-28 15:29:59,522 Training Epoch [4/40] Iter[166/312]		Loss: 0.5610
2019-10-28 15:29:59,601 Training Epoch [4/40] Iter[167/312]		Loss: 0.5602
2019-10-28 15:29:59,680 Training Epoch [4/40] Iter[168/312]		Loss: 0.5599
2019-10-28 15:29:59,759 Training Epoch [4/40] Iter[169/312]		Loss: 0.5589
2019-10-28 15:29:59,838 Training Epoch [4/40] Iter[170/312]		Loss: 0.5592
2019-10-28 15:29:59,916 Training Epoch [4/40] Iter[171/312]		Loss: 0.5595
2019-10-28 15:29:59,995 Training Epoch [4/40] Iter[172/312]		Loss: 0.5586
2019-10-28 15:30:00,074 Training Epoch [4/40] Iter[173/312]		Loss: 0.5573
2019-10-28 15:30:00,153 Training Epoch [4/40] Iter[174/312]		Loss: 0.5570
2019-10-28 15:30:00,232 Training Epoch [4/40] Iter[175/312]		Loss: 0.5563
2019-10-28 15:30:00,311 Training Epoch [4/40] Iter[176/312]		Loss: 0.5564
2019-10-28 15:30:00,390 Training Epoch [4/40] Iter[177/312]		Loss: 0.5557
2019-10-28 15:30:00,469 Training Epoch [4/40] Iter[178/312]		Loss: 0.5556
2019-10-28 15:30:00,548 Training Epoch [4/40] Iter[179/312]		Loss: 0.5563
2019-10-28 15:30:00,626 Training Epoch [4/40] Iter[180/312]		Loss: 0.5561
2019-10-28 15:30:00,705 Training Epoch [4/40] Iter[181/312]		Loss: 0.5564
2019-10-28 15:30:00,784 Training Epoch [4/40] Iter[182/312]		Loss: 0.5564
2019-10-28 15:30:00,863 Training Epoch [4/40] Iter[183/312]		Loss: 0.5557
2019-10-28 15:30:00,942 Training Epoch [4/40] Iter[184/312]		Loss: 0.5549
2019-10-28 15:30:01,021 Training Epoch [4/40] Iter[185/312]		Loss: 0.5544
2019-10-28 15:30:01,100 Training Epoch [4/40] Iter[186/312]		Loss: 0.5537
2019-10-28 15:30:01,179 Training Epoch [4/40] Iter[187/312]		Loss: 0.5534
2019-10-28 15:30:01,258 Training Epoch [4/40] Iter[188/312]		Loss: 0.5525
2019-10-28 15:30:01,337 Training Epoch [4/40] Iter[189/312]		Loss: 0.5532
2019-10-28 15:30:01,416 Training Epoch [4/40] Iter[190/312]		Loss: 0.5530
2019-10-28 15:30:01,495 Training Epoch [4/40] Iter[191/312]		Loss: 0.5528
2019-10-28 15:30:01,574 Training Epoch [4/40] Iter[192/312]		Loss: 0.5520
2019-10-28 15:30:01,653 Training Epoch [4/40] Iter[193/312]		Loss: 0.5521
2019-10-28 15:30:01,732 Training Epoch [4/40] Iter[194/312]		Loss: 0.5522
2019-10-28 15:30:01,811 Training Epoch [4/40] Iter[195/312]		Loss: 0.5516
2019-10-28 15:30:01,890 Training Epoch [4/40] Iter[196/312]		Loss: 0.5522
2019-10-28 15:30:01,969 Training Epoch [4/40] Iter[197/312]		Loss: 0.5521
2019-10-28 15:30:02,048 Training Epoch [4/40] Iter[198/312]		Loss: 0.5521
2019-10-28 15:30:02,127 Training Epoch [4/40] Iter[199/312]		Loss: 0.5523
2019-10-28 15:30:02,206 Training Epoch [4/40] Iter[200/312]		Loss: 0.5514
2019-10-28 15:30:02,285 Training Epoch [4/40] Iter[201/312]		Loss: 0.5520
2019-10-28 15:30:02,365 Training Epoch [4/40] Iter[202/312]		Loss: 0.5521
2019-10-28 15:30:02,443 Training Epoch [4/40] Iter[203/312]		Loss: 0.5516
2019-10-28 15:30:02,522 Training Epoch [4/40] Iter[204/312]		Loss: 0.5510
2019-10-28 15:30:02,602 Training Epoch [4/40] Iter[205/312]		Loss: 0.5507
2019-10-28 15:30:02,681 Training Epoch [4/40] Iter[206/312]		Loss: 0.5506
2019-10-28 15:30:02,760 Training Epoch [4/40] Iter[207/312]		Loss: 0.5501
2019-10-28 15:30:02,839 Training Epoch [4/40] Iter[208/312]		Loss: 0.5497
2019-10-28 15:30:02,917 Training Epoch [4/40] Iter[209/312]		Loss: 0.5490
2019-10-28 15:30:02,997 Training Epoch [4/40] Iter[210/312]		Loss: 0.5488
2019-10-28 15:30:03,075 Training Epoch [4/40] Iter[211/312]		Loss: 0.5489
2019-10-28 15:30:03,154 Training Epoch [4/40] Iter[212/312]		Loss: 0.5488
2019-10-28 15:30:03,233 Training Epoch [4/40] Iter[213/312]		Loss: 0.5484
2019-10-28 15:30:03,312 Training Epoch [4/40] Iter[214/312]		Loss: 0.5473
2019-10-28 15:30:03,390 Training Epoch [4/40] Iter[215/312]		Loss: 0.5465
2019-10-28 15:30:03,469 Training Epoch [4/40] Iter[216/312]		Loss: 0.5459
2019-10-28 15:30:03,549 Training Epoch [4/40] Iter[217/312]		Loss: 0.5464
2019-10-28 15:30:03,628 Training Epoch [4/40] Iter[218/312]		Loss: 0.5457
2019-10-28 15:30:03,707 Training Epoch [4/40] Iter[219/312]		Loss: 0.5459
2019-10-28 15:30:03,786 Training Epoch [4/40] Iter[220/312]		Loss: 0.5458
2019-10-28 15:30:03,865 Training Epoch [4/40] Iter[221/312]		Loss: 0.5450
2019-10-28 15:30:03,944 Training Epoch [4/40] Iter[222/312]		Loss: 0.5440
2019-10-28 15:30:04,023 Training Epoch [4/40] Iter[223/312]		Loss: 0.5439
2019-10-28 15:30:04,101 Training Epoch [4/40] Iter[224/312]		Loss: 0.5439
2019-10-28 15:30:04,181 Training Epoch [4/40] Iter[225/312]		Loss: 0.5433
2019-10-28 15:30:04,259 Training Epoch [4/40] Iter[226/312]		Loss: 0.5429
2019-10-28 15:30:04,338 Training Epoch [4/40] Iter[227/312]		Loss: 0.5419
2019-10-28 15:30:04,417 Training Epoch [4/40] Iter[228/312]		Loss: 0.5409
2019-10-28 15:30:04,496 Training Epoch [4/40] Iter[229/312]		Loss: 0.5402
2019-10-28 15:30:04,575 Training Epoch [4/40] Iter[230/312]		Loss: 0.5400
2019-10-28 15:30:04,654 Training Epoch [4/40] Iter[231/312]		Loss: 0.5404
2019-10-28 15:30:04,733 Training Epoch [4/40] Iter[232/312]		Loss: 0.5397
2019-10-28 15:30:04,812 Training Epoch [4/40] Iter[233/312]		Loss: 0.5392
2019-10-28 15:30:04,891 Training Epoch [4/40] Iter[234/312]		Loss: 0.5388
2019-10-28 15:30:04,970 Training Epoch [4/40] Iter[235/312]		Loss: 0.5387
2019-10-28 15:30:05,049 Training Epoch [4/40] Iter[236/312]		Loss: 0.5381
2019-10-28 15:30:05,128 Training Epoch [4/40] Iter[237/312]		Loss: 0.5378
2019-10-28 15:30:05,207 Training Epoch [4/40] Iter[238/312]		Loss: 0.5378
2019-10-28 15:30:05,286 Training Epoch [4/40] Iter[239/312]		Loss: 0.5375
2019-10-28 15:30:05,366 Training Epoch [4/40] Iter[240/312]		Loss: 0.5368
2019-10-28 15:30:05,446 Training Epoch [4/40] Iter[241/312]		Loss: 0.5369
2019-10-28 15:30:05,525 Training Epoch [4/40] Iter[242/312]		Loss: 0.5369
2019-10-28 15:30:05,604 Training Epoch [4/40] Iter[243/312]		Loss: 0.5370
2019-10-28 15:30:05,683 Training Epoch [4/40] Iter[244/312]		Loss: 0.5371
2019-10-28 15:30:05,762 Training Epoch [4/40] Iter[245/312]		Loss: 0.5371
2019-10-28 15:30:05,841 Training Epoch [4/40] Iter[246/312]		Loss: 0.5365
2019-10-28 15:30:05,920 Training Epoch [4/40] Iter[247/312]		Loss: 0.5368
2019-10-28 15:30:05,999 Training Epoch [4/40] Iter[248/312]		Loss: 0.5367
2019-10-28 15:30:06,078 Training Epoch [4/40] Iter[249/312]		Loss: 0.5368
2019-10-28 15:30:06,157 Training Epoch [4/40] Iter[250/312]		Loss: 0.5368
2019-10-28 15:30:06,236 Training Epoch [4/40] Iter[251/312]		Loss: 0.5368
2019-10-28 15:30:06,315 Training Epoch [4/40] Iter[252/312]		Loss: 0.5361
2019-10-28 15:30:06,395 Training Epoch [4/40] Iter[253/312]		Loss: 0.5362
2019-10-28 15:30:06,474 Training Epoch [4/40] Iter[254/312]		Loss: 0.5356
2019-10-28 15:30:06,553 Training Epoch [4/40] Iter[255/312]		Loss: 0.5353
2019-10-28 15:30:06,632 Training Epoch [4/40] Iter[256/312]		Loss: 0.5349
2019-10-28 15:30:06,711 Training Epoch [4/40] Iter[257/312]		Loss: 0.5344
2019-10-28 15:30:06,790 Training Epoch [4/40] Iter[258/312]		Loss: 0.5342
2019-10-28 15:30:06,869 Training Epoch [4/40] Iter[259/312]		Loss: 0.5341
2019-10-28 15:30:06,948 Training Epoch [4/40] Iter[260/312]		Loss: 0.5344
2019-10-28 15:30:07,027 Training Epoch [4/40] Iter[261/312]		Loss: 0.5343
2019-10-28 15:30:07,106 Training Epoch [4/40] Iter[262/312]		Loss: 0.5340
2019-10-28 15:30:07,185 Training Epoch [4/40] Iter[263/312]		Loss: 0.5337
2019-10-28 15:30:07,265 Training Epoch [4/40] Iter[264/312]		Loss: 0.5330
2019-10-28 15:30:07,344 Training Epoch [4/40] Iter[265/312]		Loss: 0.5327
2019-10-28 15:30:07,424 Training Epoch [4/40] Iter[266/312]		Loss: 0.5327
2019-10-28 15:30:07,503 Training Epoch [4/40] Iter[267/312]		Loss: 0.5323
2019-10-28 15:30:07,582 Training Epoch [4/40] Iter[268/312]		Loss: 0.5322
2019-10-28 15:30:07,661 Training Epoch [4/40] Iter[269/312]		Loss: 0.5314
2019-10-28 15:30:07,740 Training Epoch [4/40] Iter[270/312]		Loss: 0.5314
2019-10-28 15:30:07,819 Training Epoch [4/40] Iter[271/312]		Loss: 0.5313
2019-10-28 15:30:07,897 Training Epoch [4/40] Iter[272/312]		Loss: 0.5310
2019-10-28 15:30:07,976 Training Epoch [4/40] Iter[273/312]		Loss: 0.5303
2019-10-28 15:30:08,055 Training Epoch [4/40] Iter[274/312]		Loss: 0.5302
2019-10-28 15:30:08,134 Training Epoch [4/40] Iter[275/312]		Loss: 0.5295
2019-10-28 15:30:08,213 Training Epoch [4/40] Iter[276/312]		Loss: 0.5295
2019-10-28 15:30:08,292 Training Epoch [4/40] Iter[277/312]		Loss: 0.5291
2019-10-28 15:30:08,371 Training Epoch [4/40] Iter[278/312]		Loss: 0.5284
2019-10-28 15:30:08,450 Training Epoch [4/40] Iter[279/312]		Loss: 0.5283
2019-10-28 15:30:08,529 Training Epoch [4/40] Iter[280/312]		Loss: 0.5274
2019-10-28 15:30:08,608 Training Epoch [4/40] Iter[281/312]		Loss: 0.5269
2019-10-28 15:30:08,687 Training Epoch [4/40] Iter[282/312]		Loss: 0.5273
2019-10-28 15:30:08,767 Training Epoch [4/40] Iter[283/312]		Loss: 0.5273
2019-10-28 15:30:08,846 Training Epoch [4/40] Iter[284/312]		Loss: 0.5271
2019-10-28 15:30:08,925 Training Epoch [4/40] Iter[285/312]		Loss: 0.5264
2019-10-28 15:30:09,005 Training Epoch [4/40] Iter[286/312]		Loss: 0.5263
2019-10-28 15:30:09,084 Training Epoch [4/40] Iter[287/312]		Loss: 0.5260
2019-10-28 15:30:09,164 Training Epoch [4/40] Iter[288/312]		Loss: 0.5256
2019-10-28 15:30:09,243 Training Epoch [4/40] Iter[289/312]		Loss: 0.5256
2019-10-28 15:30:09,322 Training Epoch [4/40] Iter[290/312]		Loss: 0.5254
2019-10-28 15:30:09,402 Training Epoch [4/40] Iter[291/312]		Loss: 0.5252
2019-10-28 15:30:09,481 Training Epoch [4/40] Iter[292/312]		Loss: 0.5249
2019-10-28 15:30:09,560 Training Epoch [4/40] Iter[293/312]		Loss: 0.5246
2019-10-28 15:30:09,639 Training Epoch [4/40] Iter[294/312]		Loss: 0.5239
2019-10-28 15:30:09,718 Training Epoch [4/40] Iter[295/312]		Loss: 0.5237
2019-10-28 15:30:09,797 Training Epoch [4/40] Iter[296/312]		Loss: 0.5233
2019-10-28 15:30:09,876 Training Epoch [4/40] Iter[297/312]		Loss: 0.5234
2019-10-28 15:30:09,955 Training Epoch [4/40] Iter[298/312]		Loss: 0.5231
2019-10-28 15:30:10,034 Training Epoch [4/40] Iter[299/312]		Loss: 0.5228
2019-10-28 15:30:10,113 Training Epoch [4/40] Iter[300/312]		Loss: 0.5226
2019-10-28 15:30:10,192 Training Epoch [4/40] Iter[301/312]		Loss: 0.5223
2019-10-28 15:30:10,271 Training Epoch [4/40] Iter[302/312]		Loss: 0.5227
2019-10-28 15:30:10,350 Training Epoch [4/40] Iter[303/312]		Loss: 0.5221
2019-10-28 15:30:10,429 Training Epoch [4/40] Iter[304/312]		Loss: 0.5221
2019-10-28 15:30:10,507 Training Epoch [4/40] Iter[305/312]		Loss: 0.5217
2019-10-28 15:30:10,585 Training Epoch [4/40] Iter[306/312]		Loss: 0.5217
2019-10-28 15:30:10,663 Training Epoch [4/40] Iter[307/312]		Loss: 0.5214
2019-10-28 15:30:10,741 Training Epoch [4/40] Iter[308/312]		Loss: 0.5216
2019-10-28 15:30:10,820 Training Epoch [4/40] Iter[309/312]		Loss: 0.5212
2019-10-28 15:30:10,898 Training Epoch [4/40] Iter[310/312]		Loss: 0.5213
2019-10-28 15:30:10,976 Training Epoch [4/40] Iter[311/312]		Loss: 0.5211
2019-10-28 15:30:11,015 Training Epoch [4/40] Iter[312/312]		Loss: 0.5204
2019-10-28 15:30:11,402 Testing Epoch [4/40] Iter[0/62]		Loss: 0.4488
2019-10-28 15:30:11,484 Testing Epoch [4/40] Iter[1/62]		Loss: 0.4258
2019-10-28 15:30:11,510 Testing Epoch [4/40] Iter[2/62]		Loss: 0.3955
2019-10-28 15:30:11,538 Testing Epoch [4/40] Iter[3/62]		Loss: 0.3904
2019-10-28 15:30:11,566 Testing Epoch [4/40] Iter[4/62]		Loss: 0.3920
2019-10-28 15:30:11,589 Testing Epoch [4/40] Iter[5/62]		Loss: 0.3787
2019-10-28 15:30:11,613 Testing Epoch [4/40] Iter[6/62]		Loss: 0.3810
2019-10-28 15:30:11,638 Testing Epoch [4/40] Iter[7/62]		Loss: 0.3751
2019-10-28 15:30:11,661 Testing Epoch [4/40] Iter[8/62]		Loss: 0.3884
2019-10-28 15:30:11,687 Testing Epoch [4/40] Iter[9/62]		Loss: 0.3855
2019-10-28 15:30:11,703 Testing Epoch [4/40] Iter[10/62]		Loss: 0.3879
2019-10-28 15:30:11,720 Testing Epoch [4/40] Iter[11/62]		Loss: 0.3962
2019-10-28 15:30:11,750 Testing Epoch [4/40] Iter[12/62]		Loss: 0.3952
2019-10-28 15:30:11,771 Testing Epoch [4/40] Iter[13/62]		Loss: 0.3926
2019-10-28 15:30:11,793 Testing Epoch [4/40] Iter[14/62]		Loss: 0.4090
2019-10-28 15:30:11,810 Testing Epoch [4/40] Iter[15/62]		Loss: 0.4101
2019-10-28 15:30:11,837 Testing Epoch [4/40] Iter[16/62]		Loss: 0.4065
2019-10-28 15:30:11,855 Testing Epoch [4/40] Iter[17/62]		Loss: 0.4099
2019-10-28 15:30:11,872 Testing Epoch [4/40] Iter[18/62]		Loss: 0.4010
2019-10-28 15:30:11,898 Testing Epoch [4/40] Iter[19/62]		Loss: 0.3995
2019-10-28 15:30:11,925 Testing Epoch [4/40] Iter[20/62]		Loss: 0.4123
2019-10-28 15:30:11,942 Testing Epoch [4/40] Iter[21/62]		Loss: 0.4105
2019-10-28 15:30:11,960 Testing Epoch [4/40] Iter[22/62]		Loss: 0.4160
2019-10-28 15:30:11,990 Testing Epoch [4/40] Iter[23/62]		Loss: 0.4161
2019-10-28 15:30:12,008 Testing Epoch [4/40] Iter[24/62]		Loss: 0.4190
2019-10-28 15:30:12,026 Testing Epoch [4/40] Iter[25/62]		Loss: 0.4174
2019-10-28 15:30:12,044 Testing Epoch [4/40] Iter[26/62]		Loss: 0.4156
2019-10-28 15:30:12,070 Testing Epoch [4/40] Iter[27/62]		Loss: 0.4243
2019-10-28 15:30:12,087 Testing Epoch [4/40] Iter[28/62]		Loss: 0.4264
2019-10-28 15:30:12,122 Testing Epoch [4/40] Iter[29/62]		Loss: 0.4253
2019-10-28 15:30:12,145 Testing Epoch [4/40] Iter[30/62]		Loss: 0.4226
2019-10-28 15:30:12,173 Testing Epoch [4/40] Iter[31/62]		Loss: 0.4248
2019-10-28 15:30:12,191 Testing Epoch [4/40] Iter[32/62]		Loss: 0.4289
2019-10-28 15:30:12,209 Testing Epoch [4/40] Iter[33/62]		Loss: 0.4276
2019-10-28 15:30:12,242 Testing Epoch [4/40] Iter[34/62]		Loss: 0.4299
2019-10-28 15:30:12,269 Testing Epoch [4/40] Iter[35/62]		Loss: 0.4316
2019-10-28 15:30:12,287 Testing Epoch [4/40] Iter[36/62]		Loss: 0.4282
2019-10-28 15:30:12,305 Testing Epoch [4/40] Iter[37/62]		Loss: 0.4282
2019-10-28 15:30:12,333 Testing Epoch [4/40] Iter[38/62]		Loss: 0.4277
2019-10-28 15:30:12,360 Testing Epoch [4/40] Iter[39/62]		Loss: 0.4267
2019-10-28 15:30:12,380 Testing Epoch [4/40] Iter[40/62]		Loss: 0.4313
2019-10-28 15:30:12,397 Testing Epoch [4/40] Iter[41/62]		Loss: 0.4357
2019-10-28 15:30:12,425 Testing Epoch [4/40] Iter[42/62]		Loss: 0.4331
2019-10-28 15:30:12,449 Testing Epoch [4/40] Iter[43/62]		Loss: 0.4349
2019-10-28 15:30:12,473 Testing Epoch [4/40] Iter[44/62]		Loss: 0.4336
2019-10-28 15:30:12,497 Testing Epoch [4/40] Iter[45/62]		Loss: 0.4330
2019-10-28 15:30:12,515 Testing Epoch [4/40] Iter[46/62]		Loss: 0.4338
2019-10-28 15:30:12,541 Testing Epoch [4/40] Iter[47/62]		Loss: 0.4389
2019-10-28 15:30:12,559 Testing Epoch [4/40] Iter[48/62]		Loss: 0.4358
2019-10-28 15:30:12,586 Testing Epoch [4/40] Iter[49/62]		Loss: 0.4390
2019-10-28 15:30:12,606 Testing Epoch [4/40] Iter[50/62]		Loss: 0.4366
2019-10-28 15:30:12,633 Testing Epoch [4/40] Iter[51/62]		Loss: 0.4360
2019-10-28 15:30:12,657 Testing Epoch [4/40] Iter[52/62]		Loss: 0.4333
2019-10-28 15:30:12,681 Testing Epoch [4/40] Iter[53/62]		Loss: 0.4346
2019-10-28 15:30:12,705 Testing Epoch [4/40] Iter[54/62]		Loss: 0.4330
2019-10-28 15:30:12,722 Testing Epoch [4/40] Iter[55/62]		Loss: 0.4340
2019-10-28 15:30:12,738 Testing Epoch [4/40] Iter[56/62]		Loss: 0.4364
2019-10-28 15:30:12,755 Testing Epoch [4/40] Iter[57/62]		Loss: 0.4377
2019-10-28 15:30:12,771 Testing Epoch [4/40] Iter[58/62]		Loss: 0.4355
2019-10-28 15:30:12,788 Testing Epoch [4/40] Iter[59/62]		Loss: 0.4373
2019-10-28 15:30:12,804 Testing Epoch [4/40] Iter[60/62]		Loss: 0.4370
2019-10-28 15:30:12,821 Testing Epoch [4/40] Iter[61/62]		Loss: 0.4399
2019-10-28 15:30:12,830 Testing Epoch [4/40] Iter[62/62]		Loss: 0.4429
2019-10-28 15:30:12,900 Saving the Model
2019-10-28 15:30:13,333 Training Epoch [5/40] Iter[0/312]		Loss: 0.3484
2019-10-28 15:30:13,411 Training Epoch [5/40] Iter[1/312]		Loss: 0.4430
2019-10-28 15:30:13,495 Training Epoch [5/40] Iter[2/312]		Loss: 0.4534
2019-10-28 15:30:13,573 Training Epoch [5/40] Iter[3/312]		Loss: 0.4898
2019-10-28 15:30:13,652 Training Epoch [5/40] Iter[4/312]		Loss: 0.5097
2019-10-28 15:30:13,730 Training Epoch [5/40] Iter[5/312]		Loss: 0.5030
2019-10-28 15:30:13,809 Training Epoch [5/40] Iter[6/312]		Loss: 0.5072
2019-10-28 15:30:13,887 Training Epoch [5/40] Iter[7/312]		Loss: 0.5076
2019-10-28 15:30:13,965 Training Epoch [5/40] Iter[8/312]		Loss: 0.5216
2019-10-28 15:30:14,044 Training Epoch [5/40] Iter[9/312]		Loss: 0.5272
2019-10-28 15:30:14,123 Training Epoch [5/40] Iter[10/312]		Loss: 0.5208
2019-10-28 15:30:14,202 Training Epoch [5/40] Iter[11/312]		Loss: 0.5221
2019-10-28 15:30:14,281 Training Epoch [5/40] Iter[12/312]		Loss: 0.5312
2019-10-28 15:30:14,360 Training Epoch [5/40] Iter[13/312]		Loss: 0.5391
2019-10-28 15:30:14,438 Training Epoch [5/40] Iter[14/312]		Loss: 0.5336
2019-10-28 15:30:14,517 Training Epoch [5/40] Iter[15/312]		Loss: 0.5229
2019-10-28 15:30:14,596 Training Epoch [5/40] Iter[16/312]		Loss: 0.5216
2019-10-28 15:30:14,675 Training Epoch [5/40] Iter[17/312]		Loss: 0.5222
2019-10-28 15:30:14,754 Training Epoch [5/40] Iter[18/312]		Loss: 0.5200
2019-10-28 15:30:14,832 Training Epoch [5/40] Iter[19/312]		Loss: 0.5195
2019-10-28 15:30:14,911 Training Epoch [5/40] Iter[20/312]		Loss: 0.5163
2019-10-28 15:30:14,990 Training Epoch [5/40] Iter[21/312]		Loss: 0.5112
2019-10-28 15:30:15,069 Training Epoch [5/40] Iter[22/312]		Loss: 0.5167
2019-10-28 15:30:15,148 Training Epoch [5/40] Iter[23/312]		Loss: 0.5126
2019-10-28 15:30:15,227 Training Epoch [5/40] Iter[24/312]		Loss: 0.5104
2019-10-28 15:30:15,306 Training Epoch [5/40] Iter[25/312]		Loss: 0.5085
2019-10-28 15:30:15,384 Training Epoch [5/40] Iter[26/312]		Loss: 0.5045
2019-10-28 15:30:15,463 Training Epoch [5/40] Iter[27/312]		Loss: 0.5016
2019-10-28 15:30:15,543 Training Epoch [5/40] Iter[28/312]		Loss: 0.4962
2019-10-28 15:30:15,621 Training Epoch [5/40] Iter[29/312]		Loss: 0.4959
2019-10-28 15:30:15,700 Training Epoch [5/40] Iter[30/312]		Loss: 0.4957
2019-10-28 15:30:15,779 Training Epoch [5/40] Iter[31/312]		Loss: 0.4961
2019-10-28 15:30:15,858 Training Epoch [5/40] Iter[32/312]		Loss: 0.4951
2019-10-28 15:30:15,937 Training Epoch [5/40] Iter[33/312]		Loss: 0.4953
2019-10-28 15:30:16,016 Training Epoch [5/40] Iter[34/312]		Loss: 0.4959
2019-10-28 15:30:16,095 Training Epoch [5/40] Iter[35/312]		Loss: 0.5021
2019-10-28 15:30:16,174 Training Epoch [5/40] Iter[36/312]		Loss: 0.5056
2019-10-28 15:30:16,252 Training Epoch [5/40] Iter[37/312]		Loss: 0.5062
2019-10-28 15:30:16,331 Training Epoch [5/40] Iter[38/312]		Loss: 0.5075
2019-10-28 15:30:16,410 Training Epoch [5/40] Iter[39/312]		Loss: 0.5068
2019-10-28 15:30:16,489 Training Epoch [5/40] Iter[40/312]		Loss: 0.5056
2019-10-28 15:30:16,568 Training Epoch [5/40] Iter[41/312]		Loss: 0.5033
2019-10-28 15:30:16,647 Training Epoch [5/40] Iter[42/312]		Loss: 0.5042
2019-10-28 15:30:16,726 Training Epoch [5/40] Iter[43/312]		Loss: 0.5061
2019-10-28 15:30:16,805 Training Epoch [5/40] Iter[44/312]		Loss: 0.5051
2019-10-28 15:30:16,884 Training Epoch [5/40] Iter[45/312]		Loss: 0.5033
2019-10-28 15:30:16,963 Training Epoch [5/40] Iter[46/312]		Loss: 0.4990
2019-10-28 15:30:17,042 Training Epoch [5/40] Iter[47/312]		Loss: 0.4961
2019-10-28 15:30:17,121 Training Epoch [5/40] Iter[48/312]		Loss: 0.4937
2019-10-28 15:30:17,200 Training Epoch [5/40] Iter[49/312]		Loss: 0.4951
2019-10-28 15:30:17,279 Training Epoch [5/40] Iter[50/312]		Loss: 0.4953
2019-10-28 15:30:17,358 Training Epoch [5/40] Iter[51/312]		Loss: 0.4964
2019-10-28 15:30:17,438 Training Epoch [5/40] Iter[52/312]		Loss: 0.4975
2019-10-28 15:30:17,516 Training Epoch [5/40] Iter[53/312]		Loss: 0.4964
2019-10-28 15:30:17,595 Training Epoch [5/40] Iter[54/312]		Loss: 0.4949
2019-10-28 15:30:17,674 Training Epoch [5/40] Iter[55/312]		Loss: 0.4924
2019-10-28 15:30:17,753 Training Epoch [5/40] Iter[56/312]		Loss: 0.4918
2019-10-28 15:30:17,832 Training Epoch [5/40] Iter[57/312]		Loss: 0.4907
2019-10-28 15:30:17,910 Training Epoch [5/40] Iter[58/312]		Loss: 0.4911
2019-10-28 15:30:17,990 Training Epoch [5/40] Iter[59/312]		Loss: 0.4903
2019-10-28 15:30:18,069 Training Epoch [5/40] Iter[60/312]		Loss: 0.4877
2019-10-28 15:30:18,147 Training Epoch [5/40] Iter[61/312]		Loss: 0.4876
2019-10-28 15:30:18,226 Training Epoch [5/40] Iter[62/312]		Loss: 0.4848
2019-10-28 15:30:18,305 Training Epoch [5/40] Iter[63/312]		Loss: 0.4842
2019-10-28 15:30:18,384 Training Epoch [5/40] Iter[64/312]		Loss: 0.4856
2019-10-28 15:30:18,464 Training Epoch [5/40] Iter[65/312]		Loss: 0.4826
2019-10-28 15:30:18,543 Training Epoch [5/40] Iter[66/312]		Loss: 0.4810
2019-10-28 15:30:18,622 Training Epoch [5/40] Iter[67/312]		Loss: 0.4819
2019-10-28 15:30:18,701 Training Epoch [5/40] Iter[68/312]		Loss: 0.4803
2019-10-28 15:30:18,779 Training Epoch [5/40] Iter[69/312]		Loss: 0.4795
2019-10-28 15:30:18,858 Training Epoch [5/40] Iter[70/312]		Loss: 0.4796
2019-10-28 15:30:18,937 Training Epoch [5/40] Iter[71/312]		Loss: 0.4777
2019-10-28 15:30:19,016 Training Epoch [5/40] Iter[72/312]		Loss: 0.4761
2019-10-28 15:30:19,095 Training Epoch [5/40] Iter[73/312]		Loss: 0.4761
2019-10-28 15:30:19,174 Training Epoch [5/40] Iter[74/312]		Loss: 0.4744
2019-10-28 15:30:19,253 Training Epoch [5/40] Iter[75/312]		Loss: 0.4735
2019-10-28 15:30:19,332 Training Epoch [5/40] Iter[76/312]		Loss: 0.4720
2019-10-28 15:30:19,411 Training Epoch [5/40] Iter[77/312]		Loss: 0.4701
2019-10-28 15:30:19,490 Training Epoch [5/40] Iter[78/312]		Loss: 0.4688
2019-10-28 15:30:19,568 Training Epoch [5/40] Iter[79/312]		Loss: 0.4689
2019-10-28 15:30:19,647 Training Epoch [5/40] Iter[80/312]		Loss: 0.4681
2019-10-28 15:30:19,726 Training Epoch [5/40] Iter[81/312]		Loss: 0.4674
2019-10-28 15:30:19,805 Training Epoch [5/40] Iter[82/312]		Loss: 0.4650
2019-10-28 15:30:19,884 Training Epoch [5/40] Iter[83/312]		Loss: 0.4640
2019-10-28 15:30:19,962 Training Epoch [5/40] Iter[84/312]		Loss: 0.4635
2019-10-28 15:30:20,041 Training Epoch [5/40] Iter[85/312]		Loss: 0.4632
2019-10-28 15:30:20,120 Training Epoch [5/40] Iter[86/312]		Loss: 0.4615
2019-10-28 15:30:20,199 Training Epoch [5/40] Iter[87/312]		Loss: 0.4614
2019-10-28 15:30:20,278 Training Epoch [5/40] Iter[88/312]		Loss: 0.4605
2019-10-28 15:30:20,357 Training Epoch [5/40] Iter[89/312]		Loss: 0.4618
2019-10-28 15:30:20,436 Training Epoch [5/40] Iter[90/312]		Loss: 0.4643
2019-10-28 15:30:20,515 Training Epoch [5/40] Iter[91/312]		Loss: 0.4645
2019-10-28 15:30:20,594 Training Epoch [5/40] Iter[92/312]		Loss: 0.4638
2019-10-28 15:30:20,673 Training Epoch [5/40] Iter[93/312]		Loss: 0.4627
2019-10-28 15:30:20,752 Training Epoch [5/40] Iter[94/312]		Loss: 0.4619
2019-10-28 15:30:20,831 Training Epoch [5/40] Iter[95/312]		Loss: 0.4608
2019-10-28 15:30:20,909 Training Epoch [5/40] Iter[96/312]		Loss: 0.4624
2019-10-28 15:30:20,989 Training Epoch [5/40] Iter[97/312]		Loss: 0.4605
2019-10-28 15:30:21,068 Training Epoch [5/40] Iter[98/312]		Loss: 0.4590
2019-10-28 15:30:21,147 Training Epoch [5/40] Iter[99/312]		Loss: 0.4582
2019-10-28 15:30:21,225 Training Epoch [5/40] Iter[100/312]		Loss: 0.4573
2019-10-28 15:30:21,305 Training Epoch [5/40] Iter[101/312]		Loss: 0.4569
2019-10-28 15:30:21,384 Training Epoch [5/40] Iter[102/312]		Loss: 0.4552
2019-10-28 15:30:21,462 Training Epoch [5/40] Iter[103/312]		Loss: 0.4543
2019-10-28 15:30:21,541 Training Epoch [5/40] Iter[104/312]		Loss: 0.4546
2019-10-28 15:30:21,620 Training Epoch [5/40] Iter[105/312]		Loss: 0.4547
2019-10-28 15:30:21,699 Training Epoch [5/40] Iter[106/312]		Loss: 0.4535
2019-10-28 15:30:21,778 Training Epoch [5/40] Iter[107/312]		Loss: 0.4524
2019-10-28 15:30:21,857 Training Epoch [5/40] Iter[108/312]		Loss: 0.4526
2019-10-28 15:30:21,936 Training Epoch [5/40] Iter[109/312]		Loss: 0.4533
2019-10-28 15:30:22,015 Training Epoch [5/40] Iter[110/312]		Loss: 0.4533
2019-10-28 15:30:22,094 Training Epoch [5/40] Iter[111/312]		Loss: 0.4524
2019-10-28 15:30:22,173 Training Epoch [5/40] Iter[112/312]		Loss: 0.4519
2019-10-28 15:30:22,252 Training Epoch [5/40] Iter[113/312]		Loss: 0.4521
2019-10-28 15:30:22,331 Training Epoch [5/40] Iter[114/312]		Loss: 0.4514
2019-10-28 15:30:22,410 Training Epoch [5/40] Iter[115/312]		Loss: 0.4514
2019-10-28 15:30:22,489 Training Epoch [5/40] Iter[116/312]		Loss: 0.4515
2019-10-28 15:30:22,568 Training Epoch [5/40] Iter[117/312]		Loss: 0.4510
2019-10-28 15:30:22,647 Training Epoch [5/40] Iter[118/312]		Loss: 0.4504
2019-10-28 15:30:22,726 Training Epoch [5/40] Iter[119/312]		Loss: 0.4500
2019-10-28 15:30:22,805 Training Epoch [5/40] Iter[120/312]		Loss: 0.4496
2019-10-28 15:30:22,883 Training Epoch [5/40] Iter[121/312]		Loss: 0.4494
2019-10-28 15:30:22,962 Training Epoch [5/40] Iter[122/312]		Loss: 0.4500
2019-10-28 15:30:23,041 Training Epoch [5/40] Iter[123/312]		Loss: 0.4514
2019-10-28 15:30:23,120 Training Epoch [5/40] Iter[124/312]		Loss: 0.4509
2019-10-28 15:30:23,199 Training Epoch [5/40] Iter[125/312]		Loss: 0.4502
2019-10-28 15:30:23,278 Training Epoch [5/40] Iter[126/312]		Loss: 0.4506
2019-10-28 15:30:23,358 Training Epoch [5/40] Iter[127/312]		Loss: 0.4503
2019-10-28 15:30:23,437 Training Epoch [5/40] Iter[128/312]		Loss: 0.4506
2019-10-28 15:30:23,516 Training Epoch [5/40] Iter[129/312]		Loss: 0.4517
2019-10-28 15:30:23,595 Training Epoch [5/40] Iter[130/312]		Loss: 0.4511
2019-10-28 15:30:23,674 Training Epoch [5/40] Iter[131/312]		Loss: 0.4514
2019-10-28 15:30:23,753 Training Epoch [5/40] Iter[132/312]		Loss: 0.4509
2019-10-28 15:30:23,832 Training Epoch [5/40] Iter[133/312]		Loss: 0.4499
2019-10-28 15:30:23,911 Training Epoch [5/40] Iter[134/312]		Loss: 0.4497
2019-10-28 15:30:23,990 Training Epoch [5/40] Iter[135/312]		Loss: 0.4510
2019-10-28 15:30:24,069 Training Epoch [5/40] Iter[136/312]		Loss: 0.4508
2019-10-28 15:30:24,148 Training Epoch [5/40] Iter[137/312]		Loss: 0.4514
2019-10-28 15:30:24,227 Training Epoch [5/40] Iter[138/312]		Loss: 0.4525
2019-10-28 15:30:24,306 Training Epoch [5/40] Iter[139/312]		Loss: 0.4526
2019-10-28 15:30:24,385 Training Epoch [5/40] Iter[140/312]		Loss: 0.4522
2019-10-28 15:30:24,464 Training Epoch [5/40] Iter[141/312]		Loss: 0.4525
2019-10-28 15:30:24,543 Training Epoch [5/40] Iter[142/312]		Loss: 0.4511
2019-10-28 15:30:24,622 Training Epoch [5/40] Iter[143/312]		Loss: 0.4506
2019-10-28 15:30:24,701 Training Epoch [5/40] Iter[144/312]		Loss: 0.4511
2019-10-28 15:30:24,780 Training Epoch [5/40] Iter[145/312]		Loss: 0.4502
2019-10-28 15:30:24,859 Training Epoch [5/40] Iter[146/312]		Loss: 0.4501
2019-10-28 15:30:24,937 Training Epoch [5/40] Iter[147/312]		Loss: 0.4494
2019-10-28 15:30:25,016 Training Epoch [5/40] Iter[148/312]		Loss: 0.4501
2019-10-28 15:30:25,095 Training Epoch [5/40] Iter[149/312]		Loss: 0.4502
2019-10-28 15:30:25,174 Training Epoch [5/40] Iter[150/312]		Loss: 0.4494
2019-10-28 15:30:25,253 Training Epoch [5/40] Iter[151/312]		Loss: 0.4494
2019-10-28 15:30:25,332 Training Epoch [5/40] Iter[152/312]		Loss: 0.4494
2019-10-28 15:30:25,411 Training Epoch [5/40] Iter[153/312]		Loss: 0.4494
2019-10-28 15:30:25,490 Training Epoch [5/40] Iter[154/312]		Loss: 0.4490
2019-10-28 15:30:25,569 Training Epoch [5/40] Iter[155/312]		Loss: 0.4484
2019-10-28 15:30:25,647 Training Epoch [5/40] Iter[156/312]		Loss: 0.4488
2019-10-28 15:30:25,726 Training Epoch [5/40] Iter[157/312]		Loss: 0.4491
2019-10-28 15:30:25,805 Training Epoch [5/40] Iter[158/312]		Loss: 0.4485
2019-10-28 15:30:25,884 Training Epoch [5/40] Iter[159/312]		Loss: 0.4492
2019-10-28 15:30:25,963 Training Epoch [5/40] Iter[160/312]		Loss: 0.4484
2019-10-28 15:30:26,042 Training Epoch [5/40] Iter[161/312]		Loss: 0.4481
2019-10-28 15:30:26,121 Training Epoch [5/40] Iter[162/312]		Loss: 0.4477
2019-10-28 15:30:26,200 Training Epoch [5/40] Iter[163/312]		Loss: 0.4473
2019-10-28 15:30:26,278 Training Epoch [5/40] Iter[164/312]		Loss: 0.4470
2019-10-28 15:30:26,357 Training Epoch [5/40] Iter[165/312]		Loss: 0.4468
2019-10-28 15:30:26,436 Training Epoch [5/40] Iter[166/312]		Loss: 0.4465
2019-10-28 15:30:26,515 Training Epoch [5/40] Iter[167/312]		Loss: 0.4458
2019-10-28 15:30:26,594 Training Epoch [5/40] Iter[168/312]		Loss: 0.4460
2019-10-28 15:30:26,673 Training Epoch [5/40] Iter[169/312]		Loss: 0.4463
2019-10-28 15:30:26,751 Training Epoch [5/40] Iter[170/312]		Loss: 0.4458
2019-10-28 15:30:26,830 Training Epoch [5/40] Iter[171/312]		Loss: 0.4451
2019-10-28 15:30:26,909 Training Epoch [5/40] Iter[172/312]		Loss: 0.4444
2019-10-28 15:30:26,988 Training Epoch [5/40] Iter[173/312]		Loss: 0.4445
2019-10-28 15:30:27,067 Training Epoch [5/40] Iter[174/312]		Loss: 0.4448
2019-10-28 15:30:27,146 Training Epoch [5/40] Iter[175/312]		Loss: 0.4451
2019-10-28 15:30:27,225 Training Epoch [5/40] Iter[176/312]		Loss: 0.4456
2019-10-28 15:30:27,304 Training Epoch [5/40] Iter[177/312]		Loss: 0.4452
2019-10-28 15:30:27,383 Training Epoch [5/40] Iter[178/312]		Loss: 0.4462
2019-10-28 15:30:27,462 Training Epoch [5/40] Iter[179/312]		Loss: 0.4456
2019-10-28 15:30:27,541 Training Epoch [5/40] Iter[180/312]		Loss: 0.4452
2019-10-28 15:30:27,619 Training Epoch [5/40] Iter[181/312]		Loss: 0.4444
2019-10-28 15:30:27,698 Training Epoch [5/40] Iter[182/312]		Loss: 0.4441
2019-10-28 15:30:27,777 Training Epoch [5/40] Iter[183/312]		Loss: 0.4436
2019-10-28 15:30:27,856 Training Epoch [5/40] Iter[184/312]		Loss: 0.4427
2019-10-28 15:30:27,935 Training Epoch [5/40] Iter[185/312]		Loss: 0.4423
2019-10-28 15:30:28,014 Training Epoch [5/40] Iter[186/312]		Loss: 0.4419
2019-10-28 15:30:28,092 Training Epoch [5/40] Iter[187/312]		Loss: 0.4415
2019-10-28 15:30:28,172 Training Epoch [5/40] Iter[188/312]		Loss: 0.4412
2019-10-28 15:30:28,251 Training Epoch [5/40] Iter[189/312]		Loss: 0.4406
2019-10-28 15:30:28,330 Training Epoch [5/40] Iter[190/312]		Loss: 0.4414
2019-10-28 15:30:28,410 Training Epoch [5/40] Iter[191/312]		Loss: 0.4411
2019-10-28 15:30:28,489 Training Epoch [5/40] Iter[192/312]		Loss: 0.4405
2019-10-28 15:30:28,567 Training Epoch [5/40] Iter[193/312]		Loss: 0.4403
2019-10-28 15:30:28,646 Training Epoch [5/40] Iter[194/312]		Loss: 0.4397
2019-10-28 15:30:28,725 Training Epoch [5/40] Iter[195/312]		Loss: 0.4394
2019-10-28 15:30:28,804 Training Epoch [5/40] Iter[196/312]		Loss: 0.4392
2019-10-28 15:30:28,883 Training Epoch [5/40] Iter[197/312]		Loss: 0.4391
2019-10-28 15:30:28,962 Training Epoch [5/40] Iter[198/312]		Loss: 0.4388
2019-10-28 15:30:29,041 Training Epoch [5/40] Iter[199/312]		Loss: 0.4381
2019-10-28 15:30:29,120 Training Epoch [5/40] Iter[200/312]		Loss: 0.4382
2019-10-28 15:30:29,199 Training Epoch [5/40] Iter[201/312]		Loss: 0.4372
2019-10-28 15:30:29,278 Training Epoch [5/40] Iter[202/312]		Loss: 0.4367
2019-10-28 15:30:29,357 Training Epoch [5/40] Iter[203/312]		Loss: 0.4369
2019-10-28 15:30:29,437 Training Epoch [5/40] Iter[204/312]		Loss: 0.4367
2019-10-28 15:30:29,516 Training Epoch [5/40] Iter[205/312]		Loss: 0.4369
2019-10-28 15:30:29,595 Training Epoch [5/40] Iter[206/312]		Loss: 0.4367
2019-10-28 15:30:29,674 Training Epoch [5/40] Iter[207/312]		Loss: 0.4361
2019-10-28 15:30:29,753 Training Epoch [5/40] Iter[208/312]		Loss: 0.4354
2019-10-28 15:30:29,832 Training Epoch [5/40] Iter[209/312]		Loss: 0.4355
2019-10-28 15:30:29,911 Training Epoch [5/40] Iter[210/312]		Loss: 0.4353
2019-10-28 15:30:29,990 Training Epoch [5/40] Iter[211/312]		Loss: 0.4345
2019-10-28 15:30:30,069 Training Epoch [5/40] Iter[212/312]		Loss: 0.4349
2019-10-28 15:30:30,148 Training Epoch [5/40] Iter[213/312]		Loss: 0.4349
2019-10-28 15:30:30,227 Training Epoch [5/40] Iter[214/312]		Loss: 0.4358
2019-10-28 15:30:30,305 Training Epoch [5/40] Iter[215/312]		Loss: 0.4349
2019-10-28 15:30:30,384 Training Epoch [5/40] Iter[216/312]		Loss: 0.4351
2019-10-28 15:30:30,463 Training Epoch [5/40] Iter[217/312]		Loss: 0.4346
2019-10-28 15:30:30,542 Training Epoch [5/40] Iter[218/312]		Loss: 0.4353
2019-10-28 15:30:30,620 Training Epoch [5/40] Iter[219/312]		Loss: 0.4351
2019-10-28 15:30:30,699 Training Epoch [5/40] Iter[220/312]		Loss: 0.4352
2019-10-28 15:30:30,778 Training Epoch [5/40] Iter[221/312]		Loss: 0.4346
2019-10-28 15:30:30,857 Training Epoch [5/40] Iter[222/312]		Loss: 0.4344
2019-10-28 15:30:30,936 Training Epoch [5/40] Iter[223/312]		Loss: 0.4340
2019-10-28 15:30:31,015 Training Epoch [5/40] Iter[224/312]		Loss: 0.4337
2019-10-28 15:30:31,094 Training Epoch [5/40] Iter[225/312]		Loss: 0.4335
2019-10-28 15:30:31,173 Training Epoch [5/40] Iter[226/312]		Loss: 0.4335
2019-10-28 15:30:31,252 Training Epoch [5/40] Iter[227/312]		Loss: 0.4329
2019-10-28 15:30:31,331 Training Epoch [5/40] Iter[228/312]		Loss: 0.4329
2019-10-28 15:30:31,410 Training Epoch [5/40] Iter[229/312]		Loss: 0.4328
2019-10-28 15:30:31,488 Training Epoch [5/40] Iter[230/312]		Loss: 0.4330
2019-10-28 15:30:31,567 Training Epoch [5/40] Iter[231/312]		Loss: 0.4329
2019-10-28 15:30:31,646 Training Epoch [5/40] Iter[232/312]		Loss: 0.4327
2019-10-28 15:30:31,725 Training Epoch [5/40] Iter[233/312]		Loss: 0.4324
2019-10-28 15:30:31,804 Training Epoch [5/40] Iter[234/312]		Loss: 0.4323
2019-10-28 15:30:31,883 Training Epoch [5/40] Iter[235/312]		Loss: 0.4326
2019-10-28 15:30:31,962 Training Epoch [5/40] Iter[236/312]		Loss: 0.4324
2019-10-28 15:30:32,040 Training Epoch [5/40] Iter[237/312]		Loss: 0.4324
2019-10-28 15:30:32,119 Training Epoch [5/40] Iter[238/312]		Loss: 0.4328
2019-10-28 15:30:32,198 Training Epoch [5/40] Iter[239/312]		Loss: 0.4326
2019-10-28 15:30:32,277 Training Epoch [5/40] Iter[240/312]		Loss: 0.4323
2019-10-28 15:30:32,360 Training Epoch [5/40] Iter[241/312]		Loss: 0.4326
2019-10-28 15:30:32,439 Training Epoch [5/40] Iter[242/312]		Loss: 0.4319
2019-10-28 15:30:32,518 Training Epoch [5/40] Iter[243/312]		Loss: 0.4325
2019-10-28 15:30:32,597 Training Epoch [5/40] Iter[244/312]		Loss: 0.4326
2019-10-28 15:30:32,676 Training Epoch [5/40] Iter[245/312]		Loss: 0.4320
2019-10-28 15:30:32,754 Training Epoch [5/40] Iter[246/312]		Loss: 0.4322
2019-10-28 15:30:32,833 Training Epoch [5/40] Iter[247/312]		Loss: 0.4321
2019-10-28 15:30:32,912 Training Epoch [5/40] Iter[248/312]		Loss: 0.4322
2019-10-28 15:30:32,991 Training Epoch [5/40] Iter[249/312]		Loss: 0.4322
2019-10-28 15:30:33,069 Training Epoch [5/40] Iter[250/312]		Loss: 0.4319
2019-10-28 15:30:33,148 Training Epoch [5/40] Iter[251/312]		Loss: 0.4315
2019-10-28 15:30:33,227 Training Epoch [5/40] Iter[252/312]		Loss: 0.4326
2019-10-28 15:30:33,306 Training Epoch [5/40] Iter[253/312]		Loss: 0.4324
2019-10-28 15:30:33,386 Training Epoch [5/40] Iter[254/312]		Loss: 0.4323
2019-10-28 15:30:33,465 Training Epoch [5/40] Iter[255/312]		Loss: 0.4321
2019-10-28 15:30:33,543 Training Epoch [5/40] Iter[256/312]		Loss: 0.4324
2019-10-28 15:30:33,622 Training Epoch [5/40] Iter[257/312]		Loss: 0.4321
2019-10-28 15:30:33,701 Training Epoch [5/40] Iter[258/312]		Loss: 0.4323
2019-10-28 15:30:33,780 Training Epoch [5/40] Iter[259/312]		Loss: 0.4322
2019-10-28 15:30:33,859 Training Epoch [5/40] Iter[260/312]		Loss: 0.4319
2019-10-28 15:30:33,938 Training Epoch [5/40] Iter[261/312]		Loss: 0.4314
2019-10-28 15:30:34,017 Training Epoch [5/40] Iter[262/312]		Loss: 0.4312
2019-10-28 15:30:34,096 Training Epoch [5/40] Iter[263/312]		Loss: 0.4309
2019-10-28 15:30:34,175 Training Epoch [5/40] Iter[264/312]		Loss: 0.4307
2019-10-28 15:30:34,254 Training Epoch [5/40] Iter[265/312]		Loss: 0.4305
2019-10-28 15:30:34,333 Training Epoch [5/40] Iter[266/312]		Loss: 0.4306
2019-10-28 15:30:34,412 Training Epoch [5/40] Iter[267/312]		Loss: 0.4302
2019-10-28 15:30:34,491 Training Epoch [5/40] Iter[268/312]		Loss: 0.4304
2019-10-28 15:30:34,570 Training Epoch [5/40] Iter[269/312]		Loss: 0.4303
2019-10-28 15:30:34,649 Training Epoch [5/40] Iter[270/312]		Loss: 0.4299
2019-10-28 15:30:34,728 Training Epoch [5/40] Iter[271/312]		Loss: 0.4292
2019-10-28 15:30:34,807 Training Epoch [5/40] Iter[272/312]		Loss: 0.4289
2019-10-28 15:30:34,886 Training Epoch [5/40] Iter[273/312]		Loss: 0.4287
2019-10-28 15:30:34,965 Training Epoch [5/40] Iter[274/312]		Loss: 0.4286
2019-10-28 15:30:35,044 Training Epoch [5/40] Iter[275/312]		Loss: 0.4283
2019-10-28 15:30:35,123 Training Epoch [5/40] Iter[276/312]		Loss: 0.4283
2019-10-28 15:30:35,202 Training Epoch [5/40] Iter[277/312]		Loss: 0.4277
2019-10-28 15:30:35,281 Training Epoch [5/40] Iter[278/312]		Loss: 0.4276
2019-10-28 15:30:35,360 Training Epoch [5/40] Iter[279/312]		Loss: 0.4275
2019-10-28 15:30:35,439 Training Epoch [5/40] Iter[280/312]		Loss: 0.4278
2019-10-28 15:30:35,518 Training Epoch [5/40] Iter[281/312]		Loss: 0.4278
2019-10-28 15:30:35,597 Training Epoch [5/40] Iter[282/312]		Loss: 0.4280
2019-10-28 15:30:35,676 Training Epoch [5/40] Iter[283/312]		Loss: 0.4279
2019-10-28 15:30:35,755 Training Epoch [5/40] Iter[284/312]		Loss: 0.4278
2019-10-28 15:30:35,834 Training Epoch [5/40] Iter[285/312]		Loss: 0.4276
2019-10-28 15:30:35,913 Training Epoch [5/40] Iter[286/312]		Loss: 0.4276
2019-10-28 15:30:35,992 Training Epoch [5/40] Iter[287/312]		Loss: 0.4280
2019-10-28 15:30:36,071 Training Epoch [5/40] Iter[288/312]		Loss: 0.4285
2019-10-28 15:30:36,150 Training Epoch [5/40] Iter[289/312]		Loss: 0.4289
2019-10-28 15:30:36,229 Training Epoch [5/40] Iter[290/312]		Loss: 0.4288
2019-10-28 15:30:36,308 Training Epoch [5/40] Iter[291/312]		Loss: 0.4286
2019-10-28 15:30:36,387 Training Epoch [5/40] Iter[292/312]		Loss: 0.4283
2019-10-28 15:30:36,467 Training Epoch [5/40] Iter[293/312]		Loss: 0.4279
2019-10-28 15:30:36,545 Training Epoch [5/40] Iter[294/312]		Loss: 0.4275
2019-10-28 15:30:36,624 Training Epoch [5/40] Iter[295/312]		Loss: 0.4270
2019-10-28 15:30:36,703 Training Epoch [5/40] Iter[296/312]		Loss: 0.4266
2019-10-28 15:30:36,783 Training Epoch [5/40] Iter[297/312]		Loss: 0.4269
2019-10-28 15:30:36,862 Training Epoch [5/40] Iter[298/312]		Loss: 0.4269
2019-10-28 15:30:36,941 Training Epoch [5/40] Iter[299/312]		Loss: 0.4272
2019-10-28 15:30:37,020 Training Epoch [5/40] Iter[300/312]		Loss: 0.4266
2019-10-28 15:30:37,099 Training Epoch [5/40] Iter[301/312]		Loss: 0.4262
2019-10-28 15:30:37,178 Training Epoch [5/40] Iter[302/312]		Loss: 0.4258
2019-10-28 15:30:37,257 Training Epoch [5/40] Iter[303/312]		Loss: 0.4258
2019-10-28 15:30:37,337 Training Epoch [5/40] Iter[304/312]		Loss: 0.4256
2019-10-28 15:30:37,415 Training Epoch [5/40] Iter[305/312]		Loss: 0.4260
2019-10-28 15:30:37,493 Training Epoch [5/40] Iter[306/312]		Loss: 0.4255
2019-10-28 15:30:37,571 Training Epoch [5/40] Iter[307/312]		Loss: 0.4252
2019-10-28 15:30:37,649 Training Epoch [5/40] Iter[308/312]		Loss: 0.4247
2019-10-28 15:30:37,727 Training Epoch [5/40] Iter[309/312]		Loss: 0.4241
2019-10-28 15:30:37,806 Training Epoch [5/40] Iter[310/312]		Loss: 0.4241
2019-10-28 15:30:37,884 Training Epoch [5/40] Iter[311/312]		Loss: 0.4236
2019-10-28 15:30:37,923 Training Epoch [5/40] Iter[312/312]		Loss: 0.4229
2019-10-28 15:30:38,368 Testing Epoch [5/40] Iter[0/62]		Loss: 0.3716
2019-10-28 15:30:38,398 Testing Epoch [5/40] Iter[1/62]		Loss: 0.3266
2019-10-28 15:30:38,414 Testing Epoch [5/40] Iter[2/62]		Loss: 0.3221
2019-10-28 15:30:38,439 Testing Epoch [5/40] Iter[3/62]		Loss: 0.3314
2019-10-28 15:30:38,458 Testing Epoch [5/40] Iter[4/62]		Loss: 0.3378
2019-10-28 15:30:38,481 Testing Epoch [5/40] Iter[5/62]		Loss: 0.3267
2019-10-28 15:30:38,505 Testing Epoch [5/40] Iter[6/62]		Loss: 0.3280
2019-10-28 15:30:38,529 Testing Epoch [5/40] Iter[7/62]		Loss: 0.3367
2019-10-28 15:30:38,557 Testing Epoch [5/40] Iter[8/62]		Loss: 0.3438
2019-10-28 15:30:38,581 Testing Epoch [5/40] Iter[9/62]		Loss: 0.3432
2019-10-28 15:30:38,598 Testing Epoch [5/40] Iter[10/62]		Loss: 0.3337
2019-10-28 15:30:38,615 Testing Epoch [5/40] Iter[11/62]		Loss: 0.3327
2019-10-28 15:30:38,641 Testing Epoch [5/40] Iter[12/62]		Loss: 0.3348
2019-10-28 15:30:38,659 Testing Epoch [5/40] Iter[13/62]		Loss: 0.3357
2019-10-28 15:30:38,686 Testing Epoch [5/40] Iter[14/62]		Loss: 0.3569
2019-10-28 15:30:38,714 Testing Epoch [5/40] Iter[15/62]		Loss: 0.3620
2019-10-28 15:30:38,734 Testing Epoch [5/40] Iter[16/62]		Loss: 0.3584
2019-10-28 15:30:38,761 Testing Epoch [5/40] Iter[17/62]		Loss: 0.3535
2019-10-28 15:30:38,784 Testing Epoch [5/40] Iter[18/62]		Loss: 0.3480
2019-10-28 15:30:38,802 Testing Epoch [5/40] Iter[19/62]		Loss: 0.3472
2019-10-28 15:30:38,833 Testing Epoch [5/40] Iter[20/62]		Loss: 0.3543
2019-10-28 15:30:38,852 Testing Epoch [5/40] Iter[21/62]		Loss: 0.3574
2019-10-28 15:30:38,869 Testing Epoch [5/40] Iter[22/62]		Loss: 0.3615
2019-10-28 15:30:38,887 Testing Epoch [5/40] Iter[23/62]		Loss: 0.3603
2019-10-28 15:30:38,914 Testing Epoch [5/40] Iter[24/62]		Loss: 0.3641
2019-10-28 15:30:38,938 Testing Epoch [5/40] Iter[25/62]		Loss: 0.3616
2019-10-28 15:30:38,959 Testing Epoch [5/40] Iter[26/62]		Loss: 0.3594
2019-10-28 15:30:38,977 Testing Epoch [5/40] Iter[27/62]		Loss: 0.3657
2019-10-28 15:30:39,009 Testing Epoch [5/40] Iter[28/62]		Loss: 0.3650
2019-10-28 15:30:39,026 Testing Epoch [5/40] Iter[29/62]		Loss: 0.3653
2019-10-28 15:30:39,053 Testing Epoch [5/40] Iter[30/62]		Loss: 0.3648
2019-10-28 15:30:39,071 Testing Epoch [5/40] Iter[31/62]		Loss: 0.3647
2019-10-28 15:30:39,088 Testing Epoch [5/40] Iter[32/62]		Loss: 0.3658
2019-10-28 15:30:39,120 Testing Epoch [5/40] Iter[33/62]		Loss: 0.3655
2019-10-28 15:30:39,144 Testing Epoch [5/40] Iter[34/62]		Loss: 0.3670
2019-10-28 15:30:39,162 Testing Epoch [5/40] Iter[35/62]		Loss: 0.3659
2019-10-28 15:30:39,180 Testing Epoch [5/40] Iter[36/62]		Loss: 0.3616
2019-10-28 15:30:39,206 Testing Epoch [5/40] Iter[37/62]		Loss: 0.3611
2019-10-28 15:30:39,233 Testing Epoch [5/40] Iter[38/62]		Loss: 0.3629
2019-10-28 15:30:39,251 Testing Epoch [5/40] Iter[39/62]		Loss: 0.3647
2019-10-28 15:30:39,268 Testing Epoch [5/40] Iter[40/62]		Loss: 0.3681
2019-10-28 15:30:39,301 Testing Epoch [5/40] Iter[41/62]		Loss: 0.3708
2019-10-28 15:30:39,326 Testing Epoch [5/40] Iter[42/62]		Loss: 0.3687
2019-10-28 15:30:39,344 Testing Epoch [5/40] Iter[43/62]		Loss: 0.3670
2019-10-28 15:30:39,362 Testing Epoch [5/40] Iter[44/62]		Loss: 0.3648
2019-10-28 15:30:39,394 Testing Epoch [5/40] Iter[45/62]		Loss: 0.3650
2019-10-28 15:30:39,418 Testing Epoch [5/40] Iter[46/62]		Loss: 0.3652
2019-10-28 15:30:39,436 Testing Epoch [5/40] Iter[47/62]		Loss: 0.3694
2019-10-28 15:30:39,454 Testing Epoch [5/40] Iter[48/62]		Loss: 0.3671
2019-10-28 15:30:39,485 Testing Epoch [5/40] Iter[49/62]		Loss: 0.3701
2019-10-28 15:30:39,503 Testing Epoch [5/40] Iter[50/62]		Loss: 0.3690
2019-10-28 15:30:39,521 Testing Epoch [5/40] Iter[51/62]		Loss: 0.3687
2019-10-28 15:30:39,539 Testing Epoch [5/40] Iter[52/62]		Loss: 0.3662
2019-10-28 15:30:39,570 Testing Epoch [5/40] Iter[53/62]		Loss: 0.3666
2019-10-28 15:30:39,591 Testing Epoch [5/40] Iter[54/62]		Loss: 0.3652
2019-10-28 15:30:39,609 Testing Epoch [5/40] Iter[55/62]		Loss: 0.3644
2019-10-28 15:30:39,625 Testing Epoch [5/40] Iter[56/62]		Loss: 0.3637
2019-10-28 15:30:39,641 Testing Epoch [5/40] Iter[57/62]		Loss: 0.3652
2019-10-28 15:30:39,658 Testing Epoch [5/40] Iter[58/62]		Loss: 0.3644
2019-10-28 15:30:39,674 Testing Epoch [5/40] Iter[59/62]		Loss: 0.3641
2019-10-28 15:30:39,691 Testing Epoch [5/40] Iter[60/62]		Loss: 0.3622
2019-10-28 15:30:39,707 Testing Epoch [5/40] Iter[61/62]		Loss: 0.3636
2019-10-28 15:30:39,717 Testing Epoch [5/40] Iter[62/62]		Loss: 0.3668
2019-10-28 15:30:39,790 Saving the Model
2019-10-28 15:30:40,225 Training Epoch [6/40] Iter[0/312]		Loss: 0.3834
2019-10-28 15:30:40,304 Training Epoch [6/40] Iter[1/312]		Loss: 0.4861
2019-10-28 15:30:40,382 Training Epoch [6/40] Iter[2/312]		Loss: 0.5481
2019-10-28 15:30:40,460 Training Epoch [6/40] Iter[3/312]		Loss: 0.5158
2019-10-28 15:30:40,540 Training Epoch [6/40] Iter[4/312]		Loss: 0.5123
2019-10-28 15:30:40,618 Training Epoch [6/40] Iter[5/312]		Loss: 0.4813
2019-10-28 15:30:40,696 Training Epoch [6/40] Iter[6/312]		Loss: 0.4617
2019-10-28 15:30:40,774 Training Epoch [6/40] Iter[7/312]		Loss: 0.4622
2019-10-28 15:30:40,853 Training Epoch [6/40] Iter[8/312]		Loss: 0.4585
2019-10-28 15:30:40,932 Training Epoch [6/40] Iter[9/312]		Loss: 0.4598
2019-10-28 15:30:41,011 Training Epoch [6/40] Iter[10/312]		Loss: 0.4523
2019-10-28 15:30:41,090 Training Epoch [6/40] Iter[11/312]		Loss: 0.4408
2019-10-28 15:30:41,169 Training Epoch [6/40] Iter[12/312]		Loss: 0.4301
2019-10-28 15:30:41,248 Training Epoch [6/40] Iter[13/312]		Loss: 0.4311
2019-10-28 15:30:41,327 Training Epoch [6/40] Iter[14/312]		Loss: 0.4321
2019-10-28 15:30:41,406 Training Epoch [6/40] Iter[15/312]		Loss: 0.4322
2019-10-28 15:30:41,485 Training Epoch [6/40] Iter[16/312]		Loss: 0.4327
2019-10-28 15:30:41,564 Training Epoch [6/40] Iter[17/312]		Loss: 0.4404
2019-10-28 15:30:41,643 Training Epoch [6/40] Iter[18/312]		Loss: 0.4400
2019-10-28 15:30:41,722 Training Epoch [6/40] Iter[19/312]		Loss: 0.4334
2019-10-28 15:30:41,801 Training Epoch [6/40] Iter[20/312]		Loss: 0.4273
2019-10-28 15:30:41,879 Training Epoch [6/40] Iter[21/312]		Loss: 0.4218
2019-10-28 15:30:41,958 Training Epoch [6/40] Iter[22/312]		Loss: 0.4184
2019-10-28 15:30:42,037 Training Epoch [6/40] Iter[23/312]		Loss: 0.4180
2019-10-28 15:30:42,116 Training Epoch [6/40] Iter[24/312]		Loss: 0.4164
2019-10-28 15:30:42,195 Training Epoch [6/40] Iter[25/312]		Loss: 0.4188
2019-10-28 15:30:42,274 Training Epoch [6/40] Iter[26/312]		Loss: 0.4210
2019-10-28 15:30:42,354 Training Epoch [6/40] Iter[27/312]		Loss: 0.4171
2019-10-28 15:30:42,433 Training Epoch [6/40] Iter[28/312]		Loss: 0.4154
2019-10-28 15:30:42,511 Training Epoch [6/40] Iter[29/312]		Loss: 0.4166
2019-10-28 15:30:42,590 Training Epoch [6/40] Iter[30/312]		Loss: 0.4132
2019-10-28 15:30:42,669 Training Epoch [6/40] Iter[31/312]		Loss: 0.4088
2019-10-28 15:30:42,748 Training Epoch [6/40] Iter[32/312]		Loss: 0.4040
2019-10-28 15:30:42,827 Training Epoch [6/40] Iter[33/312]		Loss: 0.4017
2019-10-28 15:30:42,906 Training Epoch [6/40] Iter[34/312]		Loss: 0.4033
2019-10-28 15:30:42,985 Training Epoch [6/40] Iter[35/312]		Loss: 0.4020
2019-10-28 15:30:43,064 Training Epoch [6/40] Iter[36/312]		Loss: 0.3967
2019-10-28 15:30:43,142 Training Epoch [6/40] Iter[37/312]		Loss: 0.3958
2019-10-28 15:30:43,221 Training Epoch [6/40] Iter[38/312]		Loss: 0.3928
2019-10-28 15:30:43,300 Training Epoch [6/40] Iter[39/312]		Loss: 0.3912
2019-10-28 15:30:43,379 Training Epoch [6/40] Iter[40/312]		Loss: 0.3914
2019-10-28 15:30:43,458 Training Epoch [6/40] Iter[41/312]		Loss: 0.3934
2019-10-28 15:30:43,537 Training Epoch [6/40] Iter[42/312]		Loss: 0.3942
2019-10-28 15:30:43,616 Training Epoch [6/40] Iter[43/312]		Loss: 0.3922
2019-10-28 15:30:43,695 Training Epoch [6/40] Iter[44/312]		Loss: 0.3959
2019-10-28 15:30:43,774 Training Epoch [6/40] Iter[45/312]		Loss: 0.3954
2019-10-28 15:30:43,853 Training Epoch [6/40] Iter[46/312]		Loss: 0.3939
2019-10-28 15:30:43,932 Training Epoch [6/40] Iter[47/312]		Loss: 0.3951
2019-10-28 15:30:44,011 Training Epoch [6/40] Iter[48/312]		Loss: 0.3944
2019-10-28 15:30:44,089 Training Epoch [6/40] Iter[49/312]		Loss: 0.3962
2019-10-28 15:30:44,168 Training Epoch [6/40] Iter[50/312]		Loss: 0.3961
2019-10-28 15:30:44,247 Training Epoch [6/40] Iter[51/312]		Loss: 0.3937
2019-10-28 15:30:44,326 Training Epoch [6/40] Iter[52/312]		Loss: 0.3932
2019-10-28 15:30:44,405 Training Epoch [6/40] Iter[53/312]		Loss: 0.3919
2019-10-28 15:30:44,484 Training Epoch [6/40] Iter[54/312]		Loss: 0.3903
2019-10-28 15:30:44,563 Training Epoch [6/40] Iter[55/312]		Loss: 0.3906
2019-10-28 15:30:44,642 Training Epoch [6/40] Iter[56/312]		Loss: 0.3911
2019-10-28 15:30:44,721 Training Epoch [6/40] Iter[57/312]		Loss: 0.3920
2019-10-28 15:30:44,799 Training Epoch [6/40] Iter[58/312]		Loss: 0.3927
2019-10-28 15:30:44,878 Training Epoch [6/40] Iter[59/312]		Loss: 0.3902
2019-10-28 15:30:44,957 Training Epoch [6/40] Iter[60/312]		Loss: 0.3902
2019-10-28 15:30:45,036 Training Epoch [6/40] Iter[61/312]		Loss: 0.3898
2019-10-28 15:30:45,115 Training Epoch [6/40] Iter[62/312]		Loss: 0.3880
2019-10-28 15:30:45,195 Training Epoch [6/40] Iter[63/312]		Loss: 0.3876
2019-10-28 15:30:45,274 Training Epoch [6/40] Iter[64/312]		Loss: 0.3895
2019-10-28 15:30:45,353 Training Epoch [6/40] Iter[65/312]		Loss: 0.3884
2019-10-28 15:30:45,432 Training Epoch [6/40] Iter[66/312]		Loss: 0.3865
2019-10-28 15:30:45,512 Training Epoch [6/40] Iter[67/312]		Loss: 0.3856
2019-10-28 15:30:45,591 Training Epoch [6/40] Iter[68/312]		Loss: 0.3836
2019-10-28 15:30:45,670 Training Epoch [6/40] Iter[69/312]		Loss: 0.3820
2019-10-28 15:30:45,749 Training Epoch [6/40] Iter[70/312]		Loss: 0.3807
2019-10-28 15:30:45,828 Training Epoch [6/40] Iter[71/312]		Loss: 0.3795
2019-10-28 15:30:45,907 Training Epoch [6/40] Iter[72/312]		Loss: 0.3789
2019-10-28 15:30:45,986 Training Epoch [6/40] Iter[73/312]		Loss: 0.3794
2019-10-28 15:30:46,065 Training Epoch [6/40] Iter[74/312]		Loss: 0.3805
2019-10-28 15:30:46,144 Training Epoch [6/40] Iter[75/312]		Loss: 0.3799
2019-10-28 15:30:46,223 Training Epoch [6/40] Iter[76/312]		Loss: 0.3795
2019-10-28 15:30:46,302 Training Epoch [6/40] Iter[77/312]		Loss: 0.3789
2019-10-28 15:30:46,381 Training Epoch [6/40] Iter[78/312]		Loss: 0.3782
2019-10-28 15:30:46,460 Training Epoch [6/40] Iter[79/312]		Loss: 0.3781
2019-10-28 15:30:46,539 Training Epoch [6/40] Iter[80/312]		Loss: 0.3783
2019-10-28 15:30:46,618 Training Epoch [6/40] Iter[81/312]		Loss: 0.3782
2019-10-28 15:30:46,697 Training Epoch [6/40] Iter[82/312]		Loss: 0.3774
2019-10-28 15:30:46,776 Training Epoch [6/40] Iter[83/312]		Loss: 0.3765
2019-10-28 15:30:46,855 Training Epoch [6/40] Iter[84/312]		Loss: 0.3760
2019-10-28 15:30:46,934 Training Epoch [6/40] Iter[85/312]		Loss: 0.3756
2019-10-28 15:30:47,013 Training Epoch [6/40] Iter[86/312]		Loss: 0.3759
2019-10-28 15:30:47,091 Training Epoch [6/40] Iter[87/312]		Loss: 0.3755
2019-10-28 15:30:47,170 Training Epoch [6/40] Iter[88/312]		Loss: 0.3746
2019-10-28 15:30:47,249 Training Epoch [6/40] Iter[89/312]		Loss: 0.3749
2019-10-28 15:30:47,328 Training Epoch [6/40] Iter[90/312]		Loss: 0.3754
2019-10-28 15:30:47,408 Training Epoch [6/40] Iter[91/312]		Loss: 0.3761
2019-10-28 15:30:47,486 Training Epoch [6/40] Iter[92/312]		Loss: 0.3770
2019-10-28 15:30:47,565 Training Epoch [6/40] Iter[93/312]		Loss: 0.3772
2019-10-28 15:30:47,644 Training Epoch [6/40] Iter[94/312]		Loss: 0.3774
2019-10-28 15:30:47,723 Training Epoch [6/40] Iter[95/312]		Loss: 0.3765
2019-10-28 15:30:47,802 Training Epoch [6/40] Iter[96/312]		Loss: 0.3759
2019-10-28 15:30:47,881 Training Epoch [6/40] Iter[97/312]		Loss: 0.3757
2019-10-28 15:30:47,960 Training Epoch [6/40] Iter[98/312]		Loss: 0.3749
2019-10-28 15:30:48,039 Training Epoch [6/40] Iter[99/312]		Loss: 0.3741
2019-10-28 15:30:48,118 Training Epoch [6/40] Iter[100/312]		Loss: 0.3725
2019-10-28 15:30:48,197 Training Epoch [6/40] Iter[101/312]		Loss: 0.3722
2019-10-28 15:30:48,276 Training Epoch [6/40] Iter[102/312]		Loss: 0.3730
2019-10-28 15:30:48,355 Training Epoch [6/40] Iter[103/312]		Loss: 0.3735
2019-10-28 15:30:48,434 Training Epoch [6/40] Iter[104/312]		Loss: 0.3731
2019-10-28 15:30:48,513 Training Epoch [6/40] Iter[105/312]		Loss: 0.3728
2019-10-28 15:30:48,592 Training Epoch [6/40] Iter[106/312]		Loss: 0.3727
2019-10-28 15:30:48,670 Training Epoch [6/40] Iter[107/312]		Loss: 0.3726
2019-10-28 15:30:48,749 Training Epoch [6/40] Iter[108/312]		Loss: 0.3723
2019-10-28 15:30:48,828 Training Epoch [6/40] Iter[109/312]		Loss: 0.3719
2019-10-28 15:30:48,907 Training Epoch [6/40] Iter[110/312]		Loss: 0.3709
2019-10-28 15:30:48,986 Training Epoch [6/40] Iter[111/312]		Loss: 0.3721
2019-10-28 15:30:49,066 Training Epoch [6/40] Iter[112/312]		Loss: 0.3734
2019-10-28 15:30:49,145 Training Epoch [6/40] Iter[113/312]		Loss: 0.3736
2019-10-28 15:30:49,224 Training Epoch [6/40] Iter[114/312]		Loss: 0.3735
2019-10-28 15:30:49,303 Training Epoch [6/40] Iter[115/312]		Loss: 0.3729
2019-10-28 15:30:49,382 Training Epoch [6/40] Iter[116/312]		Loss: 0.3726
2019-10-28 15:30:49,462 Training Epoch [6/40] Iter[117/312]		Loss: 0.3717
2019-10-28 15:30:49,541 Training Epoch [6/40] Iter[118/312]		Loss: 0.3711
2019-10-28 15:30:49,620 Training Epoch [6/40] Iter[119/312]		Loss: 0.3700
2019-10-28 15:30:49,699 Training Epoch [6/40] Iter[120/312]		Loss: 0.3705
2019-10-28 15:30:49,778 Training Epoch [6/40] Iter[121/312]		Loss: 0.3699
2019-10-28 15:30:49,857 Training Epoch [6/40] Iter[122/312]		Loss: 0.3695
2019-10-28 15:30:49,936 Training Epoch [6/40] Iter[123/312]		Loss: 0.3690
2019-10-28 15:30:50,015 Training Epoch [6/40] Iter[124/312]		Loss: 0.3696
2019-10-28 15:30:50,094 Training Epoch [6/40] Iter[125/312]		Loss: 0.3691
2019-10-28 15:30:50,173 Training Epoch [6/40] Iter[126/312]		Loss: 0.3691
2019-10-28 15:30:50,252 Training Epoch [6/40] Iter[127/312]		Loss: 0.3702
2019-10-28 15:30:50,331 Training Epoch [6/40] Iter[128/312]		Loss: 0.3701
2019-10-28 15:30:50,410 Training Epoch [6/40] Iter[129/312]		Loss: 0.3697
2019-10-28 15:30:50,489 Training Epoch [6/40] Iter[130/312]		Loss: 0.3691
2019-10-28 15:30:50,568 Training Epoch [6/40] Iter[131/312]		Loss: 0.3679
2019-10-28 15:30:50,647 Training Epoch [6/40] Iter[132/312]		Loss: 0.3675
2019-10-28 15:30:50,726 Training Epoch [6/40] Iter[133/312]		Loss: 0.3670
2019-10-28 15:30:50,805 Training Epoch [6/40] Iter[134/312]		Loss: 0.3665
2019-10-28 15:30:50,884 Training Epoch [6/40] Iter[135/312]		Loss: 0.3668
2019-10-28 15:30:50,962 Training Epoch [6/40] Iter[136/312]		Loss: 0.3671
2019-10-28 15:30:51,042 Training Epoch [6/40] Iter[137/312]		Loss: 0.3668
2019-10-28 15:30:51,121 Training Epoch [6/40] Iter[138/312]		Loss: 0.3669
2019-10-28 15:30:51,200 Training Epoch [6/40] Iter[139/312]		Loss: 0.3669
2019-10-28 15:30:51,279 Training Epoch [6/40] Iter[140/312]		Loss: 0.3672
2019-10-28 15:30:51,358 Training Epoch [6/40] Iter[141/312]		Loss: 0.3669
2019-10-28 15:30:51,437 Training Epoch [6/40] Iter[142/312]		Loss: 0.3656
2019-10-28 15:30:51,516 Training Epoch [6/40] Iter[143/312]		Loss: 0.3656
2019-10-28 15:30:51,595 Training Epoch [6/40] Iter[144/312]		Loss: 0.3658
2019-10-28 15:30:51,674 Training Epoch [6/40] Iter[145/312]		Loss: 0.3664
2019-10-28 15:30:51,754 Training Epoch [6/40] Iter[146/312]		Loss: 0.3679
2019-10-28 15:30:51,832 Training Epoch [6/40] Iter[147/312]		Loss: 0.3673
2019-10-28 15:30:51,911 Training Epoch [6/40] Iter[148/312]		Loss: 0.3671
2019-10-28 15:30:51,990 Training Epoch [6/40] Iter[149/312]		Loss: 0.3674
2019-10-28 15:30:52,069 Training Epoch [6/40] Iter[150/312]		Loss: 0.3673
2019-10-28 15:30:52,148 Training Epoch [6/40] Iter[151/312]		Loss: 0.3672
2019-10-28 15:30:52,227 Training Epoch [6/40] Iter[152/312]		Loss: 0.3670
2019-10-28 15:30:52,307 Training Epoch [6/40] Iter[153/312]		Loss: 0.3667
2019-10-28 15:30:52,386 Training Epoch [6/40] Iter[154/312]		Loss: 0.3667
2019-10-28 15:30:52,465 Training Epoch [6/40] Iter[155/312]		Loss: 0.3660
2019-10-28 15:30:52,544 Training Epoch [6/40] Iter[156/312]		Loss: 0.3666
2019-10-28 15:30:52,627 Training Epoch [6/40] Iter[157/312]		Loss: 0.3668
2019-10-28 15:30:52,705 Training Epoch [6/40] Iter[158/312]		Loss: 0.3670
2019-10-28 15:30:52,784 Training Epoch [6/40] Iter[159/312]		Loss: 0.3678
2019-10-28 15:30:52,863 Training Epoch [6/40] Iter[160/312]		Loss: 0.3674
2019-10-28 15:30:52,946 Training Epoch [6/40] Iter[161/312]		Loss: 0.3670
2019-10-28 15:30:53,026 Training Epoch [6/40] Iter[162/312]		Loss: 0.3668
2019-10-28 15:30:53,104 Training Epoch [6/40] Iter[163/312]		Loss: 0.3669
2019-10-28 15:30:53,183 Training Epoch [6/40] Iter[164/312]		Loss: 0.3672
2019-10-28 15:30:53,263 Training Epoch [6/40] Iter[165/312]		Loss: 0.3675
2019-10-28 15:30:53,342 Training Epoch [6/40] Iter[166/312]		Loss: 0.3673
2019-10-28 15:30:53,421 Training Epoch [6/40] Iter[167/312]		Loss: 0.3666
2019-10-28 15:30:53,500 Training Epoch [6/40] Iter[168/312]		Loss: 0.3667
2019-10-28 15:30:53,579 Training Epoch [6/40] Iter[169/312]		Loss: 0.3673
2019-10-28 15:30:53,658 Training Epoch [6/40] Iter[170/312]		Loss: 0.3677
2019-10-28 15:30:53,737 Training Epoch [6/40] Iter[171/312]		Loss: 0.3683
2019-10-28 15:30:53,815 Training Epoch [6/40] Iter[172/312]		Loss: 0.3681
2019-10-28 15:30:53,894 Training Epoch [6/40] Iter[173/312]		Loss: 0.3685
2019-10-28 15:30:53,973 Training Epoch [6/40] Iter[174/312]		Loss: 0.3695
2019-10-28 15:30:54,052 Training Epoch [6/40] Iter[175/312]		Loss: 0.3698
2019-10-28 15:30:54,132 Training Epoch [6/40] Iter[176/312]		Loss: 0.3693
2019-10-28 15:30:54,212 Training Epoch [6/40] Iter[177/312]		Loss: 0.3700
2019-10-28 15:30:54,291 Training Epoch [6/40] Iter[178/312]		Loss: 0.3706
2019-10-28 15:30:54,371 Training Epoch [6/40] Iter[179/312]		Loss: 0.3706
2019-10-28 15:30:54,451 Training Epoch [6/40] Iter[180/312]		Loss: 0.3702
2019-10-28 15:30:54,530 Training Epoch [6/40] Iter[181/312]		Loss: 0.3693
2019-10-28 15:30:54,609 Training Epoch [6/40] Iter[182/312]		Loss: 0.3693
2019-10-28 15:30:54,688 Training Epoch [6/40] Iter[183/312]		Loss: 0.3696
2019-10-28 15:30:54,767 Training Epoch [6/40] Iter[184/312]		Loss: 0.3694
2019-10-28 15:30:54,846 Training Epoch [6/40] Iter[185/312]		Loss: 0.3697
2019-10-28 15:30:54,925 Training Epoch [6/40] Iter[186/312]		Loss: 0.3698
2019-10-28 15:30:55,005 Training Epoch [6/40] Iter[187/312]		Loss: 0.3695
2019-10-28 15:30:55,084 Training Epoch [6/40] Iter[188/312]		Loss: 0.3691
2019-10-28 15:30:55,163 Training Epoch [6/40] Iter[189/312]		Loss: 0.3686
2019-10-28 15:30:55,242 Training Epoch [6/40] Iter[190/312]		Loss: 0.3682
2019-10-28 15:30:55,321 Training Epoch [6/40] Iter[191/312]		Loss: 0.3682
2019-10-28 15:30:55,401 Training Epoch [6/40] Iter[192/312]		Loss: 0.3677
2019-10-28 15:30:55,480 Training Epoch [6/40] Iter[193/312]		Loss: 0.3689
2019-10-28 15:30:55,559 Training Epoch [6/40] Iter[194/312]		Loss: 0.3687
2019-10-28 15:30:55,638 Training Epoch [6/40] Iter[195/312]		Loss: 0.3681
2019-10-28 15:30:55,717 Training Epoch [6/40] Iter[196/312]		Loss: 0.3676
2019-10-28 15:30:55,796 Training Epoch [6/40] Iter[197/312]		Loss: 0.3674
2019-10-28 15:30:55,875 Training Epoch [6/40] Iter[198/312]		Loss: 0.3667
2019-10-28 15:30:55,954 Training Epoch [6/40] Iter[199/312]		Loss: 0.3659
2019-10-28 15:30:56,034 Training Epoch [6/40] Iter[200/312]		Loss: 0.3661
2019-10-28 15:30:56,113 Training Epoch [6/40] Iter[201/312]		Loss: 0.3663
2019-10-28 15:30:56,193 Training Epoch [6/40] Iter[202/312]		Loss: 0.3667
2019-10-28 15:30:56,272 Training Epoch [6/40] Iter[203/312]		Loss: 0.3662
2019-10-28 15:30:56,351 Training Epoch [6/40] Iter[204/312]		Loss: 0.3661
2019-10-28 15:30:56,431 Training Epoch [6/40] Iter[205/312]		Loss: 0.3662
2019-10-28 15:30:56,510 Training Epoch [6/40] Iter[206/312]		Loss: 0.3662
2019-10-28 15:30:56,589 Training Epoch [6/40] Iter[207/312]		Loss: 0.3664
2019-10-28 15:30:56,668 Training Epoch [6/40] Iter[208/312]		Loss: 0.3666
2019-10-28 15:30:56,747 Training Epoch [6/40] Iter[209/312]		Loss: 0.3665
2019-10-28 15:30:56,826 Training Epoch [6/40] Iter[210/312]		Loss: 0.3667
2019-10-28 15:30:56,905 Training Epoch [6/40] Iter[211/312]		Loss: 0.3672
2019-10-28 15:30:56,983 Training Epoch [6/40] Iter[212/312]		Loss: 0.3677
2019-10-28 15:30:57,062 Training Epoch [6/40] Iter[213/312]		Loss: 0.3672
2019-10-28 15:30:57,142 Training Epoch [6/40] Iter[214/312]		Loss: 0.3666
2019-10-28 15:30:57,221 Training Epoch [6/40] Iter[215/312]		Loss: 0.3665
2019-10-28 15:30:57,300 Training Epoch [6/40] Iter[216/312]		Loss: 0.3660
2019-10-28 15:30:57,379 Training Epoch [6/40] Iter[217/312]		Loss: 0.3667
2019-10-28 15:30:57,458 Training Epoch [6/40] Iter[218/312]		Loss: 0.3668
2019-10-28 15:30:57,537 Training Epoch [6/40] Iter[219/312]		Loss: 0.3668
2019-10-28 15:30:57,616 Training Epoch [6/40] Iter[220/312]		Loss: 0.3670
2019-10-28 15:30:57,695 Training Epoch [6/40] Iter[221/312]		Loss: 0.3674
2019-10-28 15:30:57,774 Training Epoch [6/40] Iter[222/312]		Loss: 0.3677
2019-10-28 15:30:57,853 Training Epoch [6/40] Iter[223/312]		Loss: 0.3677
2019-10-28 15:30:57,932 Training Epoch [6/40] Iter[224/312]		Loss: 0.3682
2019-10-28 15:30:58,011 Training Epoch [6/40] Iter[225/312]		Loss: 0.3683
2019-10-28 15:30:58,090 Training Epoch [6/40] Iter[226/312]		Loss: 0.3681
2019-10-28 15:30:58,169 Training Epoch [6/40] Iter[227/312]		Loss: 0.3680
2019-10-28 15:30:58,248 Training Epoch [6/40] Iter[228/312]		Loss: 0.3684
2019-10-28 15:30:58,327 Training Epoch [6/40] Iter[229/312]		Loss: 0.3686
2019-10-28 15:30:58,407 Training Epoch [6/40] Iter[230/312]		Loss: 0.3685
2019-10-28 15:30:58,485 Training Epoch [6/40] Iter[231/312]		Loss: 0.3684
2019-10-28 15:30:58,565 Training Epoch [6/40] Iter[232/312]		Loss: 0.3685
2019-10-28 15:30:58,643 Training Epoch [6/40] Iter[233/312]		Loss: 0.3683
2019-10-28 15:30:58,722 Training Epoch [6/40] Iter[234/312]		Loss: 0.3680
2019-10-28 15:30:58,801 Training Epoch [6/40] Iter[235/312]		Loss: 0.3683
2019-10-28 15:30:58,880 Training Epoch [6/40] Iter[236/312]		Loss: 0.3677
2019-10-28 15:30:58,959 Training Epoch [6/40] Iter[237/312]		Loss: 0.3675
2019-10-28 15:30:59,038 Training Epoch [6/40] Iter[238/312]		Loss: 0.3673
2019-10-28 15:30:59,117 Training Epoch [6/40] Iter[239/312]		Loss: 0.3670
2019-10-28 15:30:59,196 Training Epoch [6/40] Iter[240/312]		Loss: 0.3666
2019-10-28 15:30:59,275 Training Epoch [6/40] Iter[241/312]		Loss: 0.3668
2019-10-28 15:30:59,354 Training Epoch [6/40] Iter[242/312]		Loss: 0.3664
2019-10-28 15:30:59,433 Training Epoch [6/40] Iter[243/312]		Loss: 0.3664
2019-10-28 15:30:59,512 Training Epoch [6/40] Iter[244/312]		Loss: 0.3661
2019-10-28 15:30:59,591 Training Epoch [6/40] Iter[245/312]		Loss: 0.3660
2019-10-28 15:30:59,670 Training Epoch [6/40] Iter[246/312]		Loss: 0.3661
2019-10-28 15:30:59,749 Training Epoch [6/40] Iter[247/312]		Loss: 0.3663
2019-10-28 15:30:59,828 Training Epoch [6/40] Iter[248/312]		Loss: 0.3671
2019-10-28 15:30:59,906 Training Epoch [6/40] Iter[249/312]		Loss: 0.3666
2019-10-28 15:30:59,985 Training Epoch [6/40] Iter[250/312]		Loss: 0.3663
2019-10-28 15:31:00,064 Training Epoch [6/40] Iter[251/312]		Loss: 0.3660
2019-10-28 15:31:00,143 Training Epoch [6/40] Iter[252/312]		Loss: 0.3654
2019-10-28 15:31:00,223 Training Epoch [6/40] Iter[253/312]		Loss: 0.3652
2019-10-28 15:31:00,301 Training Epoch [6/40] Iter[254/312]		Loss: 0.3653
2019-10-28 15:31:00,380 Training Epoch [6/40] Iter[255/312]		Loss: 0.3647
2019-10-28 15:31:00,460 Training Epoch [6/40] Iter[256/312]		Loss: 0.3647
2019-10-28 15:31:00,539 Training Epoch [6/40] Iter[257/312]		Loss: 0.3643
2019-10-28 15:31:00,618 Training Epoch [6/40] Iter[258/312]		Loss: 0.3643
2019-10-28 15:31:00,697 Training Epoch [6/40] Iter[259/312]		Loss: 0.3639
2019-10-28 15:31:00,776 Training Epoch [6/40] Iter[260/312]		Loss: 0.3638
2019-10-28 15:31:00,855 Training Epoch [6/40] Iter[261/312]		Loss: 0.3633
2019-10-28 15:31:00,934 Training Epoch [6/40] Iter[262/312]		Loss: 0.3628
2019-10-28 15:31:01,013 Training Epoch [6/40] Iter[263/312]		Loss: 0.3626
2019-10-28 15:31:01,092 Training Epoch [6/40] Iter[264/312]		Loss: 0.3625
2019-10-28 15:31:01,171 Training Epoch [6/40] Iter[265/312]		Loss: 0.3624
2019-10-28 15:31:01,250 Training Epoch [6/40] Iter[266/312]		Loss: 0.3620
2019-10-28 15:31:01,329 Training Epoch [6/40] Iter[267/312]		Loss: 0.3616
2019-10-28 15:31:01,408 Training Epoch [6/40] Iter[268/312]		Loss: 0.3614
2019-10-28 15:31:01,487 Training Epoch [6/40] Iter[269/312]		Loss: 0.3614
2019-10-28 15:31:01,566 Training Epoch [6/40] Iter[270/312]		Loss: 0.3611
2019-10-28 15:31:01,646 Training Epoch [6/40] Iter[271/312]		Loss: 0.3607
2019-10-28 15:31:01,725 Training Epoch [6/40] Iter[272/312]		Loss: 0.3608
2019-10-28 15:31:01,805 Training Epoch [6/40] Iter[273/312]		Loss: 0.3606
2019-10-28 15:31:01,885 Training Epoch [6/40] Iter[274/312]		Loss: 0.3603
2019-10-28 15:31:01,964 Training Epoch [6/40] Iter[275/312]		Loss: 0.3607
2019-10-28 15:31:02,043 Training Epoch [6/40] Iter[276/312]		Loss: 0.3602
2019-10-28 15:31:02,122 Training Epoch [6/40] Iter[277/312]		Loss: 0.3601
2019-10-28 15:31:02,200 Training Epoch [6/40] Iter[278/312]		Loss: 0.3602
2019-10-28 15:31:02,279 Training Epoch [6/40] Iter[279/312]		Loss: 0.3603
2019-10-28 15:31:02,359 Training Epoch [6/40] Iter[280/312]		Loss: 0.3603
2019-10-28 15:31:02,438 Training Epoch [6/40] Iter[281/312]		Loss: 0.3605
2019-10-28 15:31:02,517 Training Epoch [6/40] Iter[282/312]		Loss: 0.3602
2019-10-28 15:31:02,595 Training Epoch [6/40] Iter[283/312]		Loss: 0.3602
2019-10-28 15:31:02,678 Training Epoch [6/40] Iter[284/312]		Loss: 0.3601
2019-10-28 15:31:02,758 Training Epoch [6/40] Iter[285/312]		Loss: 0.3602
2019-10-28 15:31:02,837 Training Epoch [6/40] Iter[286/312]		Loss: 0.3600
2019-10-28 15:31:02,916 Training Epoch [6/40] Iter[287/312]		Loss: 0.3600
2019-10-28 15:31:02,999 Training Epoch [6/40] Iter[288/312]		Loss: 0.3597
2019-10-28 15:31:03,078 Training Epoch [6/40] Iter[289/312]		Loss: 0.3601
2019-10-28 15:31:03,157 Training Epoch [6/40] Iter[290/312]		Loss: 0.3605
2019-10-28 15:31:03,236 Training Epoch [6/40] Iter[291/312]		Loss: 0.3602
2019-10-28 15:31:03,319 Training Epoch [6/40] Iter[292/312]		Loss: 0.3602
2019-10-28 15:31:03,398 Training Epoch [6/40] Iter[293/312]		Loss: 0.3601
2019-10-28 15:31:03,477 Training Epoch [6/40] Iter[294/312]		Loss: 0.3601
2019-10-28 15:31:03,556 Training Epoch [6/40] Iter[295/312]		Loss: 0.3597
2019-10-28 15:31:03,635 Training Epoch [6/40] Iter[296/312]		Loss: 0.3595
2019-10-28 15:31:03,714 Training Epoch [6/40] Iter[297/312]		Loss: 0.3598
2019-10-28 15:31:03,793 Training Epoch [6/40] Iter[298/312]		Loss: 0.3596
2019-10-28 15:31:03,872 Training Epoch [6/40] Iter[299/312]		Loss: 0.3595
2019-10-28 15:31:03,951 Training Epoch [6/40] Iter[300/312]		Loss: 0.3592
2019-10-28 15:31:04,030 Training Epoch [6/40] Iter[301/312]		Loss: 0.3588
2019-10-28 15:31:04,108 Training Epoch [6/40] Iter[302/312]		Loss: 0.3586
2019-10-28 15:31:04,187 Training Epoch [6/40] Iter[303/312]		Loss: 0.3591
2019-10-28 15:31:04,266 Training Epoch [6/40] Iter[304/312]		Loss: 0.3591
2019-10-28 15:31:04,344 Training Epoch [6/40] Iter[305/312]		Loss: 0.3588
2019-10-28 15:31:04,423 Training Epoch [6/40] Iter[306/312]		Loss: 0.3590
2019-10-28 15:31:04,501 Training Epoch [6/40] Iter[307/312]		Loss: 0.3587
2019-10-28 15:31:04,579 Training Epoch [6/40] Iter[308/312]		Loss: 0.3586
2019-10-28 15:31:04,657 Training Epoch [6/40] Iter[309/312]		Loss: 0.3584
2019-10-28 15:31:04,735 Training Epoch [6/40] Iter[310/312]		Loss: 0.3582
2019-10-28 15:31:04,813 Training Epoch [6/40] Iter[311/312]		Loss: 0.3578
2019-10-28 15:31:04,852 Training Epoch [6/40] Iter[312/312]		Loss: 0.3576
2019-10-28 15:31:05,294 Testing Epoch [6/40] Iter[0/62]		Loss: 0.3247
2019-10-28 15:31:05,326 Testing Epoch [6/40] Iter[1/62]		Loss: 0.3305
2019-10-28 15:31:05,348 Testing Epoch [6/40] Iter[2/62]		Loss: 0.3123
2019-10-28 15:31:05,365 Testing Epoch [6/40] Iter[3/62]		Loss: 0.2997
2019-10-28 15:31:05,392 Testing Epoch [6/40] Iter[4/62]		Loss: 0.2968
2019-10-28 15:31:05,417 Testing Epoch [6/40] Iter[5/62]		Loss: 0.2869
2019-10-28 15:31:05,437 Testing Epoch [6/40] Iter[6/62]		Loss: 0.2980
2019-10-28 15:31:05,453 Testing Epoch [6/40] Iter[7/62]		Loss: 0.2982
2019-10-28 15:31:05,481 Testing Epoch [6/40] Iter[8/62]		Loss: 0.3117
2019-10-28 15:31:05,509 Testing Epoch [6/40] Iter[9/62]		Loss: 0.3149
2019-10-28 15:31:05,527 Testing Epoch [6/40] Iter[10/62]		Loss: 0.3089
2019-10-28 15:31:05,557 Testing Epoch [6/40] Iter[11/62]		Loss: 0.3124
2019-10-28 15:31:05,577 Testing Epoch [6/40] Iter[12/62]		Loss: 0.3126
2019-10-28 15:31:05,595 Testing Epoch [6/40] Iter[13/62]		Loss: 0.3134
2019-10-28 15:31:05,613 Testing Epoch [6/40] Iter[14/62]		Loss: 0.3299
2019-10-28 15:31:05,638 Testing Epoch [6/40] Iter[15/62]		Loss: 0.3331
2019-10-28 15:31:05,661 Testing Epoch [6/40] Iter[16/62]		Loss: 0.3291
2019-10-28 15:31:05,688 Testing Epoch [6/40] Iter[17/62]		Loss: 0.3264
2019-10-28 15:31:05,713 Testing Epoch [6/40] Iter[18/62]		Loss: 0.3185
2019-10-28 15:31:05,738 Testing Epoch [6/40] Iter[19/62]		Loss: 0.3153
2019-10-28 15:31:05,755 Testing Epoch [6/40] Iter[20/62]		Loss: 0.3205
2019-10-28 15:31:05,773 Testing Epoch [6/40] Iter[21/62]		Loss: 0.3204
2019-10-28 15:31:05,801 Testing Epoch [6/40] Iter[22/62]		Loss: 0.3229
2019-10-28 15:31:05,830 Testing Epoch [6/40] Iter[23/62]		Loss: 0.3241
2019-10-28 15:31:05,849 Testing Epoch [6/40] Iter[24/62]		Loss: 0.3277
2019-10-28 15:31:05,873 Testing Epoch [6/40] Iter[25/62]		Loss: 0.3243
2019-10-28 15:31:05,891 Testing Epoch [6/40] Iter[26/62]		Loss: 0.3218
2019-10-28 15:31:05,909 Testing Epoch [6/40] Iter[27/62]		Loss: 0.3296
2019-10-28 15:31:05,938 Testing Epoch [6/40] Iter[28/62]		Loss: 0.3299
2019-10-28 15:31:05,956 Testing Epoch [6/40] Iter[29/62]		Loss: 0.3319
2019-10-28 15:31:05,974 Testing Epoch [6/40] Iter[30/62]		Loss: 0.3313
2019-10-28 15:31:05,992 Testing Epoch [6/40] Iter[31/62]		Loss: 0.3315
2019-10-28 15:31:06,025 Testing Epoch [6/40] Iter[32/62]		Loss: 0.3336
2019-10-28 15:31:06,045 Testing Epoch [6/40] Iter[33/62]		Loss: 0.3335
2019-10-28 15:31:06,065 Testing Epoch [6/40] Iter[34/62]		Loss: 0.3352
2019-10-28 15:31:06,093 Testing Epoch [6/40] Iter[35/62]		Loss: 0.3350
2019-10-28 15:31:06,110 Testing Epoch [6/40] Iter[36/62]		Loss: 0.3326
2019-10-28 15:31:06,137 Testing Epoch [6/40] Iter[37/62]		Loss: 0.3316
2019-10-28 15:31:06,156 Testing Epoch [6/40] Iter[38/62]		Loss: 0.3305
2019-10-28 15:31:06,173 Testing Epoch [6/40] Iter[39/62]		Loss: 0.3309
2019-10-28 15:31:06,198 Testing Epoch [6/40] Iter[40/62]		Loss: 0.3327
2019-10-28 15:31:06,227 Testing Epoch [6/40] Iter[41/62]		Loss: 0.3342
2019-10-28 15:31:06,244 Testing Epoch [6/40] Iter[42/62]		Loss: 0.3316
2019-10-28 15:31:06,262 Testing Epoch [6/40] Iter[43/62]		Loss: 0.3305
2019-10-28 15:31:06,293 Testing Epoch [6/40] Iter[44/62]		Loss: 0.3284
2019-10-28 15:31:06,317 Testing Epoch [6/40] Iter[45/62]		Loss: 0.3288
2019-10-28 15:31:06,342 Testing Epoch [6/40] Iter[46/62]		Loss: 0.3289
2019-10-28 15:31:06,362 Testing Epoch [6/40] Iter[47/62]		Loss: 0.3342
2019-10-28 15:31:06,389 Testing Epoch [6/40] Iter[48/62]		Loss: 0.3319
2019-10-28 15:31:06,415 Testing Epoch [6/40] Iter[49/62]		Loss: 0.3335
2019-10-28 15:31:06,433 Testing Epoch [6/40] Iter[50/62]		Loss: 0.3335
2019-10-28 15:31:06,451 Testing Epoch [6/40] Iter[51/62]		Loss: 0.3324
2019-10-28 15:31:06,481 Testing Epoch [6/40] Iter[52/62]		Loss: 0.3298
2019-10-28 15:31:06,506 Testing Epoch [6/40] Iter[53/62]		Loss: 0.3296
2019-10-28 15:31:06,524 Testing Epoch [6/40] Iter[54/62]		Loss: 0.3277
2019-10-28 15:31:06,541 Testing Epoch [6/40] Iter[55/62]		Loss: 0.3267
2019-10-28 15:31:06,558 Testing Epoch [6/40] Iter[56/62]		Loss: 0.3268
2019-10-28 15:31:06,574 Testing Epoch [6/40] Iter[57/62]		Loss: 0.3277
2019-10-28 15:31:06,591 Testing Epoch [6/40] Iter[58/62]		Loss: 0.3264
2019-10-28 15:31:06,608 Testing Epoch [6/40] Iter[59/62]		Loss: 0.3266
2019-10-28 15:31:06,624 Testing Epoch [6/40] Iter[60/62]		Loss: 0.3264
2019-10-28 15:31:06,641 Testing Epoch [6/40] Iter[61/62]		Loss: 0.3270
2019-10-28 15:31:06,650 Testing Epoch [6/40] Iter[62/62]		Loss: 0.3292
2019-10-28 15:31:06,723 Saving the Model
2019-10-28 15:31:07,154 Training Epoch [7/40] Iter[0/312]		Loss: 0.3191
2019-10-28 15:31:07,235 Training Epoch [7/40] Iter[1/312]		Loss: 0.3831
2019-10-28 15:31:07,313 Training Epoch [7/40] Iter[2/312]		Loss: 0.3982
2019-10-28 15:31:07,393 Training Epoch [7/40] Iter[3/312]		Loss: 0.4234
2019-10-28 15:31:07,474 Training Epoch [7/40] Iter[4/312]		Loss: 0.4099
2019-10-28 15:31:07,552 Training Epoch [7/40] Iter[5/312]		Loss: 0.4294
2019-10-28 15:31:07,630 Training Epoch [7/40] Iter[6/312]		Loss: 0.4289
2019-10-28 15:31:07,709 Training Epoch [7/40] Iter[7/312]		Loss: 0.4368
2019-10-28 15:31:07,789 Training Epoch [7/40] Iter[8/312]		Loss: 0.4449
2019-10-28 15:31:07,868 Training Epoch [7/40] Iter[9/312]		Loss: 0.4412
2019-10-28 15:31:07,947 Training Epoch [7/40] Iter[10/312]		Loss: 0.4508
2019-10-28 15:31:08,026 Training Epoch [7/40] Iter[11/312]		Loss: 0.4470
2019-10-28 15:31:08,106 Training Epoch [7/40] Iter[12/312]		Loss: 0.4453
2019-10-28 15:31:08,185 Training Epoch [7/40] Iter[13/312]		Loss: 0.4464
2019-10-28 15:31:08,264 Training Epoch [7/40] Iter[14/312]		Loss: 0.4533
2019-10-28 15:31:08,343 Training Epoch [7/40] Iter[15/312]		Loss: 0.4487
2019-10-28 15:31:08,423 Training Epoch [7/40] Iter[16/312]		Loss: 0.4416
2019-10-28 15:31:08,502 Training Epoch [7/40] Iter[17/312]		Loss: 0.4404
2019-10-28 15:31:08,581 Training Epoch [7/40] Iter[18/312]		Loss: 0.4416
2019-10-28 15:31:08,661 Training Epoch [7/40] Iter[19/312]		Loss: 0.4387
2019-10-28 15:31:08,740 Training Epoch [7/40] Iter[20/312]		Loss: 0.4303
2019-10-28 15:31:08,819 Training Epoch [7/40] Iter[21/312]		Loss: 0.4245
2019-10-28 15:31:08,898 Training Epoch [7/40] Iter[22/312]		Loss: 0.4247
2019-10-28 15:31:08,978 Training Epoch [7/40] Iter[23/312]		Loss: 0.4235
2019-10-28 15:31:09,057 Training Epoch [7/40] Iter[24/312]		Loss: 0.4205
2019-10-28 15:31:09,137 Training Epoch [7/40] Iter[25/312]		Loss: 0.4176
2019-10-28 15:31:09,216 Training Epoch [7/40] Iter[26/312]		Loss: 0.4144
2019-10-28 15:31:09,295 Training Epoch [7/40] Iter[27/312]		Loss: 0.4119
2019-10-28 15:31:09,375 Training Epoch [7/40] Iter[28/312]		Loss: 0.4101
2019-10-28 15:31:09,454 Training Epoch [7/40] Iter[29/312]		Loss: 0.4130
2019-10-28 15:31:09,534 Training Epoch [7/40] Iter[30/312]		Loss: 0.4141
2019-10-28 15:31:09,613 Training Epoch [7/40] Iter[31/312]		Loss: 0.4140
2019-10-28 15:31:09,692 Training Epoch [7/40] Iter[32/312]		Loss: 0.4136
2019-10-28 15:31:09,772 Training Epoch [7/40] Iter[33/312]		Loss: 0.4167
2019-10-28 15:31:09,851 Training Epoch [7/40] Iter[34/312]		Loss: 0.4152
2019-10-28 15:31:09,930 Training Epoch [7/40] Iter[35/312]		Loss: 0.4138
2019-10-28 15:31:10,010 Training Epoch [7/40] Iter[36/312]		Loss: 0.4108
2019-10-28 15:31:10,089 Training Epoch [7/40] Iter[37/312]		Loss: 0.4066
2019-10-28 15:31:10,168 Training Epoch [7/40] Iter[38/312]		Loss: 0.4033
2019-10-28 15:31:10,247 Training Epoch [7/40] Iter[39/312]		Loss: 0.4020
2019-10-28 15:31:10,326 Training Epoch [7/40] Iter[40/312]		Loss: 0.4000
2019-10-28 15:31:10,406 Training Epoch [7/40] Iter[41/312]		Loss: 0.3991
2019-10-28 15:31:10,485 Training Epoch [7/40] Iter[42/312]		Loss: 0.3960
2019-10-28 15:31:10,564 Training Epoch [7/40] Iter[43/312]		Loss: 0.3948
2019-10-28 15:31:10,643 Training Epoch [7/40] Iter[44/312]		Loss: 0.3922
2019-10-28 15:31:10,723 Training Epoch [7/40] Iter[45/312]		Loss: 0.3900
2019-10-28 15:31:10,802 Training Epoch [7/40] Iter[46/312]		Loss: 0.3861
2019-10-28 15:31:10,882 Training Epoch [7/40] Iter[47/312]		Loss: 0.3848
2019-10-28 15:31:10,961 Training Epoch [7/40] Iter[48/312]		Loss: 0.3860
2019-10-28 15:31:11,040 Training Epoch [7/40] Iter[49/312]		Loss: 0.3870
2019-10-28 15:31:11,120 Training Epoch [7/40] Iter[50/312]		Loss: 0.3858
2019-10-28 15:31:11,200 Training Epoch [7/40] Iter[51/312]		Loss: 0.3840
2019-10-28 15:31:11,279 Training Epoch [7/40] Iter[52/312]		Loss: 0.3842
2019-10-28 15:31:11,359 Training Epoch [7/40] Iter[53/312]		Loss: 0.3830
2019-10-28 15:31:11,438 Training Epoch [7/40] Iter[54/312]		Loss: 0.3834
2019-10-28 15:31:11,517 Training Epoch [7/40] Iter[55/312]		Loss: 0.3838
2019-10-28 15:31:11,597 Training Epoch [7/40] Iter[56/312]		Loss: 0.3818
2019-10-28 15:31:11,676 Training Epoch [7/40] Iter[57/312]		Loss: 0.3798
2019-10-28 15:31:11,755 Training Epoch [7/40] Iter[58/312]		Loss: 0.3770
2019-10-28 15:31:11,835 Training Epoch [7/40] Iter[59/312]		Loss: 0.3745
2019-10-28 15:31:11,914 Training Epoch [7/40] Iter[60/312]		Loss: 0.3722
2019-10-28 15:31:11,994 Training Epoch [7/40] Iter[61/312]		Loss: 0.3707
2019-10-28 15:31:12,073 Training Epoch [7/40] Iter[62/312]		Loss: 0.3696
2019-10-28 15:31:12,153 Training Epoch [7/40] Iter[63/312]		Loss: 0.3684
2019-10-28 15:31:12,232 Training Epoch [7/40] Iter[64/312]		Loss: 0.3683
2019-10-28 15:31:12,312 Training Epoch [7/40] Iter[65/312]		Loss: 0.3671
2019-10-28 15:31:12,391 Training Epoch [7/40] Iter[66/312]		Loss: 0.3650
2019-10-28 15:31:12,470 Training Epoch [7/40] Iter[67/312]		Loss: 0.3651
2019-10-28 15:31:12,549 Training Epoch [7/40] Iter[68/312]		Loss: 0.3625
2019-10-28 15:31:12,628 Training Epoch [7/40] Iter[69/312]		Loss: 0.3639
2019-10-28 15:31:12,707 Training Epoch [7/40] Iter[70/312]		Loss: 0.3636
2019-10-28 15:31:12,787 Training Epoch [7/40] Iter[71/312]		Loss: 0.3643
2019-10-28 15:31:12,866 Training Epoch [7/40] Iter[72/312]		Loss: 0.3632
2019-10-28 15:31:12,945 Training Epoch [7/40] Iter[73/312]		Loss: 0.3627
2019-10-28 15:31:13,024 Training Epoch [7/40] Iter[74/312]		Loss: 0.3626
2019-10-28 15:31:13,103 Training Epoch [7/40] Iter[75/312]		Loss: 0.3624
2019-10-28 15:31:13,183 Training Epoch [7/40] Iter[76/312]		Loss: 0.3620
2019-10-28 15:31:13,263 Training Epoch [7/40] Iter[77/312]		Loss: 0.3621
2019-10-28 15:31:13,342 Training Epoch [7/40] Iter[78/312]		Loss: 0.3622
2019-10-28 15:31:13,421 Training Epoch [7/40] Iter[79/312]		Loss: 0.3617
2019-10-28 15:31:13,500 Training Epoch [7/40] Iter[80/312]		Loss: 0.3610
2019-10-28 15:31:13,579 Training Epoch [7/40] Iter[81/312]		Loss: 0.3593
2019-10-28 15:31:13,658 Training Epoch [7/40] Iter[82/312]		Loss: 0.3587
2019-10-28 15:31:13,738 Training Epoch [7/40] Iter[83/312]		Loss: 0.3579
2019-10-28 15:31:13,818 Training Epoch [7/40] Iter[84/312]		Loss: 0.3565
2019-10-28 15:31:13,899 Training Epoch [7/40] Iter[85/312]		Loss: 0.3571
2019-10-28 15:31:13,978 Training Epoch [7/40] Iter[86/312]		Loss: 0.3560
2019-10-28 15:31:14,057 Training Epoch [7/40] Iter[87/312]		Loss: 0.3547
2019-10-28 15:31:14,139 Training Epoch [7/40] Iter[88/312]		Loss: 0.3579
2019-10-28 15:31:14,219 Training Epoch [7/40] Iter[89/312]		Loss: 0.3575
2019-10-28 15:31:14,298 Training Epoch [7/40] Iter[90/312]		Loss: 0.3570
2019-10-28 15:31:14,383 Training Epoch [7/40] Iter[91/312]		Loss: 0.3557
2019-10-28 15:31:14,463 Training Epoch [7/40] Iter[92/312]		Loss: 0.3550
2019-10-28 15:31:14,543 Training Epoch [7/40] Iter[93/312]		Loss: 0.3544
2019-10-28 15:31:14,623 Training Epoch [7/40] Iter[94/312]		Loss: 0.3542
2019-10-28 15:31:14,702 Training Epoch [7/40] Iter[95/312]		Loss: 0.3531
2019-10-28 15:31:14,781 Training Epoch [7/40] Iter[96/312]		Loss: 0.3542
2019-10-28 15:31:14,862 Training Epoch [7/40] Iter[97/312]		Loss: 0.3537
2019-10-28 15:31:14,943 Training Epoch [7/40] Iter[98/312]		Loss: 0.3542
2019-10-28 15:31:15,022 Training Epoch [7/40] Iter[99/312]		Loss: 0.3534
2019-10-28 15:31:15,102 Training Epoch [7/40] Iter[100/312]		Loss: 0.3533
2019-10-28 15:31:15,183 Training Epoch [7/40] Iter[101/312]		Loss: 0.3525
2019-10-28 15:31:15,262 Training Epoch [7/40] Iter[102/312]		Loss: 0.3526
2019-10-28 15:31:15,342 Training Epoch [7/40] Iter[103/312]		Loss: 0.3518
2019-10-28 15:31:15,421 Training Epoch [7/40] Iter[104/312]		Loss: 0.3523
2019-10-28 15:31:15,503 Training Epoch [7/40] Iter[105/312]		Loss: 0.3519
2019-10-28 15:31:15,583 Training Epoch [7/40] Iter[106/312]		Loss: 0.3527
2019-10-28 15:31:15,662 Training Epoch [7/40] Iter[107/312]		Loss: 0.3527
2019-10-28 15:31:15,741 Training Epoch [7/40] Iter[108/312]		Loss: 0.3537
2019-10-28 15:31:15,823 Training Epoch [7/40] Iter[109/312]		Loss: 0.3528
2019-10-28 15:31:15,902 Training Epoch [7/40] Iter[110/312]		Loss: 0.3522
2019-10-28 15:31:15,981 Training Epoch [7/40] Iter[111/312]		Loss: 0.3518
2019-10-28 15:31:16,060 Training Epoch [7/40] Iter[112/312]		Loss: 0.3510
2019-10-28 15:31:16,139 Training Epoch [7/40] Iter[113/312]		Loss: 0.3512
2019-10-28 15:31:16,218 Training Epoch [7/40] Iter[114/312]		Loss: 0.3508
2019-10-28 15:31:16,297 Training Epoch [7/40] Iter[115/312]		Loss: 0.3506
2019-10-28 15:31:16,377 Training Epoch [7/40] Iter[116/312]		Loss: 0.3512
2019-10-28 15:31:16,456 Training Epoch [7/40] Iter[117/312]		Loss: 0.3509
2019-10-28 15:31:16,535 Training Epoch [7/40] Iter[118/312]		Loss: 0.3502
2019-10-28 15:31:16,614 Training Epoch [7/40] Iter[119/312]		Loss: 0.3495
2019-10-28 15:31:16,693 Training Epoch [7/40] Iter[120/312]		Loss: 0.3488
2019-10-28 15:31:16,772 Training Epoch [7/40] Iter[121/312]		Loss: 0.3480
2019-10-28 15:31:16,851 Training Epoch [7/40] Iter[122/312]		Loss: 0.3471
2019-10-28 15:31:16,930 Training Epoch [7/40] Iter[123/312]		Loss: 0.3461
2019-10-28 15:31:17,009 Training Epoch [7/40] Iter[124/312]		Loss: 0.3458
2019-10-28 15:31:17,088 Training Epoch [7/40] Iter[125/312]		Loss: 0.3459
2019-10-28 15:31:17,167 Training Epoch [7/40] Iter[126/312]		Loss: 0.3456
2019-10-28 15:31:17,247 Training Epoch [7/40] Iter[127/312]		Loss: 0.3462
2019-10-28 15:31:17,326 Training Epoch [7/40] Iter[128/312]		Loss: 0.3454
2019-10-28 15:31:17,406 Training Epoch [7/40] Iter[129/312]		Loss: 0.3463
2019-10-28 15:31:17,485 Training Epoch [7/40] Iter[130/312]		Loss: 0.3458
2019-10-28 15:31:17,564 Training Epoch [7/40] Iter[131/312]		Loss: 0.3460
2019-10-28 15:31:17,643 Training Epoch [7/40] Iter[132/312]		Loss: 0.3453
2019-10-28 15:31:17,722 Training Epoch [7/40] Iter[133/312]		Loss: 0.3453
2019-10-28 15:31:17,801 Training Epoch [7/40] Iter[134/312]		Loss: 0.3452
2019-10-28 15:31:17,880 Training Epoch [7/40] Iter[135/312]		Loss: 0.3445
2019-10-28 15:31:17,959 Training Epoch [7/40] Iter[136/312]		Loss: 0.3446
2019-10-28 15:31:18,044 Training Epoch [7/40] Iter[137/312]		Loss: 0.3454
2019-10-28 15:31:18,123 Training Epoch [7/40] Iter[138/312]		Loss: 0.3449
2019-10-28 15:31:18,202 Training Epoch [7/40] Iter[139/312]		Loss: 0.3448
2019-10-28 15:31:18,281 Training Epoch [7/40] Iter[140/312]		Loss: 0.3446
2019-10-28 15:31:18,363 Training Epoch [7/40] Iter[141/312]		Loss: 0.3449
2019-10-28 15:31:18,442 Training Epoch [7/40] Iter[142/312]		Loss: 0.3443
2019-10-28 15:31:18,521 Training Epoch [7/40] Iter[143/312]		Loss: 0.3439
2019-10-28 15:31:18,600 Training Epoch [7/40] Iter[144/312]		Loss: 0.3441
2019-10-28 15:31:18,680 Training Epoch [7/40] Iter[145/312]		Loss: 0.3442
2019-10-28 15:31:18,759 Training Epoch [7/40] Iter[146/312]		Loss: 0.3443
2019-10-28 15:31:18,838 Training Epoch [7/40] Iter[147/312]		Loss: 0.3445
2019-10-28 15:31:18,917 Training Epoch [7/40] Iter[148/312]		Loss: 0.3454
2019-10-28 15:31:18,996 Training Epoch [7/40] Iter[149/312]		Loss: 0.3453
2019-10-28 15:31:19,075 Training Epoch [7/40] Iter[150/312]		Loss: 0.3449
2019-10-28 15:31:19,154 Training Epoch [7/40] Iter[151/312]		Loss: 0.3446
2019-10-28 15:31:19,234 Training Epoch [7/40] Iter[152/312]		Loss: 0.3449
2019-10-28 15:31:19,313 Training Epoch [7/40] Iter[153/312]		Loss: 0.3450
2019-10-28 15:31:19,392 Training Epoch [7/40] Iter[154/312]		Loss: 0.3449
2019-10-28 15:31:19,471 Training Epoch [7/40] Iter[155/312]		Loss: 0.3447
2019-10-28 15:31:19,550 Training Epoch [7/40] Iter[156/312]		Loss: 0.3441
2019-10-28 15:31:19,629 Training Epoch [7/40] Iter[157/312]		Loss: 0.3440
2019-10-28 15:31:19,708 Training Epoch [7/40] Iter[158/312]		Loss: 0.3441
2019-10-28 15:31:19,787 Training Epoch [7/40] Iter[159/312]		Loss: 0.3439
2019-10-28 15:31:19,865 Training Epoch [7/40] Iter[160/312]		Loss: 0.3444
2019-10-28 15:31:19,944 Training Epoch [7/40] Iter[161/312]		Loss: 0.3446
2019-10-28 15:31:20,028 Training Epoch [7/40] Iter[162/312]		Loss: 0.3439
2019-10-28 15:31:20,107 Training Epoch [7/40] Iter[163/312]		Loss: 0.3439
2019-10-28 15:31:20,186 Training Epoch [7/40] Iter[164/312]		Loss: 0.3445
2019-10-28 15:31:20,265 Training Epoch [7/40] Iter[165/312]		Loss: 0.3453
2019-10-28 15:31:20,344 Training Epoch [7/40] Iter[166/312]		Loss: 0.3460
2019-10-28 15:31:20,423 Training Epoch [7/40] Iter[167/312]		Loss: 0.3461
2019-10-28 15:31:20,502 Training Epoch [7/40] Iter[168/312]		Loss: 0.3467
2019-10-28 15:31:20,580 Training Epoch [7/40] Iter[169/312]		Loss: 0.3464
2019-10-28 15:31:20,659 Training Epoch [7/40] Iter[170/312]		Loss: 0.3466
2019-10-28 15:31:20,742 Training Epoch [7/40] Iter[171/312]		Loss: 0.3470
2019-10-28 15:31:20,821 Training Epoch [7/40] Iter[172/312]		Loss: 0.3479
2019-10-28 15:31:20,900 Training Epoch [7/40] Iter[173/312]		Loss: 0.3476
2019-10-28 15:31:20,979 Training Epoch [7/40] Iter[174/312]		Loss: 0.3477
2019-10-28 15:31:21,058 Training Epoch [7/40] Iter[175/312]		Loss: 0.3470
2019-10-28 15:31:21,138 Training Epoch [7/40] Iter[176/312]		Loss: 0.3471
2019-10-28 15:31:21,218 Training Epoch [7/40] Iter[177/312]		Loss: 0.3467
2019-10-28 15:31:21,297 Training Epoch [7/40] Iter[178/312]		Loss: 0.3464
2019-10-28 15:31:21,377 Training Epoch [7/40] Iter[179/312]		Loss: 0.3456
2019-10-28 15:31:21,456 Training Epoch [7/40] Iter[180/312]		Loss: 0.3453
2019-10-28 15:31:21,535 Training Epoch [7/40] Iter[181/312]		Loss: 0.3454
2019-10-28 15:31:21,614 Training Epoch [7/40] Iter[182/312]		Loss: 0.3447
2019-10-28 15:31:21,693 Training Epoch [7/40] Iter[183/312]		Loss: 0.3445
2019-10-28 15:31:21,772 Training Epoch [7/40] Iter[184/312]		Loss: 0.3442
2019-10-28 15:31:21,851 Training Epoch [7/40] Iter[185/312]		Loss: 0.3440
2019-10-28 15:31:21,930 Training Epoch [7/40] Iter[186/312]		Loss: 0.3439
2019-10-28 15:31:22,009 Training Epoch [7/40] Iter[187/312]		Loss: 0.3433
2019-10-28 15:31:22,089 Training Epoch [7/40] Iter[188/312]		Loss: 0.3434
2019-10-28 15:31:22,168 Training Epoch [7/40] Iter[189/312]		Loss: 0.3447
2019-10-28 15:31:22,248 Training Epoch [7/40] Iter[190/312]		Loss: 0.3441
2019-10-28 15:31:22,327 Training Epoch [7/40] Iter[191/312]		Loss: 0.3437
2019-10-28 15:31:22,407 Training Epoch [7/40] Iter[192/312]		Loss: 0.3435
2019-10-28 15:31:22,486 Training Epoch [7/40] Iter[193/312]		Loss: 0.3431
2019-10-28 15:31:22,566 Training Epoch [7/40] Iter[194/312]		Loss: 0.3424
2019-10-28 15:31:22,645 Training Epoch [7/40] Iter[195/312]		Loss: 0.3419
2019-10-28 15:31:22,724 Training Epoch [7/40] Iter[196/312]		Loss: 0.3418
2019-10-28 15:31:22,803 Training Epoch [7/40] Iter[197/312]		Loss: 0.3424
2019-10-28 15:31:22,883 Training Epoch [7/40] Iter[198/312]		Loss: 0.3428
2019-10-28 15:31:22,962 Training Epoch [7/40] Iter[199/312]		Loss: 0.3431
2019-10-28 15:31:23,042 Training Epoch [7/40] Iter[200/312]		Loss: 0.3431
2019-10-28 15:31:23,121 Training Epoch [7/40] Iter[201/312]		Loss: 0.3428
2019-10-28 15:31:23,200 Training Epoch [7/40] Iter[202/312]		Loss: 0.3424
2019-10-28 15:31:23,280 Training Epoch [7/40] Iter[203/312]		Loss: 0.3421
2019-10-28 15:31:23,360 Training Epoch [7/40] Iter[204/312]		Loss: 0.3419
2019-10-28 15:31:23,440 Training Epoch [7/40] Iter[205/312]		Loss: 0.3417
2019-10-28 15:31:23,520 Training Epoch [7/40] Iter[206/312]		Loss: 0.3411
2019-10-28 15:31:23,599 Training Epoch [7/40] Iter[207/312]		Loss: 0.3405
2019-10-28 15:31:23,678 Training Epoch [7/40] Iter[208/312]		Loss: 0.3407
2019-10-28 15:31:23,757 Training Epoch [7/40] Iter[209/312]		Loss: 0.3405
2019-10-28 15:31:23,837 Training Epoch [7/40] Iter[210/312]		Loss: 0.3402
2019-10-28 15:31:23,916 Training Epoch [7/40] Iter[211/312]		Loss: 0.3405
2019-10-28 15:31:23,996 Training Epoch [7/40] Iter[212/312]		Loss: 0.3407
2019-10-28 15:31:24,075 Training Epoch [7/40] Iter[213/312]		Loss: 0.3403
2019-10-28 15:31:24,154 Training Epoch [7/40] Iter[214/312]		Loss: 0.3403
2019-10-28 15:31:24,234 Training Epoch [7/40] Iter[215/312]		Loss: 0.3405
2019-10-28 15:31:24,313 Training Epoch [7/40] Iter[216/312]		Loss: 0.3401
2019-10-28 15:31:24,392 Training Epoch [7/40] Iter[217/312]		Loss: 0.3399
2019-10-28 15:31:24,472 Training Epoch [7/40] Iter[218/312]		Loss: 0.3398
2019-10-28 15:31:24,551 Training Epoch [7/40] Iter[219/312]		Loss: 0.3398
2019-10-28 15:31:24,630 Training Epoch [7/40] Iter[220/312]		Loss: 0.3396
2019-10-28 15:31:24,709 Training Epoch [7/40] Iter[221/312]		Loss: 0.3391
2019-10-28 15:31:24,788 Training Epoch [7/40] Iter[222/312]		Loss: 0.3392
2019-10-28 15:31:24,867 Training Epoch [7/40] Iter[223/312]		Loss: 0.3392
2019-10-28 15:31:24,946 Training Epoch [7/40] Iter[224/312]		Loss: 0.3392
2019-10-28 15:31:25,025 Training Epoch [7/40] Iter[225/312]		Loss: 0.3388
2019-10-28 15:31:25,105 Training Epoch [7/40] Iter[226/312]		Loss: 0.3388
2019-10-28 15:31:25,184 Training Epoch [7/40] Iter[227/312]		Loss: 0.3391
2019-10-28 15:31:25,264 Training Epoch [7/40] Iter[228/312]		Loss: 0.3387
2019-10-28 15:31:25,343 Training Epoch [7/40] Iter[229/312]		Loss: 0.3382
2019-10-28 15:31:25,422 Training Epoch [7/40] Iter[230/312]		Loss: 0.3383
2019-10-28 15:31:25,502 Training Epoch [7/40] Iter[231/312]		Loss: 0.3386
2019-10-28 15:31:25,581 Training Epoch [7/40] Iter[232/312]		Loss: 0.3383
2019-10-28 15:31:25,660 Training Epoch [7/40] Iter[233/312]		Loss: 0.3377
2019-10-28 15:31:25,739 Training Epoch [7/40] Iter[234/312]		Loss: 0.3377
2019-10-28 15:31:25,818 Training Epoch [7/40] Iter[235/312]		Loss: 0.3372
2019-10-28 15:31:25,898 Training Epoch [7/40] Iter[236/312]		Loss: 0.3369
2019-10-28 15:31:25,977 Training Epoch [7/40] Iter[237/312]		Loss: 0.3364
2019-10-28 15:31:26,056 Training Epoch [7/40] Iter[238/312]		Loss: 0.3363
2019-10-28 15:31:26,135 Training Epoch [7/40] Iter[239/312]		Loss: 0.3359
2019-10-28 15:31:26,215 Training Epoch [7/40] Iter[240/312]		Loss: 0.3364
2019-10-28 15:31:26,294 Training Epoch [7/40] Iter[241/312]		Loss: 0.3363
2019-10-28 15:31:26,374 Training Epoch [7/40] Iter[242/312]		Loss: 0.3362
2019-10-28 15:31:26,453 Training Epoch [7/40] Iter[243/312]		Loss: 0.3363
2019-10-28 15:31:26,532 Training Epoch [7/40] Iter[244/312]		Loss: 0.3363
2019-10-28 15:31:26,611 Training Epoch [7/40] Iter[245/312]		Loss: 0.3364
2019-10-28 15:31:26,690 Training Epoch [7/40] Iter[246/312]		Loss: 0.3365
2019-10-28 15:31:26,770 Training Epoch [7/40] Iter[247/312]		Loss: 0.3368
2019-10-28 15:31:26,849 Training Epoch [7/40] Iter[248/312]		Loss: 0.3372
2019-10-28 15:31:26,928 Training Epoch [7/40] Iter[249/312]		Loss: 0.3371
2019-10-28 15:31:27,007 Training Epoch [7/40] Iter[250/312]		Loss: 0.3373
2019-10-28 15:31:27,087 Training Epoch [7/40] Iter[251/312]		Loss: 0.3371
2019-10-28 15:31:27,166 Training Epoch [7/40] Iter[252/312]		Loss: 0.3368
2019-10-28 15:31:27,245 Training Epoch [7/40] Iter[253/312]		Loss: 0.3367
2019-10-28 15:31:27,324 Training Epoch [7/40] Iter[254/312]		Loss: 0.3368
2019-10-28 15:31:27,404 Training Epoch [7/40] Iter[255/312]		Loss: 0.3369
2019-10-28 15:31:27,484 Training Epoch [7/40] Iter[256/312]		Loss: 0.3368
2019-10-28 15:31:27,563 Training Epoch [7/40] Iter[257/312]		Loss: 0.3366
2019-10-28 15:31:27,642 Training Epoch [7/40] Iter[258/312]		Loss: 0.3364
2019-10-28 15:31:27,721 Training Epoch [7/40] Iter[259/312]		Loss: 0.3359
2019-10-28 15:31:27,800 Training Epoch [7/40] Iter[260/312]		Loss: 0.3360
2019-10-28 15:31:27,879 Training Epoch [7/40] Iter[261/312]		Loss: 0.3365
2019-10-28 15:31:27,958 Training Epoch [7/40] Iter[262/312]		Loss: 0.3361
2019-10-28 15:31:28,037 Training Epoch [7/40] Iter[263/312]		Loss: 0.3362
2019-10-28 15:31:28,116 Training Epoch [7/40] Iter[264/312]		Loss: 0.3360
2019-10-28 15:31:28,195 Training Epoch [7/40] Iter[265/312]		Loss: 0.3362
2019-10-28 15:31:28,274 Training Epoch [7/40] Iter[266/312]		Loss: 0.3358
2019-10-28 15:31:28,353 Training Epoch [7/40] Iter[267/312]		Loss: 0.3353
2019-10-28 15:31:28,432 Training Epoch [7/40] Iter[268/312]		Loss: 0.3349
2019-10-28 15:31:28,511 Training Epoch [7/40] Iter[269/312]		Loss: 0.3349
2019-10-28 15:31:28,590 Training Epoch [7/40] Iter[270/312]		Loss: 0.3346
2019-10-28 15:31:28,669 Training Epoch [7/40] Iter[271/312]		Loss: 0.3344
2019-10-28 15:31:28,748 Training Epoch [7/40] Iter[272/312]		Loss: 0.3341
2019-10-28 15:31:28,827 Training Epoch [7/40] Iter[273/312]		Loss: 0.3337
2019-10-28 15:31:28,906 Training Epoch [7/40] Iter[274/312]		Loss: 0.3333
2019-10-28 15:31:28,985 Training Epoch [7/40] Iter[275/312]		Loss: 0.3331
2019-10-28 15:31:29,065 Training Epoch [7/40] Iter[276/312]		Loss: 0.3326
2019-10-28 15:31:29,144 Training Epoch [7/40] Iter[277/312]		Loss: 0.3323
2019-10-28 15:31:29,223 Training Epoch [7/40] Iter[278/312]		Loss: 0.3325
2019-10-28 15:31:29,302 Training Epoch [7/40] Iter[279/312]		Loss: 0.3324
2019-10-28 15:31:29,382 Training Epoch [7/40] Iter[280/312]		Loss: 0.3322
2019-10-28 15:31:29,461 Training Epoch [7/40] Iter[281/312]		Loss: 0.3323
2019-10-28 15:31:29,540 Training Epoch [7/40] Iter[282/312]		Loss: 0.3320
2019-10-28 15:31:29,619 Training Epoch [7/40] Iter[283/312]		Loss: 0.3318
2019-10-28 15:31:29,698 Training Epoch [7/40] Iter[284/312]		Loss: 0.3317
2019-10-28 15:31:29,776 Training Epoch [7/40] Iter[285/312]		Loss: 0.3319
2019-10-28 15:31:29,855 Training Epoch [7/40] Iter[286/312]		Loss: 0.3319
2019-10-28 15:31:29,934 Training Epoch [7/40] Iter[287/312]		Loss: 0.3318
2019-10-28 15:31:30,012 Training Epoch [7/40] Iter[288/312]		Loss: 0.3320
2019-10-28 15:31:30,091 Training Epoch [7/40] Iter[289/312]		Loss: 0.3320
2019-10-28 15:31:30,170 Training Epoch [7/40] Iter[290/312]		Loss: 0.3318
2019-10-28 15:31:30,249 Training Epoch [7/40] Iter[291/312]		Loss: 0.3321
2019-10-28 15:31:30,328 Training Epoch [7/40] Iter[292/312]		Loss: 0.3321
2019-10-28 15:31:30,407 Training Epoch [7/40] Iter[293/312]		Loss: 0.3318
2019-10-28 15:31:30,486 Training Epoch [7/40] Iter[294/312]		Loss: 0.3314
2019-10-28 15:31:30,565 Training Epoch [7/40] Iter[295/312]		Loss: 0.3312
2019-10-28 15:31:30,644 Training Epoch [7/40] Iter[296/312]		Loss: 0.3317
2019-10-28 15:31:30,723 Training Epoch [7/40] Iter[297/312]		Loss: 0.3314
2019-10-28 15:31:30,802 Training Epoch [7/40] Iter[298/312]		Loss: 0.3311
2019-10-28 15:31:30,881 Training Epoch [7/40] Iter[299/312]		Loss: 0.3308
2019-10-28 15:31:30,960 Training Epoch [7/40] Iter[300/312]		Loss: 0.3309
2019-10-28 15:31:31,039 Training Epoch [7/40] Iter[301/312]		Loss: 0.3306
2019-10-28 15:31:31,118 Training Epoch [7/40] Iter[302/312]		Loss: 0.3305
2019-10-28 15:31:31,197 Training Epoch [7/40] Iter[303/312]		Loss: 0.3309
2019-10-28 15:31:31,276 Training Epoch [7/40] Iter[304/312]		Loss: 0.3307
2019-10-28 15:31:31,354 Training Epoch [7/40] Iter[305/312]		Loss: 0.3307
2019-10-28 15:31:31,432 Training Epoch [7/40] Iter[306/312]		Loss: 0.3305
2019-10-28 15:31:31,510 Training Epoch [7/40] Iter[307/312]		Loss: 0.3303
2019-10-28 15:31:31,589 Training Epoch [7/40] Iter[308/312]		Loss: 0.3300
2019-10-28 15:31:31,668 Training Epoch [7/40] Iter[309/312]		Loss: 0.3301
2019-10-28 15:31:31,746 Training Epoch [7/40] Iter[310/312]		Loss: 0.3298
2019-10-28 15:31:31,824 Training Epoch [7/40] Iter[311/312]		Loss: 0.3294
2019-10-28 15:31:31,862 Training Epoch [7/40] Iter[312/312]		Loss: 0.3293
2019-10-28 15:31:32,288 Testing Epoch [7/40] Iter[0/62]		Loss: 0.3700
2019-10-28 15:31:32,321 Testing Epoch [7/40] Iter[1/62]		Loss: 0.3254
2019-10-28 15:31:32,350 Testing Epoch [7/40] Iter[2/62]		Loss: 0.2902
2019-10-28 15:31:32,377 Testing Epoch [7/40] Iter[3/62]		Loss: 0.3002
2019-10-28 15:31:32,395 Testing Epoch [7/40] Iter[4/62]		Loss: 0.2922
2019-10-28 15:31:32,414 Testing Epoch [7/40] Iter[5/62]		Loss: 0.2809
2019-10-28 15:31:32,445 Testing Epoch [7/40] Iter[6/62]		Loss: 0.2794
2019-10-28 15:31:32,469 Testing Epoch [7/40] Iter[7/62]		Loss: 0.2899
2019-10-28 15:31:32,493 Testing Epoch [7/40] Iter[8/62]		Loss: 0.3021
2019-10-28 15:31:32,519 Testing Epoch [7/40] Iter[9/62]		Loss: 0.3006
2019-10-28 15:31:32,537 Testing Epoch [7/40] Iter[10/62]		Loss: 0.2969
2019-10-28 15:31:32,555 Testing Epoch [7/40] Iter[11/62]		Loss: 0.3004
2019-10-28 15:31:32,574 Testing Epoch [7/40] Iter[12/62]		Loss: 0.2999
2019-10-28 15:31:32,597 Testing Epoch [7/40] Iter[13/62]		Loss: 0.3015
2019-10-28 15:31:32,626 Testing Epoch [7/40] Iter[14/62]		Loss: 0.3292
2019-10-28 15:31:32,649 Testing Epoch [7/40] Iter[15/62]		Loss: 0.3301
2019-10-28 15:31:32,667 Testing Epoch [7/40] Iter[16/62]		Loss: 0.3269
2019-10-28 15:31:32,685 Testing Epoch [7/40] Iter[17/62]		Loss: 0.3220
2019-10-28 15:31:32,714 Testing Epoch [7/40] Iter[18/62]		Loss: 0.3147
2019-10-28 15:31:32,731 Testing Epoch [7/40] Iter[19/62]		Loss: 0.3118
2019-10-28 15:31:32,749 Testing Epoch [7/40] Iter[20/62]		Loss: 0.3158
2019-10-28 15:31:32,773 Testing Epoch [7/40] Iter[21/62]		Loss: 0.3165
2019-10-28 15:31:32,797 Testing Epoch [7/40] Iter[22/62]		Loss: 0.3174
2019-10-28 15:31:32,821 Testing Epoch [7/40] Iter[23/62]		Loss: 0.3194
2019-10-28 15:31:32,849 Testing Epoch [7/40] Iter[24/62]		Loss: 0.3214
2019-10-28 15:31:32,869 Testing Epoch [7/40] Iter[25/62]		Loss: 0.3174
2019-10-28 15:31:32,893 Testing Epoch [7/40] Iter[26/62]		Loss: 0.3135
2019-10-28 15:31:32,911 Testing Epoch [7/40] Iter[27/62]		Loss: 0.3270
2019-10-28 15:31:32,937 Testing Epoch [7/40] Iter[28/62]		Loss: 0.3282
2019-10-28 15:31:32,955 Testing Epoch [7/40] Iter[29/62]		Loss: 0.3274
2019-10-28 15:31:32,972 Testing Epoch [7/40] Iter[30/62]		Loss: 0.3301
2019-10-28 15:31:33,002 Testing Epoch [7/40] Iter[31/62]		Loss: 0.3301
2019-10-28 15:31:33,020 Testing Epoch [7/40] Iter[32/62]		Loss: 0.3314
2019-10-28 15:31:33,038 Testing Epoch [7/40] Iter[33/62]		Loss: 0.3292
2019-10-28 15:31:33,055 Testing Epoch [7/40] Iter[34/62]		Loss: 0.3329
2019-10-28 15:31:33,086 Testing Epoch [7/40] Iter[35/62]		Loss: 0.3313
2019-10-28 15:31:33,113 Testing Epoch [7/40] Iter[36/62]		Loss: 0.3273
2019-10-28 15:31:33,137 Testing Epoch [7/40] Iter[37/62]		Loss: 0.3259
2019-10-28 15:31:33,156 Testing Epoch [7/40] Iter[38/62]		Loss: 0.3244
2019-10-28 15:31:33,173 Testing Epoch [7/40] Iter[39/62]		Loss: 0.3276
2019-10-28 15:31:33,201 Testing Epoch [7/40] Iter[40/62]		Loss: 0.3302
2019-10-28 15:31:33,223 Testing Epoch [7/40] Iter[41/62]		Loss: 0.3345
2019-10-28 15:31:33,240 Testing Epoch [7/40] Iter[42/62]		Loss: 0.3314
2019-10-28 15:31:33,273 Testing Epoch [7/40] Iter[43/62]		Loss: 0.3309
2019-10-28 15:31:33,297 Testing Epoch [7/40] Iter[44/62]		Loss: 0.3296
2019-10-28 15:31:33,315 Testing Epoch [7/40] Iter[45/62]		Loss: 0.3295
2019-10-28 15:31:33,341 Testing Epoch [7/40] Iter[46/62]		Loss: 0.3320
2019-10-28 15:31:33,365 Testing Epoch [7/40] Iter[47/62]		Loss: 0.3379
2019-10-28 15:31:33,392 Testing Epoch [7/40] Iter[48/62]		Loss: 0.3347
2019-10-28 15:31:33,413 Testing Epoch [7/40] Iter[49/62]		Loss: 0.3384
2019-10-28 15:31:33,431 Testing Epoch [7/40] Iter[50/62]		Loss: 0.3369
2019-10-28 15:31:33,449 Testing Epoch [7/40] Iter[51/62]		Loss: 0.3359
2019-10-28 15:31:33,478 Testing Epoch [7/40] Iter[52/62]		Loss: 0.3329
2019-10-28 15:31:33,496 Testing Epoch [7/40] Iter[53/62]		Loss: 0.3338
2019-10-28 15:31:33,521 Testing Epoch [7/40] Iter[54/62]		Loss: 0.3317
2019-10-28 15:31:33,538 Testing Epoch [7/40] Iter[55/62]		Loss: 0.3307
2019-10-28 15:31:33,554 Testing Epoch [7/40] Iter[56/62]		Loss: 0.3299
2019-10-28 15:31:33,571 Testing Epoch [7/40] Iter[57/62]		Loss: 0.3311
2019-10-28 15:31:33,588 Testing Epoch [7/40] Iter[58/62]		Loss: 0.3297
2019-10-28 15:31:33,604 Testing Epoch [7/40] Iter[59/62]		Loss: 0.3300
2019-10-28 15:31:33,621 Testing Epoch [7/40] Iter[60/62]		Loss: 0.3293
2019-10-28 15:31:33,637 Testing Epoch [7/40] Iter[61/62]		Loss: 0.3308
2019-10-28 15:31:33,647 Testing Epoch [7/40] Iter[62/62]		Loss: 0.3335
2019-10-28 15:31:34,134 Training Epoch [8/40] Iter[0/312]		Loss: 0.1688
2019-10-28 15:31:34,215 Training Epoch [8/40] Iter[1/312]		Loss: 0.3240
2019-10-28 15:31:34,299 Training Epoch [8/40] Iter[2/312]		Loss: 0.3329
2019-10-28 15:31:34,379 Training Epoch [8/40] Iter[3/312]		Loss: 0.3815
2019-10-28 15:31:34,463 Training Epoch [8/40] Iter[4/312]		Loss: 0.4122
2019-10-28 15:31:34,541 Training Epoch [8/40] Iter[5/312]		Loss: 0.4038
2019-10-28 15:31:34,623 Training Epoch [8/40] Iter[6/312]		Loss: 0.3973
2019-10-28 15:31:34,701 Training Epoch [8/40] Iter[7/312]		Loss: 0.3843
2019-10-28 15:31:34,781 Training Epoch [8/40] Iter[8/312]		Loss: 0.3757
2019-10-28 15:31:34,859 Training Epoch [8/40] Iter[9/312]		Loss: 0.3707
2019-10-28 15:31:34,938 Training Epoch [8/40] Iter[10/312]		Loss: 0.3777
2019-10-28 15:31:35,017 Training Epoch [8/40] Iter[11/312]		Loss: 0.3755
2019-10-28 15:31:35,096 Training Epoch [8/40] Iter[12/312]		Loss: 0.3783
2019-10-28 15:31:35,175 Training Epoch [8/40] Iter[13/312]		Loss: 0.3731
2019-10-28 15:31:35,254 Training Epoch [8/40] Iter[14/312]		Loss: 0.3649
2019-10-28 15:31:35,333 Training Epoch [8/40] Iter[15/312]		Loss: 0.3658
2019-10-28 15:31:35,412 Training Epoch [8/40] Iter[16/312]		Loss: 0.3797
2019-10-28 15:31:35,491 Training Epoch [8/40] Iter[17/312]		Loss: 0.3785
2019-10-28 15:31:35,571 Training Epoch [8/40] Iter[18/312]		Loss: 0.3767
2019-10-28 15:31:35,650 Training Epoch [8/40] Iter[19/312]		Loss: 0.3770
2019-10-28 15:31:35,729 Training Epoch [8/40] Iter[20/312]		Loss: 0.3776
2019-10-28 15:31:35,808 Training Epoch [8/40] Iter[21/312]		Loss: 0.3745
2019-10-28 15:31:35,887 Training Epoch [8/40] Iter[22/312]		Loss: 0.3719
2019-10-28 15:31:35,966 Training Epoch [8/40] Iter[23/312]		Loss: 0.3677
2019-10-28 15:31:36,045 Training Epoch [8/40] Iter[24/312]		Loss: 0.3641
2019-10-28 15:31:36,124 Training Epoch [8/40] Iter[25/312]		Loss: 0.3608
2019-10-28 15:31:36,204 Training Epoch [8/40] Iter[26/312]		Loss: 0.3624
2019-10-28 15:31:36,283 Training Epoch [8/40] Iter[27/312]		Loss: 0.3571
2019-10-28 15:31:36,362 Training Epoch [8/40] Iter[28/312]		Loss: 0.3528
2019-10-28 15:31:36,441 Training Epoch [8/40] Iter[29/312]		Loss: 0.3529
2019-10-28 15:31:36,520 Training Epoch [8/40] Iter[30/312]		Loss: 0.3546
2019-10-28 15:31:36,599 Training Epoch [8/40] Iter[31/312]		Loss: 0.3509
2019-10-28 15:31:36,678 Training Epoch [8/40] Iter[32/312]		Loss: 0.3479
2019-10-28 15:31:36,757 Training Epoch [8/40] Iter[33/312]		Loss: 0.3468
2019-10-28 15:31:36,836 Training Epoch [8/40] Iter[34/312]		Loss: 0.3451
2019-10-28 15:31:36,915 Training Epoch [8/40] Iter[35/312]		Loss: 0.3430
2019-10-28 15:31:36,994 Training Epoch [8/40] Iter[36/312]		Loss: 0.3435
2019-10-28 15:31:37,073 Training Epoch [8/40] Iter[37/312]		Loss: 0.3413
2019-10-28 15:31:37,152 Training Epoch [8/40] Iter[38/312]		Loss: 0.3433
2019-10-28 15:31:37,231 Training Epoch [8/40] Iter[39/312]		Loss: 0.3425
2019-10-28 15:31:37,310 Training Epoch [8/40] Iter[40/312]		Loss: 0.3439
2019-10-28 15:31:37,389 Training Epoch [8/40] Iter[41/312]		Loss: 0.3458
2019-10-28 15:31:37,468 Training Epoch [8/40] Iter[42/312]		Loss: 0.3423
2019-10-28 15:31:37,547 Training Epoch [8/40] Iter[43/312]		Loss: 0.3401
2019-10-28 15:31:37,626 Training Epoch [8/40] Iter[44/312]		Loss: 0.3393
2019-10-28 15:31:37,706 Training Epoch [8/40] Iter[45/312]		Loss: 0.3412
2019-10-28 15:31:37,785 Training Epoch [8/40] Iter[46/312]		Loss: 0.3388
2019-10-28 15:31:37,864 Training Epoch [8/40] Iter[47/312]		Loss: 0.3379
2019-10-28 15:31:37,943 Training Epoch [8/40] Iter[48/312]		Loss: 0.3385
2019-10-28 15:31:38,022 Training Epoch [8/40] Iter[49/312]		Loss: 0.3402
2019-10-28 15:31:38,101 Training Epoch [8/40] Iter[50/312]		Loss: 0.3406
2019-10-28 15:31:38,180 Training Epoch [8/40] Iter[51/312]		Loss: 0.3401
2019-10-28 15:31:38,259 Training Epoch [8/40] Iter[52/312]		Loss: 0.3383
2019-10-28 15:31:38,338 Training Epoch [8/40] Iter[53/312]		Loss: 0.3377
2019-10-28 15:31:38,417 Training Epoch [8/40] Iter[54/312]		Loss: 0.3372
2019-10-28 15:31:38,495 Training Epoch [8/40] Iter[55/312]		Loss: 0.3356
2019-10-28 15:31:38,575 Training Epoch [8/40] Iter[56/312]		Loss: 0.3354
2019-10-28 15:31:38,654 Training Epoch [8/40] Iter[57/312]		Loss: 0.3353
2019-10-28 15:31:38,732 Training Epoch [8/40] Iter[58/312]		Loss: 0.3340
2019-10-28 15:31:38,811 Training Epoch [8/40] Iter[59/312]		Loss: 0.3327
2019-10-28 15:31:38,890 Training Epoch [8/40] Iter[60/312]		Loss: 0.3311
2019-10-28 15:31:38,969 Training Epoch [8/40] Iter[61/312]		Loss: 0.3301
2019-10-28 15:31:39,048 Training Epoch [8/40] Iter[62/312]		Loss: 0.3292
2019-10-28 15:31:39,126 Training Epoch [8/40] Iter[63/312]		Loss: 0.3305
2019-10-28 15:31:39,206 Training Epoch [8/40] Iter[64/312]		Loss: 0.3304
2019-10-28 15:31:39,285 Training Epoch [8/40] Iter[65/312]		Loss: 0.3279
2019-10-28 15:31:39,364 Training Epoch [8/40] Iter[66/312]		Loss: 0.3273
2019-10-28 15:31:39,443 Training Epoch [8/40] Iter[67/312]		Loss: 0.3262
2019-10-28 15:31:39,522 Training Epoch [8/40] Iter[68/312]		Loss: 0.3261
2019-10-28 15:31:39,601 Training Epoch [8/40] Iter[69/312]		Loss: 0.3247
2019-10-28 15:31:39,680 Training Epoch [8/40] Iter[70/312]		Loss: 0.3238
2019-10-28 15:31:39,759 Training Epoch [8/40] Iter[71/312]		Loss: 0.3235
2019-10-28 15:31:39,838 Training Epoch [8/40] Iter[72/312]		Loss: 0.3237
2019-10-28 15:31:39,918 Training Epoch [8/40] Iter[73/312]		Loss: 0.3228
2019-10-28 15:31:39,997 Training Epoch [8/40] Iter[74/312]		Loss: 0.3230
2019-10-28 15:31:40,076 Training Epoch [8/40] Iter[75/312]		Loss: 0.3228
2019-10-28 15:31:40,155 Training Epoch [8/40] Iter[76/312]		Loss: 0.3219
2019-10-28 15:31:40,234 Training Epoch [8/40] Iter[77/312]		Loss: 0.3211
2019-10-28 15:31:40,313 Training Epoch [8/40] Iter[78/312]		Loss: 0.3196
2019-10-28 15:31:40,392 Training Epoch [8/40] Iter[79/312]		Loss: 0.3190
2019-10-28 15:31:40,471 Training Epoch [8/40] Iter[80/312]		Loss: 0.3180
2019-10-28 15:31:40,550 Training Epoch [8/40] Iter[81/312]		Loss: 0.3175
2019-10-28 15:31:40,629 Training Epoch [8/40] Iter[82/312]		Loss: 0.3182
2019-10-28 15:31:40,708 Training Epoch [8/40] Iter[83/312]		Loss: 0.3182
2019-10-28 15:31:40,787 Training Epoch [8/40] Iter[84/312]		Loss: 0.3187
2019-10-28 15:31:40,866 Training Epoch [8/40] Iter[85/312]		Loss: 0.3184
2019-10-28 15:31:40,945 Training Epoch [8/40] Iter[86/312]		Loss: 0.3179
2019-10-28 15:31:41,024 Training Epoch [8/40] Iter[87/312]		Loss: 0.3173
2019-10-28 15:31:41,103 Training Epoch [8/40] Iter[88/312]		Loss: 0.3177
2019-10-28 15:31:41,182 Training Epoch [8/40] Iter[89/312]		Loss: 0.3176
2019-10-28 15:31:41,261 Training Epoch [8/40] Iter[90/312]		Loss: 0.3174
2019-10-28 15:31:41,340 Training Epoch [8/40] Iter[91/312]		Loss: 0.3178
2019-10-28 15:31:41,419 Training Epoch [8/40] Iter[92/312]		Loss: 0.3167
2019-10-28 15:31:41,498 Training Epoch [8/40] Iter[93/312]		Loss: 0.3168
2019-10-28 15:31:41,577 Training Epoch [8/40] Iter[94/312]		Loss: 0.3162
2019-10-28 15:31:41,656 Training Epoch [8/40] Iter[95/312]		Loss: 0.3156
2019-10-28 15:31:41,735 Training Epoch [8/40] Iter[96/312]		Loss: 0.3163
2019-10-28 15:31:41,815 Training Epoch [8/40] Iter[97/312]		Loss: 0.3150
2019-10-28 15:31:41,894 Training Epoch [8/40] Iter[98/312]		Loss: 0.3146
2019-10-28 15:31:41,973 Training Epoch [8/40] Iter[99/312]		Loss: 0.3143
2019-10-28 15:31:42,052 Training Epoch [8/40] Iter[100/312]		Loss: 0.3133
2019-10-28 15:31:42,131 Training Epoch [8/40] Iter[101/312]		Loss: 0.3120
2019-10-28 15:31:42,210 Training Epoch [8/40] Iter[102/312]		Loss: 0.3110
2019-10-28 15:31:42,289 Training Epoch [8/40] Iter[103/312]		Loss: 0.3113
2019-10-28 15:31:42,368 Training Epoch [8/40] Iter[104/312]		Loss: 0.3112
2019-10-28 15:31:42,448 Training Epoch [8/40] Iter[105/312]		Loss: 0.3108
2019-10-28 15:31:42,527 Training Epoch [8/40] Iter[106/312]		Loss: 0.3096
2019-10-28 15:31:42,606 Training Epoch [8/40] Iter[107/312]		Loss: 0.3088
2019-10-28 15:31:42,685 Training Epoch [8/40] Iter[108/312]		Loss: 0.3082
2019-10-28 15:31:42,765 Training Epoch [8/40] Iter[109/312]		Loss: 0.3076
2019-10-28 15:31:42,843 Training Epoch [8/40] Iter[110/312]		Loss: 0.3086
2019-10-28 15:31:42,922 Training Epoch [8/40] Iter[111/312]		Loss: 0.3080
2019-10-28 15:31:43,001 Training Epoch [8/40] Iter[112/312]		Loss: 0.3075
2019-10-28 15:31:43,080 Training Epoch [8/40] Iter[113/312]		Loss: 0.3068
2019-10-28 15:31:43,159 Training Epoch [8/40] Iter[114/312]		Loss: 0.3063
2019-10-28 15:31:43,238 Training Epoch [8/40] Iter[115/312]		Loss: 0.3059
2019-10-28 15:31:43,317 Training Epoch [8/40] Iter[116/312]		Loss: 0.3062
2019-10-28 15:31:43,396 Training Epoch [8/40] Iter[117/312]		Loss: 0.3053
2019-10-28 15:31:43,475 Training Epoch [8/40] Iter[118/312]		Loss: 0.3045
2019-10-28 15:31:43,555 Training Epoch [8/40] Iter[119/312]		Loss: 0.3040
2019-10-28 15:31:43,634 Training Epoch [8/40] Iter[120/312]		Loss: 0.3048
2019-10-28 15:31:43,713 Training Epoch [8/40] Iter[121/312]		Loss: 0.3051
2019-10-28 15:31:43,792 Training Epoch [8/40] Iter[122/312]		Loss: 0.3049
2019-10-28 15:31:43,871 Training Epoch [8/40] Iter[123/312]		Loss: 0.3046
2019-10-28 15:31:43,950 Training Epoch [8/40] Iter[124/312]		Loss: 0.3040
2019-10-28 15:31:44,029 Training Epoch [8/40] Iter[125/312]		Loss: 0.3042
2019-10-28 15:31:44,108 Training Epoch [8/40] Iter[126/312]		Loss: 0.3041
2019-10-28 15:31:44,188 Training Epoch [8/40] Iter[127/312]		Loss: 0.3036
2019-10-28 15:31:44,267 Training Epoch [8/40] Iter[128/312]		Loss: 0.3031
2019-10-28 15:31:44,346 Training Epoch [8/40] Iter[129/312]		Loss: 0.3028
2019-10-28 15:31:44,425 Training Epoch [8/40] Iter[130/312]		Loss: 0.3021
2019-10-28 15:31:44,504 Training Epoch [8/40] Iter[131/312]		Loss: 0.3018
2019-10-28 15:31:44,583 Training Epoch [8/40] Iter[132/312]		Loss: 0.3010
2019-10-28 15:31:44,662 Training Epoch [8/40] Iter[133/312]		Loss: 0.3005
2019-10-28 15:31:44,741 Training Epoch [8/40] Iter[134/312]		Loss: 0.3005
2019-10-28 15:31:44,819 Training Epoch [8/40] Iter[135/312]		Loss: 0.3000
2019-10-28 15:31:44,898 Training Epoch [8/40] Iter[136/312]		Loss: 0.2991
2019-10-28 15:31:44,977 Training Epoch [8/40] Iter[137/312]		Loss: 0.2994
2019-10-28 15:31:45,056 Training Epoch [8/40] Iter[138/312]		Loss: 0.2989
2019-10-28 15:31:45,135 Training Epoch [8/40] Iter[139/312]		Loss: 0.2982
2019-10-28 15:31:45,214 Training Epoch [8/40] Iter[140/312]		Loss: 0.2981
2019-10-28 15:31:45,293 Training Epoch [8/40] Iter[141/312]		Loss: 0.2985
2019-10-28 15:31:45,372 Training Epoch [8/40] Iter[142/312]		Loss: 0.2981
2019-10-28 15:31:45,451 Training Epoch [8/40] Iter[143/312]		Loss: 0.2975
2019-10-28 15:31:45,530 Training Epoch [8/40] Iter[144/312]		Loss: 0.2971
2019-10-28 15:31:45,609 Training Epoch [8/40] Iter[145/312]		Loss: 0.2977
2019-10-28 15:31:45,688 Training Epoch [8/40] Iter[146/312]		Loss: 0.2975
2019-10-28 15:31:45,766 Training Epoch [8/40] Iter[147/312]		Loss: 0.2976
2019-10-28 15:31:45,845 Training Epoch [8/40] Iter[148/312]		Loss: 0.2976
2019-10-28 15:31:45,925 Training Epoch [8/40] Iter[149/312]		Loss: 0.2980
2019-10-28 15:31:46,003 Training Epoch [8/40] Iter[150/312]		Loss: 0.2976
2019-10-28 15:31:46,082 Training Epoch [8/40] Iter[151/312]		Loss: 0.2974
2019-10-28 15:31:46,161 Training Epoch [8/40] Iter[152/312]		Loss: 0.2975
2019-10-28 15:31:46,241 Training Epoch [8/40] Iter[153/312]		Loss: 0.2972
2019-10-28 15:31:46,320 Training Epoch [8/40] Iter[154/312]		Loss: 0.2969
2019-10-28 15:31:46,399 Training Epoch [8/40] Iter[155/312]		Loss: 0.2966
2019-10-28 15:31:46,478 Training Epoch [8/40] Iter[156/312]		Loss: 0.2956
2019-10-28 15:31:46,557 Training Epoch [8/40] Iter[157/312]		Loss: 0.2956
2019-10-28 15:31:46,636 Training Epoch [8/40] Iter[158/312]		Loss: 0.2958
2019-10-28 15:31:46,715 Training Epoch [8/40] Iter[159/312]		Loss: 0.2961
2019-10-28 15:31:46,794 Training Epoch [8/40] Iter[160/312]		Loss: 0.2957
2019-10-28 15:31:46,872 Training Epoch [8/40] Iter[161/312]		Loss: 0.2953
2019-10-28 15:31:46,951 Training Epoch [8/40] Iter[162/312]		Loss: 0.2944
2019-10-28 15:31:47,030 Training Epoch [8/40] Iter[163/312]		Loss: 0.2943
2019-10-28 15:31:47,109 Training Epoch [8/40] Iter[164/312]		Loss: 0.2937
2019-10-28 15:31:47,188 Training Epoch [8/40] Iter[165/312]		Loss: 0.2940
2019-10-28 15:31:47,267 Training Epoch [8/40] Iter[166/312]		Loss: 0.2935
2019-10-28 15:31:47,346 Training Epoch [8/40] Iter[167/312]		Loss: 0.2937
2019-10-28 15:31:47,426 Training Epoch [8/40] Iter[168/312]		Loss: 0.2946
2019-10-28 15:31:47,505 Training Epoch [8/40] Iter[169/312]		Loss: 0.2954
2019-10-28 15:31:47,584 Training Epoch [8/40] Iter[170/312]		Loss: 0.2956
2019-10-28 15:31:47,662 Training Epoch [8/40] Iter[171/312]		Loss: 0.2957
2019-10-28 15:31:47,742 Training Epoch [8/40] Iter[172/312]		Loss: 0.2950
2019-10-28 15:31:47,820 Training Epoch [8/40] Iter[173/312]		Loss: 0.2944
2019-10-28 15:31:47,899 Training Epoch [8/40] Iter[174/312]		Loss: 0.2944
2019-10-28 15:31:47,978 Training Epoch [8/40] Iter[175/312]		Loss: 0.2945
2019-10-28 15:31:48,057 Training Epoch [8/40] Iter[176/312]		Loss: 0.2946
2019-10-28 15:31:48,136 Training Epoch [8/40] Iter[177/312]		Loss: 0.2942
2019-10-28 15:31:48,215 Training Epoch [8/40] Iter[178/312]		Loss: 0.2942
2019-10-28 15:31:48,294 Training Epoch [8/40] Iter[179/312]		Loss: 0.2941
2019-10-28 15:31:48,373 Training Epoch [8/40] Iter[180/312]		Loss: 0.2936
2019-10-28 15:31:48,452 Training Epoch [8/40] Iter[181/312]		Loss: 0.2936
2019-10-28 15:31:48,531 Training Epoch [8/40] Iter[182/312]		Loss: 0.2946
2019-10-28 15:31:48,610 Training Epoch [8/40] Iter[183/312]		Loss: 0.2947
2019-10-28 15:31:48,689 Training Epoch [8/40] Iter[184/312]		Loss: 0.2948
2019-10-28 15:31:48,768 Training Epoch [8/40] Iter[185/312]		Loss: 0.2948
2019-10-28 15:31:48,846 Training Epoch [8/40] Iter[186/312]		Loss: 0.2946
2019-10-28 15:31:48,926 Training Epoch [8/40] Iter[187/312]		Loss: 0.2947
2019-10-28 15:31:49,004 Training Epoch [8/40] Iter[188/312]		Loss: 0.2946
2019-10-28 15:31:49,083 Training Epoch [8/40] Iter[189/312]		Loss: 0.2942
2019-10-28 15:31:49,162 Training Epoch [8/40] Iter[190/312]		Loss: 0.2943
2019-10-28 15:31:49,241 Training Epoch [8/40] Iter[191/312]		Loss: 0.2946
2019-10-28 15:31:49,320 Training Epoch [8/40] Iter[192/312]		Loss: 0.2946
2019-10-28 15:31:49,399 Training Epoch [8/40] Iter[193/312]		Loss: 0.2949
2019-10-28 15:31:49,479 Training Epoch [8/40] Iter[194/312]		Loss: 0.2947
2019-10-28 15:31:49,558 Training Epoch [8/40] Iter[195/312]		Loss: 0.2945
2019-10-28 15:31:49,637 Training Epoch [8/40] Iter[196/312]		Loss: 0.2952
2019-10-28 15:31:49,716 Training Epoch [8/40] Iter[197/312]		Loss: 0.2949
2019-10-28 15:31:49,795 Training Epoch [8/40] Iter[198/312]		Loss: 0.2954
2019-10-28 15:31:49,873 Training Epoch [8/40] Iter[199/312]		Loss: 0.2952
2019-10-28 15:31:49,952 Training Epoch [8/40] Iter[200/312]		Loss: 0.2952
2019-10-28 15:31:50,031 Training Epoch [8/40] Iter[201/312]		Loss: 0.2948
2019-10-28 15:31:50,110 Training Epoch [8/40] Iter[202/312]		Loss: 0.2949
2019-10-28 15:31:50,191 Training Epoch [8/40] Iter[203/312]		Loss: 0.2949
2019-10-28 15:31:50,271 Training Epoch [8/40] Iter[204/312]		Loss: 0.2947
2019-10-28 15:31:50,351 Training Epoch [8/40] Iter[205/312]		Loss: 0.2950
2019-10-28 15:31:50,431 Training Epoch [8/40] Iter[206/312]		Loss: 0.2944
2019-10-28 15:31:50,511 Training Epoch [8/40] Iter[207/312]		Loss: 0.2941
2019-10-28 15:31:50,591 Training Epoch [8/40] Iter[208/312]		Loss: 0.2943
2019-10-28 15:31:50,671 Training Epoch [8/40] Iter[209/312]		Loss: 0.2943
2019-10-28 15:31:50,751 Training Epoch [8/40] Iter[210/312]		Loss: 0.2942
2019-10-28 15:31:50,831 Training Epoch [8/40] Iter[211/312]		Loss: 0.2939
2019-10-28 15:31:50,911 Training Epoch [8/40] Iter[212/312]		Loss: 0.2941
2019-10-28 15:31:50,991 Training Epoch [8/40] Iter[213/312]		Loss: 0.2944
2019-10-28 15:31:51,071 Training Epoch [8/40] Iter[214/312]		Loss: 0.2939
2019-10-28 15:31:51,151 Training Epoch [8/40] Iter[215/312]		Loss: 0.2934
2019-10-28 15:31:51,230 Training Epoch [8/40] Iter[216/312]		Loss: 0.2931
2019-10-28 15:31:51,310 Training Epoch [8/40] Iter[217/312]		Loss: 0.2928
2019-10-28 15:31:51,389 Training Epoch [8/40] Iter[218/312]		Loss: 0.2926
2019-10-28 15:31:51,468 Training Epoch [8/40] Iter[219/312]		Loss: 0.2924
2019-10-28 15:31:51,548 Training Epoch [8/40] Iter[220/312]		Loss: 0.2922
2019-10-28 15:31:51,627 Training Epoch [8/40] Iter[221/312]		Loss: 0.2922
2019-10-28 15:31:51,706 Training Epoch [8/40] Iter[222/312]		Loss: 0.2919
2019-10-28 15:31:51,784 Training Epoch [8/40] Iter[223/312]		Loss: 0.2919
2019-10-28 15:31:51,864 Training Epoch [8/40] Iter[224/312]		Loss: 0.2918
2019-10-28 15:31:51,943 Training Epoch [8/40] Iter[225/312]		Loss: 0.2913
2019-10-28 15:31:52,022 Training Epoch [8/40] Iter[226/312]		Loss: 0.2912
2019-10-28 15:31:52,101 Training Epoch [8/40] Iter[227/312]		Loss: 0.2914
2019-10-28 15:31:52,180 Training Epoch [8/40] Iter[228/312]		Loss: 0.2910
2019-10-28 15:31:52,259 Training Epoch [8/40] Iter[229/312]		Loss: 0.2906
2019-10-28 15:31:52,338 Training Epoch [8/40] Iter[230/312]		Loss: 0.2906
2019-10-28 15:31:52,417 Training Epoch [8/40] Iter[231/312]		Loss: 0.2907
2019-10-28 15:31:52,496 Training Epoch [8/40] Iter[232/312]		Loss: 0.2909
2019-10-28 15:31:52,579 Training Epoch [8/40] Iter[233/312]		Loss: 0.2905
2019-10-28 15:31:52,657 Training Epoch [8/40] Iter[234/312]		Loss: 0.2901
2019-10-28 15:31:52,736 Training Epoch [8/40] Iter[235/312]		Loss: 0.2904
2019-10-28 15:31:52,815 Training Epoch [8/40] Iter[236/312]		Loss: 0.2901
2019-10-28 15:31:52,894 Training Epoch [8/40] Iter[237/312]		Loss: 0.2900
2019-10-28 15:31:52,973 Training Epoch [8/40] Iter[238/312]		Loss: 0.2899
2019-10-28 15:31:53,052 Training Epoch [8/40] Iter[239/312]		Loss: 0.2898
2019-10-28 15:31:53,131 Training Epoch [8/40] Iter[240/312]		Loss: 0.2897
2019-10-28 15:31:53,210 Training Epoch [8/40] Iter[241/312]		Loss: 0.2895
2019-10-28 15:31:53,289 Training Epoch [8/40] Iter[242/312]		Loss: 0.2896
2019-10-28 15:31:53,368 Training Epoch [8/40] Iter[243/312]		Loss: 0.2900
2019-10-28 15:31:53,447 Training Epoch [8/40] Iter[244/312]		Loss: 0.2897
2019-10-28 15:31:53,526 Training Epoch [8/40] Iter[245/312]		Loss: 0.2892
2019-10-28 15:31:53,605 Training Epoch [8/40] Iter[246/312]		Loss: 0.2890
2019-10-28 15:31:53,684 Training Epoch [8/40] Iter[247/312]		Loss: 0.2893
2019-10-28 15:31:53,763 Training Epoch [8/40] Iter[248/312]		Loss: 0.2894
2019-10-28 15:31:53,842 Training Epoch [8/40] Iter[249/312]		Loss: 0.2896
2019-10-28 15:31:53,921 Training Epoch [8/40] Iter[250/312]		Loss: 0.2900
2019-10-28 15:31:54,000 Training Epoch [8/40] Iter[251/312]		Loss: 0.2900
2019-10-28 15:31:54,079 Training Epoch [8/40] Iter[252/312]		Loss: 0.2902
2019-10-28 15:31:54,158 Training Epoch [8/40] Iter[253/312]		Loss: 0.2903
2019-10-28 15:31:54,238 Training Epoch [8/40] Iter[254/312]		Loss: 0.2900
2019-10-28 15:31:54,317 Training Epoch [8/40] Iter[255/312]		Loss: 0.2901
2019-10-28 15:31:54,396 Training Epoch [8/40] Iter[256/312]		Loss: 0.2899
2019-10-28 15:31:54,475 Training Epoch [8/40] Iter[257/312]		Loss: 0.2896
2019-10-28 15:31:54,554 Training Epoch [8/40] Iter[258/312]		Loss: 0.2894
2019-10-28 15:31:54,633 Training Epoch [8/40] Iter[259/312]		Loss: 0.2892
2019-10-28 15:31:54,712 Training Epoch [8/40] Iter[260/312]		Loss: 0.2893
2019-10-28 15:31:54,791 Training Epoch [8/40] Iter[261/312]		Loss: 0.2894
2019-10-28 15:31:54,869 Training Epoch [8/40] Iter[262/312]		Loss: 0.2893
2019-10-28 15:31:54,948 Training Epoch [8/40] Iter[263/312]		Loss: 0.2893
2019-10-28 15:31:55,027 Training Epoch [8/40] Iter[264/312]		Loss: 0.2892
2019-10-28 15:31:55,106 Training Epoch [8/40] Iter[265/312]		Loss: 0.2890
2019-10-28 15:31:55,185 Training Epoch [8/40] Iter[266/312]		Loss: 0.2889
2019-10-28 15:31:55,264 Training Epoch [8/40] Iter[267/312]		Loss: 0.2887
2019-10-28 15:31:55,343 Training Epoch [8/40] Iter[268/312]		Loss: 0.2885
2019-10-28 15:31:55,422 Training Epoch [8/40] Iter[269/312]		Loss: 0.2885
2019-10-28 15:31:55,501 Training Epoch [8/40] Iter[270/312]		Loss: 0.2885
2019-10-28 15:31:55,580 Training Epoch [8/40] Iter[271/312]		Loss: 0.2886
2019-10-28 15:31:55,659 Training Epoch [8/40] Iter[272/312]		Loss: 0.2883
2019-10-28 15:31:55,738 Training Epoch [8/40] Iter[273/312]		Loss: 0.2882
2019-10-28 15:31:55,817 Training Epoch [8/40] Iter[274/312]		Loss: 0.2882
2019-10-28 15:31:55,896 Training Epoch [8/40] Iter[275/312]		Loss: 0.2878
2019-10-28 15:31:55,975 Training Epoch [8/40] Iter[276/312]		Loss: 0.2877
2019-10-28 15:31:56,053 Training Epoch [8/40] Iter[277/312]		Loss: 0.2874
2019-10-28 15:31:56,132 Training Epoch [8/40] Iter[278/312]		Loss: 0.2872
2019-10-28 15:31:56,212 Training Epoch [8/40] Iter[279/312]		Loss: 0.2872
2019-10-28 15:31:56,291 Training Epoch [8/40] Iter[280/312]		Loss: 0.2876
2019-10-28 15:31:56,370 Training Epoch [8/40] Iter[281/312]		Loss: 0.2876
2019-10-28 15:31:56,449 Training Epoch [8/40] Iter[282/312]		Loss: 0.2879
2019-10-28 15:31:56,528 Training Epoch [8/40] Iter[283/312]		Loss: 0.2877
2019-10-28 15:31:56,607 Training Epoch [8/40] Iter[284/312]		Loss: 0.2874
2019-10-28 15:31:56,686 Training Epoch [8/40] Iter[285/312]		Loss: 0.2872
2019-10-28 15:31:56,765 Training Epoch [8/40] Iter[286/312]		Loss: 0.2871
2019-10-28 15:31:56,844 Training Epoch [8/40] Iter[287/312]		Loss: 0.2870
2019-10-28 15:31:56,923 Training Epoch [8/40] Iter[288/312]		Loss: 0.2871
2019-10-28 15:31:57,002 Training Epoch [8/40] Iter[289/312]		Loss: 0.2870
2019-10-28 15:31:57,081 Training Epoch [8/40] Iter[290/312]		Loss: 0.2870
2019-10-28 15:31:57,160 Training Epoch [8/40] Iter[291/312]		Loss: 0.2868
2019-10-28 15:31:57,239 Training Epoch [8/40] Iter[292/312]		Loss: 0.2871
2019-10-28 15:31:57,318 Training Epoch [8/40] Iter[293/312]		Loss: 0.2869
2019-10-28 15:31:57,397 Training Epoch [8/40] Iter[294/312]		Loss: 0.2865
2019-10-28 15:31:57,476 Training Epoch [8/40] Iter[295/312]		Loss: 0.2866
2019-10-28 15:31:57,555 Training Epoch [8/40] Iter[296/312]		Loss: 0.2866
2019-10-28 15:31:57,634 Training Epoch [8/40] Iter[297/312]		Loss: 0.2872
2019-10-28 15:31:57,712 Training Epoch [8/40] Iter[298/312]		Loss: 0.2874
2019-10-28 15:31:57,791 Training Epoch [8/40] Iter[299/312]		Loss: 0.2877
2019-10-28 15:31:57,870 Training Epoch [8/40] Iter[300/312]		Loss: 0.2877
2019-10-28 15:31:57,948 Training Epoch [8/40] Iter[301/312]		Loss: 0.2876
2019-10-28 15:31:58,027 Training Epoch [8/40] Iter[302/312]		Loss: 0.2876
2019-10-28 15:31:58,106 Training Epoch [8/40] Iter[303/312]		Loss: 0.2874
2019-10-28 15:31:58,185 Training Epoch [8/40] Iter[304/312]		Loss: 0.2871
2019-10-28 15:31:58,264 Training Epoch [8/40] Iter[305/312]		Loss: 0.2872
2019-10-28 15:31:58,342 Training Epoch [8/40] Iter[306/312]		Loss: 0.2868
2019-10-28 15:31:58,420 Training Epoch [8/40] Iter[307/312]		Loss: 0.2869
2019-10-28 15:31:58,498 Training Epoch [8/40] Iter[308/312]		Loss: 0.2867
2019-10-28 15:31:58,577 Training Epoch [8/40] Iter[309/312]		Loss: 0.2866
2019-10-28 15:31:58,655 Training Epoch [8/40] Iter[310/312]		Loss: 0.2868
2019-10-28 15:31:58,733 Training Epoch [8/40] Iter[311/312]		Loss: 0.2868
2019-10-28 15:31:58,772 Training Epoch [8/40] Iter[312/312]		Loss: 0.2863
2019-10-28 15:31:59,165 Testing Epoch [8/40] Iter[0/62]		Loss: 0.2687
2019-10-28 15:31:59,216 Testing Epoch [8/40] Iter[1/62]		Loss: 0.2588
2019-10-28 15:31:59,251 Testing Epoch [8/40] Iter[2/62]		Loss: 0.2422
2019-10-28 15:31:59,278 Testing Epoch [8/40] Iter[3/62]		Loss: 0.2553
2019-10-28 15:31:59,295 Testing Epoch [8/40] Iter[4/62]		Loss: 0.2578
2019-10-28 15:31:59,312 Testing Epoch [8/40] Iter[5/62]		Loss: 0.2420
2019-10-28 15:31:59,328 Testing Epoch [8/40] Iter[6/62]		Loss: 0.2408
2019-10-28 15:31:59,354 Testing Epoch [8/40] Iter[7/62]		Loss: 0.2415
2019-10-28 15:31:59,377 Testing Epoch [8/40] Iter[8/62]		Loss: 0.2557
2019-10-28 15:31:59,397 Testing Epoch [8/40] Iter[9/62]		Loss: 0.2564
2019-10-28 15:31:59,414 Testing Epoch [8/40] Iter[10/62]		Loss: 0.2552
2019-10-28 15:31:59,443 Testing Epoch [8/40] Iter[11/62]		Loss: 0.2556
2019-10-28 15:31:59,465 Testing Epoch [8/40] Iter[12/62]		Loss: 0.2571
2019-10-28 15:31:59,483 Testing Epoch [8/40] Iter[13/62]		Loss: 0.2558
2019-10-28 15:31:59,501 Testing Epoch [8/40] Iter[14/62]		Loss: 0.2783
2019-10-28 15:31:59,526 Testing Epoch [8/40] Iter[15/62]		Loss: 0.2805
2019-10-28 15:31:59,546 Testing Epoch [8/40] Iter[16/62]		Loss: 0.2792
2019-10-28 15:31:59,566 Testing Epoch [8/40] Iter[17/62]		Loss: 0.2756
2019-10-28 15:31:59,584 Testing Epoch [8/40] Iter[18/62]		Loss: 0.2736
2019-10-28 15:31:59,618 Testing Epoch [8/40] Iter[19/62]		Loss: 0.2732
2019-10-28 15:31:59,637 Testing Epoch [8/40] Iter[20/62]		Loss: 0.2777
2019-10-28 15:31:59,655 Testing Epoch [8/40] Iter[21/62]		Loss: 0.2753
2019-10-28 15:31:59,682 Testing Epoch [8/40] Iter[22/62]		Loss: 0.2794
2019-10-28 15:31:59,703 Testing Epoch [8/40] Iter[23/62]		Loss: 0.2792
2019-10-28 15:31:59,720 Testing Epoch [8/40] Iter[24/62]		Loss: 0.2832
2019-10-28 15:31:59,746 Testing Epoch [8/40] Iter[25/62]		Loss: 0.2816
2019-10-28 15:31:59,770 Testing Epoch [8/40] Iter[26/62]		Loss: 0.2802
2019-10-28 15:31:59,797 Testing Epoch [8/40] Iter[27/62]		Loss: 0.2927
2019-10-28 15:31:59,815 Testing Epoch [8/40] Iter[28/62]		Loss: 0.2933
2019-10-28 15:31:59,841 Testing Epoch [8/40] Iter[29/62]		Loss: 0.2945
2019-10-28 15:31:59,858 Testing Epoch [8/40] Iter[30/62]		Loss: 0.2943
2019-10-28 15:31:59,876 Testing Epoch [8/40] Iter[31/62]		Loss: 0.2934
2019-10-28 15:31:59,902 Testing Epoch [8/40] Iter[32/62]		Loss: 0.2961
2019-10-28 15:31:59,924 Testing Epoch [8/40] Iter[33/62]		Loss: 0.2943
2019-10-28 15:31:59,942 Testing Epoch [8/40] Iter[34/62]		Loss: 0.2967
2019-10-28 15:31:59,960 Testing Epoch [8/40] Iter[35/62]		Loss: 0.2963
2019-10-28 15:31:59,986 Testing Epoch [8/40] Iter[36/62]		Loss: 0.2930
2019-10-28 15:32:00,006 Testing Epoch [8/40] Iter[37/62]		Loss: 0.2928
2019-10-28 15:32:00,026 Testing Epoch [8/40] Iter[38/62]		Loss: 0.2925
2019-10-28 15:32:00,043 Testing Epoch [8/40] Iter[39/62]		Loss: 0.2948
2019-10-28 15:32:00,074 Testing Epoch [8/40] Iter[40/62]		Loss: 0.2962
2019-10-28 15:32:00,093 Testing Epoch [8/40] Iter[41/62]		Loss: 0.2988
2019-10-28 15:32:00,111 Testing Epoch [8/40] Iter[42/62]		Loss: 0.2962
2019-10-28 15:32:00,128 Testing Epoch [8/40] Iter[43/62]		Loss: 0.2951
2019-10-28 15:32:00,154 Testing Epoch [8/40] Iter[44/62]		Loss: 0.2924
2019-10-28 15:32:00,176 Testing Epoch [8/40] Iter[45/62]		Loss: 0.2930
2019-10-28 15:32:00,194 Testing Epoch [8/40] Iter[46/62]		Loss: 0.2924
2019-10-28 15:32:00,211 Testing Epoch [8/40] Iter[47/62]		Loss: 0.2975
2019-10-28 15:32:00,246 Testing Epoch [8/40] Iter[48/62]		Loss: 0.2953
2019-10-28 15:32:00,264 Testing Epoch [8/40] Iter[49/62]		Loss: 0.2986
2019-10-28 15:32:00,282 Testing Epoch [8/40] Iter[50/62]		Loss: 0.2975
2019-10-28 15:32:00,310 Testing Epoch [8/40] Iter[51/62]		Loss: 0.2980
2019-10-28 15:32:00,337 Testing Epoch [8/40] Iter[52/62]		Loss: 0.2966
2019-10-28 15:32:00,355 Testing Epoch [8/40] Iter[53/62]		Loss: 0.2973
2019-10-28 15:32:00,373 Testing Epoch [8/40] Iter[54/62]		Loss: 0.2964
2019-10-28 15:32:00,390 Testing Epoch [8/40] Iter[55/62]		Loss: 0.2958
2019-10-28 15:32:00,407 Testing Epoch [8/40] Iter[56/62]		Loss: 0.2943
2019-10-28 15:32:00,423 Testing Epoch [8/40] Iter[57/62]		Loss: 0.2955
2019-10-28 15:32:00,441 Testing Epoch [8/40] Iter[58/62]		Loss: 0.2945
2019-10-28 15:32:00,456 Testing Epoch [8/40] Iter[59/62]		Loss: 0.2957
2019-10-28 15:32:00,473 Testing Epoch [8/40] Iter[60/62]		Loss: 0.2935
2019-10-28 15:32:00,490 Testing Epoch [8/40] Iter[61/62]		Loss: 0.2952
2019-10-28 15:32:00,499 Testing Epoch [8/40] Iter[62/62]		Loss: 0.2978
2019-10-28 15:32:00,571 Saving the Model
2019-10-28 15:32:01,013 Training Epoch [9/40] Iter[0/312]		Loss: 0.1740
2019-10-28 15:32:01,091 Training Epoch [9/40] Iter[1/312]		Loss: 0.3085
2019-10-28 15:32:01,175 Training Epoch [9/40] Iter[2/312]		Loss: 0.3356
2019-10-28 15:32:01,253 Training Epoch [9/40] Iter[3/312]		Loss: 0.3676
2019-10-28 15:32:01,335 Training Epoch [9/40] Iter[4/312]		Loss: 0.4152
2019-10-28 15:32:01,413 Training Epoch [9/40] Iter[5/312]		Loss: 0.4546
2019-10-28 15:32:01,491 Training Epoch [9/40] Iter[6/312]		Loss: 0.4587
2019-10-28 15:32:01,570 Training Epoch [9/40] Iter[7/312]		Loss: 0.4341
2019-10-28 15:32:01,649 Training Epoch [9/40] Iter[8/312]		Loss: 0.4126
2019-10-28 15:32:01,729 Training Epoch [9/40] Iter[9/312]		Loss: 0.4040
2019-10-28 15:32:01,808 Training Epoch [9/40] Iter[10/312]		Loss: 0.3944
2019-10-28 15:32:01,887 Training Epoch [9/40] Iter[11/312]		Loss: 0.3913
2019-10-28 15:32:01,967 Training Epoch [9/40] Iter[12/312]		Loss: 0.3954
2019-10-28 15:32:02,046 Training Epoch [9/40] Iter[13/312]		Loss: 0.3895
2019-10-28 15:32:02,125 Training Epoch [9/40] Iter[14/312]		Loss: 0.3809
2019-10-28 15:32:02,205 Training Epoch [9/40] Iter[15/312]		Loss: 0.3798
2019-10-28 15:32:02,284 Training Epoch [9/40] Iter[16/312]		Loss: 0.3755
2019-10-28 15:32:02,364 Training Epoch [9/40] Iter[17/312]		Loss: 0.3658
2019-10-28 15:32:02,443 Training Epoch [9/40] Iter[18/312]		Loss: 0.3619
2019-10-28 15:32:02,522 Training Epoch [9/40] Iter[19/312]		Loss: 0.3546
2019-10-28 15:32:02,602 Training Epoch [9/40] Iter[20/312]		Loss: 0.3504
2019-10-28 15:32:02,681 Training Epoch [9/40] Iter[21/312]		Loss: 0.3489
2019-10-28 15:32:02,760 Training Epoch [9/40] Iter[22/312]		Loss: 0.3505
2019-10-28 15:32:02,840 Training Epoch [9/40] Iter[23/312]		Loss: 0.3449
2019-10-28 15:32:02,919 Training Epoch [9/40] Iter[24/312]		Loss: 0.3409
2019-10-28 15:32:02,998 Training Epoch [9/40] Iter[25/312]		Loss: 0.3361
2019-10-28 15:32:03,078 Training Epoch [9/40] Iter[26/312]		Loss: 0.3381
2019-10-28 15:32:03,157 Training Epoch [9/40] Iter[27/312]		Loss: 0.3396
2019-10-28 15:32:03,237 Training Epoch [9/40] Iter[28/312]		Loss: 0.3398
2019-10-28 15:32:03,317 Training Epoch [9/40] Iter[29/312]		Loss: 0.3389
2019-10-28 15:32:03,397 Training Epoch [9/40] Iter[30/312]		Loss: 0.3397
2019-10-28 15:32:03,476 Training Epoch [9/40] Iter[31/312]		Loss: 0.3361
2019-10-28 15:32:03,556 Training Epoch [9/40] Iter[32/312]		Loss: 0.3359
2019-10-28 15:32:03,635 Training Epoch [9/40] Iter[33/312]		Loss: 0.3325
2019-10-28 15:32:03,715 Training Epoch [9/40] Iter[34/312]		Loss: 0.3361
2019-10-28 15:32:03,795 Training Epoch [9/40] Iter[35/312]		Loss: 0.3350
2019-10-28 15:32:03,874 Training Epoch [9/40] Iter[36/312]		Loss: 0.3337
2019-10-28 15:32:03,953 Training Epoch [9/40] Iter[37/312]		Loss: 0.3299
2019-10-28 15:32:04,032 Training Epoch [9/40] Iter[38/312]		Loss: 0.3264
2019-10-28 15:32:04,111 Training Epoch [9/40] Iter[39/312]		Loss: 0.3270
2019-10-28 15:32:04,191 Training Epoch [9/40] Iter[40/312]		Loss: 0.3232
2019-10-28 15:32:04,270 Training Epoch [9/40] Iter[41/312]		Loss: 0.3202
2019-10-28 15:32:04,349 Training Epoch [9/40] Iter[42/312]		Loss: 0.3193
2019-10-28 15:32:04,430 Training Epoch [9/40] Iter[43/312]		Loss: 0.3172
2019-10-28 15:32:04,509 Training Epoch [9/40] Iter[44/312]		Loss: 0.3156
2019-10-28 15:32:04,588 Training Epoch [9/40] Iter[45/312]		Loss: 0.3150
2019-10-28 15:32:04,668 Training Epoch [9/40] Iter[46/312]		Loss: 0.3166
2019-10-28 15:32:04,748 Training Epoch [9/40] Iter[47/312]		Loss: 0.3145
2019-10-28 15:32:04,828 Training Epoch [9/40] Iter[48/312]		Loss: 0.3131
2019-10-28 15:32:04,908 Training Epoch [9/40] Iter[49/312]		Loss: 0.3106
2019-10-28 15:32:04,988 Training Epoch [9/40] Iter[50/312]		Loss: 0.3107
2019-10-28 15:32:05,068 Training Epoch [9/40] Iter[51/312]		Loss: 0.3112
2019-10-28 15:32:05,148 Training Epoch [9/40] Iter[52/312]		Loss: 0.3121
2019-10-28 15:32:05,228 Training Epoch [9/40] Iter[53/312]		Loss: 0.3115
2019-10-28 15:32:05,307 Training Epoch [9/40] Iter[54/312]		Loss: 0.3123
2019-10-28 15:32:05,387 Training Epoch [9/40] Iter[55/312]		Loss: 0.3104
2019-10-28 15:32:05,467 Training Epoch [9/40] Iter[56/312]		Loss: 0.3093
2019-10-28 15:32:05,547 Training Epoch [9/40] Iter[57/312]		Loss: 0.3087
2019-10-28 15:32:05,627 Training Epoch [9/40] Iter[58/312]		Loss: 0.3086
2019-10-28 15:32:05,707 Training Epoch [9/40] Iter[59/312]		Loss: 0.3086
2019-10-28 15:32:05,790 Training Epoch [9/40] Iter[60/312]		Loss: 0.3088
2019-10-28 15:32:05,870 Training Epoch [9/40] Iter[61/312]		Loss: 0.3095
2019-10-28 15:32:05,950 Training Epoch [9/40] Iter[62/312]		Loss: 0.3093
2019-10-28 15:32:06,031 Training Epoch [9/40] Iter[63/312]		Loss: 0.3096
2019-10-28 15:32:06,110 Training Epoch [9/40] Iter[64/312]		Loss: 0.3103
2019-10-28 15:32:06,190 Training Epoch [9/40] Iter[65/312]		Loss: 0.3111
2019-10-28 15:32:06,275 Training Epoch [9/40] Iter[66/312]		Loss: 0.3115
2019-10-28 15:32:06,354 Training Epoch [9/40] Iter[67/312]		Loss: 0.3108
2019-10-28 15:32:06,433 Training Epoch [9/40] Iter[68/312]		Loss: 0.3110
2019-10-28 15:32:06,518 Training Epoch [9/40] Iter[69/312]		Loss: 0.3100
2019-10-28 15:32:06,597 Training Epoch [9/40] Iter[70/312]		Loss: 0.3110
2019-10-28 15:32:06,682 Training Epoch [9/40] Iter[71/312]		Loss: 0.3094
2019-10-28 15:32:06,761 Training Epoch [9/40] Iter[72/312]		Loss: 0.3091
2019-10-28 15:32:06,840 Training Epoch [9/40] Iter[73/312]		Loss: 0.3079
2019-10-28 15:32:06,919 Training Epoch [9/40] Iter[74/312]		Loss: 0.3072
2019-10-28 15:32:06,998 Training Epoch [9/40] Iter[75/312]		Loss: 0.3075
2019-10-28 15:32:07,077 Training Epoch [9/40] Iter[76/312]		Loss: 0.3080
2019-10-28 15:32:07,156 Training Epoch [9/40] Iter[77/312]		Loss: 0.3076
2019-10-28 15:32:07,235 Training Epoch [9/40] Iter[78/312]		Loss: 0.3076
2019-10-28 15:32:07,315 Training Epoch [9/40] Iter[79/312]		Loss: 0.3070
2019-10-28 15:32:07,394 Training Epoch [9/40] Iter[80/312]		Loss: 0.3071
2019-10-28 15:32:07,473 Training Epoch [9/40] Iter[81/312]		Loss: 0.3073
2019-10-28 15:32:07,552 Training Epoch [9/40] Iter[82/312]		Loss: 0.3065
2019-10-28 15:32:07,631 Training Epoch [9/40] Iter[83/312]		Loss: 0.3075
2019-10-28 15:32:07,710 Training Epoch [9/40] Iter[84/312]		Loss: 0.3072
2019-10-28 15:32:07,789 Training Epoch [9/40] Iter[85/312]		Loss: 0.3068
2019-10-28 15:32:07,868 Training Epoch [9/40] Iter[86/312]		Loss: 0.3065
2019-10-28 15:32:07,947 Training Epoch [9/40] Iter[87/312]		Loss: 0.3057
2019-10-28 15:32:08,026 Training Epoch [9/40] Iter[88/312]		Loss: 0.3055
2019-10-28 15:32:08,105 Training Epoch [9/40] Iter[89/312]		Loss: 0.3051
2019-10-28 15:32:08,184 Training Epoch [9/40] Iter[90/312]		Loss: 0.3047
2019-10-28 15:32:08,264 Training Epoch [9/40] Iter[91/312]		Loss: 0.3042
2019-10-28 15:32:08,343 Training Epoch [9/40] Iter[92/312]		Loss: 0.3031
2019-10-28 15:32:08,422 Training Epoch [9/40] Iter[93/312]		Loss: 0.3022
2019-10-28 15:32:08,502 Training Epoch [9/40] Iter[94/312]		Loss: 0.3016
2019-10-28 15:32:08,581 Training Epoch [9/40] Iter[95/312]		Loss: 0.3012
2019-10-28 15:32:08,660 Training Epoch [9/40] Iter[96/312]		Loss: 0.3003
2019-10-28 15:32:08,739 Training Epoch [9/40] Iter[97/312]		Loss: 0.3002
2019-10-28 15:32:08,818 Training Epoch [9/40] Iter[98/312]		Loss: 0.3010
2019-10-28 15:32:08,897 Training Epoch [9/40] Iter[99/312]		Loss: 0.3010
2019-10-28 15:32:08,976 Training Epoch [9/40] Iter[100/312]		Loss: 0.3008
2019-10-28 15:32:09,056 Training Epoch [9/40] Iter[101/312]		Loss: 0.3000
2019-10-28 15:32:09,134 Training Epoch [9/40] Iter[102/312]		Loss: 0.3007
2019-10-28 15:32:09,214 Training Epoch [9/40] Iter[103/312]		Loss: 0.3001
2019-10-28 15:32:09,293 Training Epoch [9/40] Iter[104/312]		Loss: 0.3013
2019-10-28 15:32:09,373 Training Epoch [9/40] Iter[105/312]		Loss: 0.3007
2019-10-28 15:32:09,452 Training Epoch [9/40] Iter[106/312]		Loss: 0.3015
2019-10-28 15:32:09,531 Training Epoch [9/40] Iter[107/312]		Loss: 0.3013
2019-10-28 15:32:09,610 Training Epoch [9/40] Iter[108/312]		Loss: 0.3021
2019-10-28 15:32:09,690 Training Epoch [9/40] Iter[109/312]		Loss: 0.3017
2019-10-28 15:32:09,769 Training Epoch [9/40] Iter[110/312]		Loss: 0.3022
2019-10-28 15:32:09,848 Training Epoch [9/40] Iter[111/312]		Loss: 0.3028
2019-10-28 15:32:09,927 Training Epoch [9/40] Iter[112/312]		Loss: 0.3031
2019-10-28 15:32:10,006 Training Epoch [9/40] Iter[113/312]		Loss: 0.3025
2019-10-28 15:32:10,085 Training Epoch [9/40] Iter[114/312]		Loss: 0.3020
2019-10-28 15:32:10,165 Training Epoch [9/40] Iter[115/312]		Loss: 0.3020
2019-10-28 15:32:10,244 Training Epoch [9/40] Iter[116/312]		Loss: 0.3020
2019-10-28 15:32:10,323 Training Epoch [9/40] Iter[117/312]		Loss: 0.3014
2019-10-28 15:32:10,408 Training Epoch [9/40] Iter[118/312]		Loss: 0.3011
2019-10-28 15:32:10,487 Training Epoch [9/40] Iter[119/312]		Loss: 0.3018
2019-10-28 15:32:10,566 Training Epoch [9/40] Iter[120/312]		Loss: 0.3015
2019-10-28 15:32:10,645 Training Epoch [9/40] Iter[121/312]		Loss: 0.3029
2019-10-28 15:32:10,730 Training Epoch [9/40] Iter[122/312]		Loss: 0.3035
2019-10-28 15:32:10,809 Training Epoch [9/40] Iter[123/312]		Loss: 0.3031
2019-10-28 15:32:10,888 Training Epoch [9/40] Iter[124/312]		Loss: 0.3027
2019-10-28 15:32:10,967 Training Epoch [9/40] Iter[125/312]		Loss: 0.3021
2019-10-28 15:32:11,046 Training Epoch [9/40] Iter[126/312]		Loss: 0.3013
2019-10-28 15:32:11,125 Training Epoch [9/40] Iter[127/312]		Loss: 0.3004
2019-10-28 15:32:11,205 Training Epoch [9/40] Iter[128/312]		Loss: 0.3003
2019-10-28 15:32:11,284 Training Epoch [9/40] Iter[129/312]		Loss: 0.3001
2019-10-28 15:32:11,364 Training Epoch [9/40] Iter[130/312]		Loss: 0.2994
2019-10-28 15:32:11,443 Training Epoch [9/40] Iter[131/312]		Loss: 0.2989
2019-10-28 15:32:11,523 Training Epoch [9/40] Iter[132/312]		Loss: 0.2980
2019-10-28 15:32:11,602 Training Epoch [9/40] Iter[133/312]		Loss: 0.2985
2019-10-28 15:32:11,681 Training Epoch [9/40] Iter[134/312]		Loss: 0.2979
2019-10-28 15:32:11,760 Training Epoch [9/40] Iter[135/312]		Loss: 0.2978
2019-10-28 15:32:11,839 Training Epoch [9/40] Iter[136/312]		Loss: 0.2970
2019-10-28 15:32:11,918 Training Epoch [9/40] Iter[137/312]		Loss: 0.2964
2019-10-28 15:32:11,997 Training Epoch [9/40] Iter[138/312]		Loss: 0.2956
2019-10-28 15:32:12,076 Training Epoch [9/40] Iter[139/312]		Loss: 0.2948
2019-10-28 15:32:12,155 Training Epoch [9/40] Iter[140/312]		Loss: 0.2945
2019-10-28 15:32:12,235 Training Epoch [9/40] Iter[141/312]		Loss: 0.2941
2019-10-28 15:32:12,314 Training Epoch [9/40] Iter[142/312]		Loss: 0.2948
2019-10-28 15:32:12,393 Training Epoch [9/40] Iter[143/312]		Loss: 0.2942
2019-10-28 15:32:12,473 Training Epoch [9/40] Iter[144/312]		Loss: 0.2945
2019-10-28 15:32:12,552 Training Epoch [9/40] Iter[145/312]		Loss: 0.2940
2019-10-28 15:32:12,631 Training Epoch [9/40] Iter[146/312]		Loss: 0.2934
2019-10-28 15:32:12,710 Training Epoch [9/40] Iter[147/312]		Loss: 0.2926
2019-10-28 15:32:12,789 Training Epoch [9/40] Iter[148/312]		Loss: 0.2929
2019-10-28 15:32:12,868 Training Epoch [9/40] Iter[149/312]		Loss: 0.2928
2019-10-28 15:32:12,947 Training Epoch [9/40] Iter[150/312]		Loss: 0.2927
2019-10-28 15:32:13,026 Training Epoch [9/40] Iter[151/312]		Loss: 0.2922
2019-10-28 15:32:13,106 Training Epoch [9/40] Iter[152/312]		Loss: 0.2920
2019-10-28 15:32:13,186 Training Epoch [9/40] Iter[153/312]		Loss: 0.2919
2019-10-28 15:32:13,266 Training Epoch [9/40] Iter[154/312]		Loss: 0.2916
2019-10-28 15:32:13,347 Training Epoch [9/40] Iter[155/312]		Loss: 0.2908
2019-10-28 15:32:13,427 Training Epoch [9/40] Iter[156/312]		Loss: 0.2899
2019-10-28 15:32:13,507 Training Epoch [9/40] Iter[157/312]		Loss: 0.2902
2019-10-28 15:32:13,587 Training Epoch [9/40] Iter[158/312]		Loss: 0.2901
2019-10-28 15:32:13,667 Training Epoch [9/40] Iter[159/312]		Loss: 0.2895
2019-10-28 15:32:13,747 Training Epoch [9/40] Iter[160/312]		Loss: 0.2892
2019-10-28 15:32:13,827 Training Epoch [9/40] Iter[161/312]		Loss: 0.2892
2019-10-28 15:32:13,907 Training Epoch [9/40] Iter[162/312]		Loss: 0.2889
2019-10-28 15:32:13,987 Training Epoch [9/40] Iter[163/312]		Loss: 0.2885
2019-10-28 15:32:14,067 Training Epoch [9/40] Iter[164/312]		Loss: 0.2884
2019-10-28 15:32:14,147 Training Epoch [9/40] Iter[165/312]		Loss: 0.2887
2019-10-28 15:32:14,227 Training Epoch [9/40] Iter[166/312]		Loss: 0.2884
2019-10-28 15:32:14,307 Training Epoch [9/40] Iter[167/312]		Loss: 0.2878
2019-10-28 15:32:14,387 Training Epoch [9/40] Iter[168/312]		Loss: 0.2876
2019-10-28 15:32:14,467 Training Epoch [9/40] Iter[169/312]		Loss: 0.2871
2019-10-28 15:32:14,547 Training Epoch [9/40] Iter[170/312]		Loss: 0.2869
2019-10-28 15:32:14,627 Training Epoch [9/40] Iter[171/312]		Loss: 0.2868
2019-10-28 15:32:14,707 Training Epoch [9/40] Iter[172/312]		Loss: 0.2866
2019-10-28 15:32:14,787 Training Epoch [9/40] Iter[173/312]		Loss: 0.2867
2019-10-28 15:32:14,868 Training Epoch [9/40] Iter[174/312]		Loss: 0.2871
2019-10-28 15:32:14,948 Training Epoch [9/40] Iter[175/312]		Loss: 0.2866
2019-10-28 15:32:15,028 Training Epoch [9/40] Iter[176/312]		Loss: 0.2864
2019-10-28 15:32:15,108 Training Epoch [9/40] Iter[177/312]		Loss: 0.2865
2019-10-28 15:32:15,188 Training Epoch [9/40] Iter[178/312]		Loss: 0.2870
2019-10-28 15:32:15,268 Training Epoch [9/40] Iter[179/312]		Loss: 0.2867
2019-10-28 15:32:15,348 Training Epoch [9/40] Iter[180/312]		Loss: 0.2866
2019-10-28 15:32:15,428 Training Epoch [9/40] Iter[181/312]		Loss: 0.2865
2019-10-28 15:32:15,508 Training Epoch [9/40] Iter[182/312]		Loss: 0.2864
2019-10-28 15:32:15,588 Training Epoch [9/40] Iter[183/312]		Loss: 0.2863
2019-10-28 15:32:15,668 Training Epoch [9/40] Iter[184/312]		Loss: 0.2859
2019-10-28 15:32:15,748 Training Epoch [9/40] Iter[185/312]		Loss: 0.2854
2019-10-28 15:32:15,828 Training Epoch [9/40] Iter[186/312]		Loss: 0.2850
2019-10-28 15:32:15,908 Training Epoch [9/40] Iter[187/312]		Loss: 0.2848
2019-10-28 15:32:15,988 Training Epoch [9/40] Iter[188/312]		Loss: 0.2847
2019-10-28 15:32:16,068 Training Epoch [9/40] Iter[189/312]		Loss: 0.2844
2019-10-28 15:32:16,148 Training Epoch [9/40] Iter[190/312]		Loss: 0.2845
2019-10-28 15:32:16,228 Training Epoch [9/40] Iter[191/312]		Loss: 0.2841
2019-10-28 15:32:16,308 Training Epoch [9/40] Iter[192/312]		Loss: 0.2843
2019-10-28 15:32:16,388 Training Epoch [9/40] Iter[193/312]		Loss: 0.2844
2019-10-28 15:32:16,469 Training Epoch [9/40] Iter[194/312]		Loss: 0.2838
2019-10-28 15:32:16,549 Training Epoch [9/40] Iter[195/312]		Loss: 0.2838
2019-10-28 15:32:16,629 Training Epoch [9/40] Iter[196/312]		Loss: 0.2835
2019-10-28 15:32:16,708 Training Epoch [9/40] Iter[197/312]		Loss: 0.2837
2019-10-28 15:32:16,788 Training Epoch [9/40] Iter[198/312]		Loss: 0.2847
2019-10-28 15:32:16,868 Training Epoch [9/40] Iter[199/312]		Loss: 0.2851
2019-10-28 15:32:16,948 Training Epoch [9/40] Iter[200/312]		Loss: 0.2852
2019-10-28 15:32:17,028 Training Epoch [9/40] Iter[201/312]		Loss: 0.2860
2019-10-28 15:32:17,108 Training Epoch [9/40] Iter[202/312]		Loss: 0.2859
2019-10-28 15:32:17,188 Training Epoch [9/40] Iter[203/312]		Loss: 0.2856
2019-10-28 15:32:17,268 Training Epoch [9/40] Iter[204/312]		Loss: 0.2862
2019-10-28 15:32:17,348 Training Epoch [9/40] Iter[205/312]		Loss: 0.2860
2019-10-28 15:32:17,429 Training Epoch [9/40] Iter[206/312]		Loss: 0.2855
2019-10-28 15:32:17,509 Training Epoch [9/40] Iter[207/312]		Loss: 0.2853
2019-10-28 15:32:17,589 Training Epoch [9/40] Iter[208/312]		Loss: 0.2858
2019-10-28 15:32:17,669 Training Epoch [9/40] Iter[209/312]		Loss: 0.2859
2019-10-28 15:32:17,748 Training Epoch [9/40] Iter[210/312]		Loss: 0.2860
2019-10-28 15:32:17,828 Training Epoch [9/40] Iter[211/312]		Loss: 0.2859
2019-10-28 15:32:17,908 Training Epoch [9/40] Iter[212/312]		Loss: 0.2859
2019-10-28 15:32:17,988 Training Epoch [9/40] Iter[213/312]		Loss: 0.2863
2019-10-28 15:32:18,068 Training Epoch [9/40] Iter[214/312]		Loss: 0.2859
2019-10-28 15:32:18,148 Training Epoch [9/40] Iter[215/312]		Loss: 0.2858
2019-10-28 15:32:18,229 Training Epoch [9/40] Iter[216/312]		Loss: 0.2857
2019-10-28 15:32:18,309 Training Epoch [9/40] Iter[217/312]		Loss: 0.2854
2019-10-28 15:32:18,389 Training Epoch [9/40] Iter[218/312]		Loss: 0.2858
2019-10-28 15:32:18,469 Training Epoch [9/40] Iter[219/312]		Loss: 0.2855
2019-10-28 15:32:18,549 Training Epoch [9/40] Iter[220/312]		Loss: 0.2856
2019-10-28 15:32:18,629 Training Epoch [9/40] Iter[221/312]		Loss: 0.2851
2019-10-28 15:32:18,709 Training Epoch [9/40] Iter[222/312]		Loss: 0.2849
2019-10-28 15:32:18,789 Training Epoch [9/40] Iter[223/312]		Loss: 0.2846
2019-10-28 15:32:18,869 Training Epoch [9/40] Iter[224/312]		Loss: 0.2847
2019-10-28 15:32:18,949 Training Epoch [9/40] Iter[225/312]		Loss: 0.2843
2019-10-28 15:32:19,029 Training Epoch [9/40] Iter[226/312]		Loss: 0.2839
2019-10-28 15:32:19,109 Training Epoch [9/40] Iter[227/312]		Loss: 0.2836
2019-10-28 15:32:19,190 Training Epoch [9/40] Iter[228/312]		Loss: 0.2834
2019-10-28 15:32:19,270 Training Epoch [9/40] Iter[229/312]		Loss: 0.2833
2019-10-28 15:32:19,350 Training Epoch [9/40] Iter[230/312]		Loss: 0.2828
2019-10-28 15:32:19,430 Training Epoch [9/40] Iter[231/312]		Loss: 0.2833
2019-10-28 15:32:19,510 Training Epoch [9/40] Iter[232/312]		Loss: 0.2835
2019-10-28 15:32:19,590 Training Epoch [9/40] Iter[233/312]		Loss: 0.2834
2019-10-28 15:32:19,670 Training Epoch [9/40] Iter[234/312]		Loss: 0.2829
2019-10-28 15:32:19,750 Training Epoch [9/40] Iter[235/312]		Loss: 0.2827
2019-10-28 15:32:19,830 Training Epoch [9/40] Iter[236/312]		Loss: 0.2825
2019-10-28 15:32:19,910 Training Epoch [9/40] Iter[237/312]		Loss: 0.2822
2019-10-28 15:32:19,990 Training Epoch [9/40] Iter[238/312]		Loss: 0.2820
2019-10-28 15:32:20,070 Training Epoch [9/40] Iter[239/312]		Loss: 0.2820
2019-10-28 15:32:20,149 Training Epoch [9/40] Iter[240/312]		Loss: 0.2818
2019-10-28 15:32:20,229 Training Epoch [9/40] Iter[241/312]		Loss: 0.2815
2019-10-28 15:32:20,309 Training Epoch [9/40] Iter[242/312]		Loss: 0.2812
2019-10-28 15:32:20,389 Training Epoch [9/40] Iter[243/312]		Loss: 0.2810
2019-10-28 15:32:20,469 Training Epoch [9/40] Iter[244/312]		Loss: 0.2808
2019-10-28 15:32:20,550 Training Epoch [9/40] Iter[245/312]		Loss: 0.2806
2019-10-28 15:32:20,630 Training Epoch [9/40] Iter[246/312]		Loss: 0.2807
2019-10-28 15:32:20,709 Training Epoch [9/40] Iter[247/312]		Loss: 0.2805
2019-10-28 15:32:20,789 Training Epoch [9/40] Iter[248/312]		Loss: 0.2802
2019-10-28 15:32:20,869 Training Epoch [9/40] Iter[249/312]		Loss: 0.2798
2019-10-28 15:32:20,949 Training Epoch [9/40] Iter[250/312]		Loss: 0.2798
2019-10-28 15:32:21,029 Training Epoch [9/40] Iter[251/312]		Loss: 0.2798
2019-10-28 15:32:21,109 Training Epoch [9/40] Iter[252/312]		Loss: 0.2798
2019-10-28 15:32:21,190 Training Epoch [9/40] Iter[253/312]		Loss: 0.2801
2019-10-28 15:32:21,270 Training Epoch [9/40] Iter[254/312]		Loss: 0.2800
2019-10-28 15:32:21,350 Training Epoch [9/40] Iter[255/312]		Loss: 0.2801
2019-10-28 15:32:21,430 Training Epoch [9/40] Iter[256/312]		Loss: 0.2799
2019-10-28 15:32:21,510 Training Epoch [9/40] Iter[257/312]		Loss: 0.2800
2019-10-28 15:32:21,590 Training Epoch [9/40] Iter[258/312]		Loss: 0.2800
2019-10-28 15:32:21,670 Training Epoch [9/40] Iter[259/312]		Loss: 0.2803
2019-10-28 15:32:21,750 Training Epoch [9/40] Iter[260/312]		Loss: 0.2802
2019-10-28 15:32:21,830 Training Epoch [9/40] Iter[261/312]		Loss: 0.2804
2019-10-28 15:32:21,910 Training Epoch [9/40] Iter[262/312]		Loss: 0.2803
2019-10-28 15:32:21,989 Training Epoch [9/40] Iter[263/312]		Loss: 0.2801
2019-10-28 15:32:22,069 Training Epoch [9/40] Iter[264/312]		Loss: 0.2799
2019-10-28 15:32:22,149 Training Epoch [9/40] Iter[265/312]		Loss: 0.2794
2019-10-28 15:32:22,229 Training Epoch [9/40] Iter[266/312]		Loss: 0.2792
2019-10-28 15:32:22,309 Training Epoch [9/40] Iter[267/312]		Loss: 0.2789
2019-10-28 15:32:22,389 Training Epoch [9/40] Iter[268/312]		Loss: 0.2786
2019-10-28 15:32:22,470 Training Epoch [9/40] Iter[269/312]		Loss: 0.2787
2019-10-28 15:32:22,550 Training Epoch [9/40] Iter[270/312]		Loss: 0.2787
2019-10-28 15:32:22,630 Training Epoch [9/40] Iter[271/312]		Loss: 0.2786
2019-10-28 15:32:22,710 Training Epoch [9/40] Iter[272/312]		Loss: 0.2785
2019-10-28 15:32:22,790 Training Epoch [9/40] Iter[273/312]		Loss: 0.2786
2019-10-28 15:32:22,870 Training Epoch [9/40] Iter[274/312]		Loss: 0.2784
2019-10-28 15:32:22,950 Training Epoch [9/40] Iter[275/312]		Loss: 0.2786
2019-10-28 15:32:23,029 Training Epoch [9/40] Iter[276/312]		Loss: 0.2785
2019-10-28 15:32:23,109 Training Epoch [9/40] Iter[277/312]		Loss: 0.2783
2019-10-28 15:32:23,190 Training Epoch [9/40] Iter[278/312]		Loss: 0.2781
2019-10-28 15:32:23,270 Training Epoch [9/40] Iter[279/312]		Loss: 0.2779
2019-10-28 15:32:23,350 Training Epoch [9/40] Iter[280/312]		Loss: 0.2780
2019-10-28 15:32:23,430 Training Epoch [9/40] Iter[281/312]		Loss: 0.2776
2019-10-28 15:32:23,510 Training Epoch [9/40] Iter[282/312]		Loss: 0.2780
2019-10-28 15:32:23,590 Training Epoch [9/40] Iter[283/312]		Loss: 0.2778
2019-10-28 15:32:23,670 Training Epoch [9/40] Iter[284/312]		Loss: 0.2779
2019-10-28 15:32:23,750 Training Epoch [9/40] Iter[285/312]		Loss: 0.2777
2019-10-28 15:32:23,830 Training Epoch [9/40] Iter[286/312]		Loss: 0.2773
2019-10-28 15:32:23,910 Training Epoch [9/40] Iter[287/312]		Loss: 0.2773
2019-10-28 15:32:23,990 Training Epoch [9/40] Iter[288/312]		Loss: 0.2771
2019-10-28 15:32:24,070 Training Epoch [9/40] Iter[289/312]		Loss: 0.2768
2019-10-28 15:32:24,150 Training Epoch [9/40] Iter[290/312]		Loss: 0.2766
2019-10-28 15:32:24,230 Training Epoch [9/40] Iter[291/312]		Loss: 0.2766
2019-10-28 15:32:24,310 Training Epoch [9/40] Iter[292/312]		Loss: 0.2765
2019-10-28 15:32:24,391 Training Epoch [9/40] Iter[293/312]		Loss: 0.2763
2019-10-28 15:32:24,471 Training Epoch [9/40] Iter[294/312]		Loss: 0.2761
2019-10-28 15:32:24,551 Training Epoch [9/40] Iter[295/312]		Loss: 0.2761
2019-10-28 15:32:24,631 Training Epoch [9/40] Iter[296/312]		Loss: 0.2758
2019-10-28 15:32:24,711 Training Epoch [9/40] Iter[297/312]		Loss: 0.2757
2019-10-28 15:32:24,791 Training Epoch [9/40] Iter[298/312]		Loss: 0.2755
2019-10-28 15:32:24,871 Training Epoch [9/40] Iter[299/312]		Loss: 0.2754
2019-10-28 15:32:24,951 Training Epoch [9/40] Iter[300/312]		Loss: 0.2754
2019-10-28 15:32:25,031 Training Epoch [9/40] Iter[301/312]		Loss: 0.2752
2019-10-28 15:32:25,110 Training Epoch [9/40] Iter[302/312]		Loss: 0.2751
2019-10-28 15:32:25,190 Training Epoch [9/40] Iter[303/312]		Loss: 0.2749
2019-10-28 15:32:25,270 Training Epoch [9/40] Iter[304/312]		Loss: 0.2746
2019-10-28 15:32:25,350 Training Epoch [9/40] Iter[305/312]		Loss: 0.2743
2019-10-28 15:32:25,429 Training Epoch [9/40] Iter[306/312]		Loss: 0.2744
2019-10-28 15:32:25,508 Training Epoch [9/40] Iter[307/312]		Loss: 0.2743
2019-10-28 15:32:25,587 Training Epoch [9/40] Iter[308/312]		Loss: 0.2740
2019-10-28 15:32:25,667 Training Epoch [9/40] Iter[309/312]		Loss: 0.2741
2019-10-28 15:32:25,746 Training Epoch [9/40] Iter[310/312]		Loss: 0.2740
2019-10-28 15:32:25,826 Training Epoch [9/40] Iter[311/312]		Loss: 0.2742
2019-10-28 15:32:25,865 Training Epoch [9/40] Iter[312/312]		Loss: 0.2740
2019-10-28 15:32:26,312 Testing Epoch [9/40] Iter[0/62]		Loss: 0.1856
2019-10-28 15:32:26,346 Testing Epoch [9/40] Iter[1/62]		Loss: 0.2184
2019-10-28 15:32:26,374 Testing Epoch [9/40] Iter[2/62]		Loss: 0.2139
2019-10-28 15:32:26,414 Testing Epoch [9/40] Iter[3/62]		Loss: 0.2171
2019-10-28 15:32:26,430 Testing Epoch [9/40] Iter[4/62]		Loss: 0.2245
2019-10-28 15:32:26,460 Testing Epoch [9/40] Iter[5/62]		Loss: 0.2284
2019-10-28 15:32:26,479 Testing Epoch [9/40] Iter[6/62]		Loss: 0.2322
2019-10-28 15:32:26,510 Testing Epoch [9/40] Iter[7/62]		Loss: 0.2313
2019-10-28 15:32:26,529 Testing Epoch [9/40] Iter[8/62]		Loss: 0.2343
2019-10-28 15:32:26,557 Testing Epoch [9/40] Iter[9/62]		Loss: 0.2360
2019-10-28 15:32:26,580 Testing Epoch [9/40] Iter[10/62]		Loss: 0.2351
2019-10-28 15:32:26,598 Testing Epoch [9/40] Iter[11/62]		Loss: 0.2435
2019-10-28 15:32:26,617 Testing Epoch [9/40] Iter[12/62]		Loss: 0.2467
2019-10-28 15:32:26,646 Testing Epoch [9/40] Iter[13/62]		Loss: 0.2500
2019-10-28 15:32:26,674 Testing Epoch [9/40] Iter[14/62]		Loss: 0.2665
2019-10-28 15:32:26,699 Testing Epoch [9/40] Iter[15/62]		Loss: 0.2679
2019-10-28 15:32:26,722 Testing Epoch [9/40] Iter[16/62]		Loss: 0.2655
2019-10-28 15:32:26,741 Testing Epoch [9/40] Iter[17/62]		Loss: 0.2622
2019-10-28 15:32:26,760 Testing Epoch [9/40] Iter[18/62]		Loss: 0.2576
2019-10-28 15:32:26,788 Testing Epoch [9/40] Iter[19/62]		Loss: 0.2553
2019-10-28 15:32:26,807 Testing Epoch [9/40] Iter[20/62]		Loss: 0.2572
2019-10-28 15:32:26,842 Testing Epoch [9/40] Iter[21/62]		Loss: 0.2568
2019-10-28 15:32:26,860 Testing Epoch [9/40] Iter[22/62]		Loss: 0.2572
2019-10-28 15:32:26,886 Testing Epoch [9/40] Iter[23/62]		Loss: 0.2563
2019-10-28 15:32:26,905 Testing Epoch [9/40] Iter[24/62]		Loss: 0.2625
2019-10-28 15:32:26,933 Testing Epoch [9/40] Iter[25/62]		Loss: 0.2611
2019-10-28 15:32:26,958 Testing Epoch [9/40] Iter[26/62]		Loss: 0.2592
2019-10-28 15:32:26,976 Testing Epoch [9/40] Iter[27/62]		Loss: 0.2665
2019-10-28 15:32:26,995 Testing Epoch [9/40] Iter[28/62]		Loss: 0.2686
2019-10-28 15:32:27,026 Testing Epoch [9/40] Iter[29/62]		Loss: 0.2685
2019-10-28 15:32:27,045 Testing Epoch [9/40] Iter[30/62]		Loss: 0.2691
2019-10-28 15:32:27,063 Testing Epoch [9/40] Iter[31/62]		Loss: 0.2683
2019-10-28 15:32:27,090 Testing Epoch [9/40] Iter[32/62]		Loss: 0.2702
2019-10-28 15:32:27,112 Testing Epoch [9/40] Iter[33/62]		Loss: 0.2698
2019-10-28 15:32:27,135 Testing Epoch [9/40] Iter[34/62]		Loss: 0.2727
2019-10-28 15:32:27,154 Testing Epoch [9/40] Iter[35/62]		Loss: 0.2717
2019-10-28 15:32:27,182 Testing Epoch [9/40] Iter[36/62]		Loss: 0.2706
2019-10-28 15:32:27,204 Testing Epoch [9/40] Iter[37/62]		Loss: 0.2683
2019-10-28 15:32:27,224 Testing Epoch [9/40] Iter[38/62]		Loss: 0.2672
2019-10-28 15:32:27,243 Testing Epoch [9/40] Iter[39/62]		Loss: 0.2678
2019-10-28 15:32:27,274 Testing Epoch [9/40] Iter[40/62]		Loss: 0.2694
2019-10-28 15:32:27,293 Testing Epoch [9/40] Iter[41/62]		Loss: 0.2704
2019-10-28 15:32:27,312 Testing Epoch [9/40] Iter[42/62]		Loss: 0.2682
2019-10-28 15:32:27,335 Testing Epoch [9/40] Iter[43/62]		Loss: 0.2677
2019-10-28 15:32:27,362 Testing Epoch [9/40] Iter[44/62]		Loss: 0.2663
2019-10-28 15:32:27,390 Testing Epoch [9/40] Iter[45/62]		Loss: 0.2674
2019-10-28 15:32:27,412 Testing Epoch [9/40] Iter[46/62]		Loss: 0.2688
2019-10-28 15:32:27,431 Testing Epoch [9/40] Iter[47/62]		Loss: 0.2745
2019-10-28 15:32:27,462 Testing Epoch [9/40] Iter[48/62]		Loss: 0.2724
2019-10-28 15:32:27,480 Testing Epoch [9/40] Iter[49/62]		Loss: 0.2746
2019-10-28 15:32:27,509 Testing Epoch [9/40] Iter[50/62]		Loss: 0.2737
2019-10-28 15:32:27,526 Testing Epoch [9/40] Iter[51/62]		Loss: 0.2732
2019-10-28 15:32:27,554 Testing Epoch [9/40] Iter[52/62]		Loss: 0.2714
2019-10-28 15:32:27,572 Testing Epoch [9/40] Iter[53/62]		Loss: 0.2714
2019-10-28 15:32:27,590 Testing Epoch [9/40] Iter[54/62]		Loss: 0.2698
2019-10-28 15:32:27,609 Testing Epoch [9/40] Iter[55/62]		Loss: 0.2692
2019-10-28 15:32:27,627 Testing Epoch [9/40] Iter[56/62]		Loss: 0.2691
2019-10-28 15:32:27,644 Testing Epoch [9/40] Iter[57/62]		Loss: 0.2692
2019-10-28 15:32:27,661 Testing Epoch [9/40] Iter[58/62]		Loss: 0.2689
2019-10-28 15:32:27,678 Testing Epoch [9/40] Iter[59/62]		Loss: 0.2696
2019-10-28 15:32:27,695 Testing Epoch [9/40] Iter[60/62]		Loss: 0.2686
2019-10-28 15:32:27,713 Testing Epoch [9/40] Iter[61/62]		Loss: 0.2697
2019-10-28 15:32:27,722 Testing Epoch [9/40] Iter[62/62]		Loss: 0.2723
2019-10-28 15:32:27,797 Saving the Model
2019-10-28 15:32:28,245 Training Epoch [10/40] Iter[0/312]		Loss: 0.2709
2019-10-28 15:32:28,324 Training Epoch [10/40] Iter[1/312]		Loss: 0.3005
2019-10-28 15:32:28,404 Training Epoch [10/40] Iter[2/312]		Loss: 0.3190
2019-10-28 15:32:28,486 Training Epoch [10/40] Iter[3/312]		Loss: 0.2927
2019-10-28 15:32:28,566 Training Epoch [10/40] Iter[4/312]		Loss: 0.2908
2019-10-28 15:32:28,645 Training Epoch [10/40] Iter[5/312]		Loss: 0.2965
2019-10-28 15:32:28,725 Training Epoch [10/40] Iter[6/312]		Loss: 0.2904
2019-10-28 15:32:28,804 Training Epoch [10/40] Iter[7/312]		Loss: 0.3066
2019-10-28 15:32:28,884 Training Epoch [10/40] Iter[8/312]		Loss: 0.3043
2019-10-28 15:32:28,964 Training Epoch [10/40] Iter[9/312]		Loss: 0.2982
2019-10-28 15:32:29,044 Training Epoch [10/40] Iter[10/312]		Loss: 0.2937
2019-10-28 15:32:29,123 Training Epoch [10/40] Iter[11/312]		Loss: 0.2854
2019-10-28 15:32:29,203 Training Epoch [10/40] Iter[12/312]		Loss: 0.2884
2019-10-28 15:32:29,283 Training Epoch [10/40] Iter[13/312]		Loss: 0.2796
2019-10-28 15:32:29,363 Training Epoch [10/40] Iter[14/312]		Loss: 0.2746
2019-10-28 15:32:29,444 Training Epoch [10/40] Iter[15/312]		Loss: 0.2744
2019-10-28 15:32:29,523 Training Epoch [10/40] Iter[16/312]		Loss: 0.2708
2019-10-28 15:32:29,603 Training Epoch [10/40] Iter[17/312]		Loss: 0.2705
2019-10-28 15:32:29,683 Training Epoch [10/40] Iter[18/312]		Loss: 0.2720
2019-10-28 15:32:29,763 Training Epoch [10/40] Iter[19/312]		Loss: 0.2674
2019-10-28 15:32:29,843 Training Epoch [10/40] Iter[20/312]		Loss: 0.2626
2019-10-28 15:32:29,923 Training Epoch [10/40] Iter[21/312]		Loss: 0.2606
2019-10-28 15:32:30,003 Training Epoch [10/40] Iter[22/312]		Loss: 0.2613
2019-10-28 15:32:30,082 Training Epoch [10/40] Iter[23/312]		Loss: 0.2612
2019-10-28 15:32:30,162 Training Epoch [10/40] Iter[24/312]		Loss: 0.2572
2019-10-28 15:32:30,242 Training Epoch [10/40] Iter[25/312]		Loss: 0.2559
2019-10-28 15:32:30,322 Training Epoch [10/40] Iter[26/312]		Loss: 0.2544
2019-10-28 15:32:30,402 Training Epoch [10/40] Iter[27/312]		Loss: 0.2519
2019-10-28 15:32:30,482 Training Epoch [10/40] Iter[28/312]		Loss: 0.2558
2019-10-28 15:32:30,562 Training Epoch [10/40] Iter[29/312]		Loss: 0.2592
2019-10-28 15:32:30,642 Training Epoch [10/40] Iter[30/312]		Loss: 0.2583
2019-10-28 15:32:30,722 Training Epoch [10/40] Iter[31/312]		Loss: 0.2566
2019-10-28 15:32:30,802 Training Epoch [10/40] Iter[32/312]		Loss: 0.2555
2019-10-28 15:32:30,882 Training Epoch [10/40] Iter[33/312]		Loss: 0.2590
2019-10-28 15:32:30,962 Training Epoch [10/40] Iter[34/312]		Loss: 0.2631
2019-10-28 15:32:31,042 Training Epoch [10/40] Iter[35/312]		Loss: 0.2603
2019-10-28 15:32:31,123 Training Epoch [10/40] Iter[36/312]		Loss: 0.2595
2019-10-28 15:32:31,203 Training Epoch [10/40] Iter[37/312]		Loss: 0.2593
2019-10-28 15:32:31,283 Training Epoch [10/40] Iter[38/312]		Loss: 0.2598
2019-10-28 15:32:31,363 Training Epoch [10/40] Iter[39/312]		Loss: 0.2584
2019-10-28 15:32:31,443 Training Epoch [10/40] Iter[40/312]		Loss: 0.2596
2019-10-28 15:32:31,523 Training Epoch [10/40] Iter[41/312]		Loss: 0.2584
2019-10-28 15:32:31,603 Training Epoch [10/40] Iter[42/312]		Loss: 0.2577
2019-10-28 15:32:31,683 Training Epoch [10/40] Iter[43/312]		Loss: 0.2562
2019-10-28 15:32:31,763 Training Epoch [10/40] Iter[44/312]		Loss: 0.2566
2019-10-28 15:32:31,843 Training Epoch [10/40] Iter[45/312]		Loss: 0.2574
2019-10-28 15:32:31,923 Training Epoch [10/40] Iter[46/312]		Loss: 0.2564
2019-10-28 15:32:32,003 Training Epoch [10/40] Iter[47/312]		Loss: 0.2576
2019-10-28 15:32:32,083 Training Epoch [10/40] Iter[48/312]		Loss: 0.2571
2019-10-28 15:32:32,163 Training Epoch [10/40] Iter[49/312]		Loss: 0.2559
2019-10-28 15:32:32,243 Training Epoch [10/40] Iter[50/312]		Loss: 0.2572
2019-10-28 15:32:32,323 Training Epoch [10/40] Iter[51/312]		Loss: 0.2583
2019-10-28 15:32:32,403 Training Epoch [10/40] Iter[52/312]		Loss: 0.2579
2019-10-28 15:32:32,483 Training Epoch [10/40] Iter[53/312]		Loss: 0.2571
2019-10-28 15:32:32,563 Training Epoch [10/40] Iter[54/312]		Loss: 0.2568
2019-10-28 15:32:32,643 Training Epoch [10/40] Iter[55/312]		Loss: 0.2573
2019-10-28 15:32:32,723 Training Epoch [10/40] Iter[56/312]		Loss: 0.2578
2019-10-28 15:32:32,803 Training Epoch [10/40] Iter[57/312]		Loss: 0.2568
2019-10-28 15:32:32,883 Training Epoch [10/40] Iter[58/312]		Loss: 0.2569
2019-10-28 15:32:32,963 Training Epoch [10/40] Iter[59/312]		Loss: 0.2563
2019-10-28 15:32:33,043 Training Epoch [10/40] Iter[60/312]		Loss: 0.2555
2019-10-28 15:32:33,123 Training Epoch [10/40] Iter[61/312]		Loss: 0.2559
2019-10-28 15:32:33,203 Training Epoch [10/40] Iter[62/312]		Loss: 0.2557
2019-10-28 15:32:33,283 Training Epoch [10/40] Iter[63/312]		Loss: 0.2557
2019-10-28 15:32:33,363 Training Epoch [10/40] Iter[64/312]		Loss: 0.2564
2019-10-28 15:32:33,443 Training Epoch [10/40] Iter[65/312]		Loss: 0.2569
2019-10-28 15:32:33,523 Training Epoch [10/40] Iter[66/312]		Loss: 0.2558
2019-10-28 15:32:33,603 Training Epoch [10/40] Iter[67/312]		Loss: 0.2573
2019-10-28 15:32:33,683 Training Epoch [10/40] Iter[68/312]		Loss: 0.2571
2019-10-28 15:32:33,764 Training Epoch [10/40] Iter[69/312]		Loss: 0.2566
2019-10-28 15:32:33,844 Training Epoch [10/40] Iter[70/312]		Loss: 0.2567
2019-10-28 15:32:33,923 Training Epoch [10/40] Iter[71/312]		Loss: 0.2577
2019-10-28 15:32:34,003 Training Epoch [10/40] Iter[72/312]		Loss: 0.2570
2019-10-28 15:32:34,083 Training Epoch [10/40] Iter[73/312]		Loss: 0.2576
2019-10-28 15:32:34,164 Training Epoch [10/40] Iter[74/312]		Loss: 0.2569
2019-10-28 15:32:34,244 Training Epoch [10/40] Iter[75/312]		Loss: 0.2579
2019-10-28 15:32:34,323 Training Epoch [10/40] Iter[76/312]		Loss: 0.2577
2019-10-28 15:32:34,404 Training Epoch [10/40] Iter[77/312]		Loss: 0.2572
2019-10-28 15:32:34,484 Training Epoch [10/40] Iter[78/312]		Loss: 0.2580
2019-10-28 15:32:34,564 Training Epoch [10/40] Iter[79/312]		Loss: 0.2586
2019-10-28 15:32:34,643 Training Epoch [10/40] Iter[80/312]		Loss: 0.2583
2019-10-28 15:32:34,723 Training Epoch [10/40] Iter[81/312]		Loss: 0.2591
2019-10-28 15:32:34,803 Training Epoch [10/40] Iter[82/312]		Loss: 0.2585
2019-10-28 15:32:34,883 Training Epoch [10/40] Iter[83/312]		Loss: 0.2570
2019-10-28 15:32:34,962 Training Epoch [10/40] Iter[84/312]		Loss: 0.2570
2019-10-28 15:32:35,042 Training Epoch [10/40] Iter[85/312]		Loss: 0.2565
2019-10-28 15:32:35,122 Training Epoch [10/40] Iter[86/312]		Loss: 0.2561
2019-10-28 15:32:35,202 Training Epoch [10/40] Iter[87/312]		Loss: 0.2562
2019-10-28 15:32:35,282 Training Epoch [10/40] Iter[88/312]		Loss: 0.2555
2019-10-28 15:32:35,362 Training Epoch [10/40] Iter[89/312]		Loss: 0.2563
2019-10-28 15:32:35,442 Training Epoch [10/40] Iter[90/312]		Loss: 0.2560
2019-10-28 15:32:35,522 Training Epoch [10/40] Iter[91/312]		Loss: 0.2553
2019-10-28 15:32:35,602 Training Epoch [10/40] Iter[92/312]		Loss: 0.2556
2019-10-28 15:32:35,682 Training Epoch [10/40] Iter[93/312]		Loss: 0.2556
2019-10-28 15:32:35,762 Training Epoch [10/40] Iter[94/312]		Loss: 0.2553
2019-10-28 15:32:35,842 Training Epoch [10/40] Iter[95/312]		Loss: 0.2550
2019-10-28 15:32:35,921 Training Epoch [10/40] Iter[96/312]		Loss: 0.2555
2019-10-28 15:32:36,001 Training Epoch [10/40] Iter[97/312]		Loss: 0.2561
2019-10-28 15:32:36,081 Training Epoch [10/40] Iter[98/312]		Loss: 0.2552
2019-10-28 15:32:36,161 Training Epoch [10/40] Iter[99/312]		Loss: 0.2549
2019-10-28 15:32:36,241 Training Epoch [10/40] Iter[100/312]		Loss: 0.2551
2019-10-28 15:32:36,321 Training Epoch [10/40] Iter[101/312]		Loss: 0.2546
2019-10-28 15:32:36,401 Training Epoch [10/40] Iter[102/312]		Loss: 0.2539
2019-10-28 15:32:36,481 Training Epoch [10/40] Iter[103/312]		Loss: 0.2541
2019-10-28 15:32:36,561 Training Epoch [10/40] Iter[104/312]		Loss: 0.2544
2019-10-28 15:32:36,641 Training Epoch [10/40] Iter[105/312]		Loss: 0.2550
2019-10-28 15:32:36,721 Training Epoch [10/40] Iter[106/312]		Loss: 0.2547
2019-10-28 15:32:36,801 Training Epoch [10/40] Iter[107/312]		Loss: 0.2546
2019-10-28 15:32:36,881 Training Epoch [10/40] Iter[108/312]		Loss: 0.2541
2019-10-28 15:32:36,961 Training Epoch [10/40] Iter[109/312]		Loss: 0.2545
2019-10-28 15:32:37,041 Training Epoch [10/40] Iter[110/312]		Loss: 0.2543
2019-10-28 15:32:37,121 Training Epoch [10/40] Iter[111/312]		Loss: 0.2543
2019-10-28 15:32:37,201 Training Epoch [10/40] Iter[112/312]		Loss: 0.2543
2019-10-28 15:32:37,281 Training Epoch [10/40] Iter[113/312]		Loss: 0.2540
2019-10-28 15:32:37,361 Training Epoch [10/40] Iter[114/312]		Loss: 0.2535
2019-10-28 15:32:37,441 Training Epoch [10/40] Iter[115/312]		Loss: 0.2540
2019-10-28 15:32:37,521 Training Epoch [10/40] Iter[116/312]		Loss: 0.2536
2019-10-28 15:32:37,601 Training Epoch [10/40] Iter[117/312]		Loss: 0.2540
2019-10-28 15:32:37,680 Training Epoch [10/40] Iter[118/312]		Loss: 0.2534
2019-10-28 15:32:37,760 Training Epoch [10/40] Iter[119/312]		Loss: 0.2529
2019-10-28 15:32:37,840 Training Epoch [10/40] Iter[120/312]		Loss: 0.2532
2019-10-28 15:32:37,920 Training Epoch [10/40] Iter[121/312]		Loss: 0.2526
2019-10-28 15:32:38,000 Training Epoch [10/40] Iter[122/312]		Loss: 0.2522
2019-10-28 15:32:38,080 Training Epoch [10/40] Iter[123/312]		Loss: 0.2521
2019-10-28 15:32:38,160 Training Epoch [10/40] Iter[124/312]		Loss: 0.2522
2019-10-28 15:32:38,240 Training Epoch [10/40] Iter[125/312]		Loss: 0.2529
2019-10-28 15:32:38,320 Training Epoch [10/40] Iter[126/312]		Loss: 0.2526
2019-10-28 15:32:38,400 Training Epoch [10/40] Iter[127/312]		Loss: 0.2530
2019-10-28 15:32:38,481 Training Epoch [10/40] Iter[128/312]		Loss: 0.2537
2019-10-28 15:32:38,561 Training Epoch [10/40] Iter[129/312]		Loss: 0.2531
2019-10-28 15:32:38,641 Training Epoch [10/40] Iter[130/312]		Loss: 0.2540
2019-10-28 15:32:38,721 Training Epoch [10/40] Iter[131/312]		Loss: 0.2542
2019-10-28 15:32:38,801 Training Epoch [10/40] Iter[132/312]		Loss: 0.2542
2019-10-28 15:32:38,881 Training Epoch [10/40] Iter[133/312]		Loss: 0.2541
2019-10-28 15:32:38,961 Training Epoch [10/40] Iter[134/312]		Loss: 0.2534
2019-10-28 15:32:39,041 Training Epoch [10/40] Iter[135/312]		Loss: 0.2535
2019-10-28 15:32:39,121 Training Epoch [10/40] Iter[136/312]		Loss: 0.2536
2019-10-28 15:32:39,200 Training Epoch [10/40] Iter[137/312]		Loss: 0.2535
2019-10-28 15:32:39,280 Training Epoch [10/40] Iter[138/312]		Loss: 0.2535
2019-10-28 15:32:39,359 Training Epoch [10/40] Iter[139/312]		Loss: 0.2534
2019-10-28 15:32:39,439 Training Epoch [10/40] Iter[140/312]		Loss: 0.2537
2019-10-28 15:32:39,518 Training Epoch [10/40] Iter[141/312]		Loss: 0.2539
2019-10-28 15:32:39,597 Training Epoch [10/40] Iter[142/312]		Loss: 0.2536
2019-10-28 15:32:39,676 Training Epoch [10/40] Iter[143/312]		Loss: 0.2533
2019-10-28 15:32:39,755 Training Epoch [10/40] Iter[144/312]		Loss: 0.2536
2019-10-28 15:32:39,834 Training Epoch [10/40] Iter[145/312]		Loss: 0.2533
2019-10-28 15:32:39,913 Training Epoch [10/40] Iter[146/312]		Loss: 0.2536
2019-10-28 15:32:39,992 Training Epoch [10/40] Iter[147/312]		Loss: 0.2533
2019-10-28 15:32:40,071 Training Epoch [10/40] Iter[148/312]		Loss: 0.2527
2019-10-28 15:32:40,150 Training Epoch [10/40] Iter[149/312]		Loss: 0.2532
2019-10-28 15:32:40,229 Training Epoch [10/40] Iter[150/312]		Loss: 0.2528
2019-10-28 15:32:40,308 Training Epoch [10/40] Iter[151/312]		Loss: 0.2531
2019-10-28 15:32:40,387 Training Epoch [10/40] Iter[152/312]		Loss: 0.2529
2019-10-28 15:32:40,467 Training Epoch [10/40] Iter[153/312]		Loss: 0.2530
2019-10-28 15:32:40,546 Training Epoch [10/40] Iter[154/312]		Loss: 0.2527
2019-10-28 15:32:40,625 Training Epoch [10/40] Iter[155/312]		Loss: 0.2524
2019-10-28 15:32:40,704 Training Epoch [10/40] Iter[156/312]		Loss: 0.2520
2019-10-28 15:32:40,783 Training Epoch [10/40] Iter[157/312]		Loss: 0.2531
2019-10-28 15:32:40,862 Training Epoch [10/40] Iter[158/312]		Loss: 0.2535
2019-10-28 15:32:40,942 Training Epoch [10/40] Iter[159/312]		Loss: 0.2536
2019-10-28 15:32:41,021 Training Epoch [10/40] Iter[160/312]		Loss: 0.2537
2019-10-28 15:32:41,100 Training Epoch [10/40] Iter[161/312]		Loss: 0.2537
2019-10-28 15:32:41,179 Training Epoch [10/40] Iter[162/312]		Loss: 0.2537
2019-10-28 15:32:41,258 Training Epoch [10/40] Iter[163/312]		Loss: 0.2536
2019-10-28 15:32:41,338 Training Epoch [10/40] Iter[164/312]		Loss: 0.2536
2019-10-28 15:32:41,418 Training Epoch [10/40] Iter[165/312]		Loss: 0.2532
2019-10-28 15:32:41,497 Training Epoch [10/40] Iter[166/312]		Loss: 0.2530
2019-10-28 15:32:41,577 Training Epoch [10/40] Iter[167/312]		Loss: 0.2541
2019-10-28 15:32:41,656 Training Epoch [10/40] Iter[168/312]		Loss: 0.2547
2019-10-28 15:32:41,735 Training Epoch [10/40] Iter[169/312]		Loss: 0.2547
2019-10-28 15:32:41,813 Training Epoch [10/40] Iter[170/312]		Loss: 0.2551
2019-10-28 15:32:41,893 Training Epoch [10/40] Iter[171/312]		Loss: 0.2544
2019-10-28 15:32:41,972 Training Epoch [10/40] Iter[172/312]		Loss: 0.2540
2019-10-28 15:32:42,052 Training Epoch [10/40] Iter[173/312]		Loss: 0.2541
2019-10-28 15:32:42,131 Training Epoch [10/40] Iter[174/312]		Loss: 0.2540
2019-10-28 15:32:42,211 Training Epoch [10/40] Iter[175/312]		Loss: 0.2539
2019-10-28 15:32:42,290 Training Epoch [10/40] Iter[176/312]		Loss: 0.2538
2019-10-28 15:32:42,369 Training Epoch [10/40] Iter[177/312]		Loss: 0.2536
2019-10-28 15:32:42,449 Training Epoch [10/40] Iter[178/312]		Loss: 0.2542
2019-10-28 15:32:42,528 Training Epoch [10/40] Iter[179/312]		Loss: 0.2541
2019-10-28 15:32:42,607 Training Epoch [10/40] Iter[180/312]		Loss: 0.2543
2019-10-28 15:32:42,686 Training Epoch [10/40] Iter[181/312]		Loss: 0.2546
2019-10-28 15:32:42,766 Training Epoch [10/40] Iter[182/312]		Loss: 0.2555
2019-10-28 15:32:42,846 Training Epoch [10/40] Iter[183/312]		Loss: 0.2553
2019-10-28 15:32:42,925 Training Epoch [10/40] Iter[184/312]		Loss: 0.2560
2019-10-28 15:32:43,004 Training Epoch [10/40] Iter[185/312]		Loss: 0.2564
2019-10-28 15:32:43,083 Training Epoch [10/40] Iter[186/312]		Loss: 0.2562
2019-10-28 15:32:43,163 Training Epoch [10/40] Iter[187/312]		Loss: 0.2564
2019-10-28 15:32:43,242 Training Epoch [10/40] Iter[188/312]		Loss: 0.2561
2019-10-28 15:32:43,321 Training Epoch [10/40] Iter[189/312]		Loss: 0.2563
2019-10-28 15:32:43,400 Training Epoch [10/40] Iter[190/312]		Loss: 0.2561
2019-10-28 15:32:43,479 Training Epoch [10/40] Iter[191/312]		Loss: 0.2558
2019-10-28 15:32:43,559 Training Epoch [10/40] Iter[192/312]		Loss: 0.2555
2019-10-28 15:32:43,639 Training Epoch [10/40] Iter[193/312]		Loss: 0.2557
2019-10-28 15:32:43,717 Training Epoch [10/40] Iter[194/312]		Loss: 0.2555
2019-10-28 15:32:43,797 Training Epoch [10/40] Iter[195/312]		Loss: 0.2556
2019-10-28 15:32:43,876 Training Epoch [10/40] Iter[196/312]		Loss: 0.2556
2019-10-28 15:32:43,955 Training Epoch [10/40] Iter[197/312]		Loss: 0.2554
2019-10-28 15:32:44,035 Training Epoch [10/40] Iter[198/312]		Loss: 0.2553
2019-10-28 15:32:44,114 Training Epoch [10/40] Iter[199/312]		Loss: 0.2551
2019-10-28 15:32:44,193 Training Epoch [10/40] Iter[200/312]		Loss: 0.2546
2019-10-28 15:32:44,273 Training Epoch [10/40] Iter[201/312]		Loss: 0.2546
2019-10-28 15:32:44,352 Training Epoch [10/40] Iter[202/312]		Loss: 0.2544
2019-10-28 15:32:44,431 Training Epoch [10/40] Iter[203/312]		Loss: 0.2546
2019-10-28 15:32:44,510 Training Epoch [10/40] Iter[204/312]		Loss: 0.2542
2019-10-28 15:32:44,589 Training Epoch [10/40] Iter[205/312]		Loss: 0.2546
2019-10-28 15:32:44,668 Training Epoch [10/40] Iter[206/312]		Loss: 0.2545
2019-10-28 15:32:44,747 Training Epoch [10/40] Iter[207/312]		Loss: 0.2545
2019-10-28 15:32:44,826 Training Epoch [10/40] Iter[208/312]		Loss: 0.2546
2019-10-28 15:32:44,905 Training Epoch [10/40] Iter[209/312]		Loss: 0.2547
2019-10-28 15:32:44,984 Training Epoch [10/40] Iter[210/312]		Loss: 0.2546
2019-10-28 15:32:45,063 Training Epoch [10/40] Iter[211/312]		Loss: 0.2549
2019-10-28 15:32:45,143 Training Epoch [10/40] Iter[212/312]		Loss: 0.2547
2019-10-28 15:32:45,223 Training Epoch [10/40] Iter[213/312]		Loss: 0.2547
2019-10-28 15:32:45,302 Training Epoch [10/40] Iter[214/312]		Loss: 0.2546
2019-10-28 15:32:45,381 Training Epoch [10/40] Iter[215/312]		Loss: 0.2546
2019-10-28 15:32:45,461 Training Epoch [10/40] Iter[216/312]		Loss: 0.2549
2019-10-28 15:32:45,540 Training Epoch [10/40] Iter[217/312]		Loss: 0.2548
2019-10-28 15:32:45,619 Training Epoch [10/40] Iter[218/312]		Loss: 0.2551
2019-10-28 15:32:45,698 Training Epoch [10/40] Iter[219/312]		Loss: 0.2553
2019-10-28 15:32:45,778 Training Epoch [10/40] Iter[220/312]		Loss: 0.2553
2019-10-28 15:32:45,857 Training Epoch [10/40] Iter[221/312]		Loss: 0.2547
2019-10-28 15:32:45,936 Training Epoch [10/40] Iter[222/312]		Loss: 0.2547
2019-10-28 15:32:46,015 Training Epoch [10/40] Iter[223/312]		Loss: 0.2550
2019-10-28 15:32:46,094 Training Epoch [10/40] Iter[224/312]		Loss: 0.2549
2019-10-28 15:32:46,174 Training Epoch [10/40] Iter[225/312]		Loss: 0.2548
2019-10-28 15:32:46,253 Training Epoch [10/40] Iter[226/312]		Loss: 0.2543
2019-10-28 15:32:46,333 Training Epoch [10/40] Iter[227/312]		Loss: 0.2542
2019-10-28 15:32:46,412 Training Epoch [10/40] Iter[228/312]		Loss: 0.2538
2019-10-28 15:32:46,491 Training Epoch [10/40] Iter[229/312]		Loss: 0.2538
2019-10-28 15:32:46,571 Training Epoch [10/40] Iter[230/312]		Loss: 0.2537
2019-10-28 15:32:46,650 Training Epoch [10/40] Iter[231/312]		Loss: 0.2537
2019-10-28 15:32:46,730 Training Epoch [10/40] Iter[232/312]		Loss: 0.2535
2019-10-28 15:32:46,809 Training Epoch [10/40] Iter[233/312]		Loss: 0.2537
2019-10-28 15:32:46,889 Training Epoch [10/40] Iter[234/312]		Loss: 0.2538
2019-10-28 15:32:46,968 Training Epoch [10/40] Iter[235/312]		Loss: 0.2541
2019-10-28 15:32:47,047 Training Epoch [10/40] Iter[236/312]		Loss: 0.2541
2019-10-28 15:32:47,127 Training Epoch [10/40] Iter[237/312]		Loss: 0.2543
2019-10-28 15:32:47,207 Training Epoch [10/40] Iter[238/312]		Loss: 0.2546
2019-10-28 15:32:47,286 Training Epoch [10/40] Iter[239/312]		Loss: 0.2543
2019-10-28 15:32:47,365 Training Epoch [10/40] Iter[240/312]		Loss: 0.2544
2019-10-28 15:32:47,445 Training Epoch [10/40] Iter[241/312]		Loss: 0.2545
2019-10-28 15:32:47,524 Training Epoch [10/40] Iter[242/312]		Loss: 0.2543
2019-10-28 15:32:47,604 Training Epoch [10/40] Iter[243/312]		Loss: 0.2543
2019-10-28 15:32:47,683 Training Epoch [10/40] Iter[244/312]		Loss: 0.2546
2019-10-28 15:32:47,763 Training Epoch [10/40] Iter[245/312]		Loss: 0.2547
2019-10-28 15:32:47,842 Training Epoch [10/40] Iter[246/312]		Loss: 0.2549
2019-10-28 15:32:47,921 Training Epoch [10/40] Iter[247/312]		Loss: 0.2548
2019-10-28 15:32:48,000 Training Epoch [10/40] Iter[248/312]		Loss: 0.2545
2019-10-28 15:32:48,080 Training Epoch [10/40] Iter[249/312]		Loss: 0.2545
2019-10-28 15:32:48,159 Training Epoch [10/40] Iter[250/312]		Loss: 0.2544
2019-10-28 15:32:48,238 Training Epoch [10/40] Iter[251/312]		Loss: 0.2543
2019-10-28 15:32:48,317 Training Epoch [10/40] Iter[252/312]		Loss: 0.2539
2019-10-28 15:32:48,397 Training Epoch [10/40] Iter[253/312]		Loss: 0.2543
2019-10-28 15:32:48,476 Training Epoch [10/40] Iter[254/312]		Loss: 0.2541
2019-10-28 15:32:48,556 Training Epoch [10/40] Iter[255/312]		Loss: 0.2541
2019-10-28 15:32:48,635 Training Epoch [10/40] Iter[256/312]		Loss: 0.2540
2019-10-28 15:32:48,714 Training Epoch [10/40] Iter[257/312]		Loss: 0.2537
2019-10-28 15:32:48,793 Training Epoch [10/40] Iter[258/312]		Loss: 0.2535
2019-10-28 15:32:48,872 Training Epoch [10/40] Iter[259/312]		Loss: 0.2533
2019-10-28 15:32:48,951 Training Epoch [10/40] Iter[260/312]		Loss: 0.2530
2019-10-28 15:32:49,030 Training Epoch [10/40] Iter[261/312]		Loss: 0.2532
2019-10-28 15:32:49,109 Training Epoch [10/40] Iter[262/312]		Loss: 0.2529
2019-10-28 15:32:49,188 Training Epoch [10/40] Iter[263/312]		Loss: 0.2530
2019-10-28 15:32:49,268 Training Epoch [10/40] Iter[264/312]		Loss: 0.2530
2019-10-28 15:32:49,347 Training Epoch [10/40] Iter[265/312]		Loss: 0.2531
2019-10-28 15:32:49,427 Training Epoch [10/40] Iter[266/312]		Loss: 0.2533
2019-10-28 15:32:49,506 Training Epoch [10/40] Iter[267/312]		Loss: 0.2532
2019-10-28 15:32:49,585 Training Epoch [10/40] Iter[268/312]		Loss: 0.2530
2019-10-28 15:32:49,664 Training Epoch [10/40] Iter[269/312]		Loss: 0.2531
2019-10-28 15:32:49,743 Training Epoch [10/40] Iter[270/312]		Loss: 0.2530
2019-10-28 15:32:49,822 Training Epoch [10/40] Iter[271/312]		Loss: 0.2531
2019-10-28 15:32:49,901 Training Epoch [10/40] Iter[272/312]		Loss: 0.2531
2019-10-28 15:32:49,980 Training Epoch [10/40] Iter[273/312]		Loss: 0.2535
2019-10-28 15:32:50,059 Training Epoch [10/40] Iter[274/312]		Loss: 0.2532
2019-10-28 15:32:50,138 Training Epoch [10/40] Iter[275/312]		Loss: 0.2530
2019-10-28 15:32:50,218 Training Epoch [10/40] Iter[276/312]		Loss: 0.2529
2019-10-28 15:32:50,297 Training Epoch [10/40] Iter[277/312]		Loss: 0.2527
2019-10-28 15:32:50,376 Training Epoch [10/40] Iter[278/312]		Loss: 0.2526
2019-10-28 15:32:50,455 Training Epoch [10/40] Iter[279/312]		Loss: 0.2525
2019-10-28 15:32:50,534 Training Epoch [10/40] Iter[280/312]		Loss: 0.2525
2019-10-28 15:32:50,613 Training Epoch [10/40] Iter[281/312]		Loss: 0.2523
2019-10-28 15:32:50,692 Training Epoch [10/40] Iter[282/312]		Loss: 0.2521
2019-10-28 15:32:50,771 Training Epoch [10/40] Iter[283/312]		Loss: 0.2517
2019-10-28 15:32:50,850 Training Epoch [10/40] Iter[284/312]		Loss: 0.2516
2019-10-28 15:32:50,930 Training Epoch [10/40] Iter[285/312]		Loss: 0.2519
2019-10-28 15:32:51,009 Training Epoch [10/40] Iter[286/312]		Loss: 0.2518
2019-10-28 15:32:51,088 Training Epoch [10/40] Iter[287/312]		Loss: 0.2516
2019-10-28 15:32:51,167 Training Epoch [10/40] Iter[288/312]		Loss: 0.2518
2019-10-28 15:32:51,246 Training Epoch [10/40] Iter[289/312]		Loss: 0.2513
2019-10-28 15:32:51,325 Training Epoch [10/40] Iter[290/312]		Loss: 0.2516
2019-10-28 15:32:51,405 Training Epoch [10/40] Iter[291/312]		Loss: 0.2519
2019-10-28 15:32:51,484 Training Epoch [10/40] Iter[292/312]		Loss: 0.2519
2019-10-28 15:32:51,563 Training Epoch [10/40] Iter[293/312]		Loss: 0.2519
2019-10-28 15:32:51,642 Training Epoch [10/40] Iter[294/312]		Loss: 0.2518
2019-10-28 15:32:51,722 Training Epoch [10/40] Iter[295/312]		Loss: 0.2526
2019-10-28 15:32:51,801 Training Epoch [10/40] Iter[296/312]		Loss: 0.2525
2019-10-28 15:32:51,880 Training Epoch [10/40] Iter[297/312]		Loss: 0.2524
2019-10-28 15:32:51,958 Training Epoch [10/40] Iter[298/312]		Loss: 0.2524
2019-10-28 15:32:52,037 Training Epoch [10/40] Iter[299/312]		Loss: 0.2526
2019-10-28 15:32:52,116 Training Epoch [10/40] Iter[300/312]		Loss: 0.2525
2019-10-28 15:32:52,196 Training Epoch [10/40] Iter[301/312]		Loss: 0.2522
2019-10-28 15:32:52,280 Training Epoch [10/40] Iter[302/312]		Loss: 0.2524
2019-10-28 15:32:52,359 Training Epoch [10/40] Iter[303/312]		Loss: 0.2522
2019-10-28 15:32:52,438 Training Epoch [10/40] Iter[304/312]		Loss: 0.2522
2019-10-28 15:32:52,516 Training Epoch [10/40] Iter[305/312]		Loss: 0.2520
2019-10-28 15:32:52,594 Training Epoch [10/40] Iter[306/312]		Loss: 0.2519
2019-10-28 15:32:52,673 Training Epoch [10/40] Iter[307/312]		Loss: 0.2516
2019-10-28 15:32:52,751 Training Epoch [10/40] Iter[308/312]		Loss: 0.2514
2019-10-28 15:32:52,829 Training Epoch [10/40] Iter[309/312]		Loss: 0.2514
2019-10-28 15:32:52,907 Training Epoch [10/40] Iter[310/312]		Loss: 0.2514
2019-10-28 15:32:52,985 Training Epoch [10/40] Iter[311/312]		Loss: 0.2514
2019-10-28 15:32:53,023 Training Epoch [10/40] Iter[312/312]		Loss: 0.2513
2019-10-28 15:32:53,446 Testing Epoch [10/40] Iter[0/62]		Loss: 0.2629
2019-10-28 15:32:53,475 Testing Epoch [10/40] Iter[1/62]		Loss: 0.2610
2019-10-28 15:32:53,497 Testing Epoch [10/40] Iter[2/62]		Loss: 0.2330
2019-10-28 15:32:53,527 Testing Epoch [10/40] Iter[3/62]		Loss: 0.2401
2019-10-28 15:32:53,554 Testing Epoch [10/40] Iter[4/62]		Loss: 0.2277
2019-10-28 15:32:53,572 Testing Epoch [10/40] Iter[5/62]		Loss: 0.2163
2019-10-28 15:32:53,601 Testing Epoch [10/40] Iter[6/62]		Loss: 0.2151
2019-10-28 15:32:53,634 Testing Epoch [10/40] Iter[7/62]		Loss: 0.2191
2019-10-28 15:32:53,651 Testing Epoch [10/40] Iter[8/62]		Loss: 0.2273
2019-10-28 15:32:53,677 Testing Epoch [10/40] Iter[9/62]		Loss: 0.2268
2019-10-28 15:32:53,695 Testing Epoch [10/40] Iter[10/62]		Loss: 0.2239
2019-10-28 15:32:53,713 Testing Epoch [10/40] Iter[11/62]		Loss: 0.2247
2019-10-28 15:32:53,750 Testing Epoch [10/40] Iter[12/62]		Loss: 0.2266
2019-10-28 15:32:53,766 Testing Epoch [10/40] Iter[13/62]		Loss: 0.2293
2019-10-28 15:32:53,784 Testing Epoch [10/40] Iter[14/62]		Loss: 0.2452
2019-10-28 15:32:53,810 Testing Epoch [10/40] Iter[15/62]		Loss: 0.2462
2019-10-28 15:32:53,831 Testing Epoch [10/40] Iter[16/62]		Loss: 0.2434
2019-10-28 15:32:53,857 Testing Epoch [10/40] Iter[17/62]		Loss: 0.2407
2019-10-28 15:32:53,875 Testing Epoch [10/40] Iter[18/62]		Loss: 0.2369
2019-10-28 15:32:53,894 Testing Epoch [10/40] Iter[19/62]		Loss: 0.2359
2019-10-28 15:32:53,920 Testing Epoch [10/40] Iter[20/62]		Loss: 0.2379
2019-10-28 15:32:53,946 Testing Epoch [10/40] Iter[21/62]		Loss: 0.2389
2019-10-28 15:32:53,965 Testing Epoch [10/40] Iter[22/62]		Loss: 0.2414
2019-10-28 15:32:53,983 Testing Epoch [10/40] Iter[23/62]		Loss: 0.2409
2019-10-28 15:32:54,014 Testing Epoch [10/40] Iter[24/62]		Loss: 0.2462
2019-10-28 15:32:54,031 Testing Epoch [10/40] Iter[25/62]		Loss: 0.2440
2019-10-28 15:32:54,052 Testing Epoch [10/40] Iter[26/62]		Loss: 0.2419
2019-10-28 15:32:54,082 Testing Epoch [10/40] Iter[27/62]		Loss: 0.2455
2019-10-28 15:32:54,099 Testing Epoch [10/40] Iter[28/62]		Loss: 0.2472
2019-10-28 15:32:54,118 Testing Epoch [10/40] Iter[29/62]		Loss: 0.2464
2019-10-28 15:32:54,135 Testing Epoch [10/40] Iter[30/62]		Loss: 0.2477
2019-10-28 15:32:54,166 Testing Epoch [10/40] Iter[31/62]		Loss: 0.2476
2019-10-28 15:32:54,184 Testing Epoch [10/40] Iter[32/62]		Loss: 0.2497
2019-10-28 15:32:54,202 Testing Epoch [10/40] Iter[33/62]		Loss: 0.2481
2019-10-28 15:32:54,230 Testing Epoch [10/40] Iter[34/62]		Loss: 0.2495
2019-10-28 15:32:54,248 Testing Epoch [10/40] Iter[35/62]		Loss: 0.2498
2019-10-28 15:32:54,266 Testing Epoch [10/40] Iter[36/62]		Loss: 0.2478
2019-10-28 15:32:54,283 Testing Epoch [10/40] Iter[37/62]		Loss: 0.2480
2019-10-28 15:32:54,314 Testing Epoch [10/40] Iter[38/62]		Loss: 0.2478
2019-10-28 15:32:54,334 Testing Epoch [10/40] Iter[39/62]		Loss: 0.2488
2019-10-28 15:32:54,353 Testing Epoch [10/40] Iter[40/62]		Loss: 0.2508
2019-10-28 15:32:54,370 Testing Epoch [10/40] Iter[41/62]		Loss: 0.2523
2019-10-28 15:32:54,406 Testing Epoch [10/40] Iter[42/62]		Loss: 0.2503
2019-10-28 15:32:54,424 Testing Epoch [10/40] Iter[43/62]		Loss: 0.2495
2019-10-28 15:32:54,449 Testing Epoch [10/40] Iter[44/62]		Loss: 0.2483
2019-10-28 15:32:54,470 Testing Epoch [10/40] Iter[45/62]		Loss: 0.2486
2019-10-28 15:32:54,494 Testing Epoch [10/40] Iter[46/62]		Loss: 0.2490
2019-10-28 15:32:54,516 Testing Epoch [10/40] Iter[47/62]		Loss: 0.2543
2019-10-28 15:32:54,541 Testing Epoch [10/40] Iter[48/62]		Loss: 0.2529
2019-10-28 15:32:54,558 Testing Epoch [10/40] Iter[49/62]		Loss: 0.2560
2019-10-28 15:32:54,585 Testing Epoch [10/40] Iter[50/62]		Loss: 0.2557
2019-10-28 15:32:54,603 Testing Epoch [10/40] Iter[51/62]		Loss: 0.2559
2019-10-28 15:32:54,630 Testing Epoch [10/40] Iter[52/62]		Loss: 0.2548
2019-10-28 15:32:54,656 Testing Epoch [10/40] Iter[53/62]		Loss: 0.2558
2019-10-28 15:32:54,681 Testing Epoch [10/40] Iter[54/62]		Loss: 0.2547
2019-10-28 15:32:54,697 Testing Epoch [10/40] Iter[55/62]		Loss: 0.2547
2019-10-28 15:32:54,714 Testing Epoch [10/40] Iter[56/62]		Loss: 0.2551
2019-10-28 15:32:54,730 Testing Epoch [10/40] Iter[57/62]		Loss: 0.2560
2019-10-28 15:32:54,747 Testing Epoch [10/40] Iter[58/62]		Loss: 0.2546
2019-10-28 15:32:54,764 Testing Epoch [10/40] Iter[59/62]		Loss: 0.2552
2019-10-28 15:32:54,780 Testing Epoch [10/40] Iter[60/62]		Loss: 0.2543
2019-10-28 15:32:54,797 Testing Epoch [10/40] Iter[61/62]		Loss: 0.2548
2019-10-28 15:32:54,806 Testing Epoch [10/40] Iter[62/62]		Loss: 0.2572
2019-10-28 15:32:54,878 Saving the Model
2019-10-28 15:32:55,307 Training Epoch [11/40] Iter[0/312]		Loss: 0.1682
2019-10-28 15:32:55,386 Training Epoch [11/40] Iter[1/312]		Loss: 0.2429
2019-10-28 15:32:55,465 Training Epoch [11/40] Iter[2/312]		Loss: 0.2545
2019-10-28 15:32:55,545 Training Epoch [11/40] Iter[3/312]		Loss: 0.2282
2019-10-28 15:32:55,625 Training Epoch [11/40] Iter[4/312]		Loss: 0.2283
2019-10-28 15:32:55,703 Training Epoch [11/40] Iter[5/312]		Loss: 0.2355
2019-10-28 15:32:55,782 Training Epoch [11/40] Iter[6/312]		Loss: 0.2489
2019-10-28 15:32:55,860 Training Epoch [11/40] Iter[7/312]		Loss: 0.2583
2019-10-28 15:32:55,939 Training Epoch [11/40] Iter[8/312]		Loss: 0.2447
2019-10-28 15:32:56,018 Training Epoch [11/40] Iter[9/312]		Loss: 0.2345
2019-10-28 15:32:56,097 Training Epoch [11/40] Iter[10/312]		Loss: 0.2304
2019-10-28 15:32:56,176 Training Epoch [11/40] Iter[11/312]		Loss: 0.2217
2019-10-28 15:32:56,255 Training Epoch [11/40] Iter[12/312]		Loss: 0.2145
2019-10-28 15:32:56,334 Training Epoch [11/40] Iter[13/312]		Loss: 0.2139
2019-10-28 15:32:56,414 Training Epoch [11/40] Iter[14/312]		Loss: 0.2118
2019-10-28 15:32:56,493 Training Epoch [11/40] Iter[15/312]		Loss: 0.2138
2019-10-28 15:32:56,572 Training Epoch [11/40] Iter[16/312]		Loss: 0.2124
2019-10-28 15:32:56,651 Training Epoch [11/40] Iter[17/312]		Loss: 0.2119
2019-10-28 15:32:56,730 Training Epoch [11/40] Iter[18/312]		Loss: 0.2090
2019-10-28 15:32:56,810 Training Epoch [11/40] Iter[19/312]		Loss: 0.2078
2019-10-28 15:32:56,889 Training Epoch [11/40] Iter[20/312]		Loss: 0.2063
2019-10-28 15:32:56,968 Training Epoch [11/40] Iter[21/312]		Loss: 0.2045
2019-10-28 15:32:57,047 Training Epoch [11/40] Iter[22/312]		Loss: 0.2041
2019-10-28 15:32:57,126 Training Epoch [11/40] Iter[23/312]		Loss: 0.2024
2019-10-28 15:32:57,206 Training Epoch [11/40] Iter[24/312]		Loss: 0.2011
2019-10-28 15:32:57,285 Training Epoch [11/40] Iter[25/312]		Loss: 0.2015
2019-10-28 15:32:57,364 Training Epoch [11/40] Iter[26/312]		Loss: 0.1999
2019-10-28 15:32:57,443 Training Epoch [11/40] Iter[27/312]		Loss: 0.1969
2019-10-28 15:32:57,522 Training Epoch [11/40] Iter[28/312]		Loss: 0.1954
2019-10-28 15:32:57,602 Training Epoch [11/40] Iter[29/312]		Loss: 0.1957
2019-10-28 15:32:57,681 Training Epoch [11/40] Iter[30/312]		Loss: 0.1932
2019-10-28 15:32:57,760 Training Epoch [11/40] Iter[31/312]		Loss: 0.1914
2019-10-28 15:32:57,839 Training Epoch [11/40] Iter[32/312]		Loss: 0.1944
2019-10-28 15:32:57,918 Training Epoch [11/40] Iter[33/312]		Loss: 0.1942
2019-10-28 15:32:57,997 Training Epoch [11/40] Iter[34/312]		Loss: 0.1946
2019-10-28 15:32:58,076 Training Epoch [11/40] Iter[35/312]		Loss: 0.1951
2019-10-28 15:32:58,155 Training Epoch [11/40] Iter[36/312]		Loss: 0.1967
2019-10-28 15:32:58,234 Training Epoch [11/40] Iter[37/312]		Loss: 0.1971
2019-10-28 15:32:58,313 Training Epoch [11/40] Iter[38/312]		Loss: 0.1987
2019-10-28 15:32:58,393 Training Epoch [11/40] Iter[39/312]		Loss: 0.1975
2019-10-28 15:32:58,472 Training Epoch [11/40] Iter[40/312]		Loss: 0.1994
2019-10-28 15:32:58,551 Training Epoch [11/40] Iter[41/312]		Loss: 0.1975
2019-10-28 15:32:58,630 Training Epoch [11/40] Iter[42/312]		Loss: 0.1968
2019-10-28 15:32:58,710 Training Epoch [11/40] Iter[43/312]		Loss: 0.1969
2019-10-28 15:32:58,789 Training Epoch [11/40] Iter[44/312]		Loss: 0.1972
2019-10-28 15:32:58,868 Training Epoch [11/40] Iter[45/312]		Loss: 0.1971
2019-10-28 15:32:58,947 Training Epoch [11/40] Iter[46/312]		Loss: 0.1961
2019-10-28 15:32:59,026 Training Epoch [11/40] Iter[47/312]		Loss: 0.1948
2019-10-28 15:32:59,105 Training Epoch [11/40] Iter[48/312]		Loss: 0.1934
2019-10-28 15:32:59,184 Training Epoch [11/40] Iter[49/312]		Loss: 0.1922
2019-10-28 15:32:59,263 Training Epoch [11/40] Iter[50/312]		Loss: 0.1929
2019-10-28 15:32:59,342 Training Epoch [11/40] Iter[51/312]		Loss: 0.1923
2019-10-28 15:32:59,421 Training Epoch [11/40] Iter[52/312]		Loss: 0.1913
2019-10-28 15:32:59,501 Training Epoch [11/40] Iter[53/312]		Loss: 0.1907
2019-10-28 15:32:59,580 Training Epoch [11/40] Iter[54/312]		Loss: 0.1899
2019-10-28 15:32:59,659 Training Epoch [11/40] Iter[55/312]		Loss: 0.1906
2019-10-28 15:32:59,738 Training Epoch [11/40] Iter[56/312]		Loss: 0.1918
2019-10-28 15:32:59,817 Training Epoch [11/40] Iter[57/312]		Loss: 0.1923
2019-10-28 15:32:59,896 Training Epoch [11/40] Iter[58/312]		Loss: 0.1940
2019-10-28 15:32:59,975 Training Epoch [11/40] Iter[59/312]		Loss: 0.1933
2019-10-28 15:33:00,054 Training Epoch [11/40] Iter[60/312]		Loss: 0.1924
2019-10-28 15:33:00,134 Training Epoch [11/40] Iter[61/312]		Loss: 0.1926
2019-10-28 15:33:00,213 Training Epoch [11/40] Iter[62/312]		Loss: 0.1941
2019-10-28 15:33:00,292 Training Epoch [11/40] Iter[63/312]		Loss: 0.1935
2019-10-28 15:33:00,372 Training Epoch [11/40] Iter[64/312]		Loss: 0.1932
2019-10-28 15:33:00,450 Training Epoch [11/40] Iter[65/312]		Loss: 0.1924
2019-10-28 15:33:00,529 Training Epoch [11/40] Iter[66/312]		Loss: 0.1920
2019-10-28 15:33:00,609 Training Epoch [11/40] Iter[67/312]		Loss: 0.1926
2019-10-28 15:33:00,688 Training Epoch [11/40] Iter[68/312]		Loss: 0.1922
2019-10-28 15:33:00,766 Training Epoch [11/40] Iter[69/312]		Loss: 0.1928
2019-10-28 15:33:00,846 Training Epoch [11/40] Iter[70/312]		Loss: 0.1934
2019-10-28 15:33:00,924 Training Epoch [11/40] Iter[71/312]		Loss: 0.1925
2019-10-28 15:33:01,003 Training Epoch [11/40] Iter[72/312]		Loss: 0.1928
2019-10-28 15:33:01,083 Training Epoch [11/40] Iter[73/312]		Loss: 0.1918
2019-10-28 15:33:01,162 Training Epoch [11/40] Iter[74/312]		Loss: 0.1914
2019-10-28 15:33:01,241 Training Epoch [11/40] Iter[75/312]		Loss: 0.1907
2019-10-28 15:33:01,320 Training Epoch [11/40] Iter[76/312]		Loss: 0.1909
2019-10-28 15:33:01,399 Training Epoch [11/40] Iter[77/312]		Loss: 0.1916
2019-10-28 15:33:01,479 Training Epoch [11/40] Iter[78/312]		Loss: 0.1925
2019-10-28 15:33:01,558 Training Epoch [11/40] Iter[79/312]		Loss: 0.1920
2019-10-28 15:33:01,637 Training Epoch [11/40] Iter[80/312]		Loss: 0.1917
2019-10-28 15:33:01,717 Training Epoch [11/40] Iter[81/312]		Loss: 0.1917
2019-10-28 15:33:01,796 Training Epoch [11/40] Iter[82/312]		Loss: 0.1918
2019-10-28 15:33:01,875 Training Epoch [11/40] Iter[83/312]		Loss: 0.1917
2019-10-28 15:33:01,954 Training Epoch [11/40] Iter[84/312]		Loss: 0.1916
2019-10-28 15:33:02,034 Training Epoch [11/40] Iter[85/312]		Loss: 0.1914
2019-10-28 15:33:02,113 Training Epoch [11/40] Iter[86/312]		Loss: 0.1908
2019-10-28 15:33:02,192 Training Epoch [11/40] Iter[87/312]		Loss: 0.1905
2019-10-28 15:33:02,271 Training Epoch [11/40] Iter[88/312]		Loss: 0.1911
2019-10-28 15:33:02,351 Training Epoch [11/40] Iter[89/312]		Loss: 0.1904
2019-10-28 15:33:02,430 Training Epoch [11/40] Iter[90/312]		Loss: 0.1900
2019-10-28 15:33:02,510 Training Epoch [11/40] Iter[91/312]		Loss: 0.1897
2019-10-28 15:33:02,589 Training Epoch [11/40] Iter[92/312]		Loss: 0.1892
2019-10-28 15:33:02,668 Training Epoch [11/40] Iter[93/312]		Loss: 0.1884
2019-10-28 15:33:02,747 Training Epoch [11/40] Iter[94/312]		Loss: 0.1883
2019-10-28 15:33:02,826 Training Epoch [11/40] Iter[95/312]		Loss: 0.1881
2019-10-28 15:33:02,905 Training Epoch [11/40] Iter[96/312]		Loss: 0.1881
2019-10-28 15:33:02,984 Training Epoch [11/40] Iter[97/312]		Loss: 0.1876
2019-10-28 15:33:03,064 Training Epoch [11/40] Iter[98/312]		Loss: 0.1869
2019-10-28 15:33:03,143 Training Epoch [11/40] Iter[99/312]		Loss: 0.1871
2019-10-28 15:33:03,223 Training Epoch [11/40] Iter[100/312]		Loss: 0.1871
2019-10-28 15:33:03,302 Training Epoch [11/40] Iter[101/312]		Loss: 0.1866
2019-10-28 15:33:03,381 Training Epoch [11/40] Iter[102/312]		Loss: 0.1867
2019-10-28 15:33:03,460 Training Epoch [11/40] Iter[103/312]		Loss: 0.1864
2019-10-28 15:33:03,540 Training Epoch [11/40] Iter[104/312]		Loss: 0.1857
2019-10-28 15:33:03,619 Training Epoch [11/40] Iter[105/312]		Loss: 0.1863
2019-10-28 15:33:03,698 Training Epoch [11/40] Iter[106/312]		Loss: 0.1854
2019-10-28 15:33:03,777 Training Epoch [11/40] Iter[107/312]		Loss: 0.1856
2019-10-28 15:33:03,856 Training Epoch [11/40] Iter[108/312]		Loss: 0.1859
2019-10-28 15:33:03,935 Training Epoch [11/40] Iter[109/312]		Loss: 0.1862
2019-10-28 15:33:04,014 Training Epoch [11/40] Iter[110/312]		Loss: 0.1857
2019-10-28 15:33:04,093 Training Epoch [11/40] Iter[111/312]		Loss: 0.1852
2019-10-28 15:33:04,172 Training Epoch [11/40] Iter[112/312]		Loss: 0.1854
2019-10-28 15:33:04,251 Training Epoch [11/40] Iter[113/312]		Loss: 0.1863
2019-10-28 15:33:04,330 Training Epoch [11/40] Iter[114/312]		Loss: 0.1863
2019-10-28 15:33:04,409 Training Epoch [11/40] Iter[115/312]		Loss: 0.1867
2019-10-28 15:33:04,488 Training Epoch [11/40] Iter[116/312]		Loss: 0.1863
2019-10-28 15:33:04,567 Training Epoch [11/40] Iter[117/312]		Loss: 0.1859
2019-10-28 15:33:04,646 Training Epoch [11/40] Iter[118/312]		Loss: 0.1851
2019-10-28 15:33:04,725 Training Epoch [11/40] Iter[119/312]		Loss: 0.1847
2019-10-28 15:33:04,803 Training Epoch [11/40] Iter[120/312]		Loss: 0.1844
2019-10-28 15:33:04,883 Training Epoch [11/40] Iter[121/312]		Loss: 0.1840
2019-10-28 15:33:04,962 Training Epoch [11/40] Iter[122/312]		Loss: 0.1837
2019-10-28 15:33:05,041 Training Epoch [11/40] Iter[123/312]		Loss: 0.1851
2019-10-28 15:33:05,120 Training Epoch [11/40] Iter[124/312]		Loss: 0.1859
2019-10-28 15:33:05,199 Training Epoch [11/40] Iter[125/312]		Loss: 0.1860
2019-10-28 15:33:05,278 Training Epoch [11/40] Iter[126/312]		Loss: 0.1853
2019-10-28 15:33:05,357 Training Epoch [11/40] Iter[127/312]		Loss: 0.1853
2019-10-28 15:33:05,436 Training Epoch [11/40] Iter[128/312]		Loss: 0.1850
2019-10-28 15:33:05,515 Training Epoch [11/40] Iter[129/312]		Loss: 0.1849
2019-10-28 15:33:05,594 Training Epoch [11/40] Iter[130/312]		Loss: 0.1846
2019-10-28 15:33:05,673 Training Epoch [11/40] Iter[131/312]		Loss: 0.1847
2019-10-28 15:33:05,753 Training Epoch [11/40] Iter[132/312]		Loss: 0.1846
2019-10-28 15:33:05,832 Training Epoch [11/40] Iter[133/312]		Loss: 0.1841
2019-10-28 15:33:05,911 Training Epoch [11/40] Iter[134/312]		Loss: 0.1840
2019-10-28 15:33:05,990 Training Epoch [11/40] Iter[135/312]		Loss: 0.1841
2019-10-28 15:33:06,069 Training Epoch [11/40] Iter[136/312]		Loss: 0.1835
2019-10-28 15:33:06,148 Training Epoch [11/40] Iter[137/312]		Loss: 0.1831
2019-10-28 15:33:06,227 Training Epoch [11/40] Iter[138/312]		Loss: 0.1835
2019-10-28 15:33:06,306 Training Epoch [11/40] Iter[139/312]		Loss: 0.1832
2019-10-28 15:33:06,385 Training Epoch [11/40] Iter[140/312]		Loss: 0.1833
2019-10-28 15:33:06,464 Training Epoch [11/40] Iter[141/312]		Loss: 0.1834
2019-10-28 15:33:06,543 Training Epoch [11/40] Iter[142/312]		Loss: 0.1832
2019-10-28 15:33:06,622 Training Epoch [11/40] Iter[143/312]		Loss: 0.1829
2019-10-28 15:33:06,702 Training Epoch [11/40] Iter[144/312]		Loss: 0.1830
2019-10-28 15:33:06,780 Training Epoch [11/40] Iter[145/312]		Loss: 0.1826
2019-10-28 15:33:06,859 Training Epoch [11/40] Iter[146/312]		Loss: 0.1826
2019-10-28 15:33:06,938 Training Epoch [11/40] Iter[147/312]		Loss: 0.1824
2019-10-28 15:33:07,017 Training Epoch [11/40] Iter[148/312]		Loss: 0.1823
2019-10-28 15:33:07,096 Training Epoch [11/40] Iter[149/312]		Loss: 0.1826
2019-10-28 15:33:07,176 Training Epoch [11/40] Iter[150/312]		Loss: 0.1821
2019-10-28 15:33:07,255 Training Epoch [11/40] Iter[151/312]		Loss: 0.1820
2019-10-28 15:33:07,334 Training Epoch [11/40] Iter[152/312]		Loss: 0.1817
2019-10-28 15:33:07,413 Training Epoch [11/40] Iter[153/312]		Loss: 0.1816
2019-10-28 15:33:07,492 Training Epoch [11/40] Iter[154/312]		Loss: 0.1816
2019-10-28 15:33:07,571 Training Epoch [11/40] Iter[155/312]		Loss: 0.1813
2019-10-28 15:33:07,650 Training Epoch [11/40] Iter[156/312]		Loss: 0.1811
2019-10-28 15:33:07,729 Training Epoch [11/40] Iter[157/312]		Loss: 0.1808
2019-10-28 15:33:07,808 Training Epoch [11/40] Iter[158/312]		Loss: 0.1805
2019-10-28 15:33:07,887 Training Epoch [11/40] Iter[159/312]		Loss: 0.1807
2019-10-28 15:33:07,966 Training Epoch [11/40] Iter[160/312]		Loss: 0.1802
2019-10-28 15:33:08,045 Training Epoch [11/40] Iter[161/312]		Loss: 0.1806
2019-10-28 15:33:08,124 Training Epoch [11/40] Iter[162/312]		Loss: 0.1804
2019-10-28 15:33:08,203 Training Epoch [11/40] Iter[163/312]		Loss: 0.1805
2019-10-28 15:33:08,282 Training Epoch [11/40] Iter[164/312]		Loss: 0.1802
2019-10-28 15:33:08,361 Training Epoch [11/40] Iter[165/312]		Loss: 0.1802
2019-10-28 15:33:08,441 Training Epoch [11/40] Iter[166/312]		Loss: 0.1800
2019-10-28 15:33:08,520 Training Epoch [11/40] Iter[167/312]		Loss: 0.1796
2019-10-28 15:33:08,599 Training Epoch [11/40] Iter[168/312]		Loss: 0.1796
2019-10-28 15:33:08,678 Training Epoch [11/40] Iter[169/312]		Loss: 0.1792
2019-10-28 15:33:08,757 Training Epoch [11/40] Iter[170/312]		Loss: 0.1791
2019-10-28 15:33:08,836 Training Epoch [11/40] Iter[171/312]		Loss: 0.1794
2019-10-28 15:33:08,914 Training Epoch [11/40] Iter[172/312]		Loss: 0.1791
2019-10-28 15:33:08,993 Training Epoch [11/40] Iter[173/312]		Loss: 0.1790
2019-10-28 15:33:09,072 Training Epoch [11/40] Iter[174/312]		Loss: 0.1786
2019-10-28 15:33:09,152 Training Epoch [11/40] Iter[175/312]		Loss: 0.1787
2019-10-28 15:33:09,231 Training Epoch [11/40] Iter[176/312]		Loss: 0.1785
2019-10-28 15:33:09,310 Training Epoch [11/40] Iter[177/312]		Loss: 0.1782
2019-10-28 15:33:09,389 Training Epoch [11/40] Iter[178/312]		Loss: 0.1782
2019-10-28 15:33:09,468 Training Epoch [11/40] Iter[179/312]		Loss: 0.1780
2019-10-28 15:33:09,547 Training Epoch [11/40] Iter[180/312]		Loss: 0.1777
2019-10-28 15:33:09,626 Training Epoch [11/40] Iter[181/312]		Loss: 0.1778
2019-10-28 15:33:09,705 Training Epoch [11/40] Iter[182/312]		Loss: 0.1775
2019-10-28 15:33:09,784 Training Epoch [11/40] Iter[183/312]		Loss: 0.1778
2019-10-28 15:33:09,863 Training Epoch [11/40] Iter[184/312]		Loss: 0.1781
2019-10-28 15:33:09,942 Training Epoch [11/40] Iter[185/312]		Loss: 0.1780
2019-10-28 15:33:10,021 Training Epoch [11/40] Iter[186/312]		Loss: 0.1784
2019-10-28 15:33:10,100 Training Epoch [11/40] Iter[187/312]		Loss: 0.1781
2019-10-28 15:33:10,179 Training Epoch [11/40] Iter[188/312]		Loss: 0.1778
2019-10-28 15:33:10,258 Training Epoch [11/40] Iter[189/312]		Loss: 0.1777
2019-10-28 15:33:10,337 Training Epoch [11/40] Iter[190/312]		Loss: 0.1775
2019-10-28 15:33:10,416 Training Epoch [11/40] Iter[191/312]		Loss: 0.1775
2019-10-28 15:33:10,495 Training Epoch [11/40] Iter[192/312]		Loss: 0.1776
2019-10-28 15:33:10,574 Training Epoch [11/40] Iter[193/312]		Loss: 0.1778
2019-10-28 15:33:10,653 Training Epoch [11/40] Iter[194/312]		Loss: 0.1776
2019-10-28 15:33:10,732 Training Epoch [11/40] Iter[195/312]		Loss: 0.1773
2019-10-28 15:33:10,811 Training Epoch [11/40] Iter[196/312]		Loss: 0.1769
2019-10-28 15:33:10,890 Training Epoch [11/40] Iter[197/312]		Loss: 0.1769
2019-10-28 15:33:10,969 Training Epoch [11/40] Iter[198/312]		Loss: 0.1766
2019-10-28 15:33:11,048 Training Epoch [11/40] Iter[199/312]		Loss: 0.1768
2019-10-28 15:33:11,127 Training Epoch [11/40] Iter[200/312]		Loss: 0.1769
2019-10-28 15:33:11,207 Training Epoch [11/40] Iter[201/312]		Loss: 0.1766
2019-10-28 15:33:11,286 Training Epoch [11/40] Iter[202/312]		Loss: 0.1770
2019-10-28 15:33:11,365 Training Epoch [11/40] Iter[203/312]		Loss: 0.1775
2019-10-28 15:33:11,444 Training Epoch [11/40] Iter[204/312]		Loss: 0.1772
2019-10-28 15:33:11,523 Training Epoch [11/40] Iter[205/312]		Loss: 0.1771
2019-10-28 15:33:11,602 Training Epoch [11/40] Iter[206/312]		Loss: 0.1772
2019-10-28 15:33:11,681 Training Epoch [11/40] Iter[207/312]		Loss: 0.1776
2019-10-28 15:33:11,760 Training Epoch [11/40] Iter[208/312]		Loss: 0.1779
2019-10-28 15:33:11,839 Training Epoch [11/40] Iter[209/312]		Loss: 0.1781
2019-10-28 15:33:11,918 Training Epoch [11/40] Iter[210/312]		Loss: 0.1779
2019-10-28 15:33:11,997 Training Epoch [11/40] Iter[211/312]		Loss: 0.1777
2019-10-28 15:33:12,076 Training Epoch [11/40] Iter[212/312]		Loss: 0.1775
2019-10-28 15:33:12,155 Training Epoch [11/40] Iter[213/312]		Loss: 0.1774
2019-10-28 15:33:12,234 Training Epoch [11/40] Iter[214/312]		Loss: 0.1775
2019-10-28 15:33:12,313 Training Epoch [11/40] Iter[215/312]		Loss: 0.1778
2019-10-28 15:33:12,392 Training Epoch [11/40] Iter[216/312]		Loss: 0.1774
2019-10-28 15:33:12,471 Training Epoch [11/40] Iter[217/312]		Loss: 0.1776
2019-10-28 15:33:12,550 Training Epoch [11/40] Iter[218/312]		Loss: 0.1778
2019-10-28 15:33:12,630 Training Epoch [11/40] Iter[219/312]		Loss: 0.1775
2019-10-28 15:33:12,709 Training Epoch [11/40] Iter[220/312]		Loss: 0.1773
2019-10-28 15:33:12,788 Training Epoch [11/40] Iter[221/312]		Loss: 0.1773
2019-10-28 15:33:12,867 Training Epoch [11/40] Iter[222/312]		Loss: 0.1769
2019-10-28 15:33:12,946 Training Epoch [11/40] Iter[223/312]		Loss: 0.1770
2019-10-28 15:33:13,025 Training Epoch [11/40] Iter[224/312]		Loss: 0.1769
2019-10-28 15:33:13,104 Training Epoch [11/40] Iter[225/312]		Loss: 0.1767
2019-10-28 15:33:13,183 Training Epoch [11/40] Iter[226/312]		Loss: 0.1767
2019-10-28 15:33:13,262 Training Epoch [11/40] Iter[227/312]		Loss: 0.1766
2019-10-28 15:33:13,342 Training Epoch [11/40] Iter[228/312]		Loss: 0.1762
2019-10-28 15:33:13,421 Training Epoch [11/40] Iter[229/312]		Loss: 0.1765
2019-10-28 15:33:13,500 Training Epoch [11/40] Iter[230/312]		Loss: 0.1767
2019-10-28 15:33:13,579 Training Epoch [11/40] Iter[231/312]		Loss: 0.1764
2019-10-28 15:33:13,658 Training Epoch [11/40] Iter[232/312]		Loss: 0.1767
2019-10-28 15:33:13,738 Training Epoch [11/40] Iter[233/312]		Loss: 0.1764
2019-10-28 15:33:13,817 Training Epoch [11/40] Iter[234/312]		Loss: 0.1763
2019-10-28 15:33:13,896 Training Epoch [11/40] Iter[235/312]		Loss: 0.1768
2019-10-28 15:33:13,974 Training Epoch [11/40] Iter[236/312]		Loss: 0.1766
2019-10-28 15:33:14,054 Training Epoch [11/40] Iter[237/312]		Loss: 0.1767
2019-10-28 15:33:14,133 Training Epoch [11/40] Iter[238/312]		Loss: 0.1766
2019-10-28 15:33:14,212 Training Epoch [11/40] Iter[239/312]		Loss: 0.1768
2019-10-28 15:33:14,291 Training Epoch [11/40] Iter[240/312]		Loss: 0.1770
2019-10-28 15:33:14,370 Training Epoch [11/40] Iter[241/312]		Loss: 0.1771
2019-10-28 15:33:14,450 Training Epoch [11/40] Iter[242/312]		Loss: 0.1776
2019-10-28 15:33:14,529 Training Epoch [11/40] Iter[243/312]		Loss: 0.1774
2019-10-28 15:33:14,608 Training Epoch [11/40] Iter[244/312]		Loss: 0.1774
2019-10-28 15:33:14,688 Training Epoch [11/40] Iter[245/312]		Loss: 0.1773
2019-10-28 15:33:14,767 Training Epoch [11/40] Iter[246/312]		Loss: 0.1775
2019-10-28 15:33:14,846 Training Epoch [11/40] Iter[247/312]		Loss: 0.1775
2019-10-28 15:33:14,924 Training Epoch [11/40] Iter[248/312]		Loss: 0.1774
2019-10-28 15:33:15,003 Training Epoch [11/40] Iter[249/312]		Loss: 0.1774
2019-10-28 15:33:15,083 Training Epoch [11/40] Iter[250/312]		Loss: 0.1772
2019-10-28 15:33:15,162 Training Epoch [11/40] Iter[251/312]		Loss: 0.1771
2019-10-28 15:33:15,241 Training Epoch [11/40] Iter[252/312]		Loss: 0.1770
2019-10-28 15:33:15,320 Training Epoch [11/40] Iter[253/312]		Loss: 0.1771
2019-10-28 15:33:15,399 Training Epoch [11/40] Iter[254/312]		Loss: 0.1771
2019-10-28 15:33:15,478 Training Epoch [11/40] Iter[255/312]		Loss: 0.1771
2019-10-28 15:33:15,557 Training Epoch [11/40] Iter[256/312]		Loss: 0.1771
2019-10-28 15:33:15,636 Training Epoch [11/40] Iter[257/312]		Loss: 0.1772
2019-10-28 15:33:15,715 Training Epoch [11/40] Iter[258/312]		Loss: 0.1771
2019-10-28 15:33:15,794 Training Epoch [11/40] Iter[259/312]		Loss: 0.1769
2019-10-28 15:33:15,873 Training Epoch [11/40] Iter[260/312]		Loss: 0.1770
2019-10-28 15:33:15,952 Training Epoch [11/40] Iter[261/312]		Loss: 0.1769
2019-10-28 15:33:16,031 Training Epoch [11/40] Iter[262/312]		Loss: 0.1766
2019-10-28 15:33:16,110 Training Epoch [11/40] Iter[263/312]		Loss: 0.1765
2019-10-28 15:33:16,189 Training Epoch [11/40] Iter[264/312]		Loss: 0.1765
2019-10-28 15:33:16,269 Training Epoch [11/40] Iter[265/312]		Loss: 0.1761
2019-10-28 15:33:16,348 Training Epoch [11/40] Iter[266/312]		Loss: 0.1760
2019-10-28 15:33:16,427 Training Epoch [11/40] Iter[267/312]		Loss: 0.1759
2019-10-28 15:33:16,507 Training Epoch [11/40] Iter[268/312]		Loss: 0.1757
2019-10-28 15:33:16,586 Training Epoch [11/40] Iter[269/312]		Loss: 0.1756
2019-10-28 15:33:16,666 Training Epoch [11/40] Iter[270/312]		Loss: 0.1753
2019-10-28 15:33:16,745 Training Epoch [11/40] Iter[271/312]		Loss: 0.1751
2019-10-28 15:33:16,824 Training Epoch [11/40] Iter[272/312]		Loss: 0.1751
2019-10-28 15:33:16,903 Training Epoch [11/40] Iter[273/312]		Loss: 0.1750
2019-10-28 15:33:16,981 Training Epoch [11/40] Iter[274/312]		Loss: 0.1748
2019-10-28 15:33:17,060 Training Epoch [11/40] Iter[275/312]		Loss: 0.1750
2019-10-28 15:33:17,139 Training Epoch [11/40] Iter[276/312]		Loss: 0.1749
2019-10-28 15:33:17,218 Training Epoch [11/40] Iter[277/312]		Loss: 0.1747
2019-10-28 15:33:17,298 Training Epoch [11/40] Iter[278/312]		Loss: 0.1746
2019-10-28 15:33:17,377 Training Epoch [11/40] Iter[279/312]		Loss: 0.1744
2019-10-28 15:33:17,456 Training Epoch [11/40] Iter[280/312]		Loss: 0.1742
2019-10-28 15:33:17,535 Training Epoch [11/40] Iter[281/312]		Loss: 0.1741
2019-10-28 15:33:17,615 Training Epoch [11/40] Iter[282/312]		Loss: 0.1742
2019-10-28 15:33:17,694 Training Epoch [11/40] Iter[283/312]		Loss: 0.1740
2019-10-28 15:33:17,774 Training Epoch [11/40] Iter[284/312]		Loss: 0.1739
2019-10-28 15:33:17,853 Training Epoch [11/40] Iter[285/312]		Loss: 0.1740
2019-10-28 15:33:17,932 Training Epoch [11/40] Iter[286/312]		Loss: 0.1739
2019-10-28 15:33:18,011 Training Epoch [11/40] Iter[287/312]		Loss: 0.1738
2019-10-28 15:33:18,090 Training Epoch [11/40] Iter[288/312]		Loss: 0.1739
2019-10-28 15:33:18,169 Training Epoch [11/40] Iter[289/312]		Loss: 0.1737
2019-10-28 15:33:18,248 Training Epoch [11/40] Iter[290/312]		Loss: 0.1739
2019-10-28 15:33:18,327 Training Epoch [11/40] Iter[291/312]		Loss: 0.1738
2019-10-28 15:33:18,406 Training Epoch [11/40] Iter[292/312]		Loss: 0.1737
2019-10-28 15:33:18,485 Training Epoch [11/40] Iter[293/312]		Loss: 0.1735
2019-10-28 15:33:18,564 Training Epoch [11/40] Iter[294/312]		Loss: 0.1735
2019-10-28 15:33:18,643 Training Epoch [11/40] Iter[295/312]		Loss: 0.1738
2019-10-28 15:33:18,722 Training Epoch [11/40] Iter[296/312]		Loss: 0.1737
2019-10-28 15:33:18,801 Training Epoch [11/40] Iter[297/312]		Loss: 0.1737
2019-10-28 15:33:18,880 Training Epoch [11/40] Iter[298/312]		Loss: 0.1737
2019-10-28 15:33:18,959 Training Epoch [11/40] Iter[299/312]		Loss: 0.1737
2019-10-28 15:33:19,038 Training Epoch [11/40] Iter[300/312]		Loss: 0.1734
2019-10-28 15:33:19,117 Training Epoch [11/40] Iter[301/312]		Loss: 0.1732
2019-10-28 15:33:19,196 Training Epoch [11/40] Iter[302/312]		Loss: 0.1732
2019-10-28 15:33:19,276 Training Epoch [11/40] Iter[303/312]		Loss: 0.1735
2019-10-28 15:33:19,355 Training Epoch [11/40] Iter[304/312]		Loss: 0.1734
2019-10-28 15:33:19,433 Training Epoch [11/40] Iter[305/312]		Loss: 0.1732
2019-10-28 15:33:19,512 Training Epoch [11/40] Iter[306/312]		Loss: 0.1732
2019-10-28 15:33:19,590 Training Epoch [11/40] Iter[307/312]		Loss: 0.1732
2019-10-28 15:33:19,668 Training Epoch [11/40] Iter[308/312]		Loss: 0.1733
2019-10-28 15:33:19,746 Training Epoch [11/40] Iter[309/312]		Loss: 0.1732
2019-10-28 15:33:19,824 Training Epoch [11/40] Iter[310/312]		Loss: 0.1732
2019-10-28 15:33:19,902 Training Epoch [11/40] Iter[311/312]		Loss: 0.1732
2019-10-28 15:33:19,941 Training Epoch [11/40] Iter[312/312]		Loss: 0.1738
2019-10-28 15:33:20,345 Testing Epoch [11/40] Iter[0/62]		Loss: 0.1723
2019-10-28 15:33:20,398 Testing Epoch [11/40] Iter[1/62]		Loss: 0.1757
2019-10-28 15:33:20,426 Testing Epoch [11/40] Iter[2/62]		Loss: 0.1617
2019-10-28 15:33:20,442 Testing Epoch [11/40] Iter[3/62]		Loss: 0.1627
2019-10-28 15:33:20,471 Testing Epoch [11/40] Iter[4/62]		Loss: 0.1698
2019-10-28 15:33:20,496 Testing Epoch [11/40] Iter[5/62]		Loss: 0.1624
2019-10-28 15:33:20,529 Testing Epoch [11/40] Iter[6/62]		Loss: 0.1703
2019-10-28 15:33:20,545 Testing Epoch [11/40] Iter[7/62]		Loss: 0.1691
2019-10-28 15:33:20,562 Testing Epoch [11/40] Iter[8/62]		Loss: 0.1721
2019-10-28 15:33:20,592 Testing Epoch [11/40] Iter[9/62]		Loss: 0.1734
2019-10-28 15:33:20,618 Testing Epoch [11/40] Iter[10/62]		Loss: 0.1756
2019-10-28 15:33:20,641 Testing Epoch [11/40] Iter[11/62]		Loss: 0.1872
2019-10-28 15:33:20,660 Testing Epoch [11/40] Iter[12/62]		Loss: 0.1884
2019-10-28 15:33:20,677 Testing Epoch [11/40] Iter[13/62]		Loss: 0.1903
2019-10-28 15:33:20,709 Testing Epoch [11/40] Iter[14/62]		Loss: 0.2019
2019-10-28 15:33:20,733 Testing Epoch [11/40] Iter[15/62]		Loss: 0.2032
2019-10-28 15:33:20,757 Testing Epoch [11/40] Iter[16/62]		Loss: 0.1991
2019-10-28 15:33:20,781 Testing Epoch [11/40] Iter[17/62]		Loss: 0.1982
2019-10-28 15:33:20,805 Testing Epoch [11/40] Iter[18/62]		Loss: 0.1954
2019-10-28 15:33:20,829 Testing Epoch [11/40] Iter[19/62]		Loss: 0.1925
2019-10-28 15:33:20,853 Testing Epoch [11/40] Iter[20/62]		Loss: 0.1937
2019-10-28 15:33:20,873 Testing Epoch [11/40] Iter[21/62]		Loss: 0.1920
2019-10-28 15:33:20,891 Testing Epoch [11/40] Iter[22/62]		Loss: 0.1920
2019-10-28 15:33:20,909 Testing Epoch [11/40] Iter[23/62]		Loss: 0.1895
2019-10-28 15:33:20,939 Testing Epoch [11/40] Iter[24/62]		Loss: 0.1931
2019-10-28 15:33:20,965 Testing Epoch [11/40] Iter[25/62]		Loss: 0.1916
2019-10-28 15:33:20,993 Testing Epoch [11/40] Iter[26/62]		Loss: 0.1905
2019-10-28 15:33:21,013 Testing Epoch [11/40] Iter[27/62]		Loss: 0.1979
2019-10-28 15:33:21,037 Testing Epoch [11/40] Iter[28/62]		Loss: 0.2016
2019-10-28 15:33:21,062 Testing Epoch [11/40] Iter[29/62]		Loss: 0.2018
2019-10-28 15:33:21,079 Testing Epoch [11/40] Iter[30/62]		Loss: 0.2033
2019-10-28 15:33:21,109 Testing Epoch [11/40] Iter[31/62]		Loss: 0.2012
2019-10-28 15:33:21,127 Testing Epoch [11/40] Iter[32/62]		Loss: 0.2029
2019-10-28 15:33:21,153 Testing Epoch [11/40] Iter[33/62]		Loss: 0.2026
2019-10-28 15:33:21,171 Testing Epoch [11/40] Iter[34/62]		Loss: 0.2045
2019-10-28 15:33:21,189 Testing Epoch [11/40] Iter[35/62]		Loss: 0.2038
2019-10-28 15:33:21,214 Testing Epoch [11/40] Iter[36/62]		Loss: 0.2025
2019-10-28 15:33:21,239 Testing Epoch [11/40] Iter[37/62]		Loss: 0.2013
2019-10-28 15:33:21,257 Testing Epoch [11/40] Iter[38/62]		Loss: 0.2005
2019-10-28 15:33:21,275 Testing Epoch [11/40] Iter[39/62]		Loss: 0.2015
2019-10-28 15:33:21,302 Testing Epoch [11/40] Iter[40/62]		Loss: 0.2032
2019-10-28 15:33:21,326 Testing Epoch [11/40] Iter[41/62]		Loss: 0.2052
2019-10-28 15:33:21,344 Testing Epoch [11/40] Iter[42/62]		Loss: 0.2031
2019-10-28 15:33:21,370 Testing Epoch [11/40] Iter[43/62]		Loss: 0.2021
2019-10-28 15:33:21,388 Testing Epoch [11/40] Iter[44/62]		Loss: 0.1998
2019-10-28 15:33:21,405 Testing Epoch [11/40] Iter[45/62]		Loss: 0.1992
2019-10-28 15:33:21,423 Testing Epoch [11/40] Iter[46/62]		Loss: 0.1989
2019-10-28 15:33:21,450 Testing Epoch [11/40] Iter[47/62]		Loss: 0.2042
2019-10-28 15:33:21,474 Testing Epoch [11/40] Iter[48/62]		Loss: 0.2031
2019-10-28 15:33:21,501 Testing Epoch [11/40] Iter[49/62]		Loss: 0.2051
2019-10-28 15:33:21,524 Testing Epoch [11/40] Iter[50/62]		Loss: 0.2040
2019-10-28 15:33:21,549 Testing Epoch [11/40] Iter[51/62]		Loss: 0.2037
2019-10-28 15:33:21,574 Testing Epoch [11/40] Iter[52/62]		Loss: 0.2020
2019-10-28 15:33:21,601 Testing Epoch [11/40] Iter[53/62]		Loss: 0.2020
2019-10-28 15:33:21,621 Testing Epoch [11/40] Iter[54/62]		Loss: 0.2011
2019-10-28 15:33:21,638 Testing Epoch [11/40] Iter[55/62]		Loss: 0.2007
2019-10-28 15:33:21,654 Testing Epoch [11/40] Iter[56/62]		Loss: 0.2000
2019-10-28 15:33:21,672 Testing Epoch [11/40] Iter[57/62]		Loss: 0.1998
2019-10-28 15:33:21,687 Testing Epoch [11/40] Iter[58/62]		Loss: 0.1994
2019-10-28 15:33:21,704 Testing Epoch [11/40] Iter[59/62]		Loss: 0.2004
2019-10-28 15:33:21,720 Testing Epoch [11/40] Iter[60/62]		Loss: 0.1996
2019-10-28 15:33:21,737 Testing Epoch [11/40] Iter[61/62]		Loss: 0.1995
2019-10-28 15:33:21,747 Testing Epoch [11/40] Iter[62/62]		Loss: 0.1998
2019-10-28 15:33:21,817 Saving the Model
2019-10-28 15:33:22,245 Training Epoch [12/40] Iter[0/312]		Loss: 0.2834
2019-10-28 15:33:22,327 Training Epoch [12/40] Iter[1/312]		Loss: 0.2065
2019-10-28 15:33:22,406 Training Epoch [12/40] Iter[2/312]		Loss: 0.1997
2019-10-28 15:33:22,487 Training Epoch [12/40] Iter[3/312]		Loss: 0.1957
2019-10-28 15:33:22,564 Training Epoch [12/40] Iter[4/312]		Loss: 0.1971
2019-10-28 15:33:22,642 Training Epoch [12/40] Iter[5/312]		Loss: 0.1889
2019-10-28 15:33:22,719 Training Epoch [12/40] Iter[6/312]		Loss: 0.1839
2019-10-28 15:33:22,798 Training Epoch [12/40] Iter[7/312]		Loss: 0.1770
2019-10-28 15:33:22,877 Training Epoch [12/40] Iter[8/312]		Loss: 0.1711
2019-10-28 15:33:22,956 Training Epoch [12/40] Iter[9/312]		Loss: 0.1705
2019-10-28 15:33:23,034 Training Epoch [12/40] Iter[10/312]		Loss: 0.1673
2019-10-28 15:33:23,113 Training Epoch [12/40] Iter[11/312]		Loss: 0.1651
2019-10-28 15:33:23,192 Training Epoch [12/40] Iter[12/312]		Loss: 0.1625
2019-10-28 15:33:23,271 Training Epoch [12/40] Iter[13/312]		Loss: 0.1616
2019-10-28 15:33:23,351 Training Epoch [12/40] Iter[14/312]		Loss: 0.1579
2019-10-28 15:33:23,430 Training Epoch [12/40] Iter[15/312]		Loss: 0.1577
2019-10-28 15:33:23,510 Training Epoch [12/40] Iter[16/312]		Loss: 0.1584
2019-10-28 15:33:23,590 Training Epoch [12/40] Iter[17/312]		Loss: 0.1581
2019-10-28 15:33:23,669 Training Epoch [12/40] Iter[18/312]		Loss: 0.1580
2019-10-28 15:33:23,748 Training Epoch [12/40] Iter[19/312]		Loss: 0.1604
2019-10-28 15:33:23,827 Training Epoch [12/40] Iter[20/312]		Loss: 0.1594
2019-10-28 15:33:23,905 Training Epoch [12/40] Iter[21/312]		Loss: 0.1581
2019-10-28 15:33:23,984 Training Epoch [12/40] Iter[22/312]		Loss: 0.1616
2019-10-28 15:33:24,063 Training Epoch [12/40] Iter[23/312]		Loss: 0.1616
2019-10-28 15:33:24,142 Training Epoch [12/40] Iter[24/312]		Loss: 0.1623
2019-10-28 15:33:24,221 Training Epoch [12/40] Iter[25/312]		Loss: 0.1627
2019-10-28 15:33:24,300 Training Epoch [12/40] Iter[26/312]		Loss: 0.1604
2019-10-28 15:33:24,379 Training Epoch [12/40] Iter[27/312]		Loss: 0.1600
2019-10-28 15:33:24,459 Training Epoch [12/40] Iter[28/312]		Loss: 0.1583
2019-10-28 15:33:24,538 Training Epoch [12/40] Iter[29/312]		Loss: 0.1575
2019-10-28 15:33:24,617 Training Epoch [12/40] Iter[30/312]		Loss: 0.1556
2019-10-28 15:33:24,696 Training Epoch [12/40] Iter[31/312]		Loss: 0.1560
2019-10-28 15:33:24,780 Training Epoch [12/40] Iter[32/312]		Loss: 0.1542
2019-10-28 15:33:24,859 Training Epoch [12/40] Iter[33/312]		Loss: 0.1540
2019-10-28 15:33:24,938 Training Epoch [12/40] Iter[34/312]		Loss: 0.1528
2019-10-28 15:33:25,017 Training Epoch [12/40] Iter[35/312]		Loss: 0.1518
2019-10-28 15:33:25,096 Training Epoch [12/40] Iter[36/312]		Loss: 0.1503
2019-10-28 15:33:25,175 Training Epoch [12/40] Iter[37/312]		Loss: 0.1500
2019-10-28 15:33:25,254 Training Epoch [12/40] Iter[38/312]		Loss: 0.1512
2019-10-28 15:33:25,333 Training Epoch [12/40] Iter[39/312]		Loss: 0.1516
2019-10-28 15:33:25,412 Training Epoch [12/40] Iter[40/312]		Loss: 0.1518
2019-10-28 15:33:25,490 Training Epoch [12/40] Iter[41/312]		Loss: 0.1517
2019-10-28 15:33:25,569 Training Epoch [12/40] Iter[42/312]		Loss: 0.1519
2019-10-28 15:33:25,648 Training Epoch [12/40] Iter[43/312]		Loss: 0.1528
2019-10-28 15:33:25,727 Training Epoch [12/40] Iter[44/312]		Loss: 0.1524
2019-10-28 15:33:25,805 Training Epoch [12/40] Iter[45/312]		Loss: 0.1545
2019-10-28 15:33:25,884 Training Epoch [12/40] Iter[46/312]		Loss: 0.1560
2019-10-28 15:33:25,963 Training Epoch [12/40] Iter[47/312]		Loss: 0.1553
2019-10-28 15:33:26,042 Training Epoch [12/40] Iter[48/312]		Loss: 0.1551
2019-10-28 15:33:26,121 Training Epoch [12/40] Iter[49/312]		Loss: 0.1555
2019-10-28 15:33:26,200 Training Epoch [12/40] Iter[50/312]		Loss: 0.1548
2019-10-28 15:33:26,279 Training Epoch [12/40] Iter[51/312]		Loss: 0.1549
2019-10-28 15:33:26,358 Training Epoch [12/40] Iter[52/312]		Loss: 0.1546
2019-10-28 15:33:26,437 Training Epoch [12/40] Iter[53/312]		Loss: 0.1550
2019-10-28 15:33:26,516 Training Epoch [12/40] Iter[54/312]		Loss: 0.1553
2019-10-28 15:33:26,596 Training Epoch [12/40] Iter[55/312]		Loss: 0.1546
2019-10-28 15:33:26,675 Training Epoch [12/40] Iter[56/312]		Loss: 0.1544
2019-10-28 15:33:26,755 Training Epoch [12/40] Iter[57/312]		Loss: 0.1544
2019-10-28 15:33:26,834 Training Epoch [12/40] Iter[58/312]		Loss: 0.1537
2019-10-28 15:33:26,913 Training Epoch [12/40] Iter[59/312]		Loss: 0.1533
2019-10-28 15:33:26,993 Training Epoch [12/40] Iter[60/312]		Loss: 0.1526
2019-10-28 15:33:27,072 Training Epoch [12/40] Iter[61/312]		Loss: 0.1527
2019-10-28 15:33:27,151 Training Epoch [12/40] Iter[62/312]		Loss: 0.1518
2019-10-28 15:33:27,230 Training Epoch [12/40] Iter[63/312]		Loss: 0.1515
2019-10-28 15:33:27,309 Training Epoch [12/40] Iter[64/312]		Loss: 0.1514
2019-10-28 15:33:27,388 Training Epoch [12/40] Iter[65/312]		Loss: 0.1502
2019-10-28 15:33:27,467 Training Epoch [12/40] Iter[66/312]		Loss: 0.1501
2019-10-28 15:33:27,546 Training Epoch [12/40] Iter[67/312]		Loss: 0.1505
2019-10-28 15:33:27,625 Training Epoch [12/40] Iter[68/312]		Loss: 0.1505
2019-10-28 15:33:27,704 Training Epoch [12/40] Iter[69/312]		Loss: 0.1500
2019-10-28 15:33:27,784 Training Epoch [12/40] Iter[70/312]		Loss: 0.1510
2019-10-28 15:33:27,863 Training Epoch [12/40] Iter[71/312]		Loss: 0.1523
2019-10-28 15:33:27,942 Training Epoch [12/40] Iter[72/312]		Loss: 0.1527
2019-10-28 15:33:28,021 Training Epoch [12/40] Iter[73/312]		Loss: 0.1527
2019-10-28 15:33:28,099 Training Epoch [12/40] Iter[74/312]		Loss: 0.1530
2019-10-28 15:33:28,178 Training Epoch [12/40] Iter[75/312]		Loss: 0.1534
2019-10-28 15:33:28,257 Training Epoch [12/40] Iter[76/312]		Loss: 0.1530
2019-10-28 15:33:28,337 Training Epoch [12/40] Iter[77/312]		Loss: 0.1528
2019-10-28 15:33:28,416 Training Epoch [12/40] Iter[78/312]		Loss: 0.1529
2019-10-28 15:33:28,495 Training Epoch [12/40] Iter[79/312]		Loss: 0.1527
2019-10-28 15:33:28,574 Training Epoch [12/40] Iter[80/312]		Loss: 0.1523
2019-10-28 15:33:28,653 Training Epoch [12/40] Iter[81/312]		Loss: 0.1517
2019-10-28 15:33:28,732 Training Epoch [12/40] Iter[82/312]		Loss: 0.1516
2019-10-28 15:33:28,811 Training Epoch [12/40] Iter[83/312]		Loss: 0.1515
2019-10-28 15:33:28,890 Training Epoch [12/40] Iter[84/312]		Loss: 0.1512
2019-10-28 15:33:28,969 Training Epoch [12/40] Iter[85/312]		Loss: 0.1511
2019-10-28 15:33:29,048 Training Epoch [12/40] Iter[86/312]		Loss: 0.1516
2019-10-28 15:33:29,127 Training Epoch [12/40] Iter[87/312]		Loss: 0.1514
2019-10-28 15:33:29,206 Training Epoch [12/40] Iter[88/312]		Loss: 0.1519
2019-10-28 15:33:29,285 Training Epoch [12/40] Iter[89/312]		Loss: 0.1518
2019-10-28 15:33:29,364 Training Epoch [12/40] Iter[90/312]		Loss: 0.1519
2019-10-28 15:33:29,444 Training Epoch [12/40] Iter[91/312]		Loss: 0.1515
2019-10-28 15:33:29,523 Training Epoch [12/40] Iter[92/312]		Loss: 0.1518
2019-10-28 15:33:29,601 Training Epoch [12/40] Iter[93/312]		Loss: 0.1513
2019-10-28 15:33:29,681 Training Epoch [12/40] Iter[94/312]		Loss: 0.1509
2019-10-28 15:33:29,760 Training Epoch [12/40] Iter[95/312]		Loss: 0.1510
2019-10-28 15:33:29,839 Training Epoch [12/40] Iter[96/312]		Loss: 0.1518
2019-10-28 15:33:29,918 Training Epoch [12/40] Iter[97/312]		Loss: 0.1520
2019-10-28 15:33:29,997 Training Epoch [12/40] Iter[98/312]		Loss: 0.1522
2019-10-28 15:33:30,076 Training Epoch [12/40] Iter[99/312]		Loss: 0.1525
2019-10-28 15:33:30,155 Training Epoch [12/40] Iter[100/312]		Loss: 0.1529
2019-10-28 15:33:30,234 Training Epoch [12/40] Iter[101/312]		Loss: 0.1535
2019-10-28 15:33:30,313 Training Epoch [12/40] Iter[102/312]		Loss: 0.1532
2019-10-28 15:33:30,392 Training Epoch [12/40] Iter[103/312]		Loss: 0.1532
2019-10-28 15:33:30,471 Training Epoch [12/40] Iter[104/312]		Loss: 0.1533
2019-10-28 15:33:30,550 Training Epoch [12/40] Iter[105/312]		Loss: 0.1531
2019-10-28 15:33:30,629 Training Epoch [12/40] Iter[106/312]		Loss: 0.1527
2019-10-28 15:33:30,708 Training Epoch [12/40] Iter[107/312]		Loss: 0.1523
2019-10-28 15:33:30,787 Training Epoch [12/40] Iter[108/312]		Loss: 0.1523
2019-10-28 15:33:30,865 Training Epoch [12/40] Iter[109/312]		Loss: 0.1533
2019-10-28 15:33:30,944 Training Epoch [12/40] Iter[110/312]		Loss: 0.1535
2019-10-28 15:33:31,023 Training Epoch [12/40] Iter[111/312]		Loss: 0.1536
2019-10-28 15:33:31,102 Training Epoch [12/40] Iter[112/312]		Loss: 0.1534
2019-10-28 15:33:31,181 Training Epoch [12/40] Iter[113/312]		Loss: 0.1540
2019-10-28 15:33:31,260 Training Epoch [12/40] Iter[114/312]		Loss: 0.1539
2019-10-28 15:33:31,339 Training Epoch [12/40] Iter[115/312]		Loss: 0.1537
2019-10-28 15:33:31,418 Training Epoch [12/40] Iter[116/312]		Loss: 0.1538
2019-10-28 15:33:31,497 Training Epoch [12/40] Iter[117/312]		Loss: 0.1547
2019-10-28 15:33:31,576 Training Epoch [12/40] Iter[118/312]		Loss: 0.1550
2019-10-28 15:33:31,655 Training Epoch [12/40] Iter[119/312]		Loss: 0.1546
2019-10-28 15:33:31,734 Training Epoch [12/40] Iter[120/312]		Loss: 0.1550
2019-10-28 15:33:31,813 Training Epoch [12/40] Iter[121/312]		Loss: 0.1556
2019-10-28 15:33:31,892 Training Epoch [12/40] Iter[122/312]		Loss: 0.1562
2019-10-28 15:33:31,971 Training Epoch [12/40] Iter[123/312]		Loss: 0.1559
2019-10-28 15:33:32,050 Training Epoch [12/40] Iter[124/312]		Loss: 0.1556
2019-10-28 15:33:32,129 Training Epoch [12/40] Iter[125/312]		Loss: 0.1558
2019-10-28 15:33:32,209 Training Epoch [12/40] Iter[126/312]		Loss: 0.1560
2019-10-28 15:33:32,288 Training Epoch [12/40] Iter[127/312]		Loss: 0.1559
2019-10-28 15:33:32,367 Training Epoch [12/40] Iter[128/312]		Loss: 0.1561
2019-10-28 15:33:32,446 Training Epoch [12/40] Iter[129/312]		Loss: 0.1562
2019-10-28 15:33:32,525 Training Epoch [12/40] Iter[130/312]		Loss: 0.1566
2019-10-28 15:33:32,604 Training Epoch [12/40] Iter[131/312]		Loss: 0.1565
2019-10-28 15:33:32,683 Training Epoch [12/40] Iter[132/312]		Loss: 0.1563
2019-10-28 15:33:32,761 Training Epoch [12/40] Iter[133/312]		Loss: 0.1563
2019-10-28 15:33:32,840 Training Epoch [12/40] Iter[134/312]		Loss: 0.1565
2019-10-28 15:33:32,919 Training Epoch [12/40] Iter[135/312]		Loss: 0.1564
2019-10-28 15:33:32,998 Training Epoch [12/40] Iter[136/312]		Loss: 0.1571
2019-10-28 15:33:33,077 Training Epoch [12/40] Iter[137/312]		Loss: 0.1570
2019-10-28 15:33:33,156 Training Epoch [12/40] Iter[138/312]		Loss: 0.1569
2019-10-28 15:33:33,235 Training Epoch [12/40] Iter[139/312]		Loss: 0.1571
2019-10-28 15:33:33,314 Training Epoch [12/40] Iter[140/312]		Loss: 0.1568
2019-10-28 15:33:33,393 Training Epoch [12/40] Iter[141/312]		Loss: 0.1569
2019-10-28 15:33:33,472 Training Epoch [12/40] Iter[142/312]		Loss: 0.1569
2019-10-28 15:33:33,551 Training Epoch [12/40] Iter[143/312]		Loss: 0.1567
2019-10-28 15:33:33,631 Training Epoch [12/40] Iter[144/312]		Loss: 0.1570
2019-10-28 15:33:33,710 Training Epoch [12/40] Iter[145/312]		Loss: 0.1566
2019-10-28 15:33:33,789 Training Epoch [12/40] Iter[146/312]		Loss: 0.1564
2019-10-28 15:33:33,868 Training Epoch [12/40] Iter[147/312]		Loss: 0.1564
2019-10-28 15:33:33,946 Training Epoch [12/40] Iter[148/312]		Loss: 0.1562
2019-10-28 15:33:34,025 Training Epoch [12/40] Iter[149/312]		Loss: 0.1567
2019-10-28 15:33:34,104 Training Epoch [12/40] Iter[150/312]		Loss: 0.1569
2019-10-28 15:33:34,183 Training Epoch [12/40] Iter[151/312]		Loss: 0.1568
2019-10-28 15:33:34,262 Training Epoch [12/40] Iter[152/312]		Loss: 0.1571
2019-10-28 15:33:34,342 Training Epoch [12/40] Iter[153/312]		Loss: 0.1581
2019-10-28 15:33:34,421 Training Epoch [12/40] Iter[154/312]		Loss: 0.1581
2019-10-28 15:33:34,500 Training Epoch [12/40] Iter[155/312]		Loss: 0.1582
2019-10-28 15:33:34,579 Training Epoch [12/40] Iter[156/312]		Loss: 0.1579
2019-10-28 15:33:34,658 Training Epoch [12/40] Iter[157/312]		Loss: 0.1575
2019-10-28 15:33:34,737 Training Epoch [12/40] Iter[158/312]		Loss: 0.1576
2019-10-28 15:33:34,816 Training Epoch [12/40] Iter[159/312]		Loss: 0.1573
2019-10-28 15:33:34,895 Training Epoch [12/40] Iter[160/312]		Loss: 0.1570
2019-10-28 15:33:34,974 Training Epoch [12/40] Iter[161/312]		Loss: 0.1568
2019-10-28 15:33:35,054 Training Epoch [12/40] Iter[162/312]		Loss: 0.1567
2019-10-28 15:33:35,133 Training Epoch [12/40] Iter[163/312]		Loss: 0.1568
2019-10-28 15:33:35,212 Training Epoch [12/40] Iter[164/312]		Loss: 0.1568
2019-10-28 15:33:35,291 Training Epoch [12/40] Iter[165/312]		Loss: 0.1566
2019-10-28 15:33:35,371 Training Epoch [12/40] Iter[166/312]		Loss: 0.1565
2019-10-28 15:33:35,450 Training Epoch [12/40] Iter[167/312]		Loss: 0.1563
2019-10-28 15:33:35,529 Training Epoch [12/40] Iter[168/312]		Loss: 0.1568
2019-10-28 15:33:35,607 Training Epoch [12/40] Iter[169/312]		Loss: 0.1570
2019-10-28 15:33:35,686 Training Epoch [12/40] Iter[170/312]		Loss: 0.1568
2019-10-28 15:33:35,765 Training Epoch [12/40] Iter[171/312]		Loss: 0.1566
2019-10-28 15:33:35,844 Training Epoch [12/40] Iter[172/312]		Loss: 0.1564
2019-10-28 15:33:35,923 Training Epoch [12/40] Iter[173/312]		Loss: 0.1561
2019-10-28 15:33:36,002 Training Epoch [12/40] Iter[174/312]		Loss: 0.1561
2019-10-28 15:33:36,081 Training Epoch [12/40] Iter[175/312]		Loss: 0.1562
2019-10-28 15:33:36,160 Training Epoch [12/40] Iter[176/312]		Loss: 0.1562
2019-10-28 15:33:36,239 Training Epoch [12/40] Iter[177/312]		Loss: 0.1559
2019-10-28 15:33:36,318 Training Epoch [12/40] Iter[178/312]		Loss: 0.1559
2019-10-28 15:33:36,397 Training Epoch [12/40] Iter[179/312]		Loss: 0.1558
2019-10-28 15:33:36,476 Training Epoch [12/40] Iter[180/312]		Loss: 0.1557
2019-10-28 15:33:36,555 Training Epoch [12/40] Iter[181/312]		Loss: 0.1557
2019-10-28 15:33:36,634 Training Epoch [12/40] Iter[182/312]		Loss: 0.1562
2019-10-28 15:33:36,713 Training Epoch [12/40] Iter[183/312]		Loss: 0.1564
2019-10-28 15:33:36,792 Training Epoch [12/40] Iter[184/312]		Loss: 0.1570
2019-10-28 15:33:36,871 Training Epoch [12/40] Iter[185/312]		Loss: 0.1571
2019-10-28 15:33:36,950 Training Epoch [12/40] Iter[186/312]		Loss: 0.1573
2019-10-28 15:33:37,029 Training Epoch [12/40] Iter[187/312]		Loss: 0.1573
2019-10-28 15:33:37,108 Training Epoch [12/40] Iter[188/312]		Loss: 0.1571
2019-10-28 15:33:37,187 Training Epoch [12/40] Iter[189/312]		Loss: 0.1567
2019-10-28 15:33:37,269 Training Epoch [12/40] Iter[190/312]		Loss: 0.1565
2019-10-28 15:33:37,348 Training Epoch [12/40] Iter[191/312]		Loss: 0.1566
2019-10-28 15:33:37,427 Training Epoch [12/40] Iter[192/312]		Loss: 0.1570
2019-10-28 15:33:37,506 Training Epoch [12/40] Iter[193/312]		Loss: 0.1571
2019-10-28 15:33:37,586 Training Epoch [12/40] Iter[194/312]		Loss: 0.1571
2019-10-28 15:33:37,665 Training Epoch [12/40] Iter[195/312]		Loss: 0.1569
2019-10-28 15:33:37,744 Training Epoch [12/40] Iter[196/312]		Loss: 0.1577
2019-10-28 15:33:37,822 Training Epoch [12/40] Iter[197/312]		Loss: 0.1575
2019-10-28 15:33:37,901 Training Epoch [12/40] Iter[198/312]		Loss: 0.1578
2019-10-28 15:33:37,980 Training Epoch [12/40] Iter[199/312]		Loss: 0.1582
2019-10-28 15:33:38,059 Training Epoch [12/40] Iter[200/312]		Loss: 0.1587
2019-10-28 15:33:38,138 Training Epoch [12/40] Iter[201/312]		Loss: 0.1586
2019-10-28 15:33:38,217 Training Epoch [12/40] Iter[202/312]		Loss: 0.1583
2019-10-28 15:33:38,295 Training Epoch [12/40] Iter[203/312]		Loss: 0.1583
2019-10-28 15:33:38,374 Training Epoch [12/40] Iter[204/312]		Loss: 0.1587
2019-10-28 15:33:38,453 Training Epoch [12/40] Iter[205/312]		Loss: 0.1586
2019-10-28 15:33:38,532 Training Epoch [12/40] Iter[206/312]		Loss: 0.1587
2019-10-28 15:33:38,611 Training Epoch [12/40] Iter[207/312]		Loss: 0.1588
2019-10-28 15:33:38,690 Training Epoch [12/40] Iter[208/312]		Loss: 0.1589
2019-10-28 15:33:38,769 Training Epoch [12/40] Iter[209/312]		Loss: 0.1592
2019-10-28 15:33:38,848 Training Epoch [12/40] Iter[210/312]		Loss: 0.1593
2019-10-28 15:33:38,927 Training Epoch [12/40] Iter[211/312]		Loss: 0.1593
2019-10-28 15:33:39,006 Training Epoch [12/40] Iter[212/312]		Loss: 0.1592
2019-10-28 15:33:39,085 Training Epoch [12/40] Iter[213/312]		Loss: 0.1598
2019-10-28 15:33:39,164 Training Epoch [12/40] Iter[214/312]		Loss: 0.1601
2019-10-28 15:33:39,243 Training Epoch [12/40] Iter[215/312]		Loss: 0.1602
2019-10-28 15:33:39,322 Training Epoch [12/40] Iter[216/312]		Loss: 0.1602
2019-10-28 15:33:39,401 Training Epoch [12/40] Iter[217/312]		Loss: 0.1602
2019-10-28 15:33:39,480 Training Epoch [12/40] Iter[218/312]		Loss: 0.1603
2019-10-28 15:33:39,560 Training Epoch [12/40] Iter[219/312]		Loss: 0.1603
2019-10-28 15:33:39,639 Training Epoch [12/40] Iter[220/312]		Loss: 0.1606
2019-10-28 15:33:39,718 Training Epoch [12/40] Iter[221/312]		Loss: 0.1606
2019-10-28 15:33:39,797 Training Epoch [12/40] Iter[222/312]		Loss: 0.1606
2019-10-28 15:33:39,876 Training Epoch [12/40] Iter[223/312]		Loss: 0.1606
2019-10-28 15:33:39,955 Training Epoch [12/40] Iter[224/312]		Loss: 0.1606
2019-10-28 15:33:40,034 Training Epoch [12/40] Iter[225/312]		Loss: 0.1607
2019-10-28 15:33:40,113 Training Epoch [12/40] Iter[226/312]		Loss: 0.1607
2019-10-28 15:33:40,192 Training Epoch [12/40] Iter[227/312]		Loss: 0.1607
2019-10-28 15:33:40,270 Training Epoch [12/40] Iter[228/312]		Loss: 0.1607
2019-10-28 15:33:40,349 Training Epoch [12/40] Iter[229/312]		Loss: 0.1606
2019-10-28 15:33:40,428 Training Epoch [12/40] Iter[230/312]		Loss: 0.1604
2019-10-28 15:33:40,512 Training Epoch [12/40] Iter[231/312]		Loss: 0.1603
2019-10-28 15:33:40,595 Training Epoch [12/40] Iter[232/312]		Loss: 0.1603
2019-10-28 15:33:40,674 Training Epoch [12/40] Iter[233/312]		Loss: 0.1602
2019-10-28 15:33:40,753 Training Epoch [12/40] Iter[234/312]		Loss: 0.1600
2019-10-28 15:33:40,832 Training Epoch [12/40] Iter[235/312]		Loss: 0.1597
2019-10-28 15:33:40,910 Training Epoch [12/40] Iter[236/312]		Loss: 0.1596
2019-10-28 15:33:40,989 Training Epoch [12/40] Iter[237/312]		Loss: 0.1600
2019-10-28 15:33:41,068 Training Epoch [12/40] Iter[238/312]		Loss: 0.1601
2019-10-28 15:33:41,147 Training Epoch [12/40] Iter[239/312]		Loss: 0.1603
2019-10-28 15:33:41,226 Training Epoch [12/40] Iter[240/312]		Loss: 0.1608
2019-10-28 15:33:41,305 Training Epoch [12/40] Iter[241/312]		Loss: 0.1613
2019-10-28 15:33:41,384 Training Epoch [12/40] Iter[242/312]		Loss: 0.1612
2019-10-28 15:33:41,463 Training Epoch [12/40] Iter[243/312]		Loss: 0.1614
2019-10-28 15:33:41,542 Training Epoch [12/40] Iter[244/312]		Loss: 0.1614
2019-10-28 15:33:41,621 Training Epoch [12/40] Iter[245/312]		Loss: 0.1613
2019-10-28 15:33:41,700 Training Epoch [12/40] Iter[246/312]		Loss: 0.1613
2019-10-28 15:33:41,779 Training Epoch [12/40] Iter[247/312]		Loss: 0.1613
2019-10-28 15:33:41,858 Training Epoch [12/40] Iter[248/312]		Loss: 0.1611
2019-10-28 15:33:41,937 Training Epoch [12/40] Iter[249/312]		Loss: 0.1609
2019-10-28 15:33:42,016 Training Epoch [12/40] Iter[250/312]		Loss: 0.1609
2019-10-28 15:33:42,095 Training Epoch [12/40] Iter[251/312]		Loss: 0.1608
2019-10-28 15:33:42,175 Training Epoch [12/40] Iter[252/312]		Loss: 0.1607
2019-10-28 15:33:42,254 Training Epoch [12/40] Iter[253/312]		Loss: 0.1609
2019-10-28 15:33:42,333 Training Epoch [12/40] Iter[254/312]		Loss: 0.1608
2019-10-28 15:33:42,412 Training Epoch [12/40] Iter[255/312]		Loss: 0.1609
2019-10-28 15:33:42,491 Training Epoch [12/40] Iter[256/312]		Loss: 0.1609
2019-10-28 15:33:42,571 Training Epoch [12/40] Iter[257/312]		Loss: 0.1610
2019-10-28 15:33:42,651 Training Epoch [12/40] Iter[258/312]		Loss: 0.1608
2019-10-28 15:33:42,731 Training Epoch [12/40] Iter[259/312]		Loss: 0.1608
2019-10-28 15:33:42,812 Training Epoch [12/40] Iter[260/312]		Loss: 0.1610
2019-10-28 15:33:42,892 Training Epoch [12/40] Iter[261/312]		Loss: 0.1608
2019-10-28 15:33:42,972 Training Epoch [12/40] Iter[262/312]		Loss: 0.1609
2019-10-28 15:33:43,052 Training Epoch [12/40] Iter[263/312]		Loss: 0.1614
2019-10-28 15:33:43,133 Training Epoch [12/40] Iter[264/312]		Loss: 0.1612
2019-10-28 15:33:43,213 Training Epoch [12/40] Iter[265/312]		Loss: 0.1613
2019-10-28 15:33:43,293 Training Epoch [12/40] Iter[266/312]		Loss: 0.1610
2019-10-28 15:33:43,372 Training Epoch [12/40] Iter[267/312]		Loss: 0.1609
2019-10-28 15:33:43,452 Training Epoch [12/40] Iter[268/312]		Loss: 0.1611
2019-10-28 15:33:43,532 Training Epoch [12/40] Iter[269/312]		Loss: 0.1614
2019-10-28 15:33:43,611 Training Epoch [12/40] Iter[270/312]		Loss: 0.1615
2019-10-28 15:33:43,691 Training Epoch [12/40] Iter[271/312]		Loss: 0.1621
2019-10-28 15:33:43,771 Training Epoch [12/40] Iter[272/312]		Loss: 0.1620
2019-10-28 15:33:43,851 Training Epoch [12/40] Iter[273/312]		Loss: 0.1619
2019-10-28 15:33:43,930 Training Epoch [12/40] Iter[274/312]		Loss: 0.1620
2019-10-28 15:33:44,009 Training Epoch [12/40] Iter[275/312]		Loss: 0.1623
2019-10-28 15:33:44,089 Training Epoch [12/40] Iter[276/312]		Loss: 0.1625
2019-10-28 15:33:44,168 Training Epoch [12/40] Iter[277/312]		Loss: 0.1623
2019-10-28 15:33:44,248 Training Epoch [12/40] Iter[278/312]		Loss: 0.1625
2019-10-28 15:33:44,327 Training Epoch [12/40] Iter[279/312]		Loss: 0.1624
2019-10-28 15:33:44,407 Training Epoch [12/40] Iter[280/312]		Loss: 0.1622
2019-10-28 15:33:44,487 Training Epoch [12/40] Iter[281/312]		Loss: 0.1621
2019-10-28 15:33:44,566 Training Epoch [12/40] Iter[282/312]		Loss: 0.1621
2019-10-28 15:33:44,646 Training Epoch [12/40] Iter[283/312]		Loss: 0.1619
2019-10-28 15:33:44,726 Training Epoch [12/40] Iter[284/312]		Loss: 0.1616
2019-10-28 15:33:44,806 Training Epoch [12/40] Iter[285/312]		Loss: 0.1617
2019-10-28 15:33:44,886 Training Epoch [12/40] Iter[286/312]		Loss: 0.1616
2019-10-28 15:33:44,966 Training Epoch [12/40] Iter[287/312]		Loss: 0.1615
2019-10-28 15:33:45,046 Training Epoch [12/40] Iter[288/312]		Loss: 0.1613
2019-10-28 15:33:45,126 Training Epoch [12/40] Iter[289/312]		Loss: 0.1618
2019-10-28 15:33:45,206 Training Epoch [12/40] Iter[290/312]		Loss: 0.1616
2019-10-28 15:33:45,286 Training Epoch [12/40] Iter[291/312]		Loss: 0.1617
2019-10-28 15:33:45,366 Training Epoch [12/40] Iter[292/312]		Loss: 0.1617
2019-10-28 15:33:45,446 Training Epoch [12/40] Iter[293/312]		Loss: 0.1616
2019-10-28 15:33:45,526 Training Epoch [12/40] Iter[294/312]		Loss: 0.1615
2019-10-28 15:33:45,605 Training Epoch [12/40] Iter[295/312]		Loss: 0.1616
2019-10-28 15:33:45,685 Training Epoch [12/40] Iter[296/312]		Loss: 0.1615
2019-10-28 15:33:45,764 Training Epoch [12/40] Iter[297/312]		Loss: 0.1614
2019-10-28 15:33:45,844 Training Epoch [12/40] Iter[298/312]		Loss: 0.1613
2019-10-28 15:33:45,923 Training Epoch [12/40] Iter[299/312]		Loss: 0.1613
2019-10-28 15:33:46,003 Training Epoch [12/40] Iter[300/312]		Loss: 0.1612
2019-10-28 15:33:46,083 Training Epoch [12/40] Iter[301/312]		Loss: 0.1611
2019-10-28 15:33:46,162 Training Epoch [12/40] Iter[302/312]		Loss: 0.1611
2019-10-28 15:33:46,243 Training Epoch [12/40] Iter[303/312]		Loss: 0.1611
2019-10-28 15:33:46,322 Training Epoch [12/40] Iter[304/312]		Loss: 0.1612
2019-10-28 15:33:46,401 Training Epoch [12/40] Iter[305/312]		Loss: 0.1614
2019-10-28 15:33:46,480 Training Epoch [12/40] Iter[306/312]		Loss: 0.1613
2019-10-28 15:33:46,560 Training Epoch [12/40] Iter[307/312]		Loss: 0.1614
2019-10-28 15:33:46,639 Training Epoch [12/40] Iter[308/312]		Loss: 0.1613
2019-10-28 15:33:46,718 Training Epoch [12/40] Iter[309/312]		Loss: 0.1611
2019-10-28 15:33:46,797 Training Epoch [12/40] Iter[310/312]		Loss: 0.1610
2019-10-28 15:33:46,876 Training Epoch [12/40] Iter[311/312]		Loss: 0.1612
2019-10-28 15:33:46,916 Training Epoch [12/40] Iter[312/312]		Loss: 0.1610
2019-10-28 15:33:47,350 Testing Epoch [12/40] Iter[0/62]		Loss: 0.1482
2019-10-28 15:33:47,382 Testing Epoch [12/40] Iter[1/62]		Loss: 0.1554
2019-10-28 15:33:47,414 Testing Epoch [12/40] Iter[2/62]		Loss: 0.1374
2019-10-28 15:33:47,442 Testing Epoch [12/40] Iter[3/62]		Loss: 0.1423
2019-10-28 15:33:47,458 Testing Epoch [12/40] Iter[4/62]		Loss: 0.1448
2019-10-28 15:33:47,475 Testing Epoch [12/40] Iter[5/62]		Loss: 0.1384
2019-10-28 15:33:47,510 Testing Epoch [12/40] Iter[6/62]		Loss: 0.1408
2019-10-28 15:33:47,529 Testing Epoch [12/40] Iter[7/62]		Loss: 0.1433
2019-10-28 15:33:47,547 Testing Epoch [12/40] Iter[8/62]		Loss: 0.1457
2019-10-28 15:33:47,565 Testing Epoch [12/40] Iter[9/62]		Loss: 0.1455
2019-10-28 15:33:47,598 Testing Epoch [12/40] Iter[10/62]		Loss: 0.1460
2019-10-28 15:33:47,615 Testing Epoch [12/40] Iter[11/62]		Loss: 0.1531
2019-10-28 15:33:47,635 Testing Epoch [12/40] Iter[12/62]		Loss: 0.1535
2019-10-28 15:33:47,651 Testing Epoch [12/40] Iter[13/62]		Loss: 0.1548
2019-10-28 15:33:47,678 Testing Epoch [12/40] Iter[14/62]		Loss: 0.1694
2019-10-28 15:33:47,702 Testing Epoch [12/40] Iter[15/62]		Loss: 0.1729
2019-10-28 15:33:47,723 Testing Epoch [12/40] Iter[16/62]		Loss: 0.1694
2019-10-28 15:33:47,739 Testing Epoch [12/40] Iter[17/62]		Loss: 0.1677
2019-10-28 15:33:47,766 Testing Epoch [12/40] Iter[18/62]		Loss: 0.1652
2019-10-28 15:33:47,787 Testing Epoch [12/40] Iter[19/62]		Loss: 0.1631
2019-10-28 15:33:47,821 Testing Epoch [12/40] Iter[20/62]		Loss: 0.1644
2019-10-28 15:33:47,838 Testing Epoch [12/40] Iter[21/62]		Loss: 0.1635
2019-10-28 15:33:47,856 Testing Epoch [12/40] Iter[22/62]		Loss: 0.1654
2019-10-28 15:33:47,882 Testing Epoch [12/40] Iter[23/62]		Loss: 0.1638
2019-10-28 15:33:47,909 Testing Epoch [12/40] Iter[24/62]		Loss: 0.1678
2019-10-28 15:33:47,927 Testing Epoch [12/40] Iter[25/62]		Loss: 0.1666
2019-10-28 15:33:47,945 Testing Epoch [12/40] Iter[26/62]		Loss: 0.1650
2019-10-28 15:33:47,975 Testing Epoch [12/40] Iter[27/62]		Loss: 0.1733
2019-10-28 15:33:48,001 Testing Epoch [12/40] Iter[28/62]		Loss: 0.1757
2019-10-28 15:33:48,029 Testing Epoch [12/40] Iter[29/62]		Loss: 0.1756
2019-10-28 15:33:48,051 Testing Epoch [12/40] Iter[30/62]		Loss: 0.1766
2019-10-28 15:33:48,076 Testing Epoch [12/40] Iter[31/62]		Loss: 0.1751
2019-10-28 15:33:48,094 Testing Epoch [12/40] Iter[32/62]		Loss: 0.1770
2019-10-28 15:33:48,114 Testing Epoch [12/40] Iter[33/62]		Loss: 0.1754
2019-10-28 15:33:48,140 Testing Epoch [12/40] Iter[34/62]		Loss: 0.1780
2019-10-28 15:33:48,162 Testing Epoch [12/40] Iter[35/62]		Loss: 0.1777
2019-10-28 15:33:48,184 Testing Epoch [12/40] Iter[36/62]		Loss: 0.1758
2019-10-28 15:33:48,202 Testing Epoch [12/40] Iter[37/62]		Loss: 0.1744
2019-10-28 15:33:48,233 Testing Epoch [12/40] Iter[38/62]		Loss: 0.1735
2019-10-28 15:33:48,251 Testing Epoch [12/40] Iter[39/62]		Loss: 0.1742
2019-10-28 15:33:48,269 Testing Epoch [12/40] Iter[40/62]		Loss: 0.1762
2019-10-28 15:33:48,287 Testing Epoch [12/40] Iter[41/62]		Loss: 0.1778
2019-10-28 15:33:48,314 Testing Epoch [12/40] Iter[42/62]		Loss: 0.1760
2019-10-28 15:33:48,343 Testing Epoch [12/40] Iter[43/62]		Loss: 0.1754
2019-10-28 15:33:48,362 Testing Epoch [12/40] Iter[44/62]		Loss: 0.1739
2019-10-28 15:33:48,389 Testing Epoch [12/40] Iter[45/62]		Loss: 0.1740
2019-10-28 15:33:48,405 Testing Epoch [12/40] Iter[46/62]		Loss: 0.1738
2019-10-28 15:33:48,438 Testing Epoch [12/40] Iter[47/62]		Loss: 0.1796
2019-10-28 15:33:48,456 Testing Epoch [12/40] Iter[48/62]		Loss: 0.1783
2019-10-28 15:33:48,481 Testing Epoch [12/40] Iter[49/62]		Loss: 0.1810
2019-10-28 15:33:48,499 Testing Epoch [12/40] Iter[50/62]		Loss: 0.1801
2019-10-28 15:33:48,526 Testing Epoch [12/40] Iter[51/62]		Loss: 0.1801
2019-10-28 15:33:48,547 Testing Epoch [12/40] Iter[52/62]		Loss: 0.1787
2019-10-28 15:33:48,577 Testing Epoch [12/40] Iter[53/62]		Loss: 0.1793
2019-10-28 15:33:48,595 Testing Epoch [12/40] Iter[54/62]		Loss: 0.1784
2019-10-28 15:33:48,612 Testing Epoch [12/40] Iter[55/62]		Loss: 0.1780
2019-10-28 15:33:48,629 Testing Epoch [12/40] Iter[56/62]		Loss: 0.1777
2019-10-28 15:33:48,646 Testing Epoch [12/40] Iter[57/62]		Loss: 0.1780
2019-10-28 15:33:48,663 Testing Epoch [12/40] Iter[58/62]		Loss: 0.1773
2019-10-28 15:33:48,680 Testing Epoch [12/40] Iter[59/62]		Loss: 0.1782
2019-10-28 15:33:48,696 Testing Epoch [12/40] Iter[60/62]		Loss: 0.1773
2019-10-28 15:33:48,713 Testing Epoch [12/40] Iter[61/62]		Loss: 0.1778
2019-10-28 15:33:48,723 Testing Epoch [12/40] Iter[62/62]		Loss: 0.1791
2019-10-28 15:33:48,797 Saving the Model
2019-10-28 15:33:49,282 Training Epoch [13/40] Iter[0/312]		Loss: 0.1527
2019-10-28 15:33:49,373 Training Epoch [13/40] Iter[1/312]		Loss: 0.2011
2019-10-28 15:33:49,460 Training Epoch [13/40] Iter[2/312]		Loss: 0.1735
2019-10-28 15:33:49,542 Training Epoch [13/40] Iter[3/312]		Loss: 0.1695
2019-10-28 15:33:49,626 Training Epoch [13/40] Iter[4/312]		Loss: 0.1640
2019-10-28 15:33:49,708 Training Epoch [13/40] Iter[5/312]		Loss: 0.1637
2019-10-28 15:33:49,787 Training Epoch [13/40] Iter[6/312]		Loss: 0.1619
2019-10-28 15:33:49,869 Training Epoch [13/40] Iter[7/312]		Loss: 0.1565
2019-10-28 15:33:49,950 Training Epoch [13/40] Iter[8/312]		Loss: 0.1556
2019-10-28 15:33:50,031 Training Epoch [13/40] Iter[9/312]		Loss: 0.1602
2019-10-28 15:33:50,112 Training Epoch [13/40] Iter[10/312]		Loss: 0.1597
2019-10-28 15:33:50,194 Training Epoch [13/40] Iter[11/312]		Loss: 0.1574
2019-10-28 15:33:50,275 Training Epoch [13/40] Iter[12/312]		Loss: 0.1602
2019-10-28 15:33:50,361 Training Epoch [13/40] Iter[13/312]		Loss: 0.1577
2019-10-28 15:33:50,442 Training Epoch [13/40] Iter[14/312]		Loss: 0.1550
2019-10-28 15:33:50,522 Training Epoch [13/40] Iter[15/312]		Loss: 0.1537
2019-10-28 15:33:50,602 Training Epoch [13/40] Iter[16/312]		Loss: 0.1552
2019-10-28 15:33:50,682 Training Epoch [13/40] Iter[17/312]		Loss: 0.1562
2019-10-28 15:33:50,762 Training Epoch [13/40] Iter[18/312]		Loss: 0.1546
2019-10-28 15:33:50,842 Training Epoch [13/40] Iter[19/312]		Loss: 0.1518
2019-10-28 15:33:50,922 Training Epoch [13/40] Iter[20/312]		Loss: 0.1538
2019-10-28 15:33:51,002 Training Epoch [13/40] Iter[21/312]		Loss: 0.1554
2019-10-28 15:33:51,082 Training Epoch [13/40] Iter[22/312]		Loss: 0.1566
2019-10-28 15:33:51,162 Training Epoch [13/40] Iter[23/312]		Loss: 0.1559
2019-10-28 15:33:51,241 Training Epoch [13/40] Iter[24/312]		Loss: 0.1571
2019-10-28 15:33:51,321 Training Epoch [13/40] Iter[25/312]		Loss: 0.1557
2019-10-28 15:33:51,401 Training Epoch [13/40] Iter[26/312]		Loss: 0.1540
2019-10-28 15:33:51,480 Training Epoch [13/40] Iter[27/312]		Loss: 0.1538
2019-10-28 15:33:51,559 Training Epoch [13/40] Iter[28/312]		Loss: 0.1527
2019-10-28 15:33:51,639 Training Epoch [13/40] Iter[29/312]		Loss: 0.1516
2019-10-28 15:33:51,718 Training Epoch [13/40] Iter[30/312]		Loss: 0.1529
2019-10-28 15:33:51,798 Training Epoch [13/40] Iter[31/312]		Loss: 0.1536
2019-10-28 15:33:51,878 Training Epoch [13/40] Iter[32/312]		Loss: 0.1533
2019-10-28 15:33:51,958 Training Epoch [13/40] Iter[33/312]		Loss: 0.1523
2019-10-28 15:33:52,037 Training Epoch [13/40] Iter[34/312]		Loss: 0.1529
2019-10-28 15:33:52,117 Training Epoch [13/40] Iter[35/312]		Loss: 0.1525
2019-10-28 15:33:52,197 Training Epoch [13/40] Iter[36/312]		Loss: 0.1546
2019-10-28 15:33:52,276 Training Epoch [13/40] Iter[37/312]		Loss: 0.1533
2019-10-28 15:33:52,356 Training Epoch [13/40] Iter[38/312]		Loss: 0.1532
2019-10-28 15:33:52,436 Training Epoch [13/40] Iter[39/312]		Loss: 0.1530
2019-10-28 15:33:52,516 Training Epoch [13/40] Iter[40/312]		Loss: 0.1524
2019-10-28 15:33:52,596 Training Epoch [13/40] Iter[41/312]		Loss: 0.1520
2019-10-28 15:33:52,676 Training Epoch [13/40] Iter[42/312]		Loss: 0.1518
2019-10-28 15:33:52,755 Training Epoch [13/40] Iter[43/312]		Loss: 0.1512
2019-10-28 15:33:52,834 Training Epoch [13/40] Iter[44/312]		Loss: 0.1511
2019-10-28 15:33:52,913 Training Epoch [13/40] Iter[45/312]		Loss: 0.1511
2019-10-28 15:33:52,992 Training Epoch [13/40] Iter[46/312]		Loss: 0.1508
2019-10-28 15:33:53,072 Training Epoch [13/40] Iter[47/312]		Loss: 0.1508
2019-10-28 15:33:53,151 Training Epoch [13/40] Iter[48/312]		Loss: 0.1515
2019-10-28 15:33:53,230 Training Epoch [13/40] Iter[49/312]		Loss: 0.1507
2019-10-28 15:33:53,309 Training Epoch [13/40] Iter[50/312]		Loss: 0.1512
2019-10-28 15:33:53,389 Training Epoch [13/40] Iter[51/312]		Loss: 0.1522
2019-10-28 15:33:53,468 Training Epoch [13/40] Iter[52/312]		Loss: 0.1523
2019-10-28 15:33:53,548 Training Epoch [13/40] Iter[53/312]		Loss: 0.1535
2019-10-28 15:33:53,627 Training Epoch [13/40] Iter[54/312]		Loss: 0.1550
2019-10-28 15:33:53,707 Training Epoch [13/40] Iter[55/312]		Loss: 0.1543
2019-10-28 15:33:53,786 Training Epoch [13/40] Iter[56/312]		Loss: 0.1549
2019-10-28 15:33:53,865 Training Epoch [13/40] Iter[57/312]		Loss: 0.1552
2019-10-28 15:33:53,945 Training Epoch [13/40] Iter[58/312]		Loss: 0.1546
2019-10-28 15:33:54,024 Training Epoch [13/40] Iter[59/312]		Loss: 0.1540
2019-10-28 15:33:54,104 Training Epoch [13/40] Iter[60/312]		Loss: 0.1534
2019-10-28 15:33:54,183 Training Epoch [13/40] Iter[61/312]		Loss: 0.1527
2019-10-28 15:33:54,263 Training Epoch [13/40] Iter[62/312]		Loss: 0.1522
2019-10-28 15:33:54,342 Training Epoch [13/40] Iter[63/312]		Loss: 0.1516
2019-10-28 15:33:54,422 Training Epoch [13/40] Iter[64/312]		Loss: 0.1533
2019-10-28 15:33:54,502 Training Epoch [13/40] Iter[65/312]		Loss: 0.1533
2019-10-28 15:33:54,581 Training Epoch [13/40] Iter[66/312]		Loss: 0.1535
2019-10-28 15:33:54,660 Training Epoch [13/40] Iter[67/312]		Loss: 0.1544
2019-10-28 15:33:54,740 Training Epoch [13/40] Iter[68/312]		Loss: 0.1543
2019-10-28 15:33:54,820 Training Epoch [13/40] Iter[69/312]		Loss: 0.1543
2019-10-28 15:33:54,899 Training Epoch [13/40] Iter[70/312]		Loss: 0.1541
2019-10-28 15:33:54,978 Training Epoch [13/40] Iter[71/312]		Loss: 0.1534
2019-10-28 15:33:55,058 Training Epoch [13/40] Iter[72/312]		Loss: 0.1536
2019-10-28 15:33:55,137 Training Epoch [13/40] Iter[73/312]		Loss: 0.1533
2019-10-28 15:33:55,216 Training Epoch [13/40] Iter[74/312]		Loss: 0.1528
2019-10-28 15:33:55,296 Training Epoch [13/40] Iter[75/312]		Loss: 0.1528
2019-10-28 15:33:55,375 Training Epoch [13/40] Iter[76/312]		Loss: 0.1525
2019-10-28 15:33:55,454 Training Epoch [13/40] Iter[77/312]		Loss: 0.1532
2019-10-28 15:33:55,533 Training Epoch [13/40] Iter[78/312]		Loss: 0.1543
2019-10-28 15:33:55,612 Training Epoch [13/40] Iter[79/312]		Loss: 0.1543
2019-10-28 15:33:55,691 Training Epoch [13/40] Iter[80/312]		Loss: 0.1541
2019-10-28 15:33:55,770 Training Epoch [13/40] Iter[81/312]		Loss: 0.1541
2019-10-28 15:33:55,850 Training Epoch [13/40] Iter[82/312]		Loss: 0.1538
2019-10-28 15:33:55,929 Training Epoch [13/40] Iter[83/312]		Loss: 0.1537
2019-10-28 15:33:56,008 Training Epoch [13/40] Iter[84/312]		Loss: 0.1540
2019-10-28 15:33:56,087 Training Epoch [13/40] Iter[85/312]		Loss: 0.1541
2019-10-28 15:33:56,166 Training Epoch [13/40] Iter[86/312]		Loss: 0.1539
2019-10-28 15:33:56,246 Training Epoch [13/40] Iter[87/312]		Loss: 0.1549
2019-10-28 15:33:56,326 Training Epoch [13/40] Iter[88/312]		Loss: 0.1554
2019-10-28 15:33:56,405 Training Epoch [13/40] Iter[89/312]		Loss: 0.1556
2019-10-28 15:33:56,484 Training Epoch [13/40] Iter[90/312]		Loss: 0.1555
2019-10-28 15:33:56,563 Training Epoch [13/40] Iter[91/312]		Loss: 0.1558
2019-10-28 15:33:56,642 Training Epoch [13/40] Iter[92/312]		Loss: 0.1554
2019-10-28 15:33:56,722 Training Epoch [13/40] Iter[93/312]		Loss: 0.1553
2019-10-28 15:33:56,801 Training Epoch [13/40] Iter[94/312]		Loss: 0.1557
2019-10-28 15:33:56,881 Training Epoch [13/40] Iter[95/312]		Loss: 0.1556
2019-10-28 15:33:56,960 Training Epoch [13/40] Iter[96/312]		Loss: 0.1559
2019-10-28 15:33:57,040 Training Epoch [13/40] Iter[97/312]		Loss: 0.1552
2019-10-28 15:33:57,119 Training Epoch [13/40] Iter[98/312]		Loss: 0.1551
2019-10-28 15:33:57,199 Training Epoch [13/40] Iter[99/312]		Loss: 0.1548
2019-10-28 15:33:57,279 Training Epoch [13/40] Iter[100/312]		Loss: 0.1558
2019-10-28 15:33:57,359 Training Epoch [13/40] Iter[101/312]		Loss: 0.1555
2019-10-28 15:33:57,438 Training Epoch [13/40] Iter[102/312]		Loss: 0.1552
2019-10-28 15:33:57,518 Training Epoch [13/40] Iter[103/312]		Loss: 0.1555
2019-10-28 15:33:57,597 Training Epoch [13/40] Iter[104/312]		Loss: 0.1553
2019-10-28 15:33:57,677 Training Epoch [13/40] Iter[105/312]		Loss: 0.1551
2019-10-28 15:33:57,756 Training Epoch [13/40] Iter[106/312]		Loss: 0.1554
2019-10-28 15:33:57,835 Training Epoch [13/40] Iter[107/312]		Loss: 0.1549
2019-10-28 15:33:57,914 Training Epoch [13/40] Iter[108/312]		Loss: 0.1547
2019-10-28 15:33:57,993 Training Epoch [13/40] Iter[109/312]		Loss: 0.1544
2019-10-28 15:33:58,073 Training Epoch [13/40] Iter[110/312]		Loss: 0.1549
2019-10-28 15:33:58,153 Training Epoch [13/40] Iter[111/312]		Loss: 0.1546
2019-10-28 15:33:58,233 Training Epoch [13/40] Iter[112/312]		Loss: 0.1544
2019-10-28 15:33:58,313 Training Epoch [13/40] Iter[113/312]		Loss: 0.1545
2019-10-28 15:33:58,393 Training Epoch [13/40] Iter[114/312]		Loss: 0.1543
2019-10-28 15:33:58,474 Training Epoch [13/40] Iter[115/312]		Loss: 0.1546
2019-10-28 15:33:58,554 Training Epoch [13/40] Iter[116/312]		Loss: 0.1544
2019-10-28 15:33:58,634 Training Epoch [13/40] Iter[117/312]		Loss: 0.1540
2019-10-28 15:33:58,714 Training Epoch [13/40] Iter[118/312]		Loss: 0.1538
2019-10-28 15:33:58,793 Training Epoch [13/40] Iter[119/312]		Loss: 0.1537
2019-10-28 15:33:58,873 Training Epoch [13/40] Iter[120/312]		Loss: 0.1533
2019-10-28 15:33:58,953 Training Epoch [13/40] Iter[121/312]		Loss: 0.1532
2019-10-28 15:33:59,032 Training Epoch [13/40] Iter[122/312]		Loss: 0.1530
2019-10-28 15:33:59,112 Training Epoch [13/40] Iter[123/312]		Loss: 0.1527
2019-10-28 15:33:59,192 Training Epoch [13/40] Iter[124/312]		Loss: 0.1527
2019-10-28 15:33:59,272 Training Epoch [13/40] Iter[125/312]		Loss: 0.1524
2019-10-28 15:33:59,352 Training Epoch [13/40] Iter[126/312]		Loss: 0.1521
2019-10-28 15:33:59,431 Training Epoch [13/40] Iter[127/312]		Loss: 0.1520
2019-10-28 15:33:59,510 Training Epoch [13/40] Iter[128/312]		Loss: 0.1518
2019-10-28 15:33:59,590 Training Epoch [13/40] Iter[129/312]		Loss: 0.1520
2019-10-28 15:33:59,669 Training Epoch [13/40] Iter[130/312]		Loss: 0.1521
2019-10-28 15:33:59,749 Training Epoch [13/40] Iter[131/312]		Loss: 0.1524
2019-10-28 15:33:59,828 Training Epoch [13/40] Iter[132/312]		Loss: 0.1525
2019-10-28 15:33:59,907 Training Epoch [13/40] Iter[133/312]		Loss: 0.1523
2019-10-28 15:33:59,987 Training Epoch [13/40] Iter[134/312]		Loss: 0.1523
2019-10-28 15:34:00,066 Training Epoch [13/40] Iter[135/312]		Loss: 0.1521
2019-10-28 15:34:00,145 Training Epoch [13/40] Iter[136/312]		Loss: 0.1522
2019-10-28 15:34:00,224 Training Epoch [13/40] Iter[137/312]		Loss: 0.1526
2019-10-28 15:34:00,303 Training Epoch [13/40] Iter[138/312]		Loss: 0.1525
2019-10-28 15:34:00,383 Training Epoch [13/40] Iter[139/312]		Loss: 0.1527
2019-10-28 15:34:00,462 Training Epoch [13/40] Iter[140/312]		Loss: 0.1525
2019-10-28 15:34:00,541 Training Epoch [13/40] Iter[141/312]		Loss: 0.1527
2019-10-28 15:34:00,620 Training Epoch [13/40] Iter[142/312]		Loss: 0.1525
2019-10-28 15:34:00,700 Training Epoch [13/40] Iter[143/312]		Loss: 0.1526
2019-10-28 15:34:00,779 Training Epoch [13/40] Iter[144/312]		Loss: 0.1526
2019-10-28 15:34:00,858 Training Epoch [13/40] Iter[145/312]		Loss: 0.1522
2019-10-28 15:34:00,937 Training Epoch [13/40] Iter[146/312]		Loss: 0.1521
2019-10-28 15:34:01,016 Training Epoch [13/40] Iter[147/312]		Loss: 0.1522
2019-10-28 15:34:01,096 Training Epoch [13/40] Iter[148/312]		Loss: 0.1521
2019-10-28 15:34:01,176 Training Epoch [13/40] Iter[149/312]		Loss: 0.1518
2019-10-28 15:34:01,256 Training Epoch [13/40] Iter[150/312]		Loss: 0.1521
2019-10-28 15:34:01,336 Training Epoch [13/40] Iter[151/312]		Loss: 0.1528
2019-10-28 15:34:01,415 Training Epoch [13/40] Iter[152/312]		Loss: 0.1524
2019-10-28 15:34:01,495 Training Epoch [13/40] Iter[153/312]		Loss: 0.1524
2019-10-28 15:34:01,575 Training Epoch [13/40] Iter[154/312]		Loss: 0.1521
2019-10-28 15:34:01,655 Training Epoch [13/40] Iter[155/312]		Loss: 0.1525
2019-10-28 15:34:01,735 Training Epoch [13/40] Iter[156/312]		Loss: 0.1521
2019-10-28 15:34:01,814 Training Epoch [13/40] Iter[157/312]		Loss: 0.1520
2019-10-28 15:34:01,894 Training Epoch [13/40] Iter[158/312]		Loss: 0.1522
2019-10-28 15:34:01,973 Training Epoch [13/40] Iter[159/312]		Loss: 0.1518
2019-10-28 15:34:02,053 Training Epoch [13/40] Iter[160/312]		Loss: 0.1516
2019-10-28 15:34:02,133 Training Epoch [13/40] Iter[161/312]		Loss: 0.1518
2019-10-28 15:34:02,212 Training Epoch [13/40] Iter[162/312]		Loss: 0.1524
2019-10-28 15:34:02,292 Training Epoch [13/40] Iter[163/312]		Loss: 0.1523
2019-10-28 15:34:02,371 Training Epoch [13/40] Iter[164/312]		Loss: 0.1537
2019-10-28 15:34:02,450 Training Epoch [13/40] Iter[165/312]		Loss: 0.1544
2019-10-28 15:34:02,530 Training Epoch [13/40] Iter[166/312]		Loss: 0.1548
2019-10-28 15:34:02,609 Training Epoch [13/40] Iter[167/312]		Loss: 0.1545
2019-10-28 15:34:02,689 Training Epoch [13/40] Iter[168/312]		Loss: 0.1546
2019-10-28 15:34:02,768 Training Epoch [13/40] Iter[169/312]		Loss: 0.1548
2019-10-28 15:34:02,847 Training Epoch [13/40] Iter[170/312]		Loss: 0.1553
2019-10-28 15:34:02,927 Training Epoch [13/40] Iter[171/312]		Loss: 0.1551
2019-10-28 15:34:03,007 Training Epoch [13/40] Iter[172/312]		Loss: 0.1550
2019-10-28 15:34:03,086 Training Epoch [13/40] Iter[173/312]		Loss: 0.1552
2019-10-28 15:34:03,166 Training Epoch [13/40] Iter[174/312]		Loss: 0.1554
2019-10-28 15:34:03,245 Training Epoch [13/40] Iter[175/312]		Loss: 0.1555
2019-10-28 15:34:03,324 Training Epoch [13/40] Iter[176/312]		Loss: 0.1552
2019-10-28 15:34:03,404 Training Epoch [13/40] Iter[177/312]		Loss: 0.1554
2019-10-28 15:34:03,483 Training Epoch [13/40] Iter[178/312]		Loss: 0.1553
2019-10-28 15:34:03,568 Training Epoch [13/40] Iter[179/312]		Loss: 0.1553
2019-10-28 15:34:03,647 Training Epoch [13/40] Iter[180/312]		Loss: 0.1554
2019-10-28 15:34:03,726 Training Epoch [13/40] Iter[181/312]		Loss: 0.1554
2019-10-28 15:34:03,805 Training Epoch [13/40] Iter[182/312]		Loss: 0.1552
2019-10-28 15:34:03,887 Training Epoch [13/40] Iter[183/312]		Loss: 0.1555
2019-10-28 15:34:03,966 Training Epoch [13/40] Iter[184/312]		Loss: 0.1556
2019-10-28 15:34:04,045 Training Epoch [13/40] Iter[185/312]		Loss: 0.1557
2019-10-28 15:34:04,124 Training Epoch [13/40] Iter[186/312]		Loss: 0.1555
2019-10-28 15:34:04,204 Training Epoch [13/40] Iter[187/312]		Loss: 0.1553
2019-10-28 15:34:04,284 Training Epoch [13/40] Iter[188/312]		Loss: 0.1553
2019-10-28 15:34:04,363 Training Epoch [13/40] Iter[189/312]		Loss: 0.1552
2019-10-28 15:34:04,443 Training Epoch [13/40] Iter[190/312]		Loss: 0.1554
2019-10-28 15:34:04,522 Training Epoch [13/40] Iter[191/312]		Loss: 0.1554
2019-10-28 15:34:04,601 Training Epoch [13/40] Iter[192/312]		Loss: 0.1555
2019-10-28 15:34:04,680 Training Epoch [13/40] Iter[193/312]		Loss: 0.1554
2019-10-28 15:34:04,760 Training Epoch [13/40] Iter[194/312]		Loss: 0.1557
2019-10-28 15:34:04,839 Training Epoch [13/40] Iter[195/312]		Loss: 0.1554
2019-10-28 15:34:04,919 Training Epoch [13/40] Iter[196/312]		Loss: 0.1554
2019-10-28 15:34:04,998 Training Epoch [13/40] Iter[197/312]		Loss: 0.1553
2019-10-28 15:34:05,078 Training Epoch [13/40] Iter[198/312]		Loss: 0.1556
2019-10-28 15:34:05,157 Training Epoch [13/40] Iter[199/312]		Loss: 0.1555
2019-10-28 15:34:05,237 Training Epoch [13/40] Iter[200/312]		Loss: 0.1554
2019-10-28 15:34:05,317 Training Epoch [13/40] Iter[201/312]		Loss: 0.1552
2019-10-28 15:34:05,397 Training Epoch [13/40] Iter[202/312]		Loss: 0.1553
2019-10-28 15:34:05,477 Training Epoch [13/40] Iter[203/312]		Loss: 0.1552
2019-10-28 15:34:05,556 Training Epoch [13/40] Iter[204/312]		Loss: 0.1551
2019-10-28 15:34:05,636 Training Epoch [13/40] Iter[205/312]		Loss: 0.1552
2019-10-28 15:34:05,716 Training Epoch [13/40] Iter[206/312]		Loss: 0.1549
2019-10-28 15:34:05,795 Training Epoch [13/40] Iter[207/312]		Loss: 0.1549
2019-10-28 15:34:05,875 Training Epoch [13/40] Iter[208/312]		Loss: 0.1549
2019-10-28 15:34:05,956 Training Epoch [13/40] Iter[209/312]		Loss: 0.1547
2019-10-28 15:34:06,035 Training Epoch [13/40] Iter[210/312]		Loss: 0.1548
2019-10-28 15:34:06,115 Training Epoch [13/40] Iter[211/312]		Loss: 0.1546
2019-10-28 15:34:06,195 Training Epoch [13/40] Iter[212/312]		Loss: 0.1548
2019-10-28 15:34:06,275 Training Epoch [13/40] Iter[213/312]		Loss: 0.1548
2019-10-28 15:34:06,354 Training Epoch [13/40] Iter[214/312]		Loss: 0.1551
2019-10-28 15:34:06,434 Training Epoch [13/40] Iter[215/312]		Loss: 0.1550
2019-10-28 15:34:06,514 Training Epoch [13/40] Iter[216/312]		Loss: 0.1550
2019-10-28 15:34:06,594 Training Epoch [13/40] Iter[217/312]		Loss: 0.1547
2019-10-28 15:34:06,673 Training Epoch [13/40] Iter[218/312]		Loss: 0.1546
2019-10-28 15:34:06,753 Training Epoch [13/40] Iter[219/312]		Loss: 0.1551
2019-10-28 15:34:06,838 Training Epoch [13/40] Iter[220/312]		Loss: 0.1549
2019-10-28 15:34:06,918 Training Epoch [13/40] Iter[221/312]		Loss: 0.1549
2019-10-28 15:34:06,997 Training Epoch [13/40] Iter[222/312]		Loss: 0.1547
2019-10-28 15:34:07,077 Training Epoch [13/40] Iter[223/312]		Loss: 0.1551
2019-10-28 15:34:07,156 Training Epoch [13/40] Iter[224/312]		Loss: 0.1549
2019-10-28 15:34:07,236 Training Epoch [13/40] Iter[225/312]		Loss: 0.1550
2019-10-28 15:34:07,316 Training Epoch [13/40] Iter[226/312]		Loss: 0.1550
2019-10-28 15:34:07,395 Training Epoch [13/40] Iter[227/312]		Loss: 0.1550
2019-10-28 15:34:07,475 Training Epoch [13/40] Iter[228/312]		Loss: 0.1549
2019-10-28 15:34:07,554 Training Epoch [13/40] Iter[229/312]		Loss: 0.1550
2019-10-28 15:34:07,634 Training Epoch [13/40] Iter[230/312]		Loss: 0.1550
2019-10-28 15:34:07,714 Training Epoch [13/40] Iter[231/312]		Loss: 0.1555
2019-10-28 15:34:07,793 Training Epoch [13/40] Iter[232/312]		Loss: 0.1556
2019-10-28 15:34:07,872 Training Epoch [13/40] Iter[233/312]		Loss: 0.1555
2019-10-28 15:34:07,952 Training Epoch [13/40] Iter[234/312]		Loss: 0.1555
2019-10-28 15:34:08,031 Training Epoch [13/40] Iter[235/312]		Loss: 0.1555
2019-10-28 15:34:08,110 Training Epoch [13/40] Iter[236/312]		Loss: 0.1555
2019-10-28 15:34:08,190 Training Epoch [13/40] Iter[237/312]		Loss: 0.1558
2019-10-28 15:34:08,269 Training Epoch [13/40] Iter[238/312]		Loss: 0.1559
2019-10-28 15:34:08,348 Training Epoch [13/40] Iter[239/312]		Loss: 0.1559
2019-10-28 15:34:08,428 Training Epoch [13/40] Iter[240/312]		Loss: 0.1560
2019-10-28 15:34:08,507 Training Epoch [13/40] Iter[241/312]		Loss: 0.1560
2019-10-28 15:34:08,586 Training Epoch [13/40] Iter[242/312]		Loss: 0.1558
2019-10-28 15:34:08,665 Training Epoch [13/40] Iter[243/312]		Loss: 0.1557
2019-10-28 15:34:08,745 Training Epoch [13/40] Iter[244/312]		Loss: 0.1555
2019-10-28 15:34:08,824 Training Epoch [13/40] Iter[245/312]		Loss: 0.1556
2019-10-28 15:34:08,903 Training Epoch [13/40] Iter[246/312]		Loss: 0.1558
2019-10-28 15:34:08,983 Training Epoch [13/40] Iter[247/312]		Loss: 0.1559
2019-10-28 15:34:09,062 Training Epoch [13/40] Iter[248/312]		Loss: 0.1559
2019-10-28 15:34:09,141 Training Epoch [13/40] Iter[249/312]		Loss: 0.1564
2019-10-28 15:34:09,221 Training Epoch [13/40] Iter[250/312]		Loss: 0.1562
2019-10-28 15:34:09,301 Training Epoch [13/40] Iter[251/312]		Loss: 0.1565
2019-10-28 15:34:09,380 Training Epoch [13/40] Iter[252/312]		Loss: 0.1566
2019-10-28 15:34:09,459 Training Epoch [13/40] Iter[253/312]		Loss: 0.1566
2019-10-28 15:34:09,539 Training Epoch [13/40] Iter[254/312]		Loss: 0.1564
2019-10-28 15:34:09,618 Training Epoch [13/40] Iter[255/312]		Loss: 0.1561
2019-10-28 15:34:09,698 Training Epoch [13/40] Iter[256/312]		Loss: 0.1560
2019-10-28 15:34:09,777 Training Epoch [13/40] Iter[257/312]		Loss: 0.1558
2019-10-28 15:34:09,856 Training Epoch [13/40] Iter[258/312]		Loss: 0.1557
2019-10-28 15:34:09,935 Training Epoch [13/40] Iter[259/312]		Loss: 0.1560
2019-10-28 15:34:10,019 Training Epoch [13/40] Iter[260/312]		Loss: 0.1558
2019-10-28 15:34:10,098 Training Epoch [13/40] Iter[261/312]		Loss: 0.1558
2019-10-28 15:34:10,178 Training Epoch [13/40] Iter[262/312]		Loss: 0.1556
2019-10-28 15:34:10,257 Training Epoch [13/40] Iter[263/312]		Loss: 0.1555
2019-10-28 15:34:10,336 Training Epoch [13/40] Iter[264/312]		Loss: 0.1554
2019-10-28 15:34:10,416 Training Epoch [13/40] Iter[265/312]		Loss: 0.1554
2019-10-28 15:34:10,495 Training Epoch [13/40] Iter[266/312]		Loss: 0.1552
2019-10-28 15:34:10,575 Training Epoch [13/40] Iter[267/312]		Loss: 0.1550
2019-10-28 15:34:10,654 Training Epoch [13/40] Iter[268/312]		Loss: 0.1549
2019-10-28 15:34:10,733 Training Epoch [13/40] Iter[269/312]		Loss: 0.1549
2019-10-28 15:34:10,812 Training Epoch [13/40] Iter[270/312]		Loss: 0.1550
2019-10-28 15:34:10,892 Training Epoch [13/40] Iter[271/312]		Loss: 0.1549
2019-10-28 15:34:10,971 Training Epoch [13/40] Iter[272/312]		Loss: 0.1548
2019-10-28 15:34:11,050 Training Epoch [13/40] Iter[273/312]		Loss: 0.1546
2019-10-28 15:34:11,129 Training Epoch [13/40] Iter[274/312]		Loss: 0.1545
2019-10-28 15:34:11,209 Training Epoch [13/40] Iter[275/312]		Loss: 0.1546
2019-10-28 15:34:11,288 Training Epoch [13/40] Iter[276/312]		Loss: 0.1544
2019-10-28 15:34:11,367 Training Epoch [13/40] Iter[277/312]		Loss: 0.1543
2019-10-28 15:34:11,447 Training Epoch [13/40] Iter[278/312]		Loss: 0.1543
2019-10-28 15:34:11,526 Training Epoch [13/40] Iter[279/312]		Loss: 0.1541
2019-10-28 15:34:11,605 Training Epoch [13/40] Iter[280/312]		Loss: 0.1541
2019-10-28 15:34:11,685 Training Epoch [13/40] Iter[281/312]		Loss: 0.1540
2019-10-28 15:34:11,764 Training Epoch [13/40] Iter[282/312]		Loss: 0.1538
2019-10-28 15:34:11,844 Training Epoch [13/40] Iter[283/312]		Loss: 0.1540
2019-10-28 15:34:11,924 Training Epoch [13/40] Iter[284/312]		Loss: 0.1543
2019-10-28 15:34:12,003 Training Epoch [13/40] Iter[285/312]		Loss: 0.1546
2019-10-28 15:34:12,082 Training Epoch [13/40] Iter[286/312]		Loss: 0.1546
2019-10-28 15:34:12,162 Training Epoch [13/40] Iter[287/312]		Loss: 0.1550
2019-10-28 15:34:12,241 Training Epoch [13/40] Iter[288/312]		Loss: 0.1548
2019-10-28 15:34:12,320 Training Epoch [13/40] Iter[289/312]		Loss: 0.1548
2019-10-28 15:34:12,400 Training Epoch [13/40] Iter[290/312]		Loss: 0.1548
2019-10-28 15:34:12,479 Training Epoch [13/40] Iter[291/312]		Loss: 0.1547
2019-10-28 15:34:12,558 Training Epoch [13/40] Iter[292/312]		Loss: 0.1546
2019-10-28 15:34:12,638 Training Epoch [13/40] Iter[293/312]		Loss: 0.1545
2019-10-28 15:34:12,717 Training Epoch [13/40] Iter[294/312]		Loss: 0.1543
2019-10-28 15:34:12,796 Training Epoch [13/40] Iter[295/312]		Loss: 0.1543
2019-10-28 15:34:12,875 Training Epoch [13/40] Iter[296/312]		Loss: 0.1541
2019-10-28 15:34:12,954 Training Epoch [13/40] Iter[297/312]		Loss: 0.1539
2019-10-28 15:34:13,033 Training Epoch [13/40] Iter[298/312]		Loss: 0.1541
2019-10-28 15:34:13,113 Training Epoch [13/40] Iter[299/312]		Loss: 0.1542
2019-10-28 15:34:13,192 Training Epoch [13/40] Iter[300/312]		Loss: 0.1541
2019-10-28 15:34:13,272 Training Epoch [13/40] Iter[301/312]		Loss: 0.1542
2019-10-28 15:34:13,351 Training Epoch [13/40] Iter[302/312]		Loss: 0.1541
2019-10-28 15:34:13,431 Training Epoch [13/40] Iter[303/312]		Loss: 0.1541
2019-10-28 15:34:13,510 Training Epoch [13/40] Iter[304/312]		Loss: 0.1543
2019-10-28 15:34:13,589 Training Epoch [13/40] Iter[305/312]		Loss: 0.1541
2019-10-28 15:34:13,667 Training Epoch [13/40] Iter[306/312]		Loss: 0.1541
2019-10-28 15:34:13,746 Training Epoch [13/40] Iter[307/312]		Loss: 0.1540
2019-10-28 15:34:13,824 Training Epoch [13/40] Iter[308/312]		Loss: 0.1541
2019-10-28 15:34:13,903 Training Epoch [13/40] Iter[309/312]		Loss: 0.1540
2019-10-28 15:34:13,981 Training Epoch [13/40] Iter[310/312]		Loss: 0.1540
2019-10-28 15:34:14,060 Training Epoch [13/40] Iter[311/312]		Loss: 0.1540
2019-10-28 15:34:14,098 Training Epoch [13/40] Iter[312/312]		Loss: 0.1539
2019-10-28 15:34:14,537 Testing Epoch [13/40] Iter[0/62]		Loss: 0.1563
2019-10-28 15:34:14,554 Testing Epoch [13/40] Iter[1/62]		Loss: 0.1581
2019-10-28 15:34:14,588 Testing Epoch [13/40] Iter[2/62]		Loss: 0.1421
2019-10-28 15:34:14,618 Testing Epoch [13/40] Iter[3/62]		Loss: 0.1443
2019-10-28 15:34:14,636 Testing Epoch [13/40] Iter[4/62]		Loss: 0.1487
2019-10-28 15:34:14,652 Testing Epoch [13/40] Iter[5/62]		Loss: 0.1426
2019-10-28 15:34:14,678 Testing Epoch [13/40] Iter[6/62]		Loss: 0.1454
2019-10-28 15:34:14,706 Testing Epoch [13/40] Iter[7/62]		Loss: 0.1458
2019-10-28 15:34:14,729 Testing Epoch [13/40] Iter[8/62]		Loss: 0.1478
2019-10-28 15:34:14,745 Testing Epoch [13/40] Iter[9/62]		Loss: 0.1463
2019-10-28 15:34:14,766 Testing Epoch [13/40] Iter[10/62]		Loss: 0.1476
2019-10-28 15:34:14,790 Testing Epoch [13/40] Iter[11/62]		Loss: 0.1562
2019-10-28 15:34:14,814 Testing Epoch [13/40] Iter[12/62]		Loss: 0.1570
2019-10-28 15:34:14,832 Testing Epoch [13/40] Iter[13/62]		Loss: 0.1580
2019-10-28 15:34:14,865 Testing Epoch [13/40] Iter[14/62]		Loss: 0.1729
2019-10-28 15:34:14,881 Testing Epoch [13/40] Iter[15/62]		Loss: 0.1750
2019-10-28 15:34:14,909 Testing Epoch [13/40] Iter[16/62]		Loss: 0.1714
2019-10-28 15:34:14,927 Testing Epoch [13/40] Iter[17/62]		Loss: 0.1708
2019-10-28 15:34:14,953 Testing Epoch [13/40] Iter[18/62]		Loss: 0.1670
2019-10-28 15:34:14,971 Testing Epoch [13/40] Iter[19/62]		Loss: 0.1649
2019-10-28 15:34:14,997 Testing Epoch [13/40] Iter[20/62]		Loss: 0.1663
2019-10-28 15:34:15,015 Testing Epoch [13/40] Iter[21/62]		Loss: 0.1647
2019-10-28 15:34:15,042 Testing Epoch [13/40] Iter[22/62]		Loss: 0.1658
2019-10-28 15:34:15,069 Testing Epoch [13/40] Iter[23/62]		Loss: 0.1642
2019-10-28 15:34:15,093 Testing Epoch [13/40] Iter[24/62]		Loss: 0.1686
2019-10-28 15:34:15,111 Testing Epoch [13/40] Iter[25/62]		Loss: 0.1667
2019-10-28 15:34:15,129 Testing Epoch [13/40] Iter[26/62]		Loss: 0.1654
2019-10-28 15:34:15,158 Testing Epoch [13/40] Iter[27/62]		Loss: 0.1734
2019-10-28 15:34:15,176 Testing Epoch [13/40] Iter[28/62]		Loss: 0.1769
2019-10-28 15:34:15,194 Testing Epoch [13/40] Iter[29/62]		Loss: 0.1769
2019-10-28 15:34:15,230 Testing Epoch [13/40] Iter[30/62]		Loss: 0.1778
2019-10-28 15:34:15,250 Testing Epoch [13/40] Iter[31/62]		Loss: 0.1765
2019-10-28 15:34:15,278 Testing Epoch [13/40] Iter[32/62]		Loss: 0.1782
2019-10-28 15:34:15,296 Testing Epoch [13/40] Iter[33/62]		Loss: 0.1776
2019-10-28 15:34:15,314 Testing Epoch [13/40] Iter[34/62]		Loss: 0.1799
2019-10-28 15:34:15,341 Testing Epoch [13/40] Iter[35/62]		Loss: 0.1792
2019-10-28 15:34:15,371 Testing Epoch [13/40] Iter[36/62]		Loss: 0.1774
2019-10-28 15:34:15,390 Testing Epoch [13/40] Iter[37/62]		Loss: 0.1762
2019-10-28 15:34:15,407 Testing Epoch [13/40] Iter[38/62]		Loss: 0.1749
2019-10-28 15:34:15,439 Testing Epoch [13/40] Iter[39/62]		Loss: 0.1756
2019-10-28 15:34:15,457 Testing Epoch [13/40] Iter[40/62]		Loss: 0.1773
2019-10-28 15:34:15,489 Testing Epoch [13/40] Iter[41/62]		Loss: 0.1797
2019-10-28 15:34:15,507 Testing Epoch [13/40] Iter[42/62]		Loss: 0.1776
2019-10-28 15:34:15,533 Testing Epoch [13/40] Iter[43/62]		Loss: 0.1768
2019-10-28 15:34:15,558 Testing Epoch [13/40] Iter[44/62]		Loss: 0.1748
2019-10-28 15:34:15,576 Testing Epoch [13/40] Iter[45/62]		Loss: 0.1746
2019-10-28 15:34:15,594 Testing Epoch [13/40] Iter[46/62]		Loss: 0.1740
2019-10-28 15:34:15,625 Testing Epoch [13/40] Iter[47/62]		Loss: 0.1796
2019-10-28 15:34:15,652 Testing Epoch [13/40] Iter[48/62]		Loss: 0.1784
2019-10-28 15:34:15,670 Testing Epoch [13/40] Iter[49/62]		Loss: 0.1808
2019-10-28 15:34:15,689 Testing Epoch [13/40] Iter[50/62]		Loss: 0.1801
2019-10-28 15:34:15,714 Testing Epoch [13/40] Iter[51/62]		Loss: 0.1800
2019-10-28 15:34:15,745 Testing Epoch [13/40] Iter[52/62]		Loss: 0.1785
2019-10-28 15:34:15,763 Testing Epoch [13/40] Iter[53/62]		Loss: 0.1791
2019-10-28 15:34:15,781 Testing Epoch [13/40] Iter[54/62]		Loss: 0.1780
2019-10-28 15:34:15,799 Testing Epoch [13/40] Iter[55/62]		Loss: 0.1778
2019-10-28 15:34:15,816 Testing Epoch [13/40] Iter[56/62]		Loss: 0.1770
2019-10-28 15:34:15,833 Testing Epoch [13/40] Iter[57/62]		Loss: 0.1772
2019-10-28 15:34:15,850 Testing Epoch [13/40] Iter[58/62]		Loss: 0.1767
2019-10-28 15:34:15,866 Testing Epoch [13/40] Iter[59/62]		Loss: 0.1778
2019-10-28 15:34:15,883 Testing Epoch [13/40] Iter[60/62]		Loss: 0.1771
2019-10-28 15:34:15,900 Testing Epoch [13/40] Iter[61/62]		Loss: 0.1773
2019-10-28 15:34:15,909 Testing Epoch [13/40] Iter[62/62]		Loss: 0.1783
2019-10-28 15:34:15,982 Saving the Model
2019-10-28 15:34:16,421 Training Epoch [14/40] Iter[0/312]		Loss: 0.1212
2019-10-28 15:34:16,501 Training Epoch [14/40] Iter[1/312]		Loss: 0.1264
2019-10-28 15:34:16,583 Training Epoch [14/40] Iter[2/312]		Loss: 0.1269
2019-10-28 15:34:16,661 Training Epoch [14/40] Iter[3/312]		Loss: 0.1346
2019-10-28 15:34:16,747 Training Epoch [14/40] Iter[4/312]		Loss: 0.1385
2019-10-28 15:34:16,824 Training Epoch [14/40] Iter[5/312]		Loss: 0.1404
2019-10-28 15:34:16,907 Training Epoch [14/40] Iter[6/312]		Loss: 0.1373
2019-10-28 15:34:16,984 Training Epoch [14/40] Iter[7/312]		Loss: 0.1372
2019-10-28 15:34:17,063 Training Epoch [14/40] Iter[8/312]		Loss: 0.1510
2019-10-28 15:34:17,142 Training Epoch [14/40] Iter[9/312]		Loss: 0.1480
2019-10-28 15:34:17,222 Training Epoch [14/40] Iter[10/312]		Loss: 0.1458
2019-10-28 15:34:17,301 Training Epoch [14/40] Iter[11/312]		Loss: 0.1407
2019-10-28 15:34:17,380 Training Epoch [14/40] Iter[12/312]		Loss: 0.1449
2019-10-28 15:34:17,460 Training Epoch [14/40] Iter[13/312]		Loss: 0.1420
2019-10-28 15:34:17,539 Training Epoch [14/40] Iter[14/312]		Loss: 0.1398
2019-10-28 15:34:17,618 Training Epoch [14/40] Iter[15/312]		Loss: 0.1381
2019-10-28 15:34:17,697 Training Epoch [14/40] Iter[16/312]		Loss: 0.1376
2019-10-28 15:34:17,776 Training Epoch [14/40] Iter[17/312]		Loss: 0.1398
2019-10-28 15:34:17,855 Training Epoch [14/40] Iter[18/312]		Loss: 0.1388
2019-10-28 15:34:17,935 Training Epoch [14/40] Iter[19/312]		Loss: 0.1370
2019-10-28 15:34:18,014 Training Epoch [14/40] Iter[20/312]		Loss: 0.1351
2019-10-28 15:34:18,093 Training Epoch [14/40] Iter[21/312]		Loss: 0.1334
2019-10-28 15:34:18,172 Training Epoch [14/40] Iter[22/312]		Loss: 0.1356
2019-10-28 15:34:18,251 Training Epoch [14/40] Iter[23/312]		Loss: 0.1375
2019-10-28 15:34:18,330 Training Epoch [14/40] Iter[24/312]		Loss: 0.1369
2019-10-28 15:34:18,410 Training Epoch [14/40] Iter[25/312]		Loss: 0.1354
2019-10-28 15:34:18,489 Training Epoch [14/40] Iter[26/312]		Loss: 0.1356
2019-10-28 15:34:18,568 Training Epoch [14/40] Iter[27/312]		Loss: 0.1373
2019-10-28 15:34:18,647 Training Epoch [14/40] Iter[28/312]		Loss: 0.1365
2019-10-28 15:34:18,726 Training Epoch [14/40] Iter[29/312]		Loss: 0.1356
2019-10-28 15:34:18,805 Training Epoch [14/40] Iter[30/312]		Loss: 0.1378
2019-10-28 15:34:18,884 Training Epoch [14/40] Iter[31/312]		Loss: 0.1401
2019-10-28 15:34:18,963 Training Epoch [14/40] Iter[32/312]		Loss: 0.1425
2019-10-28 15:34:19,042 Training Epoch [14/40] Iter[33/312]		Loss: 0.1409
2019-10-28 15:34:19,122 Training Epoch [14/40] Iter[34/312]		Loss: 0.1401
2019-10-28 15:34:19,201 Training Epoch [14/40] Iter[35/312]		Loss: 0.1389
2019-10-28 15:34:19,280 Training Epoch [14/40] Iter[36/312]		Loss: 0.1387
2019-10-28 15:34:19,359 Training Epoch [14/40] Iter[37/312]		Loss: 0.1388
2019-10-28 15:34:19,439 Training Epoch [14/40] Iter[38/312]		Loss: 0.1384
2019-10-28 15:34:19,518 Training Epoch [14/40] Iter[39/312]		Loss: 0.1383
2019-10-28 15:34:19,597 Training Epoch [14/40] Iter[40/312]		Loss: 0.1379
2019-10-28 15:34:19,676 Training Epoch [14/40] Iter[41/312]		Loss: 0.1372
2019-10-28 15:34:19,755 Training Epoch [14/40] Iter[42/312]		Loss: 0.1368
2019-10-28 15:34:19,834 Training Epoch [14/40] Iter[43/312]		Loss: 0.1363
2019-10-28 15:34:19,913 Training Epoch [14/40] Iter[44/312]		Loss: 0.1370
2019-10-28 15:34:19,992 Training Epoch [14/40] Iter[45/312]		Loss: 0.1378
2019-10-28 15:34:20,071 Training Epoch [14/40] Iter[46/312]		Loss: 0.1379
2019-10-28 15:34:20,150 Training Epoch [14/40] Iter[47/312]		Loss: 0.1384
2019-10-28 15:34:20,230 Training Epoch [14/40] Iter[48/312]		Loss: 0.1386
2019-10-28 15:34:20,309 Training Epoch [14/40] Iter[49/312]		Loss: 0.1395
2019-10-28 15:34:20,388 Training Epoch [14/40] Iter[50/312]		Loss: 0.1398
2019-10-28 15:34:20,467 Training Epoch [14/40] Iter[51/312]		Loss: 0.1394
2019-10-28 15:34:20,547 Training Epoch [14/40] Iter[52/312]		Loss: 0.1397
2019-10-28 15:34:20,626 Training Epoch [14/40] Iter[53/312]		Loss: 0.1402
2019-10-28 15:34:20,705 Training Epoch [14/40] Iter[54/312]		Loss: 0.1391
2019-10-28 15:34:20,784 Training Epoch [14/40] Iter[55/312]		Loss: 0.1397
2019-10-28 15:34:20,864 Training Epoch [14/40] Iter[56/312]		Loss: 0.1401
2019-10-28 15:34:20,943 Training Epoch [14/40] Iter[57/312]		Loss: 0.1402
2019-10-28 15:34:21,022 Training Epoch [14/40] Iter[58/312]		Loss: 0.1402
2019-10-28 15:34:21,103 Training Epoch [14/40] Iter[59/312]		Loss: 0.1393
2019-10-28 15:34:21,182 Training Epoch [14/40] Iter[60/312]		Loss: 0.1396
2019-10-28 15:34:21,261 Training Epoch [14/40] Iter[61/312]		Loss: 0.1403
2019-10-28 15:34:21,340 Training Epoch [14/40] Iter[62/312]		Loss: 0.1403
2019-10-28 15:34:21,420 Training Epoch [14/40] Iter[63/312]		Loss: 0.1399
2019-10-28 15:34:21,499 Training Epoch [14/40] Iter[64/312]		Loss: 0.1397
2019-10-28 15:34:21,579 Training Epoch [14/40] Iter[65/312]		Loss: 0.1395
2019-10-28 15:34:21,658 Training Epoch [14/40] Iter[66/312]		Loss: 0.1390
2019-10-28 15:34:21,738 Training Epoch [14/40] Iter[67/312]		Loss: 0.1394
2019-10-28 15:34:21,818 Training Epoch [14/40] Iter[68/312]		Loss: 0.1389
2019-10-28 15:34:21,898 Training Epoch [14/40] Iter[69/312]		Loss: 0.1384
2019-10-28 15:34:21,979 Training Epoch [14/40] Iter[70/312]		Loss: 0.1389
2019-10-28 15:34:22,059 Training Epoch [14/40] Iter[71/312]		Loss: 0.1385
2019-10-28 15:34:22,139 Training Epoch [14/40] Iter[72/312]		Loss: 0.1380
2019-10-28 15:34:22,223 Training Epoch [14/40] Iter[73/312]		Loss: 0.1380
2019-10-28 15:34:22,303 Training Epoch [14/40] Iter[74/312]		Loss: 0.1394
2019-10-28 15:34:22,387 Training Epoch [14/40] Iter[75/312]		Loss: 0.1389
2019-10-28 15:34:22,467 Training Epoch [14/40] Iter[76/312]		Loss: 0.1388
2019-10-28 15:34:22,547 Training Epoch [14/40] Iter[77/312]		Loss: 0.1387
2019-10-28 15:34:22,626 Training Epoch [14/40] Iter[78/312]		Loss: 0.1383
2019-10-28 15:34:22,707 Training Epoch [14/40] Iter[79/312]		Loss: 0.1384
2019-10-28 15:34:22,791 Training Epoch [14/40] Iter[80/312]		Loss: 0.1386
2019-10-28 15:34:22,870 Training Epoch [14/40] Iter[81/312]		Loss: 0.1382
2019-10-28 15:34:22,951 Training Epoch [14/40] Iter[82/312]		Loss: 0.1379
2019-10-28 15:34:23,031 Training Epoch [14/40] Iter[83/312]		Loss: 0.1375
2019-10-28 15:34:23,111 Training Epoch [14/40] Iter[84/312]		Loss: 0.1384
2019-10-28 15:34:23,190 Training Epoch [14/40] Iter[85/312]		Loss: 0.1385
2019-10-28 15:34:23,271 Training Epoch [14/40] Iter[86/312]		Loss: 0.1387
2019-10-28 15:34:23,351 Training Epoch [14/40] Iter[87/312]		Loss: 0.1386
2019-10-28 15:34:23,431 Training Epoch [14/40] Iter[88/312]		Loss: 0.1388
2019-10-28 15:34:23,515 Training Epoch [14/40] Iter[89/312]		Loss: 0.1386
2019-10-28 15:34:23,595 Training Epoch [14/40] Iter[90/312]		Loss: 0.1400
2019-10-28 15:34:23,674 Training Epoch [14/40] Iter[91/312]		Loss: 0.1398
2019-10-28 15:34:23,755 Training Epoch [14/40] Iter[92/312]		Loss: 0.1396
2019-10-28 15:34:23,835 Training Epoch [14/40] Iter[93/312]		Loss: 0.1404
2019-10-28 15:34:23,915 Training Epoch [14/40] Iter[94/312]		Loss: 0.1404
2019-10-28 15:34:23,995 Training Epoch [14/40] Iter[95/312]		Loss: 0.1401
2019-10-28 15:34:24,075 Training Epoch [14/40] Iter[96/312]		Loss: 0.1400
2019-10-28 15:34:24,155 Training Epoch [14/40] Iter[97/312]		Loss: 0.1402
2019-10-28 15:34:24,235 Training Epoch [14/40] Iter[98/312]		Loss: 0.1397
2019-10-28 15:34:24,317 Training Epoch [14/40] Iter[99/312]		Loss: 0.1397
2019-10-28 15:34:24,397 Training Epoch [14/40] Iter[100/312]		Loss: 0.1398
2019-10-28 15:34:24,476 Training Epoch [14/40] Iter[101/312]		Loss: 0.1395
2019-10-28 15:34:24,555 Training Epoch [14/40] Iter[102/312]		Loss: 0.1392
2019-10-28 15:34:24,634 Training Epoch [14/40] Iter[103/312]		Loss: 0.1392
2019-10-28 15:34:24,713 Training Epoch [14/40] Iter[104/312]		Loss: 0.1389
2019-10-28 15:34:24,792 Training Epoch [14/40] Iter[105/312]		Loss: 0.1395
2019-10-28 15:34:24,871 Training Epoch [14/40] Iter[106/312]		Loss: 0.1403
2019-10-28 15:34:24,950 Training Epoch [14/40] Iter[107/312]		Loss: 0.1399
2019-10-28 15:34:25,029 Training Epoch [14/40] Iter[108/312]		Loss: 0.1400
2019-10-28 15:34:25,109 Training Epoch [14/40] Iter[109/312]		Loss: 0.1408
2019-10-28 15:34:25,188 Training Epoch [14/40] Iter[110/312]		Loss: 0.1405
2019-10-28 15:34:25,267 Training Epoch [14/40] Iter[111/312]		Loss: 0.1405
2019-10-28 15:34:25,347 Training Epoch [14/40] Iter[112/312]		Loss: 0.1402
2019-10-28 15:34:25,426 Training Epoch [14/40] Iter[113/312]		Loss: 0.1406
2019-10-28 15:34:25,505 Training Epoch [14/40] Iter[114/312]		Loss: 0.1412
2019-10-28 15:34:25,584 Training Epoch [14/40] Iter[115/312]		Loss: 0.1416
2019-10-28 15:34:25,664 Training Epoch [14/40] Iter[116/312]		Loss: 0.1418
2019-10-28 15:34:25,743 Training Epoch [14/40] Iter[117/312]		Loss: 0.1417
2019-10-28 15:34:25,822 Training Epoch [14/40] Iter[118/312]		Loss: 0.1413
2019-10-28 15:34:25,901 Training Epoch [14/40] Iter[119/312]		Loss: 0.1411
2019-10-28 15:34:25,980 Training Epoch [14/40] Iter[120/312]		Loss: 0.1407
2019-10-28 15:34:26,060 Training Epoch [14/40] Iter[121/312]		Loss: 0.1406
2019-10-28 15:34:26,139 Training Epoch [14/40] Iter[122/312]		Loss: 0.1412
2019-10-28 15:34:26,219 Training Epoch [14/40] Iter[123/312]		Loss: 0.1414
2019-10-28 15:34:26,299 Training Epoch [14/40] Iter[124/312]		Loss: 0.1417
2019-10-28 15:34:26,378 Training Epoch [14/40] Iter[125/312]		Loss: 0.1417
2019-10-28 15:34:26,457 Training Epoch [14/40] Iter[126/312]		Loss: 0.1415
2019-10-28 15:34:26,537 Training Epoch [14/40] Iter[127/312]		Loss: 0.1415
2019-10-28 15:34:26,616 Training Epoch [14/40] Iter[128/312]		Loss: 0.1422
2019-10-28 15:34:26,695 Training Epoch [14/40] Iter[129/312]		Loss: 0.1418
2019-10-28 15:34:26,775 Training Epoch [14/40] Iter[130/312]		Loss: 0.1424
2019-10-28 15:34:26,854 Training Epoch [14/40] Iter[131/312]		Loss: 0.1425
2019-10-28 15:34:26,934 Training Epoch [14/40] Iter[132/312]		Loss: 0.1423
2019-10-28 15:34:27,013 Training Epoch [14/40] Iter[133/312]		Loss: 0.1423
2019-10-28 15:34:27,092 Training Epoch [14/40] Iter[134/312]		Loss: 0.1425
2019-10-28 15:34:27,172 Training Epoch [14/40] Iter[135/312]		Loss: 0.1426
2019-10-28 15:34:27,251 Training Epoch [14/40] Iter[136/312]		Loss: 0.1424
2019-10-28 15:34:27,330 Training Epoch [14/40] Iter[137/312]		Loss: 0.1421
2019-10-28 15:34:27,410 Training Epoch [14/40] Iter[138/312]		Loss: 0.1424
2019-10-28 15:34:27,489 Training Epoch [14/40] Iter[139/312]		Loss: 0.1426
2019-10-28 15:34:27,569 Training Epoch [14/40] Iter[140/312]		Loss: 0.1425
2019-10-28 15:34:27,648 Training Epoch [14/40] Iter[141/312]		Loss: 0.1425
2019-10-28 15:34:27,727 Training Epoch [14/40] Iter[142/312]		Loss: 0.1424
2019-10-28 15:34:27,806 Training Epoch [14/40] Iter[143/312]		Loss: 0.1425
2019-10-28 15:34:27,885 Training Epoch [14/40] Iter[144/312]		Loss: 0.1422
2019-10-28 15:34:27,965 Training Epoch [14/40] Iter[145/312]		Loss: 0.1421
2019-10-28 15:34:28,044 Training Epoch [14/40] Iter[146/312]		Loss: 0.1421
2019-10-28 15:34:28,123 Training Epoch [14/40] Iter[147/312]		Loss: 0.1426
2019-10-28 15:34:28,202 Training Epoch [14/40] Iter[148/312]		Loss: 0.1426
2019-10-28 15:34:28,281 Training Epoch [14/40] Iter[149/312]		Loss: 0.1423
2019-10-28 15:34:28,361 Training Epoch [14/40] Iter[150/312]		Loss: 0.1424
2019-10-28 15:34:28,441 Training Epoch [14/40] Iter[151/312]		Loss: 0.1420
2019-10-28 15:34:28,520 Training Epoch [14/40] Iter[152/312]		Loss: 0.1416
2019-10-28 15:34:28,599 Training Epoch [14/40] Iter[153/312]		Loss: 0.1418
2019-10-28 15:34:28,679 Training Epoch [14/40] Iter[154/312]		Loss: 0.1415
2019-10-28 15:34:28,758 Training Epoch [14/40] Iter[155/312]		Loss: 0.1415
2019-10-28 15:34:28,838 Training Epoch [14/40] Iter[156/312]		Loss: 0.1418
2019-10-28 15:34:28,917 Training Epoch [14/40] Iter[157/312]		Loss: 0.1419
2019-10-28 15:34:28,997 Training Epoch [14/40] Iter[158/312]		Loss: 0.1418
2019-10-28 15:34:29,076 Training Epoch [14/40] Iter[159/312]		Loss: 0.1418
2019-10-28 15:34:29,156 Training Epoch [14/40] Iter[160/312]		Loss: 0.1423
2019-10-28 15:34:29,235 Training Epoch [14/40] Iter[161/312]		Loss: 0.1423
2019-10-28 15:34:29,315 Training Epoch [14/40] Iter[162/312]		Loss: 0.1425
2019-10-28 15:34:29,394 Training Epoch [14/40] Iter[163/312]		Loss: 0.1426
2019-10-28 15:34:29,474 Training Epoch [14/40] Iter[164/312]		Loss: 0.1428
2019-10-28 15:34:29,553 Training Epoch [14/40] Iter[165/312]		Loss: 0.1429
2019-10-28 15:34:29,633 Training Epoch [14/40] Iter[166/312]		Loss: 0.1429
2019-10-28 15:34:29,712 Training Epoch [14/40] Iter[167/312]		Loss: 0.1427
2019-10-28 15:34:29,792 Training Epoch [14/40] Iter[168/312]		Loss: 0.1426
2019-10-28 15:34:29,871 Training Epoch [14/40] Iter[169/312]		Loss: 0.1427
2019-10-28 15:34:29,950 Training Epoch [14/40] Iter[170/312]		Loss: 0.1425
2019-10-28 15:34:30,029 Training Epoch [14/40] Iter[171/312]		Loss: 0.1434
2019-10-28 15:34:30,109 Training Epoch [14/40] Iter[172/312]		Loss: 0.1434
2019-10-28 15:34:30,188 Training Epoch [14/40] Iter[173/312]		Loss: 0.1439
2019-10-28 15:34:30,268 Training Epoch [14/40] Iter[174/312]		Loss: 0.1440
2019-10-28 15:34:30,347 Training Epoch [14/40] Iter[175/312]		Loss: 0.1450
2019-10-28 15:34:30,426 Training Epoch [14/40] Iter[176/312]		Loss: 0.1454
2019-10-28 15:34:30,506 Training Epoch [14/40] Iter[177/312]		Loss: 0.1454
2019-10-28 15:34:30,585 Training Epoch [14/40] Iter[178/312]		Loss: 0.1451
2019-10-28 15:34:30,664 Training Epoch [14/40] Iter[179/312]		Loss: 0.1452
2019-10-28 15:34:30,743 Training Epoch [14/40] Iter[180/312]		Loss: 0.1451
2019-10-28 15:34:30,822 Training Epoch [14/40] Iter[181/312]		Loss: 0.1456
2019-10-28 15:34:30,901 Training Epoch [14/40] Iter[182/312]		Loss: 0.1455
2019-10-28 15:34:30,981 Training Epoch [14/40] Iter[183/312]		Loss: 0.1460
2019-10-28 15:34:31,060 Training Epoch [14/40] Iter[184/312]		Loss: 0.1470
2019-10-28 15:34:31,139 Training Epoch [14/40] Iter[185/312]		Loss: 0.1469
2019-10-28 15:34:31,218 Training Epoch [14/40] Iter[186/312]		Loss: 0.1468
2019-10-28 15:34:31,298 Training Epoch [14/40] Iter[187/312]		Loss: 0.1467
2019-10-28 15:34:31,377 Training Epoch [14/40] Iter[188/312]		Loss: 0.1469
2019-10-28 15:34:31,457 Training Epoch [14/40] Iter[189/312]		Loss: 0.1468
2019-10-28 15:34:31,536 Training Epoch [14/40] Iter[190/312]		Loss: 0.1467
2019-10-28 15:34:31,616 Training Epoch [14/40] Iter[191/312]		Loss: 0.1466
2019-10-28 15:34:31,695 Training Epoch [14/40] Iter[192/312]		Loss: 0.1469
2019-10-28 15:34:31,775 Training Epoch [14/40] Iter[193/312]		Loss: 0.1467
2019-10-28 15:34:31,855 Training Epoch [14/40] Iter[194/312]		Loss: 0.1467
2019-10-28 15:34:31,934 Training Epoch [14/40] Iter[195/312]		Loss: 0.1469
2019-10-28 15:34:32,014 Training Epoch [14/40] Iter[196/312]		Loss: 0.1473
2019-10-28 15:34:32,093 Training Epoch [14/40] Iter[197/312]		Loss: 0.1478
2019-10-28 15:34:32,172 Training Epoch [14/40] Iter[198/312]		Loss: 0.1479
2019-10-28 15:34:32,251 Training Epoch [14/40] Iter[199/312]		Loss: 0.1480
2019-10-28 15:34:32,331 Training Epoch [14/40] Iter[200/312]		Loss: 0.1481
2019-10-28 15:34:32,410 Training Epoch [14/40] Iter[201/312]		Loss: 0.1478
2019-10-28 15:34:32,490 Training Epoch [14/40] Iter[202/312]		Loss: 0.1481
2019-10-28 15:34:32,569 Training Epoch [14/40] Iter[203/312]		Loss: 0.1479
2019-10-28 15:34:32,649 Training Epoch [14/40] Iter[204/312]		Loss: 0.1487
2019-10-28 15:34:32,728 Training Epoch [14/40] Iter[205/312]		Loss: 0.1486
2019-10-28 15:34:32,807 Training Epoch [14/40] Iter[206/312]		Loss: 0.1484
2019-10-28 15:34:32,887 Training Epoch [14/40] Iter[207/312]		Loss: 0.1487
2019-10-28 15:34:32,966 Training Epoch [14/40] Iter[208/312]		Loss: 0.1485
2019-10-28 15:34:33,045 Training Epoch [14/40] Iter[209/312]		Loss: 0.1484
2019-10-28 15:34:33,125 Training Epoch [14/40] Iter[210/312]		Loss: 0.1483
2019-10-28 15:34:33,204 Training Epoch [14/40] Iter[211/312]		Loss: 0.1482
2019-10-28 15:34:33,284 Training Epoch [14/40] Iter[212/312]		Loss: 0.1479
2019-10-28 15:34:33,363 Training Epoch [14/40] Iter[213/312]		Loss: 0.1478
2019-10-28 15:34:33,443 Training Epoch [14/40] Iter[214/312]		Loss: 0.1477
2019-10-28 15:34:33,522 Training Epoch [14/40] Iter[215/312]		Loss: 0.1478
2019-10-28 15:34:33,602 Training Epoch [14/40] Iter[216/312]		Loss: 0.1476
2019-10-28 15:34:33,681 Training Epoch [14/40] Iter[217/312]		Loss: 0.1476
2019-10-28 15:34:33,760 Training Epoch [14/40] Iter[218/312]		Loss: 0.1475
2019-10-28 15:34:33,839 Training Epoch [14/40] Iter[219/312]		Loss: 0.1473
2019-10-28 15:34:33,919 Training Epoch [14/40] Iter[220/312]		Loss: 0.1472
2019-10-28 15:34:33,998 Training Epoch [14/40] Iter[221/312]		Loss: 0.1470
2019-10-28 15:34:34,077 Training Epoch [14/40] Iter[222/312]		Loss: 0.1470
2019-10-28 15:34:34,157 Training Epoch [14/40] Iter[223/312]		Loss: 0.1470
2019-10-28 15:34:34,237 Training Epoch [14/40] Iter[224/312]		Loss: 0.1470
2019-10-28 15:34:34,316 Training Epoch [14/40] Iter[225/312]		Loss: 0.1470
2019-10-28 15:34:34,396 Training Epoch [14/40] Iter[226/312]		Loss: 0.1470
2019-10-28 15:34:34,476 Training Epoch [14/40] Iter[227/312]		Loss: 0.1469
2019-10-28 15:34:34,555 Training Epoch [14/40] Iter[228/312]		Loss: 0.1467
2019-10-28 15:34:34,634 Training Epoch [14/40] Iter[229/312]		Loss: 0.1468
2019-10-28 15:34:34,713 Training Epoch [14/40] Iter[230/312]		Loss: 0.1468
2019-10-28 15:34:34,793 Training Epoch [14/40] Iter[231/312]		Loss: 0.1467
2019-10-28 15:34:34,872 Training Epoch [14/40] Iter[232/312]		Loss: 0.1467
2019-10-28 15:34:34,951 Training Epoch [14/40] Iter[233/312]		Loss: 0.1468
2019-10-28 15:34:35,031 Training Epoch [14/40] Iter[234/312]		Loss: 0.1468
2019-10-28 15:34:35,110 Training Epoch [14/40] Iter[235/312]		Loss: 0.1467
2019-10-28 15:34:35,190 Training Epoch [14/40] Iter[236/312]		Loss: 0.1465
2019-10-28 15:34:35,269 Training Epoch [14/40] Iter[237/312]		Loss: 0.1464
2019-10-28 15:34:35,349 Training Epoch [14/40] Iter[238/312]		Loss: 0.1464
2019-10-28 15:34:35,429 Training Epoch [14/40] Iter[239/312]		Loss: 0.1464
2019-10-28 15:34:35,508 Training Epoch [14/40] Iter[240/312]		Loss: 0.1463
2019-10-28 15:34:35,587 Training Epoch [14/40] Iter[241/312]		Loss: 0.1467
2019-10-28 15:34:35,667 Training Epoch [14/40] Iter[242/312]		Loss: 0.1467
2019-10-28 15:34:35,746 Training Epoch [14/40] Iter[243/312]		Loss: 0.1465
2019-10-28 15:34:35,826 Training Epoch [14/40] Iter[244/312]		Loss: 0.1467
2019-10-28 15:34:35,905 Training Epoch [14/40] Iter[245/312]		Loss: 0.1465
2019-10-28 15:34:35,984 Training Epoch [14/40] Iter[246/312]		Loss: 0.1467
2019-10-28 15:34:36,063 Training Epoch [14/40] Iter[247/312]		Loss: 0.1470
2019-10-28 15:34:36,142 Training Epoch [14/40] Iter[248/312]		Loss: 0.1467
2019-10-28 15:34:36,221 Training Epoch [14/40] Iter[249/312]		Loss: 0.1469
2019-10-28 15:34:36,301 Training Epoch [14/40] Iter[250/312]		Loss: 0.1467
2019-10-28 15:34:36,380 Training Epoch [14/40] Iter[251/312]		Loss: 0.1469
2019-10-28 15:34:36,460 Training Epoch [14/40] Iter[252/312]		Loss: 0.1469
2019-10-28 15:34:36,539 Training Epoch [14/40] Iter[253/312]		Loss: 0.1467
2019-10-28 15:34:36,619 Training Epoch [14/40] Iter[254/312]		Loss: 0.1467
2019-10-28 15:34:36,698 Training Epoch [14/40] Iter[255/312]		Loss: 0.1467
2019-10-28 15:34:36,778 Training Epoch [14/40] Iter[256/312]		Loss: 0.1469
2019-10-28 15:34:36,857 Training Epoch [14/40] Iter[257/312]		Loss: 0.1467
2019-10-28 15:34:36,936 Training Epoch [14/40] Iter[258/312]		Loss: 0.1468
2019-10-28 15:34:37,016 Training Epoch [14/40] Iter[259/312]		Loss: 0.1470
2019-10-28 15:34:37,095 Training Epoch [14/40] Iter[260/312]		Loss: 0.1469
2019-10-28 15:34:37,175 Training Epoch [14/40] Iter[261/312]		Loss: 0.1468
2019-10-28 15:34:37,254 Training Epoch [14/40] Iter[262/312]		Loss: 0.1470
2019-10-28 15:34:37,334 Training Epoch [14/40] Iter[263/312]		Loss: 0.1471
2019-10-28 15:34:37,414 Training Epoch [14/40] Iter[264/312]		Loss: 0.1476
2019-10-28 15:34:37,494 Training Epoch [14/40] Iter[265/312]		Loss: 0.1475
2019-10-28 15:34:37,573 Training Epoch [14/40] Iter[266/312]		Loss: 0.1478
2019-10-28 15:34:37,653 Training Epoch [14/40] Iter[267/312]		Loss: 0.1480
2019-10-28 15:34:37,732 Training Epoch [14/40] Iter[268/312]		Loss: 0.1479
2019-10-28 15:34:37,812 Training Epoch [14/40] Iter[269/312]		Loss: 0.1478
2019-10-28 15:34:37,891 Training Epoch [14/40] Iter[270/312]		Loss: 0.1477
2019-10-28 15:34:37,971 Training Epoch [14/40] Iter[271/312]		Loss: 0.1479
2019-10-28 15:34:38,050 Training Epoch [14/40] Iter[272/312]		Loss: 0.1477
2019-10-28 15:34:38,130 Training Epoch [14/40] Iter[273/312]		Loss: 0.1479
2019-10-28 15:34:38,210 Training Epoch [14/40] Iter[274/312]		Loss: 0.1478
2019-10-28 15:34:38,290 Training Epoch [14/40] Iter[275/312]		Loss: 0.1477
2019-10-28 15:34:38,369 Training Epoch [14/40] Iter[276/312]		Loss: 0.1475
2019-10-28 15:34:38,449 Training Epoch [14/40] Iter[277/312]		Loss: 0.1474
2019-10-28 15:34:38,529 Training Epoch [14/40] Iter[278/312]		Loss: 0.1475
2019-10-28 15:34:38,609 Training Epoch [14/40] Iter[279/312]		Loss: 0.1474
2019-10-28 15:34:38,689 Training Epoch [14/40] Iter[280/312]		Loss: 0.1473
2019-10-28 15:34:38,768 Training Epoch [14/40] Iter[281/312]		Loss: 0.1474
2019-10-28 15:34:38,848 Training Epoch [14/40] Iter[282/312]		Loss: 0.1477
2019-10-28 15:34:38,927 Training Epoch [14/40] Iter[283/312]		Loss: 0.1475
2019-10-28 15:34:39,007 Training Epoch [14/40] Iter[284/312]		Loss: 0.1474
2019-10-28 15:34:39,086 Training Epoch [14/40] Iter[285/312]		Loss: 0.1473
2019-10-28 15:34:39,166 Training Epoch [14/40] Iter[286/312]		Loss: 0.1477
2019-10-28 15:34:39,246 Training Epoch [14/40] Iter[287/312]		Loss: 0.1479
2019-10-28 15:34:39,325 Training Epoch [14/40] Iter[288/312]		Loss: 0.1479
2019-10-28 15:34:39,405 Training Epoch [14/40] Iter[289/312]		Loss: 0.1477
2019-10-28 15:34:39,485 Training Epoch [14/40] Iter[290/312]		Loss: 0.1475
2019-10-28 15:34:39,564 Training Epoch [14/40] Iter[291/312]		Loss: 0.1475
2019-10-28 15:34:39,643 Training Epoch [14/40] Iter[292/312]		Loss: 0.1474
2019-10-28 15:34:39,723 Training Epoch [14/40] Iter[293/312]		Loss: 0.1474
2019-10-28 15:34:39,802 Training Epoch [14/40] Iter[294/312]		Loss: 0.1477
2019-10-28 15:34:39,882 Training Epoch [14/40] Iter[295/312]		Loss: 0.1478
2019-10-28 15:34:39,961 Training Epoch [14/40] Iter[296/312]		Loss: 0.1477
2019-10-28 15:34:40,041 Training Epoch [14/40] Iter[297/312]		Loss: 0.1477
2019-10-28 15:34:40,120 Training Epoch [14/40] Iter[298/312]		Loss: 0.1475
2019-10-28 15:34:40,200 Training Epoch [14/40] Iter[299/312]		Loss: 0.1476
2019-10-28 15:34:40,280 Training Epoch [14/40] Iter[300/312]		Loss: 0.1474
2019-10-28 15:34:40,360 Training Epoch [14/40] Iter[301/312]		Loss: 0.1473
2019-10-28 15:34:40,440 Training Epoch [14/40] Iter[302/312]		Loss: 0.1471
2019-10-28 15:34:40,519 Training Epoch [14/40] Iter[303/312]		Loss: 0.1473
2019-10-28 15:34:40,599 Training Epoch [14/40] Iter[304/312]		Loss: 0.1474
2019-10-28 15:34:40,678 Training Epoch [14/40] Iter[305/312]		Loss: 0.1477
2019-10-28 15:34:40,756 Training Epoch [14/40] Iter[306/312]		Loss: 0.1477
2019-10-28 15:34:40,835 Training Epoch [14/40] Iter[307/312]		Loss: 0.1478
2019-10-28 15:34:40,913 Training Epoch [14/40] Iter[308/312]		Loss: 0.1478
2019-10-28 15:34:40,992 Training Epoch [14/40] Iter[309/312]		Loss: 0.1477
2019-10-28 15:34:41,071 Training Epoch [14/40] Iter[310/312]		Loss: 0.1475
2019-10-28 15:34:41,150 Training Epoch [14/40] Iter[311/312]		Loss: 0.1474
2019-10-28 15:34:41,189 Training Epoch [14/40] Iter[312/312]		Loss: 0.1473
2019-10-28 15:34:41,538 Testing Epoch [14/40] Iter[0/62]		Loss: 0.1577
2019-10-28 15:34:41,654 Testing Epoch [14/40] Iter[1/62]		Loss: 0.1547
2019-10-28 15:34:41,690 Testing Epoch [14/40] Iter[2/62]		Loss: 0.1363
2019-10-28 15:34:41,715 Testing Epoch [14/40] Iter[3/62]		Loss: 0.1414
2019-10-28 15:34:41,733 Testing Epoch [14/40] Iter[4/62]		Loss: 0.1425
2019-10-28 15:34:41,758 Testing Epoch [14/40] Iter[5/62]		Loss: 0.1370
2019-10-28 15:34:41,782 Testing Epoch [14/40] Iter[6/62]		Loss: 0.1401
2019-10-28 15:34:41,801 Testing Epoch [14/40] Iter[7/62]		Loss: 0.1424
2019-10-28 15:34:41,830 Testing Epoch [14/40] Iter[8/62]		Loss: 0.1442
2019-10-28 15:34:41,857 Testing Epoch [14/40] Iter[9/62]		Loss: 0.1434
2019-10-28 15:34:41,881 Testing Epoch [14/40] Iter[10/62]		Loss: 0.1448
2019-10-28 15:34:41,905 Testing Epoch [14/40] Iter[11/62]		Loss: 0.1522
2019-10-28 15:34:41,929 Testing Epoch [14/40] Iter[12/62]		Loss: 0.1522
2019-10-28 15:34:41,957 Testing Epoch [14/40] Iter[13/62]		Loss: 0.1533
2019-10-28 15:34:41,975 Testing Epoch [14/40] Iter[14/62]		Loss: 0.1677
2019-10-28 15:34:42,001 Testing Epoch [14/40] Iter[15/62]		Loss: 0.1698
2019-10-28 15:34:42,030 Testing Epoch [14/40] Iter[16/62]		Loss: 0.1672
2019-10-28 15:34:42,048 Testing Epoch [14/40] Iter[17/62]		Loss: 0.1662
2019-10-28 15:34:42,073 Testing Epoch [14/40] Iter[18/62]		Loss: 0.1631
2019-10-28 15:34:42,105 Testing Epoch [14/40] Iter[19/62]		Loss: 0.1608
2019-10-28 15:34:42,123 Testing Epoch [14/40] Iter[20/62]		Loss: 0.1622
2019-10-28 15:34:42,150 Testing Epoch [14/40] Iter[21/62]		Loss: 0.1611
2019-10-28 15:34:42,175 Testing Epoch [14/40] Iter[22/62]		Loss: 0.1619
2019-10-28 15:34:42,193 Testing Epoch [14/40] Iter[23/62]		Loss: 0.1602
2019-10-28 15:34:42,221 Testing Epoch [14/40] Iter[24/62]		Loss: 0.1644
2019-10-28 15:34:42,248 Testing Epoch [14/40] Iter[25/62]		Loss: 0.1630
2019-10-28 15:34:42,266 Testing Epoch [14/40] Iter[26/62]		Loss: 0.1612
2019-10-28 15:34:42,283 Testing Epoch [14/40] Iter[27/62]		Loss: 0.1688
2019-10-28 15:34:42,310 Testing Epoch [14/40] Iter[28/62]		Loss: 0.1724
2019-10-28 15:34:42,328 Testing Epoch [14/40] Iter[29/62]		Loss: 0.1725
2019-10-28 15:34:42,350 Testing Epoch [14/40] Iter[30/62]		Loss: 0.1738
2019-10-28 15:34:42,382 Testing Epoch [14/40] Iter[31/62]		Loss: 0.1726
2019-10-28 15:34:42,406 Testing Epoch [14/40] Iter[32/62]		Loss: 0.1740
2019-10-28 15:34:42,430 Testing Epoch [14/40] Iter[33/62]		Loss: 0.1733
2019-10-28 15:34:42,453 Testing Epoch [14/40] Iter[34/62]		Loss: 0.1756
2019-10-28 15:34:42,477 Testing Epoch [14/40] Iter[35/62]		Loss: 0.1751
2019-10-28 15:34:42,501 Testing Epoch [14/40] Iter[36/62]		Loss: 0.1732
2019-10-28 15:34:42,525 Testing Epoch [14/40] Iter[37/62]		Loss: 0.1724
2019-10-28 15:34:42,550 Testing Epoch [14/40] Iter[38/62]		Loss: 0.1711
2019-10-28 15:34:42,577 Testing Epoch [14/40] Iter[39/62]		Loss: 0.1719
2019-10-28 15:34:42,602 Testing Epoch [14/40] Iter[40/62]		Loss: 0.1735
2019-10-28 15:34:42,625 Testing Epoch [14/40] Iter[41/62]		Loss: 0.1750
2019-10-28 15:34:42,649 Testing Epoch [14/40] Iter[42/62]		Loss: 0.1729
2019-10-28 15:34:42,667 Testing Epoch [14/40] Iter[43/62]		Loss: 0.1721
2019-10-28 15:34:42,697 Testing Epoch [14/40] Iter[44/62]		Loss: 0.1701
2019-10-28 15:34:42,725 Testing Epoch [14/40] Iter[45/62]		Loss: 0.1702
2019-10-28 15:34:42,743 Testing Epoch [14/40] Iter[46/62]		Loss: 0.1698
2019-10-28 15:34:42,769 Testing Epoch [14/40] Iter[47/62]		Loss: 0.1757
2019-10-28 15:34:42,788 Testing Epoch [14/40] Iter[48/62]		Loss: 0.1745
2019-10-28 15:34:42,819 Testing Epoch [14/40] Iter[49/62]		Loss: 0.1769
2019-10-28 15:34:42,837 Testing Epoch [14/40] Iter[50/62]		Loss: 0.1761
2019-10-28 15:34:42,870 Testing Epoch [14/40] Iter[51/62]		Loss: 0.1759
2019-10-28 15:34:42,888 Testing Epoch [14/40] Iter[52/62]		Loss: 0.1744
2019-10-28 15:34:42,913 Testing Epoch [14/40] Iter[53/62]		Loss: 0.1749
2019-10-28 15:34:42,937 Testing Epoch [14/40] Iter[54/62]		Loss: 0.1736
2019-10-28 15:34:42,954 Testing Epoch [14/40] Iter[55/62]		Loss: 0.1736
2019-10-28 15:34:42,971 Testing Epoch [14/40] Iter[56/62]		Loss: 0.1729
2019-10-28 15:34:42,987 Testing Epoch [14/40] Iter[57/62]		Loss: 0.1729
2019-10-28 15:34:43,004 Testing Epoch [14/40] Iter[58/62]		Loss: 0.1722
2019-10-28 15:34:43,021 Testing Epoch [14/40] Iter[59/62]		Loss: 0.1735
2019-10-28 15:34:43,037 Testing Epoch [14/40] Iter[60/62]		Loss: 0.1724
2019-10-28 15:34:43,054 Testing Epoch [14/40] Iter[61/62]		Loss: 0.1725
2019-10-28 15:34:43,064 Testing Epoch [14/40] Iter[62/62]		Loss: 0.1735
2019-10-28 15:34:43,138 Saving the Model
2019-10-28 15:34:43,583 Training Epoch [15/40] Iter[0/312]		Loss: 0.1168
2019-10-28 15:34:43,661 Training Epoch [15/40] Iter[1/312]		Loss: 0.1679
2019-10-28 15:34:43,743 Training Epoch [15/40] Iter[2/312]		Loss: 0.1595
2019-10-28 15:34:43,821 Training Epoch [15/40] Iter[3/312]		Loss: 0.1455
2019-10-28 15:34:43,907 Training Epoch [15/40] Iter[4/312]		Loss: 0.1351
2019-10-28 15:34:43,985 Training Epoch [15/40] Iter[5/312]		Loss: 0.1274
2019-10-28 15:34:44,064 Training Epoch [15/40] Iter[6/312]		Loss: 0.1269
2019-10-28 15:34:44,142 Training Epoch [15/40] Iter[7/312]		Loss: 0.1214
2019-10-28 15:34:44,222 Training Epoch [15/40] Iter[8/312]		Loss: 0.1191
2019-10-28 15:34:44,302 Training Epoch [15/40] Iter[9/312]		Loss: 0.1200
2019-10-28 15:34:44,382 Training Epoch [15/40] Iter[10/312]		Loss: 0.1292
2019-10-28 15:34:44,461 Training Epoch [15/40] Iter[11/312]		Loss: 0.1376
2019-10-28 15:34:44,541 Training Epoch [15/40] Iter[12/312]		Loss: 0.1390
2019-10-28 15:34:44,620 Training Epoch [15/40] Iter[13/312]		Loss: 0.1391
2019-10-28 15:34:44,700 Training Epoch [15/40] Iter[14/312]		Loss: 0.1377
2019-10-28 15:34:44,779 Training Epoch [15/40] Iter[15/312]		Loss: 0.1362
2019-10-28 15:34:44,858 Training Epoch [15/40] Iter[16/312]		Loss: 0.1333
2019-10-28 15:34:44,938 Training Epoch [15/40] Iter[17/312]		Loss: 0.1316
2019-10-28 15:34:45,017 Training Epoch [15/40] Iter[18/312]		Loss: 0.1312
2019-10-28 15:34:45,097 Training Epoch [15/40] Iter[19/312]		Loss: 0.1300
2019-10-28 15:34:45,176 Training Epoch [15/40] Iter[20/312]		Loss: 0.1323
2019-10-28 15:34:45,256 Training Epoch [15/40] Iter[21/312]		Loss: 0.1324
2019-10-28 15:34:45,335 Training Epoch [15/40] Iter[22/312]		Loss: 0.1312
2019-10-28 15:34:45,415 Training Epoch [15/40] Iter[23/312]		Loss: 0.1291
2019-10-28 15:34:45,494 Training Epoch [15/40] Iter[24/312]		Loss: 0.1293
2019-10-28 15:34:45,574 Training Epoch [15/40] Iter[25/312]		Loss: 0.1309
2019-10-28 15:34:45,653 Training Epoch [15/40] Iter[26/312]		Loss: 0.1315
2019-10-28 15:34:45,732 Training Epoch [15/40] Iter[27/312]		Loss: 0.1337
2019-10-28 15:34:45,812 Training Epoch [15/40] Iter[28/312]		Loss: 0.1329
2019-10-28 15:34:45,891 Training Epoch [15/40] Iter[29/312]		Loss: 0.1329
2019-10-28 15:34:45,970 Training Epoch [15/40] Iter[30/312]		Loss: 0.1323
2019-10-28 15:34:46,050 Training Epoch [15/40] Iter[31/312]		Loss: 0.1331
2019-10-28 15:34:46,129 Training Epoch [15/40] Iter[32/312]		Loss: 0.1354
2019-10-28 15:34:46,208 Training Epoch [15/40] Iter[33/312]		Loss: 0.1343
2019-10-28 15:34:46,288 Training Epoch [15/40] Iter[34/312]		Loss: 0.1341
2019-10-28 15:34:46,367 Training Epoch [15/40] Iter[35/312]		Loss: 0.1333
2019-10-28 15:34:46,447 Training Epoch [15/40] Iter[36/312]		Loss: 0.1355
2019-10-28 15:34:46,526 Training Epoch [15/40] Iter[37/312]		Loss: 0.1375
2019-10-28 15:34:46,606 Training Epoch [15/40] Iter[38/312]		Loss: 0.1369
2019-10-28 15:34:46,685 Training Epoch [15/40] Iter[39/312]		Loss: 0.1376
2019-10-28 15:34:46,765 Training Epoch [15/40] Iter[40/312]		Loss: 0.1367
2019-10-28 15:34:46,844 Training Epoch [15/40] Iter[41/312]		Loss: 0.1389
2019-10-28 15:34:46,924 Training Epoch [15/40] Iter[42/312]		Loss: 0.1379
2019-10-28 15:34:47,004 Training Epoch [15/40] Iter[43/312]		Loss: 0.1397
2019-10-28 15:34:47,083 Training Epoch [15/40] Iter[44/312]		Loss: 0.1397
2019-10-28 15:34:47,162 Training Epoch [15/40] Iter[45/312]		Loss: 0.1402
2019-10-28 15:34:47,242 Training Epoch [15/40] Iter[46/312]		Loss: 0.1397
2019-10-28 15:34:47,321 Training Epoch [15/40] Iter[47/312]		Loss: 0.1391
2019-10-28 15:34:47,401 Training Epoch [15/40] Iter[48/312]		Loss: 0.1391
2019-10-28 15:34:47,480 Training Epoch [15/40] Iter[49/312]		Loss: 0.1392
2019-10-28 15:34:47,560 Training Epoch [15/40] Iter[50/312]		Loss: 0.1387
2019-10-28 15:34:47,639 Training Epoch [15/40] Iter[51/312]		Loss: 0.1386
2019-10-28 15:34:47,718 Training Epoch [15/40] Iter[52/312]		Loss: 0.1375
2019-10-28 15:34:47,797 Training Epoch [15/40] Iter[53/312]		Loss: 0.1374
2019-10-28 15:34:47,877 Training Epoch [15/40] Iter[54/312]		Loss: 0.1366
2019-10-28 15:34:47,956 Training Epoch [15/40] Iter[55/312]		Loss: 0.1357
2019-10-28 15:34:48,035 Training Epoch [15/40] Iter[56/312]		Loss: 0.1361
2019-10-28 15:34:48,114 Training Epoch [15/40] Iter[57/312]		Loss: 0.1368
2019-10-28 15:34:48,194 Training Epoch [15/40] Iter[58/312]		Loss: 0.1369
2019-10-28 15:34:48,274 Training Epoch [15/40] Iter[59/312]		Loss: 0.1368
2019-10-28 15:34:48,353 Training Epoch [15/40] Iter[60/312]		Loss: 0.1364
2019-10-28 15:34:48,433 Training Epoch [15/40] Iter[61/312]		Loss: 0.1364
2019-10-28 15:34:48,513 Training Epoch [15/40] Iter[62/312]		Loss: 0.1359
2019-10-28 15:34:48,592 Training Epoch [15/40] Iter[63/312]		Loss: 0.1362
2019-10-28 15:34:48,672 Training Epoch [15/40] Iter[64/312]		Loss: 0.1371
2019-10-28 15:34:48,752 Training Epoch [15/40] Iter[65/312]		Loss: 0.1379
2019-10-28 15:34:48,831 Training Epoch [15/40] Iter[66/312]		Loss: 0.1379
2019-10-28 15:34:48,916 Training Epoch [15/40] Iter[67/312]		Loss: 0.1380
2019-10-28 15:34:48,999 Training Epoch [15/40] Iter[68/312]		Loss: 0.1391
2019-10-28 15:34:49,079 Training Epoch [15/40] Iter[69/312]		Loss: 0.1388
2019-10-28 15:34:49,158 Training Epoch [15/40] Iter[70/312]		Loss: 0.1383
2019-10-28 15:34:49,238 Training Epoch [15/40] Iter[71/312]		Loss: 0.1380
2019-10-28 15:34:49,318 Training Epoch [15/40] Iter[72/312]		Loss: 0.1379
2019-10-28 15:34:49,398 Training Epoch [15/40] Iter[73/312]		Loss: 0.1390
2019-10-28 15:34:49,477 Training Epoch [15/40] Iter[74/312]		Loss: 0.1393
2019-10-28 15:34:49,557 Training Epoch [15/40] Iter[75/312]		Loss: 0.1394
2019-10-28 15:34:49,637 Training Epoch [15/40] Iter[76/312]		Loss: 0.1398
2019-10-28 15:34:49,717 Training Epoch [15/40] Iter[77/312]		Loss: 0.1396
2019-10-28 15:34:49,796 Training Epoch [15/40] Iter[78/312]		Loss: 0.1393
2019-10-28 15:34:49,876 Training Epoch [15/40] Iter[79/312]		Loss: 0.1392
2019-10-28 15:34:49,955 Training Epoch [15/40] Iter[80/312]		Loss: 0.1386
2019-10-28 15:34:50,035 Training Epoch [15/40] Iter[81/312]		Loss: 0.1386
2019-10-28 15:34:50,115 Training Epoch [15/40] Iter[82/312]		Loss: 0.1383
2019-10-28 15:34:50,195 Training Epoch [15/40] Iter[83/312]		Loss: 0.1386
2019-10-28 15:34:50,274 Training Epoch [15/40] Iter[84/312]		Loss: 0.1384
2019-10-28 15:34:50,354 Training Epoch [15/40] Iter[85/312]		Loss: 0.1380
2019-10-28 15:34:50,434 Training Epoch [15/40] Iter[86/312]		Loss: 0.1379
2019-10-28 15:34:50,514 Training Epoch [15/40] Iter[87/312]		Loss: 0.1379
2019-10-28 15:34:50,594 Training Epoch [15/40] Iter[88/312]		Loss: 0.1373
2019-10-28 15:34:50,673 Training Epoch [15/40] Iter[89/312]		Loss: 0.1377
2019-10-28 15:34:50,752 Training Epoch [15/40] Iter[90/312]		Loss: 0.1373
2019-10-28 15:34:50,831 Training Epoch [15/40] Iter[91/312]		Loss: 0.1368
2019-10-28 15:34:50,910 Training Epoch [15/40] Iter[92/312]		Loss: 0.1367
2019-10-28 15:34:50,990 Training Epoch [15/40] Iter[93/312]		Loss: 0.1370
2019-10-28 15:34:51,069 Training Epoch [15/40] Iter[94/312]		Loss: 0.1376
2019-10-28 15:34:51,148 Training Epoch [15/40] Iter[95/312]		Loss: 0.1379
2019-10-28 15:34:51,228 Training Epoch [15/40] Iter[96/312]		Loss: 0.1376
2019-10-28 15:34:51,307 Training Epoch [15/40] Iter[97/312]		Loss: 0.1384
2019-10-28 15:34:51,387 Training Epoch [15/40] Iter[98/312]		Loss: 0.1380
2019-10-28 15:34:51,467 Training Epoch [15/40] Iter[99/312]		Loss: 0.1378
2019-10-28 15:34:51,546 Training Epoch [15/40] Iter[100/312]		Loss: 0.1384
2019-10-28 15:34:51,626 Training Epoch [15/40] Iter[101/312]		Loss: 0.1378
2019-10-28 15:34:51,706 Training Epoch [15/40] Iter[102/312]		Loss: 0.1383
2019-10-28 15:34:51,786 Training Epoch [15/40] Iter[103/312]		Loss: 0.1381
2019-10-28 15:34:51,865 Training Epoch [15/40] Iter[104/312]		Loss: 0.1384
2019-10-28 15:34:51,945 Training Epoch [15/40] Iter[105/312]		Loss: 0.1381
2019-10-28 15:34:52,024 Training Epoch [15/40] Iter[106/312]		Loss: 0.1387
2019-10-28 15:34:52,103 Training Epoch [15/40] Iter[107/312]		Loss: 0.1389
2019-10-28 15:34:52,183 Training Epoch [15/40] Iter[108/312]		Loss: 0.1388
2019-10-28 15:34:52,262 Training Epoch [15/40] Iter[109/312]		Loss: 0.1392
2019-10-28 15:34:52,342 Training Epoch [15/40] Iter[110/312]		Loss: 0.1395
2019-10-28 15:34:52,421 Training Epoch [15/40] Iter[111/312]		Loss: 0.1394
2019-10-28 15:34:52,501 Training Epoch [15/40] Iter[112/312]		Loss: 0.1393
2019-10-28 15:34:52,580 Training Epoch [15/40] Iter[113/312]		Loss: 0.1400
2019-10-28 15:34:52,660 Training Epoch [15/40] Iter[114/312]		Loss: 0.1404
2019-10-28 15:34:52,739 Training Epoch [15/40] Iter[115/312]		Loss: 0.1405
2019-10-28 15:34:52,818 Training Epoch [15/40] Iter[116/312]		Loss: 0.1403
2019-10-28 15:34:52,898 Training Epoch [15/40] Iter[117/312]		Loss: 0.1398
2019-10-28 15:34:52,977 Training Epoch [15/40] Iter[118/312]		Loss: 0.1410
2019-10-28 15:34:53,057 Training Epoch [15/40] Iter[119/312]		Loss: 0.1409
2019-10-28 15:34:53,136 Training Epoch [15/40] Iter[120/312]		Loss: 0.1414
2019-10-28 15:34:53,216 Training Epoch [15/40] Iter[121/312]		Loss: 0.1417
2019-10-28 15:34:53,296 Training Epoch [15/40] Iter[122/312]		Loss: 0.1413
2019-10-28 15:34:53,376 Training Epoch [15/40] Iter[123/312]		Loss: 0.1410
2019-10-28 15:34:53,455 Training Epoch [15/40] Iter[124/312]		Loss: 0.1409
2019-10-28 15:34:53,535 Training Epoch [15/40] Iter[125/312]		Loss: 0.1409
2019-10-28 15:34:53,614 Training Epoch [15/40] Iter[126/312]		Loss: 0.1414
2019-10-28 15:34:53,694 Training Epoch [15/40] Iter[127/312]		Loss: 0.1421
2019-10-28 15:34:53,774 Training Epoch [15/40] Iter[128/312]		Loss: 0.1421
2019-10-28 15:34:53,853 Training Epoch [15/40] Iter[129/312]		Loss: 0.1422
2019-10-28 15:34:53,933 Training Epoch [15/40] Iter[130/312]		Loss: 0.1420
2019-10-28 15:34:54,013 Training Epoch [15/40] Iter[131/312]		Loss: 0.1425
2019-10-28 15:34:54,092 Training Epoch [15/40] Iter[132/312]		Loss: 0.1423
2019-10-28 15:34:54,171 Training Epoch [15/40] Iter[133/312]		Loss: 0.1429
2019-10-28 15:34:54,251 Training Epoch [15/40] Iter[134/312]		Loss: 0.1431
2019-10-28 15:34:54,331 Training Epoch [15/40] Iter[135/312]		Loss: 0.1434
2019-10-28 15:34:54,411 Training Epoch [15/40] Iter[136/312]		Loss: 0.1437
2019-10-28 15:34:54,491 Training Epoch [15/40] Iter[137/312]		Loss: 0.1439
2019-10-28 15:34:54,570 Training Epoch [15/40] Iter[138/312]		Loss: 0.1436
2019-10-28 15:34:54,650 Training Epoch [15/40] Iter[139/312]		Loss: 0.1434
2019-10-28 15:34:54,729 Training Epoch [15/40] Iter[140/312]		Loss: 0.1434
2019-10-28 15:34:54,809 Training Epoch [15/40] Iter[141/312]		Loss: 0.1434
2019-10-28 15:34:54,888 Training Epoch [15/40] Iter[142/312]		Loss: 0.1436
2019-10-28 15:34:54,968 Training Epoch [15/40] Iter[143/312]		Loss: 0.1434
2019-10-28 15:34:55,047 Training Epoch [15/40] Iter[144/312]		Loss: 0.1435
2019-10-28 15:34:55,127 Training Epoch [15/40] Iter[145/312]		Loss: 0.1435
2019-10-28 15:34:55,206 Training Epoch [15/40] Iter[146/312]		Loss: 0.1432
2019-10-28 15:34:55,286 Training Epoch [15/40] Iter[147/312]		Loss: 0.1434
2019-10-28 15:34:55,366 Training Epoch [15/40] Iter[148/312]		Loss: 0.1432
2019-10-28 15:34:55,446 Training Epoch [15/40] Iter[149/312]		Loss: 0.1435
2019-10-28 15:34:55,526 Training Epoch [15/40] Iter[150/312]		Loss: 0.1434
2019-10-28 15:34:55,605 Training Epoch [15/40] Iter[151/312]		Loss: 0.1432
2019-10-28 15:34:55,685 Training Epoch [15/40] Iter[152/312]		Loss: 0.1430
2019-10-28 15:34:55,764 Training Epoch [15/40] Iter[153/312]		Loss: 0.1435
2019-10-28 15:34:55,844 Training Epoch [15/40] Iter[154/312]		Loss: 0.1434
2019-10-28 15:34:55,923 Training Epoch [15/40] Iter[155/312]		Loss: 0.1431
2019-10-28 15:34:56,003 Training Epoch [15/40] Iter[156/312]		Loss: 0.1428
2019-10-28 15:34:56,082 Training Epoch [15/40] Iter[157/312]		Loss: 0.1426
2019-10-28 15:34:56,162 Training Epoch [15/40] Iter[158/312]		Loss: 0.1427
2019-10-28 15:34:56,241 Training Epoch [15/40] Iter[159/312]		Loss: 0.1426
2019-10-28 15:34:56,321 Training Epoch [15/40] Iter[160/312]		Loss: 0.1430
2019-10-28 15:34:56,401 Training Epoch [15/40] Iter[161/312]		Loss: 0.1428
2019-10-28 15:34:56,481 Training Epoch [15/40] Iter[162/312]		Loss: 0.1438
2019-10-28 15:34:56,560 Training Epoch [15/40] Iter[163/312]		Loss: 0.1436
2019-10-28 15:34:56,640 Training Epoch [15/40] Iter[164/312]		Loss: 0.1433
2019-10-28 15:34:56,719 Training Epoch [15/40] Iter[165/312]		Loss: 0.1434
2019-10-28 15:34:56,799 Training Epoch [15/40] Iter[166/312]		Loss: 0.1431
2019-10-28 15:34:56,879 Training Epoch [15/40] Iter[167/312]		Loss: 0.1431
2019-10-28 15:34:56,959 Training Epoch [15/40] Iter[168/312]		Loss: 0.1429
2019-10-28 15:34:57,039 Training Epoch [15/40] Iter[169/312]		Loss: 0.1431
2019-10-28 15:34:57,118 Training Epoch [15/40] Iter[170/312]		Loss: 0.1434
2019-10-28 15:34:57,198 Training Epoch [15/40] Iter[171/312]		Loss: 0.1430
2019-10-28 15:34:57,278 Training Epoch [15/40] Iter[172/312]		Loss: 0.1429
2019-10-28 15:34:57,357 Training Epoch [15/40] Iter[173/312]		Loss: 0.1428
2019-10-28 15:34:57,437 Training Epoch [15/40] Iter[174/312]		Loss: 0.1426
2019-10-28 15:34:57,517 Training Epoch [15/40] Iter[175/312]		Loss: 0.1426
2019-10-28 15:34:57,596 Training Epoch [15/40] Iter[176/312]		Loss: 0.1429
2019-10-28 15:34:57,675 Training Epoch [15/40] Iter[177/312]		Loss: 0.1427
2019-10-28 15:34:57,754 Training Epoch [15/40] Iter[178/312]		Loss: 0.1426
2019-10-28 15:34:57,833 Training Epoch [15/40] Iter[179/312]		Loss: 0.1428
2019-10-28 15:34:57,913 Training Epoch [15/40] Iter[180/312]		Loss: 0.1428
2019-10-28 15:34:57,992 Training Epoch [15/40] Iter[181/312]		Loss: 0.1431
2019-10-28 15:34:58,071 Training Epoch [15/40] Iter[182/312]		Loss: 0.1430
2019-10-28 15:34:58,151 Training Epoch [15/40] Iter[183/312]		Loss: 0.1433
2019-10-28 15:34:58,230 Training Epoch [15/40] Iter[184/312]		Loss: 0.1432
2019-10-28 15:34:58,309 Training Epoch [15/40] Iter[185/312]		Loss: 0.1430
2019-10-28 15:34:58,389 Training Epoch [15/40] Iter[186/312]		Loss: 0.1430
2019-10-28 15:34:58,468 Training Epoch [15/40] Iter[187/312]		Loss: 0.1429
2019-10-28 15:34:58,548 Training Epoch [15/40] Iter[188/312]		Loss: 0.1427
2019-10-28 15:34:58,627 Training Epoch [15/40] Iter[189/312]		Loss: 0.1431
2019-10-28 15:34:58,707 Training Epoch [15/40] Iter[190/312]		Loss: 0.1433
2019-10-28 15:34:58,786 Training Epoch [15/40] Iter[191/312]		Loss: 0.1433
2019-10-28 15:34:58,866 Training Epoch [15/40] Iter[192/312]		Loss: 0.1432
2019-10-28 15:34:58,945 Training Epoch [15/40] Iter[193/312]		Loss: 0.1431
2019-10-28 15:34:59,024 Training Epoch [15/40] Iter[194/312]		Loss: 0.1437
2019-10-28 15:34:59,103 Training Epoch [15/40] Iter[195/312]		Loss: 0.1437
2019-10-28 15:34:59,183 Training Epoch [15/40] Iter[196/312]		Loss: 0.1438
2019-10-28 15:34:59,262 Training Epoch [15/40] Iter[197/312]		Loss: 0.1440
2019-10-28 15:34:59,342 Training Epoch [15/40] Iter[198/312]		Loss: 0.1442
2019-10-28 15:34:59,421 Training Epoch [15/40] Iter[199/312]		Loss: 0.1439
2019-10-28 15:34:59,501 Training Epoch [15/40] Iter[200/312]		Loss: 0.1440
2019-10-28 15:34:59,580 Training Epoch [15/40] Iter[201/312]		Loss: 0.1439
2019-10-28 15:34:59,660 Training Epoch [15/40] Iter[202/312]		Loss: 0.1441
2019-10-28 15:34:59,739 Training Epoch [15/40] Iter[203/312]		Loss: 0.1437
2019-10-28 15:34:59,818 Training Epoch [15/40] Iter[204/312]		Loss: 0.1436
2019-10-28 15:34:59,897 Training Epoch [15/40] Iter[205/312]		Loss: 0.1434
2019-10-28 15:34:59,976 Training Epoch [15/40] Iter[206/312]		Loss: 0.1436
2019-10-28 15:35:00,055 Training Epoch [15/40] Iter[207/312]		Loss: 0.1437
2019-10-28 15:35:00,135 Training Epoch [15/40] Iter[208/312]		Loss: 0.1436
2019-10-28 15:35:00,214 Training Epoch [15/40] Iter[209/312]		Loss: 0.1435
2019-10-28 15:35:00,294 Training Epoch [15/40] Iter[210/312]		Loss: 0.1433
2019-10-28 15:35:00,373 Training Epoch [15/40] Iter[211/312]		Loss: 0.1434
2019-10-28 15:35:00,452 Training Epoch [15/40] Iter[212/312]		Loss: 0.1434
2019-10-28 15:35:00,531 Training Epoch [15/40] Iter[213/312]		Loss: 0.1435
2019-10-28 15:35:00,610 Training Epoch [15/40] Iter[214/312]		Loss: 0.1434
2019-10-28 15:35:00,690 Training Epoch [15/40] Iter[215/312]		Loss: 0.1437
2019-10-28 15:35:00,769 Training Epoch [15/40] Iter[216/312]		Loss: 0.1436
2019-10-28 15:35:00,848 Training Epoch [15/40] Iter[217/312]		Loss: 0.1437
2019-10-28 15:35:00,926 Training Epoch [15/40] Iter[218/312]		Loss: 0.1435
2019-10-28 15:35:01,006 Training Epoch [15/40] Iter[219/312]		Loss: 0.1434
2019-10-28 15:35:01,084 Training Epoch [15/40] Iter[220/312]		Loss: 0.1433
2019-10-28 15:35:01,164 Training Epoch [15/40] Iter[221/312]		Loss: 0.1431
2019-10-28 15:35:01,243 Training Epoch [15/40] Iter[222/312]		Loss: 0.1428
2019-10-28 15:35:01,323 Training Epoch [15/40] Iter[223/312]		Loss: 0.1430
2019-10-28 15:35:01,402 Training Epoch [15/40] Iter[224/312]		Loss: 0.1429
2019-10-28 15:35:01,481 Training Epoch [15/40] Iter[225/312]		Loss: 0.1428
2019-10-28 15:35:01,560 Training Epoch [15/40] Iter[226/312]		Loss: 0.1430
2019-10-28 15:35:01,639 Training Epoch [15/40] Iter[227/312]		Loss: 0.1431
2019-10-28 15:35:01,718 Training Epoch [15/40] Iter[228/312]		Loss: 0.1433
2019-10-28 15:35:01,798 Training Epoch [15/40] Iter[229/312]		Loss: 0.1434
2019-10-28 15:35:01,877 Training Epoch [15/40] Iter[230/312]		Loss: 0.1434
2019-10-28 15:35:01,956 Training Epoch [15/40] Iter[231/312]		Loss: 0.1434
2019-10-28 15:35:02,035 Training Epoch [15/40] Iter[232/312]		Loss: 0.1438
2019-10-28 15:35:02,115 Training Epoch [15/40] Iter[233/312]		Loss: 0.1439
2019-10-28 15:35:02,195 Training Epoch [15/40] Iter[234/312]		Loss: 0.1437
2019-10-28 15:35:02,275 Training Epoch [15/40] Iter[235/312]		Loss: 0.1438
2019-10-28 15:35:02,355 Training Epoch [15/40] Iter[236/312]		Loss: 0.1442
2019-10-28 15:35:02,434 Training Epoch [15/40] Iter[237/312]		Loss: 0.1442
2019-10-28 15:35:02,513 Training Epoch [15/40] Iter[238/312]		Loss: 0.1444
2019-10-28 15:35:02,593 Training Epoch [15/40] Iter[239/312]		Loss: 0.1443
2019-10-28 15:35:02,672 Training Epoch [15/40] Iter[240/312]		Loss: 0.1445
2019-10-28 15:35:02,751 Training Epoch [15/40] Iter[241/312]		Loss: 0.1445
2019-10-28 15:35:02,830 Training Epoch [15/40] Iter[242/312]		Loss: 0.1449
2019-10-28 15:35:02,909 Training Epoch [15/40] Iter[243/312]		Loss: 0.1449
2019-10-28 15:35:02,989 Training Epoch [15/40] Iter[244/312]		Loss: 0.1450
2019-10-28 15:35:03,068 Training Epoch [15/40] Iter[245/312]		Loss: 0.1448
2019-10-28 15:35:03,147 Training Epoch [15/40] Iter[246/312]		Loss: 0.1455
2019-10-28 15:35:03,227 Training Epoch [15/40] Iter[247/312]		Loss: 0.1455
2019-10-28 15:35:03,306 Training Epoch [15/40] Iter[248/312]		Loss: 0.1454
2019-10-28 15:35:03,385 Training Epoch [15/40] Iter[249/312]		Loss: 0.1453
2019-10-28 15:35:03,464 Training Epoch [15/40] Iter[250/312]		Loss: 0.1452
2019-10-28 15:35:03,544 Training Epoch [15/40] Iter[251/312]		Loss: 0.1454
2019-10-28 15:35:03,623 Training Epoch [15/40] Iter[252/312]		Loss: 0.1453
2019-10-28 15:35:03,703 Training Epoch [15/40] Iter[253/312]		Loss: 0.1455
2019-10-28 15:35:03,782 Training Epoch [15/40] Iter[254/312]		Loss: 0.1454
2019-10-28 15:35:03,861 Training Epoch [15/40] Iter[255/312]		Loss: 0.1454
2019-10-28 15:35:03,940 Training Epoch [15/40] Iter[256/312]		Loss: 0.1453
2019-10-28 15:35:04,019 Training Epoch [15/40] Iter[257/312]		Loss: 0.1453
2019-10-28 15:35:04,098 Training Epoch [15/40] Iter[258/312]		Loss: 0.1455
2019-10-28 15:35:04,177 Training Epoch [15/40] Iter[259/312]		Loss: 0.1454
2019-10-28 15:35:04,257 Training Epoch [15/40] Iter[260/312]		Loss: 0.1458
2019-10-28 15:35:04,336 Training Epoch [15/40] Iter[261/312]		Loss: 0.1456
2019-10-28 15:35:04,416 Training Epoch [15/40] Iter[262/312]		Loss: 0.1456
2019-10-28 15:35:04,496 Training Epoch [15/40] Iter[263/312]		Loss: 0.1456
2019-10-28 15:35:04,575 Training Epoch [15/40] Iter[264/312]		Loss: 0.1454
2019-10-28 15:35:04,655 Training Epoch [15/40] Iter[265/312]		Loss: 0.1454
2019-10-28 15:35:04,734 Training Epoch [15/40] Iter[266/312]		Loss: 0.1453
2019-10-28 15:35:04,814 Training Epoch [15/40] Iter[267/312]		Loss: 0.1450
2019-10-28 15:35:04,894 Training Epoch [15/40] Iter[268/312]		Loss: 0.1450
2019-10-28 15:35:04,973 Training Epoch [15/40] Iter[269/312]		Loss: 0.1451
2019-10-28 15:35:05,053 Training Epoch [15/40] Iter[270/312]		Loss: 0.1450
2019-10-28 15:35:05,133 Training Epoch [15/40] Iter[271/312]		Loss: 0.1449
2019-10-28 15:35:05,213 Training Epoch [15/40] Iter[272/312]		Loss: 0.1448
2019-10-28 15:35:05,292 Training Epoch [15/40] Iter[273/312]		Loss: 0.1447
2019-10-28 15:35:05,372 Training Epoch [15/40] Iter[274/312]		Loss: 0.1447
2019-10-28 15:35:05,452 Training Epoch [15/40] Iter[275/312]		Loss: 0.1446
2019-10-28 15:35:05,531 Training Epoch [15/40] Iter[276/312]		Loss: 0.1450
2019-10-28 15:35:05,611 Training Epoch [15/40] Iter[277/312]		Loss: 0.1453
2019-10-28 15:35:05,691 Training Epoch [15/40] Iter[278/312]		Loss: 0.1454
2019-10-28 15:35:05,770 Training Epoch [15/40] Iter[279/312]		Loss: 0.1453
2019-10-28 15:35:05,851 Training Epoch [15/40] Iter[280/312]		Loss: 0.1452
2019-10-28 15:35:05,930 Training Epoch [15/40] Iter[281/312]		Loss: 0.1454
2019-10-28 15:35:06,010 Training Epoch [15/40] Iter[282/312]		Loss: 0.1455
2019-10-28 15:35:06,090 Training Epoch [15/40] Iter[283/312]		Loss: 0.1456
2019-10-28 15:35:06,170 Training Epoch [15/40] Iter[284/312]		Loss: 0.1454
2019-10-28 15:35:06,249 Training Epoch [15/40] Iter[285/312]		Loss: 0.1453
2019-10-28 15:35:06,329 Training Epoch [15/40] Iter[286/312]		Loss: 0.1453
2019-10-28 15:35:06,409 Training Epoch [15/40] Iter[287/312]		Loss: 0.1452
2019-10-28 15:35:06,488 Training Epoch [15/40] Iter[288/312]		Loss: 0.1453
2019-10-28 15:35:06,568 Training Epoch [15/40] Iter[289/312]		Loss: 0.1451
2019-10-28 15:35:06,647 Training Epoch [15/40] Iter[290/312]		Loss: 0.1450
2019-10-28 15:35:06,727 Training Epoch [15/40] Iter[291/312]		Loss: 0.1454
2019-10-28 15:35:06,806 Training Epoch [15/40] Iter[292/312]		Loss: 0.1453
2019-10-28 15:35:06,886 Training Epoch [15/40] Iter[293/312]		Loss: 0.1452
2019-10-28 15:35:06,966 Training Epoch [15/40] Iter[294/312]		Loss: 0.1452
2019-10-28 15:35:07,046 Training Epoch [15/40] Iter[295/312]		Loss: 0.1452
2019-10-28 15:35:07,126 Training Epoch [15/40] Iter[296/312]		Loss: 0.1452
2019-10-28 15:35:07,205 Training Epoch [15/40] Iter[297/312]		Loss: 0.1451
2019-10-28 15:35:07,285 Training Epoch [15/40] Iter[298/312]		Loss: 0.1454
2019-10-28 15:35:07,364 Training Epoch [15/40] Iter[299/312]		Loss: 0.1457
2019-10-28 15:35:07,444 Training Epoch [15/40] Iter[300/312]		Loss: 0.1458
2019-10-28 15:35:07,523 Training Epoch [15/40] Iter[301/312]		Loss: 0.1457
2019-10-28 15:35:07,602 Training Epoch [15/40] Iter[302/312]		Loss: 0.1461
2019-10-28 15:35:07,682 Training Epoch [15/40] Iter[303/312]		Loss: 0.1460
2019-10-28 15:35:07,761 Training Epoch [15/40] Iter[304/312]		Loss: 0.1458
2019-10-28 15:35:07,840 Training Epoch [15/40] Iter[305/312]		Loss: 0.1460
2019-10-28 15:35:07,918 Training Epoch [15/40] Iter[306/312]		Loss: 0.1460
2019-10-28 15:35:07,996 Training Epoch [15/40] Iter[307/312]		Loss: 0.1461
2019-10-28 15:35:08,074 Training Epoch [15/40] Iter[308/312]		Loss: 0.1460
2019-10-28 15:35:08,153 Training Epoch [15/40] Iter[309/312]		Loss: 0.1462
2019-10-28 15:35:08,232 Training Epoch [15/40] Iter[310/312]		Loss: 0.1461
2019-10-28 15:35:08,310 Training Epoch [15/40] Iter[311/312]		Loss: 0.1460
2019-10-28 15:35:08,349 Training Epoch [15/40] Iter[312/312]		Loss: 0.1460
2019-10-28 15:35:08,722 Testing Epoch [15/40] Iter[0/62]		Loss: 0.1498
2019-10-28 15:35:08,839 Testing Epoch [15/40] Iter[1/62]		Loss: 0.1508
2019-10-28 15:35:08,856 Testing Epoch [15/40] Iter[2/62]		Loss: 0.1370
2019-10-28 15:35:08,885 Testing Epoch [15/40] Iter[3/62]		Loss: 0.1419
2019-10-28 15:35:08,902 Testing Epoch [15/40] Iter[4/62]		Loss: 0.1442
2019-10-28 15:35:08,929 Testing Epoch [15/40] Iter[5/62]		Loss: 0.1383
2019-10-28 15:35:08,946 Testing Epoch [15/40] Iter[6/62]		Loss: 0.1408
2019-10-28 15:35:08,973 Testing Epoch [15/40] Iter[7/62]		Loss: 0.1439
2019-10-28 15:35:08,990 Testing Epoch [15/40] Iter[8/62]		Loss: 0.1452
2019-10-28 15:35:09,017 Testing Epoch [15/40] Iter[9/62]		Loss: 0.1434
2019-10-28 15:35:09,043 Testing Epoch [15/40] Iter[10/62]		Loss: 0.1423
2019-10-28 15:35:09,067 Testing Epoch [15/40] Iter[11/62]		Loss: 0.1479
2019-10-28 15:35:09,085 Testing Epoch [15/40] Iter[12/62]		Loss: 0.1472
2019-10-28 15:35:09,103 Testing Epoch [15/40] Iter[13/62]		Loss: 0.1487
2019-10-28 15:35:09,128 Testing Epoch [15/40] Iter[14/62]		Loss: 0.1627
2019-10-28 15:35:09,150 Testing Epoch [15/40] Iter[15/62]		Loss: 0.1650
2019-10-28 15:35:09,168 Testing Epoch [15/40] Iter[16/62]		Loss: 0.1620
2019-10-28 15:35:09,186 Testing Epoch [15/40] Iter[17/62]		Loss: 0.1624
2019-10-28 15:35:09,213 Testing Epoch [15/40] Iter[18/62]		Loss: 0.1597
2019-10-28 15:35:09,234 Testing Epoch [15/40] Iter[19/62]		Loss: 0.1570
2019-10-28 15:35:09,254 Testing Epoch [15/40] Iter[20/62]		Loss: 0.1586
2019-10-28 15:35:09,272 Testing Epoch [15/40] Iter[21/62]		Loss: 0.1571
2019-10-28 15:35:09,305 Testing Epoch [15/40] Iter[22/62]		Loss: 0.1584
2019-10-28 15:35:09,323 Testing Epoch [15/40] Iter[23/62]		Loss: 0.1573
2019-10-28 15:35:09,341 Testing Epoch [15/40] Iter[24/62]		Loss: 0.1609
2019-10-28 15:35:09,366 Testing Epoch [15/40] Iter[25/62]		Loss: 0.1600
2019-10-28 15:35:09,388 Testing Epoch [15/40] Iter[26/62]		Loss: 0.1584
2019-10-28 15:35:09,406 Testing Epoch [15/40] Iter[27/62]		Loss: 0.1665
2019-10-28 15:35:09,424 Testing Epoch [15/40] Iter[28/62]		Loss: 0.1700
2019-10-28 15:35:09,454 Testing Epoch [15/40] Iter[29/62]		Loss: 0.1709
2019-10-28 15:35:09,472 Testing Epoch [15/40] Iter[30/62]		Loss: 0.1713
2019-10-28 15:35:09,500 Testing Epoch [15/40] Iter[31/62]		Loss: 0.1702
2019-10-28 15:35:09,517 Testing Epoch [15/40] Iter[32/62]		Loss: 0.1714
2019-10-28 15:35:09,545 Testing Epoch [15/40] Iter[33/62]		Loss: 0.1705
2019-10-28 15:35:09,563 Testing Epoch [15/40] Iter[34/62]		Loss: 0.1730
2019-10-28 15:35:09,593 Testing Epoch [15/40] Iter[35/62]		Loss: 0.1725
2019-10-28 15:35:09,612 Testing Epoch [15/40] Iter[36/62]		Loss: 0.1704
2019-10-28 15:35:09,629 Testing Epoch [15/40] Iter[37/62]		Loss: 0.1693
2019-10-28 15:35:09,647 Testing Epoch [15/40] Iter[38/62]		Loss: 0.1682
2019-10-28 15:35:09,678 Testing Epoch [15/40] Iter[39/62]		Loss: 0.1688
2019-10-28 15:35:09,702 Testing Epoch [15/40] Iter[40/62]		Loss: 0.1706
2019-10-28 15:35:09,726 Testing Epoch [15/40] Iter[41/62]		Loss: 0.1723
2019-10-28 15:35:09,747 Testing Epoch [15/40] Iter[42/62]		Loss: 0.1707
2019-10-28 15:35:09,765 Testing Epoch [15/40] Iter[43/62]		Loss: 0.1698
2019-10-28 15:35:09,797 Testing Epoch [15/40] Iter[44/62]		Loss: 0.1681
2019-10-28 15:35:09,815 Testing Epoch [15/40] Iter[45/62]		Loss: 0.1680
2019-10-28 15:35:09,834 Testing Epoch [15/40] Iter[46/62]		Loss: 0.1671
2019-10-28 15:35:09,850 Testing Epoch [15/40] Iter[47/62]		Loss: 0.1730
2019-10-28 15:35:09,876 Testing Epoch [15/40] Iter[48/62]		Loss: 0.1718
2019-10-28 15:35:09,895 Testing Epoch [15/40] Iter[49/62]		Loss: 0.1744
2019-10-28 15:35:09,925 Testing Epoch [15/40] Iter[50/62]		Loss: 0.1736
2019-10-28 15:35:09,948 Testing Epoch [15/40] Iter[51/62]		Loss: 0.1737
2019-10-28 15:35:09,966 Testing Epoch [15/40] Iter[52/62]		Loss: 0.1725
2019-10-28 15:35:09,986 Testing Epoch [15/40] Iter[53/62]		Loss: 0.1729
2019-10-28 15:35:10,014 Testing Epoch [15/40] Iter[54/62]		Loss: 0.1716
2019-10-28 15:35:10,032 Testing Epoch [15/40] Iter[55/62]		Loss: 0.1715
2019-10-28 15:35:10,049 Testing Epoch [15/40] Iter[56/62]		Loss: 0.1707
2019-10-28 15:35:10,066 Testing Epoch [15/40] Iter[57/62]		Loss: 0.1709
2019-10-28 15:35:10,082 Testing Epoch [15/40] Iter[58/62]		Loss: 0.1703
2019-10-28 15:35:10,099 Testing Epoch [15/40] Iter[59/62]		Loss: 0.1714
2019-10-28 15:35:10,116 Testing Epoch [15/40] Iter[60/62]		Loss: 0.1708
2019-10-28 15:35:10,133 Testing Epoch [15/40] Iter[61/62]		Loss: 0.1707
2019-10-28 15:35:10,142 Testing Epoch [15/40] Iter[62/62]		Loss: 0.1717
2019-10-28 15:35:10,213 Saving the Model
2019-10-28 15:35:10,530 Training Epoch [16/40] Iter[0/312]		Loss: 0.1315
2019-10-28 15:35:10,680 Training Epoch [16/40] Iter[1/312]		Loss: 0.1500
2019-10-28 15:35:10,761 Training Epoch [16/40] Iter[2/312]		Loss: 0.1326
2019-10-28 15:35:10,840 Training Epoch [16/40] Iter[3/312]		Loss: 0.1222
2019-10-28 15:35:10,918 Training Epoch [16/40] Iter[4/312]		Loss: 0.1285
2019-10-28 15:35:10,996 Training Epoch [16/40] Iter[5/312]		Loss: 0.1387
2019-10-28 15:35:11,075 Training Epoch [16/40] Iter[6/312]		Loss: 0.1360
2019-10-28 15:35:11,154 Training Epoch [16/40] Iter[7/312]		Loss: 0.1338
2019-10-28 15:35:11,232 Training Epoch [16/40] Iter[8/312]		Loss: 0.1369
2019-10-28 15:35:11,311 Training Epoch [16/40] Iter[9/312]		Loss: 0.1319
2019-10-28 15:35:11,390 Training Epoch [16/40] Iter[10/312]		Loss: 0.1333
2019-10-28 15:35:11,469 Training Epoch [16/40] Iter[11/312]		Loss: 0.1359
2019-10-28 15:35:11,548 Training Epoch [16/40] Iter[12/312]		Loss: 0.1476
2019-10-28 15:35:11,626 Training Epoch [16/40] Iter[13/312]		Loss: 0.1447
2019-10-28 15:35:11,706 Training Epoch [16/40] Iter[14/312]		Loss: 0.1434
2019-10-28 15:35:11,785 Training Epoch [16/40] Iter[15/312]		Loss: 0.1404
2019-10-28 15:35:11,864 Training Epoch [16/40] Iter[16/312]		Loss: 0.1465
2019-10-28 15:35:11,943 Training Epoch [16/40] Iter[17/312]		Loss: 0.1495
2019-10-28 15:35:12,022 Training Epoch [16/40] Iter[18/312]		Loss: 0.1514
2019-10-28 15:35:12,101 Training Epoch [16/40] Iter[19/312]		Loss: 0.1497
2019-10-28 15:35:12,180 Training Epoch [16/40] Iter[20/312]		Loss: 0.1503
2019-10-28 15:35:12,260 Training Epoch [16/40] Iter[21/312]		Loss: 0.1484
2019-10-28 15:35:12,339 Training Epoch [16/40] Iter[22/312]		Loss: 0.1470
2019-10-28 15:35:12,418 Training Epoch [16/40] Iter[23/312]		Loss: 0.1464
2019-10-28 15:35:12,497 Training Epoch [16/40] Iter[24/312]		Loss: 0.1449
2019-10-28 15:35:12,576 Training Epoch [16/40] Iter[25/312]		Loss: 0.1478
2019-10-28 15:35:12,655 Training Epoch [16/40] Iter[26/312]		Loss: 0.1484
2019-10-28 15:35:12,734 Training Epoch [16/40] Iter[27/312]		Loss: 0.1498
2019-10-28 15:35:12,813 Training Epoch [16/40] Iter[28/312]		Loss: 0.1483
2019-10-28 15:35:12,892 Training Epoch [16/40] Iter[29/312]		Loss: 0.1467
2019-10-28 15:35:12,971 Training Epoch [16/40] Iter[30/312]		Loss: 0.1452
2019-10-28 15:35:13,050 Training Epoch [16/40] Iter[31/312]		Loss: 0.1453
2019-10-28 15:35:13,129 Training Epoch [16/40] Iter[32/312]		Loss: 0.1456
2019-10-28 15:35:13,208 Training Epoch [16/40] Iter[33/312]		Loss: 0.1443
2019-10-28 15:35:13,287 Training Epoch [16/40] Iter[34/312]		Loss: 0.1466
2019-10-28 15:35:13,366 Training Epoch [16/40] Iter[35/312]		Loss: 0.1467
2019-10-28 15:35:13,445 Training Epoch [16/40] Iter[36/312]		Loss: 0.1475
2019-10-28 15:35:13,524 Training Epoch [16/40] Iter[37/312]		Loss: 0.1459
2019-10-28 15:35:13,603 Training Epoch [16/40] Iter[38/312]		Loss: 0.1452
2019-10-28 15:35:13,682 Training Epoch [16/40] Iter[39/312]		Loss: 0.1454
2019-10-28 15:35:13,761 Training Epoch [16/40] Iter[40/312]		Loss: 0.1456
2019-10-28 15:35:13,840 Training Epoch [16/40] Iter[41/312]		Loss: 0.1492
2019-10-28 15:35:13,919 Training Epoch [16/40] Iter[42/312]		Loss: 0.1484
2019-10-28 15:35:13,998 Training Epoch [16/40] Iter[43/312]		Loss: 0.1481
2019-10-28 15:35:14,077 Training Epoch [16/40] Iter[44/312]		Loss: 0.1470
2019-10-28 15:35:14,156 Training Epoch [16/40] Iter[45/312]		Loss: 0.1481
2019-10-28 15:35:14,235 Training Epoch [16/40] Iter[46/312]		Loss: 0.1484
2019-10-28 15:35:14,314 Training Epoch [16/40] Iter[47/312]		Loss: 0.1479
2019-10-28 15:35:14,393 Training Epoch [16/40] Iter[48/312]		Loss: 0.1467
2019-10-28 15:35:14,472 Training Epoch [16/40] Iter[49/312]		Loss: 0.1457
2019-10-28 15:35:14,551 Training Epoch [16/40] Iter[50/312]		Loss: 0.1457
2019-10-28 15:35:14,630 Training Epoch [16/40] Iter[51/312]		Loss: 0.1450
2019-10-28 15:35:14,709 Training Epoch [16/40] Iter[52/312]		Loss: 0.1445
2019-10-28 15:35:14,789 Training Epoch [16/40] Iter[53/312]		Loss: 0.1442
2019-10-28 15:35:14,868 Training Epoch [16/40] Iter[54/312]		Loss: 0.1441
2019-10-28 15:35:14,947 Training Epoch [16/40] Iter[55/312]		Loss: 0.1432
2019-10-28 15:35:15,026 Training Epoch [16/40] Iter[56/312]		Loss: 0.1436
2019-10-28 15:35:15,105 Training Epoch [16/40] Iter[57/312]		Loss: 0.1443
2019-10-28 15:35:15,184 Training Epoch [16/40] Iter[58/312]		Loss: 0.1438
2019-10-28 15:35:15,264 Training Epoch [16/40] Iter[59/312]		Loss: 0.1445
2019-10-28 15:35:15,343 Training Epoch [16/40] Iter[60/312]		Loss: 0.1449
2019-10-28 15:35:15,423 Training Epoch [16/40] Iter[61/312]		Loss: 0.1447
2019-10-28 15:35:15,502 Training Epoch [16/40] Iter[62/312]		Loss: 0.1449
2019-10-28 15:35:15,582 Training Epoch [16/40] Iter[63/312]		Loss: 0.1446
2019-10-28 15:35:15,661 Training Epoch [16/40] Iter[64/312]		Loss: 0.1442
2019-10-28 15:35:15,741 Training Epoch [16/40] Iter[65/312]		Loss: 0.1439
2019-10-28 15:35:15,820 Training Epoch [16/40] Iter[66/312]		Loss: 0.1430
2019-10-28 15:35:15,899 Training Epoch [16/40] Iter[67/312]		Loss: 0.1431
2019-10-28 15:35:15,978 Training Epoch [16/40] Iter[68/312]		Loss: 0.1430
2019-10-28 15:35:16,058 Training Epoch [16/40] Iter[69/312]		Loss: 0.1432
2019-10-28 15:35:16,137 Training Epoch [16/40] Iter[70/312]		Loss: 0.1426
2019-10-28 15:35:16,216 Training Epoch [16/40] Iter[71/312]		Loss: 0.1431
2019-10-28 15:35:16,295 Training Epoch [16/40] Iter[72/312]		Loss: 0.1430
2019-10-28 15:35:16,375 Training Epoch [16/40] Iter[73/312]		Loss: 0.1438
2019-10-28 15:35:16,454 Training Epoch [16/40] Iter[74/312]		Loss: 0.1448
2019-10-28 15:35:16,533 Training Epoch [16/40] Iter[75/312]		Loss: 0.1468
2019-10-28 15:35:16,612 Training Epoch [16/40] Iter[76/312]		Loss: 0.1463
2019-10-28 15:35:16,691 Training Epoch [16/40] Iter[77/312]		Loss: 0.1455
2019-10-28 15:35:16,770 Training Epoch [16/40] Iter[78/312]		Loss: 0.1450
2019-10-28 15:35:16,849 Training Epoch [16/40] Iter[79/312]		Loss: 0.1447
2019-10-28 15:35:16,928 Training Epoch [16/40] Iter[80/312]		Loss: 0.1450
2019-10-28 15:35:17,007 Training Epoch [16/40] Iter[81/312]		Loss: 0.1452
2019-10-28 15:35:17,086 Training Epoch [16/40] Iter[82/312]		Loss: 0.1455
2019-10-28 15:35:17,165 Training Epoch [16/40] Iter[83/312]		Loss: 0.1456
2019-10-28 15:35:17,244 Training Epoch [16/40] Iter[84/312]		Loss: 0.1454
2019-10-28 15:35:17,323 Training Epoch [16/40] Iter[85/312]		Loss: 0.1458
2019-10-28 15:35:17,402 Training Epoch [16/40] Iter[86/312]		Loss: 0.1456
2019-10-28 15:35:17,482 Training Epoch [16/40] Iter[87/312]		Loss: 0.1458
2019-10-28 15:35:17,561 Training Epoch [16/40] Iter[88/312]		Loss: 0.1453
2019-10-28 15:35:17,640 Training Epoch [16/40] Iter[89/312]		Loss: 0.1451
2019-10-28 15:35:17,719 Training Epoch [16/40] Iter[90/312]		Loss: 0.1450
2019-10-28 15:35:17,799 Training Epoch [16/40] Iter[91/312]		Loss: 0.1445
2019-10-28 15:35:17,878 Training Epoch [16/40] Iter[92/312]		Loss: 0.1443
2019-10-28 15:35:17,958 Training Epoch [16/40] Iter[93/312]		Loss: 0.1441
2019-10-28 15:35:18,037 Training Epoch [16/40] Iter[94/312]		Loss: 0.1440
2019-10-28 15:35:18,116 Training Epoch [16/40] Iter[95/312]		Loss: 0.1439
2019-10-28 15:35:18,196 Training Epoch [16/40] Iter[96/312]		Loss: 0.1434
2019-10-28 15:35:18,276 Training Epoch [16/40] Iter[97/312]		Loss: 0.1431
2019-10-28 15:35:18,355 Training Epoch [16/40] Iter[98/312]		Loss: 0.1431
2019-10-28 15:35:18,434 Training Epoch [16/40] Iter[99/312]		Loss: 0.1429
2019-10-28 15:35:18,514 Training Epoch [16/40] Iter[100/312]		Loss: 0.1424
2019-10-28 15:35:18,593 Training Epoch [16/40] Iter[101/312]		Loss: 0.1431
2019-10-28 15:35:18,672 Training Epoch [16/40] Iter[102/312]		Loss: 0.1435
2019-10-28 15:35:18,754 Training Epoch [16/40] Iter[103/312]		Loss: 0.1434
2019-10-28 15:35:18,834 Training Epoch [16/40] Iter[104/312]		Loss: 0.1436
2019-10-28 15:35:18,912 Training Epoch [16/40] Iter[105/312]		Loss: 0.1433
2019-10-28 15:35:18,991 Training Epoch [16/40] Iter[106/312]		Loss: 0.1429
2019-10-28 15:35:19,070 Training Epoch [16/40] Iter[107/312]		Loss: 0.1426
2019-10-28 15:35:19,149 Training Epoch [16/40] Iter[108/312]		Loss: 0.1425
2019-10-28 15:35:19,228 Training Epoch [16/40] Iter[109/312]		Loss: 0.1430
2019-10-28 15:35:19,308 Training Epoch [16/40] Iter[110/312]		Loss: 0.1428
2019-10-28 15:35:19,387 Training Epoch [16/40] Iter[111/312]		Loss: 0.1432
2019-10-28 15:35:19,466 Training Epoch [16/40] Iter[112/312]		Loss: 0.1430
2019-10-28 15:35:19,545 Training Epoch [16/40] Iter[113/312]		Loss: 0.1427
2019-10-28 15:35:19,624 Training Epoch [16/40] Iter[114/312]		Loss: 0.1429
2019-10-28 15:35:19,703 Training Epoch [16/40] Iter[115/312]		Loss: 0.1428
2019-10-28 15:35:19,782 Training Epoch [16/40] Iter[116/312]		Loss: 0.1432
2019-10-28 15:35:19,862 Training Epoch [16/40] Iter[117/312]		Loss: 0.1440
2019-10-28 15:35:19,941 Training Epoch [16/40] Iter[118/312]		Loss: 0.1441
2019-10-28 15:35:20,020 Training Epoch [16/40] Iter[119/312]		Loss: 0.1440
2019-10-28 15:35:20,099 Training Epoch [16/40] Iter[120/312]		Loss: 0.1440
2019-10-28 15:35:20,179 Training Epoch [16/40] Iter[121/312]		Loss: 0.1445
2019-10-28 15:35:20,258 Training Epoch [16/40] Iter[122/312]		Loss: 0.1444
2019-10-28 15:35:20,337 Training Epoch [16/40] Iter[123/312]		Loss: 0.1441
2019-10-28 15:35:20,417 Training Epoch [16/40] Iter[124/312]		Loss: 0.1438
2019-10-28 15:35:20,496 Training Epoch [16/40] Iter[125/312]		Loss: 0.1446
2019-10-28 15:35:20,576 Training Epoch [16/40] Iter[126/312]		Loss: 0.1448
2019-10-28 15:35:20,656 Training Epoch [16/40] Iter[127/312]		Loss: 0.1446
2019-10-28 15:35:20,735 Training Epoch [16/40] Iter[128/312]		Loss: 0.1445
2019-10-28 15:35:20,815 Training Epoch [16/40] Iter[129/312]		Loss: 0.1448
2019-10-28 15:35:20,894 Training Epoch [16/40] Iter[130/312]		Loss: 0.1447
2019-10-28 15:35:20,973 Training Epoch [16/40] Iter[131/312]		Loss: 0.1448
2019-10-28 15:35:21,052 Training Epoch [16/40] Iter[132/312]		Loss: 0.1447
2019-10-28 15:35:21,131 Training Epoch [16/40] Iter[133/312]		Loss: 0.1445
2019-10-28 15:35:21,211 Training Epoch [16/40] Iter[134/312]		Loss: 0.1446
2019-10-28 15:35:21,290 Training Epoch [16/40] Iter[135/312]		Loss: 0.1448
2019-10-28 15:35:21,369 Training Epoch [16/40] Iter[136/312]		Loss: 0.1446
2019-10-28 15:35:21,448 Training Epoch [16/40] Iter[137/312]		Loss: 0.1448
2019-10-28 15:35:21,528 Training Epoch [16/40] Iter[138/312]		Loss: 0.1447
2019-10-28 15:35:21,607 Training Epoch [16/40] Iter[139/312]		Loss: 0.1443
2019-10-28 15:35:21,686 Training Epoch [16/40] Iter[140/312]		Loss: 0.1442
2019-10-28 15:35:21,765 Training Epoch [16/40] Iter[141/312]		Loss: 0.1440
2019-10-28 15:35:21,845 Training Epoch [16/40] Iter[142/312]		Loss: 0.1441
2019-10-28 15:35:21,924 Training Epoch [16/40] Iter[143/312]		Loss: 0.1439
2019-10-28 15:35:22,002 Training Epoch [16/40] Iter[144/312]		Loss: 0.1441
2019-10-28 15:35:22,082 Training Epoch [16/40] Iter[145/312]		Loss: 0.1438
2019-10-28 15:35:22,161 Training Epoch [16/40] Iter[146/312]		Loss: 0.1437
2019-10-28 15:35:22,240 Training Epoch [16/40] Iter[147/312]		Loss: 0.1438
2019-10-28 15:35:22,320 Training Epoch [16/40] Iter[148/312]		Loss: 0.1440
2019-10-28 15:35:22,399 Training Epoch [16/40] Iter[149/312]		Loss: 0.1439
2019-10-28 15:35:22,478 Training Epoch [16/40] Iter[150/312]		Loss: 0.1440
2019-10-28 15:35:22,557 Training Epoch [16/40] Iter[151/312]		Loss: 0.1438
2019-10-28 15:35:22,636 Training Epoch [16/40] Iter[152/312]		Loss: 0.1434
2019-10-28 15:35:22,715 Training Epoch [16/40] Iter[153/312]		Loss: 0.1433
2019-10-28 15:35:22,794 Training Epoch [16/40] Iter[154/312]		Loss: 0.1432
2019-10-28 15:35:22,873 Training Epoch [16/40] Iter[155/312]		Loss: 0.1432
2019-10-28 15:35:22,952 Training Epoch [16/40] Iter[156/312]		Loss: 0.1430
2019-10-28 15:35:23,032 Training Epoch [16/40] Iter[157/312]		Loss: 0.1426
2019-10-28 15:35:23,111 Training Epoch [16/40] Iter[158/312]		Loss: 0.1427
2019-10-28 15:35:23,190 Training Epoch [16/40] Iter[159/312]		Loss: 0.1427
2019-10-28 15:35:23,269 Training Epoch [16/40] Iter[160/312]		Loss: 0.1426
2019-10-28 15:35:23,349 Training Epoch [16/40] Iter[161/312]		Loss: 0.1429
2019-10-28 15:35:23,428 Training Epoch [16/40] Iter[162/312]		Loss: 0.1429
2019-10-28 15:35:23,508 Training Epoch [16/40] Iter[163/312]		Loss: 0.1428
2019-10-28 15:35:23,587 Training Epoch [16/40] Iter[164/312]		Loss: 0.1436
2019-10-28 15:35:23,667 Training Epoch [16/40] Iter[165/312]		Loss: 0.1434
2019-10-28 15:35:23,746 Training Epoch [16/40] Iter[166/312]		Loss: 0.1432
2019-10-28 15:35:23,825 Training Epoch [16/40] Iter[167/312]		Loss: 0.1431
2019-10-28 15:35:23,905 Training Epoch [16/40] Iter[168/312]		Loss: 0.1432
2019-10-28 15:35:23,984 Training Epoch [16/40] Iter[169/312]		Loss: 0.1430
2019-10-28 15:35:24,063 Training Epoch [16/40] Iter[170/312]		Loss: 0.1428
2019-10-28 15:35:24,142 Training Epoch [16/40] Iter[171/312]		Loss: 0.1439
2019-10-28 15:35:24,222 Training Epoch [16/40] Iter[172/312]		Loss: 0.1438
2019-10-28 15:35:24,301 Training Epoch [16/40] Iter[173/312]		Loss: 0.1438
2019-10-28 15:35:24,380 Training Epoch [16/40] Iter[174/312]		Loss: 0.1436
2019-10-28 15:35:24,460 Training Epoch [16/40] Iter[175/312]		Loss: 0.1434
2019-10-28 15:35:24,539 Training Epoch [16/40] Iter[176/312]		Loss: 0.1433
2019-10-28 15:35:24,618 Training Epoch [16/40] Iter[177/312]		Loss: 0.1439
2019-10-28 15:35:24,697 Training Epoch [16/40] Iter[178/312]		Loss: 0.1436
2019-10-28 15:35:24,776 Training Epoch [16/40] Iter[179/312]		Loss: 0.1434
2019-10-28 15:35:24,856 Training Epoch [16/40] Iter[180/312]		Loss: 0.1434
2019-10-28 15:35:24,935 Training Epoch [16/40] Iter[181/312]		Loss: 0.1433
2019-10-28 15:35:25,014 Training Epoch [16/40] Iter[182/312]		Loss: 0.1433
2019-10-28 15:35:25,093 Training Epoch [16/40] Iter[183/312]		Loss: 0.1438
2019-10-28 15:35:25,173 Training Epoch [16/40] Iter[184/312]		Loss: 0.1436
2019-10-28 15:35:25,252 Training Epoch [16/40] Iter[185/312]		Loss: 0.1437
2019-10-28 15:35:25,331 Training Epoch [16/40] Iter[186/312]		Loss: 0.1440
2019-10-28 15:35:25,410 Training Epoch [16/40] Iter[187/312]		Loss: 0.1439
2019-10-28 15:35:25,489 Training Epoch [16/40] Iter[188/312]		Loss: 0.1440
2019-10-28 15:35:25,568 Training Epoch [16/40] Iter[189/312]		Loss: 0.1439
2019-10-28 15:35:25,647 Training Epoch [16/40] Iter[190/312]		Loss: 0.1438
2019-10-28 15:35:25,726 Training Epoch [16/40] Iter[191/312]		Loss: 0.1440
2019-10-28 15:35:25,805 Training Epoch [16/40] Iter[192/312]		Loss: 0.1438
2019-10-28 15:35:25,884 Training Epoch [16/40] Iter[193/312]		Loss: 0.1436
2019-10-28 15:35:25,962 Training Epoch [16/40] Iter[194/312]		Loss: 0.1438
2019-10-28 15:35:26,042 Training Epoch [16/40] Iter[195/312]		Loss: 0.1436
2019-10-28 15:35:26,120 Training Epoch [16/40] Iter[196/312]		Loss: 0.1439
2019-10-28 15:35:26,199 Training Epoch [16/40] Iter[197/312]		Loss: 0.1438
2019-10-28 15:35:26,278 Training Epoch [16/40] Iter[198/312]		Loss: 0.1442
2019-10-28 15:35:26,358 Training Epoch [16/40] Iter[199/312]		Loss: 0.1440
2019-10-28 15:35:26,436 Training Epoch [16/40] Iter[200/312]		Loss: 0.1442
2019-10-28 15:35:26,515 Training Epoch [16/40] Iter[201/312]		Loss: 0.1443
2019-10-28 15:35:26,595 Training Epoch [16/40] Iter[202/312]		Loss: 0.1446
2019-10-28 15:35:26,674 Training Epoch [16/40] Iter[203/312]		Loss: 0.1443
2019-10-28 15:35:26,753 Training Epoch [16/40] Iter[204/312]		Loss: 0.1442
2019-10-28 15:35:26,832 Training Epoch [16/40] Iter[205/312]		Loss: 0.1439
2019-10-28 15:35:26,911 Training Epoch [16/40] Iter[206/312]		Loss: 0.1436
2019-10-28 15:35:26,991 Training Epoch [16/40] Iter[207/312]		Loss: 0.1436
2019-10-28 15:35:27,070 Training Epoch [16/40] Iter[208/312]		Loss: 0.1434
2019-10-28 15:35:27,149 Training Epoch [16/40] Iter[209/312]		Loss: 0.1434
2019-10-28 15:35:27,228 Training Epoch [16/40] Iter[210/312]		Loss: 0.1434
2019-10-28 15:35:27,308 Training Epoch [16/40] Iter[211/312]		Loss: 0.1432
2019-10-28 15:35:27,387 Training Epoch [16/40] Iter[212/312]		Loss: 0.1431
2019-10-28 15:35:27,466 Training Epoch [16/40] Iter[213/312]		Loss: 0.1433
2019-10-28 15:35:27,546 Training Epoch [16/40] Iter[214/312]		Loss: 0.1431
2019-10-28 15:35:27,625 Training Epoch [16/40] Iter[215/312]		Loss: 0.1432
2019-10-28 15:35:27,704 Training Epoch [16/40] Iter[216/312]		Loss: 0.1429
2019-10-28 15:35:27,784 Training Epoch [16/40] Iter[217/312]		Loss: 0.1429
2019-10-28 15:35:27,863 Training Epoch [16/40] Iter[218/312]		Loss: 0.1426
2019-10-28 15:35:27,942 Training Epoch [16/40] Iter[219/312]		Loss: 0.1425
2019-10-28 15:35:28,021 Training Epoch [16/40] Iter[220/312]		Loss: 0.1426
2019-10-28 15:35:28,100 Training Epoch [16/40] Iter[221/312]		Loss: 0.1427
2019-10-28 15:35:28,179 Training Epoch [16/40] Iter[222/312]		Loss: 0.1427
2019-10-28 15:35:28,258 Training Epoch [16/40] Iter[223/312]		Loss: 0.1428
2019-10-28 15:35:28,338 Training Epoch [16/40] Iter[224/312]		Loss: 0.1429
2019-10-28 15:35:28,417 Training Epoch [16/40] Iter[225/312]		Loss: 0.1435
2019-10-28 15:35:28,496 Training Epoch [16/40] Iter[226/312]		Loss: 0.1433
2019-10-28 15:35:28,576 Training Epoch [16/40] Iter[227/312]		Loss: 0.1432
2019-10-28 15:35:28,655 Training Epoch [16/40] Iter[228/312]		Loss: 0.1431
2019-10-28 15:35:28,734 Training Epoch [16/40] Iter[229/312]		Loss: 0.1432
2019-10-28 15:35:28,814 Training Epoch [16/40] Iter[230/312]		Loss: 0.1430
2019-10-28 15:35:28,893 Training Epoch [16/40] Iter[231/312]		Loss: 0.1430
2019-10-28 15:35:28,972 Training Epoch [16/40] Iter[232/312]		Loss: 0.1428
2019-10-28 15:35:29,051 Training Epoch [16/40] Iter[233/312]		Loss: 0.1427
2019-10-28 15:35:29,136 Training Epoch [16/40] Iter[234/312]		Loss: 0.1427
2019-10-28 15:35:29,215 Training Epoch [16/40] Iter[235/312]		Loss: 0.1426
2019-10-28 15:35:29,294 Training Epoch [16/40] Iter[236/312]		Loss: 0.1425
2019-10-28 15:35:29,373 Training Epoch [16/40] Iter[237/312]		Loss: 0.1422
2019-10-28 15:35:29,455 Training Epoch [16/40] Iter[238/312]		Loss: 0.1421
2019-10-28 15:35:29,533 Training Epoch [16/40] Iter[239/312]		Loss: 0.1424
2019-10-28 15:35:29,613 Training Epoch [16/40] Iter[240/312]		Loss: 0.1424
2019-10-28 15:35:29,692 Training Epoch [16/40] Iter[241/312]		Loss: 0.1424
2019-10-28 15:35:29,771 Training Epoch [16/40] Iter[242/312]		Loss: 0.1424
2019-10-28 15:35:29,850 Training Epoch [16/40] Iter[243/312]		Loss: 0.1428
2019-10-28 15:35:29,929 Training Epoch [16/40] Iter[244/312]		Loss: 0.1428
2019-10-28 15:35:30,008 Training Epoch [16/40] Iter[245/312]		Loss: 0.1427
2019-10-28 15:35:30,087 Training Epoch [16/40] Iter[246/312]		Loss: 0.1426
2019-10-28 15:35:30,166 Training Epoch [16/40] Iter[247/312]		Loss: 0.1424
2019-10-28 15:35:30,245 Training Epoch [16/40] Iter[248/312]		Loss: 0.1424
2019-10-28 15:35:30,324 Training Epoch [16/40] Iter[249/312]		Loss: 0.1422
2019-10-28 15:35:30,403 Training Epoch [16/40] Iter[250/312]		Loss: 0.1423
2019-10-28 15:35:30,482 Training Epoch [16/40] Iter[251/312]		Loss: 0.1421
2019-10-28 15:35:30,561 Training Epoch [16/40] Iter[252/312]		Loss: 0.1420
2019-10-28 15:35:30,640 Training Epoch [16/40] Iter[253/312]		Loss: 0.1418
2019-10-28 15:35:30,719 Training Epoch [16/40] Iter[254/312]		Loss: 0.1417
2019-10-28 15:35:30,798 Training Epoch [16/40] Iter[255/312]		Loss: 0.1416
2019-10-28 15:35:30,877 Training Epoch [16/40] Iter[256/312]		Loss: 0.1419
2019-10-28 15:35:30,956 Training Epoch [16/40] Iter[257/312]		Loss: 0.1419
2019-10-28 15:35:31,035 Training Epoch [16/40] Iter[258/312]		Loss: 0.1417
2019-10-28 15:35:31,114 Training Epoch [16/40] Iter[259/312]		Loss: 0.1418
2019-10-28 15:35:31,194 Training Epoch [16/40] Iter[260/312]		Loss: 0.1419
2019-10-28 15:35:31,273 Training Epoch [16/40] Iter[261/312]		Loss: 0.1419
2019-10-28 15:35:31,352 Training Epoch [16/40] Iter[262/312]		Loss: 0.1418
2019-10-28 15:35:31,431 Training Epoch [16/40] Iter[263/312]		Loss: 0.1416
2019-10-28 15:35:31,511 Training Epoch [16/40] Iter[264/312]		Loss: 0.1417
2019-10-28 15:35:31,590 Training Epoch [16/40] Iter[265/312]		Loss: 0.1416
2019-10-28 15:35:31,669 Training Epoch [16/40] Iter[266/312]		Loss: 0.1416
2019-10-28 15:35:31,748 Training Epoch [16/40] Iter[267/312]		Loss: 0.1418
2019-10-28 15:35:31,827 Training Epoch [16/40] Iter[268/312]		Loss: 0.1417
2019-10-28 15:35:31,907 Training Epoch [16/40] Iter[269/312]		Loss: 0.1416
2019-10-28 15:35:31,986 Training Epoch [16/40] Iter[270/312]		Loss: 0.1416
2019-10-28 15:35:32,065 Training Epoch [16/40] Iter[271/312]		Loss: 0.1419
2019-10-28 15:35:32,144 Training Epoch [16/40] Iter[272/312]		Loss: 0.1420
2019-10-28 15:35:32,224 Training Epoch [16/40] Iter[273/312]		Loss: 0.1418
2019-10-28 15:35:32,303 Training Epoch [16/40] Iter[274/312]		Loss: 0.1419
2019-10-28 15:35:32,382 Training Epoch [16/40] Iter[275/312]		Loss: 0.1417
2019-10-28 15:35:32,462 Training Epoch [16/40] Iter[276/312]		Loss: 0.1417
2019-10-28 15:35:32,541 Training Epoch [16/40] Iter[277/312]		Loss: 0.1416
2019-10-28 15:35:32,620 Training Epoch [16/40] Iter[278/312]		Loss: 0.1415
2019-10-28 15:35:32,700 Training Epoch [16/40] Iter[279/312]		Loss: 0.1412
2019-10-28 15:35:32,779 Training Epoch [16/40] Iter[280/312]		Loss: 0.1411
2019-10-28 15:35:32,858 Training Epoch [16/40] Iter[281/312]		Loss: 0.1413
2019-10-28 15:35:32,937 Training Epoch [16/40] Iter[282/312]		Loss: 0.1413
2019-10-28 15:35:33,017 Training Epoch [16/40] Iter[283/312]		Loss: 0.1417
2019-10-28 15:35:33,096 Training Epoch [16/40] Iter[284/312]		Loss: 0.1416
2019-10-28 15:35:33,176 Training Epoch [16/40] Iter[285/312]		Loss: 0.1415
2019-10-28 15:35:33,256 Training Epoch [16/40] Iter[286/312]		Loss: 0.1417
2019-10-28 15:35:33,336 Training Epoch [16/40] Iter[287/312]		Loss: 0.1416
2019-10-28 15:35:33,415 Training Epoch [16/40] Iter[288/312]		Loss: 0.1416
2019-10-28 15:35:33,495 Training Epoch [16/40] Iter[289/312]		Loss: 0.1415
2019-10-28 15:35:33,574 Training Epoch [16/40] Iter[290/312]		Loss: 0.1413
2019-10-28 15:35:33,653 Training Epoch [16/40] Iter[291/312]		Loss: 0.1413
2019-10-28 15:35:33,733 Training Epoch [16/40] Iter[292/312]		Loss: 0.1412
2019-10-28 15:35:33,812 Training Epoch [16/40] Iter[293/312]		Loss: 0.1411
2019-10-28 15:35:33,892 Training Epoch [16/40] Iter[294/312]		Loss: 0.1413
2019-10-28 15:35:33,971 Training Epoch [16/40] Iter[295/312]		Loss: 0.1414
2019-10-28 15:35:34,051 Training Epoch [16/40] Iter[296/312]		Loss: 0.1415
2019-10-28 15:35:34,130 Training Epoch [16/40] Iter[297/312]		Loss: 0.1416
2019-10-28 15:35:34,210 Training Epoch [16/40] Iter[298/312]		Loss: 0.1415
2019-10-28 15:35:34,290 Training Epoch [16/40] Iter[299/312]		Loss: 0.1415
2019-10-28 15:35:34,369 Training Epoch [16/40] Iter[300/312]		Loss: 0.1414
2019-10-28 15:35:34,448 Training Epoch [16/40] Iter[301/312]		Loss: 0.1416
2019-10-28 15:35:34,528 Training Epoch [16/40] Iter[302/312]		Loss: 0.1416
2019-10-28 15:35:34,607 Training Epoch [16/40] Iter[303/312]		Loss: 0.1414
2019-10-28 15:35:34,686 Training Epoch [16/40] Iter[304/312]		Loss: 0.1412
2019-10-28 15:35:34,765 Training Epoch [16/40] Iter[305/312]		Loss: 0.1411
2019-10-28 15:35:34,844 Training Epoch [16/40] Iter[306/312]		Loss: 0.1413
2019-10-28 15:35:34,922 Training Epoch [16/40] Iter[307/312]		Loss: 0.1412
2019-10-28 15:35:35,001 Training Epoch [16/40] Iter[308/312]		Loss: 0.1411
2019-10-28 15:35:35,079 Training Epoch [16/40] Iter[309/312]		Loss: 0.1410
2019-10-28 15:35:35,158 Training Epoch [16/40] Iter[310/312]		Loss: 0.1409
2019-10-28 15:35:35,237 Training Epoch [16/40] Iter[311/312]		Loss: 0.1410
2019-10-28 15:35:35,276 Training Epoch [16/40] Iter[312/312]		Loss: 0.1409
2019-10-28 15:35:35,702 Testing Epoch [16/40] Iter[0/62]		Loss: 0.1568
2019-10-28 15:35:35,730 Testing Epoch [16/40] Iter[1/62]		Loss: 0.1518
2019-10-28 15:35:35,766 Testing Epoch [16/40] Iter[2/62]		Loss: 0.1335
2019-10-28 15:35:35,792 Testing Epoch [16/40] Iter[3/62]		Loss: 0.1368
2019-10-28 15:35:35,815 Testing Epoch [16/40] Iter[4/62]		Loss: 0.1338
2019-10-28 15:35:35,845 Testing Epoch [16/40] Iter[5/62]		Loss: 0.1275
2019-10-28 15:35:35,861 Testing Epoch [16/40] Iter[6/62]		Loss: 0.1294
2019-10-28 15:35:35,879 Testing Epoch [16/40] Iter[7/62]		Loss: 0.1327
2019-10-28 15:35:35,904 Testing Epoch [16/40] Iter[8/62]		Loss: 0.1351
2019-10-28 15:35:35,933 Testing Epoch [16/40] Iter[9/62]		Loss: 0.1348
2019-10-28 15:35:35,953 Testing Epoch [16/40] Iter[10/62]		Loss: 0.1357
2019-10-28 15:35:35,970 Testing Epoch [16/40] Iter[11/62]		Loss: 0.1407
2019-10-28 15:35:35,988 Testing Epoch [16/40] Iter[12/62]		Loss: 0.1421
2019-10-28 15:35:36,018 Testing Epoch [16/40] Iter[13/62]		Loss: 0.1423
2019-10-28 15:35:36,038 Testing Epoch [16/40] Iter[14/62]		Loss: 0.1581
2019-10-28 15:35:36,056 Testing Epoch [16/40] Iter[15/62]		Loss: 0.1597
2019-10-28 15:35:36,074 Testing Epoch [16/40] Iter[16/62]		Loss: 0.1571
2019-10-28 15:35:36,105 Testing Epoch [16/40] Iter[17/62]		Loss: 0.1562
2019-10-28 15:35:36,123 Testing Epoch [16/40] Iter[18/62]		Loss: 0.1525
2019-10-28 15:35:36,153 Testing Epoch [16/40] Iter[19/62]		Loss: 0.1504
2019-10-28 15:35:36,171 Testing Epoch [16/40] Iter[20/62]		Loss: 0.1521
2019-10-28 15:35:36,201 Testing Epoch [16/40] Iter[21/62]		Loss: 0.1510
2019-10-28 15:35:36,221 Testing Epoch [16/40] Iter[22/62]		Loss: 0.1521
2019-10-28 15:35:36,238 Testing Epoch [16/40] Iter[23/62]		Loss: 0.1514
2019-10-28 15:35:36,256 Testing Epoch [16/40] Iter[24/62]		Loss: 0.1557
2019-10-28 15:35:36,292 Testing Epoch [16/40] Iter[25/62]		Loss: 0.1544
2019-10-28 15:35:36,309 Testing Epoch [16/40] Iter[26/62]		Loss: 0.1527
2019-10-28 15:35:36,327 Testing Epoch [16/40] Iter[27/62]		Loss: 0.1601
2019-10-28 15:35:36,344 Testing Epoch [16/40] Iter[28/62]		Loss: 0.1638
2019-10-28 15:35:36,378 Testing Epoch [16/40] Iter[29/62]		Loss: 0.1640
2019-10-28 15:35:36,396 Testing Epoch [16/40] Iter[30/62]		Loss: 0.1648
2019-10-28 15:35:36,413 Testing Epoch [16/40] Iter[31/62]		Loss: 0.1637
2019-10-28 15:35:36,430 Testing Epoch [16/40] Iter[32/62]		Loss: 0.1653
2019-10-28 15:35:36,462 Testing Epoch [16/40] Iter[33/62]		Loss: 0.1646
2019-10-28 15:35:36,479 Testing Epoch [16/40] Iter[34/62]		Loss: 0.1669
2019-10-28 15:35:36,498 Testing Epoch [16/40] Iter[35/62]		Loss: 0.1665
2019-10-28 15:35:36,526 Testing Epoch [16/40] Iter[36/62]		Loss: 0.1644
2019-10-28 15:35:36,543 Testing Epoch [16/40] Iter[37/62]		Loss: 0.1632
2019-10-28 15:35:36,561 Testing Epoch [16/40] Iter[38/62]		Loss: 0.1620
2019-10-28 15:35:36,579 Testing Epoch [16/40] Iter[39/62]		Loss: 0.1627
2019-10-28 15:35:36,610 Testing Epoch [16/40] Iter[40/62]		Loss: 0.1643
2019-10-28 15:35:36,628 Testing Epoch [16/40] Iter[41/62]		Loss: 0.1665
2019-10-28 15:35:36,645 Testing Epoch [16/40] Iter[42/62]		Loss: 0.1644
2019-10-28 15:35:36,663 Testing Epoch [16/40] Iter[43/62]		Loss: 0.1637
2019-10-28 15:35:36,690 Testing Epoch [16/40] Iter[44/62]		Loss: 0.1620
2019-10-28 15:35:36,714 Testing Epoch [16/40] Iter[45/62]		Loss: 0.1621
2019-10-28 15:35:36,731 Testing Epoch [16/40] Iter[46/62]		Loss: 0.1618
2019-10-28 15:35:36,757 Testing Epoch [16/40] Iter[47/62]		Loss: 0.1675
2019-10-28 15:35:36,784 Testing Epoch [16/40] Iter[48/62]		Loss: 0.1665
2019-10-28 15:35:36,805 Testing Epoch [16/40] Iter[49/62]		Loss: 0.1691
2019-10-28 15:35:36,822 Testing Epoch [16/40] Iter[50/62]		Loss: 0.1685
2019-10-28 15:35:36,840 Testing Epoch [16/40] Iter[51/62]		Loss: 0.1684
2019-10-28 15:35:36,870 Testing Epoch [16/40] Iter[52/62]		Loss: 0.1670
2019-10-28 15:35:36,888 Testing Epoch [16/40] Iter[53/62]		Loss: 0.1677
2019-10-28 15:35:36,905 Testing Epoch [16/40] Iter[54/62]		Loss: 0.1665
2019-10-28 15:35:36,922 Testing Epoch [16/40] Iter[55/62]		Loss: 0.1662
2019-10-28 15:35:36,939 Testing Epoch [16/40] Iter[56/62]		Loss: 0.1657
2019-10-28 15:35:36,955 Testing Epoch [16/40] Iter[57/62]		Loss: 0.1661
2019-10-28 15:35:36,972 Testing Epoch [16/40] Iter[58/62]		Loss: 0.1653
2019-10-28 15:35:36,988 Testing Epoch [16/40] Iter[59/62]		Loss: 0.1663
2019-10-28 15:35:37,005 Testing Epoch [16/40] Iter[60/62]		Loss: 0.1652
2019-10-28 15:35:37,022 Testing Epoch [16/40] Iter[61/62]		Loss: 0.1656
2019-10-28 15:35:37,031 Testing Epoch [16/40] Iter[62/62]		Loss: 0.1669
2019-10-28 15:35:37,101 Saving the Model
2019-10-28 15:35:37,505 Training Epoch [17/40] Iter[0/312]		Loss: 0.1460
2019-10-28 15:35:37,593 Training Epoch [17/40] Iter[1/312]		Loss: 0.1304
2019-10-28 15:35:37,673 Training Epoch [17/40] Iter[2/312]		Loss: 0.1248
2019-10-28 15:35:37,759 Training Epoch [17/40] Iter[3/312]		Loss: 0.1352
2019-10-28 15:35:37,836 Training Epoch [17/40] Iter[4/312]		Loss: 0.1272
2019-10-28 15:35:37,914 Training Epoch [17/40] Iter[5/312]		Loss: 0.1285
2019-10-28 15:35:37,994 Training Epoch [17/40] Iter[6/312]		Loss: 0.1292
2019-10-28 15:35:38,073 Training Epoch [17/40] Iter[7/312]		Loss: 0.1311
2019-10-28 15:35:38,153 Training Epoch [17/40] Iter[8/312]		Loss: 0.1337
2019-10-28 15:35:38,232 Training Epoch [17/40] Iter[9/312]		Loss: 0.1365
2019-10-28 15:35:38,311 Training Epoch [17/40] Iter[10/312]		Loss: 0.1327
2019-10-28 15:35:38,391 Training Epoch [17/40] Iter[11/312]		Loss: 0.1313
2019-10-28 15:35:38,470 Training Epoch [17/40] Iter[12/312]		Loss: 0.1302
2019-10-28 15:35:38,549 Training Epoch [17/40] Iter[13/312]		Loss: 0.1288
2019-10-28 15:35:38,628 Training Epoch [17/40] Iter[14/312]		Loss: 0.1314
2019-10-28 15:35:38,707 Training Epoch [17/40] Iter[15/312]		Loss: 0.1304
2019-10-28 15:35:38,786 Training Epoch [17/40] Iter[16/312]		Loss: 0.1297
2019-10-28 15:35:38,865 Training Epoch [17/40] Iter[17/312]		Loss: 0.1313
2019-10-28 15:35:38,944 Training Epoch [17/40] Iter[18/312]		Loss: 0.1294
2019-10-28 15:35:39,023 Training Epoch [17/40] Iter[19/312]		Loss: 0.1318
2019-10-28 15:35:39,102 Training Epoch [17/40] Iter[20/312]		Loss: 0.1325
2019-10-28 15:35:39,181 Training Epoch [17/40] Iter[21/312]		Loss: 0.1308
2019-10-28 15:35:39,260 Training Epoch [17/40] Iter[22/312]		Loss: 0.1287
2019-10-28 15:35:39,339 Training Epoch [17/40] Iter[23/312]		Loss: 0.1320
2019-10-28 15:35:39,418 Training Epoch [17/40] Iter[24/312]		Loss: 0.1314
2019-10-28 15:35:39,497 Training Epoch [17/40] Iter[25/312]		Loss: 0.1331
2019-10-28 15:35:39,575 Training Epoch [17/40] Iter[26/312]		Loss: 0.1314
2019-10-28 15:35:39,654 Training Epoch [17/40] Iter[27/312]		Loss: 0.1313
2019-10-28 15:35:39,733 Training Epoch [17/40] Iter[28/312]		Loss: 0.1309
2019-10-28 15:35:39,812 Training Epoch [17/40] Iter[29/312]		Loss: 0.1312
2019-10-28 15:35:39,891 Training Epoch [17/40] Iter[30/312]		Loss: 0.1314
2019-10-28 15:35:39,970 Training Epoch [17/40] Iter[31/312]		Loss: 0.1298
2019-10-28 15:35:40,049 Training Epoch [17/40] Iter[32/312]		Loss: 0.1303
2019-10-28 15:35:40,128 Training Epoch [17/40] Iter[33/312]		Loss: 0.1287
2019-10-28 15:35:40,207 Training Epoch [17/40] Iter[34/312]		Loss: 0.1282
2019-10-28 15:35:40,286 Training Epoch [17/40] Iter[35/312]		Loss: 0.1301
2019-10-28 15:35:40,365 Training Epoch [17/40] Iter[36/312]		Loss: 0.1314
2019-10-28 15:35:40,444 Training Epoch [17/40] Iter[37/312]		Loss: 0.1316
2019-10-28 15:35:40,523 Training Epoch [17/40] Iter[38/312]		Loss: 0.1308
2019-10-28 15:35:40,602 Training Epoch [17/40] Iter[39/312]		Loss: 0.1302
2019-10-28 15:35:40,681 Training Epoch [17/40] Iter[40/312]		Loss: 0.1307
2019-10-28 15:35:40,760 Training Epoch [17/40] Iter[41/312]		Loss: 0.1320
2019-10-28 15:35:40,839 Training Epoch [17/40] Iter[42/312]		Loss: 0.1311
2019-10-28 15:35:40,918 Training Epoch [17/40] Iter[43/312]		Loss: 0.1309
2019-10-28 15:35:40,996 Training Epoch [17/40] Iter[44/312]		Loss: 0.1305
2019-10-28 15:35:41,075 Training Epoch [17/40] Iter[45/312]		Loss: 0.1305
2019-10-28 15:35:41,154 Training Epoch [17/40] Iter[46/312]		Loss: 0.1311
2019-10-28 15:35:41,233 Training Epoch [17/40] Iter[47/312]		Loss: 0.1300
2019-10-28 15:35:41,312 Training Epoch [17/40] Iter[48/312]		Loss: 0.1296
2019-10-28 15:35:41,391 Training Epoch [17/40] Iter[49/312]		Loss: 0.1298
2019-10-28 15:35:41,470 Training Epoch [17/40] Iter[50/312]		Loss: 0.1302
2019-10-28 15:35:41,549 Training Epoch [17/40] Iter[51/312]		Loss: 0.1298
2019-10-28 15:35:41,628 Training Epoch [17/40] Iter[52/312]		Loss: 0.1288
2019-10-28 15:35:41,707 Training Epoch [17/40] Iter[53/312]		Loss: 0.1299
2019-10-28 15:35:41,786 Training Epoch [17/40] Iter[54/312]		Loss: 0.1309
2019-10-28 15:35:41,865 Training Epoch [17/40] Iter[55/312]		Loss: 0.1324
2019-10-28 15:35:41,944 Training Epoch [17/40] Iter[56/312]		Loss: 0.1328
2019-10-28 15:35:42,023 Training Epoch [17/40] Iter[57/312]		Loss: 0.1321
2019-10-28 15:35:42,102 Training Epoch [17/40] Iter[58/312]		Loss: 0.1319
2019-10-28 15:35:42,181 Training Epoch [17/40] Iter[59/312]		Loss: 0.1312
2019-10-28 15:35:42,260 Training Epoch [17/40] Iter[60/312]		Loss: 0.1314
2019-10-28 15:35:42,339 Training Epoch [17/40] Iter[61/312]		Loss: 0.1311
2019-10-28 15:35:42,418 Training Epoch [17/40] Iter[62/312]		Loss: 0.1310
2019-10-28 15:35:42,497 Training Epoch [17/40] Iter[63/312]		Loss: 0.1326
2019-10-28 15:35:42,576 Training Epoch [17/40] Iter[64/312]		Loss: 0.1336
2019-10-28 15:35:42,655 Training Epoch [17/40] Iter[65/312]		Loss: 0.1336
2019-10-28 15:35:42,734 Training Epoch [17/40] Iter[66/312]		Loss: 0.1339
2019-10-28 15:35:42,813 Training Epoch [17/40] Iter[67/312]		Loss: 0.1344
2019-10-28 15:35:42,892 Training Epoch [17/40] Iter[68/312]		Loss: 0.1343
2019-10-28 15:35:42,970 Training Epoch [17/40] Iter[69/312]		Loss: 0.1339
2019-10-28 15:35:43,049 Training Epoch [17/40] Iter[70/312]		Loss: 0.1337
2019-10-28 15:35:43,128 Training Epoch [17/40] Iter[71/312]		Loss: 0.1332
2019-10-28 15:35:43,207 Training Epoch [17/40] Iter[72/312]		Loss: 0.1337
2019-10-28 15:35:43,286 Training Epoch [17/40] Iter[73/312]		Loss: 0.1340
2019-10-28 15:35:43,366 Training Epoch [17/40] Iter[74/312]		Loss: 0.1335
2019-10-28 15:35:43,444 Training Epoch [17/40] Iter[75/312]		Loss: 0.1328
2019-10-28 15:35:43,523 Training Epoch [17/40] Iter[76/312]		Loss: 0.1328
2019-10-28 15:35:43,602 Training Epoch [17/40] Iter[77/312]		Loss: 0.1329
2019-10-28 15:35:43,682 Training Epoch [17/40] Iter[78/312]		Loss: 0.1325
2019-10-28 15:35:43,761 Training Epoch [17/40] Iter[79/312]		Loss: 0.1320
2019-10-28 15:35:43,840 Training Epoch [17/40] Iter[80/312]		Loss: 0.1314
2019-10-28 15:35:43,918 Training Epoch [17/40] Iter[81/312]		Loss: 0.1310
2019-10-28 15:35:43,997 Training Epoch [17/40] Iter[82/312]		Loss: 0.1311
2019-10-28 15:35:44,076 Training Epoch [17/40] Iter[83/312]		Loss: 0.1308
2019-10-28 15:35:44,155 Training Epoch [17/40] Iter[84/312]		Loss: 0.1309
2019-10-28 15:35:44,234 Training Epoch [17/40] Iter[85/312]		Loss: 0.1308
2019-10-28 15:35:44,313 Training Epoch [17/40] Iter[86/312]		Loss: 0.1308
2019-10-28 15:35:44,392 Training Epoch [17/40] Iter[87/312]		Loss: 0.1312
2019-10-28 15:35:44,470 Training Epoch [17/40] Iter[88/312]		Loss: 0.1314
2019-10-28 15:35:44,549 Training Epoch [17/40] Iter[89/312]		Loss: 0.1318
2019-10-28 15:35:44,628 Training Epoch [17/40] Iter[90/312]		Loss: 0.1317
2019-10-28 15:35:44,707 Training Epoch [17/40] Iter[91/312]		Loss: 0.1320
2019-10-28 15:35:44,786 Training Epoch [17/40] Iter[92/312]		Loss: 0.1318
2019-10-28 15:35:44,865 Training Epoch [17/40] Iter[93/312]		Loss: 0.1315
2019-10-28 15:35:44,944 Training Epoch [17/40] Iter[94/312]		Loss: 0.1314
2019-10-28 15:35:45,023 Training Epoch [17/40] Iter[95/312]		Loss: 0.1313
2019-10-28 15:35:45,102 Training Epoch [17/40] Iter[96/312]		Loss: 0.1310
2019-10-28 15:35:45,181 Training Epoch [17/40] Iter[97/312]		Loss: 0.1308
2019-10-28 15:35:45,260 Training Epoch [17/40] Iter[98/312]		Loss: 0.1305
2019-10-28 15:35:45,339 Training Epoch [17/40] Iter[99/312]		Loss: 0.1300
2019-10-28 15:35:45,418 Training Epoch [17/40] Iter[100/312]		Loss: 0.1300
2019-10-28 15:35:45,497 Training Epoch [17/40] Iter[101/312]		Loss: 0.1295
2019-10-28 15:35:45,576 Training Epoch [17/40] Iter[102/312]		Loss: 0.1293
2019-10-28 15:35:45,655 Training Epoch [17/40] Iter[103/312]		Loss: 0.1294
2019-10-28 15:35:45,734 Training Epoch [17/40] Iter[104/312]		Loss: 0.1292
2019-10-28 15:35:45,813 Training Epoch [17/40] Iter[105/312]		Loss: 0.1290
2019-10-28 15:35:45,892 Training Epoch [17/40] Iter[106/312]		Loss: 0.1287
2019-10-28 15:35:45,971 Training Epoch [17/40] Iter[107/312]		Loss: 0.1283
2019-10-28 15:35:46,050 Training Epoch [17/40] Iter[108/312]		Loss: 0.1285
2019-10-28 15:35:46,129 Training Epoch [17/40] Iter[109/312]		Loss: 0.1292
2019-10-28 15:35:46,209 Training Epoch [17/40] Iter[110/312]		Loss: 0.1295
2019-10-28 15:35:46,288 Training Epoch [17/40] Iter[111/312]		Loss: 0.1296
2019-10-28 15:35:46,367 Training Epoch [17/40] Iter[112/312]		Loss: 0.1294
2019-10-28 15:35:46,446 Training Epoch [17/40] Iter[113/312]		Loss: 0.1288
2019-10-28 15:35:46,525 Training Epoch [17/40] Iter[114/312]		Loss: 0.1290
2019-10-28 15:35:46,605 Training Epoch [17/40] Iter[115/312]		Loss: 0.1286
2019-10-28 15:35:46,684 Training Epoch [17/40] Iter[116/312]		Loss: 0.1285
2019-10-28 15:35:46,763 Training Epoch [17/40] Iter[117/312]		Loss: 0.1283
2019-10-28 15:35:46,842 Training Epoch [17/40] Iter[118/312]		Loss: 0.1282
2019-10-28 15:35:46,921 Training Epoch [17/40] Iter[119/312]		Loss: 0.1279
2019-10-28 15:35:47,000 Training Epoch [17/40] Iter[120/312]		Loss: 0.1277
2019-10-28 15:35:47,079 Training Epoch [17/40] Iter[121/312]		Loss: 0.1276
2019-10-28 15:35:47,158 Training Epoch [17/40] Iter[122/312]		Loss: 0.1276
2019-10-28 15:35:47,237 Training Epoch [17/40] Iter[123/312]		Loss: 0.1280
2019-10-28 15:35:47,316 Training Epoch [17/40] Iter[124/312]		Loss: 0.1279
2019-10-28 15:35:47,395 Training Epoch [17/40] Iter[125/312]		Loss: 0.1280
2019-10-28 15:35:47,474 Training Epoch [17/40] Iter[126/312]		Loss: 0.1279
2019-10-28 15:35:47,553 Training Epoch [17/40] Iter[127/312]		Loss: 0.1278
2019-10-28 15:35:47,632 Training Epoch [17/40] Iter[128/312]		Loss: 0.1278
2019-10-28 15:35:47,712 Training Epoch [17/40] Iter[129/312]		Loss: 0.1278
2019-10-28 15:35:47,791 Training Epoch [17/40] Iter[130/312]		Loss: 0.1278
2019-10-28 15:35:47,870 Training Epoch [17/40] Iter[131/312]		Loss: 0.1279
2019-10-28 15:35:47,948 Training Epoch [17/40] Iter[132/312]		Loss: 0.1283
2019-10-28 15:35:48,027 Training Epoch [17/40] Iter[133/312]		Loss: 0.1280
2019-10-28 15:35:48,106 Training Epoch [17/40] Iter[134/312]		Loss: 0.1280
2019-10-28 15:35:48,185 Training Epoch [17/40] Iter[135/312]		Loss: 0.1281
2019-10-28 15:35:48,264 Training Epoch [17/40] Iter[136/312]		Loss: 0.1280
2019-10-28 15:35:48,343 Training Epoch [17/40] Iter[137/312]		Loss: 0.1280
2019-10-28 15:35:48,422 Training Epoch [17/40] Iter[138/312]		Loss: 0.1283
2019-10-28 15:35:48,501 Training Epoch [17/40] Iter[139/312]		Loss: 0.1283
2019-10-28 15:35:48,580 Training Epoch [17/40] Iter[140/312]		Loss: 0.1282
2019-10-28 15:35:48,659 Training Epoch [17/40] Iter[141/312]		Loss: 0.1280
2019-10-28 15:35:48,738 Training Epoch [17/40] Iter[142/312]		Loss: 0.1285
2019-10-28 15:35:48,817 Training Epoch [17/40] Iter[143/312]		Loss: 0.1283
2019-10-28 15:35:48,896 Training Epoch [17/40] Iter[144/312]		Loss: 0.1292
2019-10-28 15:35:48,975 Training Epoch [17/40] Iter[145/312]		Loss: 0.1289
2019-10-28 15:35:49,054 Training Epoch [17/40] Iter[146/312]		Loss: 0.1292
2019-10-28 15:35:49,133 Training Epoch [17/40] Iter[147/312]		Loss: 0.1289
2019-10-28 15:35:49,212 Training Epoch [17/40] Iter[148/312]		Loss: 0.1302
2019-10-28 15:35:49,291 Training Epoch [17/40] Iter[149/312]		Loss: 0.1301
2019-10-28 15:35:49,370 Training Epoch [17/40] Iter[150/312]		Loss: 0.1301
2019-10-28 15:35:49,449 Training Epoch [17/40] Iter[151/312]		Loss: 0.1298
2019-10-28 15:35:49,528 Training Epoch [17/40] Iter[152/312]		Loss: 0.1299
2019-10-28 15:35:49,607 Training Epoch [17/40] Iter[153/312]		Loss: 0.1301
2019-10-28 15:35:49,686 Training Epoch [17/40] Iter[154/312]		Loss: 0.1299
2019-10-28 15:35:49,765 Training Epoch [17/40] Iter[155/312]		Loss: 0.1302
2019-10-28 15:35:49,844 Training Epoch [17/40] Iter[156/312]		Loss: 0.1300
2019-10-28 15:35:49,923 Training Epoch [17/40] Iter[157/312]		Loss: 0.1301
2019-10-28 15:35:50,002 Training Epoch [17/40] Iter[158/312]		Loss: 0.1301
2019-10-28 15:35:50,081 Training Epoch [17/40] Iter[159/312]		Loss: 0.1299
2019-10-28 15:35:50,160 Training Epoch [17/40] Iter[160/312]		Loss: 0.1298
2019-10-28 15:35:50,239 Training Epoch [17/40] Iter[161/312]		Loss: 0.1303
2019-10-28 15:35:50,318 Training Epoch [17/40] Iter[162/312]		Loss: 0.1303
2019-10-28 15:35:50,397 Training Epoch [17/40] Iter[163/312]		Loss: 0.1301
2019-10-28 15:35:50,476 Training Epoch [17/40] Iter[164/312]		Loss: 0.1304
2019-10-28 15:35:50,555 Training Epoch [17/40] Iter[165/312]		Loss: 0.1303
2019-10-28 15:35:50,634 Training Epoch [17/40] Iter[166/312]		Loss: 0.1303
2019-10-28 15:35:50,713 Training Epoch [17/40] Iter[167/312]		Loss: 0.1301
2019-10-28 15:35:50,792 Training Epoch [17/40] Iter[168/312]		Loss: 0.1302
2019-10-28 15:35:50,870 Training Epoch [17/40] Iter[169/312]		Loss: 0.1302
2019-10-28 15:35:50,949 Training Epoch [17/40] Iter[170/312]		Loss: 0.1306
2019-10-28 15:35:51,028 Training Epoch [17/40] Iter[171/312]		Loss: 0.1304
2019-10-28 15:35:51,107 Training Epoch [17/40] Iter[172/312]		Loss: 0.1311
2019-10-28 15:35:51,186 Training Epoch [17/40] Iter[173/312]		Loss: 0.1309
2019-10-28 15:35:51,265 Training Epoch [17/40] Iter[174/312]		Loss: 0.1318
2019-10-28 15:35:51,345 Training Epoch [17/40] Iter[175/312]		Loss: 0.1319
2019-10-28 15:35:51,423 Training Epoch [17/40] Iter[176/312]		Loss: 0.1320
2019-10-28 15:35:51,502 Training Epoch [17/40] Iter[177/312]		Loss: 0.1319
2019-10-28 15:35:51,581 Training Epoch [17/40] Iter[178/312]		Loss: 0.1321
2019-10-28 15:35:51,660 Training Epoch [17/40] Iter[179/312]		Loss: 0.1320
2019-10-28 15:35:51,739 Training Epoch [17/40] Iter[180/312]		Loss: 0.1321
2019-10-28 15:35:51,818 Training Epoch [17/40] Iter[181/312]		Loss: 0.1319
2019-10-28 15:35:51,897 Training Epoch [17/40] Iter[182/312]		Loss: 0.1321
2019-10-28 15:35:51,977 Training Epoch [17/40] Iter[183/312]		Loss: 0.1322
2019-10-28 15:35:52,056 Training Epoch [17/40] Iter[184/312]		Loss: 0.1327
2019-10-28 15:35:52,136 Training Epoch [17/40] Iter[185/312]		Loss: 0.1328
2019-10-28 15:35:52,215 Training Epoch [17/40] Iter[186/312]		Loss: 0.1331
2019-10-28 15:35:52,295 Training Epoch [17/40] Iter[187/312]		Loss: 0.1334
2019-10-28 15:35:52,374 Training Epoch [17/40] Iter[188/312]		Loss: 0.1335
2019-10-28 15:35:52,453 Training Epoch [17/40] Iter[189/312]		Loss: 0.1336
2019-10-28 15:35:52,532 Training Epoch [17/40] Iter[190/312]		Loss: 0.1336
2019-10-28 15:35:52,611 Training Epoch [17/40] Iter[191/312]		Loss: 0.1337
2019-10-28 15:35:52,690 Training Epoch [17/40] Iter[192/312]		Loss: 0.1336
2019-10-28 15:35:52,769 Training Epoch [17/40] Iter[193/312]		Loss: 0.1335
2019-10-28 15:35:52,848 Training Epoch [17/40] Iter[194/312]		Loss: 0.1333
2019-10-28 15:35:52,927 Training Epoch [17/40] Iter[195/312]		Loss: 0.1331
2019-10-28 15:35:53,006 Training Epoch [17/40] Iter[196/312]		Loss: 0.1339
2019-10-28 15:35:53,085 Training Epoch [17/40] Iter[197/312]		Loss: 0.1342
2019-10-28 15:35:53,163 Training Epoch [17/40] Iter[198/312]		Loss: 0.1342
2019-10-28 15:35:53,242 Training Epoch [17/40] Iter[199/312]		Loss: 0.1339
2019-10-28 15:35:53,321 Training Epoch [17/40] Iter[200/312]		Loss: 0.1341
2019-10-28 15:35:53,400 Training Epoch [17/40] Iter[201/312]		Loss: 0.1343
2019-10-28 15:35:53,479 Training Epoch [17/40] Iter[202/312]		Loss: 0.1346
2019-10-28 15:35:53,558 Training Epoch [17/40] Iter[203/312]		Loss: 0.1346
2019-10-28 15:35:53,637 Training Epoch [17/40] Iter[204/312]		Loss: 0.1347
2019-10-28 15:35:53,716 Training Epoch [17/40] Iter[205/312]		Loss: 0.1350
2019-10-28 15:35:53,795 Training Epoch [17/40] Iter[206/312]		Loss: 0.1353
2019-10-28 15:35:53,874 Training Epoch [17/40] Iter[207/312]		Loss: 0.1352
2019-10-28 15:35:53,953 Training Epoch [17/40] Iter[208/312]		Loss: 0.1353
2019-10-28 15:35:54,032 Training Epoch [17/40] Iter[209/312]		Loss: 0.1351
2019-10-28 15:35:54,111 Training Epoch [17/40] Iter[210/312]		Loss: 0.1354
2019-10-28 15:35:54,190 Training Epoch [17/40] Iter[211/312]		Loss: 0.1354
2019-10-28 15:35:54,269 Training Epoch [17/40] Iter[212/312]		Loss: 0.1353
2019-10-28 15:35:54,348 Training Epoch [17/40] Iter[213/312]		Loss: 0.1352
2019-10-28 15:35:54,427 Training Epoch [17/40] Iter[214/312]		Loss: 0.1351
2019-10-28 15:35:54,507 Training Epoch [17/40] Iter[215/312]		Loss: 0.1348
2019-10-28 15:35:54,586 Training Epoch [17/40] Iter[216/312]		Loss: 0.1349
2019-10-28 15:35:54,665 Training Epoch [17/40] Iter[217/312]		Loss: 0.1347
2019-10-28 15:35:54,744 Training Epoch [17/40] Iter[218/312]		Loss: 0.1348
2019-10-28 15:35:54,823 Training Epoch [17/40] Iter[219/312]		Loss: 0.1347
2019-10-28 15:35:54,902 Training Epoch [17/40] Iter[220/312]		Loss: 0.1346
2019-10-28 15:35:54,980 Training Epoch [17/40] Iter[221/312]		Loss: 0.1346
2019-10-28 15:35:55,060 Training Epoch [17/40] Iter[222/312]		Loss: 0.1350
2019-10-28 15:35:55,139 Training Epoch [17/40] Iter[223/312]		Loss: 0.1350
2019-10-28 15:35:55,218 Training Epoch [17/40] Iter[224/312]		Loss: 0.1350
2019-10-28 15:35:55,298 Training Epoch [17/40] Iter[225/312]		Loss: 0.1353
2019-10-28 15:35:55,377 Training Epoch [17/40] Iter[226/312]		Loss: 0.1355
2019-10-28 15:35:55,456 Training Epoch [17/40] Iter[227/312]		Loss: 0.1354
2019-10-28 15:35:55,535 Training Epoch [17/40] Iter[228/312]		Loss: 0.1356
2019-10-28 15:35:55,614 Training Epoch [17/40] Iter[229/312]		Loss: 0.1355
2019-10-28 15:35:55,693 Training Epoch [17/40] Iter[230/312]		Loss: 0.1356
2019-10-28 15:35:55,772 Training Epoch [17/40] Iter[231/312]		Loss: 0.1355
2019-10-28 15:35:55,851 Training Epoch [17/40] Iter[232/312]		Loss: 0.1359
2019-10-28 15:35:55,930 Training Epoch [17/40] Iter[233/312]		Loss: 0.1357
2019-10-28 15:35:56,009 Training Epoch [17/40] Iter[234/312]		Loss: 0.1358
2019-10-28 15:35:56,088 Training Epoch [17/40] Iter[235/312]		Loss: 0.1358
2019-10-28 15:35:56,167 Training Epoch [17/40] Iter[236/312]		Loss: 0.1357
2019-10-28 15:35:56,246 Training Epoch [17/40] Iter[237/312]		Loss: 0.1355
2019-10-28 15:35:56,325 Training Epoch [17/40] Iter[238/312]		Loss: 0.1355
2019-10-28 15:35:56,404 Training Epoch [17/40] Iter[239/312]		Loss: 0.1356
2019-10-28 15:35:56,483 Training Epoch [17/40] Iter[240/312]		Loss: 0.1356
2019-10-28 15:35:56,562 Training Epoch [17/40] Iter[241/312]		Loss: 0.1355
2019-10-28 15:35:56,641 Training Epoch [17/40] Iter[242/312]		Loss: 0.1356
2019-10-28 15:35:56,721 Training Epoch [17/40] Iter[243/312]		Loss: 0.1359
2019-10-28 15:35:56,799 Training Epoch [17/40] Iter[244/312]		Loss: 0.1357
2019-10-28 15:35:56,878 Training Epoch [17/40] Iter[245/312]		Loss: 0.1358
2019-10-28 15:35:56,957 Training Epoch [17/40] Iter[246/312]		Loss: 0.1357
2019-10-28 15:35:57,036 Training Epoch [17/40] Iter[247/312]		Loss: 0.1356
2019-10-28 15:35:57,115 Training Epoch [17/40] Iter[248/312]		Loss: 0.1355
2019-10-28 15:35:57,194 Training Epoch [17/40] Iter[249/312]		Loss: 0.1359
2019-10-28 15:35:57,273 Training Epoch [17/40] Iter[250/312]		Loss: 0.1359
2019-10-28 15:35:57,352 Training Epoch [17/40] Iter[251/312]		Loss: 0.1361
2019-10-28 15:35:57,431 Training Epoch [17/40] Iter[252/312]		Loss: 0.1360
2019-10-28 15:35:57,510 Training Epoch [17/40] Iter[253/312]		Loss: 0.1360
2019-10-28 15:35:57,589 Training Epoch [17/40] Iter[254/312]		Loss: 0.1360
2019-10-28 15:35:57,668 Training Epoch [17/40] Iter[255/312]		Loss: 0.1362
2019-10-28 15:35:57,747 Training Epoch [17/40] Iter[256/312]		Loss: 0.1360
2019-10-28 15:35:57,826 Training Epoch [17/40] Iter[257/312]		Loss: 0.1358
2019-10-28 15:35:57,905 Training Epoch [17/40] Iter[258/312]		Loss: 0.1361
2019-10-28 15:35:57,984 Training Epoch [17/40] Iter[259/312]		Loss: 0.1360
2019-10-28 15:35:58,064 Training Epoch [17/40] Iter[260/312]		Loss: 0.1359
2019-10-28 15:35:58,143 Training Epoch [17/40] Iter[261/312]		Loss: 0.1360
2019-10-28 15:35:58,222 Training Epoch [17/40] Iter[262/312]		Loss: 0.1359
2019-10-28 15:35:58,301 Training Epoch [17/40] Iter[263/312]		Loss: 0.1357
2019-10-28 15:35:58,381 Training Epoch [17/40] Iter[264/312]		Loss: 0.1363
2019-10-28 15:35:58,460 Training Epoch [17/40] Iter[265/312]		Loss: 0.1361
2019-10-28 15:35:58,540 Training Epoch [17/40] Iter[266/312]		Loss: 0.1361
2019-10-28 15:35:58,619 Training Epoch [17/40] Iter[267/312]		Loss: 0.1364
2019-10-28 15:35:58,698 Training Epoch [17/40] Iter[268/312]		Loss: 0.1364
2019-10-28 15:35:58,777 Training Epoch [17/40] Iter[269/312]		Loss: 0.1366
2019-10-28 15:35:58,856 Training Epoch [17/40] Iter[270/312]		Loss: 0.1368
2019-10-28 15:35:58,935 Training Epoch [17/40] Iter[271/312]		Loss: 0.1367
2019-10-28 15:35:59,014 Training Epoch [17/40] Iter[272/312]		Loss: 0.1366
2019-10-28 15:35:59,094 Training Epoch [17/40] Iter[273/312]		Loss: 0.1367
2019-10-28 15:35:59,173 Training Epoch [17/40] Iter[274/312]		Loss: 0.1366
2019-10-28 15:35:59,252 Training Epoch [17/40] Iter[275/312]		Loss: 0.1365
2019-10-28 15:35:59,331 Training Epoch [17/40] Iter[276/312]		Loss: 0.1363
2019-10-28 15:35:59,410 Training Epoch [17/40] Iter[277/312]		Loss: 0.1362
2019-10-28 15:35:59,488 Training Epoch [17/40] Iter[278/312]		Loss: 0.1362
2019-10-28 15:35:59,567 Training Epoch [17/40] Iter[279/312]		Loss: 0.1364
2019-10-28 15:35:59,646 Training Epoch [17/40] Iter[280/312]		Loss: 0.1366
2019-10-28 15:35:59,725 Training Epoch [17/40] Iter[281/312]		Loss: 0.1369
2019-10-28 15:35:59,804 Training Epoch [17/40] Iter[282/312]		Loss: 0.1368
2019-10-28 15:35:59,884 Training Epoch [17/40] Iter[283/312]		Loss: 0.1370
2019-10-28 15:35:59,963 Training Epoch [17/40] Iter[284/312]		Loss: 0.1370
2019-10-28 15:36:00,042 Training Epoch [17/40] Iter[285/312]		Loss: 0.1372
2019-10-28 15:36:00,122 Training Epoch [17/40] Iter[286/312]		Loss: 0.1374
2019-10-28 15:36:00,202 Training Epoch [17/40] Iter[287/312]		Loss: 0.1372
2019-10-28 15:36:00,281 Training Epoch [17/40] Iter[288/312]		Loss: 0.1373
2019-10-28 15:36:00,361 Training Epoch [17/40] Iter[289/312]		Loss: 0.1374
2019-10-28 15:36:00,440 Training Epoch [17/40] Iter[290/312]		Loss: 0.1372
2019-10-28 15:36:00,519 Training Epoch [17/40] Iter[291/312]		Loss: 0.1372
2019-10-28 15:36:00,598 Training Epoch [17/40] Iter[292/312]		Loss: 0.1372
2019-10-28 15:36:00,678 Training Epoch [17/40] Iter[293/312]		Loss: 0.1371
2019-10-28 15:36:00,757 Training Epoch [17/40] Iter[294/312]		Loss: 0.1370
2019-10-28 15:36:00,836 Training Epoch [17/40] Iter[295/312]		Loss: 0.1368
2019-10-28 15:36:00,915 Training Epoch [17/40] Iter[296/312]		Loss: 0.1368
2019-10-28 15:36:00,994 Training Epoch [17/40] Iter[297/312]		Loss: 0.1368
2019-10-28 15:36:01,072 Training Epoch [17/40] Iter[298/312]		Loss: 0.1370
2019-10-28 15:36:01,151 Training Epoch [17/40] Iter[299/312]		Loss: 0.1368
2019-10-28 15:36:01,230 Training Epoch [17/40] Iter[300/312]		Loss: 0.1370
2019-10-28 15:36:01,309 Training Epoch [17/40] Iter[301/312]		Loss: 0.1371
2019-10-28 15:36:01,388 Training Epoch [17/40] Iter[302/312]		Loss: 0.1372
2019-10-28 15:36:01,467 Training Epoch [17/40] Iter[303/312]		Loss: 0.1372
2019-10-28 15:36:01,546 Training Epoch [17/40] Iter[304/312]		Loss: 0.1371
2019-10-28 15:36:01,624 Training Epoch [17/40] Iter[305/312]		Loss: 0.1370
2019-10-28 15:36:01,702 Training Epoch [17/40] Iter[306/312]		Loss: 0.1372
2019-10-28 15:36:01,780 Training Epoch [17/40] Iter[307/312]		Loss: 0.1372
2019-10-28 15:36:01,859 Training Epoch [17/40] Iter[308/312]		Loss: 0.1371
2019-10-28 15:36:01,937 Training Epoch [17/40] Iter[309/312]		Loss: 0.1372
2019-10-28 15:36:02,015 Training Epoch [17/40] Iter[310/312]		Loss: 0.1373
2019-10-28 15:36:02,094 Training Epoch [17/40] Iter[311/312]		Loss: 0.1374
2019-10-28 15:36:02,132 Training Epoch [17/40] Iter[312/312]		Loss: 0.1377
2019-10-28 15:36:02,567 Testing Epoch [17/40] Iter[0/62]		Loss: 0.1364
2019-10-28 15:36:02,586 Testing Epoch [17/40] Iter[1/62]		Loss: 0.1354
2019-10-28 15:36:02,605 Testing Epoch [17/40] Iter[2/62]		Loss: 0.1164
2019-10-28 15:36:02,630 Testing Epoch [17/40] Iter[3/62]		Loss: 0.1230
2019-10-28 15:36:02,661 Testing Epoch [17/40] Iter[4/62]		Loss: 0.1267
2019-10-28 15:36:02,678 Testing Epoch [17/40] Iter[5/62]		Loss: 0.1219
2019-10-28 15:36:02,697 Testing Epoch [17/40] Iter[6/62]		Loss: 0.1236
2019-10-28 15:36:02,722 Testing Epoch [17/40] Iter[7/62]		Loss: 0.1271
2019-10-28 15:36:02,750 Testing Epoch [17/40] Iter[8/62]		Loss: 0.1297
2019-10-28 15:36:02,766 Testing Epoch [17/40] Iter[9/62]		Loss: 0.1299
2019-10-28 15:36:02,793 Testing Epoch [17/40] Iter[10/62]		Loss: 0.1318
2019-10-28 15:36:02,810 Testing Epoch [17/40] Iter[11/62]		Loss: 0.1381
2019-10-28 15:36:02,841 Testing Epoch [17/40] Iter[12/62]		Loss: 0.1376
2019-10-28 15:36:02,858 Testing Epoch [17/40] Iter[13/62]		Loss: 0.1395
2019-10-28 15:36:02,876 Testing Epoch [17/40] Iter[14/62]		Loss: 0.1533
2019-10-28 15:36:02,905 Testing Epoch [17/40] Iter[15/62]		Loss: 0.1547
2019-10-28 15:36:02,932 Testing Epoch [17/40] Iter[16/62]		Loss: 0.1521
2019-10-28 15:36:02,953 Testing Epoch [17/40] Iter[17/62]		Loss: 0.1515
2019-10-28 15:36:02,971 Testing Epoch [17/40] Iter[18/62]		Loss: 0.1483
2019-10-28 15:36:02,989 Testing Epoch [17/40] Iter[19/62]		Loss: 0.1467
2019-10-28 15:36:03,022 Testing Epoch [17/40] Iter[20/62]		Loss: 0.1484
2019-10-28 15:36:03,046 Testing Epoch [17/40] Iter[21/62]		Loss: 0.1470
2019-10-28 15:36:03,064 Testing Epoch [17/40] Iter[22/62]		Loss: 0.1481
2019-10-28 15:36:03,082 Testing Epoch [17/40] Iter[23/62]		Loss: 0.1475
2019-10-28 15:36:03,109 Testing Epoch [17/40] Iter[24/62]		Loss: 0.1522
2019-10-28 15:36:03,127 Testing Epoch [17/40] Iter[25/62]		Loss: 0.1514
2019-10-28 15:36:03,145 Testing Epoch [17/40] Iter[26/62]		Loss: 0.1502
2019-10-28 15:36:03,163 Testing Epoch [17/40] Iter[27/62]		Loss: 0.1566
2019-10-28 15:36:03,194 Testing Epoch [17/40] Iter[28/62]		Loss: 0.1600
2019-10-28 15:36:03,222 Testing Epoch [17/40] Iter[29/62]		Loss: 0.1599
2019-10-28 15:36:03,240 Testing Epoch [17/40] Iter[30/62]		Loss: 0.1607
2019-10-28 15:36:03,265 Testing Epoch [17/40] Iter[31/62]		Loss: 0.1596
2019-10-28 15:36:03,282 Testing Epoch [17/40] Iter[32/62]		Loss: 0.1614
2019-10-28 15:36:03,309 Testing Epoch [17/40] Iter[33/62]		Loss: 0.1601
2019-10-28 15:36:03,327 Testing Epoch [17/40] Iter[34/62]		Loss: 0.1624
2019-10-28 15:36:03,353 Testing Epoch [17/40] Iter[35/62]		Loss: 0.1624
2019-10-28 15:36:03,371 Testing Epoch [17/40] Iter[36/62]		Loss: 0.1604
2019-10-28 15:36:03,397 Testing Epoch [17/40] Iter[37/62]		Loss: 0.1592
2019-10-28 15:36:03,415 Testing Epoch [17/40] Iter[38/62]		Loss: 0.1584
2019-10-28 15:36:03,445 Testing Epoch [17/40] Iter[39/62]		Loss: 0.1587
2019-10-28 15:36:03,472 Testing Epoch [17/40] Iter[40/62]		Loss: 0.1603
2019-10-28 15:36:03,497 Testing Epoch [17/40] Iter[41/62]		Loss: 0.1620
2019-10-28 15:36:03,515 Testing Epoch [17/40] Iter[42/62]		Loss: 0.1600
2019-10-28 15:36:03,541 Testing Epoch [17/40] Iter[43/62]		Loss: 0.1595
2019-10-28 15:36:03,565 Testing Epoch [17/40] Iter[44/62]		Loss: 0.1580
2019-10-28 15:36:03,582 Testing Epoch [17/40] Iter[45/62]		Loss: 0.1580
2019-10-28 15:36:03,609 Testing Epoch [17/40] Iter[46/62]		Loss: 0.1577
2019-10-28 15:36:03,627 Testing Epoch [17/40] Iter[47/62]		Loss: 0.1635
2019-10-28 15:36:03,657 Testing Epoch [17/40] Iter[48/62]		Loss: 0.1623
2019-10-28 15:36:03,675 Testing Epoch [17/40] Iter[49/62]		Loss: 0.1647
2019-10-28 15:36:03,701 Testing Epoch [17/40] Iter[50/62]		Loss: 0.1638
2019-10-28 15:36:03,729 Testing Epoch [17/40] Iter[51/62]		Loss: 0.1637
2019-10-28 15:36:03,746 Testing Epoch [17/40] Iter[52/62]		Loss: 0.1624
2019-10-28 15:36:03,764 Testing Epoch [17/40] Iter[53/62]		Loss: 0.1626
2019-10-28 15:36:03,793 Testing Epoch [17/40] Iter[54/62]		Loss: 0.1617
2019-10-28 15:36:03,811 Testing Epoch [17/40] Iter[55/62]		Loss: 0.1616
2019-10-28 15:36:03,827 Testing Epoch [17/40] Iter[56/62]		Loss: 0.1612
2019-10-28 15:36:03,844 Testing Epoch [17/40] Iter[57/62]		Loss: 0.1614
2019-10-28 15:36:03,860 Testing Epoch [17/40] Iter[58/62]		Loss: 0.1609
2019-10-28 15:36:03,877 Testing Epoch [17/40] Iter[59/62]		Loss: 0.1621
2019-10-28 15:36:03,895 Testing Epoch [17/40] Iter[60/62]		Loss: 0.1610
2019-10-28 15:36:03,911 Testing Epoch [17/40] Iter[61/62]		Loss: 0.1612
2019-10-28 15:36:03,920 Testing Epoch [17/40] Iter[62/62]		Loss: 0.1621
2019-10-28 15:36:03,991 Saving the Model
2019-10-28 15:36:04,433 Training Epoch [18/40] Iter[0/312]		Loss: 0.1397
2019-10-28 15:36:04,515 Training Epoch [18/40] Iter[1/312]		Loss: 0.1359
2019-10-28 15:36:04,593 Training Epoch [18/40] Iter[2/312]		Loss: 0.1197
2019-10-28 15:36:04,674 Training Epoch [18/40] Iter[3/312]		Loss: 0.1365
2019-10-28 15:36:04,753 Training Epoch [18/40] Iter[4/312]		Loss: 0.1318
2019-10-28 15:36:04,831 Training Epoch [18/40] Iter[5/312]		Loss: 0.1308
2019-10-28 15:36:04,909 Training Epoch [18/40] Iter[6/312]		Loss: 0.1301
2019-10-28 15:36:04,988 Training Epoch [18/40] Iter[7/312]		Loss: 0.1258
2019-10-28 15:36:05,067 Training Epoch [18/40] Iter[8/312]		Loss: 0.1308
2019-10-28 15:36:05,146 Training Epoch [18/40] Iter[9/312]		Loss: 0.1294
2019-10-28 15:36:05,225 Training Epoch [18/40] Iter[10/312]		Loss: 0.1305
2019-10-28 15:36:05,304 Training Epoch [18/40] Iter[11/312]		Loss: 0.1292
2019-10-28 15:36:05,383 Training Epoch [18/40] Iter[12/312]		Loss: 0.1274
2019-10-28 15:36:05,463 Training Epoch [18/40] Iter[13/312]		Loss: 0.1262
2019-10-28 15:36:05,541 Training Epoch [18/40] Iter[14/312]		Loss: 0.1231
2019-10-28 15:36:05,620 Training Epoch [18/40] Iter[15/312]		Loss: 0.1239
2019-10-28 15:36:05,699 Training Epoch [18/40] Iter[16/312]		Loss: 0.1217
2019-10-28 15:36:05,778 Training Epoch [18/40] Iter[17/312]		Loss: 0.1205
2019-10-28 15:36:05,857 Training Epoch [18/40] Iter[18/312]		Loss: 0.1193
2019-10-28 15:36:05,936 Training Epoch [18/40] Iter[19/312]		Loss: 0.1185
2019-10-28 15:36:06,015 Training Epoch [18/40] Iter[20/312]		Loss: 0.1177
2019-10-28 15:36:06,094 Training Epoch [18/40] Iter[21/312]		Loss: 0.1171
2019-10-28 15:36:06,173 Training Epoch [18/40] Iter[22/312]		Loss: 0.1164
2019-10-28 15:36:06,253 Training Epoch [18/40] Iter[23/312]		Loss: 0.1213
2019-10-28 15:36:06,332 Training Epoch [18/40] Iter[24/312]		Loss: 0.1203
2019-10-28 15:36:06,412 Training Epoch [18/40] Iter[25/312]		Loss: 0.1196
2019-10-28 15:36:06,491 Training Epoch [18/40] Iter[26/312]		Loss: 0.1204
2019-10-28 15:36:06,571 Training Epoch [18/40] Iter[27/312]		Loss: 0.1214
2019-10-28 15:36:06,650 Training Epoch [18/40] Iter[28/312]		Loss: 0.1200
2019-10-28 15:36:06,730 Training Epoch [18/40] Iter[29/312]		Loss: 0.1206
2019-10-28 15:36:06,809 Training Epoch [18/40] Iter[30/312]		Loss: 0.1215
2019-10-28 15:36:06,888 Training Epoch [18/40] Iter[31/312]		Loss: 0.1217
2019-10-28 15:36:06,967 Training Epoch [18/40] Iter[32/312]		Loss: 0.1214
2019-10-28 15:36:07,046 Training Epoch [18/40] Iter[33/312]		Loss: 0.1216
2019-10-28 15:36:07,124 Training Epoch [18/40] Iter[34/312]		Loss: 0.1203
2019-10-28 15:36:07,204 Training Epoch [18/40] Iter[35/312]		Loss: 0.1206
2019-10-28 15:36:07,283 Training Epoch [18/40] Iter[36/312]		Loss: 0.1222
2019-10-28 15:36:07,362 Training Epoch [18/40] Iter[37/312]		Loss: 0.1222
2019-10-28 15:36:07,441 Training Epoch [18/40] Iter[38/312]		Loss: 0.1243
2019-10-28 15:36:07,520 Training Epoch [18/40] Iter[39/312]		Loss: 0.1239
2019-10-28 15:36:07,599 Training Epoch [18/40] Iter[40/312]		Loss: 0.1239
2019-10-28 15:36:07,679 Training Epoch [18/40] Iter[41/312]		Loss: 0.1229
2019-10-28 15:36:07,758 Training Epoch [18/40] Iter[42/312]		Loss: 0.1229
2019-10-28 15:36:07,837 Training Epoch [18/40] Iter[43/312]		Loss: 0.1223
2019-10-28 15:36:07,916 Training Epoch [18/40] Iter[44/312]		Loss: 0.1222
2019-10-28 15:36:07,995 Training Epoch [18/40] Iter[45/312]		Loss: 0.1217
2019-10-28 15:36:08,073 Training Epoch [18/40] Iter[46/312]		Loss: 0.1243
2019-10-28 15:36:08,152 Training Epoch [18/40] Iter[47/312]		Loss: 0.1236
2019-10-28 15:36:08,232 Training Epoch [18/40] Iter[48/312]		Loss: 0.1247
2019-10-28 15:36:08,311 Training Epoch [18/40] Iter[49/312]		Loss: 0.1254
2019-10-28 15:36:08,391 Training Epoch [18/40] Iter[50/312]		Loss: 0.1266
2019-10-28 15:36:08,470 Training Epoch [18/40] Iter[51/312]		Loss: 0.1255
2019-10-28 15:36:08,549 Training Epoch [18/40] Iter[52/312]		Loss: 0.1251
2019-10-28 15:36:08,628 Training Epoch [18/40] Iter[53/312]		Loss: 0.1253
2019-10-28 15:36:08,707 Training Epoch [18/40] Iter[54/312]		Loss: 0.1257
2019-10-28 15:36:08,786 Training Epoch [18/40] Iter[55/312]		Loss: 0.1257
2019-10-28 15:36:08,866 Training Epoch [18/40] Iter[56/312]		Loss: 0.1261
2019-10-28 15:36:08,945 Training Epoch [18/40] Iter[57/312]		Loss: 0.1281
2019-10-28 15:36:09,023 Training Epoch [18/40] Iter[58/312]		Loss: 0.1289
2019-10-28 15:36:09,102 Training Epoch [18/40] Iter[59/312]		Loss: 0.1285
2019-10-28 15:36:09,181 Training Epoch [18/40] Iter[60/312]		Loss: 0.1302
2019-10-28 15:36:09,261 Training Epoch [18/40] Iter[61/312]		Loss: 0.1298
2019-10-28 15:36:09,340 Training Epoch [18/40] Iter[62/312]		Loss: 0.1300
2019-10-28 15:36:09,419 Training Epoch [18/40] Iter[63/312]		Loss: 0.1302
2019-10-28 15:36:09,498 Training Epoch [18/40] Iter[64/312]		Loss: 0.1296
2019-10-28 15:36:09,577 Training Epoch [18/40] Iter[65/312]		Loss: 0.1291
2019-10-28 15:36:09,656 Training Epoch [18/40] Iter[66/312]		Loss: 0.1300
2019-10-28 15:36:09,735 Training Epoch [18/40] Iter[67/312]		Loss: 0.1302
2019-10-28 15:36:09,815 Training Epoch [18/40] Iter[68/312]		Loss: 0.1296
2019-10-28 15:36:09,894 Training Epoch [18/40] Iter[69/312]		Loss: 0.1295
2019-10-28 15:36:09,973 Training Epoch [18/40] Iter[70/312]		Loss: 0.1300
2019-10-28 15:36:10,051 Training Epoch [18/40] Iter[71/312]		Loss: 0.1297
2019-10-28 15:36:10,130 Training Epoch [18/40] Iter[72/312]		Loss: 0.1307
2019-10-28 15:36:10,209 Training Epoch [18/40] Iter[73/312]		Loss: 0.1311
2019-10-28 15:36:10,288 Training Epoch [18/40] Iter[74/312]		Loss: 0.1318
2019-10-28 15:36:10,367 Training Epoch [18/40] Iter[75/312]		Loss: 0.1316
2019-10-28 15:36:10,446 Training Epoch [18/40] Iter[76/312]		Loss: 0.1316
2019-10-28 15:36:10,525 Training Epoch [18/40] Iter[77/312]		Loss: 0.1310
2019-10-28 15:36:10,604 Training Epoch [18/40] Iter[78/312]		Loss: 0.1308
2019-10-28 15:36:10,683 Training Epoch [18/40] Iter[79/312]		Loss: 0.1307
2019-10-28 15:36:10,762 Training Epoch [18/40] Iter[80/312]		Loss: 0.1302
2019-10-28 15:36:10,841 Training Epoch [18/40] Iter[81/312]		Loss: 0.1305
2019-10-28 15:36:10,921 Training Epoch [18/40] Iter[82/312]		Loss: 0.1307
2019-10-28 15:36:11,006 Training Epoch [18/40] Iter[83/312]		Loss: 0.1302
2019-10-28 15:36:11,091 Training Epoch [18/40] Iter[84/312]		Loss: 0.1306
2019-10-28 15:36:11,170 Training Epoch [18/40] Iter[85/312]		Loss: 0.1313
2019-10-28 15:36:11,255 Training Epoch [18/40] Iter[86/312]		Loss: 0.1310
2019-10-28 15:36:11,339 Training Epoch [18/40] Iter[87/312]		Loss: 0.1314
2019-10-28 15:36:11,423 Training Epoch [18/40] Iter[88/312]		Loss: 0.1309
2019-10-28 15:36:11,502 Training Epoch [18/40] Iter[89/312]		Loss: 0.1313
2019-10-28 15:36:11,583 Training Epoch [18/40] Iter[90/312]		Loss: 0.1318
2019-10-28 15:36:11,662 Training Epoch [18/40] Iter[91/312]		Loss: 0.1314
2019-10-28 15:36:11,741 Training Epoch [18/40] Iter[92/312]		Loss: 0.1313
2019-10-28 15:36:11,823 Training Epoch [18/40] Iter[93/312]		Loss: 0.1318
2019-10-28 15:36:11,906 Training Epoch [18/40] Iter[94/312]		Loss: 0.1318
2019-10-28 15:36:11,987 Training Epoch [18/40] Iter[95/312]		Loss: 0.1335
2019-10-28 15:36:12,066 Training Epoch [18/40] Iter[96/312]		Loss: 0.1345
2019-10-28 15:36:12,151 Training Epoch [18/40] Iter[97/312]		Loss: 0.1343
2019-10-28 15:36:12,235 Training Epoch [18/40] Iter[98/312]		Loss: 0.1341
2019-10-28 15:36:12,315 Training Epoch [18/40] Iter[99/312]		Loss: 0.1335
2019-10-28 15:36:12,394 Training Epoch [18/40] Iter[100/312]		Loss: 0.1331
2019-10-28 15:36:12,473 Training Epoch [18/40] Iter[101/312]		Loss: 0.1330
2019-10-28 15:36:12,552 Training Epoch [18/40] Iter[102/312]		Loss: 0.1331
2019-10-28 15:36:12,631 Training Epoch [18/40] Iter[103/312]		Loss: 0.1332
2019-10-28 15:36:12,710 Training Epoch [18/40] Iter[104/312]		Loss: 0.1339
2019-10-28 15:36:12,789 Training Epoch [18/40] Iter[105/312]		Loss: 0.1338
2019-10-28 15:36:12,868 Training Epoch [18/40] Iter[106/312]		Loss: 0.1338
2019-10-28 15:36:12,947 Training Epoch [18/40] Iter[107/312]		Loss: 0.1346
2019-10-28 15:36:13,026 Training Epoch [18/40] Iter[108/312]		Loss: 0.1346
2019-10-28 15:36:13,105 Training Epoch [18/40] Iter[109/312]		Loss: 0.1353
2019-10-28 15:36:13,184 Training Epoch [18/40] Iter[110/312]		Loss: 0.1352
2019-10-28 15:36:13,263 Training Epoch [18/40] Iter[111/312]		Loss: 0.1359
2019-10-28 15:36:13,342 Training Epoch [18/40] Iter[112/312]		Loss: 0.1362
2019-10-28 15:36:13,422 Training Epoch [18/40] Iter[113/312]		Loss: 0.1359
2019-10-28 15:36:13,501 Training Epoch [18/40] Iter[114/312]		Loss: 0.1361
2019-10-28 15:36:13,580 Training Epoch [18/40] Iter[115/312]		Loss: 0.1360
2019-10-28 15:36:13,659 Training Epoch [18/40] Iter[116/312]		Loss: 0.1362
2019-10-28 15:36:13,738 Training Epoch [18/40] Iter[117/312]		Loss: 0.1360
2019-10-28 15:36:13,817 Training Epoch [18/40] Iter[118/312]		Loss: 0.1359
2019-10-28 15:36:13,896 Training Epoch [18/40] Iter[119/312]		Loss: 0.1354
2019-10-28 15:36:13,975 Training Epoch [18/40] Iter[120/312]		Loss: 0.1352
2019-10-28 15:36:14,054 Training Epoch [18/40] Iter[121/312]		Loss: 0.1350
2019-10-28 15:36:14,133 Training Epoch [18/40] Iter[122/312]		Loss: 0.1350
2019-10-28 15:36:14,212 Training Epoch [18/40] Iter[123/312]		Loss: 0.1353
2019-10-28 15:36:14,291 Training Epoch [18/40] Iter[124/312]		Loss: 0.1353
2019-10-28 15:36:14,370 Training Epoch [18/40] Iter[125/312]		Loss: 0.1351
2019-10-28 15:36:14,450 Training Epoch [18/40] Iter[126/312]		Loss: 0.1352
2019-10-28 15:36:14,529 Training Epoch [18/40] Iter[127/312]		Loss: 0.1354
2019-10-28 15:36:14,608 Training Epoch [18/40] Iter[128/312]		Loss: 0.1356
2019-10-28 15:36:14,687 Training Epoch [18/40] Iter[129/312]		Loss: 0.1354
2019-10-28 15:36:14,766 Training Epoch [18/40] Iter[130/312]		Loss: 0.1353
2019-10-28 15:36:14,845 Training Epoch [18/40] Iter[131/312]		Loss: 0.1351
2019-10-28 15:36:14,924 Training Epoch [18/40] Iter[132/312]		Loss: 0.1350
2019-10-28 15:36:15,003 Training Epoch [18/40] Iter[133/312]		Loss: 0.1350
2019-10-28 15:36:15,082 Training Epoch [18/40] Iter[134/312]		Loss: 0.1352
2019-10-28 15:36:15,161 Training Epoch [18/40] Iter[135/312]		Loss: 0.1355
2019-10-28 15:36:15,240 Training Epoch [18/40] Iter[136/312]		Loss: 0.1352
2019-10-28 15:36:15,319 Training Epoch [18/40] Iter[137/312]		Loss: 0.1352
2019-10-28 15:36:15,398 Training Epoch [18/40] Iter[138/312]		Loss: 0.1351
2019-10-28 15:36:15,477 Training Epoch [18/40] Iter[139/312]		Loss: 0.1350
2019-10-28 15:36:15,556 Training Epoch [18/40] Iter[140/312]		Loss: 0.1347
2019-10-28 15:36:15,635 Training Epoch [18/40] Iter[141/312]		Loss: 0.1345
2019-10-28 15:36:15,714 Training Epoch [18/40] Iter[142/312]		Loss: 0.1350
2019-10-28 15:36:15,793 Training Epoch [18/40] Iter[143/312]		Loss: 0.1347
2019-10-28 15:36:15,872 Training Epoch [18/40] Iter[144/312]		Loss: 0.1348
2019-10-28 15:36:15,952 Training Epoch [18/40] Iter[145/312]		Loss: 0.1349
2019-10-28 15:36:16,031 Training Epoch [18/40] Iter[146/312]		Loss: 0.1349
2019-10-28 15:36:16,110 Training Epoch [18/40] Iter[147/312]		Loss: 0.1348
2019-10-28 15:36:16,190 Training Epoch [18/40] Iter[148/312]		Loss: 0.1350
2019-10-28 15:36:16,269 Training Epoch [18/40] Iter[149/312]		Loss: 0.1349
2019-10-28 15:36:16,348 Training Epoch [18/40] Iter[150/312]		Loss: 0.1347
2019-10-28 15:36:16,427 Training Epoch [18/40] Iter[151/312]		Loss: 0.1345
2019-10-28 15:36:16,506 Training Epoch [18/40] Iter[152/312]		Loss: 0.1346
2019-10-28 15:36:16,585 Training Epoch [18/40] Iter[153/312]		Loss: 0.1344
2019-10-28 15:36:16,664 Training Epoch [18/40] Iter[154/312]		Loss: 0.1349
2019-10-28 15:36:16,743 Training Epoch [18/40] Iter[155/312]		Loss: 0.1348
2019-10-28 15:36:16,822 Training Epoch [18/40] Iter[156/312]		Loss: 0.1349
2019-10-28 15:36:16,900 Training Epoch [18/40] Iter[157/312]		Loss: 0.1350
2019-10-28 15:36:16,979 Training Epoch [18/40] Iter[158/312]		Loss: 0.1355
2019-10-28 15:36:17,058 Training Epoch [18/40] Iter[159/312]		Loss: 0.1357
2019-10-28 15:36:17,137 Training Epoch [18/40] Iter[160/312]		Loss: 0.1359
2019-10-28 15:36:17,216 Training Epoch [18/40] Iter[161/312]		Loss: 0.1358
2019-10-28 15:36:17,295 Training Epoch [18/40] Iter[162/312]		Loss: 0.1356
2019-10-28 15:36:17,374 Training Epoch [18/40] Iter[163/312]		Loss: 0.1353
2019-10-28 15:36:17,453 Training Epoch [18/40] Iter[164/312]		Loss: 0.1353
2019-10-28 15:36:17,532 Training Epoch [18/40] Iter[165/312]		Loss: 0.1354
2019-10-28 15:36:17,611 Training Epoch [18/40] Iter[166/312]		Loss: 0.1352
2019-10-28 15:36:17,690 Training Epoch [18/40] Iter[167/312]		Loss: 0.1352
2019-10-28 15:36:17,769 Training Epoch [18/40] Iter[168/312]		Loss: 0.1350
2019-10-28 15:36:17,848 Training Epoch [18/40] Iter[169/312]		Loss: 0.1351
2019-10-28 15:36:17,927 Training Epoch [18/40] Iter[170/312]		Loss: 0.1355
2019-10-28 15:36:18,006 Training Epoch [18/40] Iter[171/312]		Loss: 0.1357
2019-10-28 15:36:18,085 Training Epoch [18/40] Iter[172/312]		Loss: 0.1357
2019-10-28 15:36:18,164 Training Epoch [18/40] Iter[173/312]		Loss: 0.1356
2019-10-28 15:36:18,243 Training Epoch [18/40] Iter[174/312]		Loss: 0.1355
2019-10-28 15:36:18,322 Training Epoch [18/40] Iter[175/312]		Loss: 0.1355
2019-10-28 15:36:18,401 Training Epoch [18/40] Iter[176/312]		Loss: 0.1352
2019-10-28 15:36:18,480 Training Epoch [18/40] Iter[177/312]		Loss: 0.1357
2019-10-28 15:36:18,559 Training Epoch [18/40] Iter[178/312]		Loss: 0.1359
2019-10-28 15:36:18,638 Training Epoch [18/40] Iter[179/312]		Loss: 0.1357
2019-10-28 15:36:18,717 Training Epoch [18/40] Iter[180/312]		Loss: 0.1358
2019-10-28 15:36:18,796 Training Epoch [18/40] Iter[181/312]		Loss: 0.1356
2019-10-28 15:36:18,875 Training Epoch [18/40] Iter[182/312]		Loss: 0.1354
2019-10-28 15:36:18,953 Training Epoch [18/40] Iter[183/312]		Loss: 0.1355
2019-10-28 15:36:19,033 Training Epoch [18/40] Iter[184/312]		Loss: 0.1352
2019-10-28 15:36:19,111 Training Epoch [18/40] Iter[185/312]		Loss: 0.1350
2019-10-28 15:36:19,191 Training Epoch [18/40] Iter[186/312]		Loss: 0.1352
2019-10-28 15:36:19,270 Training Epoch [18/40] Iter[187/312]		Loss: 0.1350
2019-10-28 15:36:19,349 Training Epoch [18/40] Iter[188/312]		Loss: 0.1350
2019-10-28 15:36:19,428 Training Epoch [18/40] Iter[189/312]		Loss: 0.1351
2019-10-28 15:36:19,508 Training Epoch [18/40] Iter[190/312]		Loss: 0.1354
2019-10-28 15:36:19,587 Training Epoch [18/40] Iter[191/312]		Loss: 0.1355
2019-10-28 15:36:19,666 Training Epoch [18/40] Iter[192/312]		Loss: 0.1360
2019-10-28 15:36:19,745 Training Epoch [18/40] Iter[193/312]		Loss: 0.1359
2019-10-28 15:36:19,824 Training Epoch [18/40] Iter[194/312]		Loss: 0.1358
2019-10-28 15:36:19,903 Training Epoch [18/40] Iter[195/312]		Loss: 0.1356
2019-10-28 15:36:19,982 Training Epoch [18/40] Iter[196/312]		Loss: 0.1354
2019-10-28 15:36:20,061 Training Epoch [18/40] Iter[197/312]		Loss: 0.1354
2019-10-28 15:36:20,140 Training Epoch [18/40] Iter[198/312]		Loss: 0.1353
2019-10-28 15:36:20,219 Training Epoch [18/40] Iter[199/312]		Loss: 0.1351
2019-10-28 15:36:20,298 Training Epoch [18/40] Iter[200/312]		Loss: 0.1351
2019-10-28 15:36:20,377 Training Epoch [18/40] Iter[201/312]		Loss: 0.1350
2019-10-28 15:36:20,457 Training Epoch [18/40] Iter[202/312]		Loss: 0.1350
2019-10-28 15:36:20,536 Training Epoch [18/40] Iter[203/312]		Loss: 0.1347
2019-10-28 15:36:20,615 Training Epoch [18/40] Iter[204/312]		Loss: 0.1346
2019-10-28 15:36:20,694 Training Epoch [18/40] Iter[205/312]		Loss: 0.1353
2019-10-28 15:36:20,773 Training Epoch [18/40] Iter[206/312]		Loss: 0.1354
2019-10-28 15:36:20,852 Training Epoch [18/40] Iter[207/312]		Loss: 0.1352
2019-10-28 15:36:20,931 Training Epoch [18/40] Iter[208/312]		Loss: 0.1350
2019-10-28 15:36:21,010 Training Epoch [18/40] Iter[209/312]		Loss: 0.1349
2019-10-28 15:36:21,089 Training Epoch [18/40] Iter[210/312]		Loss: 0.1349
2019-10-28 15:36:21,168 Training Epoch [18/40] Iter[211/312]		Loss: 0.1349
2019-10-28 15:36:21,247 Training Epoch [18/40] Iter[212/312]		Loss: 0.1349
2019-10-28 15:36:21,326 Training Epoch [18/40] Iter[213/312]		Loss: 0.1349
2019-10-28 15:36:21,405 Training Epoch [18/40] Iter[214/312]		Loss: 0.1348
2019-10-28 15:36:21,484 Training Epoch [18/40] Iter[215/312]		Loss: 0.1347
2019-10-28 15:36:21,563 Training Epoch [18/40] Iter[216/312]		Loss: 0.1348
2019-10-28 15:36:21,642 Training Epoch [18/40] Iter[217/312]		Loss: 0.1346
2019-10-28 15:36:21,721 Training Epoch [18/40] Iter[218/312]		Loss: 0.1345
2019-10-28 15:36:21,800 Training Epoch [18/40] Iter[219/312]		Loss: 0.1346
2019-10-28 15:36:21,879 Training Epoch [18/40] Iter[220/312]		Loss: 0.1344
2019-10-28 15:36:21,958 Training Epoch [18/40] Iter[221/312]		Loss: 0.1344
2019-10-28 15:36:22,037 Training Epoch [18/40] Iter[222/312]		Loss: 0.1342
2019-10-28 15:36:22,116 Training Epoch [18/40] Iter[223/312]		Loss: 0.1343
2019-10-28 15:36:22,195 Training Epoch [18/40] Iter[224/312]		Loss: 0.1341
2019-10-28 15:36:22,274 Training Epoch [18/40] Iter[225/312]		Loss: 0.1342
2019-10-28 15:36:22,353 Training Epoch [18/40] Iter[226/312]		Loss: 0.1345
2019-10-28 15:36:22,432 Training Epoch [18/40] Iter[227/312]		Loss: 0.1347
2019-10-28 15:36:22,511 Training Epoch [18/40] Iter[228/312]		Loss: 0.1347
2019-10-28 15:36:22,590 Training Epoch [18/40] Iter[229/312]		Loss: 0.1345
2019-10-28 15:36:22,669 Training Epoch [18/40] Iter[230/312]		Loss: 0.1345
2019-10-28 15:36:22,748 Training Epoch [18/40] Iter[231/312]		Loss: 0.1346
2019-10-28 15:36:22,827 Training Epoch [18/40] Iter[232/312]		Loss: 0.1345
2019-10-28 15:36:22,906 Training Epoch [18/40] Iter[233/312]		Loss: 0.1343
2019-10-28 15:36:22,984 Training Epoch [18/40] Iter[234/312]		Loss: 0.1344
2019-10-28 15:36:23,064 Training Epoch [18/40] Iter[235/312]		Loss: 0.1343
2019-10-28 15:36:23,143 Training Epoch [18/40] Iter[236/312]		Loss: 0.1343
2019-10-28 15:36:23,222 Training Epoch [18/40] Iter[237/312]		Loss: 0.1342
2019-10-28 15:36:23,301 Training Epoch [18/40] Iter[238/312]		Loss: 0.1340
2019-10-28 15:36:23,380 Training Epoch [18/40] Iter[239/312]		Loss: 0.1340
2019-10-28 15:36:23,460 Training Epoch [18/40] Iter[240/312]		Loss: 0.1341
2019-10-28 15:36:23,539 Training Epoch [18/40] Iter[241/312]		Loss: 0.1343
2019-10-28 15:36:23,618 Training Epoch [18/40] Iter[242/312]		Loss: 0.1342
2019-10-28 15:36:23,697 Training Epoch [18/40] Iter[243/312]		Loss: 0.1340
2019-10-28 15:36:23,776 Training Epoch [18/40] Iter[244/312]		Loss: 0.1340
2019-10-28 15:36:23,856 Training Epoch [18/40] Iter[245/312]		Loss: 0.1342
2019-10-28 15:36:23,934 Training Epoch [18/40] Iter[246/312]		Loss: 0.1343
2019-10-28 15:36:24,013 Training Epoch [18/40] Iter[247/312]		Loss: 0.1342
2019-10-28 15:36:24,092 Training Epoch [18/40] Iter[248/312]		Loss: 0.1342
2019-10-28 15:36:24,171 Training Epoch [18/40] Iter[249/312]		Loss: 0.1342
2019-10-28 15:36:24,251 Training Epoch [18/40] Iter[250/312]		Loss: 0.1342
2019-10-28 15:36:24,330 Training Epoch [18/40] Iter[251/312]		Loss: 0.1340
2019-10-28 15:36:24,409 Training Epoch [18/40] Iter[252/312]		Loss: 0.1344
2019-10-28 15:36:24,488 Training Epoch [18/40] Iter[253/312]		Loss: 0.1343
2019-10-28 15:36:24,571 Training Epoch [18/40] Iter[254/312]		Loss: 0.1342
2019-10-28 15:36:24,650 Training Epoch [18/40] Iter[255/312]		Loss: 0.1340
2019-10-28 15:36:24,729 Training Epoch [18/40] Iter[256/312]		Loss: 0.1340
2019-10-28 15:36:24,808 Training Epoch [18/40] Iter[257/312]		Loss: 0.1339
2019-10-28 15:36:24,887 Training Epoch [18/40] Iter[258/312]		Loss: 0.1339
2019-10-28 15:36:24,966 Training Epoch [18/40] Iter[259/312]		Loss: 0.1338
2019-10-28 15:36:25,045 Training Epoch [18/40] Iter[260/312]		Loss: 0.1337
2019-10-28 15:36:25,124 Training Epoch [18/40] Iter[261/312]		Loss: 0.1337
2019-10-28 15:36:25,203 Training Epoch [18/40] Iter[262/312]		Loss: 0.1336
2019-10-28 15:36:25,283 Training Epoch [18/40] Iter[263/312]		Loss: 0.1334
2019-10-28 15:36:25,362 Training Epoch [18/40] Iter[264/312]		Loss: 0.1333
2019-10-28 15:36:25,441 Training Epoch [18/40] Iter[265/312]		Loss: 0.1333
2019-10-28 15:36:25,520 Training Epoch [18/40] Iter[266/312]		Loss: 0.1334
2019-10-28 15:36:25,598 Training Epoch [18/40] Iter[267/312]		Loss: 0.1333
2019-10-28 15:36:25,677 Training Epoch [18/40] Iter[268/312]		Loss: 0.1331
2019-10-28 15:36:25,757 Training Epoch [18/40] Iter[269/312]		Loss: 0.1330
2019-10-28 15:36:25,836 Training Epoch [18/40] Iter[270/312]		Loss: 0.1329
2019-10-28 15:36:25,916 Training Epoch [18/40] Iter[271/312]		Loss: 0.1327
2019-10-28 15:36:25,995 Training Epoch [18/40] Iter[272/312]		Loss: 0.1326
2019-10-28 15:36:26,075 Training Epoch [18/40] Iter[273/312]		Loss: 0.1325
2019-10-28 15:36:26,154 Training Epoch [18/40] Iter[274/312]		Loss: 0.1328
2019-10-28 15:36:26,233 Training Epoch [18/40] Iter[275/312]		Loss: 0.1328
2019-10-28 15:36:26,312 Training Epoch [18/40] Iter[276/312]		Loss: 0.1328
2019-10-28 15:36:26,391 Training Epoch [18/40] Iter[277/312]		Loss: 0.1329
2019-10-28 15:36:26,470 Training Epoch [18/40] Iter[278/312]		Loss: 0.1328
2019-10-28 15:36:26,549 Training Epoch [18/40] Iter[279/312]		Loss: 0.1327
2019-10-28 15:36:26,628 Training Epoch [18/40] Iter[280/312]		Loss: 0.1327
2019-10-28 15:36:26,707 Training Epoch [18/40] Iter[281/312]		Loss: 0.1328
2019-10-28 15:36:26,787 Training Epoch [18/40] Iter[282/312]		Loss: 0.1326
2019-10-28 15:36:26,866 Training Epoch [18/40] Iter[283/312]		Loss: 0.1328
2019-10-28 15:36:26,945 Training Epoch [18/40] Iter[284/312]		Loss: 0.1329
2019-10-28 15:36:27,024 Training Epoch [18/40] Iter[285/312]		Loss: 0.1333
2019-10-28 15:36:27,103 Training Epoch [18/40] Iter[286/312]		Loss: 0.1332
2019-10-28 15:36:27,182 Training Epoch [18/40] Iter[287/312]		Loss: 0.1333
2019-10-28 15:36:27,261 Training Epoch [18/40] Iter[288/312]		Loss: 0.1332
2019-10-28 15:36:27,340 Training Epoch [18/40] Iter[289/312]		Loss: 0.1333
2019-10-28 15:36:27,420 Training Epoch [18/40] Iter[290/312]		Loss: 0.1334
2019-10-28 15:36:27,499 Training Epoch [18/40] Iter[291/312]		Loss: 0.1332
2019-10-28 15:36:27,579 Training Epoch [18/40] Iter[292/312]		Loss: 0.1332
2019-10-28 15:36:27,658 Training Epoch [18/40] Iter[293/312]		Loss: 0.1333
2019-10-28 15:36:27,737 Training Epoch [18/40] Iter[294/312]		Loss: 0.1334
2019-10-28 15:36:27,817 Training Epoch [18/40] Iter[295/312]		Loss: 0.1333
2019-10-28 15:36:27,896 Training Epoch [18/40] Iter[296/312]		Loss: 0.1332
2019-10-28 15:36:27,975 Training Epoch [18/40] Iter[297/312]		Loss: 0.1332
2019-10-28 15:36:28,055 Training Epoch [18/40] Iter[298/312]		Loss: 0.1335
2019-10-28 15:36:28,134 Training Epoch [18/40] Iter[299/312]		Loss: 0.1335
2019-10-28 15:36:28,214 Training Epoch [18/40] Iter[300/312]		Loss: 0.1335
2019-10-28 15:36:28,293 Training Epoch [18/40] Iter[301/312]		Loss: 0.1335
2019-10-28 15:36:28,373 Training Epoch [18/40] Iter[302/312]		Loss: 0.1334
2019-10-28 15:36:28,453 Training Epoch [18/40] Iter[303/312]		Loss: 0.1332
2019-10-28 15:36:28,532 Training Epoch [18/40] Iter[304/312]		Loss: 0.1332
2019-10-28 15:36:28,611 Training Epoch [18/40] Iter[305/312]		Loss: 0.1333
2019-10-28 15:36:28,689 Training Epoch [18/40] Iter[306/312]		Loss: 0.1335
2019-10-28 15:36:28,767 Training Epoch [18/40] Iter[307/312]		Loss: 0.1335
2019-10-28 15:36:28,846 Training Epoch [18/40] Iter[308/312]		Loss: 0.1335
2019-10-28 15:36:28,924 Training Epoch [18/40] Iter[309/312]		Loss: 0.1334
2019-10-28 15:36:29,003 Training Epoch [18/40] Iter[310/312]		Loss: 0.1335
2019-10-28 15:36:29,081 Training Epoch [18/40] Iter[311/312]		Loss: 0.1336
2019-10-28 15:36:29,120 Training Epoch [18/40] Iter[312/312]		Loss: 0.1336
2019-10-28 15:36:29,547 Testing Epoch [18/40] Iter[0/62]		Loss: 0.1414
2019-10-28 15:36:29,587 Testing Epoch [18/40] Iter[1/62]		Loss: 0.1346
2019-10-28 15:36:29,614 Testing Epoch [18/40] Iter[2/62]		Loss: 0.1162
2019-10-28 15:36:29,649 Testing Epoch [18/40] Iter[3/62]		Loss: 0.1209
2019-10-28 15:36:29,666 Testing Epoch [18/40] Iter[4/62]		Loss: 0.1288
2019-10-28 15:36:29,694 Testing Epoch [18/40] Iter[5/62]		Loss: 0.1253
2019-10-28 15:36:29,711 Testing Epoch [18/40] Iter[6/62]		Loss: 0.1278
2019-10-28 15:36:29,738 Testing Epoch [18/40] Iter[7/62]		Loss: 0.1302
2019-10-28 15:36:29,761 Testing Epoch [18/40] Iter[8/62]		Loss: 0.1323
2019-10-28 15:36:29,789 Testing Epoch [18/40] Iter[9/62]		Loss: 0.1313
2019-10-28 15:36:29,811 Testing Epoch [18/40] Iter[10/62]		Loss: 0.1332
2019-10-28 15:36:29,828 Testing Epoch [18/40] Iter[11/62]		Loss: 0.1410
2019-10-28 15:36:29,853 Testing Epoch [18/40] Iter[12/62]		Loss: 0.1407
2019-10-28 15:36:29,871 Testing Epoch [18/40] Iter[13/62]		Loss: 0.1422
2019-10-28 15:36:29,888 Testing Epoch [18/40] Iter[14/62]		Loss: 0.1558
2019-10-28 15:36:29,914 Testing Epoch [18/40] Iter[15/62]		Loss: 0.1574
2019-10-28 15:36:29,945 Testing Epoch [18/40] Iter[16/62]		Loss: 0.1544
2019-10-28 15:36:29,970 Testing Epoch [18/40] Iter[17/62]		Loss: 0.1544
2019-10-28 15:36:29,989 Testing Epoch [18/40] Iter[18/62]		Loss: 0.1515
2019-10-28 15:36:30,018 Testing Epoch [18/40] Iter[19/62]		Loss: 0.1494
2019-10-28 15:36:30,038 Testing Epoch [18/40] Iter[20/62]		Loss: 0.1507
2019-10-28 15:36:30,065 Testing Epoch [18/40] Iter[21/62]		Loss: 0.1491
2019-10-28 15:36:30,089 Testing Epoch [18/40] Iter[22/62]		Loss: 0.1497
2019-10-28 15:36:30,113 Testing Epoch [18/40] Iter[23/62]		Loss: 0.1483
2019-10-28 15:36:30,141 Testing Epoch [18/40] Iter[24/62]		Loss: 0.1523
2019-10-28 15:36:30,161 Testing Epoch [18/40] Iter[25/62]		Loss: 0.1510
2019-10-28 15:36:30,179 Testing Epoch [18/40] Iter[26/62]		Loss: 0.1497
2019-10-28 15:36:30,206 Testing Epoch [18/40] Iter[27/62]		Loss: 0.1576
2019-10-28 15:36:30,227 Testing Epoch [18/40] Iter[28/62]		Loss: 0.1613
2019-10-28 15:36:30,253 Testing Epoch [18/40] Iter[29/62]		Loss: 0.1612
2019-10-28 15:36:30,271 Testing Epoch [18/40] Iter[30/62]		Loss: 0.1612
2019-10-28 15:36:30,301 Testing Epoch [18/40] Iter[31/62]		Loss: 0.1606
2019-10-28 15:36:30,325 Testing Epoch [18/40] Iter[32/62]		Loss: 0.1624
2019-10-28 15:36:30,349 Testing Epoch [18/40] Iter[33/62]		Loss: 0.1614
2019-10-28 15:36:30,373 Testing Epoch [18/40] Iter[34/62]		Loss: 0.1641
2019-10-28 15:36:30,401 Testing Epoch [18/40] Iter[35/62]		Loss: 0.1637
2019-10-28 15:36:30,418 Testing Epoch [18/40] Iter[36/62]		Loss: 0.1618
2019-10-28 15:36:30,436 Testing Epoch [18/40] Iter[37/62]		Loss: 0.1608
2019-10-28 15:36:30,461 Testing Epoch [18/40] Iter[38/62]		Loss: 0.1600
2019-10-28 15:36:30,483 Testing Epoch [18/40] Iter[39/62]		Loss: 0.1603
2019-10-28 15:36:30,509 Testing Epoch [18/40] Iter[40/62]		Loss: 0.1618
2019-10-28 15:36:30,526 Testing Epoch [18/40] Iter[41/62]		Loss: 0.1640
2019-10-28 15:36:30,544 Testing Epoch [18/40] Iter[42/62]		Loss: 0.1617
2019-10-28 15:36:30,570 Testing Epoch [18/40] Iter[43/62]		Loss: 0.1610
2019-10-28 15:36:30,593 Testing Epoch [18/40] Iter[44/62]		Loss: 0.1592
2019-10-28 15:36:30,611 Testing Epoch [18/40] Iter[45/62]		Loss: 0.1590
2019-10-28 15:36:30,629 Testing Epoch [18/40] Iter[46/62]		Loss: 0.1587
2019-10-28 15:36:30,658 Testing Epoch [18/40] Iter[47/62]		Loss: 0.1641
2019-10-28 15:36:30,688 Testing Epoch [18/40] Iter[48/62]		Loss: 0.1631
2019-10-28 15:36:30,706 Testing Epoch [18/40] Iter[49/62]		Loss: 0.1651
2019-10-28 15:36:30,734 Testing Epoch [18/40] Iter[50/62]		Loss: 0.1642
2019-10-28 15:36:30,752 Testing Epoch [18/40] Iter[51/62]		Loss: 0.1640
2019-10-28 15:36:30,769 Testing Epoch [18/40] Iter[52/62]		Loss: 0.1627
2019-10-28 15:36:30,798 Testing Epoch [18/40] Iter[53/62]		Loss: 0.1629
2019-10-28 15:36:30,825 Testing Epoch [18/40] Iter[54/62]		Loss: 0.1618
2019-10-28 15:36:30,842 Testing Epoch [18/40] Iter[55/62]		Loss: 0.1615
2019-10-28 15:36:30,858 Testing Epoch [18/40] Iter[56/62]		Loss: 0.1609
2019-10-28 15:36:30,875 Testing Epoch [18/40] Iter[57/62]		Loss: 0.1610
2019-10-28 15:36:30,891 Testing Epoch [18/40] Iter[58/62]		Loss: 0.1605
2019-10-28 15:36:30,908 Testing Epoch [18/40] Iter[59/62]		Loss: 0.1616
2019-10-28 15:36:30,925 Testing Epoch [18/40] Iter[60/62]		Loss: 0.1607
2019-10-28 15:36:30,941 Testing Epoch [18/40] Iter[61/62]		Loss: 0.1608
2019-10-28 15:36:30,951 Testing Epoch [18/40] Iter[62/62]		Loss: 0.1618
2019-10-28 15:36:31,019 Saving the Model
2019-10-28 15:36:31,431 Training Epoch [19/40] Iter[0/312]		Loss: 0.2760
2019-10-28 15:36:31,512 Training Epoch [19/40] Iter[1/312]		Loss: 0.2128
2019-10-28 15:36:31,595 Training Epoch [19/40] Iter[2/312]		Loss: 0.1782
2019-10-28 15:36:31,678 Training Epoch [19/40] Iter[3/312]		Loss: 0.1647
2019-10-28 15:36:31,756 Training Epoch [19/40] Iter[4/312]		Loss: 0.1612
2019-10-28 15:36:31,833 Training Epoch [19/40] Iter[5/312]		Loss: 0.1603
2019-10-28 15:36:31,911 Training Epoch [19/40] Iter[6/312]		Loss: 0.1611
2019-10-28 15:36:31,990 Training Epoch [19/40] Iter[7/312]		Loss: 0.1544
2019-10-28 15:36:32,070 Training Epoch [19/40] Iter[8/312]		Loss: 0.1484
2019-10-28 15:36:32,148 Training Epoch [19/40] Iter[9/312]		Loss: 0.1475
2019-10-28 15:36:32,227 Training Epoch [19/40] Iter[10/312]		Loss: 0.1439
2019-10-28 15:36:32,306 Training Epoch [19/40] Iter[11/312]		Loss: 0.1420
2019-10-28 15:36:32,386 Training Epoch [19/40] Iter[12/312]		Loss: 0.1423
2019-10-28 15:36:32,465 Training Epoch [19/40] Iter[13/312]		Loss: 0.1463
2019-10-28 15:36:32,544 Training Epoch [19/40] Iter[14/312]		Loss: 0.1466
2019-10-28 15:36:32,623 Training Epoch [19/40] Iter[15/312]		Loss: 0.1469
2019-10-28 15:36:32,702 Training Epoch [19/40] Iter[16/312]		Loss: 0.1444
2019-10-28 15:36:32,781 Training Epoch [19/40] Iter[17/312]		Loss: 0.1421
2019-10-28 15:36:32,860 Training Epoch [19/40] Iter[18/312]		Loss: 0.1421
2019-10-28 15:36:32,939 Training Epoch [19/40] Iter[19/312]		Loss: 0.1402
2019-10-28 15:36:33,018 Training Epoch [19/40] Iter[20/312]		Loss: 0.1420
2019-10-28 15:36:33,097 Training Epoch [19/40] Iter[21/312]		Loss: 0.1398
2019-10-28 15:36:33,176 Training Epoch [19/40] Iter[22/312]		Loss: 0.1383
2019-10-28 15:36:33,255 Training Epoch [19/40] Iter[23/312]		Loss: 0.1366
2019-10-28 15:36:33,334 Training Epoch [19/40] Iter[24/312]		Loss: 0.1352
2019-10-28 15:36:33,414 Training Epoch [19/40] Iter[25/312]		Loss: 0.1346
2019-10-28 15:36:33,493 Training Epoch [19/40] Iter[26/312]		Loss: 0.1346
2019-10-28 15:36:33,572 Training Epoch [19/40] Iter[27/312]		Loss: 0.1342
2019-10-28 15:36:33,651 Training Epoch [19/40] Iter[28/312]		Loss: 0.1353
2019-10-28 15:36:33,730 Training Epoch [19/40] Iter[29/312]		Loss: 0.1345
2019-10-28 15:36:33,810 Training Epoch [19/40] Iter[30/312]		Loss: 0.1346
2019-10-28 15:36:33,889 Training Epoch [19/40] Iter[31/312]		Loss: 0.1345
2019-10-28 15:36:33,968 Training Epoch [19/40] Iter[32/312]		Loss: 0.1335
2019-10-28 15:36:34,047 Training Epoch [19/40] Iter[33/312]		Loss: 0.1359
2019-10-28 15:36:34,126 Training Epoch [19/40] Iter[34/312]		Loss: 0.1361
2019-10-28 15:36:34,205 Training Epoch [19/40] Iter[35/312]		Loss: 0.1352
2019-10-28 15:36:34,284 Training Epoch [19/40] Iter[36/312]		Loss: 0.1345
2019-10-28 15:36:34,363 Training Epoch [19/40] Iter[37/312]		Loss: 0.1336
2019-10-28 15:36:34,443 Training Epoch [19/40] Iter[38/312]		Loss: 0.1330
2019-10-28 15:36:34,522 Training Epoch [19/40] Iter[39/312]		Loss: 0.1340
2019-10-28 15:36:34,601 Training Epoch [19/40] Iter[40/312]		Loss: 0.1341
2019-10-28 15:36:34,680 Training Epoch [19/40] Iter[41/312]		Loss: 0.1350
2019-10-28 15:36:34,759 Training Epoch [19/40] Iter[42/312]		Loss: 0.1349
2019-10-28 15:36:34,838 Training Epoch [19/40] Iter[43/312]		Loss: 0.1369
2019-10-28 15:36:34,917 Training Epoch [19/40] Iter[44/312]		Loss: 0.1369
2019-10-28 15:36:34,996 Training Epoch [19/40] Iter[45/312]		Loss: 0.1371
2019-10-28 15:36:35,075 Training Epoch [19/40] Iter[46/312]		Loss: 0.1375
2019-10-28 15:36:35,155 Training Epoch [19/40] Iter[47/312]		Loss: 0.1380
2019-10-28 15:36:35,234 Training Epoch [19/40] Iter[48/312]		Loss: 0.1379
2019-10-28 15:36:35,313 Training Epoch [19/40] Iter[49/312]		Loss: 0.1370
2019-10-28 15:36:35,392 Training Epoch [19/40] Iter[50/312]		Loss: 0.1368
2019-10-28 15:36:35,471 Training Epoch [19/40] Iter[51/312]		Loss: 0.1359
2019-10-28 15:36:35,550 Training Epoch [19/40] Iter[52/312]		Loss: 0.1367
2019-10-28 15:36:35,629 Training Epoch [19/40] Iter[53/312]		Loss: 0.1387
2019-10-28 15:36:35,708 Training Epoch [19/40] Iter[54/312]		Loss: 0.1377
2019-10-28 15:36:35,787 Training Epoch [19/40] Iter[55/312]		Loss: 0.1370
2019-10-28 15:36:35,866 Training Epoch [19/40] Iter[56/312]		Loss: 0.1365
2019-10-28 15:36:35,945 Training Epoch [19/40] Iter[57/312]		Loss: 0.1369
2019-10-28 15:36:36,023 Training Epoch [19/40] Iter[58/312]		Loss: 0.1366
2019-10-28 15:36:36,102 Training Epoch [19/40] Iter[59/312]		Loss: 0.1361
2019-10-28 15:36:36,181 Training Epoch [19/40] Iter[60/312]		Loss: 0.1355
2019-10-28 15:36:36,260 Training Epoch [19/40] Iter[61/312]		Loss: 0.1354
2019-10-28 15:36:36,339 Training Epoch [19/40] Iter[62/312]		Loss: 0.1362
2019-10-28 15:36:36,418 Training Epoch [19/40] Iter[63/312]		Loss: 0.1377
2019-10-28 15:36:36,498 Training Epoch [19/40] Iter[64/312]		Loss: 0.1382
2019-10-28 15:36:36,577 Training Epoch [19/40] Iter[65/312]		Loss: 0.1386
2019-10-28 15:36:36,656 Training Epoch [19/40] Iter[66/312]		Loss: 0.1384
2019-10-28 15:36:36,735 Training Epoch [19/40] Iter[67/312]		Loss: 0.1385
2019-10-28 15:36:36,814 Training Epoch [19/40] Iter[68/312]		Loss: 0.1388
2019-10-28 15:36:36,893 Training Epoch [19/40] Iter[69/312]		Loss: 0.1392
2019-10-28 15:36:36,971 Training Epoch [19/40] Iter[70/312]		Loss: 0.1388
2019-10-28 15:36:37,050 Training Epoch [19/40] Iter[71/312]		Loss: 0.1390
2019-10-28 15:36:37,129 Training Epoch [19/40] Iter[72/312]		Loss: 0.1386
2019-10-28 15:36:37,208 Training Epoch [19/40] Iter[73/312]		Loss: 0.1385
2019-10-28 15:36:37,287 Training Epoch [19/40] Iter[74/312]		Loss: 0.1389
2019-10-28 15:36:37,366 Training Epoch [19/40] Iter[75/312]		Loss: 0.1399
2019-10-28 15:36:37,445 Training Epoch [19/40] Iter[76/312]		Loss: 0.1396
2019-10-28 15:36:37,524 Training Epoch [19/40] Iter[77/312]		Loss: 0.1401
2019-10-28 15:36:37,602 Training Epoch [19/40] Iter[78/312]		Loss: 0.1399
2019-10-28 15:36:37,682 Training Epoch [19/40] Iter[79/312]		Loss: 0.1399
2019-10-28 15:36:37,760 Training Epoch [19/40] Iter[80/312]		Loss: 0.1401
2019-10-28 15:36:37,839 Training Epoch [19/40] Iter[81/312]		Loss: 0.1398
2019-10-28 15:36:37,918 Training Epoch [19/40] Iter[82/312]		Loss: 0.1394
2019-10-28 15:36:37,997 Training Epoch [19/40] Iter[83/312]		Loss: 0.1396
2019-10-28 15:36:38,076 Training Epoch [19/40] Iter[84/312]		Loss: 0.1396
2019-10-28 15:36:38,155 Training Epoch [19/40] Iter[85/312]		Loss: 0.1396
2019-10-28 15:36:38,234 Training Epoch [19/40] Iter[86/312]		Loss: 0.1392
2019-10-28 15:36:38,312 Training Epoch [19/40] Iter[87/312]		Loss: 0.1386
2019-10-28 15:36:38,392 Training Epoch [19/40] Iter[88/312]		Loss: 0.1382
2019-10-28 15:36:38,471 Training Epoch [19/40] Iter[89/312]		Loss: 0.1382
2019-10-28 15:36:38,550 Training Epoch [19/40] Iter[90/312]		Loss: 0.1386
2019-10-28 15:36:38,629 Training Epoch [19/40] Iter[91/312]		Loss: 0.1387
2019-10-28 15:36:38,708 Training Epoch [19/40] Iter[92/312]		Loss: 0.1383
2019-10-28 15:36:38,787 Training Epoch [19/40] Iter[93/312]		Loss: 0.1379
2019-10-28 15:36:38,865 Training Epoch [19/40] Iter[94/312]		Loss: 0.1375
2019-10-28 15:36:38,945 Training Epoch [19/40] Iter[95/312]		Loss: 0.1368
2019-10-28 15:36:39,024 Training Epoch [19/40] Iter[96/312]		Loss: 0.1363
2019-10-28 15:36:39,110 Training Epoch [19/40] Iter[97/312]		Loss: 0.1362
2019-10-28 15:36:39,189 Training Epoch [19/40] Iter[98/312]		Loss: 0.1365
2019-10-28 15:36:39,268 Training Epoch [19/40] Iter[99/312]		Loss: 0.1360
2019-10-28 15:36:39,347 Training Epoch [19/40] Iter[100/312]		Loss: 0.1353
2019-10-28 15:36:39,427 Training Epoch [19/40] Iter[101/312]		Loss: 0.1351
2019-10-28 15:36:39,506 Training Epoch [19/40] Iter[102/312]		Loss: 0.1348
2019-10-28 15:36:39,585 Training Epoch [19/40] Iter[103/312]		Loss: 0.1350
2019-10-28 15:36:39,663 Training Epoch [19/40] Iter[104/312]		Loss: 0.1347
2019-10-28 15:36:39,742 Training Epoch [19/40] Iter[105/312]		Loss: 0.1346
2019-10-28 15:36:39,821 Training Epoch [19/40] Iter[106/312]		Loss: 0.1343
2019-10-28 15:36:39,900 Training Epoch [19/40] Iter[107/312]		Loss: 0.1344
2019-10-28 15:36:39,979 Training Epoch [19/40] Iter[108/312]		Loss: 0.1343
2019-10-28 15:36:40,058 Training Epoch [19/40] Iter[109/312]		Loss: 0.1339
2019-10-28 15:36:40,136 Training Epoch [19/40] Iter[110/312]		Loss: 0.1354
2019-10-28 15:36:40,215 Training Epoch [19/40] Iter[111/312]		Loss: 0.1357
2019-10-28 15:36:40,294 Training Epoch [19/40] Iter[112/312]		Loss: 0.1359
2019-10-28 15:36:40,373 Training Epoch [19/40] Iter[113/312]		Loss: 0.1356
2019-10-28 15:36:40,452 Training Epoch [19/40] Iter[114/312]		Loss: 0.1354
2019-10-28 15:36:40,531 Training Epoch [19/40] Iter[115/312]		Loss: 0.1353
2019-10-28 15:36:40,610 Training Epoch [19/40] Iter[116/312]		Loss: 0.1354
2019-10-28 15:36:40,689 Training Epoch [19/40] Iter[117/312]		Loss: 0.1352
2019-10-28 15:36:40,768 Training Epoch [19/40] Iter[118/312]		Loss: 0.1352
2019-10-28 15:36:40,847 Training Epoch [19/40] Iter[119/312]		Loss: 0.1352
2019-10-28 15:36:40,926 Training Epoch [19/40] Iter[120/312]		Loss: 0.1356
2019-10-28 15:36:41,005 Training Epoch [19/40] Iter[121/312]		Loss: 0.1355
2019-10-28 15:36:41,084 Training Epoch [19/40] Iter[122/312]		Loss: 0.1354
2019-10-28 15:36:41,163 Training Epoch [19/40] Iter[123/312]		Loss: 0.1353
2019-10-28 15:36:41,242 Training Epoch [19/40] Iter[124/312]		Loss: 0.1348
2019-10-28 15:36:41,321 Training Epoch [19/40] Iter[125/312]		Loss: 0.1354
2019-10-28 15:36:41,400 Training Epoch [19/40] Iter[126/312]		Loss: 0.1358
2019-10-28 15:36:41,479 Training Epoch [19/40] Iter[127/312]		Loss: 0.1357
2019-10-28 15:36:41,558 Training Epoch [19/40] Iter[128/312]		Loss: 0.1355
2019-10-28 15:36:41,637 Training Epoch [19/40] Iter[129/312]		Loss: 0.1353
2019-10-28 15:36:41,716 Training Epoch [19/40] Iter[130/312]		Loss: 0.1350
2019-10-28 15:36:41,795 Training Epoch [19/40] Iter[131/312]		Loss: 0.1350
2019-10-28 15:36:41,874 Training Epoch [19/40] Iter[132/312]		Loss: 0.1352
2019-10-28 15:36:41,953 Training Epoch [19/40] Iter[133/312]		Loss: 0.1351
2019-10-28 15:36:42,031 Training Epoch [19/40] Iter[134/312]		Loss: 0.1350
2019-10-28 15:36:42,110 Training Epoch [19/40] Iter[135/312]		Loss: 0.1347
2019-10-28 15:36:42,190 Training Epoch [19/40] Iter[136/312]		Loss: 0.1351
2019-10-28 15:36:42,268 Training Epoch [19/40] Iter[137/312]		Loss: 0.1350
2019-10-28 15:36:42,347 Training Epoch [19/40] Iter[138/312]		Loss: 0.1351
2019-10-28 15:36:42,427 Training Epoch [19/40] Iter[139/312]		Loss: 0.1349
2019-10-28 15:36:42,506 Training Epoch [19/40] Iter[140/312]		Loss: 0.1354
2019-10-28 15:36:42,584 Training Epoch [19/40] Iter[141/312]		Loss: 0.1357
2019-10-28 15:36:42,663 Training Epoch [19/40] Iter[142/312]		Loss: 0.1354
2019-10-28 15:36:42,742 Training Epoch [19/40] Iter[143/312]		Loss: 0.1353
2019-10-28 15:36:42,821 Training Epoch [19/40] Iter[144/312]		Loss: 0.1352
2019-10-28 15:36:42,900 Training Epoch [19/40] Iter[145/312]		Loss: 0.1351
2019-10-28 15:36:42,979 Training Epoch [19/40] Iter[146/312]		Loss: 0.1350
2019-10-28 15:36:43,058 Training Epoch [19/40] Iter[147/312]		Loss: 0.1349
2019-10-28 15:36:43,136 Training Epoch [19/40] Iter[148/312]		Loss: 0.1346
2019-10-28 15:36:43,215 Training Epoch [19/40] Iter[149/312]		Loss: 0.1344
2019-10-28 15:36:43,294 Training Epoch [19/40] Iter[150/312]		Loss: 0.1345
2019-10-28 15:36:43,373 Training Epoch [19/40] Iter[151/312]		Loss: 0.1346
2019-10-28 15:36:43,453 Training Epoch [19/40] Iter[152/312]		Loss: 0.1344
2019-10-28 15:36:43,532 Training Epoch [19/40] Iter[153/312]		Loss: 0.1342
2019-10-28 15:36:43,611 Training Epoch [19/40] Iter[154/312]		Loss: 0.1343
2019-10-28 15:36:43,690 Training Epoch [19/40] Iter[155/312]		Loss: 0.1341
2019-10-28 15:36:43,769 Training Epoch [19/40] Iter[156/312]		Loss: 0.1339
2019-10-28 15:36:43,848 Training Epoch [19/40] Iter[157/312]		Loss: 0.1336
2019-10-28 15:36:43,927 Training Epoch [19/40] Iter[158/312]		Loss: 0.1337
2019-10-28 15:36:44,006 Training Epoch [19/40] Iter[159/312]		Loss: 0.1337
2019-10-28 15:36:44,084 Training Epoch [19/40] Iter[160/312]		Loss: 0.1337
2019-10-28 15:36:44,163 Training Epoch [19/40] Iter[161/312]		Loss: 0.1334
2019-10-28 15:36:44,242 Training Epoch [19/40] Iter[162/312]		Loss: 0.1340
2019-10-28 15:36:44,321 Training Epoch [19/40] Iter[163/312]		Loss: 0.1338
2019-10-28 15:36:44,401 Training Epoch [19/40] Iter[164/312]		Loss: 0.1339
2019-10-28 15:36:44,480 Training Epoch [19/40] Iter[165/312]		Loss: 0.1340
2019-10-28 15:36:44,559 Training Epoch [19/40] Iter[166/312]		Loss: 0.1338
2019-10-28 15:36:44,637 Training Epoch [19/40] Iter[167/312]		Loss: 0.1336
2019-10-28 15:36:44,716 Training Epoch [19/40] Iter[168/312]		Loss: 0.1335
2019-10-28 15:36:44,795 Training Epoch [19/40] Iter[169/312]		Loss: 0.1333
2019-10-28 15:36:44,874 Training Epoch [19/40] Iter[170/312]		Loss: 0.1330
2019-10-28 15:36:44,953 Training Epoch [19/40] Iter[171/312]		Loss: 0.1328
2019-10-28 15:36:45,033 Training Epoch [19/40] Iter[172/312]		Loss: 0.1329
2019-10-28 15:36:45,111 Training Epoch [19/40] Iter[173/312]		Loss: 0.1332
2019-10-28 15:36:45,190 Training Epoch [19/40] Iter[174/312]		Loss: 0.1332
2019-10-28 15:36:45,269 Training Epoch [19/40] Iter[175/312]		Loss: 0.1330
2019-10-28 15:36:45,348 Training Epoch [19/40] Iter[176/312]		Loss: 0.1328
2019-10-28 15:36:45,427 Training Epoch [19/40] Iter[177/312]		Loss: 0.1336
2019-10-28 15:36:45,507 Training Epoch [19/40] Iter[178/312]		Loss: 0.1333
2019-10-28 15:36:45,586 Training Epoch [19/40] Iter[179/312]		Loss: 0.1331
2019-10-28 15:36:45,664 Training Epoch [19/40] Iter[180/312]		Loss: 0.1331
2019-10-28 15:36:45,743 Training Epoch [19/40] Iter[181/312]		Loss: 0.1329
2019-10-28 15:36:45,822 Training Epoch [19/40] Iter[182/312]		Loss: 0.1328
2019-10-28 15:36:45,904 Training Epoch [19/40] Iter[183/312]		Loss: 0.1326
2019-10-28 15:36:45,983 Training Epoch [19/40] Iter[184/312]		Loss: 0.1324
2019-10-28 15:36:46,062 Training Epoch [19/40] Iter[185/312]		Loss: 0.1323
2019-10-28 15:36:46,141 Training Epoch [19/40] Iter[186/312]		Loss: 0.1323
2019-10-28 15:36:46,220 Training Epoch [19/40] Iter[187/312]		Loss: 0.1322
2019-10-28 15:36:46,299 Training Epoch [19/40] Iter[188/312]		Loss: 0.1320
2019-10-28 15:36:46,378 Training Epoch [19/40] Iter[189/312]		Loss: 0.1324
2019-10-28 15:36:46,458 Training Epoch [19/40] Iter[190/312]		Loss: 0.1325
2019-10-28 15:36:46,537 Training Epoch [19/40] Iter[191/312]		Loss: 0.1322
2019-10-28 15:36:46,616 Training Epoch [19/40] Iter[192/312]		Loss: 0.1325
2019-10-28 15:36:46,695 Training Epoch [19/40] Iter[193/312]		Loss: 0.1324
2019-10-28 15:36:46,774 Training Epoch [19/40] Iter[194/312]		Loss: 0.1322
2019-10-28 15:36:46,853 Training Epoch [19/40] Iter[195/312]		Loss: 0.1320
2019-10-28 15:36:46,932 Training Epoch [19/40] Iter[196/312]		Loss: 0.1318
2019-10-28 15:36:47,011 Training Epoch [19/40] Iter[197/312]		Loss: 0.1320
2019-10-28 15:36:47,089 Training Epoch [19/40] Iter[198/312]		Loss: 0.1319
2019-10-28 15:36:47,168 Training Epoch [19/40] Iter[199/312]		Loss: 0.1322
2019-10-28 15:36:47,247 Training Epoch [19/40] Iter[200/312]		Loss: 0.1321
2019-10-28 15:36:47,326 Training Epoch [19/40] Iter[201/312]		Loss: 0.1320
2019-10-28 15:36:47,406 Training Epoch [19/40] Iter[202/312]		Loss: 0.1319
2019-10-28 15:36:47,485 Training Epoch [19/40] Iter[203/312]		Loss: 0.1322
2019-10-28 15:36:47,563 Training Epoch [19/40] Iter[204/312]		Loss: 0.1326
2019-10-28 15:36:47,642 Training Epoch [19/40] Iter[205/312]		Loss: 0.1324
2019-10-28 15:36:47,721 Training Epoch [19/40] Iter[206/312]		Loss: 0.1327
2019-10-28 15:36:47,800 Training Epoch [19/40] Iter[207/312]		Loss: 0.1326
2019-10-28 15:36:47,879 Training Epoch [19/40] Iter[208/312]		Loss: 0.1326
2019-10-28 15:36:47,958 Training Epoch [19/40] Iter[209/312]		Loss: 0.1326
2019-10-28 15:36:48,037 Training Epoch [19/40] Iter[210/312]		Loss: 0.1325
2019-10-28 15:36:48,116 Training Epoch [19/40] Iter[211/312]		Loss: 0.1324
2019-10-28 15:36:48,195 Training Epoch [19/40] Iter[212/312]		Loss: 0.1324
2019-10-28 15:36:48,274 Training Epoch [19/40] Iter[213/312]		Loss: 0.1325
2019-10-28 15:36:48,354 Training Epoch [19/40] Iter[214/312]		Loss: 0.1323
2019-10-28 15:36:48,433 Training Epoch [19/40] Iter[215/312]		Loss: 0.1324
2019-10-28 15:36:48,512 Training Epoch [19/40] Iter[216/312]		Loss: 0.1323
2019-10-28 15:36:48,591 Training Epoch [19/40] Iter[217/312]		Loss: 0.1321
2019-10-28 15:36:48,670 Training Epoch [19/40] Iter[218/312]		Loss: 0.1320
2019-10-28 15:36:48,749 Training Epoch [19/40] Iter[219/312]		Loss: 0.1319
2019-10-28 15:36:48,828 Training Epoch [19/40] Iter[220/312]		Loss: 0.1319
2019-10-28 15:36:48,907 Training Epoch [19/40] Iter[221/312]		Loss: 0.1321
2019-10-28 15:36:48,986 Training Epoch [19/40] Iter[222/312]		Loss: 0.1321
2019-10-28 15:36:49,065 Training Epoch [19/40] Iter[223/312]		Loss: 0.1321
2019-10-28 15:36:49,144 Training Epoch [19/40] Iter[224/312]		Loss: 0.1319
2019-10-28 15:36:49,223 Training Epoch [19/40] Iter[225/312]		Loss: 0.1318
2019-10-28 15:36:49,302 Training Epoch [19/40] Iter[226/312]		Loss: 0.1317
2019-10-28 15:36:49,381 Training Epoch [19/40] Iter[227/312]		Loss: 0.1317
2019-10-28 15:36:49,460 Training Epoch [19/40] Iter[228/312]		Loss: 0.1316
2019-10-28 15:36:49,539 Training Epoch [19/40] Iter[229/312]		Loss: 0.1320
2019-10-28 15:36:49,618 Training Epoch [19/40] Iter[230/312]		Loss: 0.1320
2019-10-28 15:36:49,697 Training Epoch [19/40] Iter[231/312]		Loss: 0.1319
2019-10-28 15:36:49,776 Training Epoch [19/40] Iter[232/312]		Loss: 0.1319
2019-10-28 15:36:49,854 Training Epoch [19/40] Iter[233/312]		Loss: 0.1318
2019-10-28 15:36:49,933 Training Epoch [19/40] Iter[234/312]		Loss: 0.1317
2019-10-28 15:36:50,012 Training Epoch [19/40] Iter[235/312]		Loss: 0.1316
2019-10-28 15:36:50,091 Training Epoch [19/40] Iter[236/312]		Loss: 0.1315
2019-10-28 15:36:50,170 Training Epoch [19/40] Iter[237/312]		Loss: 0.1316
2019-10-28 15:36:50,249 Training Epoch [19/40] Iter[238/312]		Loss: 0.1317
2019-10-28 15:36:50,328 Training Epoch [19/40] Iter[239/312]		Loss: 0.1316
2019-10-28 15:36:50,407 Training Epoch [19/40] Iter[240/312]		Loss: 0.1317
2019-10-28 15:36:50,486 Training Epoch [19/40] Iter[241/312]		Loss: 0.1318
2019-10-28 15:36:50,565 Training Epoch [19/40] Iter[242/312]		Loss: 0.1319
2019-10-28 15:36:50,643 Training Epoch [19/40] Iter[243/312]		Loss: 0.1318
2019-10-28 15:36:50,722 Training Epoch [19/40] Iter[244/312]		Loss: 0.1318
2019-10-28 15:36:50,801 Training Epoch [19/40] Iter[245/312]		Loss: 0.1319
2019-10-28 15:36:50,880 Training Epoch [19/40] Iter[246/312]		Loss: 0.1321
2019-10-28 15:36:50,959 Training Epoch [19/40] Iter[247/312]		Loss: 0.1320
2019-10-28 15:36:51,037 Training Epoch [19/40] Iter[248/312]		Loss: 0.1319
2019-10-28 15:36:51,116 Training Epoch [19/40] Iter[249/312]		Loss: 0.1318
2019-10-28 15:36:51,195 Training Epoch [19/40] Iter[250/312]		Loss: 0.1318
2019-10-28 15:36:51,274 Training Epoch [19/40] Iter[251/312]		Loss: 0.1315
2019-10-28 15:36:51,353 Training Epoch [19/40] Iter[252/312]		Loss: 0.1315
2019-10-28 15:36:51,432 Training Epoch [19/40] Iter[253/312]		Loss: 0.1316
2019-10-28 15:36:51,510 Training Epoch [19/40] Iter[254/312]		Loss: 0.1315
2019-10-28 15:36:51,589 Training Epoch [19/40] Iter[255/312]		Loss: 0.1314
2019-10-28 15:36:51,668 Training Epoch [19/40] Iter[256/312]		Loss: 0.1316
2019-10-28 15:36:51,747 Training Epoch [19/40] Iter[257/312]		Loss: 0.1316
2019-10-28 15:36:51,826 Training Epoch [19/40] Iter[258/312]		Loss: 0.1317
2019-10-28 15:36:51,905 Training Epoch [19/40] Iter[259/312]		Loss: 0.1316
2019-10-28 15:36:51,984 Training Epoch [19/40] Iter[260/312]		Loss: 0.1318
2019-10-28 15:36:52,063 Training Epoch [19/40] Iter[261/312]		Loss: 0.1318
2019-10-28 15:36:52,141 Training Epoch [19/40] Iter[262/312]		Loss: 0.1318
2019-10-28 15:36:52,220 Training Epoch [19/40] Iter[263/312]		Loss: 0.1317
2019-10-28 15:36:52,299 Training Epoch [19/40] Iter[264/312]		Loss: 0.1316
2019-10-28 15:36:52,378 Training Epoch [19/40] Iter[265/312]		Loss: 0.1317
2019-10-28 15:36:52,458 Training Epoch [19/40] Iter[266/312]		Loss: 0.1319
2019-10-28 15:36:52,536 Training Epoch [19/40] Iter[267/312]		Loss: 0.1319
2019-10-28 15:36:52,615 Training Epoch [19/40] Iter[268/312]		Loss: 0.1322
2019-10-28 15:36:52,694 Training Epoch [19/40] Iter[269/312]		Loss: 0.1321
2019-10-28 15:36:52,773 Training Epoch [19/40] Iter[270/312]		Loss: 0.1320
2019-10-28 15:36:52,852 Training Epoch [19/40] Iter[271/312]		Loss: 0.1319
2019-10-28 15:36:52,931 Training Epoch [19/40] Iter[272/312]		Loss: 0.1318
2019-10-28 15:36:53,009 Training Epoch [19/40] Iter[273/312]		Loss: 0.1318
2019-10-28 15:36:53,088 Training Epoch [19/40] Iter[274/312]		Loss: 0.1317
2019-10-28 15:36:53,167 Training Epoch [19/40] Iter[275/312]		Loss: 0.1316
2019-10-28 15:36:53,246 Training Epoch [19/40] Iter[276/312]		Loss: 0.1316
2019-10-28 15:36:53,325 Training Epoch [19/40] Iter[277/312]		Loss: 0.1316
2019-10-28 15:36:53,404 Training Epoch [19/40] Iter[278/312]		Loss: 0.1315
2019-10-28 15:36:53,483 Training Epoch [19/40] Iter[279/312]		Loss: 0.1317
2019-10-28 15:36:53,562 Training Epoch [19/40] Iter[280/312]		Loss: 0.1319
2019-10-28 15:36:53,641 Training Epoch [19/40] Iter[281/312]		Loss: 0.1318
2019-10-28 15:36:53,720 Training Epoch [19/40] Iter[282/312]		Loss: 0.1318
2019-10-28 15:36:53,799 Training Epoch [19/40] Iter[283/312]		Loss: 0.1317
2019-10-28 15:36:53,878 Training Epoch [19/40] Iter[284/312]		Loss: 0.1317
2019-10-28 15:36:53,957 Training Epoch [19/40] Iter[285/312]		Loss: 0.1319
2019-10-28 15:36:54,036 Training Epoch [19/40] Iter[286/312]		Loss: 0.1318
2019-10-28 15:36:54,115 Training Epoch [19/40] Iter[287/312]		Loss: 0.1319
2019-10-28 15:36:54,194 Training Epoch [19/40] Iter[288/312]		Loss: 0.1320
2019-10-28 15:36:54,273 Training Epoch [19/40] Iter[289/312]		Loss: 0.1322
2019-10-28 15:36:54,352 Training Epoch [19/40] Iter[290/312]		Loss: 0.1323
2019-10-28 15:36:54,431 Training Epoch [19/40] Iter[291/312]		Loss: 0.1321
2019-10-28 15:36:54,511 Training Epoch [19/40] Iter[292/312]		Loss: 0.1320
2019-10-28 15:36:54,589 Training Epoch [19/40] Iter[293/312]		Loss: 0.1323
2019-10-28 15:36:54,668 Training Epoch [19/40] Iter[294/312]		Loss: 0.1322
2019-10-28 15:36:54,747 Training Epoch [19/40] Iter[295/312]		Loss: 0.1323
2019-10-28 15:36:54,826 Training Epoch [19/40] Iter[296/312]		Loss: 0.1323
2019-10-28 15:36:54,905 Training Epoch [19/40] Iter[297/312]		Loss: 0.1325
2019-10-28 15:36:54,985 Training Epoch [19/40] Iter[298/312]		Loss: 0.1323
2019-10-28 15:36:55,064 Training Epoch [19/40] Iter[299/312]		Loss: 0.1322
2019-10-28 15:36:55,144 Training Epoch [19/40] Iter[300/312]		Loss: 0.1321
2019-10-28 15:36:55,223 Training Epoch [19/40] Iter[301/312]		Loss: 0.1321
2019-10-28 15:36:55,302 Training Epoch [19/40] Iter[302/312]		Loss: 0.1323
2019-10-28 15:36:55,381 Training Epoch [19/40] Iter[303/312]		Loss: 0.1323
2019-10-28 15:36:55,460 Training Epoch [19/40] Iter[304/312]		Loss: 0.1322
2019-10-28 15:36:55,538 Training Epoch [19/40] Iter[305/312]		Loss: 0.1322
2019-10-28 15:36:55,616 Training Epoch [19/40] Iter[306/312]		Loss: 0.1320
2019-10-28 15:36:55,694 Training Epoch [19/40] Iter[307/312]		Loss: 0.1319
2019-10-28 15:36:55,773 Training Epoch [19/40] Iter[308/312]		Loss: 0.1317
2019-10-28 15:36:55,851 Training Epoch [19/40] Iter[309/312]		Loss: 0.1317
2019-10-28 15:36:55,929 Training Epoch [19/40] Iter[310/312]		Loss: 0.1320
2019-10-28 15:36:56,007 Training Epoch [19/40] Iter[311/312]		Loss: 0.1320
2019-10-28 15:36:56,046 Training Epoch [19/40] Iter[312/312]		Loss: 0.1318
2019-10-28 15:36:56,489 Testing Epoch [19/40] Iter[0/62]		Loss: 0.1527
2019-10-28 15:36:56,524 Testing Epoch [19/40] Iter[1/62]		Loss: 0.1462
2019-10-28 15:36:56,540 Testing Epoch [19/40] Iter[2/62]		Loss: 0.1276
2019-10-28 15:36:56,569 Testing Epoch [19/40] Iter[3/62]		Loss: 0.1291
2019-10-28 15:36:56,593 Testing Epoch [19/40] Iter[4/62]		Loss: 0.1299
2019-10-28 15:36:56,617 Testing Epoch [19/40] Iter[5/62]		Loss: 0.1261
2019-10-28 15:36:56,634 Testing Epoch [19/40] Iter[6/62]		Loss: 0.1287
2019-10-28 15:36:56,650 Testing Epoch [19/40] Iter[7/62]		Loss: 0.1315
2019-10-28 15:36:56,681 Testing Epoch [19/40] Iter[8/62]		Loss: 0.1339
2019-10-28 15:36:56,705 Testing Epoch [19/40] Iter[9/62]		Loss: 0.1321
2019-10-28 15:36:56,729 Testing Epoch [19/40] Iter[10/62]		Loss: 0.1322
2019-10-28 15:36:56,747 Testing Epoch [19/40] Iter[11/62]		Loss: 0.1367
2019-10-28 15:36:56,778 Testing Epoch [19/40] Iter[12/62]		Loss: 0.1368
2019-10-28 15:36:56,797 Testing Epoch [19/40] Iter[13/62]		Loss: 0.1376
2019-10-28 15:36:56,821 Testing Epoch [19/40] Iter[14/62]		Loss: 0.1512
2019-10-28 15:36:56,839 Testing Epoch [19/40] Iter[15/62]		Loss: 0.1535
2019-10-28 15:36:56,869 Testing Epoch [19/40] Iter[16/62]		Loss: 0.1508
2019-10-28 15:36:56,889 Testing Epoch [19/40] Iter[17/62]		Loss: 0.1503
2019-10-28 15:36:56,907 Testing Epoch [19/40] Iter[18/62]		Loss: 0.1477
2019-10-28 15:36:56,933 Testing Epoch [19/40] Iter[19/62]		Loss: 0.1452
2019-10-28 15:36:56,951 Testing Epoch [19/40] Iter[20/62]		Loss: 0.1475
2019-10-28 15:36:56,978 Testing Epoch [19/40] Iter[21/62]		Loss: 0.1462
2019-10-28 15:36:57,003 Testing Epoch [19/40] Iter[22/62]		Loss: 0.1477
2019-10-28 15:36:57,027 Testing Epoch [19/40] Iter[23/62]		Loss: 0.1473
2019-10-28 15:36:57,049 Testing Epoch [19/40] Iter[24/62]		Loss: 0.1509
2019-10-28 15:36:57,067 Testing Epoch [19/40] Iter[25/62]		Loss: 0.1503
2019-10-28 15:36:57,085 Testing Epoch [19/40] Iter[26/62]		Loss: 0.1485
2019-10-28 15:36:57,114 Testing Epoch [19/40] Iter[27/62]		Loss: 0.1553
2019-10-28 15:36:57,131 Testing Epoch [19/40] Iter[28/62]		Loss: 0.1587
2019-10-28 15:36:57,149 Testing Epoch [19/40] Iter[29/62]		Loss: 0.1590
2019-10-28 15:36:57,166 Testing Epoch [19/40] Iter[30/62]		Loss: 0.1594
2019-10-28 15:36:57,196 Testing Epoch [19/40] Iter[31/62]		Loss: 0.1586
2019-10-28 15:36:57,214 Testing Epoch [19/40] Iter[32/62]		Loss: 0.1604
2019-10-28 15:36:57,232 Testing Epoch [19/40] Iter[33/62]		Loss: 0.1594
2019-10-28 15:36:57,254 Testing Epoch [19/40] Iter[34/62]		Loss: 0.1616
2019-10-28 15:36:57,285 Testing Epoch [19/40] Iter[35/62]		Loss: 0.1608
2019-10-28 15:36:57,306 Testing Epoch [19/40] Iter[36/62]		Loss: 0.1585
2019-10-28 15:36:57,324 Testing Epoch [19/40] Iter[37/62]		Loss: 0.1573
2019-10-28 15:36:57,343 Testing Epoch [19/40] Iter[38/62]		Loss: 0.1561
2019-10-28 15:36:57,373 Testing Epoch [19/40] Iter[39/62]		Loss: 0.1564
2019-10-28 15:36:57,393 Testing Epoch [19/40] Iter[40/62]		Loss: 0.1582
2019-10-28 15:36:57,411 Testing Epoch [19/40] Iter[41/62]		Loss: 0.1600
2019-10-28 15:36:57,438 Testing Epoch [19/40] Iter[42/62]		Loss: 0.1582
2019-10-28 15:36:57,456 Testing Epoch [19/40] Iter[43/62]		Loss: 0.1577
2019-10-28 15:36:57,481 Testing Epoch [19/40] Iter[44/62]		Loss: 0.1563
2019-10-28 15:36:57,505 Testing Epoch [19/40] Iter[45/62]		Loss: 0.1565
2019-10-28 15:36:57,529 Testing Epoch [19/40] Iter[46/62]		Loss: 0.1559
2019-10-28 15:36:57,555 Testing Epoch [19/40] Iter[47/62]		Loss: 0.1620
2019-10-28 15:36:57,577 Testing Epoch [19/40] Iter[48/62]		Loss: 0.1611
2019-10-28 15:36:57,595 Testing Epoch [19/40] Iter[49/62]		Loss: 0.1639
2019-10-28 15:36:57,613 Testing Epoch [19/40] Iter[50/62]		Loss: 0.1630
2019-10-28 15:36:57,642 Testing Epoch [19/40] Iter[51/62]		Loss: 0.1630
2019-10-28 15:36:57,668 Testing Epoch [19/40] Iter[52/62]		Loss: 0.1618
2019-10-28 15:36:57,685 Testing Epoch [19/40] Iter[53/62]		Loss: 0.1622
2019-10-28 15:36:57,714 Testing Epoch [19/40] Iter[54/62]		Loss: 0.1609
2019-10-28 15:36:57,731 Testing Epoch [19/40] Iter[55/62]		Loss: 0.1605
2019-10-28 15:36:57,747 Testing Epoch [19/40] Iter[56/62]		Loss: 0.1597
2019-10-28 15:36:57,764 Testing Epoch [19/40] Iter[57/62]		Loss: 0.1602
2019-10-28 15:36:57,780 Testing Epoch [19/40] Iter[58/62]		Loss: 0.1593
2019-10-28 15:36:57,797 Testing Epoch [19/40] Iter[59/62]		Loss: 0.1605
2019-10-28 15:36:57,813 Testing Epoch [19/40] Iter[60/62]		Loss: 0.1594
2019-10-28 15:36:57,830 Testing Epoch [19/40] Iter[61/62]		Loss: 0.1597
2019-10-28 15:36:57,839 Testing Epoch [19/40] Iter[62/62]		Loss: 0.1609
2019-10-28 15:36:57,909 Saving the Model
2019-10-28 15:36:58,321 Training Epoch [20/40] Iter[0/312]		Loss: 0.0666
2019-10-28 15:36:58,410 Training Epoch [20/40] Iter[1/312]		Loss: 0.1092
2019-10-28 15:36:58,489 Training Epoch [20/40] Iter[2/312]		Loss: 0.1258
2019-10-28 15:36:58,571 Training Epoch [20/40] Iter[3/312]		Loss: 0.1155
2019-10-28 15:36:58,649 Training Epoch [20/40] Iter[4/312]		Loss: 0.1165
2019-10-28 15:36:58,727 Training Epoch [20/40] Iter[5/312]		Loss: 0.1170
2019-10-28 15:36:58,805 Training Epoch [20/40] Iter[6/312]		Loss: 0.1196
2019-10-28 15:36:58,884 Training Epoch [20/40] Iter[7/312]		Loss: 0.1211
2019-10-28 15:36:58,963 Training Epoch [20/40] Iter[8/312]		Loss: 0.1264
2019-10-28 15:36:59,042 Training Epoch [20/40] Iter[9/312]		Loss: 0.1243
2019-10-28 15:36:59,121 Training Epoch [20/40] Iter[10/312]		Loss: 0.1335
2019-10-28 15:36:59,200 Training Epoch [20/40] Iter[11/312]		Loss: 0.1292
2019-10-28 15:36:59,280 Training Epoch [20/40] Iter[12/312]		Loss: 0.1277
2019-10-28 15:36:59,358 Training Epoch [20/40] Iter[13/312]		Loss: 0.1273
2019-10-28 15:36:59,437 Training Epoch [20/40] Iter[14/312]		Loss: 0.1345
2019-10-28 15:36:59,516 Training Epoch [20/40] Iter[15/312]		Loss: 0.1352
2019-10-28 15:36:59,595 Training Epoch [20/40] Iter[16/312]		Loss: 0.1337
2019-10-28 15:36:59,673 Training Epoch [20/40] Iter[17/312]		Loss: 0.1317
2019-10-28 15:36:59,752 Training Epoch [20/40] Iter[18/312]		Loss: 0.1297
2019-10-28 15:36:59,832 Training Epoch [20/40] Iter[19/312]		Loss: 0.1268
2019-10-28 15:36:59,911 Training Epoch [20/40] Iter[20/312]		Loss: 0.1256
2019-10-28 15:36:59,990 Training Epoch [20/40] Iter[21/312]		Loss: 0.1252
2019-10-28 15:37:00,069 Training Epoch [20/40] Iter[22/312]		Loss: 0.1260
2019-10-28 15:37:00,148 Training Epoch [20/40] Iter[23/312]		Loss: 0.1272
2019-10-28 15:37:00,227 Training Epoch [20/40] Iter[24/312]		Loss: 0.1264
2019-10-28 15:37:00,306 Training Epoch [20/40] Iter[25/312]		Loss: 0.1259
2019-10-28 15:37:00,385 Training Epoch [20/40] Iter[26/312]		Loss: 0.1255
2019-10-28 15:37:00,464 Training Epoch [20/40] Iter[27/312]		Loss: 0.1258
2019-10-28 15:37:00,543 Training Epoch [20/40] Iter[28/312]		Loss: 0.1254
2019-10-28 15:37:00,621 Training Epoch [20/40] Iter[29/312]		Loss: 0.1242
2019-10-28 15:37:00,700 Training Epoch [20/40] Iter[30/312]		Loss: 0.1225
2019-10-28 15:37:00,779 Training Epoch [20/40] Iter[31/312]		Loss: 0.1217
2019-10-28 15:37:00,857 Training Epoch [20/40] Iter[32/312]		Loss: 0.1206
2019-10-28 15:37:00,936 Training Epoch [20/40] Iter[33/312]		Loss: 0.1208
2019-10-28 15:37:01,015 Training Epoch [20/40] Iter[34/312]		Loss: 0.1213
2019-10-28 15:37:01,094 Training Epoch [20/40] Iter[35/312]		Loss: 0.1210
2019-10-28 15:37:01,172 Training Epoch [20/40] Iter[36/312]		Loss: 0.1206
2019-10-28 15:37:01,251 Training Epoch [20/40] Iter[37/312]		Loss: 0.1200
2019-10-28 15:37:01,330 Training Epoch [20/40] Iter[38/312]		Loss: 0.1203
2019-10-28 15:37:01,409 Training Epoch [20/40] Iter[39/312]		Loss: 0.1202
2019-10-28 15:37:01,488 Training Epoch [20/40] Iter[40/312]		Loss: 0.1222
2019-10-28 15:37:01,566 Training Epoch [20/40] Iter[41/312]		Loss: 0.1225
2019-10-28 15:37:01,645 Training Epoch [20/40] Iter[42/312]		Loss: 0.1230
2019-10-28 15:37:01,724 Training Epoch [20/40] Iter[43/312]		Loss: 0.1239
2019-10-28 15:37:01,803 Training Epoch [20/40] Iter[44/312]		Loss: 0.1248
2019-10-28 15:37:01,881 Training Epoch [20/40] Iter[45/312]		Loss: 0.1244
2019-10-28 15:37:01,960 Training Epoch [20/40] Iter[46/312]		Loss: 0.1241
2019-10-28 15:37:02,039 Training Epoch [20/40] Iter[47/312]		Loss: 0.1234
2019-10-28 15:37:02,118 Training Epoch [20/40] Iter[48/312]		Loss: 0.1228
2019-10-28 15:37:02,197 Training Epoch [20/40] Iter[49/312]		Loss: 0.1234
2019-10-28 15:37:02,276 Training Epoch [20/40] Iter[50/312]		Loss: 0.1227
2019-10-28 15:37:02,355 Training Epoch [20/40] Iter[51/312]		Loss: 0.1218
2019-10-28 15:37:02,434 Training Epoch [20/40] Iter[52/312]		Loss: 0.1217
2019-10-28 15:37:02,513 Training Epoch [20/40] Iter[53/312]		Loss: 0.1215
2019-10-28 15:37:02,592 Training Epoch [20/40] Iter[54/312]		Loss: 0.1214
2019-10-28 15:37:02,672 Training Epoch [20/40] Iter[55/312]		Loss: 0.1210
2019-10-28 15:37:02,751 Training Epoch [20/40] Iter[56/312]		Loss: 0.1211
2019-10-28 15:37:02,830 Training Epoch [20/40] Iter[57/312]		Loss: 0.1213
2019-10-28 15:37:02,909 Training Epoch [20/40] Iter[58/312]		Loss: 0.1214
2019-10-28 15:37:02,988 Training Epoch [20/40] Iter[59/312]		Loss: 0.1216
2019-10-28 15:37:03,067 Training Epoch [20/40] Iter[60/312]		Loss: 0.1211
2019-10-28 15:37:03,146 Training Epoch [20/40] Iter[61/312]		Loss: 0.1209
2019-10-28 15:37:03,225 Training Epoch [20/40] Iter[62/312]		Loss: 0.1204
2019-10-28 15:37:03,304 Training Epoch [20/40] Iter[63/312]		Loss: 0.1200
2019-10-28 15:37:03,383 Training Epoch [20/40] Iter[64/312]		Loss: 0.1199
2019-10-28 15:37:03,462 Training Epoch [20/40] Iter[65/312]		Loss: 0.1206
2019-10-28 15:37:03,541 Training Epoch [20/40] Iter[66/312]		Loss: 0.1206
2019-10-28 15:37:03,620 Training Epoch [20/40] Iter[67/312]		Loss: 0.1206
2019-10-28 15:37:03,699 Training Epoch [20/40] Iter[68/312]		Loss: 0.1202
2019-10-28 15:37:03,778 Training Epoch [20/40] Iter[69/312]		Loss: 0.1199
2019-10-28 15:37:03,857 Training Epoch [20/40] Iter[70/312]		Loss: 0.1196
2019-10-28 15:37:03,936 Training Epoch [20/40] Iter[71/312]		Loss: 0.1196
2019-10-28 15:37:04,016 Training Epoch [20/40] Iter[72/312]		Loss: 0.1201
2019-10-28 15:37:04,095 Training Epoch [20/40] Iter[73/312]		Loss: 0.1195
2019-10-28 15:37:04,174 Training Epoch [20/40] Iter[74/312]		Loss: 0.1205
2019-10-28 15:37:04,253 Training Epoch [20/40] Iter[75/312]		Loss: 0.1204
2019-10-28 15:37:04,332 Training Epoch [20/40] Iter[76/312]		Loss: 0.1203
2019-10-28 15:37:04,412 Training Epoch [20/40] Iter[77/312]		Loss: 0.1207
2019-10-28 15:37:04,491 Training Epoch [20/40] Iter[78/312]		Loss: 0.1208
2019-10-28 15:37:04,570 Training Epoch [20/40] Iter[79/312]		Loss: 0.1207
2019-10-28 15:37:04,649 Training Epoch [20/40] Iter[80/312]		Loss: 0.1233
2019-10-28 15:37:04,728 Training Epoch [20/40] Iter[81/312]		Loss: 0.1240
2019-10-28 15:37:04,807 Training Epoch [20/40] Iter[82/312]		Loss: 0.1237
2019-10-28 15:37:04,886 Training Epoch [20/40] Iter[83/312]		Loss: 0.1237
2019-10-28 15:37:04,965 Training Epoch [20/40] Iter[84/312]		Loss: 0.1237
2019-10-28 15:37:05,044 Training Epoch [20/40] Iter[85/312]		Loss: 0.1245
2019-10-28 15:37:05,123 Training Epoch [20/40] Iter[86/312]		Loss: 0.1260
2019-10-28 15:37:05,202 Training Epoch [20/40] Iter[87/312]		Loss: 0.1265
2019-10-28 15:37:05,281 Training Epoch [20/40] Iter[88/312]		Loss: 0.1261
2019-10-28 15:37:05,361 Training Epoch [20/40] Iter[89/312]		Loss: 0.1256
2019-10-28 15:37:05,441 Training Epoch [20/40] Iter[90/312]		Loss: 0.1256
2019-10-28 15:37:05,520 Training Epoch [20/40] Iter[91/312]		Loss: 0.1264
2019-10-28 15:37:05,599 Training Epoch [20/40] Iter[92/312]		Loss: 0.1271
2019-10-28 15:37:05,678 Training Epoch [20/40] Iter[93/312]		Loss: 0.1271
2019-10-28 15:37:05,758 Training Epoch [20/40] Iter[94/312]		Loss: 0.1269
2019-10-28 15:37:05,837 Training Epoch [20/40] Iter[95/312]		Loss: 0.1268
2019-10-28 15:37:05,916 Training Epoch [20/40] Iter[96/312]		Loss: 0.1270
2019-10-28 15:37:05,995 Training Epoch [20/40] Iter[97/312]		Loss: 0.1265
2019-10-28 15:37:06,074 Training Epoch [20/40] Iter[98/312]		Loss: 0.1267
2019-10-28 15:37:06,154 Training Epoch [20/40] Iter[99/312]		Loss: 0.1264
2019-10-28 15:37:06,232 Training Epoch [20/40] Iter[100/312]		Loss: 0.1268
2019-10-28 15:37:06,312 Training Epoch [20/40] Iter[101/312]		Loss: 0.1266
2019-10-28 15:37:06,390 Training Epoch [20/40] Iter[102/312]		Loss: 0.1264
2019-10-28 15:37:06,471 Training Epoch [20/40] Iter[103/312]		Loss: 0.1273
2019-10-28 15:37:06,550 Training Epoch [20/40] Iter[104/312]		Loss: 0.1273
2019-10-28 15:37:06,629 Training Epoch [20/40] Iter[105/312]		Loss: 0.1271
2019-10-28 15:37:06,708 Training Epoch [20/40] Iter[106/312]		Loss: 0.1268
2019-10-28 15:37:06,787 Training Epoch [20/40] Iter[107/312]		Loss: 0.1265
2019-10-28 15:37:06,866 Training Epoch [20/40] Iter[108/312]		Loss: 0.1263
2019-10-28 15:37:06,945 Training Epoch [20/40] Iter[109/312]		Loss: 0.1258
2019-10-28 15:37:07,023 Training Epoch [20/40] Iter[110/312]		Loss: 0.1259
2019-10-28 15:37:07,103 Training Epoch [20/40] Iter[111/312]		Loss: 0.1258
2019-10-28 15:37:07,182 Training Epoch [20/40] Iter[112/312]		Loss: 0.1253
2019-10-28 15:37:07,261 Training Epoch [20/40] Iter[113/312]		Loss: 0.1254
2019-10-28 15:37:07,340 Training Epoch [20/40] Iter[114/312]		Loss: 0.1255
2019-10-28 15:37:07,419 Training Epoch [20/40] Iter[115/312]		Loss: 0.1259
2019-10-28 15:37:07,498 Training Epoch [20/40] Iter[116/312]		Loss: 0.1257
2019-10-28 15:37:07,577 Training Epoch [20/40] Iter[117/312]		Loss: 0.1256
2019-10-28 15:37:07,656 Training Epoch [20/40] Iter[118/312]		Loss: 0.1253
2019-10-28 15:37:07,735 Training Epoch [20/40] Iter[119/312]		Loss: 0.1252
2019-10-28 15:37:07,814 Training Epoch [20/40] Iter[120/312]		Loss: 0.1253
2019-10-28 15:37:07,893 Training Epoch [20/40] Iter[121/312]		Loss: 0.1265
2019-10-28 15:37:07,972 Training Epoch [20/40] Iter[122/312]		Loss: 0.1266
2019-10-28 15:37:08,051 Training Epoch [20/40] Iter[123/312]		Loss: 0.1268
2019-10-28 15:37:08,130 Training Epoch [20/40] Iter[124/312]		Loss: 0.1267
2019-10-28 15:37:08,209 Training Epoch [20/40] Iter[125/312]		Loss: 0.1266
2019-10-28 15:37:08,288 Training Epoch [20/40] Iter[126/312]		Loss: 0.1263
2019-10-28 15:37:08,367 Training Epoch [20/40] Iter[127/312]		Loss: 0.1260
2019-10-28 15:37:08,446 Training Epoch [20/40] Iter[128/312]		Loss: 0.1266
2019-10-28 15:37:08,525 Training Epoch [20/40] Iter[129/312]		Loss: 0.1266
2019-10-28 15:37:08,604 Training Epoch [20/40] Iter[130/312]		Loss: 0.1275
2019-10-28 15:37:08,683 Training Epoch [20/40] Iter[131/312]		Loss: 0.1276
2019-10-28 15:37:08,763 Training Epoch [20/40] Iter[132/312]		Loss: 0.1278
2019-10-28 15:37:08,842 Training Epoch [20/40] Iter[133/312]		Loss: 0.1278
2019-10-28 15:37:08,921 Training Epoch [20/40] Iter[134/312]		Loss: 0.1280
2019-10-28 15:37:08,999 Training Epoch [20/40] Iter[135/312]		Loss: 0.1278
2019-10-28 15:37:09,078 Training Epoch [20/40] Iter[136/312]		Loss: 0.1274
2019-10-28 15:37:09,157 Training Epoch [20/40] Iter[137/312]		Loss: 0.1272
2019-10-28 15:37:09,236 Training Epoch [20/40] Iter[138/312]		Loss: 0.1269
2019-10-28 15:37:09,315 Training Epoch [20/40] Iter[139/312]		Loss: 0.1268
2019-10-28 15:37:09,394 Training Epoch [20/40] Iter[140/312]		Loss: 0.1267
2019-10-28 15:37:09,473 Training Epoch [20/40] Iter[141/312]		Loss: 0.1264
2019-10-28 15:37:09,552 Training Epoch [20/40] Iter[142/312]		Loss: 0.1264
2019-10-28 15:37:09,631 Training Epoch [20/40] Iter[143/312]		Loss: 0.1265
2019-10-28 15:37:09,709 Training Epoch [20/40] Iter[144/312]		Loss: 0.1267
2019-10-28 15:37:09,788 Training Epoch [20/40] Iter[145/312]		Loss: 0.1264
2019-10-28 15:37:09,867 Training Epoch [20/40] Iter[146/312]		Loss: 0.1265
2019-10-28 15:37:09,946 Training Epoch [20/40] Iter[147/312]		Loss: 0.1267
2019-10-28 15:37:10,025 Training Epoch [20/40] Iter[148/312]		Loss: 0.1267
2019-10-28 15:37:10,104 Training Epoch [20/40] Iter[149/312]		Loss: 0.1270
2019-10-28 15:37:10,183 Training Epoch [20/40] Iter[150/312]		Loss: 0.1268
2019-10-28 15:37:10,262 Training Epoch [20/40] Iter[151/312]		Loss: 0.1266
2019-10-28 15:37:10,341 Training Epoch [20/40] Iter[152/312]		Loss: 0.1263
2019-10-28 15:37:10,420 Training Epoch [20/40] Iter[153/312]		Loss: 0.1264
2019-10-28 15:37:10,499 Training Epoch [20/40] Iter[154/312]		Loss: 0.1267
2019-10-28 15:37:10,577 Training Epoch [20/40] Iter[155/312]		Loss: 0.1267
2019-10-28 15:37:10,656 Training Epoch [20/40] Iter[156/312]		Loss: 0.1264
2019-10-28 15:37:10,735 Training Epoch [20/40] Iter[157/312]		Loss: 0.1266
2019-10-28 15:37:10,814 Training Epoch [20/40] Iter[158/312]		Loss: 0.1262
2019-10-28 15:37:10,893 Training Epoch [20/40] Iter[159/312]		Loss: 0.1260
2019-10-28 15:37:10,971 Training Epoch [20/40] Iter[160/312]		Loss: 0.1264
2019-10-28 15:37:11,050 Training Epoch [20/40] Iter[161/312]		Loss: 0.1267
2019-10-28 15:37:11,129 Training Epoch [20/40] Iter[162/312]		Loss: 0.1272
2019-10-28 15:37:11,208 Training Epoch [20/40] Iter[163/312]		Loss: 0.1271
2019-10-28 15:37:11,287 Training Epoch [20/40] Iter[164/312]		Loss: 0.1270
2019-10-28 15:37:11,366 Training Epoch [20/40] Iter[165/312]		Loss: 0.1274
2019-10-28 15:37:11,445 Training Epoch [20/40] Iter[166/312]		Loss: 0.1279
2019-10-28 15:37:11,524 Training Epoch [20/40] Iter[167/312]		Loss: 0.1278
2019-10-28 15:37:11,602 Training Epoch [20/40] Iter[168/312]		Loss: 0.1279
2019-10-28 15:37:11,681 Training Epoch [20/40] Iter[169/312]		Loss: 0.1278
2019-10-28 15:37:11,760 Training Epoch [20/40] Iter[170/312]		Loss: 0.1278
2019-10-28 15:37:11,839 Training Epoch [20/40] Iter[171/312]		Loss: 0.1285
2019-10-28 15:37:11,918 Training Epoch [20/40] Iter[172/312]		Loss: 0.1285
2019-10-28 15:37:11,997 Training Epoch [20/40] Iter[173/312]		Loss: 0.1286
2019-10-28 15:37:12,076 Training Epoch [20/40] Iter[174/312]		Loss: 0.1284
2019-10-28 15:37:12,155 Training Epoch [20/40] Iter[175/312]		Loss: 0.1282
2019-10-28 15:37:12,234 Training Epoch [20/40] Iter[176/312]		Loss: 0.1279
2019-10-28 15:37:12,313 Training Epoch [20/40] Iter[177/312]		Loss: 0.1283
2019-10-28 15:37:12,392 Training Epoch [20/40] Iter[178/312]		Loss: 0.1283
2019-10-28 15:37:12,470 Training Epoch [20/40] Iter[179/312]		Loss: 0.1281
2019-10-28 15:37:12,549 Training Epoch [20/40] Iter[180/312]		Loss: 0.1279
2019-10-28 15:37:12,628 Training Epoch [20/40] Iter[181/312]		Loss: 0.1281
2019-10-28 15:37:12,707 Training Epoch [20/40] Iter[182/312]		Loss: 0.1280
2019-10-28 15:37:12,786 Training Epoch [20/40] Iter[183/312]		Loss: 0.1280
2019-10-28 15:37:12,865 Training Epoch [20/40] Iter[184/312]		Loss: 0.1283
2019-10-28 15:37:12,944 Training Epoch [20/40] Iter[185/312]		Loss: 0.1283
2019-10-28 15:37:13,023 Training Epoch [20/40] Iter[186/312]		Loss: 0.1286
2019-10-28 15:37:13,102 Training Epoch [20/40] Iter[187/312]		Loss: 0.1292
2019-10-28 15:37:13,181 Training Epoch [20/40] Iter[188/312]		Loss: 0.1290
2019-10-28 15:37:13,260 Training Epoch [20/40] Iter[189/312]		Loss: 0.1287
2019-10-28 15:37:13,339 Training Epoch [20/40] Iter[190/312]		Loss: 0.1286
2019-10-28 15:37:13,418 Training Epoch [20/40] Iter[191/312]		Loss: 0.1283
2019-10-28 15:37:13,497 Training Epoch [20/40] Iter[192/312]		Loss: 0.1282
2019-10-28 15:37:13,576 Training Epoch [20/40] Iter[193/312]		Loss: 0.1282
2019-10-28 15:37:13,655 Training Epoch [20/40] Iter[194/312]		Loss: 0.1281
2019-10-28 15:37:13,734 Training Epoch [20/40] Iter[195/312]		Loss: 0.1281
2019-10-28 15:37:13,813 Training Epoch [20/40] Iter[196/312]		Loss: 0.1279
2019-10-28 15:37:13,892 Training Epoch [20/40] Iter[197/312]		Loss: 0.1281
2019-10-28 15:37:13,971 Training Epoch [20/40] Iter[198/312]		Loss: 0.1284
2019-10-28 15:37:14,050 Training Epoch [20/40] Iter[199/312]		Loss: 0.1284
2019-10-28 15:37:14,129 Training Epoch [20/40] Iter[200/312]		Loss: 0.1282
2019-10-28 15:37:14,208 Training Epoch [20/40] Iter[201/312]		Loss: 0.1285
2019-10-28 15:37:14,287 Training Epoch [20/40] Iter[202/312]		Loss: 0.1283
2019-10-28 15:37:14,366 Training Epoch [20/40] Iter[203/312]		Loss: 0.1283
2019-10-28 15:37:14,445 Training Epoch [20/40] Iter[204/312]		Loss: 0.1281
2019-10-28 15:37:14,523 Training Epoch [20/40] Iter[205/312]		Loss: 0.1280
2019-10-28 15:37:14,602 Training Epoch [20/40] Iter[206/312]		Loss: 0.1279
2019-10-28 15:37:14,681 Training Epoch [20/40] Iter[207/312]		Loss: 0.1278
2019-10-28 15:37:14,760 Training Epoch [20/40] Iter[208/312]		Loss: 0.1276
2019-10-28 15:37:14,839 Training Epoch [20/40] Iter[209/312]		Loss: 0.1280
2019-10-28 15:37:14,918 Training Epoch [20/40] Iter[210/312]		Loss: 0.1280
2019-10-28 15:37:14,997 Training Epoch [20/40] Iter[211/312]		Loss: 0.1277
2019-10-28 15:37:15,076 Training Epoch [20/40] Iter[212/312]		Loss: 0.1276
2019-10-28 15:37:15,155 Training Epoch [20/40] Iter[213/312]		Loss: 0.1276
2019-10-28 15:37:15,234 Training Epoch [20/40] Iter[214/312]		Loss: 0.1274
2019-10-28 15:37:15,313 Training Epoch [20/40] Iter[215/312]		Loss: 0.1273
2019-10-28 15:37:15,392 Training Epoch [20/40] Iter[216/312]		Loss: 0.1271
2019-10-28 15:37:15,472 Training Epoch [20/40] Iter[217/312]		Loss: 0.1270
2019-10-28 15:37:15,551 Training Epoch [20/40] Iter[218/312]		Loss: 0.1268
2019-10-28 15:37:15,630 Training Epoch [20/40] Iter[219/312]		Loss: 0.1271
2019-10-28 15:37:15,709 Training Epoch [20/40] Iter[220/312]		Loss: 0.1270
2019-10-28 15:37:15,789 Training Epoch [20/40] Iter[221/312]		Loss: 0.1273
2019-10-28 15:37:15,868 Training Epoch [20/40] Iter[222/312]		Loss: 0.1279
2019-10-28 15:37:15,947 Training Epoch [20/40] Iter[223/312]		Loss: 0.1281
2019-10-28 15:37:16,027 Training Epoch [20/40] Iter[224/312]		Loss: 0.1279
2019-10-28 15:37:16,106 Training Epoch [20/40] Iter[225/312]		Loss: 0.1280
2019-10-28 15:37:16,185 Training Epoch [20/40] Iter[226/312]		Loss: 0.1281
2019-10-28 15:37:16,264 Training Epoch [20/40] Iter[227/312]		Loss: 0.1281
2019-10-28 15:37:16,343 Training Epoch [20/40] Iter[228/312]		Loss: 0.1283
2019-10-28 15:37:16,422 Training Epoch [20/40] Iter[229/312]		Loss: 0.1283
2019-10-28 15:37:16,501 Training Epoch [20/40] Iter[230/312]		Loss: 0.1281
2019-10-28 15:37:16,580 Training Epoch [20/40] Iter[231/312]		Loss: 0.1280
2019-10-28 15:37:16,659 Training Epoch [20/40] Iter[232/312]		Loss: 0.1282
2019-10-28 15:37:16,738 Training Epoch [20/40] Iter[233/312]		Loss: 0.1286
2019-10-28 15:37:16,817 Training Epoch [20/40] Iter[234/312]		Loss: 0.1286
2019-10-28 15:37:16,896 Training Epoch [20/40] Iter[235/312]		Loss: 0.1285
2019-10-28 15:37:16,975 Training Epoch [20/40] Iter[236/312]		Loss: 0.1285
2019-10-28 15:37:17,054 Training Epoch [20/40] Iter[237/312]		Loss: 0.1285
2019-10-28 15:37:17,133 Training Epoch [20/40] Iter[238/312]		Loss: 0.1286
2019-10-28 15:37:17,211 Training Epoch [20/40] Iter[239/312]		Loss: 0.1284
2019-10-28 15:37:17,290 Training Epoch [20/40] Iter[240/312]		Loss: 0.1284
2019-10-28 15:37:17,369 Training Epoch [20/40] Iter[241/312]		Loss: 0.1282
2019-10-28 15:37:17,448 Training Epoch [20/40] Iter[242/312]		Loss: 0.1284
2019-10-28 15:37:17,527 Training Epoch [20/40] Iter[243/312]		Loss: 0.1282
2019-10-28 15:37:17,605 Training Epoch [20/40] Iter[244/312]		Loss: 0.1281
2019-10-28 15:37:17,684 Training Epoch [20/40] Iter[245/312]		Loss: 0.1280
2019-10-28 15:37:17,763 Training Epoch [20/40] Iter[246/312]		Loss: 0.1281
2019-10-28 15:37:17,842 Training Epoch [20/40] Iter[247/312]		Loss: 0.1281
2019-10-28 15:37:17,921 Training Epoch [20/40] Iter[248/312]		Loss: 0.1281
2019-10-28 15:37:17,999 Training Epoch [20/40] Iter[249/312]		Loss: 0.1281
2019-10-28 15:37:18,078 Training Epoch [20/40] Iter[250/312]		Loss: 0.1281
2019-10-28 15:37:18,157 Training Epoch [20/40] Iter[251/312]		Loss: 0.1280
2019-10-28 15:37:18,236 Training Epoch [20/40] Iter[252/312]		Loss: 0.1279
2019-10-28 15:37:18,316 Training Epoch [20/40] Iter[253/312]		Loss: 0.1279
2019-10-28 15:37:18,394 Training Epoch [20/40] Iter[254/312]		Loss: 0.1280
2019-10-28 15:37:18,473 Training Epoch [20/40] Iter[255/312]		Loss: 0.1282
2019-10-28 15:37:18,552 Training Epoch [20/40] Iter[256/312]		Loss: 0.1282
2019-10-28 15:37:18,631 Training Epoch [20/40] Iter[257/312]		Loss: 0.1284
2019-10-28 15:37:18,710 Training Epoch [20/40] Iter[258/312]		Loss: 0.1283
2019-10-28 15:37:18,788 Training Epoch [20/40] Iter[259/312]		Loss: 0.1284
2019-10-28 15:37:18,867 Training Epoch [20/40] Iter[260/312]		Loss: 0.1283
2019-10-28 15:37:18,946 Training Epoch [20/40] Iter[261/312]		Loss: 0.1283
2019-10-28 15:37:19,025 Training Epoch [20/40] Iter[262/312]		Loss: 0.1281
2019-10-28 15:37:19,104 Training Epoch [20/40] Iter[263/312]		Loss: 0.1281
2019-10-28 15:37:19,183 Training Epoch [20/40] Iter[264/312]		Loss: 0.1281
2019-10-28 15:37:19,262 Training Epoch [20/40] Iter[265/312]		Loss: 0.1282
2019-10-28 15:37:19,341 Training Epoch [20/40] Iter[266/312]		Loss: 0.1282
2019-10-28 15:37:19,421 Training Epoch [20/40] Iter[267/312]		Loss: 0.1281
2019-10-28 15:37:19,500 Training Epoch [20/40] Iter[268/312]		Loss: 0.1279
2019-10-28 15:37:19,579 Training Epoch [20/40] Iter[269/312]		Loss: 0.1279
2019-10-28 15:37:19,658 Training Epoch [20/40] Iter[270/312]		Loss: 0.1282
2019-10-28 15:37:19,738 Training Epoch [20/40] Iter[271/312]		Loss: 0.1282
2019-10-28 15:37:19,817 Training Epoch [20/40] Iter[272/312]		Loss: 0.1285
2019-10-28 15:37:19,896 Training Epoch [20/40] Iter[273/312]		Loss: 0.1289
2019-10-28 15:37:19,975 Training Epoch [20/40] Iter[274/312]		Loss: 0.1294
2019-10-28 15:37:20,054 Training Epoch [20/40] Iter[275/312]		Loss: 0.1294
2019-10-28 15:37:20,133 Training Epoch [20/40] Iter[276/312]		Loss: 0.1295
2019-10-28 15:37:20,212 Training Epoch [20/40] Iter[277/312]		Loss: 0.1294
2019-10-28 15:37:20,292 Training Epoch [20/40] Iter[278/312]		Loss: 0.1293
2019-10-28 15:37:20,370 Training Epoch [20/40] Iter[279/312]		Loss: 0.1296
2019-10-28 15:37:20,450 Training Epoch [20/40] Iter[280/312]		Loss: 0.1295
2019-10-28 15:37:20,528 Training Epoch [20/40] Iter[281/312]		Loss: 0.1295
2019-10-28 15:37:20,607 Training Epoch [20/40] Iter[282/312]		Loss: 0.1294
2019-10-28 15:37:20,686 Training Epoch [20/40] Iter[283/312]		Loss: 0.1293
2019-10-28 15:37:20,765 Training Epoch [20/40] Iter[284/312]		Loss: 0.1292
2019-10-28 15:37:20,844 Training Epoch [20/40] Iter[285/312]		Loss: 0.1294
2019-10-28 15:37:20,923 Training Epoch [20/40] Iter[286/312]		Loss: 0.1293
2019-10-28 15:37:21,001 Training Epoch [20/40] Iter[287/312]		Loss: 0.1293
2019-10-28 15:37:21,080 Training Epoch [20/40] Iter[288/312]		Loss: 0.1293
2019-10-28 15:37:21,159 Training Epoch [20/40] Iter[289/312]		Loss: 0.1294
2019-10-28 15:37:21,238 Training Epoch [20/40] Iter[290/312]		Loss: 0.1294
2019-10-28 15:37:21,317 Training Epoch [20/40] Iter[291/312]		Loss: 0.1295
2019-10-28 15:37:21,396 Training Epoch [20/40] Iter[292/312]		Loss: 0.1294
2019-10-28 15:37:21,475 Training Epoch [20/40] Iter[293/312]		Loss: 0.1294
2019-10-28 15:37:21,553 Training Epoch [20/40] Iter[294/312]		Loss: 0.1292
2019-10-28 15:37:21,632 Training Epoch [20/40] Iter[295/312]		Loss: 0.1291
2019-10-28 15:37:21,711 Training Epoch [20/40] Iter[296/312]		Loss: 0.1290
2019-10-28 15:37:21,790 Training Epoch [20/40] Iter[297/312]		Loss: 0.1290
2019-10-28 15:37:21,869 Training Epoch [20/40] Iter[298/312]		Loss: 0.1290
2019-10-28 15:37:21,948 Training Epoch [20/40] Iter[299/312]		Loss: 0.1292
2019-10-28 15:37:22,027 Training Epoch [20/40] Iter[300/312]		Loss: 0.1294
2019-10-28 15:37:22,106 Training Epoch [20/40] Iter[301/312]		Loss: 0.1294
2019-10-28 15:37:22,185 Training Epoch [20/40] Iter[302/312]		Loss: 0.1294
2019-10-28 15:37:22,264 Training Epoch [20/40] Iter[303/312]		Loss: 0.1293
2019-10-28 15:37:22,343 Training Epoch [20/40] Iter[304/312]		Loss: 0.1292
2019-10-28 15:37:22,421 Training Epoch [20/40] Iter[305/312]		Loss: 0.1291
2019-10-28 15:37:22,499 Training Epoch [20/40] Iter[306/312]		Loss: 0.1292
2019-10-28 15:37:22,577 Training Epoch [20/40] Iter[307/312]		Loss: 0.1291
2019-10-28 15:37:22,656 Training Epoch [20/40] Iter[308/312]		Loss: 0.1289
2019-10-28 15:37:22,734 Training Epoch [20/40] Iter[309/312]		Loss: 0.1288
2019-10-28 15:37:22,813 Training Epoch [20/40] Iter[310/312]		Loss: 0.1288
2019-10-28 15:37:22,891 Training Epoch [20/40] Iter[311/312]		Loss: 0.1287
2019-10-28 15:37:22,929 Training Epoch [20/40] Iter[312/312]		Loss: 0.1286
2019-10-28 15:37:23,350 Testing Epoch [20/40] Iter[0/62]		Loss: 0.1411
2019-10-28 15:37:23,390 Testing Epoch [20/40] Iter[1/62]		Loss: 0.1393
2019-10-28 15:37:23,414 Testing Epoch [20/40] Iter[2/62]		Loss: 0.1251
2019-10-28 15:37:23,445 Testing Epoch [20/40] Iter[3/62]		Loss: 0.1278
2019-10-28 15:37:23,469 Testing Epoch [20/40] Iter[4/62]		Loss: 0.1285
2019-10-28 15:37:23,493 Testing Epoch [20/40] Iter[5/62]		Loss: 0.1232
2019-10-28 15:37:23,518 Testing Epoch [20/40] Iter[6/62]		Loss: 0.1247
2019-10-28 15:37:23,537 Testing Epoch [20/40] Iter[7/62]		Loss: 0.1263
2019-10-28 15:37:23,554 Testing Epoch [20/40] Iter[8/62]		Loss: 0.1302
2019-10-28 15:37:23,581 Testing Epoch [20/40] Iter[9/62]		Loss: 0.1285
2019-10-28 15:37:23,605 Testing Epoch [20/40] Iter[10/62]		Loss: 0.1292
2019-10-28 15:37:23,629 Testing Epoch [20/40] Iter[11/62]		Loss: 0.1348
2019-10-28 15:37:23,653 Testing Epoch [20/40] Iter[12/62]		Loss: 0.1345
2019-10-28 15:37:23,677 Testing Epoch [20/40] Iter[13/62]		Loss: 0.1365
2019-10-28 15:37:23,701 Testing Epoch [20/40] Iter[14/62]		Loss: 0.1505
2019-10-28 15:37:23,725 Testing Epoch [20/40] Iter[15/62]		Loss: 0.1534
2019-10-28 15:37:23,749 Testing Epoch [20/40] Iter[16/62]		Loss: 0.1506
2019-10-28 15:37:23,773 Testing Epoch [20/40] Iter[17/62]		Loss: 0.1502
2019-10-28 15:37:23,797 Testing Epoch [20/40] Iter[18/62]		Loss: 0.1475
2019-10-28 15:37:23,821 Testing Epoch [20/40] Iter[19/62]		Loss: 0.1455
2019-10-28 15:37:23,841 Testing Epoch [20/40] Iter[20/62]		Loss: 0.1474
2019-10-28 15:37:23,859 Testing Epoch [20/40] Iter[21/62]		Loss: 0.1460
2019-10-28 15:37:23,876 Testing Epoch [20/40] Iter[22/62]		Loss: 0.1480
2019-10-28 15:37:23,905 Testing Epoch [20/40] Iter[23/62]		Loss: 0.1472
2019-10-28 15:37:23,923 Testing Epoch [20/40] Iter[24/62]		Loss: 0.1509
2019-10-28 15:37:23,941 Testing Epoch [20/40] Iter[25/62]		Loss: 0.1497
2019-10-28 15:37:23,958 Testing Epoch [20/40] Iter[26/62]		Loss: 0.1482
2019-10-28 15:37:23,995 Testing Epoch [20/40] Iter[27/62]		Loss: 0.1569
2019-10-28 15:37:24,021 Testing Epoch [20/40] Iter[28/62]		Loss: 0.1602
2019-10-28 15:37:24,045 Testing Epoch [20/40] Iter[29/62]		Loss: 0.1600
2019-10-28 15:37:24,069 Testing Epoch [20/40] Iter[30/62]		Loss: 0.1602
2019-10-28 15:37:24,096 Testing Epoch [20/40] Iter[31/62]		Loss: 0.1591
2019-10-28 15:37:24,113 Testing Epoch [20/40] Iter[32/62]		Loss: 0.1609
2019-10-28 15:37:24,131 Testing Epoch [20/40] Iter[33/62]		Loss: 0.1597
2019-10-28 15:37:24,158 Testing Epoch [20/40] Iter[34/62]		Loss: 0.1619
2019-10-28 15:37:24,176 Testing Epoch [20/40] Iter[35/62]		Loss: 0.1613
2019-10-28 15:37:24,196 Testing Epoch [20/40] Iter[36/62]		Loss: 0.1592
2019-10-28 15:37:24,213 Testing Epoch [20/40] Iter[37/62]		Loss: 0.1580
2019-10-28 15:37:24,237 Testing Epoch [20/40] Iter[38/62]		Loss: 0.1569
2019-10-28 15:37:24,261 Testing Epoch [20/40] Iter[39/62]		Loss: 0.1573
2019-10-28 15:37:24,279 Testing Epoch [20/40] Iter[40/62]		Loss: 0.1590
2019-10-28 15:37:24,298 Testing Epoch [20/40] Iter[41/62]		Loss: 0.1607
2019-10-28 15:37:24,315 Testing Epoch [20/40] Iter[42/62]		Loss: 0.1589
2019-10-28 15:37:24,339 Testing Epoch [20/40] Iter[43/62]		Loss: 0.1580
2019-10-28 15:37:24,357 Testing Epoch [20/40] Iter[44/62]		Loss: 0.1565
2019-10-28 15:37:24,378 Testing Epoch [20/40] Iter[45/62]		Loss: 0.1565
2019-10-28 15:37:24,402 Testing Epoch [20/40] Iter[46/62]		Loss: 0.1566
2019-10-28 15:37:24,423 Testing Epoch [20/40] Iter[47/62]		Loss: 0.1625
2019-10-28 15:37:24,453 Testing Epoch [20/40] Iter[48/62]		Loss: 0.1617
2019-10-28 15:37:24,472 Testing Epoch [20/40] Iter[49/62]		Loss: 0.1643
2019-10-28 15:37:24,497 Testing Epoch [20/40] Iter[50/62]		Loss: 0.1634
2019-10-28 15:37:24,523 Testing Epoch [20/40] Iter[51/62]		Loss: 0.1635
2019-10-28 15:37:24,540 Testing Epoch [20/40] Iter[52/62]		Loss: 0.1623
2019-10-28 15:37:24,558 Testing Epoch [20/40] Iter[53/62]		Loss: 0.1627
2019-10-28 15:37:24,589 Testing Epoch [20/40] Iter[54/62]		Loss: 0.1614
2019-10-28 15:37:24,606 Testing Epoch [20/40] Iter[55/62]		Loss: 0.1612
2019-10-28 15:37:24,622 Testing Epoch [20/40] Iter[56/62]		Loss: 0.1604
2019-10-28 15:37:24,638 Testing Epoch [20/40] Iter[57/62]		Loss: 0.1607
2019-10-28 15:37:24,655 Testing Epoch [20/40] Iter[58/62]		Loss: 0.1599
2019-10-28 15:37:24,671 Testing Epoch [20/40] Iter[59/62]		Loss: 0.1610
2019-10-28 15:37:24,688 Testing Epoch [20/40] Iter[60/62]		Loss: 0.1600
2019-10-28 15:37:24,705 Testing Epoch [20/40] Iter[61/62]		Loss: 0.1601
2019-10-28 15:37:24,714 Testing Epoch [20/40] Iter[62/62]		Loss: 0.1610
2019-10-28 15:37:25,102 Training Epoch [21/40] Iter[0/312]		Loss: 0.1075
2019-10-28 15:37:25,258 Training Epoch [21/40] Iter[1/312]		Loss: 0.1134
2019-10-28 15:37:25,336 Training Epoch [21/40] Iter[2/312]		Loss: 0.1620
2019-10-28 15:37:25,414 Training Epoch [21/40] Iter[3/312]		Loss: 0.1561
2019-10-28 15:37:25,494 Training Epoch [21/40] Iter[4/312]		Loss: 0.1485
2019-10-28 15:37:25,578 Training Epoch [21/40] Iter[5/312]		Loss: 0.1463
2019-10-28 15:37:25,656 Training Epoch [21/40] Iter[6/312]		Loss: 0.1411
2019-10-28 15:37:25,734 Training Epoch [21/40] Iter[7/312]		Loss: 0.1400
2019-10-28 15:37:25,812 Training Epoch [21/40] Iter[8/312]		Loss: 0.1343
2019-10-28 15:37:25,890 Training Epoch [21/40] Iter[9/312]		Loss: 0.1304
2019-10-28 15:37:25,969 Training Epoch [21/40] Iter[10/312]		Loss: 0.1323
2019-10-28 15:37:26,048 Training Epoch [21/40] Iter[11/312]		Loss: 0.1302
2019-10-28 15:37:26,127 Training Epoch [21/40] Iter[12/312]		Loss: 0.1271
2019-10-28 15:37:26,206 Training Epoch [21/40] Iter[13/312]		Loss: 0.1251
2019-10-28 15:37:26,285 Training Epoch [21/40] Iter[14/312]		Loss: 0.1239
2019-10-28 15:37:26,363 Training Epoch [21/40] Iter[15/312]		Loss: 0.1240
2019-10-28 15:37:26,443 Training Epoch [21/40] Iter[16/312]		Loss: 0.1233
2019-10-28 15:37:26,522 Training Epoch [21/40] Iter[17/312]		Loss: 0.1291
2019-10-28 15:37:26,601 Training Epoch [21/40] Iter[18/312]		Loss: 0.1287
2019-10-28 15:37:26,680 Training Epoch [21/40] Iter[19/312]		Loss: 0.1286
2019-10-28 15:37:26,764 Training Epoch [21/40] Iter[20/312]		Loss: 0.1285
2019-10-28 15:37:26,842 Training Epoch [21/40] Iter[21/312]		Loss: 0.1314
2019-10-28 15:37:26,921 Training Epoch [21/40] Iter[22/312]		Loss: 0.1291
2019-10-28 15:37:27,000 Training Epoch [21/40] Iter[23/312]		Loss: 0.1282
2019-10-28 15:37:27,079 Training Epoch [21/40] Iter[24/312]		Loss: 0.1276
2019-10-28 15:37:27,158 Training Epoch [21/40] Iter[25/312]		Loss: 0.1281
2019-10-28 15:37:27,237 Training Epoch [21/40] Iter[26/312]		Loss: 0.1280
2019-10-28 15:37:27,316 Training Epoch [21/40] Iter[27/312]		Loss: 0.1278
2019-10-28 15:37:27,395 Training Epoch [21/40] Iter[28/312]		Loss: 0.1293
2019-10-28 15:37:27,474 Training Epoch [21/40] Iter[29/312]		Loss: 0.1279
2019-10-28 15:37:27,553 Training Epoch [21/40] Iter[30/312]		Loss: 0.1268
2019-10-28 15:37:27,631 Training Epoch [21/40] Iter[31/312]		Loss: 0.1266
2019-10-28 15:37:27,710 Training Epoch [21/40] Iter[32/312]		Loss: 0.1279
2019-10-28 15:37:27,789 Training Epoch [21/40] Iter[33/312]		Loss: 0.1279
2019-10-28 15:37:27,868 Training Epoch [21/40] Iter[34/312]		Loss: 0.1268
2019-10-28 15:37:27,947 Training Epoch [21/40] Iter[35/312]		Loss: 0.1256
2019-10-28 15:37:28,025 Training Epoch [21/40] Iter[36/312]		Loss: 0.1252
2019-10-28 15:37:28,104 Training Epoch [21/40] Iter[37/312]		Loss: 0.1247
2019-10-28 15:37:28,183 Training Epoch [21/40] Iter[38/312]		Loss: 0.1252
2019-10-28 15:37:28,262 Training Epoch [21/40] Iter[39/312]		Loss: 0.1244
2019-10-28 15:37:28,341 Training Epoch [21/40] Iter[40/312]		Loss: 0.1242
2019-10-28 15:37:28,420 Training Epoch [21/40] Iter[41/312]		Loss: 0.1237
2019-10-28 15:37:28,499 Training Epoch [21/40] Iter[42/312]		Loss: 0.1225
2019-10-28 15:37:28,578 Training Epoch [21/40] Iter[43/312]		Loss: 0.1242
2019-10-28 15:37:28,656 Training Epoch [21/40] Iter[44/312]		Loss: 0.1232
2019-10-28 15:37:28,735 Training Epoch [21/40] Iter[45/312]		Loss: 0.1235
2019-10-28 15:37:28,814 Training Epoch [21/40] Iter[46/312]		Loss: 0.1224
2019-10-28 15:37:28,893 Training Epoch [21/40] Iter[47/312]		Loss: 0.1214
2019-10-28 15:37:28,972 Training Epoch [21/40] Iter[48/312]		Loss: 0.1207
2019-10-28 15:37:29,050 Training Epoch [21/40] Iter[49/312]		Loss: 0.1202
2019-10-28 15:37:29,129 Training Epoch [21/40] Iter[50/312]		Loss: 0.1199
2019-10-28 15:37:29,209 Training Epoch [21/40] Iter[51/312]		Loss: 0.1213
2019-10-28 15:37:29,288 Training Epoch [21/40] Iter[52/312]		Loss: 0.1213
2019-10-28 15:37:29,367 Training Epoch [21/40] Iter[53/312]		Loss: 0.1214
2019-10-28 15:37:29,445 Training Epoch [21/40] Iter[54/312]		Loss: 0.1220
2019-10-28 15:37:29,524 Training Epoch [21/40] Iter[55/312]		Loss: 0.1222
2019-10-28 15:37:29,603 Training Epoch [21/40] Iter[56/312]		Loss: 0.1217
2019-10-28 15:37:29,682 Training Epoch [21/40] Iter[57/312]		Loss: 0.1209
2019-10-28 15:37:29,761 Training Epoch [21/40] Iter[58/312]		Loss: 0.1218
2019-10-28 15:37:29,840 Training Epoch [21/40] Iter[59/312]		Loss: 0.1211
2019-10-28 15:37:29,919 Training Epoch [21/40] Iter[60/312]		Loss: 0.1205
2019-10-28 15:37:29,997 Training Epoch [21/40] Iter[61/312]		Loss: 0.1203
2019-10-28 15:37:30,076 Training Epoch [21/40] Iter[62/312]		Loss: 0.1208
2019-10-28 15:37:30,156 Training Epoch [21/40] Iter[63/312]		Loss: 0.1209
2019-10-28 15:37:30,235 Training Epoch [21/40] Iter[64/312]		Loss: 0.1202
2019-10-28 15:37:30,314 Training Epoch [21/40] Iter[65/312]		Loss: 0.1209
2019-10-28 15:37:30,392 Training Epoch [21/40] Iter[66/312]		Loss: 0.1202
2019-10-28 15:37:30,471 Training Epoch [21/40] Iter[67/312]		Loss: 0.1204
2019-10-28 15:37:30,550 Training Epoch [21/40] Iter[68/312]		Loss: 0.1200
2019-10-28 15:37:30,629 Training Epoch [21/40] Iter[69/312]		Loss: 0.1204
2019-10-28 15:37:30,708 Training Epoch [21/40] Iter[70/312]		Loss: 0.1211
2019-10-28 15:37:30,787 Training Epoch [21/40] Iter[71/312]		Loss: 0.1211
2019-10-28 15:37:30,866 Training Epoch [21/40] Iter[72/312]		Loss: 0.1208
2019-10-28 15:37:30,945 Training Epoch [21/40] Iter[73/312]		Loss: 0.1212
2019-10-28 15:37:31,024 Training Epoch [21/40] Iter[74/312]		Loss: 0.1210
2019-10-28 15:37:31,102 Training Epoch [21/40] Iter[75/312]		Loss: 0.1215
2019-10-28 15:37:31,181 Training Epoch [21/40] Iter[76/312]		Loss: 0.1222
2019-10-28 15:37:31,260 Training Epoch [21/40] Iter[77/312]		Loss: 0.1218
2019-10-28 15:37:31,339 Training Epoch [21/40] Iter[78/312]		Loss: 0.1216
2019-10-28 15:37:31,418 Training Epoch [21/40] Iter[79/312]		Loss: 0.1218
2019-10-28 15:37:31,497 Training Epoch [21/40] Iter[80/312]		Loss: 0.1220
2019-10-28 15:37:31,576 Training Epoch [21/40] Iter[81/312]		Loss: 0.1215
2019-10-28 15:37:31,655 Training Epoch [21/40] Iter[82/312]		Loss: 0.1215
2019-10-28 15:37:31,734 Training Epoch [21/40] Iter[83/312]		Loss: 0.1219
2019-10-28 15:37:31,813 Training Epoch [21/40] Iter[84/312]		Loss: 0.1219
2019-10-28 15:37:31,892 Training Epoch [21/40] Iter[85/312]		Loss: 0.1215
2019-10-28 15:37:31,971 Training Epoch [21/40] Iter[86/312]		Loss: 0.1220
2019-10-28 15:37:32,049 Training Epoch [21/40] Iter[87/312]		Loss: 0.1212
2019-10-28 15:37:32,128 Training Epoch [21/40] Iter[88/312]		Loss: 0.1224
2019-10-28 15:37:32,207 Training Epoch [21/40] Iter[89/312]		Loss: 0.1227
2019-10-28 15:37:32,286 Training Epoch [21/40] Iter[90/312]		Loss: 0.1221
2019-10-28 15:37:32,365 Training Epoch [21/40] Iter[91/312]		Loss: 0.1219
2019-10-28 15:37:32,444 Training Epoch [21/40] Iter[92/312]		Loss: 0.1223
2019-10-28 15:37:32,523 Training Epoch [21/40] Iter[93/312]		Loss: 0.1232
2019-10-28 15:37:32,602 Training Epoch [21/40] Iter[94/312]		Loss: 0.1229
2019-10-28 15:37:32,681 Training Epoch [21/40] Iter[95/312]		Loss: 0.1236
2019-10-28 15:37:32,760 Training Epoch [21/40] Iter[96/312]		Loss: 0.1236
2019-10-28 15:37:32,839 Training Epoch [21/40] Iter[97/312]		Loss: 0.1234
2019-10-28 15:37:32,917 Training Epoch [21/40] Iter[98/312]		Loss: 0.1232
2019-10-28 15:37:32,996 Training Epoch [21/40] Iter[99/312]		Loss: 0.1227
2019-10-28 15:37:33,075 Training Epoch [21/40] Iter[100/312]		Loss: 0.1226
2019-10-28 15:37:33,154 Training Epoch [21/40] Iter[101/312]		Loss: 0.1226
2019-10-28 15:37:33,233 Training Epoch [21/40] Iter[102/312]		Loss: 0.1221
2019-10-28 15:37:33,312 Training Epoch [21/40] Iter[103/312]		Loss: 0.1218
2019-10-28 15:37:33,391 Training Epoch [21/40] Iter[104/312]		Loss: 0.1217
2019-10-28 15:37:33,470 Training Epoch [21/40] Iter[105/312]		Loss: 0.1211
2019-10-28 15:37:33,549 Training Epoch [21/40] Iter[106/312]		Loss: 0.1209
2019-10-28 15:37:33,628 Training Epoch [21/40] Iter[107/312]		Loss: 0.1210
2019-10-28 15:37:33,707 Training Epoch [21/40] Iter[108/312]		Loss: 0.1210
2019-10-28 15:37:33,786 Training Epoch [21/40] Iter[109/312]		Loss: 0.1204
2019-10-28 15:37:33,865 Training Epoch [21/40] Iter[110/312]		Loss: 0.1203
2019-10-28 15:37:33,944 Training Epoch [21/40] Iter[111/312]		Loss: 0.1204
2019-10-28 15:37:34,023 Training Epoch [21/40] Iter[112/312]		Loss: 0.1201
2019-10-28 15:37:34,102 Training Epoch [21/40] Iter[113/312]		Loss: 0.1205
2019-10-28 15:37:34,181 Training Epoch [21/40] Iter[114/312]		Loss: 0.1202
2019-10-28 15:37:34,259 Training Epoch [21/40] Iter[115/312]		Loss: 0.1198
2019-10-28 15:37:34,339 Training Epoch [21/40] Iter[116/312]		Loss: 0.1198
2019-10-28 15:37:34,418 Training Epoch [21/40] Iter[117/312]		Loss: 0.1196
2019-10-28 15:37:34,497 Training Epoch [21/40] Iter[118/312]		Loss: 0.1194
2019-10-28 15:37:34,576 Training Epoch [21/40] Iter[119/312]		Loss: 0.1201
2019-10-28 15:37:34,655 Training Epoch [21/40] Iter[120/312]		Loss: 0.1199
2019-10-28 15:37:34,734 Training Epoch [21/40] Iter[121/312]		Loss: 0.1196
2019-10-28 15:37:34,813 Training Epoch [21/40] Iter[122/312]		Loss: 0.1194
2019-10-28 15:37:34,892 Training Epoch [21/40] Iter[123/312]		Loss: 0.1192
2019-10-28 15:37:34,971 Training Epoch [21/40] Iter[124/312]		Loss: 0.1191
2019-10-28 15:37:35,050 Training Epoch [21/40] Iter[125/312]		Loss: 0.1190
2019-10-28 15:37:35,129 Training Epoch [21/40] Iter[126/312]		Loss: 0.1190
2019-10-28 15:37:35,209 Training Epoch [21/40] Iter[127/312]		Loss: 0.1189
2019-10-28 15:37:35,289 Training Epoch [21/40] Iter[128/312]		Loss: 0.1187
2019-10-28 15:37:35,368 Training Epoch [21/40] Iter[129/312]		Loss: 0.1185
2019-10-28 15:37:35,447 Training Epoch [21/40] Iter[130/312]		Loss: 0.1181
2019-10-28 15:37:35,526 Training Epoch [21/40] Iter[131/312]		Loss: 0.1179
2019-10-28 15:37:35,605 Training Epoch [21/40] Iter[132/312]		Loss: 0.1180
2019-10-28 15:37:35,684 Training Epoch [21/40] Iter[133/312]		Loss: 0.1176
2019-10-28 15:37:35,763 Training Epoch [21/40] Iter[134/312]		Loss: 0.1177
2019-10-28 15:37:35,842 Training Epoch [21/40] Iter[135/312]		Loss: 0.1180
2019-10-28 15:37:35,922 Training Epoch [21/40] Iter[136/312]		Loss: 0.1184
2019-10-28 15:37:36,001 Training Epoch [21/40] Iter[137/312]		Loss: 0.1184
2019-10-28 15:37:36,080 Training Epoch [21/40] Iter[138/312]		Loss: 0.1180
2019-10-28 15:37:36,159 Training Epoch [21/40] Iter[139/312]		Loss: 0.1180
2019-10-28 15:37:36,238 Training Epoch [21/40] Iter[140/312]		Loss: 0.1179
2019-10-28 15:37:36,317 Training Epoch [21/40] Iter[141/312]		Loss: 0.1179
2019-10-28 15:37:36,396 Training Epoch [21/40] Iter[142/312]		Loss: 0.1180
2019-10-28 15:37:36,475 Training Epoch [21/40] Iter[143/312]		Loss: 0.1178
2019-10-28 15:37:36,554 Training Epoch [21/40] Iter[144/312]		Loss: 0.1182
2019-10-28 15:37:36,633 Training Epoch [21/40] Iter[145/312]		Loss: 0.1179
2019-10-28 15:37:36,712 Training Epoch [21/40] Iter[146/312]		Loss: 0.1179
2019-10-28 15:37:36,791 Training Epoch [21/40] Iter[147/312]		Loss: 0.1176
2019-10-28 15:37:36,870 Training Epoch [21/40] Iter[148/312]		Loss: 0.1175
2019-10-28 15:37:36,949 Training Epoch [21/40] Iter[149/312]		Loss: 0.1173
2019-10-28 15:37:37,028 Training Epoch [21/40] Iter[150/312]		Loss: 0.1170
2019-10-28 15:37:37,107 Training Epoch [21/40] Iter[151/312]		Loss: 0.1173
2019-10-28 15:37:37,186 Training Epoch [21/40] Iter[152/312]		Loss: 0.1175
2019-10-28 15:37:37,266 Training Epoch [21/40] Iter[153/312]		Loss: 0.1173
2019-10-28 15:37:37,345 Training Epoch [21/40] Iter[154/312]		Loss: 0.1171
2019-10-28 15:37:37,424 Training Epoch [21/40] Iter[155/312]		Loss: 0.1170
2019-10-28 15:37:37,503 Training Epoch [21/40] Iter[156/312]		Loss: 0.1169
2019-10-28 15:37:37,581 Training Epoch [21/40] Iter[157/312]		Loss: 0.1170
2019-10-28 15:37:37,660 Training Epoch [21/40] Iter[158/312]		Loss: 0.1168
2019-10-28 15:37:37,739 Training Epoch [21/40] Iter[159/312]		Loss: 0.1169
2019-10-28 15:37:37,818 Training Epoch [21/40] Iter[160/312]		Loss: 0.1166
2019-10-28 15:37:37,897 Training Epoch [21/40] Iter[161/312]		Loss: 0.1166
2019-10-28 15:37:37,976 Training Epoch [21/40] Iter[162/312]		Loss: 0.1168
2019-10-28 15:37:38,055 Training Epoch [21/40] Iter[163/312]		Loss: 0.1166
2019-10-28 15:37:38,134 Training Epoch [21/40] Iter[164/312]		Loss: 0.1166
2019-10-28 15:37:38,213 Training Epoch [21/40] Iter[165/312]		Loss: 0.1164
2019-10-28 15:37:38,292 Training Epoch [21/40] Iter[166/312]		Loss: 0.1169
2019-10-28 15:37:38,371 Training Epoch [21/40] Iter[167/312]		Loss: 0.1167
2019-10-28 15:37:38,450 Training Epoch [21/40] Iter[168/312]		Loss: 0.1170
2019-10-28 15:37:38,529 Training Epoch [21/40] Iter[169/312]		Loss: 0.1169
2019-10-28 15:37:38,608 Training Epoch [21/40] Iter[170/312]		Loss: 0.1167
2019-10-28 15:37:38,687 Training Epoch [21/40] Iter[171/312]		Loss: 0.1168
2019-10-28 15:37:38,766 Training Epoch [21/40] Iter[172/312]		Loss: 0.1165
2019-10-28 15:37:38,845 Training Epoch [21/40] Iter[173/312]		Loss: 0.1168
2019-10-28 15:37:38,923 Training Epoch [21/40] Iter[174/312]		Loss: 0.1167
2019-10-28 15:37:39,002 Training Epoch [21/40] Iter[175/312]		Loss: 0.1167
2019-10-28 15:37:39,081 Training Epoch [21/40] Iter[176/312]		Loss: 0.1165
2019-10-28 15:37:39,160 Training Epoch [21/40] Iter[177/312]		Loss: 0.1163
2019-10-28 15:37:39,239 Training Epoch [21/40] Iter[178/312]		Loss: 0.1163
2019-10-28 15:37:39,318 Training Epoch [21/40] Iter[179/312]		Loss: 0.1161
2019-10-28 15:37:39,397 Training Epoch [21/40] Iter[180/312]		Loss: 0.1162
2019-10-28 15:37:39,476 Training Epoch [21/40] Iter[181/312]		Loss: 0.1162
2019-10-28 15:37:39,555 Training Epoch [21/40] Iter[182/312]		Loss: 0.1161
2019-10-28 15:37:39,634 Training Epoch [21/40] Iter[183/312]		Loss: 0.1161
2019-10-28 15:37:39,712 Training Epoch [21/40] Iter[184/312]		Loss: 0.1163
2019-10-28 15:37:39,791 Training Epoch [21/40] Iter[185/312]		Loss: 0.1162
2019-10-28 15:37:39,870 Training Epoch [21/40] Iter[186/312]		Loss: 0.1164
2019-10-28 15:37:39,949 Training Epoch [21/40] Iter[187/312]		Loss: 0.1164
2019-10-28 15:37:40,028 Training Epoch [21/40] Iter[188/312]		Loss: 0.1164
2019-10-28 15:37:40,106 Training Epoch [21/40] Iter[189/312]		Loss: 0.1162
2019-10-28 15:37:40,186 Training Epoch [21/40] Iter[190/312]		Loss: 0.1161
2019-10-28 15:37:40,264 Training Epoch [21/40] Iter[191/312]		Loss: 0.1161
2019-10-28 15:37:40,343 Training Epoch [21/40] Iter[192/312]		Loss: 0.1160
2019-10-28 15:37:40,422 Training Epoch [21/40] Iter[193/312]		Loss: 0.1159
2019-10-28 15:37:40,501 Training Epoch [21/40] Iter[194/312]		Loss: 0.1157
2019-10-28 15:37:40,580 Training Epoch [21/40] Iter[195/312]		Loss: 0.1160
2019-10-28 15:37:40,659 Training Epoch [21/40] Iter[196/312]		Loss: 0.1160
2019-10-28 15:37:40,738 Training Epoch [21/40] Iter[197/312]		Loss: 0.1159
2019-10-28 15:37:40,817 Training Epoch [21/40] Iter[198/312]		Loss: 0.1157
2019-10-28 15:37:40,896 Training Epoch [21/40] Iter[199/312]		Loss: 0.1156
2019-10-28 15:37:40,975 Training Epoch [21/40] Iter[200/312]		Loss: 0.1155
2019-10-28 15:37:41,054 Training Epoch [21/40] Iter[201/312]		Loss: 0.1154
2019-10-28 15:37:41,133 Training Epoch [21/40] Iter[202/312]		Loss: 0.1152
2019-10-28 15:37:41,212 Training Epoch [21/40] Iter[203/312]		Loss: 0.1151
2019-10-28 15:37:41,291 Training Epoch [21/40] Iter[204/312]		Loss: 0.1149
2019-10-28 15:37:41,370 Training Epoch [21/40] Iter[205/312]		Loss: 0.1153
2019-10-28 15:37:41,449 Training Epoch [21/40] Iter[206/312]		Loss: 0.1152
2019-10-28 15:37:41,528 Training Epoch [21/40] Iter[207/312]		Loss: 0.1153
2019-10-28 15:37:41,607 Training Epoch [21/40] Iter[208/312]		Loss: 0.1153
2019-10-28 15:37:41,686 Training Epoch [21/40] Iter[209/312]		Loss: 0.1150
2019-10-28 15:37:41,764 Training Epoch [21/40] Iter[210/312]		Loss: 0.1149
2019-10-28 15:37:41,843 Training Epoch [21/40] Iter[211/312]		Loss: 0.1149
2019-10-28 15:37:41,922 Training Epoch [21/40] Iter[212/312]		Loss: 0.1147
2019-10-28 15:37:42,001 Training Epoch [21/40] Iter[213/312]		Loss: 0.1151
2019-10-28 15:37:42,080 Training Epoch [21/40] Iter[214/312]		Loss: 0.1150
2019-10-28 15:37:42,158 Training Epoch [21/40] Iter[215/312]		Loss: 0.1153
2019-10-28 15:37:42,237 Training Epoch [21/40] Iter[216/312]		Loss: 0.1156
2019-10-28 15:37:42,316 Training Epoch [21/40] Iter[217/312]		Loss: 0.1159
2019-10-28 15:37:42,395 Training Epoch [21/40] Iter[218/312]		Loss: 0.1161
2019-10-28 15:37:42,474 Training Epoch [21/40] Iter[219/312]		Loss: 0.1163
2019-10-28 15:37:42,553 Training Epoch [21/40] Iter[220/312]		Loss: 0.1163
2019-10-28 15:37:42,632 Training Epoch [21/40] Iter[221/312]		Loss: 0.1162
2019-10-28 15:37:42,711 Training Epoch [21/40] Iter[222/312]		Loss: 0.1161
2019-10-28 15:37:42,789 Training Epoch [21/40] Iter[223/312]		Loss: 0.1162
2019-10-28 15:37:42,868 Training Epoch [21/40] Iter[224/312]		Loss: 0.1166
2019-10-28 15:37:42,947 Training Epoch [21/40] Iter[225/312]		Loss: 0.1165
2019-10-28 15:37:43,026 Training Epoch [21/40] Iter[226/312]		Loss: 0.1164
2019-10-28 15:37:43,105 Training Epoch [21/40] Iter[227/312]		Loss: 0.1164
2019-10-28 15:37:43,184 Training Epoch [21/40] Iter[228/312]		Loss: 0.1164
2019-10-28 15:37:43,263 Training Epoch [21/40] Iter[229/312]		Loss: 0.1162
2019-10-28 15:37:43,342 Training Epoch [21/40] Iter[230/312]		Loss: 0.1166
2019-10-28 15:37:43,421 Training Epoch [21/40] Iter[231/312]		Loss: 0.1166
2019-10-28 15:37:43,500 Training Epoch [21/40] Iter[232/312]		Loss: 0.1165
2019-10-28 15:37:43,580 Training Epoch [21/40] Iter[233/312]		Loss: 0.1164
2019-10-28 15:37:43,659 Training Epoch [21/40] Iter[234/312]		Loss: 0.1168
2019-10-28 15:37:43,738 Training Epoch [21/40] Iter[235/312]		Loss: 0.1168
2019-10-28 15:37:43,817 Training Epoch [21/40] Iter[236/312]		Loss: 0.1167
2019-10-28 15:37:43,896 Training Epoch [21/40] Iter[237/312]		Loss: 0.1166
2019-10-28 15:37:43,975 Training Epoch [21/40] Iter[238/312]		Loss: 0.1173
2019-10-28 15:37:44,054 Training Epoch [21/40] Iter[239/312]		Loss: 0.1174
2019-10-28 15:37:44,133 Training Epoch [21/40] Iter[240/312]		Loss: 0.1174
2019-10-28 15:37:44,212 Training Epoch [21/40] Iter[241/312]		Loss: 0.1175
2019-10-28 15:37:44,291 Training Epoch [21/40] Iter[242/312]		Loss: 0.1175
2019-10-28 15:37:44,370 Training Epoch [21/40] Iter[243/312]		Loss: 0.1174
2019-10-28 15:37:44,449 Training Epoch [21/40] Iter[244/312]		Loss: 0.1175
2019-10-28 15:37:44,528 Training Epoch [21/40] Iter[245/312]		Loss: 0.1177
2019-10-28 15:37:44,607 Training Epoch [21/40] Iter[246/312]		Loss: 0.1178
2019-10-28 15:37:44,686 Training Epoch [21/40] Iter[247/312]		Loss: 0.1177
2019-10-28 15:37:44,765 Training Epoch [21/40] Iter[248/312]		Loss: 0.1178
2019-10-28 15:37:44,844 Training Epoch [21/40] Iter[249/312]		Loss: 0.1177
2019-10-28 15:37:44,923 Training Epoch [21/40] Iter[250/312]		Loss: 0.1179
2019-10-28 15:37:45,002 Training Epoch [21/40] Iter[251/312]		Loss: 0.1178
2019-10-28 15:37:45,081 Training Epoch [21/40] Iter[252/312]		Loss: 0.1178
2019-10-28 15:37:45,160 Training Epoch [21/40] Iter[253/312]		Loss: 0.1177
2019-10-28 15:37:45,239 Training Epoch [21/40] Iter[254/312]		Loss: 0.1177
2019-10-28 15:37:45,318 Training Epoch [21/40] Iter[255/312]		Loss: 0.1175
2019-10-28 15:37:45,398 Training Epoch [21/40] Iter[256/312]		Loss: 0.1174
2019-10-28 15:37:45,476 Training Epoch [21/40] Iter[257/312]		Loss: 0.1173
2019-10-28 15:37:45,555 Training Epoch [21/40] Iter[258/312]		Loss: 0.1173
2019-10-28 15:37:45,634 Training Epoch [21/40] Iter[259/312]		Loss: 0.1172
2019-10-28 15:37:45,713 Training Epoch [21/40] Iter[260/312]		Loss: 0.1170
2019-10-28 15:37:45,792 Training Epoch [21/40] Iter[261/312]		Loss: 0.1169
2019-10-28 15:37:45,871 Training Epoch [21/40] Iter[262/312]		Loss: 0.1171
2019-10-28 15:37:45,949 Training Epoch [21/40] Iter[263/312]		Loss: 0.1171
2019-10-28 15:37:46,028 Training Epoch [21/40] Iter[264/312]		Loss: 0.1170
2019-10-28 15:37:46,107 Training Epoch [21/40] Iter[265/312]		Loss: 0.1170
2019-10-28 15:37:46,187 Training Epoch [21/40] Iter[266/312]		Loss: 0.1168
2019-10-28 15:37:46,266 Training Epoch [21/40] Iter[267/312]		Loss: 0.1166
2019-10-28 15:37:46,345 Training Epoch [21/40] Iter[268/312]		Loss: 0.1165
2019-10-28 15:37:46,424 Training Epoch [21/40] Iter[269/312]		Loss: 0.1163
2019-10-28 15:37:46,503 Training Epoch [21/40] Iter[270/312]		Loss: 0.1164
2019-10-28 15:37:46,582 Training Epoch [21/40] Iter[271/312]		Loss: 0.1163
2019-10-28 15:37:46,661 Training Epoch [21/40] Iter[272/312]		Loss: 0.1162
2019-10-28 15:37:46,740 Training Epoch [21/40] Iter[273/312]		Loss: 0.1165
2019-10-28 15:37:46,819 Training Epoch [21/40] Iter[274/312]		Loss: 0.1164
2019-10-28 15:37:46,898 Training Epoch [21/40] Iter[275/312]		Loss: 0.1163
2019-10-28 15:37:46,976 Training Epoch [21/40] Iter[276/312]		Loss: 0.1164
2019-10-28 15:37:47,055 Training Epoch [21/40] Iter[277/312]		Loss: 0.1163
2019-10-28 15:37:47,134 Training Epoch [21/40] Iter[278/312]		Loss: 0.1161
2019-10-28 15:37:47,214 Training Epoch [21/40] Iter[279/312]		Loss: 0.1161
2019-10-28 15:37:47,293 Training Epoch [21/40] Iter[280/312]		Loss: 0.1161
2019-10-28 15:37:47,372 Training Epoch [21/40] Iter[281/312]		Loss: 0.1163
2019-10-28 15:37:47,451 Training Epoch [21/40] Iter[282/312]		Loss: 0.1163
2019-10-28 15:37:47,530 Training Epoch [21/40] Iter[283/312]		Loss: 0.1162
2019-10-28 15:37:47,608 Training Epoch [21/40] Iter[284/312]		Loss: 0.1167
2019-10-28 15:37:47,687 Training Epoch [21/40] Iter[285/312]		Loss: 0.1167
2019-10-28 15:37:47,766 Training Epoch [21/40] Iter[286/312]		Loss: 0.1166
2019-10-28 15:37:47,845 Training Epoch [21/40] Iter[287/312]		Loss: 0.1166
2019-10-28 15:37:47,924 Training Epoch [21/40] Iter[288/312]		Loss: 0.1165
2019-10-28 15:37:48,003 Training Epoch [21/40] Iter[289/312]		Loss: 0.1167
2019-10-28 15:37:48,082 Training Epoch [21/40] Iter[290/312]		Loss: 0.1169
2019-10-28 15:37:48,161 Training Epoch [21/40] Iter[291/312]		Loss: 0.1169
2019-10-28 15:37:48,240 Training Epoch [21/40] Iter[292/312]		Loss: 0.1170
2019-10-28 15:37:48,319 Training Epoch [21/40] Iter[293/312]		Loss: 0.1168
2019-10-28 15:37:48,398 Training Epoch [21/40] Iter[294/312]		Loss: 0.1168
2019-10-28 15:37:48,477 Training Epoch [21/40] Iter[295/312]		Loss: 0.1169
2019-10-28 15:37:48,556 Training Epoch [21/40] Iter[296/312]		Loss: 0.1169
2019-10-28 15:37:48,636 Training Epoch [21/40] Iter[297/312]		Loss: 0.1167
2019-10-28 15:37:48,715 Training Epoch [21/40] Iter[298/312]		Loss: 0.1172
2019-10-28 15:37:48,794 Training Epoch [21/40] Iter[299/312]		Loss: 0.1172
2019-10-28 15:37:48,872 Training Epoch [21/40] Iter[300/312]		Loss: 0.1172
2019-10-28 15:37:48,951 Training Epoch [21/40] Iter[301/312]		Loss: 0.1171
2019-10-28 15:37:49,030 Training Epoch [21/40] Iter[302/312]		Loss: 0.1172
2019-10-28 15:37:49,109 Training Epoch [21/40] Iter[303/312]		Loss: 0.1171
2019-10-28 15:37:49,188 Training Epoch [21/40] Iter[304/312]		Loss: 0.1170
2019-10-28 15:37:49,267 Training Epoch [21/40] Iter[305/312]		Loss: 0.1169
2019-10-28 15:37:49,345 Training Epoch [21/40] Iter[306/312]		Loss: 0.1171
2019-10-28 15:37:49,424 Training Epoch [21/40] Iter[307/312]		Loss: 0.1171
2019-10-28 15:37:49,502 Training Epoch [21/40] Iter[308/312]		Loss: 0.1170
2019-10-28 15:37:49,580 Training Epoch [21/40] Iter[309/312]		Loss: 0.1171
2019-10-28 15:37:49,658 Training Epoch [21/40] Iter[310/312]		Loss: 0.1171
2019-10-28 15:37:49,736 Training Epoch [21/40] Iter[311/312]		Loss: 0.1172
2019-10-28 15:37:49,775 Training Epoch [21/40] Iter[312/312]		Loss: 0.1171
2019-10-28 15:37:50,199 Testing Epoch [21/40] Iter[0/62]		Loss: 0.1265
2019-10-28 15:37:50,227 Testing Epoch [21/40] Iter[1/62]		Loss: 0.1277
2019-10-28 15:37:50,258 Testing Epoch [21/40] Iter[2/62]		Loss: 0.1127
2019-10-28 15:37:50,289 Testing Epoch [21/40] Iter[3/62]		Loss: 0.1161
2019-10-28 15:37:50,307 Testing Epoch [21/40] Iter[4/62]		Loss: 0.1223
2019-10-28 15:37:50,324 Testing Epoch [21/40] Iter[5/62]		Loss: 0.1185
2019-10-28 15:37:50,354 Testing Epoch [21/40] Iter[6/62]		Loss: 0.1207
2019-10-28 15:37:50,381 Testing Epoch [21/40] Iter[7/62]		Loss: 0.1229
2019-10-28 15:37:50,401 Testing Epoch [21/40] Iter[8/62]		Loss: 0.1246
2019-10-28 15:37:50,421 Testing Epoch [21/40] Iter[9/62]		Loss: 0.1235
2019-10-28 15:37:50,445 Testing Epoch [21/40] Iter[10/62]		Loss: 0.1242
2019-10-28 15:37:50,462 Testing Epoch [21/40] Iter[11/62]		Loss: 0.1312
2019-10-28 15:37:50,489 Testing Epoch [21/40] Iter[12/62]		Loss: 0.1312
2019-10-28 15:37:50,506 Testing Epoch [21/40] Iter[13/62]		Loss: 0.1336
2019-10-28 15:37:50,533 Testing Epoch [21/40] Iter[14/62]		Loss: 0.1459
2019-10-28 15:37:50,551 Testing Epoch [21/40] Iter[15/62]		Loss: 0.1481
2019-10-28 15:37:50,577 Testing Epoch [21/40] Iter[16/62]		Loss: 0.1449
2019-10-28 15:37:50,594 Testing Epoch [21/40] Iter[17/62]		Loss: 0.1460
2019-10-28 15:37:50,621 Testing Epoch [21/40] Iter[18/62]		Loss: 0.1437
2019-10-28 15:37:50,639 Testing Epoch [21/40] Iter[19/62]		Loss: 0.1416
2019-10-28 15:37:50,669 Testing Epoch [21/40] Iter[20/62]		Loss: 0.1435
2019-10-28 15:37:50,686 Testing Epoch [21/40] Iter[21/62]		Loss: 0.1418
2019-10-28 15:37:50,717 Testing Epoch [21/40] Iter[22/62]		Loss: 0.1432
2019-10-28 15:37:50,737 Testing Epoch [21/40] Iter[23/62]		Loss: 0.1419
2019-10-28 15:37:50,761 Testing Epoch [21/40] Iter[24/62]		Loss: 0.1450
2019-10-28 15:37:50,785 Testing Epoch [21/40] Iter[25/62]		Loss: 0.1441
2019-10-28 15:37:50,809 Testing Epoch [21/40] Iter[26/62]		Loss: 0.1430
2019-10-28 15:37:50,827 Testing Epoch [21/40] Iter[27/62]		Loss: 0.1503
2019-10-28 15:37:50,857 Testing Epoch [21/40] Iter[28/62]		Loss: 0.1541
2019-10-28 15:37:50,879 Testing Epoch [21/40] Iter[29/62]		Loss: 0.1543
2019-10-28 15:37:50,904 Testing Epoch [21/40] Iter[30/62]		Loss: 0.1549
2019-10-28 15:37:50,922 Testing Epoch [21/40] Iter[31/62]		Loss: 0.1538
2019-10-28 15:37:50,940 Testing Epoch [21/40] Iter[32/62]		Loss: 0.1555
2019-10-28 15:37:50,969 Testing Epoch [21/40] Iter[33/62]		Loss: 0.1544
2019-10-28 15:37:50,994 Testing Epoch [21/40] Iter[34/62]		Loss: 0.1567
2019-10-28 15:37:51,012 Testing Epoch [21/40] Iter[35/62]		Loss: 0.1561
2019-10-28 15:37:51,030 Testing Epoch [21/40] Iter[36/62]		Loss: 0.1541
2019-10-28 15:37:51,061 Testing Epoch [21/40] Iter[37/62]		Loss: 0.1530
2019-10-28 15:37:51,085 Testing Epoch [21/40] Iter[38/62]		Loss: 0.1519
2019-10-28 15:37:51,103 Testing Epoch [21/40] Iter[39/62]		Loss: 0.1522
2019-10-28 15:37:51,121 Testing Epoch [21/40] Iter[40/62]		Loss: 0.1542
2019-10-28 15:37:51,145 Testing Epoch [21/40] Iter[41/62]		Loss: 0.1556
2019-10-28 15:37:51,171 Testing Epoch [21/40] Iter[42/62]		Loss: 0.1536
2019-10-28 15:37:51,189 Testing Epoch [21/40] Iter[43/62]		Loss: 0.1531
2019-10-28 15:37:51,220 Testing Epoch [21/40] Iter[44/62]		Loss: 0.1514
2019-10-28 15:37:51,237 Testing Epoch [21/40] Iter[45/62]		Loss: 0.1511
2019-10-28 15:37:51,265 Testing Epoch [21/40] Iter[46/62]		Loss: 0.1509
2019-10-28 15:37:51,283 Testing Epoch [21/40] Iter[47/62]		Loss: 0.1566
2019-10-28 15:37:51,313 Testing Epoch [21/40] Iter[48/62]		Loss: 0.1556
2019-10-28 15:37:51,330 Testing Epoch [21/40] Iter[49/62]		Loss: 0.1578
2019-10-28 15:37:51,353 Testing Epoch [21/40] Iter[50/62]		Loss: 0.1568
2019-10-28 15:37:51,372 Testing Epoch [21/40] Iter[51/62]		Loss: 0.1568
2019-10-28 15:37:51,394 Testing Epoch [21/40] Iter[52/62]		Loss: 0.1555
2019-10-28 15:37:51,428 Testing Epoch [21/40] Iter[53/62]		Loss: 0.1558
2019-10-28 15:37:51,450 Testing Epoch [21/40] Iter[54/62]		Loss: 0.1547
2019-10-28 15:37:51,466 Testing Epoch [21/40] Iter[55/62]		Loss: 0.1543
2019-10-28 15:37:51,483 Testing Epoch [21/40] Iter[56/62]		Loss: 0.1536
2019-10-28 15:37:51,500 Testing Epoch [21/40] Iter[57/62]		Loss: 0.1537
2019-10-28 15:37:51,517 Testing Epoch [21/40] Iter[58/62]		Loss: 0.1532
2019-10-28 15:37:51,533 Testing Epoch [21/40] Iter[59/62]		Loss: 0.1543
2019-10-28 15:37:51,550 Testing Epoch [21/40] Iter[60/62]		Loss: 0.1535
2019-10-28 15:37:51,567 Testing Epoch [21/40] Iter[61/62]		Loss: 0.1535
2019-10-28 15:37:51,576 Testing Epoch [21/40] Iter[62/62]		Loss: 0.1542
2019-10-28 15:37:51,647 Saving the Model
2019-10-28 15:37:51,986 Training Epoch [22/40] Iter[0/312]		Loss: 0.0960
2019-10-28 15:37:52,130 Training Epoch [22/40] Iter[1/312]		Loss: 0.0956
2019-10-28 15:37:52,208 Training Epoch [22/40] Iter[2/312]		Loss: 0.0861
2019-10-28 15:37:52,287 Training Epoch [22/40] Iter[3/312]		Loss: 0.0977
2019-10-28 15:37:52,364 Training Epoch [22/40] Iter[4/312]		Loss: 0.0986
2019-10-28 15:37:52,445 Training Epoch [22/40] Iter[5/312]		Loss: 0.0951
2019-10-28 15:37:52,522 Training Epoch [22/40] Iter[6/312]		Loss: 0.0971
2019-10-28 15:37:52,600 Training Epoch [22/40] Iter[7/312]		Loss: 0.0973
2019-10-28 15:37:52,678 Training Epoch [22/40] Iter[8/312]		Loss: 0.0986
2019-10-28 15:37:52,757 Training Epoch [22/40] Iter[9/312]		Loss: 0.1017
2019-10-28 15:37:52,835 Training Epoch [22/40] Iter[10/312]		Loss: 0.1062
2019-10-28 15:37:52,914 Training Epoch [22/40] Iter[11/312]		Loss: 0.1135
2019-10-28 15:37:52,993 Training Epoch [22/40] Iter[12/312]		Loss: 0.1105
2019-10-28 15:37:53,072 Training Epoch [22/40] Iter[13/312]		Loss: 0.1096
2019-10-28 15:37:53,151 Training Epoch [22/40] Iter[14/312]		Loss: 0.1090
2019-10-28 15:37:53,230 Training Epoch [22/40] Iter[15/312]		Loss: 0.1115
2019-10-28 15:37:53,309 Training Epoch [22/40] Iter[16/312]		Loss: 0.1124
2019-10-28 15:37:53,388 Training Epoch [22/40] Iter[17/312]		Loss: 0.1117
2019-10-28 15:37:53,467 Training Epoch [22/40] Iter[18/312]		Loss: 0.1146
2019-10-28 15:37:53,546 Training Epoch [22/40] Iter[19/312]		Loss: 0.1129
2019-10-28 15:37:53,625 Training Epoch [22/40] Iter[20/312]		Loss: 0.1113
2019-10-28 15:37:53,704 Training Epoch [22/40] Iter[21/312]		Loss: 0.1112
2019-10-28 15:37:53,783 Training Epoch [22/40] Iter[22/312]		Loss: 0.1121
2019-10-28 15:37:53,862 Training Epoch [22/40] Iter[23/312]		Loss: 0.1114
2019-10-28 15:37:53,941 Training Epoch [22/40] Iter[24/312]		Loss: 0.1117
2019-10-28 15:37:54,020 Training Epoch [22/40] Iter[25/312]		Loss: 0.1122
2019-10-28 15:37:54,099 Training Epoch [22/40] Iter[26/312]		Loss: 0.1117
2019-10-28 15:37:54,178 Training Epoch [22/40] Iter[27/312]		Loss: 0.1104
2019-10-28 15:37:54,257 Training Epoch [22/40] Iter[28/312]		Loss: 0.1102
2019-10-28 15:37:54,336 Training Epoch [22/40] Iter[29/312]		Loss: 0.1108
2019-10-28 15:37:54,415 Training Epoch [22/40] Iter[30/312]		Loss: 0.1104
2019-10-28 15:37:54,494 Training Epoch [22/40] Iter[31/312]		Loss: 0.1096
2019-10-28 15:37:54,572 Training Epoch [22/40] Iter[32/312]		Loss: 0.1082
2019-10-28 15:37:54,651 Training Epoch [22/40] Iter[33/312]		Loss: 0.1085
2019-10-28 15:37:54,730 Training Epoch [22/40] Iter[34/312]		Loss: 0.1130
2019-10-28 15:37:54,808 Training Epoch [22/40] Iter[35/312]		Loss: 0.1134
2019-10-28 15:37:54,887 Training Epoch [22/40] Iter[36/312]		Loss: 0.1134
2019-10-28 15:37:54,966 Training Epoch [22/40] Iter[37/312]		Loss: 0.1123
2019-10-28 15:37:55,045 Training Epoch [22/40] Iter[38/312]		Loss: 0.1134
2019-10-28 15:37:55,124 Training Epoch [22/40] Iter[39/312]		Loss: 0.1130
2019-10-28 15:37:55,203 Training Epoch [22/40] Iter[40/312]		Loss: 0.1125
2019-10-28 15:37:55,281 Training Epoch [22/40] Iter[41/312]		Loss: 0.1123
2019-10-28 15:37:55,360 Training Epoch [22/40] Iter[42/312]		Loss: 0.1129
2019-10-28 15:37:55,439 Training Epoch [22/40] Iter[43/312]		Loss: 0.1126
2019-10-28 15:37:55,518 Training Epoch [22/40] Iter[44/312]		Loss: 0.1129
2019-10-28 15:37:55,597 Training Epoch [22/40] Iter[45/312]		Loss: 0.1136
2019-10-28 15:37:55,676 Training Epoch [22/40] Iter[46/312]		Loss: 0.1139
2019-10-28 15:37:55,755 Training Epoch [22/40] Iter[47/312]		Loss: 0.1140
2019-10-28 15:37:55,834 Training Epoch [22/40] Iter[48/312]		Loss: 0.1166
2019-10-28 15:37:55,913 Training Epoch [22/40] Iter[49/312]		Loss: 0.1157
2019-10-28 15:37:55,992 Training Epoch [22/40] Iter[50/312]		Loss: 0.1155
2019-10-28 15:37:56,071 Training Epoch [22/40] Iter[51/312]		Loss: 0.1148
2019-10-28 15:37:56,151 Training Epoch [22/40] Iter[52/312]		Loss: 0.1145
2019-10-28 15:37:56,230 Training Epoch [22/40] Iter[53/312]		Loss: 0.1143
2019-10-28 15:37:56,310 Training Epoch [22/40] Iter[54/312]		Loss: 0.1151
2019-10-28 15:37:56,389 Training Epoch [22/40] Iter[55/312]		Loss: 0.1147
2019-10-28 15:37:56,474 Training Epoch [22/40] Iter[56/312]		Loss: 0.1149
2019-10-28 15:37:56,554 Training Epoch [22/40] Iter[57/312]		Loss: 0.1143
2019-10-28 15:37:56,638 Training Epoch [22/40] Iter[58/312]		Loss: 0.1150
2019-10-28 15:37:56,722 Training Epoch [22/40] Iter[59/312]		Loss: 0.1157
2019-10-28 15:37:56,801 Training Epoch [22/40] Iter[60/312]		Loss: 0.1154
2019-10-28 15:37:56,886 Training Epoch [22/40] Iter[61/312]		Loss: 0.1149
2019-10-28 15:37:56,966 Training Epoch [22/40] Iter[62/312]		Loss: 0.1147
2019-10-28 15:37:57,045 Training Epoch [22/40] Iter[63/312]		Loss: 0.1147
2019-10-28 15:37:57,126 Training Epoch [22/40] Iter[64/312]		Loss: 0.1141
2019-10-28 15:37:57,206 Training Epoch [22/40] Iter[65/312]		Loss: 0.1145
2019-10-28 15:37:57,285 Training Epoch [22/40] Iter[66/312]		Loss: 0.1139
2019-10-28 15:37:57,364 Training Epoch [22/40] Iter[67/312]		Loss: 0.1140
2019-10-28 15:37:57,447 Training Epoch [22/40] Iter[68/312]		Loss: 0.1139
2019-10-28 15:37:57,531 Training Epoch [22/40] Iter[69/312]		Loss: 0.1142
2019-10-28 15:37:57,610 Training Epoch [22/40] Iter[70/312]		Loss: 0.1143
2019-10-28 15:37:57,689 Training Epoch [22/40] Iter[71/312]		Loss: 0.1143
2019-10-28 15:37:57,770 Training Epoch [22/40] Iter[72/312]		Loss: 0.1139
2019-10-28 15:37:57,850 Training Epoch [22/40] Iter[73/312]		Loss: 0.1137
2019-10-28 15:37:57,929 Training Epoch [22/40] Iter[74/312]		Loss: 0.1134
2019-10-28 15:37:58,008 Training Epoch [22/40] Iter[75/312]		Loss: 0.1138
2019-10-28 15:37:58,091 Training Epoch [22/40] Iter[76/312]		Loss: 0.1136
2019-10-28 15:37:58,175 Training Epoch [22/40] Iter[77/312]		Loss: 0.1134
2019-10-28 15:37:58,255 Training Epoch [22/40] Iter[78/312]		Loss: 0.1138
2019-10-28 15:37:58,334 Training Epoch [22/40] Iter[79/312]		Loss: 0.1135
2019-10-28 15:37:58,415 Training Epoch [22/40] Iter[80/312]		Loss: 0.1130
2019-10-28 15:37:58,495 Training Epoch [22/40] Iter[81/312]		Loss: 0.1126
2019-10-28 15:37:58,574 Training Epoch [22/40] Iter[82/312]		Loss: 0.1124
2019-10-28 15:37:58,653 Training Epoch [22/40] Iter[83/312]		Loss: 0.1120
2019-10-28 15:37:58,735 Training Epoch [22/40] Iter[84/312]		Loss: 0.1122
2019-10-28 15:37:58,815 Training Epoch [22/40] Iter[85/312]		Loss: 0.1120
2019-10-28 15:37:58,894 Training Epoch [22/40] Iter[86/312]		Loss: 0.1120
2019-10-28 15:37:58,972 Training Epoch [22/40] Iter[87/312]		Loss: 0.1118
2019-10-28 15:37:59,054 Training Epoch [22/40] Iter[88/312]		Loss: 0.1116
2019-10-28 15:37:59,135 Training Epoch [22/40] Iter[89/312]		Loss: 0.1122
2019-10-28 15:37:59,213 Training Epoch [22/40] Iter[90/312]		Loss: 0.1129
2019-10-28 15:37:59,292 Training Epoch [22/40] Iter[91/312]		Loss: 0.1125
2019-10-28 15:37:59,374 Training Epoch [22/40] Iter[92/312]		Loss: 0.1131
2019-10-28 15:37:59,459 Training Epoch [22/40] Iter[93/312]		Loss: 0.1130
2019-10-28 15:37:59,542 Training Epoch [22/40] Iter[94/312]		Loss: 0.1132
2019-10-28 15:37:59,623 Training Epoch [22/40] Iter[95/312]		Loss: 0.1132
2019-10-28 15:37:59,702 Training Epoch [22/40] Iter[96/312]		Loss: 0.1130
2019-10-28 15:37:59,782 Training Epoch [22/40] Iter[97/312]		Loss: 0.1128
2019-10-28 15:37:59,861 Training Epoch [22/40] Iter[98/312]		Loss: 0.1130
2019-10-28 15:37:59,940 Training Epoch [22/40] Iter[99/312]		Loss: 0.1140
2019-10-28 15:38:00,022 Training Epoch [22/40] Iter[100/312]		Loss: 0.1138
2019-10-28 15:38:00,107 Training Epoch [22/40] Iter[101/312]		Loss: 0.1142
2019-10-28 15:38:00,187 Training Epoch [22/40] Iter[102/312]		Loss: 0.1145
2019-10-28 15:38:00,266 Training Epoch [22/40] Iter[103/312]		Loss: 0.1147
2019-10-28 15:38:00,344 Training Epoch [22/40] Iter[104/312]		Loss: 0.1145
2019-10-28 15:38:00,427 Training Epoch [22/40] Iter[105/312]		Loss: 0.1142
2019-10-28 15:38:00,506 Training Epoch [22/40] Iter[106/312]		Loss: 0.1143
2019-10-28 15:38:00,585 Training Epoch [22/40] Iter[107/312]		Loss: 0.1142
2019-10-28 15:38:00,664 Training Epoch [22/40] Iter[108/312]		Loss: 0.1153
2019-10-28 15:38:00,742 Training Epoch [22/40] Iter[109/312]		Loss: 0.1151
2019-10-28 15:38:00,821 Training Epoch [22/40] Iter[110/312]		Loss: 0.1152
2019-10-28 15:38:00,900 Training Epoch [22/40] Iter[111/312]		Loss: 0.1154
2019-10-28 15:38:00,979 Training Epoch [22/40] Iter[112/312]		Loss: 0.1153
2019-10-28 15:38:01,058 Training Epoch [22/40] Iter[113/312]		Loss: 0.1152
2019-10-28 15:38:01,137 Training Epoch [22/40] Iter[114/312]		Loss: 0.1151
2019-10-28 15:38:01,216 Training Epoch [22/40] Iter[115/312]		Loss: 0.1150
2019-10-28 15:38:01,295 Training Epoch [22/40] Iter[116/312]		Loss: 0.1149
2019-10-28 15:38:01,374 Training Epoch [22/40] Iter[117/312]		Loss: 0.1149
2019-10-28 15:38:01,453 Training Epoch [22/40] Iter[118/312]		Loss: 0.1159
2019-10-28 15:38:01,532 Training Epoch [22/40] Iter[119/312]		Loss: 0.1155
2019-10-28 15:38:01,610 Training Epoch [22/40] Iter[120/312]		Loss: 0.1156
2019-10-28 15:38:01,689 Training Epoch [22/40] Iter[121/312]		Loss: 0.1161
2019-10-28 15:38:01,768 Training Epoch [22/40] Iter[122/312]		Loss: 0.1161
2019-10-28 15:38:01,847 Training Epoch [22/40] Iter[123/312]		Loss: 0.1162
2019-10-28 15:38:01,926 Training Epoch [22/40] Iter[124/312]		Loss: 0.1161
2019-10-28 15:38:02,005 Training Epoch [22/40] Iter[125/312]		Loss: 0.1162
2019-10-28 15:38:02,084 Training Epoch [22/40] Iter[126/312]		Loss: 0.1160
2019-10-28 15:38:02,163 Training Epoch [22/40] Iter[127/312]		Loss: 0.1161
2019-10-28 15:38:02,242 Training Epoch [22/40] Iter[128/312]		Loss: 0.1160
2019-10-28 15:38:02,321 Training Epoch [22/40] Iter[129/312]		Loss: 0.1158
2019-10-28 15:38:02,400 Training Epoch [22/40] Iter[130/312]		Loss: 0.1164
2019-10-28 15:38:02,479 Training Epoch [22/40] Iter[131/312]		Loss: 0.1164
2019-10-28 15:38:02,557 Training Epoch [22/40] Iter[132/312]		Loss: 0.1166
2019-10-28 15:38:02,636 Training Epoch [22/40] Iter[133/312]		Loss: 0.1165
2019-10-28 15:38:02,715 Training Epoch [22/40] Iter[134/312]		Loss: 0.1163
2019-10-28 15:38:02,793 Training Epoch [22/40] Iter[135/312]		Loss: 0.1165
2019-10-28 15:38:02,872 Training Epoch [22/40] Iter[136/312]		Loss: 0.1164
2019-10-28 15:38:02,951 Training Epoch [22/40] Iter[137/312]		Loss: 0.1165
2019-10-28 15:38:03,030 Training Epoch [22/40] Iter[138/312]		Loss: 0.1169
2019-10-28 15:38:03,109 Training Epoch [22/40] Iter[139/312]		Loss: 0.1172
2019-10-28 15:38:03,187 Training Epoch [22/40] Iter[140/312]		Loss: 0.1168
2019-10-28 15:38:03,266 Training Epoch [22/40] Iter[141/312]		Loss: 0.1165
2019-10-28 15:38:03,345 Training Epoch [22/40] Iter[142/312]		Loss: 0.1164
2019-10-28 15:38:03,424 Training Epoch [22/40] Iter[143/312]		Loss: 0.1168
2019-10-28 15:38:03,503 Training Epoch [22/40] Iter[144/312]		Loss: 0.1170
2019-10-28 15:38:03,582 Training Epoch [22/40] Iter[145/312]		Loss: 0.1167
2019-10-28 15:38:03,661 Training Epoch [22/40] Iter[146/312]		Loss: 0.1164
2019-10-28 15:38:03,740 Training Epoch [22/40] Iter[147/312]		Loss: 0.1165
2019-10-28 15:38:03,819 Training Epoch [22/40] Iter[148/312]		Loss: 0.1168
2019-10-28 15:38:03,898 Training Epoch [22/40] Iter[149/312]		Loss: 0.1167
2019-10-28 15:38:03,976 Training Epoch [22/40] Iter[150/312]		Loss: 0.1164
2019-10-28 15:38:04,055 Training Epoch [22/40] Iter[151/312]		Loss: 0.1164
2019-10-28 15:38:04,134 Training Epoch [22/40] Iter[152/312]		Loss: 0.1163
2019-10-28 15:38:04,213 Training Epoch [22/40] Iter[153/312]		Loss: 0.1161
2019-10-28 15:38:04,292 Training Epoch [22/40] Iter[154/312]		Loss: 0.1158
2019-10-28 15:38:04,371 Training Epoch [22/40] Iter[155/312]		Loss: 0.1164
2019-10-28 15:38:04,450 Training Epoch [22/40] Iter[156/312]		Loss: 0.1167
2019-10-28 15:38:04,529 Training Epoch [22/40] Iter[157/312]		Loss: 0.1168
2019-10-28 15:38:04,608 Training Epoch [22/40] Iter[158/312]		Loss: 0.1171
2019-10-28 15:38:04,687 Training Epoch [22/40] Iter[159/312]		Loss: 0.1172
2019-10-28 15:38:04,765 Training Epoch [22/40] Iter[160/312]		Loss: 0.1169
2019-10-28 15:38:04,845 Training Epoch [22/40] Iter[161/312]		Loss: 0.1173
2019-10-28 15:38:04,923 Training Epoch [22/40] Iter[162/312]		Loss: 0.1174
2019-10-28 15:38:05,002 Training Epoch [22/40] Iter[163/312]		Loss: 0.1174
2019-10-28 15:38:05,081 Training Epoch [22/40] Iter[164/312]		Loss: 0.1179
2019-10-28 15:38:05,160 Training Epoch [22/40] Iter[165/312]		Loss: 0.1179
2019-10-28 15:38:05,239 Training Epoch [22/40] Iter[166/312]		Loss: 0.1179
2019-10-28 15:38:05,318 Training Epoch [22/40] Iter[167/312]		Loss: 0.1182
2019-10-28 15:38:05,397 Training Epoch [22/40] Iter[168/312]		Loss: 0.1181
2019-10-28 15:38:05,476 Training Epoch [22/40] Iter[169/312]		Loss: 0.1178
2019-10-28 15:38:05,555 Training Epoch [22/40] Iter[170/312]		Loss: 0.1176
2019-10-28 15:38:05,634 Training Epoch [22/40] Iter[171/312]		Loss: 0.1173
2019-10-28 15:38:05,713 Training Epoch [22/40] Iter[172/312]		Loss: 0.1172
2019-10-28 15:38:05,792 Training Epoch [22/40] Iter[173/312]		Loss: 0.1170
2019-10-28 15:38:05,871 Training Epoch [22/40] Iter[174/312]		Loss: 0.1172
2019-10-28 15:38:05,950 Training Epoch [22/40] Iter[175/312]		Loss: 0.1171
2019-10-28 15:38:06,029 Training Epoch [22/40] Iter[176/312]		Loss: 0.1171
2019-10-28 15:38:06,108 Training Epoch [22/40] Iter[177/312]		Loss: 0.1170
2019-10-28 15:38:06,187 Training Epoch [22/40] Iter[178/312]		Loss: 0.1167
2019-10-28 15:38:06,266 Training Epoch [22/40] Iter[179/312]		Loss: 0.1170
2019-10-28 15:38:06,345 Training Epoch [22/40] Iter[180/312]		Loss: 0.1168
2019-10-28 15:38:06,424 Training Epoch [22/40] Iter[181/312]		Loss: 0.1167
2019-10-28 15:38:06,503 Training Epoch [22/40] Iter[182/312]		Loss: 0.1165
2019-10-28 15:38:06,581 Training Epoch [22/40] Iter[183/312]		Loss: 0.1165
2019-10-28 15:38:06,660 Training Epoch [22/40] Iter[184/312]		Loss: 0.1166
2019-10-28 15:38:06,739 Training Epoch [22/40] Iter[185/312]		Loss: 0.1167
2019-10-28 15:38:06,818 Training Epoch [22/40] Iter[186/312]		Loss: 0.1165
2019-10-28 15:38:06,897 Training Epoch [22/40] Iter[187/312]		Loss: 0.1165
2019-10-28 15:38:06,976 Training Epoch [22/40] Iter[188/312]		Loss: 0.1166
2019-10-28 15:38:07,055 Training Epoch [22/40] Iter[189/312]		Loss: 0.1168
2019-10-28 15:38:07,134 Training Epoch [22/40] Iter[190/312]		Loss: 0.1167
2019-10-28 15:38:07,213 Training Epoch [22/40] Iter[191/312]		Loss: 0.1165
2019-10-28 15:38:07,292 Training Epoch [22/40] Iter[192/312]		Loss: 0.1163
2019-10-28 15:38:07,371 Training Epoch [22/40] Iter[193/312]		Loss: 0.1164
2019-10-28 15:38:07,451 Training Epoch [22/40] Iter[194/312]		Loss: 0.1162
2019-10-28 15:38:07,530 Training Epoch [22/40] Iter[195/312]		Loss: 0.1161
2019-10-28 15:38:07,609 Training Epoch [22/40] Iter[196/312]		Loss: 0.1160
2019-10-28 15:38:07,688 Training Epoch [22/40] Iter[197/312]		Loss: 0.1162
2019-10-28 15:38:07,766 Training Epoch [22/40] Iter[198/312]		Loss: 0.1161
2019-10-28 15:38:07,845 Training Epoch [22/40] Iter[199/312]		Loss: 0.1161
2019-10-28 15:38:07,925 Training Epoch [22/40] Iter[200/312]		Loss: 0.1161
2019-10-28 15:38:08,004 Training Epoch [22/40] Iter[201/312]		Loss: 0.1161
2019-10-28 15:38:08,084 Training Epoch [22/40] Iter[202/312]		Loss: 0.1161
2019-10-28 15:38:08,163 Training Epoch [22/40] Iter[203/312]		Loss: 0.1165
2019-10-28 15:38:08,243 Training Epoch [22/40] Iter[204/312]		Loss: 0.1163
2019-10-28 15:38:08,323 Training Epoch [22/40] Iter[205/312]		Loss: 0.1168
2019-10-28 15:38:08,402 Training Epoch [22/40] Iter[206/312]		Loss: 0.1166
2019-10-28 15:38:08,482 Training Epoch [22/40] Iter[207/312]		Loss: 0.1164
2019-10-28 15:38:08,562 Training Epoch [22/40] Iter[208/312]		Loss: 0.1164
2019-10-28 15:38:08,641 Training Epoch [22/40] Iter[209/312]		Loss: 0.1163
2019-10-28 15:38:08,721 Training Epoch [22/40] Iter[210/312]		Loss: 0.1164
2019-10-28 15:38:08,800 Training Epoch [22/40] Iter[211/312]		Loss: 0.1163
2019-10-28 15:38:08,880 Training Epoch [22/40] Iter[212/312]		Loss: 0.1161
2019-10-28 15:38:08,959 Training Epoch [22/40] Iter[213/312]		Loss: 0.1161
2019-10-28 15:38:09,039 Training Epoch [22/40] Iter[214/312]		Loss: 0.1159
2019-10-28 15:38:09,118 Training Epoch [22/40] Iter[215/312]		Loss: 0.1160
2019-10-28 15:38:09,198 Training Epoch [22/40] Iter[216/312]		Loss: 0.1159
2019-10-28 15:38:09,278 Training Epoch [22/40] Iter[217/312]		Loss: 0.1159
2019-10-28 15:38:09,357 Training Epoch [22/40] Iter[218/312]		Loss: 0.1157
2019-10-28 15:38:09,437 Training Epoch [22/40] Iter[219/312]		Loss: 0.1156
2019-10-28 15:38:09,516 Training Epoch [22/40] Iter[220/312]		Loss: 0.1157
2019-10-28 15:38:09,596 Training Epoch [22/40] Iter[221/312]		Loss: 0.1156
2019-10-28 15:38:09,676 Training Epoch [22/40] Iter[222/312]		Loss: 0.1155
2019-10-28 15:38:09,755 Training Epoch [22/40] Iter[223/312]		Loss: 0.1154
2019-10-28 15:38:09,835 Training Epoch [22/40] Iter[224/312]		Loss: 0.1154
2019-10-28 15:38:09,915 Training Epoch [22/40] Iter[225/312]		Loss: 0.1153
2019-10-28 15:38:09,994 Training Epoch [22/40] Iter[226/312]		Loss: 0.1153
2019-10-28 15:38:10,074 Training Epoch [22/40] Iter[227/312]		Loss: 0.1152
2019-10-28 15:38:10,153 Training Epoch [22/40] Iter[228/312]		Loss: 0.1152
2019-10-28 15:38:10,233 Training Epoch [22/40] Iter[229/312]		Loss: 0.1152
2019-10-28 15:38:10,312 Training Epoch [22/40] Iter[230/312]		Loss: 0.1153
2019-10-28 15:38:10,392 Training Epoch [22/40] Iter[231/312]		Loss: 0.1154
2019-10-28 15:38:10,472 Training Epoch [22/40] Iter[232/312]		Loss: 0.1154
2019-10-28 15:38:10,551 Training Epoch [22/40] Iter[233/312]		Loss: 0.1153
2019-10-28 15:38:10,631 Training Epoch [22/40] Iter[234/312]		Loss: 0.1153
2019-10-28 15:38:10,710 Training Epoch [22/40] Iter[235/312]		Loss: 0.1152
2019-10-28 15:38:10,789 Training Epoch [22/40] Iter[236/312]		Loss: 0.1151
2019-10-28 15:38:10,868 Training Epoch [22/40] Iter[237/312]		Loss: 0.1153
2019-10-28 15:38:10,948 Training Epoch [22/40] Iter[238/312]		Loss: 0.1157
2019-10-28 15:38:11,027 Training Epoch [22/40] Iter[239/312]		Loss: 0.1158
2019-10-28 15:38:11,106 Training Epoch [22/40] Iter[240/312]		Loss: 0.1159
2019-10-28 15:38:11,186 Training Epoch [22/40] Iter[241/312]		Loss: 0.1159
2019-10-28 15:38:11,265 Training Epoch [22/40] Iter[242/312]		Loss: 0.1161
2019-10-28 15:38:11,344 Training Epoch [22/40] Iter[243/312]		Loss: 0.1160
2019-10-28 15:38:11,423 Training Epoch [22/40] Iter[244/312]		Loss: 0.1161
2019-10-28 15:38:11,502 Training Epoch [22/40] Iter[245/312]		Loss: 0.1160
2019-10-28 15:38:11,581 Training Epoch [22/40] Iter[246/312]		Loss: 0.1160
2019-10-28 15:38:11,660 Training Epoch [22/40] Iter[247/312]		Loss: 0.1161
2019-10-28 15:38:11,739 Training Epoch [22/40] Iter[248/312]		Loss: 0.1162
2019-10-28 15:38:11,818 Training Epoch [22/40] Iter[249/312]		Loss: 0.1160
2019-10-28 15:38:11,897 Training Epoch [22/40] Iter[250/312]		Loss: 0.1158
2019-10-28 15:38:11,976 Training Epoch [22/40] Iter[251/312]		Loss: 0.1158
2019-10-28 15:38:12,055 Training Epoch [22/40] Iter[252/312]		Loss: 0.1157
2019-10-28 15:38:12,134 Training Epoch [22/40] Iter[253/312]		Loss: 0.1157
2019-10-28 15:38:12,214 Training Epoch [22/40] Iter[254/312]		Loss: 0.1158
2019-10-28 15:38:12,293 Training Epoch [22/40] Iter[255/312]		Loss: 0.1157
2019-10-28 15:38:12,372 Training Epoch [22/40] Iter[256/312]		Loss: 0.1162
2019-10-28 15:38:12,451 Training Epoch [22/40] Iter[257/312]		Loss: 0.1162
2019-10-28 15:38:12,530 Training Epoch [22/40] Iter[258/312]		Loss: 0.1163
2019-10-28 15:38:12,609 Training Epoch [22/40] Iter[259/312]		Loss: 0.1162
2019-10-28 15:38:12,688 Training Epoch [22/40] Iter[260/312]		Loss: 0.1160
2019-10-28 15:38:12,767 Training Epoch [22/40] Iter[261/312]		Loss: 0.1158
2019-10-28 15:38:12,846 Training Epoch [22/40] Iter[262/312]		Loss: 0.1157
2019-10-28 15:38:12,925 Training Epoch [22/40] Iter[263/312]		Loss: 0.1158
2019-10-28 15:38:13,004 Training Epoch [22/40] Iter[264/312]		Loss: 0.1158
2019-10-28 15:38:13,083 Training Epoch [22/40] Iter[265/312]		Loss: 0.1157
2019-10-28 15:38:13,162 Training Epoch [22/40] Iter[266/312]		Loss: 0.1156
2019-10-28 15:38:13,241 Training Epoch [22/40] Iter[267/312]		Loss: 0.1154
2019-10-28 15:38:13,320 Training Epoch [22/40] Iter[268/312]		Loss: 0.1153
2019-10-28 15:38:13,400 Training Epoch [22/40] Iter[269/312]		Loss: 0.1153
2019-10-28 15:38:13,479 Training Epoch [22/40] Iter[270/312]		Loss: 0.1152
2019-10-28 15:38:13,558 Training Epoch [22/40] Iter[271/312]		Loss: 0.1152
2019-10-28 15:38:13,637 Training Epoch [22/40] Iter[272/312]		Loss: 0.1151
2019-10-28 15:38:13,716 Training Epoch [22/40] Iter[273/312]		Loss: 0.1152
2019-10-28 15:38:13,795 Training Epoch [22/40] Iter[274/312]		Loss: 0.1152
2019-10-28 15:38:13,874 Training Epoch [22/40] Iter[275/312]		Loss: 0.1151
2019-10-28 15:38:13,953 Training Epoch [22/40] Iter[276/312]		Loss: 0.1151
2019-10-28 15:38:14,032 Training Epoch [22/40] Iter[277/312]		Loss: 0.1152
2019-10-28 15:38:14,111 Training Epoch [22/40] Iter[278/312]		Loss: 0.1151
2019-10-28 15:38:14,190 Training Epoch [22/40] Iter[279/312]		Loss: 0.1151
2019-10-28 15:38:14,269 Training Epoch [22/40] Iter[280/312]		Loss: 0.1149
2019-10-28 15:38:14,348 Training Epoch [22/40] Iter[281/312]		Loss: 0.1150
2019-10-28 15:38:14,427 Training Epoch [22/40] Iter[282/312]		Loss: 0.1150
2019-10-28 15:38:14,506 Training Epoch [22/40] Iter[283/312]		Loss: 0.1149
2019-10-28 15:38:14,585 Training Epoch [22/40] Iter[284/312]		Loss: 0.1148
2019-10-28 15:38:14,664 Training Epoch [22/40] Iter[285/312]		Loss: 0.1147
2019-10-28 15:38:14,743 Training Epoch [22/40] Iter[286/312]		Loss: 0.1148
2019-10-28 15:38:14,821 Training Epoch [22/40] Iter[287/312]		Loss: 0.1149
2019-10-28 15:38:14,900 Training Epoch [22/40] Iter[288/312]		Loss: 0.1149
2019-10-28 15:38:14,979 Training Epoch [22/40] Iter[289/312]		Loss: 0.1154
2019-10-28 15:38:15,058 Training Epoch [22/40] Iter[290/312]		Loss: 0.1153
2019-10-28 15:38:15,137 Training Epoch [22/40] Iter[291/312]		Loss: 0.1152
2019-10-28 15:38:15,216 Training Epoch [22/40] Iter[292/312]		Loss: 0.1151
2019-10-28 15:38:15,295 Training Epoch [22/40] Iter[293/312]		Loss: 0.1151
2019-10-28 15:38:15,374 Training Epoch [22/40] Iter[294/312]		Loss: 0.1151
2019-10-28 15:38:15,454 Training Epoch [22/40] Iter[295/312]		Loss: 0.1151
2019-10-28 15:38:15,533 Training Epoch [22/40] Iter[296/312]		Loss: 0.1150
2019-10-28 15:38:15,612 Training Epoch [22/40] Iter[297/312]		Loss: 0.1150
2019-10-28 15:38:15,690 Training Epoch [22/40] Iter[298/312]		Loss: 0.1152
2019-10-28 15:38:15,769 Training Epoch [22/40] Iter[299/312]		Loss: 0.1153
2019-10-28 15:38:15,848 Training Epoch [22/40] Iter[300/312]		Loss: 0.1155
2019-10-28 15:38:15,927 Training Epoch [22/40] Iter[301/312]		Loss: 0.1155
2019-10-28 15:38:16,006 Training Epoch [22/40] Iter[302/312]		Loss: 0.1155
2019-10-28 15:38:16,085 Training Epoch [22/40] Iter[303/312]		Loss: 0.1154
2019-10-28 15:38:16,164 Training Epoch [22/40] Iter[304/312]		Loss: 0.1155
2019-10-28 15:38:16,242 Training Epoch [22/40] Iter[305/312]		Loss: 0.1155
2019-10-28 15:38:16,321 Training Epoch [22/40] Iter[306/312]		Loss: 0.1154
2019-10-28 15:38:16,399 Training Epoch [22/40] Iter[307/312]		Loss: 0.1155
2019-10-28 15:38:16,478 Training Epoch [22/40] Iter[308/312]		Loss: 0.1155
2019-10-28 15:38:16,556 Training Epoch [22/40] Iter[309/312]		Loss: 0.1154
2019-10-28 15:38:16,634 Training Epoch [22/40] Iter[310/312]		Loss: 0.1154
2019-10-28 15:38:16,712 Training Epoch [22/40] Iter[311/312]		Loss: 0.1155
2019-10-28 15:38:16,751 Training Epoch [22/40] Iter[312/312]		Loss: 0.1161
2019-10-28 15:38:17,166 Testing Epoch [22/40] Iter[0/62]		Loss: 0.1342
2019-10-28 15:38:17,198 Testing Epoch [22/40] Iter[1/62]		Loss: 0.1329
2019-10-28 15:38:17,223 Testing Epoch [22/40] Iter[2/62]		Loss: 0.1159
2019-10-28 15:38:17,254 Testing Epoch [22/40] Iter[3/62]		Loss: 0.1195
2019-10-28 15:38:17,281 Testing Epoch [22/40] Iter[4/62]		Loss: 0.1218
2019-10-28 15:38:17,299 Testing Epoch [22/40] Iter[5/62]		Loss: 0.1167
2019-10-28 15:38:17,325 Testing Epoch [22/40] Iter[6/62]		Loss: 0.1186
2019-10-28 15:38:17,351 Testing Epoch [22/40] Iter[7/62]		Loss: 0.1217
2019-10-28 15:38:17,374 Testing Epoch [22/40] Iter[8/62]		Loss: 0.1246
2019-10-28 15:38:17,399 Testing Epoch [22/40] Iter[9/62]		Loss: 0.1236
2019-10-28 15:38:17,417 Testing Epoch [22/40] Iter[10/62]		Loss: 0.1239
2019-10-28 15:38:17,435 Testing Epoch [22/40] Iter[11/62]		Loss: 0.1297
2019-10-28 15:38:17,462 Testing Epoch [22/40] Iter[12/62]		Loss: 0.1301
2019-10-28 15:38:17,489 Testing Epoch [22/40] Iter[13/62]		Loss: 0.1315
2019-10-28 15:38:17,507 Testing Epoch [22/40] Iter[14/62]		Loss: 0.1457
2019-10-28 15:38:17,524 Testing Epoch [22/40] Iter[15/62]		Loss: 0.1477
2019-10-28 15:38:17,550 Testing Epoch [22/40] Iter[16/62]		Loss: 0.1448
2019-10-28 15:38:17,576 Testing Epoch [22/40] Iter[17/62]		Loss: 0.1447
2019-10-28 15:38:17,594 Testing Epoch [22/40] Iter[18/62]		Loss: 0.1420
2019-10-28 15:38:17,612 Testing Epoch [22/40] Iter[19/62]		Loss: 0.1398
2019-10-28 15:38:17,638 Testing Epoch [22/40] Iter[20/62]		Loss: 0.1418
2019-10-28 15:38:17,664 Testing Epoch [22/40] Iter[21/62]		Loss: 0.1404
2019-10-28 15:38:17,684 Testing Epoch [22/40] Iter[22/62]		Loss: 0.1421
2019-10-28 15:38:17,700 Testing Epoch [22/40] Iter[23/62]		Loss: 0.1411
2019-10-28 15:38:17,725 Testing Epoch [22/40] Iter[24/62]		Loss: 0.1442
2019-10-28 15:38:17,749 Testing Epoch [22/40] Iter[25/62]		Loss: 0.1432
2019-10-28 15:38:17,766 Testing Epoch [22/40] Iter[26/62]		Loss: 0.1420
2019-10-28 15:38:17,798 Testing Epoch [22/40] Iter[27/62]		Loss: 0.1499
2019-10-28 15:38:17,815 Testing Epoch [22/40] Iter[28/62]		Loss: 0.1536
2019-10-28 15:38:17,841 Testing Epoch [22/40] Iter[29/62]		Loss: 0.1538
2019-10-28 15:38:17,859 Testing Epoch [22/40] Iter[30/62]		Loss: 0.1542
2019-10-28 15:38:17,876 Testing Epoch [22/40] Iter[31/62]		Loss: 0.1531
2019-10-28 15:38:17,898 Testing Epoch [22/40] Iter[32/62]		Loss: 0.1546
2019-10-28 15:38:17,916 Testing Epoch [22/40] Iter[33/62]		Loss: 0.1536
2019-10-28 15:38:17,934 Testing Epoch [22/40] Iter[34/62]		Loss: 0.1558
2019-10-28 15:38:17,961 Testing Epoch [22/40] Iter[35/62]		Loss: 0.1553
2019-10-28 15:38:17,993 Testing Epoch [22/40] Iter[36/62]		Loss: 0.1533
2019-10-28 15:38:18,010 Testing Epoch [22/40] Iter[37/62]		Loss: 0.1522
2019-10-28 15:38:18,029 Testing Epoch [22/40] Iter[38/62]		Loss: 0.1511
2019-10-28 15:38:18,045 Testing Epoch [22/40] Iter[39/62]		Loss: 0.1515
2019-10-28 15:38:18,070 Testing Epoch [22/40] Iter[40/62]		Loss: 0.1532
2019-10-28 15:38:18,095 Testing Epoch [22/40] Iter[41/62]		Loss: 0.1548
2019-10-28 15:38:18,112 Testing Epoch [22/40] Iter[42/62]		Loss: 0.1529
2019-10-28 15:38:18,138 Testing Epoch [22/40] Iter[43/62]		Loss: 0.1522
2019-10-28 15:38:18,159 Testing Epoch [22/40] Iter[44/62]		Loss: 0.1505
2019-10-28 15:38:18,185 Testing Epoch [22/40] Iter[45/62]		Loss: 0.1504
2019-10-28 15:38:18,212 Testing Epoch [22/40] Iter[46/62]		Loss: 0.1503
2019-10-28 15:38:18,233 Testing Epoch [22/40] Iter[47/62]		Loss: 0.1562
2019-10-28 15:38:18,250 Testing Epoch [22/40] Iter[48/62]		Loss: 0.1552
2019-10-28 15:38:18,267 Testing Epoch [22/40] Iter[49/62]		Loss: 0.1576
2019-10-28 15:38:18,293 Testing Epoch [22/40] Iter[50/62]		Loss: 0.1568
2019-10-28 15:38:18,319 Testing Epoch [22/40] Iter[51/62]		Loss: 0.1569
2019-10-28 15:38:18,337 Testing Epoch [22/40] Iter[52/62]		Loss: 0.1556
2019-10-28 15:38:18,369 Testing Epoch [22/40] Iter[53/62]		Loss: 0.1560
2019-10-28 15:38:18,387 Testing Epoch [22/40] Iter[54/62]		Loss: 0.1547
2019-10-28 15:38:18,404 Testing Epoch [22/40] Iter[55/62]		Loss: 0.1544
2019-10-28 15:38:18,421 Testing Epoch [22/40] Iter[56/62]		Loss: 0.1537
2019-10-28 15:38:18,438 Testing Epoch [22/40] Iter[57/62]		Loss: 0.1539
2019-10-28 15:38:18,454 Testing Epoch [22/40] Iter[58/62]		Loss: 0.1533
2019-10-28 15:38:18,471 Testing Epoch [22/40] Iter[59/62]		Loss: 0.1544
2019-10-28 15:38:18,487 Testing Epoch [22/40] Iter[60/62]		Loss: 0.1533
2019-10-28 15:38:18,504 Testing Epoch [22/40] Iter[61/62]		Loss: 0.1534
2019-10-28 15:38:18,513 Testing Epoch [22/40] Iter[62/62]		Loss: 0.1543
2019-10-28 15:38:19,002 Training Epoch [23/40] Iter[0/312]		Loss: 0.0868
2019-10-28 15:38:19,083 Training Epoch [23/40] Iter[1/312]		Loss: 0.0926
2019-10-28 15:38:19,162 Training Epoch [23/40] Iter[2/312]		Loss: 0.0875
2019-10-28 15:38:19,243 Training Epoch [23/40] Iter[3/312]		Loss: 0.1009
2019-10-28 15:38:19,320 Training Epoch [23/40] Iter[4/312]		Loss: 0.0989
2019-10-28 15:38:19,400 Training Epoch [23/40] Iter[5/312]		Loss: 0.0979
2019-10-28 15:38:19,482 Training Epoch [23/40] Iter[6/312]		Loss: 0.0948
2019-10-28 15:38:19,560 Training Epoch [23/40] Iter[7/312]		Loss: 0.0950
2019-10-28 15:38:19,639 Training Epoch [23/40] Iter[8/312]		Loss: 0.0975
2019-10-28 15:38:19,718 Training Epoch [23/40] Iter[9/312]		Loss: 0.0955
2019-10-28 15:38:19,797 Training Epoch [23/40] Iter[10/312]		Loss: 0.0975
2019-10-28 15:38:19,875 Training Epoch [23/40] Iter[11/312]		Loss: 0.0974
2019-10-28 15:38:19,954 Training Epoch [23/40] Iter[12/312]		Loss: 0.0955
2019-10-28 15:38:20,033 Training Epoch [23/40] Iter[13/312]		Loss: 0.0963
2019-10-28 15:38:20,112 Training Epoch [23/40] Iter[14/312]		Loss: 0.1000
2019-10-28 15:38:20,191 Training Epoch [23/40] Iter[15/312]		Loss: 0.1011
2019-10-28 15:38:20,270 Training Epoch [23/40] Iter[16/312]		Loss: 0.1020
2019-10-28 15:38:20,349 Training Epoch [23/40] Iter[17/312]		Loss: 0.1039
2019-10-28 15:38:20,428 Training Epoch [23/40] Iter[18/312]		Loss: 0.1038
2019-10-28 15:38:20,507 Training Epoch [23/40] Iter[19/312]		Loss: 0.1042
2019-10-28 15:38:20,586 Training Epoch [23/40] Iter[20/312]		Loss: 0.1039
2019-10-28 15:38:20,664 Training Epoch [23/40] Iter[21/312]		Loss: 0.1038
2019-10-28 15:38:20,743 Training Epoch [23/40] Iter[22/312]		Loss: 0.1037
2019-10-28 15:38:20,822 Training Epoch [23/40] Iter[23/312]		Loss: 0.1054
2019-10-28 15:38:20,901 Training Epoch [23/40] Iter[24/312]		Loss: 0.1071
2019-10-28 15:38:20,979 Training Epoch [23/40] Iter[25/312]		Loss: 0.1069
2019-10-28 15:38:21,058 Training Epoch [23/40] Iter[26/312]		Loss: 0.1064
2019-10-28 15:38:21,137 Training Epoch [23/40] Iter[27/312]		Loss: 0.1069
2019-10-28 15:38:21,216 Training Epoch [23/40] Iter[28/312]		Loss: 0.1064
2019-10-28 15:38:21,295 Training Epoch [23/40] Iter[29/312]		Loss: 0.1080
2019-10-28 15:38:21,374 Training Epoch [23/40] Iter[30/312]		Loss: 0.1070
2019-10-28 15:38:21,453 Training Epoch [23/40] Iter[31/312]		Loss: 0.1063
2019-10-28 15:38:21,532 Training Epoch [23/40] Iter[32/312]		Loss: 0.1076
2019-10-28 15:38:21,611 Training Epoch [23/40] Iter[33/312]		Loss: 0.1080
2019-10-28 15:38:21,689 Training Epoch [23/40] Iter[34/312]		Loss: 0.1075
2019-10-28 15:38:21,768 Training Epoch [23/40] Iter[35/312]		Loss: 0.1094
2019-10-28 15:38:21,847 Training Epoch [23/40] Iter[36/312]		Loss: 0.1103
2019-10-28 15:38:21,926 Training Epoch [23/40] Iter[37/312]		Loss: 0.1101
2019-10-28 15:38:22,004 Training Epoch [23/40] Iter[38/312]		Loss: 0.1099
2019-10-28 15:38:22,083 Training Epoch [23/40] Iter[39/312]		Loss: 0.1110
2019-10-28 15:38:22,162 Training Epoch [23/40] Iter[40/312]		Loss: 0.1123
2019-10-28 15:38:22,241 Training Epoch [23/40] Iter[41/312]		Loss: 0.1117
2019-10-28 15:38:22,320 Training Epoch [23/40] Iter[42/312]		Loss: 0.1111
2019-10-28 15:38:22,399 Training Epoch [23/40] Iter[43/312]		Loss: 0.1108
2019-10-28 15:38:22,478 Training Epoch [23/40] Iter[44/312]		Loss: 0.1107
2019-10-28 15:38:22,557 Training Epoch [23/40] Iter[45/312]		Loss: 0.1125
2019-10-28 15:38:22,636 Training Epoch [23/40] Iter[46/312]		Loss: 0.1120
2019-10-28 15:38:22,715 Training Epoch [23/40] Iter[47/312]		Loss: 0.1119
2019-10-28 15:38:22,793 Training Epoch [23/40] Iter[48/312]		Loss: 0.1116
2019-10-28 15:38:22,872 Training Epoch [23/40] Iter[49/312]		Loss: 0.1132
2019-10-28 15:38:22,951 Training Epoch [23/40] Iter[50/312]		Loss: 0.1137
2019-10-28 15:38:23,030 Training Epoch [23/40] Iter[51/312]		Loss: 0.1140
2019-10-28 15:38:23,109 Training Epoch [23/40] Iter[52/312]		Loss: 0.1142
2019-10-28 15:38:23,190 Training Epoch [23/40] Iter[53/312]		Loss: 0.1136
2019-10-28 15:38:23,269 Training Epoch [23/40] Iter[54/312]		Loss: 0.1143
2019-10-28 15:38:23,350 Training Epoch [23/40] Iter[55/312]		Loss: 0.1146
2019-10-28 15:38:23,429 Training Epoch [23/40] Iter[56/312]		Loss: 0.1145
2019-10-28 15:38:23,509 Training Epoch [23/40] Iter[57/312]		Loss: 0.1147
2019-10-28 15:38:23,588 Training Epoch [23/40] Iter[58/312]		Loss: 0.1143
2019-10-28 15:38:23,670 Training Epoch [23/40] Iter[59/312]		Loss: 0.1141
2019-10-28 15:38:23,749 Training Epoch [23/40] Iter[60/312]		Loss: 0.1134
2019-10-28 15:38:23,828 Training Epoch [23/40] Iter[61/312]		Loss: 0.1137
2019-10-28 15:38:23,907 Training Epoch [23/40] Iter[62/312]		Loss: 0.1133
2019-10-28 15:38:23,990 Training Epoch [23/40] Iter[63/312]		Loss: 0.1135
2019-10-28 15:38:24,069 Training Epoch [23/40] Iter[64/312]		Loss: 0.1131
2019-10-28 15:38:24,148 Training Epoch [23/40] Iter[65/312]		Loss: 0.1144
2019-10-28 15:38:24,227 Training Epoch [23/40] Iter[66/312]		Loss: 0.1157
2019-10-28 15:38:24,306 Training Epoch [23/40] Iter[67/312]		Loss: 0.1156
2019-10-28 15:38:24,386 Training Epoch [23/40] Iter[68/312]		Loss: 0.1153
2019-10-28 15:38:24,465 Training Epoch [23/40] Iter[69/312]		Loss: 0.1151
2019-10-28 15:38:24,543 Training Epoch [23/40] Iter[70/312]		Loss: 0.1157
2019-10-28 15:38:24,622 Training Epoch [23/40] Iter[71/312]		Loss: 0.1159
2019-10-28 15:38:24,701 Training Epoch [23/40] Iter[72/312]		Loss: 0.1161
2019-10-28 15:38:24,780 Training Epoch [23/40] Iter[73/312]		Loss: 0.1157
2019-10-28 15:38:24,859 Training Epoch [23/40] Iter[74/312]		Loss: 0.1154
2019-10-28 15:38:24,938 Training Epoch [23/40] Iter[75/312]		Loss: 0.1149
2019-10-28 15:38:25,016 Training Epoch [23/40] Iter[76/312]		Loss: 0.1155
2019-10-28 15:38:25,095 Training Epoch [23/40] Iter[77/312]		Loss: 0.1155
2019-10-28 15:38:25,175 Training Epoch [23/40] Iter[78/312]		Loss: 0.1158
2019-10-28 15:38:25,254 Training Epoch [23/40] Iter[79/312]		Loss: 0.1157
2019-10-28 15:38:25,333 Training Epoch [23/40] Iter[80/312]		Loss: 0.1152
2019-10-28 15:38:25,412 Training Epoch [23/40] Iter[81/312]		Loss: 0.1149
2019-10-28 15:38:25,491 Training Epoch [23/40] Iter[82/312]		Loss: 0.1149
2019-10-28 15:38:25,570 Training Epoch [23/40] Iter[83/312]		Loss: 0.1156
2019-10-28 15:38:25,648 Training Epoch [23/40] Iter[84/312]		Loss: 0.1162
2019-10-28 15:38:25,727 Training Epoch [23/40] Iter[85/312]		Loss: 0.1164
2019-10-28 15:38:25,806 Training Epoch [23/40] Iter[86/312]		Loss: 0.1162
2019-10-28 15:38:25,885 Training Epoch [23/40] Iter[87/312]		Loss: 0.1157
2019-10-28 15:38:25,964 Training Epoch [23/40] Iter[88/312]		Loss: 0.1172
2019-10-28 15:38:26,043 Training Epoch [23/40] Iter[89/312]		Loss: 0.1176
2019-10-28 15:38:26,122 Training Epoch [23/40] Iter[90/312]		Loss: 0.1174
2019-10-28 15:38:26,201 Training Epoch [23/40] Iter[91/312]		Loss: 0.1174
2019-10-28 15:38:26,280 Training Epoch [23/40] Iter[92/312]		Loss: 0.1176
2019-10-28 15:38:26,359 Training Epoch [23/40] Iter[93/312]		Loss: 0.1174
2019-10-28 15:38:26,438 Training Epoch [23/40] Iter[94/312]		Loss: 0.1172
2019-10-28 15:38:26,519 Training Epoch [23/40] Iter[95/312]		Loss: 0.1170
2019-10-28 15:38:26,597 Training Epoch [23/40] Iter[96/312]		Loss: 0.1168
2019-10-28 15:38:26,679 Training Epoch [23/40] Iter[97/312]		Loss: 0.1175
2019-10-28 15:38:26,757 Training Epoch [23/40] Iter[98/312]		Loss: 0.1176
2019-10-28 15:38:26,836 Training Epoch [23/40] Iter[99/312]		Loss: 0.1177
2019-10-28 15:38:26,916 Training Epoch [23/40] Iter[100/312]		Loss: 0.1173
2019-10-28 15:38:26,995 Training Epoch [23/40] Iter[101/312]		Loss: 0.1169
2019-10-28 15:38:27,074 Training Epoch [23/40] Iter[102/312]		Loss: 0.1168
2019-10-28 15:38:27,153 Training Epoch [23/40] Iter[103/312]		Loss: 0.1165
2019-10-28 15:38:27,232 Training Epoch [23/40] Iter[104/312]		Loss: 0.1164
2019-10-28 15:38:27,311 Training Epoch [23/40] Iter[105/312]		Loss: 0.1158
2019-10-28 15:38:27,390 Training Epoch [23/40] Iter[106/312]		Loss: 0.1154
2019-10-28 15:38:27,469 Training Epoch [23/40] Iter[107/312]		Loss: 0.1155
2019-10-28 15:38:27,548 Training Epoch [23/40] Iter[108/312]		Loss: 0.1155
2019-10-28 15:38:27,627 Training Epoch [23/40] Iter[109/312]		Loss: 0.1157
2019-10-28 15:38:27,707 Training Epoch [23/40] Iter[110/312]		Loss: 0.1154
2019-10-28 15:38:27,785 Training Epoch [23/40] Iter[111/312]		Loss: 0.1152
2019-10-28 15:38:27,864 Training Epoch [23/40] Iter[112/312]		Loss: 0.1151
2019-10-28 15:38:27,943 Training Epoch [23/40] Iter[113/312]		Loss: 0.1150
2019-10-28 15:38:28,021 Training Epoch [23/40] Iter[114/312]		Loss: 0.1153
2019-10-28 15:38:28,100 Training Epoch [23/40] Iter[115/312]		Loss: 0.1155
2019-10-28 15:38:28,179 Training Epoch [23/40] Iter[116/312]		Loss: 0.1158
2019-10-28 15:38:28,258 Training Epoch [23/40] Iter[117/312]		Loss: 0.1158
2019-10-28 15:38:28,337 Training Epoch [23/40] Iter[118/312]		Loss: 0.1155
2019-10-28 15:38:28,418 Training Epoch [23/40] Iter[119/312]		Loss: 0.1153
2019-10-28 15:38:28,497 Training Epoch [23/40] Iter[120/312]		Loss: 0.1150
2019-10-28 15:38:28,577 Training Epoch [23/40] Iter[121/312]		Loss: 0.1151
2019-10-28 15:38:28,656 Training Epoch [23/40] Iter[122/312]		Loss: 0.1154
2019-10-28 15:38:28,735 Training Epoch [23/40] Iter[123/312]		Loss: 0.1152
2019-10-28 15:38:28,814 Training Epoch [23/40] Iter[124/312]		Loss: 0.1151
2019-10-28 15:38:28,893 Training Epoch [23/40] Iter[125/312]		Loss: 0.1152
2019-10-28 15:38:28,973 Training Epoch [23/40] Iter[126/312]		Loss: 0.1152
2019-10-28 15:38:29,052 Training Epoch [23/40] Iter[127/312]		Loss: 0.1150
2019-10-28 15:38:29,131 Training Epoch [23/40] Iter[128/312]		Loss: 0.1152
2019-10-28 15:38:29,210 Training Epoch [23/40] Iter[129/312]		Loss: 0.1149
2019-10-28 15:38:29,289 Training Epoch [23/40] Iter[130/312]		Loss: 0.1148
2019-10-28 15:38:29,368 Training Epoch [23/40] Iter[131/312]		Loss: 0.1144
2019-10-28 15:38:29,447 Training Epoch [23/40] Iter[132/312]		Loss: 0.1145
2019-10-28 15:38:29,526 Training Epoch [23/40] Iter[133/312]		Loss: 0.1146
2019-10-28 15:38:29,605 Training Epoch [23/40] Iter[134/312]		Loss: 0.1145
2019-10-28 15:38:29,684 Training Epoch [23/40] Iter[135/312]		Loss: 0.1145
2019-10-28 15:38:29,763 Training Epoch [23/40] Iter[136/312]		Loss: 0.1143
2019-10-28 15:38:29,842 Training Epoch [23/40] Iter[137/312]		Loss: 0.1145
2019-10-28 15:38:29,921 Training Epoch [23/40] Iter[138/312]		Loss: 0.1144
2019-10-28 15:38:30,000 Training Epoch [23/40] Iter[139/312]		Loss: 0.1141
2019-10-28 15:38:30,079 Training Epoch [23/40] Iter[140/312]		Loss: 0.1140
2019-10-28 15:38:30,158 Training Epoch [23/40] Iter[141/312]		Loss: 0.1140
2019-10-28 15:38:30,237 Training Epoch [23/40] Iter[142/312]		Loss: 0.1140
2019-10-28 15:38:30,316 Training Epoch [23/40] Iter[143/312]		Loss: 0.1136
2019-10-28 15:38:30,395 Training Epoch [23/40] Iter[144/312]		Loss: 0.1141
2019-10-28 15:38:30,475 Training Epoch [23/40] Iter[145/312]		Loss: 0.1141
2019-10-28 15:38:30,554 Training Epoch [23/40] Iter[146/312]		Loss: 0.1141
2019-10-28 15:38:30,633 Training Epoch [23/40] Iter[147/312]		Loss: 0.1142
2019-10-28 15:38:30,712 Training Epoch [23/40] Iter[148/312]		Loss: 0.1139
2019-10-28 15:38:30,791 Training Epoch [23/40] Iter[149/312]		Loss: 0.1137
2019-10-28 15:38:30,870 Training Epoch [23/40] Iter[150/312]		Loss: 0.1134
2019-10-28 15:38:30,949 Training Epoch [23/40] Iter[151/312]		Loss: 0.1133
2019-10-28 15:38:31,028 Training Epoch [23/40] Iter[152/312]		Loss: 0.1136
2019-10-28 15:38:31,107 Training Epoch [23/40] Iter[153/312]		Loss: 0.1135
2019-10-28 15:38:31,186 Training Epoch [23/40] Iter[154/312]		Loss: 0.1134
2019-10-28 15:38:31,265 Training Epoch [23/40] Iter[155/312]		Loss: 0.1132
2019-10-28 15:38:31,344 Training Epoch [23/40] Iter[156/312]		Loss: 0.1132
2019-10-28 15:38:31,423 Training Epoch [23/40] Iter[157/312]		Loss: 0.1130
2019-10-28 15:38:31,503 Training Epoch [23/40] Iter[158/312]		Loss: 0.1130
2019-10-28 15:38:31,582 Training Epoch [23/40] Iter[159/312]		Loss: 0.1133
2019-10-28 15:38:31,661 Training Epoch [23/40] Iter[160/312]		Loss: 0.1134
2019-10-28 15:38:31,740 Training Epoch [23/40] Iter[161/312]		Loss: 0.1133
2019-10-28 15:38:31,823 Training Epoch [23/40] Iter[162/312]		Loss: 0.1134
2019-10-28 15:38:31,901 Training Epoch [23/40] Iter[163/312]		Loss: 0.1138
2019-10-28 15:38:31,980 Training Epoch [23/40] Iter[164/312]		Loss: 0.1145
2019-10-28 15:38:32,059 Training Epoch [23/40] Iter[165/312]		Loss: 0.1144
2019-10-28 15:38:32,138 Training Epoch [23/40] Iter[166/312]		Loss: 0.1142
2019-10-28 15:38:32,217 Training Epoch [23/40] Iter[167/312]		Loss: 0.1141
2019-10-28 15:38:32,296 Training Epoch [23/40] Iter[168/312]		Loss: 0.1142
2019-10-28 15:38:32,375 Training Epoch [23/40] Iter[169/312]		Loss: 0.1140
2019-10-28 15:38:32,454 Training Epoch [23/40] Iter[170/312]		Loss: 0.1142
2019-10-28 15:38:32,533 Training Epoch [23/40] Iter[171/312]		Loss: 0.1144
2019-10-28 15:38:32,612 Training Epoch [23/40] Iter[172/312]		Loss: 0.1153
2019-10-28 15:38:32,691 Training Epoch [23/40] Iter[173/312]		Loss: 0.1151
2019-10-28 15:38:32,770 Training Epoch [23/40] Iter[174/312]		Loss: 0.1150
2019-10-28 15:38:32,849 Training Epoch [23/40] Iter[175/312]		Loss: 0.1151
2019-10-28 15:38:32,928 Training Epoch [23/40] Iter[176/312]		Loss: 0.1150
2019-10-28 15:38:33,007 Training Epoch [23/40] Iter[177/312]		Loss: 0.1151
2019-10-28 15:38:33,086 Training Epoch [23/40] Iter[178/312]		Loss: 0.1150
2019-10-28 15:38:33,165 Training Epoch [23/40] Iter[179/312]		Loss: 0.1147
2019-10-28 15:38:33,244 Training Epoch [23/40] Iter[180/312]		Loss: 0.1149
2019-10-28 15:38:33,323 Training Epoch [23/40] Iter[181/312]		Loss: 0.1150
2019-10-28 15:38:33,402 Training Epoch [23/40] Iter[182/312]		Loss: 0.1147
2019-10-28 15:38:33,481 Training Epoch [23/40] Iter[183/312]		Loss: 0.1148
2019-10-28 15:38:33,561 Training Epoch [23/40] Iter[184/312]		Loss: 0.1147
2019-10-28 15:38:33,640 Training Epoch [23/40] Iter[185/312]		Loss: 0.1147
2019-10-28 15:38:33,719 Training Epoch [23/40] Iter[186/312]		Loss: 0.1145
2019-10-28 15:38:33,798 Training Epoch [23/40] Iter[187/312]		Loss: 0.1144
2019-10-28 15:38:33,877 Training Epoch [23/40] Iter[188/312]		Loss: 0.1143
2019-10-28 15:38:33,956 Training Epoch [23/40] Iter[189/312]		Loss: 0.1141
2019-10-28 15:38:34,035 Training Epoch [23/40] Iter[190/312]		Loss: 0.1139
2019-10-28 15:38:34,114 Training Epoch [23/40] Iter[191/312]		Loss: 0.1138
2019-10-28 15:38:34,194 Training Epoch [23/40] Iter[192/312]		Loss: 0.1141
2019-10-28 15:38:34,273 Training Epoch [23/40] Iter[193/312]		Loss: 0.1141
2019-10-28 15:38:34,352 Training Epoch [23/40] Iter[194/312]		Loss: 0.1143
2019-10-28 15:38:34,431 Training Epoch [23/40] Iter[195/312]		Loss: 0.1144
2019-10-28 15:38:34,510 Training Epoch [23/40] Iter[196/312]		Loss: 0.1146
2019-10-28 15:38:34,589 Training Epoch [23/40] Iter[197/312]		Loss: 0.1146
2019-10-28 15:38:34,668 Training Epoch [23/40] Iter[198/312]		Loss: 0.1150
2019-10-28 15:38:34,747 Training Epoch [23/40] Iter[199/312]		Loss: 0.1149
2019-10-28 15:38:34,826 Training Epoch [23/40] Iter[200/312]		Loss: 0.1150
2019-10-28 15:38:34,904 Training Epoch [23/40] Iter[201/312]		Loss: 0.1153
2019-10-28 15:38:34,983 Training Epoch [23/40] Iter[202/312]		Loss: 0.1151
2019-10-28 15:38:35,063 Training Epoch [23/40] Iter[203/312]		Loss: 0.1150
2019-10-28 15:38:35,142 Training Epoch [23/40] Iter[204/312]		Loss: 0.1151
2019-10-28 15:38:35,221 Training Epoch [23/40] Iter[205/312]		Loss: 0.1151
2019-10-28 15:38:35,300 Training Epoch [23/40] Iter[206/312]		Loss: 0.1154
2019-10-28 15:38:35,379 Training Epoch [23/40] Iter[207/312]		Loss: 0.1160
2019-10-28 15:38:35,459 Training Epoch [23/40] Iter[208/312]		Loss: 0.1164
2019-10-28 15:38:35,537 Training Epoch [23/40] Iter[209/312]		Loss: 0.1163
2019-10-28 15:38:35,616 Training Epoch [23/40] Iter[210/312]		Loss: 0.1164
2019-10-28 15:38:35,696 Training Epoch [23/40] Iter[211/312]		Loss: 0.1167
2019-10-28 15:38:35,775 Training Epoch [23/40] Iter[212/312]		Loss: 0.1169
2019-10-28 15:38:35,854 Training Epoch [23/40] Iter[213/312]		Loss: 0.1168
2019-10-28 15:38:35,932 Training Epoch [23/40] Iter[214/312]		Loss: 0.1167
2019-10-28 15:38:36,011 Training Epoch [23/40] Iter[215/312]		Loss: 0.1166
2019-10-28 15:38:36,090 Training Epoch [23/40] Iter[216/312]		Loss: 0.1165
2019-10-28 15:38:36,170 Training Epoch [23/40] Iter[217/312]		Loss: 0.1164
2019-10-28 15:38:36,249 Training Epoch [23/40] Iter[218/312]		Loss: 0.1163
2019-10-28 15:38:36,327 Training Epoch [23/40] Iter[219/312]		Loss: 0.1163
2019-10-28 15:38:36,434 Training Epoch [23/40] Iter[220/312]		Loss: 0.1162
2019-10-28 15:38:36,514 Training Epoch [23/40] Iter[221/312]		Loss: 0.1161
2019-10-28 15:38:36,593 Training Epoch [23/40] Iter[222/312]		Loss: 0.1160
2019-10-28 15:38:36,672 Training Epoch [23/40] Iter[223/312]		Loss: 0.1159
2019-10-28 15:38:36,751 Training Epoch [23/40] Iter[224/312]		Loss: 0.1158
2019-10-28 15:38:36,829 Training Epoch [23/40] Iter[225/312]		Loss: 0.1161
2019-10-28 15:38:36,908 Training Epoch [23/40] Iter[226/312]		Loss: 0.1160
2019-10-28 15:38:36,987 Training Epoch [23/40] Iter[227/312]		Loss: 0.1159
2019-10-28 15:38:37,067 Training Epoch [23/40] Iter[228/312]		Loss: 0.1158
2019-10-28 15:38:37,146 Training Epoch [23/40] Iter[229/312]		Loss: 0.1156
2019-10-28 15:38:37,226 Training Epoch [23/40] Iter[230/312]		Loss: 0.1155
2019-10-28 15:38:37,305 Training Epoch [23/40] Iter[231/312]		Loss: 0.1155
2019-10-28 15:38:37,384 Training Epoch [23/40] Iter[232/312]		Loss: 0.1155
2019-10-28 15:38:37,463 Training Epoch [23/40] Iter[233/312]		Loss: 0.1153
2019-10-28 15:38:37,542 Training Epoch [23/40] Iter[234/312]		Loss: 0.1152
2019-10-28 15:38:37,621 Training Epoch [23/40] Iter[235/312]		Loss: 0.1150
2019-10-28 15:38:37,700 Training Epoch [23/40] Iter[236/312]		Loss: 0.1153
2019-10-28 15:38:37,779 Training Epoch [23/40] Iter[237/312]		Loss: 0.1153
2019-10-28 15:38:37,858 Training Epoch [23/40] Iter[238/312]		Loss: 0.1153
2019-10-28 15:38:37,937 Training Epoch [23/40] Iter[239/312]		Loss: 0.1152
2019-10-28 15:38:38,016 Training Epoch [23/40] Iter[240/312]		Loss: 0.1150
2019-10-28 15:38:38,096 Training Epoch [23/40] Iter[241/312]		Loss: 0.1154
2019-10-28 15:38:38,174 Training Epoch [23/40] Iter[242/312]		Loss: 0.1155
2019-10-28 15:38:38,253 Training Epoch [23/40] Iter[243/312]		Loss: 0.1153
2019-10-28 15:38:38,332 Training Epoch [23/40] Iter[244/312]		Loss: 0.1152
2019-10-28 15:38:38,412 Training Epoch [23/40] Iter[245/312]		Loss: 0.1151
2019-10-28 15:38:38,491 Training Epoch [23/40] Iter[246/312]		Loss: 0.1150
2019-10-28 15:38:38,569 Training Epoch [23/40] Iter[247/312]		Loss: 0.1151
2019-10-28 15:38:38,648 Training Epoch [23/40] Iter[248/312]		Loss: 0.1151
2019-10-28 15:38:38,727 Training Epoch [23/40] Iter[249/312]		Loss: 0.1150
2019-10-28 15:38:38,806 Training Epoch [23/40] Iter[250/312]		Loss: 0.1156
2019-10-28 15:38:38,885 Training Epoch [23/40] Iter[251/312]		Loss: 0.1155
2019-10-28 15:38:38,964 Training Epoch [23/40] Iter[252/312]		Loss: 0.1154
2019-10-28 15:38:39,043 Training Epoch [23/40] Iter[253/312]		Loss: 0.1153
2019-10-28 15:38:39,122 Training Epoch [23/40] Iter[254/312]		Loss: 0.1152
2019-10-28 15:38:39,201 Training Epoch [23/40] Iter[255/312]		Loss: 0.1155
2019-10-28 15:38:39,280 Training Epoch [23/40] Iter[256/312]		Loss: 0.1154
2019-10-28 15:38:39,359 Training Epoch [23/40] Iter[257/312]		Loss: 0.1156
2019-10-28 15:38:39,438 Training Epoch [23/40] Iter[258/312]		Loss: 0.1156
2019-10-28 15:38:39,517 Training Epoch [23/40] Iter[259/312]		Loss: 0.1154
2019-10-28 15:38:39,596 Training Epoch [23/40] Iter[260/312]		Loss: 0.1155
2019-10-28 15:38:39,676 Training Epoch [23/40] Iter[261/312]		Loss: 0.1155
2019-10-28 15:38:39,755 Training Epoch [23/40] Iter[262/312]		Loss: 0.1156
2019-10-28 15:38:39,834 Training Epoch [23/40] Iter[263/312]		Loss: 0.1155
2019-10-28 15:38:39,913 Training Epoch [23/40] Iter[264/312]		Loss: 0.1156
2019-10-28 15:38:39,992 Training Epoch [23/40] Iter[265/312]		Loss: 0.1156
2019-10-28 15:38:40,071 Training Epoch [23/40] Iter[266/312]		Loss: 0.1155
2019-10-28 15:38:40,150 Training Epoch [23/40] Iter[267/312]		Loss: 0.1155
2019-10-28 15:38:40,230 Training Epoch [23/40] Iter[268/312]		Loss: 0.1156
2019-10-28 15:38:40,308 Training Epoch [23/40] Iter[269/312]		Loss: 0.1155
2019-10-28 15:38:40,388 Training Epoch [23/40] Iter[270/312]		Loss: 0.1154
2019-10-28 15:38:40,467 Training Epoch [23/40] Iter[271/312]		Loss: 0.1155
2019-10-28 15:38:40,546 Training Epoch [23/40] Iter[272/312]		Loss: 0.1159
2019-10-28 15:38:40,625 Training Epoch [23/40] Iter[273/312]		Loss: 0.1157
2019-10-28 15:38:40,703 Training Epoch [23/40] Iter[274/312]		Loss: 0.1156
2019-10-28 15:38:40,783 Training Epoch [23/40] Iter[275/312]		Loss: 0.1157
2019-10-28 15:38:40,861 Training Epoch [23/40] Iter[276/312]		Loss: 0.1157
2019-10-28 15:38:40,940 Training Epoch [23/40] Iter[277/312]		Loss: 0.1157
2019-10-28 15:38:41,019 Training Epoch [23/40] Iter[278/312]		Loss: 0.1155
2019-10-28 15:38:41,098 Training Epoch [23/40] Iter[279/312]		Loss: 0.1158
2019-10-28 15:38:41,177 Training Epoch [23/40] Iter[280/312]		Loss: 0.1157
2019-10-28 15:38:41,256 Training Epoch [23/40] Iter[281/312]		Loss: 0.1156
2019-10-28 15:38:41,335 Training Epoch [23/40] Iter[282/312]		Loss: 0.1155
2019-10-28 15:38:41,414 Training Epoch [23/40] Iter[283/312]		Loss: 0.1158
2019-10-28 15:38:41,493 Training Epoch [23/40] Iter[284/312]		Loss: 0.1157
2019-10-28 15:38:41,573 Training Epoch [23/40] Iter[285/312]		Loss: 0.1156
2019-10-28 15:38:41,652 Training Epoch [23/40] Iter[286/312]		Loss: 0.1156
2019-10-28 15:38:41,731 Training Epoch [23/40] Iter[287/312]		Loss: 0.1156
2019-10-28 15:38:41,809 Training Epoch [23/40] Iter[288/312]		Loss: 0.1157
2019-10-28 15:38:41,888 Training Epoch [23/40] Iter[289/312]		Loss: 0.1157
2019-10-28 15:38:41,967 Training Epoch [23/40] Iter[290/312]		Loss: 0.1158
2019-10-28 15:38:42,046 Training Epoch [23/40] Iter[291/312]		Loss: 0.1158
2019-10-28 15:38:42,125 Training Epoch [23/40] Iter[292/312]		Loss: 0.1159
2019-10-28 15:38:42,205 Training Epoch [23/40] Iter[293/312]		Loss: 0.1158
2019-10-28 15:38:42,284 Training Epoch [23/40] Iter[294/312]		Loss: 0.1156
2019-10-28 15:38:42,364 Training Epoch [23/40] Iter[295/312]		Loss: 0.1156
2019-10-28 15:38:42,443 Training Epoch [23/40] Iter[296/312]		Loss: 0.1156
2019-10-28 15:38:42,523 Training Epoch [23/40] Iter[297/312]		Loss: 0.1156
2019-10-28 15:38:42,602 Training Epoch [23/40] Iter[298/312]		Loss: 0.1154
2019-10-28 15:38:42,682 Training Epoch [23/40] Iter[299/312]		Loss: 0.1154
2019-10-28 15:38:42,761 Training Epoch [23/40] Iter[300/312]		Loss: 0.1153
2019-10-28 15:38:42,840 Training Epoch [23/40] Iter[301/312]		Loss: 0.1155
2019-10-28 15:38:42,920 Training Epoch [23/40] Iter[302/312]		Loss: 0.1156
2019-10-28 15:38:42,999 Training Epoch [23/40] Iter[303/312]		Loss: 0.1154
2019-10-28 15:38:43,079 Training Epoch [23/40] Iter[304/312]		Loss: 0.1154
2019-10-28 15:38:43,158 Training Epoch [23/40] Iter[305/312]		Loss: 0.1153
2019-10-28 15:38:43,237 Training Epoch [23/40] Iter[306/312]		Loss: 0.1156
2019-10-28 15:38:43,315 Training Epoch [23/40] Iter[307/312]		Loss: 0.1157
2019-10-28 15:38:43,394 Training Epoch [23/40] Iter[308/312]		Loss: 0.1158
2019-10-28 15:38:43,472 Training Epoch [23/40] Iter[309/312]		Loss: 0.1159
2019-10-28 15:38:43,550 Training Epoch [23/40] Iter[310/312]		Loss: 0.1158
2019-10-28 15:38:43,629 Training Epoch [23/40] Iter[311/312]		Loss: 0.1157
2019-10-28 15:38:43,667 Training Epoch [23/40] Iter[312/312]		Loss: 0.1156
2019-10-28 15:38:44,082 Testing Epoch [23/40] Iter[0/62]		Loss: 0.1320
2019-10-28 15:38:44,123 Testing Epoch [23/40] Iter[1/62]		Loss: 0.1292
2019-10-28 15:38:44,143 Testing Epoch [23/40] Iter[2/62]		Loss: 0.1123
2019-10-28 15:38:44,165 Testing Epoch [23/40] Iter[3/62]		Loss: 0.1169
2019-10-28 15:38:44,190 Testing Epoch [23/40] Iter[4/62]		Loss: 0.1209
2019-10-28 15:38:44,211 Testing Epoch [23/40] Iter[5/62]		Loss: 0.1160
2019-10-28 15:38:44,229 Testing Epoch [23/40] Iter[6/62]		Loss: 0.1181
2019-10-28 15:38:44,258 Testing Epoch [23/40] Iter[7/62]		Loss: 0.1204
2019-10-28 15:38:44,285 Testing Epoch [23/40] Iter[8/62]		Loss: 0.1228
2019-10-28 15:38:44,309 Testing Epoch [23/40] Iter[9/62]		Loss: 0.1215
2019-10-28 15:38:44,326 Testing Epoch [23/40] Iter[10/62]		Loss: 0.1228
2019-10-28 15:38:44,353 Testing Epoch [23/40] Iter[11/62]		Loss: 0.1290
2019-10-28 15:38:44,371 Testing Epoch [23/40] Iter[12/62]		Loss: 0.1290
2019-10-28 15:38:44,404 Testing Epoch [23/40] Iter[13/62]		Loss: 0.1309
2019-10-28 15:38:44,423 Testing Epoch [23/40] Iter[14/62]		Loss: 0.1436
2019-10-28 15:38:44,439 Testing Epoch [23/40] Iter[15/62]		Loss: 0.1456
2019-10-28 15:38:44,469 Testing Epoch [23/40] Iter[16/62]		Loss: 0.1426
2019-10-28 15:38:44,493 Testing Epoch [23/40] Iter[17/62]		Loss: 0.1428
2019-10-28 15:38:44,511 Testing Epoch [23/40] Iter[18/62]		Loss: 0.1403
2019-10-28 15:38:44,529 Testing Epoch [23/40] Iter[19/62]		Loss: 0.1382
2019-10-28 15:38:44,557 Testing Epoch [23/40] Iter[20/62]		Loss: 0.1400
2019-10-28 15:38:44,581 Testing Epoch [23/40] Iter[21/62]		Loss: 0.1383
2019-10-28 15:38:44,605 Testing Epoch [23/40] Iter[22/62]		Loss: 0.1399
2019-10-28 15:38:44,629 Testing Epoch [23/40] Iter[23/62]		Loss: 0.1390
2019-10-28 15:38:44,647 Testing Epoch [23/40] Iter[24/62]		Loss: 0.1427
2019-10-28 15:38:44,673 Testing Epoch [23/40] Iter[25/62]		Loss: 0.1418
2019-10-28 15:38:44,691 Testing Epoch [23/40] Iter[26/62]		Loss: 0.1406
2019-10-28 15:38:44,708 Testing Epoch [23/40] Iter[27/62]		Loss: 0.1483
2019-10-28 15:38:44,731 Testing Epoch [23/40] Iter[28/62]		Loss: 0.1518
2019-10-28 15:38:44,749 Testing Epoch [23/40] Iter[29/62]		Loss: 0.1518
2019-10-28 15:38:44,778 Testing Epoch [23/40] Iter[30/62]		Loss: 0.1519
2019-10-28 15:38:44,798 Testing Epoch [23/40] Iter[31/62]		Loss: 0.1509
2019-10-28 15:38:44,816 Testing Epoch [23/40] Iter[32/62]		Loss: 0.1527
2019-10-28 15:38:44,833 Testing Epoch [23/40] Iter[33/62]		Loss: 0.1515
2019-10-28 15:38:44,862 Testing Epoch [23/40] Iter[34/62]		Loss: 0.1537
2019-10-28 15:38:44,880 Testing Epoch [23/40] Iter[35/62]		Loss: 0.1532
2019-10-28 15:38:44,898 Testing Epoch [23/40] Iter[36/62]		Loss: 0.1512
2019-10-28 15:38:44,925 Testing Epoch [23/40] Iter[37/62]		Loss: 0.1500
2019-10-28 15:38:44,949 Testing Epoch [23/40] Iter[38/62]		Loss: 0.1489
2019-10-28 15:38:44,967 Testing Epoch [23/40] Iter[39/62]		Loss: 0.1492
2019-10-28 15:38:44,985 Testing Epoch [23/40] Iter[40/62]		Loss: 0.1509
2019-10-28 15:38:45,017 Testing Epoch [23/40] Iter[41/62]		Loss: 0.1525
2019-10-28 15:38:45,035 Testing Epoch [23/40] Iter[42/62]		Loss: 0.1505
2019-10-28 15:38:45,061 Testing Epoch [23/40] Iter[43/62]		Loss: 0.1499
2019-10-28 15:38:45,079 Testing Epoch [23/40] Iter[44/62]		Loss: 0.1483
2019-10-28 15:38:45,105 Testing Epoch [23/40] Iter[45/62]		Loss: 0.1482
2019-10-28 15:38:45,122 Testing Epoch [23/40] Iter[46/62]		Loss: 0.1481
2019-10-28 15:38:45,154 Testing Epoch [23/40] Iter[47/62]		Loss: 0.1540
2019-10-28 15:38:45,174 Testing Epoch [23/40] Iter[48/62]		Loss: 0.1530
2019-10-28 15:38:45,201 Testing Epoch [23/40] Iter[49/62]		Loss: 0.1553
2019-10-28 15:38:45,219 Testing Epoch [23/40] Iter[50/62]		Loss: 0.1544
2019-10-28 15:38:45,236 Testing Epoch [23/40] Iter[51/62]		Loss: 0.1543
2019-10-28 15:38:45,265 Testing Epoch [23/40] Iter[52/62]		Loss: 0.1531
2019-10-28 15:38:45,283 Testing Epoch [23/40] Iter[53/62]		Loss: 0.1533
2019-10-28 15:38:45,301 Testing Epoch [23/40] Iter[54/62]		Loss: 0.1522
2019-10-28 15:38:45,318 Testing Epoch [23/40] Iter[55/62]		Loss: 0.1519
2019-10-28 15:38:45,336 Testing Epoch [23/40] Iter[56/62]		Loss: 0.1512
2019-10-28 15:38:45,352 Testing Epoch [23/40] Iter[57/62]		Loss: 0.1515
2019-10-28 15:38:45,369 Testing Epoch [23/40] Iter[58/62]		Loss: 0.1509
2019-10-28 15:38:45,385 Testing Epoch [23/40] Iter[59/62]		Loss: 0.1519
2019-10-28 15:38:45,402 Testing Epoch [23/40] Iter[60/62]		Loss: 0.1511
2019-10-28 15:38:45,419 Testing Epoch [23/40] Iter[61/62]		Loss: 0.1511
2019-10-28 15:38:45,428 Testing Epoch [23/40] Iter[62/62]		Loss: 0.1519
2019-10-28 15:38:45,499 Saving the Model
2019-10-28 15:38:45,933 Training Epoch [24/40] Iter[0/312]		Loss: 0.1187
2019-10-28 15:38:46,011 Training Epoch [24/40] Iter[1/312]		Loss: 0.1084
2019-10-28 15:38:46,090 Training Epoch [24/40] Iter[2/312]		Loss: 0.1060
2019-10-28 15:38:46,172 Training Epoch [24/40] Iter[3/312]		Loss: 0.1057
2019-10-28 15:38:46,250 Training Epoch [24/40] Iter[4/312]		Loss: 0.1000
2019-10-28 15:38:46,328 Training Epoch [24/40] Iter[5/312]		Loss: 0.0970
2019-10-28 15:38:46,406 Training Epoch [24/40] Iter[6/312]		Loss: 0.1054
2019-10-28 15:38:46,486 Training Epoch [24/40] Iter[7/312]		Loss: 0.1055
2019-10-28 15:38:46,564 Training Epoch [24/40] Iter[8/312]		Loss: 0.1121
2019-10-28 15:38:46,643 Training Epoch [24/40] Iter[9/312]		Loss: 0.1122
2019-10-28 15:38:46,722 Training Epoch [24/40] Iter[10/312]		Loss: 0.1099
2019-10-28 15:38:46,801 Training Epoch [24/40] Iter[11/312]		Loss: 0.1146
2019-10-28 15:38:46,880 Training Epoch [24/40] Iter[12/312]		Loss: 0.1119
2019-10-28 15:38:46,958 Training Epoch [24/40] Iter[13/312]		Loss: 0.1133
2019-10-28 15:38:47,037 Training Epoch [24/40] Iter[14/312]		Loss: 0.1181
2019-10-28 15:38:47,116 Training Epoch [24/40] Iter[15/312]		Loss: 0.1189
2019-10-28 15:38:47,195 Training Epoch [24/40] Iter[16/312]		Loss: 0.1171
2019-10-28 15:38:47,274 Training Epoch [24/40] Iter[17/312]		Loss: 0.1149
2019-10-28 15:38:47,353 Training Epoch [24/40] Iter[18/312]		Loss: 0.1145
2019-10-28 15:38:47,432 Training Epoch [24/40] Iter[19/312]		Loss: 0.1154
2019-10-28 15:38:47,512 Training Epoch [24/40] Iter[20/312]		Loss: 0.1134
2019-10-28 15:38:47,590 Training Epoch [24/40] Iter[21/312]		Loss: 0.1123
2019-10-28 15:38:47,669 Training Epoch [24/40] Iter[22/312]		Loss: 0.1129
2019-10-28 15:38:47,748 Training Epoch [24/40] Iter[23/312]		Loss: 0.1113
2019-10-28 15:38:47,827 Training Epoch [24/40] Iter[24/312]		Loss: 0.1110
2019-10-28 15:38:47,910 Training Epoch [24/40] Iter[25/312]		Loss: 0.1113
2019-10-28 15:38:47,989 Training Epoch [24/40] Iter[26/312]		Loss: 0.1101
2019-10-28 15:38:48,068 Training Epoch [24/40] Iter[27/312]		Loss: 0.1091
2019-10-28 15:38:48,147 Training Epoch [24/40] Iter[28/312]		Loss: 0.1144
2019-10-28 15:38:48,226 Training Epoch [24/40] Iter[29/312]		Loss: 0.1149
2019-10-28 15:38:48,305 Training Epoch [24/40] Iter[30/312]		Loss: 0.1149
2019-10-28 15:38:48,384 Training Epoch [24/40] Iter[31/312]		Loss: 0.1148
2019-10-28 15:38:48,463 Training Epoch [24/40] Iter[32/312]		Loss: 0.1172
2019-10-28 15:38:48,542 Training Epoch [24/40] Iter[33/312]		Loss: 0.1160
2019-10-28 15:38:48,621 Training Epoch [24/40] Iter[34/312]		Loss: 0.1151
2019-10-28 15:38:48,700 Training Epoch [24/40] Iter[35/312]		Loss: 0.1147
2019-10-28 15:38:48,778 Training Epoch [24/40] Iter[36/312]		Loss: 0.1148
2019-10-28 15:38:48,857 Training Epoch [24/40] Iter[37/312]		Loss: 0.1172
2019-10-28 15:38:48,936 Training Epoch [24/40] Iter[38/312]		Loss: 0.1189
2019-10-28 15:38:49,015 Training Epoch [24/40] Iter[39/312]		Loss: 0.1184
2019-10-28 15:38:49,094 Training Epoch [24/40] Iter[40/312]		Loss: 0.1175
2019-10-28 15:38:49,173 Training Epoch [24/40] Iter[41/312]		Loss: 0.1170
2019-10-28 15:38:49,252 Training Epoch [24/40] Iter[42/312]		Loss: 0.1164
2019-10-28 15:38:49,331 Training Epoch [24/40] Iter[43/312]		Loss: 0.1183
2019-10-28 15:38:49,410 Training Epoch [24/40] Iter[44/312]		Loss: 0.1176
2019-10-28 15:38:49,489 Training Epoch [24/40] Iter[45/312]		Loss: 0.1181
2019-10-28 15:38:49,568 Training Epoch [24/40] Iter[46/312]		Loss: 0.1182
2019-10-28 15:38:49,646 Training Epoch [24/40] Iter[47/312]		Loss: 0.1184
2019-10-28 15:38:49,726 Training Epoch [24/40] Iter[48/312]		Loss: 0.1178
2019-10-28 15:38:49,804 Training Epoch [24/40] Iter[49/312]		Loss: 0.1178
2019-10-28 15:38:49,883 Training Epoch [24/40] Iter[50/312]		Loss: 0.1180
2019-10-28 15:38:49,962 Training Epoch [24/40] Iter[51/312]		Loss: 0.1195
2019-10-28 15:38:50,041 Training Epoch [24/40] Iter[52/312]		Loss: 0.1187
2019-10-28 15:38:50,120 Training Epoch [24/40] Iter[53/312]		Loss: 0.1189
2019-10-28 15:38:50,199 Training Epoch [24/40] Iter[54/312]		Loss: 0.1188
2019-10-28 15:38:50,278 Training Epoch [24/40] Iter[55/312]		Loss: 0.1185
2019-10-28 15:38:50,363 Training Epoch [24/40] Iter[56/312]		Loss: 0.1186
2019-10-28 15:38:50,442 Training Epoch [24/40] Iter[57/312]		Loss: 0.1184
2019-10-28 15:38:50,521 Training Epoch [24/40] Iter[58/312]		Loss: 0.1183
2019-10-28 15:38:50,599 Training Epoch [24/40] Iter[59/312]		Loss: 0.1182
2019-10-28 15:38:50,683 Training Epoch [24/40] Iter[60/312]		Loss: 0.1180
2019-10-28 15:38:50,761 Training Epoch [24/40] Iter[61/312]		Loss: 0.1173
2019-10-28 15:38:50,840 Training Epoch [24/40] Iter[62/312]		Loss: 0.1169
2019-10-28 15:38:50,919 Training Epoch [24/40] Iter[63/312]		Loss: 0.1173
2019-10-28 15:38:51,002 Training Epoch [24/40] Iter[64/312]		Loss: 0.1171
2019-10-28 15:38:51,081 Training Epoch [24/40] Iter[65/312]		Loss: 0.1174
2019-10-28 15:38:51,160 Training Epoch [24/40] Iter[66/312]		Loss: 0.1166
2019-10-28 15:38:51,239 Training Epoch [24/40] Iter[67/312]		Loss: 0.1168
2019-10-28 15:38:51,323 Training Epoch [24/40] Iter[68/312]		Loss: 0.1168
2019-10-28 15:38:51,402 Training Epoch [24/40] Iter[69/312]		Loss: 0.1164
2019-10-28 15:38:51,481 Training Epoch [24/40] Iter[70/312]		Loss: 0.1169
2019-10-28 15:38:51,560 Training Epoch [24/40] Iter[71/312]		Loss: 0.1175
2019-10-28 15:38:51,642 Training Epoch [24/40] Iter[72/312]		Loss: 0.1178
2019-10-28 15:38:51,721 Training Epoch [24/40] Iter[73/312]		Loss: 0.1173
2019-10-28 15:38:51,800 Training Epoch [24/40] Iter[74/312]		Loss: 0.1170
2019-10-28 15:38:51,879 Training Epoch [24/40] Iter[75/312]		Loss: 0.1168
2019-10-28 15:38:51,962 Training Epoch [24/40] Iter[76/312]		Loss: 0.1169
2019-10-28 15:38:52,042 Training Epoch [24/40] Iter[77/312]		Loss: 0.1166
2019-10-28 15:38:52,121 Training Epoch [24/40] Iter[78/312]		Loss: 0.1166
2019-10-28 15:38:52,200 Training Epoch [24/40] Iter[79/312]		Loss: 0.1163
2019-10-28 15:38:52,282 Training Epoch [24/40] Iter[80/312]		Loss: 0.1159
2019-10-28 15:38:52,362 Training Epoch [24/40] Iter[81/312]		Loss: 0.1157
2019-10-28 15:38:52,441 Training Epoch [24/40] Iter[82/312]		Loss: 0.1169
2019-10-28 15:38:52,520 Training Epoch [24/40] Iter[83/312]		Loss: 0.1167
2019-10-28 15:38:52,603 Training Epoch [24/40] Iter[84/312]		Loss: 0.1163
2019-10-28 15:38:52,686 Training Epoch [24/40] Iter[85/312]		Loss: 0.1159
2019-10-28 15:38:52,765 Training Epoch [24/40] Iter[86/312]		Loss: 0.1164
2019-10-28 15:38:52,844 Training Epoch [24/40] Iter[87/312]		Loss: 0.1163
2019-10-28 15:38:52,927 Training Epoch [24/40] Iter[88/312]		Loss: 0.1162
2019-10-28 15:38:53,006 Training Epoch [24/40] Iter[89/312]		Loss: 0.1158
2019-10-28 15:38:53,085 Training Epoch [24/40] Iter[90/312]		Loss: 0.1154
2019-10-28 15:38:53,164 Training Epoch [24/40] Iter[91/312]		Loss: 0.1153
2019-10-28 15:38:53,246 Training Epoch [24/40] Iter[92/312]		Loss: 0.1148
2019-10-28 15:38:53,331 Training Epoch [24/40] Iter[93/312]		Loss: 0.1143
2019-10-28 15:38:53,410 Training Epoch [24/40] Iter[94/312]		Loss: 0.1151
2019-10-28 15:38:53,490 Training Epoch [24/40] Iter[95/312]		Loss: 0.1150
2019-10-28 15:38:53,575 Training Epoch [24/40] Iter[96/312]		Loss: 0.1163
2019-10-28 15:38:53,659 Training Epoch [24/40] Iter[97/312]		Loss: 0.1164
2019-10-28 15:38:53,738 Training Epoch [24/40] Iter[98/312]		Loss: 0.1160
2019-10-28 15:38:53,817 Training Epoch [24/40] Iter[99/312]		Loss: 0.1159
2019-10-28 15:38:53,902 Training Epoch [24/40] Iter[100/312]		Loss: 0.1161
2019-10-28 15:38:53,987 Training Epoch [24/40] Iter[101/312]		Loss: 0.1158
2019-10-28 15:38:54,066 Training Epoch [24/40] Iter[102/312]		Loss: 0.1153
2019-10-28 15:38:54,145 Training Epoch [24/40] Iter[103/312]		Loss: 0.1149
2019-10-28 15:38:54,225 Training Epoch [24/40] Iter[104/312]		Loss: 0.1150
2019-10-28 15:38:54,304 Training Epoch [24/40] Iter[105/312]		Loss: 0.1149
2019-10-28 15:38:54,383 Training Epoch [24/40] Iter[106/312]		Loss: 0.1152
2019-10-28 15:38:54,463 Training Epoch [24/40] Iter[107/312]		Loss: 0.1151
2019-10-28 15:38:54,542 Training Epoch [24/40] Iter[108/312]		Loss: 0.1151
2019-10-28 15:38:54,622 Training Epoch [24/40] Iter[109/312]		Loss: 0.1158
2019-10-28 15:38:54,701 Training Epoch [24/40] Iter[110/312]		Loss: 0.1159
2019-10-28 15:38:54,780 Training Epoch [24/40] Iter[111/312]		Loss: 0.1156
2019-10-28 15:38:54,859 Training Epoch [24/40] Iter[112/312]		Loss: 0.1153
2019-10-28 15:38:54,938 Training Epoch [24/40] Iter[113/312]		Loss: 0.1152
2019-10-28 15:38:55,018 Training Epoch [24/40] Iter[114/312]		Loss: 0.1151
2019-10-28 15:38:55,097 Training Epoch [24/40] Iter[115/312]		Loss: 0.1155
2019-10-28 15:38:55,177 Training Epoch [24/40] Iter[116/312]		Loss: 0.1156
2019-10-28 15:38:55,256 Training Epoch [24/40] Iter[117/312]		Loss: 0.1160
2019-10-28 15:38:55,335 Training Epoch [24/40] Iter[118/312]		Loss: 0.1157
2019-10-28 15:38:55,415 Training Epoch [24/40] Iter[119/312]		Loss: 0.1161
2019-10-28 15:38:55,494 Training Epoch [24/40] Iter[120/312]		Loss: 0.1158
2019-10-28 15:38:55,574 Training Epoch [24/40] Iter[121/312]		Loss: 0.1164
2019-10-28 15:38:55,653 Training Epoch [24/40] Iter[122/312]		Loss: 0.1164
2019-10-28 15:38:55,732 Training Epoch [24/40] Iter[123/312]		Loss: 0.1166
2019-10-28 15:38:55,811 Training Epoch [24/40] Iter[124/312]		Loss: 0.1162
2019-10-28 15:38:55,890 Training Epoch [24/40] Iter[125/312]		Loss: 0.1164
2019-10-28 15:38:55,970 Training Epoch [24/40] Iter[126/312]		Loss: 0.1162
2019-10-28 15:38:56,049 Training Epoch [24/40] Iter[127/312]		Loss: 0.1169
2019-10-28 15:38:56,128 Training Epoch [24/40] Iter[128/312]		Loss: 0.1167
2019-10-28 15:38:56,208 Training Epoch [24/40] Iter[129/312]		Loss: 0.1165
2019-10-28 15:38:56,288 Training Epoch [24/40] Iter[130/312]		Loss: 0.1164
2019-10-28 15:38:56,367 Training Epoch [24/40] Iter[131/312]		Loss: 0.1162
2019-10-28 15:38:56,447 Training Epoch [24/40] Iter[132/312]		Loss: 0.1165
2019-10-28 15:38:56,526 Training Epoch [24/40] Iter[133/312]		Loss: 0.1171
2019-10-28 15:38:56,605 Training Epoch [24/40] Iter[134/312]		Loss: 0.1168
2019-10-28 15:38:56,684 Training Epoch [24/40] Iter[135/312]		Loss: 0.1167
2019-10-28 15:38:56,763 Training Epoch [24/40] Iter[136/312]		Loss: 0.1165
2019-10-28 15:38:56,843 Training Epoch [24/40] Iter[137/312]		Loss: 0.1163
2019-10-28 15:38:56,922 Training Epoch [24/40] Iter[138/312]		Loss: 0.1162
2019-10-28 15:38:57,002 Training Epoch [24/40] Iter[139/312]		Loss: 0.1160
2019-10-28 15:38:57,081 Training Epoch [24/40] Iter[140/312]		Loss: 0.1157
2019-10-28 15:38:57,161 Training Epoch [24/40] Iter[141/312]		Loss: 0.1164
2019-10-28 15:38:57,241 Training Epoch [24/40] Iter[142/312]		Loss: 0.1170
2019-10-28 15:38:57,320 Training Epoch [24/40] Iter[143/312]		Loss: 0.1172
2019-10-28 15:38:57,400 Training Epoch [24/40] Iter[144/312]		Loss: 0.1181
2019-10-28 15:38:57,480 Training Epoch [24/40] Iter[145/312]		Loss: 0.1182
2019-10-28 15:38:57,559 Training Epoch [24/40] Iter[146/312]		Loss: 0.1180
2019-10-28 15:38:57,639 Training Epoch [24/40] Iter[147/312]		Loss: 0.1183
2019-10-28 15:38:57,718 Training Epoch [24/40] Iter[148/312]		Loss: 0.1187
2019-10-28 15:38:57,798 Training Epoch [24/40] Iter[149/312]		Loss: 0.1185
2019-10-28 15:38:57,877 Training Epoch [24/40] Iter[150/312]		Loss: 0.1186
2019-10-28 15:38:57,957 Training Epoch [24/40] Iter[151/312]		Loss: 0.1186
2019-10-28 15:38:58,036 Training Epoch [24/40] Iter[152/312]		Loss: 0.1183
2019-10-28 15:38:58,116 Training Epoch [24/40] Iter[153/312]		Loss: 0.1183
2019-10-28 15:38:58,195 Training Epoch [24/40] Iter[154/312]		Loss: 0.1183
2019-10-28 15:38:58,275 Training Epoch [24/40] Iter[155/312]		Loss: 0.1183
2019-10-28 15:38:58,354 Training Epoch [24/40] Iter[156/312]		Loss: 0.1182
2019-10-28 15:38:58,434 Training Epoch [24/40] Iter[157/312]		Loss: 0.1182
2019-10-28 15:38:58,513 Training Epoch [24/40] Iter[158/312]		Loss: 0.1183
2019-10-28 15:38:58,592 Training Epoch [24/40] Iter[159/312]		Loss: 0.1182
2019-10-28 15:38:58,671 Training Epoch [24/40] Iter[160/312]		Loss: 0.1183
2019-10-28 15:38:58,750 Training Epoch [24/40] Iter[161/312]		Loss: 0.1182
2019-10-28 15:38:58,829 Training Epoch [24/40] Iter[162/312]		Loss: 0.1180
2019-10-28 15:38:58,908 Training Epoch [24/40] Iter[163/312]		Loss: 0.1187
2019-10-28 15:38:58,988 Training Epoch [24/40] Iter[164/312]		Loss: 0.1188
2019-10-28 15:38:59,067 Training Epoch [24/40] Iter[165/312]		Loss: 0.1187
2019-10-28 15:38:59,147 Training Epoch [24/40] Iter[166/312]		Loss: 0.1184
2019-10-28 15:38:59,226 Training Epoch [24/40] Iter[167/312]		Loss: 0.1181
2019-10-28 15:38:59,305 Training Epoch [24/40] Iter[168/312]		Loss: 0.1181
2019-10-28 15:38:59,385 Training Epoch [24/40] Iter[169/312]		Loss: 0.1179
2019-10-28 15:38:59,464 Training Epoch [24/40] Iter[170/312]		Loss: 0.1177
2019-10-28 15:38:59,543 Training Epoch [24/40] Iter[171/312]		Loss: 0.1177
2019-10-28 15:38:59,622 Training Epoch [24/40] Iter[172/312]		Loss: 0.1177
2019-10-28 15:38:59,701 Training Epoch [24/40] Iter[173/312]		Loss: 0.1178
2019-10-28 15:38:59,780 Training Epoch [24/40] Iter[174/312]		Loss: 0.1178
2019-10-28 15:38:59,860 Training Epoch [24/40] Iter[175/312]		Loss: 0.1177
2019-10-28 15:38:59,939 Training Epoch [24/40] Iter[176/312]		Loss: 0.1175
2019-10-28 15:39:00,019 Training Epoch [24/40] Iter[177/312]		Loss: 0.1173
2019-10-28 15:39:00,098 Training Epoch [24/40] Iter[178/312]		Loss: 0.1172
2019-10-28 15:39:00,177 Training Epoch [24/40] Iter[179/312]		Loss: 0.1174
2019-10-28 15:39:00,257 Training Epoch [24/40] Iter[180/312]		Loss: 0.1173
2019-10-28 15:39:00,337 Training Epoch [24/40] Iter[181/312]		Loss: 0.1172
2019-10-28 15:39:00,417 Training Epoch [24/40] Iter[182/312]		Loss: 0.1171
2019-10-28 15:39:00,496 Training Epoch [24/40] Iter[183/312]		Loss: 0.1171
2019-10-28 15:39:00,575 Training Epoch [24/40] Iter[184/312]		Loss: 0.1171
2019-10-28 15:39:00,660 Training Epoch [24/40] Iter[185/312]		Loss: 0.1169
2019-10-28 15:39:00,739 Training Epoch [24/40] Iter[186/312]		Loss: 0.1168
2019-10-28 15:39:00,818 Training Epoch [24/40] Iter[187/312]		Loss: 0.1166
2019-10-28 15:39:00,897 Training Epoch [24/40] Iter[188/312]		Loss: 0.1167
2019-10-28 15:39:00,977 Training Epoch [24/40] Iter[189/312]		Loss: 0.1170
2019-10-28 15:39:01,056 Training Epoch [24/40] Iter[190/312]		Loss: 0.1167
2019-10-28 15:39:01,135 Training Epoch [24/40] Iter[191/312]		Loss: 0.1169
2019-10-28 15:39:01,215 Training Epoch [24/40] Iter[192/312]		Loss: 0.1169
2019-10-28 15:39:01,294 Training Epoch [24/40] Iter[193/312]		Loss: 0.1173
2019-10-28 15:39:01,374 Training Epoch [24/40] Iter[194/312]		Loss: 0.1173
2019-10-28 15:39:01,453 Training Epoch [24/40] Iter[195/312]		Loss: 0.1176
2019-10-28 15:39:01,533 Training Epoch [24/40] Iter[196/312]		Loss: 0.1174
2019-10-28 15:39:01,612 Training Epoch [24/40] Iter[197/312]		Loss: 0.1172
2019-10-28 15:39:01,691 Training Epoch [24/40] Iter[198/312]		Loss: 0.1172
2019-10-28 15:39:01,770 Training Epoch [24/40] Iter[199/312]		Loss: 0.1172
2019-10-28 15:39:01,849 Training Epoch [24/40] Iter[200/312]		Loss: 0.1171
2019-10-28 15:39:01,928 Training Epoch [24/40] Iter[201/312]		Loss: 0.1172
2019-10-28 15:39:02,008 Training Epoch [24/40] Iter[202/312]		Loss: 0.1174
2019-10-28 15:39:02,087 Training Epoch [24/40] Iter[203/312]		Loss: 0.1172
2019-10-28 15:39:02,166 Training Epoch [24/40] Iter[204/312]		Loss: 0.1170
2019-10-28 15:39:02,245 Training Epoch [24/40] Iter[205/312]		Loss: 0.1168
2019-10-28 15:39:02,325 Training Epoch [24/40] Iter[206/312]		Loss: 0.1170
2019-10-28 15:39:02,404 Training Epoch [24/40] Iter[207/312]		Loss: 0.1168
2019-10-28 15:39:02,483 Training Epoch [24/40] Iter[208/312]		Loss: 0.1168
2019-10-28 15:39:02,563 Training Epoch [24/40] Iter[209/312]		Loss: 0.1168
2019-10-28 15:39:02,642 Training Epoch [24/40] Iter[210/312]		Loss: 0.1166
2019-10-28 15:39:02,721 Training Epoch [24/40] Iter[211/312]		Loss: 0.1164
2019-10-28 15:39:02,801 Training Epoch [24/40] Iter[212/312]		Loss: 0.1163
2019-10-28 15:39:02,880 Training Epoch [24/40] Iter[213/312]		Loss: 0.1166
2019-10-28 15:39:02,959 Training Epoch [24/40] Iter[214/312]		Loss: 0.1168
2019-10-28 15:39:03,039 Training Epoch [24/40] Iter[215/312]		Loss: 0.1167
2019-10-28 15:39:03,118 Training Epoch [24/40] Iter[216/312]		Loss: 0.1168
2019-10-28 15:39:03,197 Training Epoch [24/40] Iter[217/312]		Loss: 0.1168
2019-10-28 15:39:03,276 Training Epoch [24/40] Iter[218/312]		Loss: 0.1169
2019-10-28 15:39:03,355 Training Epoch [24/40] Iter[219/312]		Loss: 0.1170
2019-10-28 15:39:03,434 Training Epoch [24/40] Iter[220/312]		Loss: 0.1170
2019-10-28 15:39:03,513 Training Epoch [24/40] Iter[221/312]		Loss: 0.1172
2019-10-28 15:39:03,592 Training Epoch [24/40] Iter[222/312]		Loss: 0.1174
2019-10-28 15:39:03,671 Training Epoch [24/40] Iter[223/312]		Loss: 0.1174
2019-10-28 15:39:03,750 Training Epoch [24/40] Iter[224/312]		Loss: 0.1173
2019-10-28 15:39:03,828 Training Epoch [24/40] Iter[225/312]		Loss: 0.1171
2019-10-28 15:39:03,907 Training Epoch [24/40] Iter[226/312]		Loss: 0.1170
2019-10-28 15:39:03,986 Training Epoch [24/40] Iter[227/312]		Loss: 0.1169
2019-10-28 15:39:04,065 Training Epoch [24/40] Iter[228/312]		Loss: 0.1168
2019-10-28 15:39:04,144 Training Epoch [24/40] Iter[229/312]		Loss: 0.1166
2019-10-28 15:39:04,223 Training Epoch [24/40] Iter[230/312]		Loss: 0.1167
2019-10-28 15:39:04,302 Training Epoch [24/40] Iter[231/312]		Loss: 0.1167
2019-10-28 15:39:04,381 Training Epoch [24/40] Iter[232/312]		Loss: 0.1167
2019-10-28 15:39:04,460 Training Epoch [24/40] Iter[233/312]		Loss: 0.1166
2019-10-28 15:39:04,539 Training Epoch [24/40] Iter[234/312]		Loss: 0.1167
2019-10-28 15:39:04,618 Training Epoch [24/40] Iter[235/312]		Loss: 0.1172
2019-10-28 15:39:04,697 Training Epoch [24/40] Iter[236/312]		Loss: 0.1172
2019-10-28 15:39:04,776 Training Epoch [24/40] Iter[237/312]		Loss: 0.1172
2019-10-28 15:39:04,855 Training Epoch [24/40] Iter[238/312]		Loss: 0.1173
2019-10-28 15:39:04,933 Training Epoch [24/40] Iter[239/312]		Loss: 0.1173
2019-10-28 15:39:05,012 Training Epoch [24/40] Iter[240/312]		Loss: 0.1172
2019-10-28 15:39:05,091 Training Epoch [24/40] Iter[241/312]		Loss: 0.1173
2019-10-28 15:39:05,170 Training Epoch [24/40] Iter[242/312]		Loss: 0.1172
2019-10-28 15:39:05,249 Training Epoch [24/40] Iter[243/312]		Loss: 0.1175
2019-10-28 15:39:05,328 Training Epoch [24/40] Iter[244/312]		Loss: 0.1174
2019-10-28 15:39:05,407 Training Epoch [24/40] Iter[245/312]		Loss: 0.1175
2019-10-28 15:39:05,486 Training Epoch [24/40] Iter[246/312]		Loss: 0.1176
2019-10-28 15:39:05,564 Training Epoch [24/40] Iter[247/312]		Loss: 0.1174
2019-10-28 15:39:05,643 Training Epoch [24/40] Iter[248/312]		Loss: 0.1175
2019-10-28 15:39:05,723 Training Epoch [24/40] Iter[249/312]		Loss: 0.1174
2019-10-28 15:39:05,801 Training Epoch [24/40] Iter[250/312]		Loss: 0.1172
2019-10-28 15:39:05,880 Training Epoch [24/40] Iter[251/312]		Loss: 0.1172
2019-10-28 15:39:05,959 Training Epoch [24/40] Iter[252/312]		Loss: 0.1170
2019-10-28 15:39:06,038 Training Epoch [24/40] Iter[253/312]		Loss: 0.1170
2019-10-28 15:39:06,117 Training Epoch [24/40] Iter[254/312]		Loss: 0.1170
2019-10-28 15:39:06,196 Training Epoch [24/40] Iter[255/312]		Loss: 0.1169
2019-10-28 15:39:06,275 Training Epoch [24/40] Iter[256/312]		Loss: 0.1171
2019-10-28 15:39:06,354 Training Epoch [24/40] Iter[257/312]		Loss: 0.1170
2019-10-28 15:39:06,433 Training Epoch [24/40] Iter[258/312]		Loss: 0.1169
2019-10-28 15:39:06,512 Training Epoch [24/40] Iter[259/312]		Loss: 0.1169
2019-10-28 15:39:06,592 Training Epoch [24/40] Iter[260/312]		Loss: 0.1169
2019-10-28 15:39:06,671 Training Epoch [24/40] Iter[261/312]		Loss: 0.1168
2019-10-28 15:39:06,749 Training Epoch [24/40] Iter[262/312]		Loss: 0.1170
2019-10-28 15:39:06,828 Training Epoch [24/40] Iter[263/312]		Loss: 0.1170
2019-10-28 15:39:06,907 Training Epoch [24/40] Iter[264/312]		Loss: 0.1169
2019-10-28 15:39:06,986 Training Epoch [24/40] Iter[265/312]		Loss: 0.1168
2019-10-28 15:39:07,065 Training Epoch [24/40] Iter[266/312]		Loss: 0.1167
2019-10-28 15:39:07,144 Training Epoch [24/40] Iter[267/312]		Loss: 0.1166
2019-10-28 15:39:07,223 Training Epoch [24/40] Iter[268/312]		Loss: 0.1165
2019-10-28 15:39:07,302 Training Epoch [24/40] Iter[269/312]		Loss: 0.1166
2019-10-28 15:39:07,380 Training Epoch [24/40] Iter[270/312]		Loss: 0.1165
2019-10-28 15:39:07,459 Training Epoch [24/40] Iter[271/312]		Loss: 0.1165
2019-10-28 15:39:07,538 Training Epoch [24/40] Iter[272/312]		Loss: 0.1165
2019-10-28 15:39:07,617 Training Epoch [24/40] Iter[273/312]		Loss: 0.1164
2019-10-28 15:39:07,696 Training Epoch [24/40] Iter[274/312]		Loss: 0.1166
2019-10-28 15:39:07,775 Training Epoch [24/40] Iter[275/312]		Loss: 0.1168
2019-10-28 15:39:07,854 Training Epoch [24/40] Iter[276/312]		Loss: 0.1166
2019-10-28 15:39:07,933 Training Epoch [24/40] Iter[277/312]		Loss: 0.1166
2019-10-28 15:39:08,012 Training Epoch [24/40] Iter[278/312]		Loss: 0.1165
2019-10-28 15:39:08,091 Training Epoch [24/40] Iter[279/312]		Loss: 0.1165
2019-10-28 15:39:08,169 Training Epoch [24/40] Iter[280/312]		Loss: 0.1165
2019-10-28 15:39:08,248 Training Epoch [24/40] Iter[281/312]		Loss: 0.1166
2019-10-28 15:39:08,327 Training Epoch [24/40] Iter[282/312]		Loss: 0.1167
2019-10-28 15:39:08,406 Training Epoch [24/40] Iter[283/312]		Loss: 0.1167
2019-10-28 15:39:08,485 Training Epoch [24/40] Iter[284/312]		Loss: 0.1167
2019-10-28 15:39:08,564 Training Epoch [24/40] Iter[285/312]		Loss: 0.1166
2019-10-28 15:39:08,643 Training Epoch [24/40] Iter[286/312]		Loss: 0.1166
2019-10-28 15:39:08,722 Training Epoch [24/40] Iter[287/312]		Loss: 0.1165
2019-10-28 15:39:08,801 Training Epoch [24/40] Iter[288/312]		Loss: 0.1164
2019-10-28 15:39:08,879 Training Epoch [24/40] Iter[289/312]		Loss: 0.1163
2019-10-28 15:39:08,958 Training Epoch [24/40] Iter[290/312]		Loss: 0.1162
2019-10-28 15:39:09,037 Training Epoch [24/40] Iter[291/312]		Loss: 0.1162
2019-10-28 15:39:09,116 Training Epoch [24/40] Iter[292/312]		Loss: 0.1163
2019-10-28 15:39:09,195 Training Epoch [24/40] Iter[293/312]		Loss: 0.1162
2019-10-28 15:39:09,274 Training Epoch [24/40] Iter[294/312]		Loss: 0.1163
2019-10-28 15:39:09,353 Training Epoch [24/40] Iter[295/312]		Loss: 0.1161
2019-10-28 15:39:09,432 Training Epoch [24/40] Iter[296/312]		Loss: 0.1161
2019-10-28 15:39:09,511 Training Epoch [24/40] Iter[297/312]		Loss: 0.1160
2019-10-28 15:39:09,590 Training Epoch [24/40] Iter[298/312]		Loss: 0.1158
2019-10-28 15:39:09,669 Training Epoch [24/40] Iter[299/312]		Loss: 0.1157
2019-10-28 15:39:09,748 Training Epoch [24/40] Iter[300/312]		Loss: 0.1157
2019-10-28 15:39:09,826 Training Epoch [24/40] Iter[301/312]		Loss: 0.1156
2019-10-28 15:39:09,906 Training Epoch [24/40] Iter[302/312]		Loss: 0.1156
2019-10-28 15:39:09,984 Training Epoch [24/40] Iter[303/312]		Loss: 0.1158
2019-10-28 15:39:10,063 Training Epoch [24/40] Iter[304/312]		Loss: 0.1158
2019-10-28 15:39:10,141 Training Epoch [24/40] Iter[305/312]		Loss: 0.1157
2019-10-28 15:39:10,220 Training Epoch [24/40] Iter[306/312]		Loss: 0.1159
2019-10-28 15:39:10,298 Training Epoch [24/40] Iter[307/312]		Loss: 0.1160
2019-10-28 15:39:10,376 Training Epoch [24/40] Iter[308/312]		Loss: 0.1160
2019-10-28 15:39:10,455 Training Epoch [24/40] Iter[309/312]		Loss: 0.1159
2019-10-28 15:39:10,533 Training Epoch [24/40] Iter[310/312]		Loss: 0.1159
2019-10-28 15:39:10,611 Training Epoch [24/40] Iter[311/312]		Loss: 0.1158
2019-10-28 15:39:10,650 Training Epoch [24/40] Iter[312/312]		Loss: 0.1157
2019-10-28 15:39:11,082 Testing Epoch [24/40] Iter[0/62]		Loss: 0.1309
2019-10-28 15:39:11,110 Testing Epoch [24/40] Iter[1/62]		Loss: 0.1292
2019-10-28 15:39:11,130 Testing Epoch [24/40] Iter[2/62]		Loss: 0.1118
2019-10-28 15:39:11,148 Testing Epoch [24/40] Iter[3/62]		Loss: 0.1168
2019-10-28 15:39:11,178 Testing Epoch [24/40] Iter[4/62]		Loss: 0.1213
2019-10-28 15:39:11,201 Testing Epoch [24/40] Iter[5/62]		Loss: 0.1164
2019-10-28 15:39:11,227 Testing Epoch [24/40] Iter[6/62]		Loss: 0.1189
2019-10-28 15:39:11,244 Testing Epoch [24/40] Iter[7/62]		Loss: 0.1212
2019-10-28 15:39:11,263 Testing Epoch [24/40] Iter[8/62]		Loss: 0.1233
2019-10-28 15:39:11,289 Testing Epoch [24/40] Iter[9/62]		Loss: 0.1222
2019-10-28 15:39:11,315 Testing Epoch [24/40] Iter[10/62]		Loss: 0.1233
2019-10-28 15:39:11,338 Testing Epoch [24/40] Iter[11/62]		Loss: 0.1299
2019-10-28 15:39:11,361 Testing Epoch [24/40] Iter[12/62]		Loss: 0.1298
2019-10-28 15:39:11,379 Testing Epoch [24/40] Iter[13/62]		Loss: 0.1320
2019-10-28 15:39:11,405 Testing Epoch [24/40] Iter[14/62]		Loss: 0.1442
2019-10-28 15:39:11,431 Testing Epoch [24/40] Iter[15/62]		Loss: 0.1463
2019-10-28 15:39:11,449 Testing Epoch [24/40] Iter[16/62]		Loss: 0.1430
2019-10-28 15:39:11,466 Testing Epoch [24/40] Iter[17/62]		Loss: 0.1436
2019-10-28 15:39:11,497 Testing Epoch [24/40] Iter[18/62]		Loss: 0.1412
2019-10-28 15:39:11,520 Testing Epoch [24/40] Iter[19/62]		Loss: 0.1393
2019-10-28 15:39:11,538 Testing Epoch [24/40] Iter[20/62]		Loss: 0.1410
2019-10-28 15:39:11,555 Testing Epoch [24/40] Iter[21/62]		Loss: 0.1394
2019-10-28 15:39:11,586 Testing Epoch [24/40] Iter[22/62]		Loss: 0.1409
2019-10-28 15:39:11,603 Testing Epoch [24/40] Iter[23/62]		Loss: 0.1397
2019-10-28 15:39:11,621 Testing Epoch [24/40] Iter[24/62]		Loss: 0.1430
2019-10-28 15:39:11,648 Testing Epoch [24/40] Iter[25/62]		Loss: 0.1423
2019-10-28 15:39:11,673 Testing Epoch [24/40] Iter[26/62]		Loss: 0.1410
2019-10-28 15:39:11,691 Testing Epoch [24/40] Iter[27/62]		Loss: 0.1486
2019-10-28 15:39:11,708 Testing Epoch [24/40] Iter[28/62]		Loss: 0.1522
2019-10-28 15:39:11,727 Testing Epoch [24/40] Iter[29/62]		Loss: 0.1522
2019-10-28 15:39:11,743 Testing Epoch [24/40] Iter[30/62]		Loss: 0.1524
2019-10-28 15:39:11,767 Testing Epoch [24/40] Iter[31/62]		Loss: 0.1513
2019-10-28 15:39:11,786 Testing Epoch [24/40] Iter[32/62]		Loss: 0.1529
2019-10-28 15:39:11,807 Testing Epoch [24/40] Iter[33/62]		Loss: 0.1518
2019-10-28 15:39:11,824 Testing Epoch [24/40] Iter[34/62]		Loss: 0.1540
2019-10-28 15:39:11,848 Testing Epoch [24/40] Iter[35/62]		Loss: 0.1536
2019-10-28 15:39:11,865 Testing Epoch [24/40] Iter[36/62]		Loss: 0.1517
2019-10-28 15:39:11,894 Testing Epoch [24/40] Iter[37/62]		Loss: 0.1505
2019-10-28 15:39:11,914 Testing Epoch [24/40] Iter[38/62]		Loss: 0.1495
2019-10-28 15:39:11,933 Testing Epoch [24/40] Iter[39/62]		Loss: 0.1498
2019-10-28 15:39:11,950 Testing Epoch [24/40] Iter[40/62]		Loss: 0.1515
2019-10-28 15:39:11,978 Testing Epoch [24/40] Iter[41/62]		Loss: 0.1531
2019-10-28 15:39:12,004 Testing Epoch [24/40] Iter[42/62]		Loss: 0.1511
2019-10-28 15:39:12,024 Testing Epoch [24/40] Iter[43/62]		Loss: 0.1504
2019-10-28 15:39:12,041 Testing Epoch [24/40] Iter[44/62]		Loss: 0.1488
2019-10-28 15:39:12,066 Testing Epoch [24/40] Iter[45/62]		Loss: 0.1486
2019-10-28 15:39:12,091 Testing Epoch [24/40] Iter[46/62]		Loss: 0.1484
2019-10-28 15:39:12,110 Testing Epoch [24/40] Iter[47/62]		Loss: 0.1543
2019-10-28 15:39:12,126 Testing Epoch [24/40] Iter[48/62]		Loss: 0.1533
2019-10-28 15:39:12,158 Testing Epoch [24/40] Iter[49/62]		Loss: 0.1554
2019-10-28 15:39:12,179 Testing Epoch [24/40] Iter[50/62]		Loss: 0.1544
2019-10-28 15:39:12,197 Testing Epoch [24/40] Iter[51/62]		Loss: 0.1543
2019-10-28 15:39:12,224 Testing Epoch [24/40] Iter[52/62]		Loss: 0.1530
2019-10-28 15:39:12,250 Testing Epoch [24/40] Iter[53/62]		Loss: 0.1533
2019-10-28 15:39:12,268 Testing Epoch [24/40] Iter[54/62]		Loss: 0.1522
2019-10-28 15:39:12,286 Testing Epoch [24/40] Iter[55/62]		Loss: 0.1519
2019-10-28 15:39:12,302 Testing Epoch [24/40] Iter[56/62]		Loss: 0.1513
2019-10-28 15:39:12,319 Testing Epoch [24/40] Iter[57/62]		Loss: 0.1515
2019-10-28 15:39:12,335 Testing Epoch [24/40] Iter[58/62]		Loss: 0.1510
2019-10-28 15:39:12,352 Testing Epoch [24/40] Iter[59/62]		Loss: 0.1520
2019-10-28 15:39:12,369 Testing Epoch [24/40] Iter[60/62]		Loss: 0.1512
2019-10-28 15:39:12,385 Testing Epoch [24/40] Iter[61/62]		Loss: 0.1510
2019-10-28 15:39:12,395 Testing Epoch [24/40] Iter[62/62]		Loss: 0.1518
2019-10-28 15:39:12,467 Saving the Model
2019-10-28 15:39:12,886 Training Epoch [25/40] Iter[0/312]		Loss: 0.0594
2019-10-28 15:39:12,974 Training Epoch [25/40] Iter[1/312]		Loss: 0.0879
2019-10-28 15:39:13,055 Training Epoch [25/40] Iter[2/312]		Loss: 0.0788
2019-10-28 15:39:13,137 Training Epoch [25/40] Iter[3/312]		Loss: 0.0788
2019-10-28 15:39:13,219 Training Epoch [25/40] Iter[4/312]		Loss: 0.0799
2019-10-28 15:39:13,296 Training Epoch [25/40] Iter[5/312]		Loss: 0.0862
2019-10-28 15:39:13,374 Training Epoch [25/40] Iter[6/312]		Loss: 0.0886
2019-10-28 15:39:13,453 Training Epoch [25/40] Iter[7/312]		Loss: 0.0963
2019-10-28 15:39:13,532 Training Epoch [25/40] Iter[8/312]		Loss: 0.0983
2019-10-28 15:39:13,611 Training Epoch [25/40] Iter[9/312]		Loss: 0.0991
2019-10-28 15:39:13,690 Training Epoch [25/40] Iter[10/312]		Loss: 0.0968
2019-10-28 15:39:13,769 Training Epoch [25/40] Iter[11/312]		Loss: 0.0938
2019-10-28 15:39:13,847 Training Epoch [25/40] Iter[12/312]		Loss: 0.0990
2019-10-28 15:39:13,926 Training Epoch [25/40] Iter[13/312]		Loss: 0.0993
2019-10-28 15:39:14,005 Training Epoch [25/40] Iter[14/312]		Loss: 0.0985
2019-10-28 15:39:14,084 Training Epoch [25/40] Iter[15/312]		Loss: 0.1004
2019-10-28 15:39:14,163 Training Epoch [25/40] Iter[16/312]		Loss: 0.0987
2019-10-28 15:39:14,242 Training Epoch [25/40] Iter[17/312]		Loss: 0.0998
2019-10-28 15:39:14,320 Training Epoch [25/40] Iter[18/312]		Loss: 0.1018
2019-10-28 15:39:14,399 Training Epoch [25/40] Iter[19/312]		Loss: 0.1021
2019-10-28 15:39:14,477 Training Epoch [25/40] Iter[20/312]		Loss: 0.1048
2019-10-28 15:39:14,556 Training Epoch [25/40] Iter[21/312]		Loss: 0.1041
2019-10-28 15:39:14,635 Training Epoch [25/40] Iter[22/312]		Loss: 0.1076
2019-10-28 15:39:14,714 Training Epoch [25/40] Iter[23/312]		Loss: 0.1077
2019-10-28 15:39:14,793 Training Epoch [25/40] Iter[24/312]		Loss: 0.1063
2019-10-28 15:39:14,872 Training Epoch [25/40] Iter[25/312]		Loss: 0.1055
2019-10-28 15:39:14,950 Training Epoch [25/40] Iter[26/312]		Loss: 0.1044
2019-10-28 15:39:15,029 Training Epoch [25/40] Iter[27/312]		Loss: 0.1040
2019-10-28 15:39:15,108 Training Epoch [25/40] Iter[28/312]		Loss: 0.1027
2019-10-28 15:39:15,187 Training Epoch [25/40] Iter[29/312]		Loss: 0.1031
2019-10-28 15:39:15,266 Training Epoch [25/40] Iter[30/312]		Loss: 0.1031
2019-10-28 15:39:15,344 Training Epoch [25/40] Iter[31/312]		Loss: 0.1030
2019-10-28 15:39:15,423 Training Epoch [25/40] Iter[32/312]		Loss: 0.1055
2019-10-28 15:39:15,502 Training Epoch [25/40] Iter[33/312]		Loss: 0.1065
2019-10-28 15:39:15,581 Training Epoch [25/40] Iter[34/312]		Loss: 0.1063
2019-10-28 15:39:15,660 Training Epoch [25/40] Iter[35/312]		Loss: 0.1065
2019-10-28 15:39:15,739 Training Epoch [25/40] Iter[36/312]		Loss: 0.1071
2019-10-28 15:39:15,817 Training Epoch [25/40] Iter[37/312]		Loss: 0.1066
2019-10-28 15:39:15,896 Training Epoch [25/40] Iter[38/312]		Loss: 0.1068
2019-10-28 15:39:15,975 Training Epoch [25/40] Iter[39/312]		Loss: 0.1067
2019-10-28 15:39:16,054 Training Epoch [25/40] Iter[40/312]		Loss: 0.1089
2019-10-28 15:39:16,133 Training Epoch [25/40] Iter[41/312]		Loss: 0.1104
2019-10-28 15:39:16,212 Training Epoch [25/40] Iter[42/312]		Loss: 0.1100
2019-10-28 15:39:16,291 Training Epoch [25/40] Iter[43/312]		Loss: 0.1094
2019-10-28 15:39:16,370 Training Epoch [25/40] Iter[44/312]		Loss: 0.1096
2019-10-28 15:39:16,449 Training Epoch [25/40] Iter[45/312]		Loss: 0.1087
2019-10-28 15:39:16,528 Training Epoch [25/40] Iter[46/312]		Loss: 0.1087
2019-10-28 15:39:16,607 Training Epoch [25/40] Iter[47/312]		Loss: 0.1088
2019-10-28 15:39:16,685 Training Epoch [25/40] Iter[48/312]		Loss: 0.1088
2019-10-28 15:39:16,764 Training Epoch [25/40] Iter[49/312]		Loss: 0.1087
2019-10-28 15:39:16,843 Training Epoch [25/40] Iter[50/312]		Loss: 0.1102
2019-10-28 15:39:16,921 Training Epoch [25/40] Iter[51/312]		Loss: 0.1096
2019-10-28 15:39:17,000 Training Epoch [25/40] Iter[52/312]		Loss: 0.1092
2019-10-28 15:39:17,079 Training Epoch [25/40] Iter[53/312]		Loss: 0.1094
2019-10-28 15:39:17,158 Training Epoch [25/40] Iter[54/312]		Loss: 0.1093
2019-10-28 15:39:17,237 Training Epoch [25/40] Iter[55/312]		Loss: 0.1093
2019-10-28 15:39:17,316 Training Epoch [25/40] Iter[56/312]		Loss: 0.1093
2019-10-28 15:39:17,395 Training Epoch [25/40] Iter[57/312]		Loss: 0.1102
2019-10-28 15:39:17,474 Training Epoch [25/40] Iter[58/312]		Loss: 0.1100
2019-10-28 15:39:17,552 Training Epoch [25/40] Iter[59/312]		Loss: 0.1114
2019-10-28 15:39:17,631 Training Epoch [25/40] Iter[60/312]		Loss: 0.1112
2019-10-28 15:39:17,710 Training Epoch [25/40] Iter[61/312]		Loss: 0.1114
2019-10-28 15:39:17,789 Training Epoch [25/40] Iter[62/312]		Loss: 0.1110
2019-10-28 15:39:17,868 Training Epoch [25/40] Iter[63/312]		Loss: 0.1109
2019-10-28 15:39:17,947 Training Epoch [25/40] Iter[64/312]		Loss: 0.1118
2019-10-28 15:39:18,026 Training Epoch [25/40] Iter[65/312]		Loss: 0.1110
2019-10-28 15:39:18,105 Training Epoch [25/40] Iter[66/312]		Loss: 0.1105
2019-10-28 15:39:18,184 Training Epoch [25/40] Iter[67/312]		Loss: 0.1111
2019-10-28 15:39:18,263 Training Epoch [25/40] Iter[68/312]		Loss: 0.1107
2019-10-28 15:39:18,342 Training Epoch [25/40] Iter[69/312]		Loss: 0.1101
2019-10-28 15:39:18,420 Training Epoch [25/40] Iter[70/312]		Loss: 0.1102
2019-10-28 15:39:18,499 Training Epoch [25/40] Iter[71/312]		Loss: 0.1102
2019-10-28 15:39:18,578 Training Epoch [25/40] Iter[72/312]		Loss: 0.1102
2019-10-28 15:39:18,657 Training Epoch [25/40] Iter[73/312]		Loss: 0.1101
2019-10-28 15:39:18,736 Training Epoch [25/40] Iter[74/312]		Loss: 0.1098
2019-10-28 15:39:18,815 Training Epoch [25/40] Iter[75/312]		Loss: 0.1102
2019-10-28 15:39:18,894 Training Epoch [25/40] Iter[76/312]		Loss: 0.1101
2019-10-28 15:39:18,973 Training Epoch [25/40] Iter[77/312]		Loss: 0.1097
2019-10-28 15:39:19,051 Training Epoch [25/40] Iter[78/312]		Loss: 0.1098
2019-10-28 15:39:19,130 Training Epoch [25/40] Iter[79/312]		Loss: 0.1091
2019-10-28 15:39:19,209 Training Epoch [25/40] Iter[80/312]		Loss: 0.1090
2019-10-28 15:39:19,288 Training Epoch [25/40] Iter[81/312]		Loss: 0.1092
2019-10-28 15:39:19,366 Training Epoch [25/40] Iter[82/312]		Loss: 0.1100
2019-10-28 15:39:19,445 Training Epoch [25/40] Iter[83/312]		Loss: 0.1095
2019-10-28 15:39:19,524 Training Epoch [25/40] Iter[84/312]		Loss: 0.1103
2019-10-28 15:39:19,603 Training Epoch [25/40] Iter[85/312]		Loss: 0.1103
2019-10-28 15:39:19,682 Training Epoch [25/40] Iter[86/312]		Loss: 0.1098
2019-10-28 15:39:19,761 Training Epoch [25/40] Iter[87/312]		Loss: 0.1098
2019-10-28 15:39:19,840 Training Epoch [25/40] Iter[88/312]		Loss: 0.1103
2019-10-28 15:39:19,918 Training Epoch [25/40] Iter[89/312]		Loss: 0.1100
2019-10-28 15:39:19,997 Training Epoch [25/40] Iter[90/312]		Loss: 0.1102
2019-10-28 15:39:20,076 Training Epoch [25/40] Iter[91/312]		Loss: 0.1103
2019-10-28 15:39:20,155 Training Epoch [25/40] Iter[92/312]		Loss: 0.1101
2019-10-28 15:39:20,233 Training Epoch [25/40] Iter[93/312]		Loss: 0.1105
2019-10-28 15:39:20,312 Training Epoch [25/40] Iter[94/312]		Loss: 0.1109
2019-10-28 15:39:20,391 Training Epoch [25/40] Iter[95/312]		Loss: 0.1111
2019-10-28 15:39:20,470 Training Epoch [25/40] Iter[96/312]		Loss: 0.1110
2019-10-28 15:39:20,549 Training Epoch [25/40] Iter[97/312]		Loss: 0.1110
2019-10-28 15:39:20,627 Training Epoch [25/40] Iter[98/312]		Loss: 0.1109
2019-10-28 15:39:20,706 Training Epoch [25/40] Iter[99/312]		Loss: 0.1111
2019-10-28 15:39:20,785 Training Epoch [25/40] Iter[100/312]		Loss: 0.1113
2019-10-28 15:39:20,864 Training Epoch [25/40] Iter[101/312]		Loss: 0.1120
2019-10-28 15:39:20,943 Training Epoch [25/40] Iter[102/312]		Loss: 0.1118
2019-10-28 15:39:21,021 Training Epoch [25/40] Iter[103/312]		Loss: 0.1125
2019-10-28 15:39:21,100 Training Epoch [25/40] Iter[104/312]		Loss: 0.1135
2019-10-28 15:39:21,179 Training Epoch [25/40] Iter[105/312]		Loss: 0.1133
2019-10-28 15:39:21,258 Training Epoch [25/40] Iter[106/312]		Loss: 0.1131
2019-10-28 15:39:21,337 Training Epoch [25/40] Iter[107/312]		Loss: 0.1134
2019-10-28 15:39:21,416 Training Epoch [25/40] Iter[108/312]		Loss: 0.1134
2019-10-28 15:39:21,495 Training Epoch [25/40] Iter[109/312]		Loss: 0.1138
2019-10-28 15:39:21,574 Training Epoch [25/40] Iter[110/312]		Loss: 0.1137
2019-10-28 15:39:21,652 Training Epoch [25/40] Iter[111/312]		Loss: 0.1137
2019-10-28 15:39:21,731 Training Epoch [25/40] Iter[112/312]		Loss: 0.1139
2019-10-28 15:39:21,810 Training Epoch [25/40] Iter[113/312]		Loss: 0.1140
2019-10-28 15:39:21,889 Training Epoch [25/40] Iter[114/312]		Loss: 0.1139
2019-10-28 15:39:21,968 Training Epoch [25/40] Iter[115/312]		Loss: 0.1138
2019-10-28 15:39:22,047 Training Epoch [25/40] Iter[116/312]		Loss: 0.1144
2019-10-28 15:39:22,125 Training Epoch [25/40] Iter[117/312]		Loss: 0.1151
2019-10-28 15:39:22,204 Training Epoch [25/40] Iter[118/312]		Loss: 0.1147
2019-10-28 15:39:22,283 Training Epoch [25/40] Iter[119/312]		Loss: 0.1149
2019-10-28 15:39:22,362 Training Epoch [25/40] Iter[120/312]		Loss: 0.1154
2019-10-28 15:39:22,441 Training Epoch [25/40] Iter[121/312]		Loss: 0.1162
2019-10-28 15:39:22,520 Training Epoch [25/40] Iter[122/312]		Loss: 0.1161
2019-10-28 15:39:22,598 Training Epoch [25/40] Iter[123/312]		Loss: 0.1161
2019-10-28 15:39:22,677 Training Epoch [25/40] Iter[124/312]		Loss: 0.1162
2019-10-28 15:39:22,756 Training Epoch [25/40] Iter[125/312]		Loss: 0.1177
2019-10-28 15:39:22,835 Training Epoch [25/40] Iter[126/312]		Loss: 0.1175
2019-10-28 15:39:22,914 Training Epoch [25/40] Iter[127/312]		Loss: 0.1174
2019-10-28 15:39:22,993 Training Epoch [25/40] Iter[128/312]		Loss: 0.1171
2019-10-28 15:39:23,072 Training Epoch [25/40] Iter[129/312]		Loss: 0.1174
2019-10-28 15:39:23,150 Training Epoch [25/40] Iter[130/312]		Loss: 0.1179
2019-10-28 15:39:23,229 Training Epoch [25/40] Iter[131/312]		Loss: 0.1185
2019-10-28 15:39:23,308 Training Epoch [25/40] Iter[132/312]		Loss: 0.1182
2019-10-28 15:39:23,387 Training Epoch [25/40] Iter[133/312]		Loss: 0.1182
2019-10-28 15:39:23,466 Training Epoch [25/40] Iter[134/312]		Loss: 0.1179
2019-10-28 15:39:23,545 Training Epoch [25/40] Iter[135/312]		Loss: 0.1179
2019-10-28 15:39:23,624 Training Epoch [25/40] Iter[136/312]		Loss: 0.1180
2019-10-28 15:39:23,703 Training Epoch [25/40] Iter[137/312]		Loss: 0.1176
2019-10-28 15:39:23,782 Training Epoch [25/40] Iter[138/312]		Loss: 0.1175
2019-10-28 15:39:23,860 Training Epoch [25/40] Iter[139/312]		Loss: 0.1173
2019-10-28 15:39:23,939 Training Epoch [25/40] Iter[140/312]		Loss: 0.1172
2019-10-28 15:39:24,018 Training Epoch [25/40] Iter[141/312]		Loss: 0.1174
2019-10-28 15:39:24,097 Training Epoch [25/40] Iter[142/312]		Loss: 0.1172
2019-10-28 15:39:24,176 Training Epoch [25/40] Iter[143/312]		Loss: 0.1172
2019-10-28 15:39:24,255 Training Epoch [25/40] Iter[144/312]		Loss: 0.1170
2019-10-28 15:39:24,334 Training Epoch [25/40] Iter[145/312]		Loss: 0.1170
2019-10-28 15:39:24,413 Training Epoch [25/40] Iter[146/312]		Loss: 0.1167
2019-10-28 15:39:24,492 Training Epoch [25/40] Iter[147/312]		Loss: 0.1165
2019-10-28 15:39:24,570 Training Epoch [25/40] Iter[148/312]		Loss: 0.1164
2019-10-28 15:39:24,649 Training Epoch [25/40] Iter[149/312]		Loss: 0.1162
2019-10-28 15:39:24,728 Training Epoch [25/40] Iter[150/312]		Loss: 0.1164
2019-10-28 15:39:24,806 Training Epoch [25/40] Iter[151/312]		Loss: 0.1165
2019-10-28 15:39:24,885 Training Epoch [25/40] Iter[152/312]		Loss: 0.1165
2019-10-28 15:39:24,964 Training Epoch [25/40] Iter[153/312]		Loss: 0.1162
2019-10-28 15:39:25,043 Training Epoch [25/40] Iter[154/312]		Loss: 0.1160
2019-10-28 15:39:25,122 Training Epoch [25/40] Iter[155/312]		Loss: 0.1158
2019-10-28 15:39:25,201 Training Epoch [25/40] Iter[156/312]		Loss: 0.1155
2019-10-28 15:39:25,280 Training Epoch [25/40] Iter[157/312]		Loss: 0.1157
2019-10-28 15:39:25,359 Training Epoch [25/40] Iter[158/312]		Loss: 0.1160
2019-10-28 15:39:25,438 Training Epoch [25/40] Iter[159/312]		Loss: 0.1158
2019-10-28 15:39:25,517 Training Epoch [25/40] Iter[160/312]		Loss: 0.1156
2019-10-28 15:39:25,596 Training Epoch [25/40] Iter[161/312]		Loss: 0.1158
2019-10-28 15:39:25,675 Training Epoch [25/40] Iter[162/312]		Loss: 0.1156
2019-10-28 15:39:25,753 Training Epoch [25/40] Iter[163/312]		Loss: 0.1155
2019-10-28 15:39:25,832 Training Epoch [25/40] Iter[164/312]		Loss: 0.1157
2019-10-28 15:39:25,911 Training Epoch [25/40] Iter[165/312]		Loss: 0.1157
2019-10-28 15:39:25,990 Training Epoch [25/40] Iter[166/312]		Loss: 0.1155
2019-10-28 15:39:26,069 Training Epoch [25/40] Iter[167/312]		Loss: 0.1157
2019-10-28 15:39:26,148 Training Epoch [25/40] Iter[168/312]		Loss: 0.1155
2019-10-28 15:39:26,227 Training Epoch [25/40] Iter[169/312]		Loss: 0.1156
2019-10-28 15:39:26,306 Training Epoch [25/40] Iter[170/312]		Loss: 0.1154
2019-10-28 15:39:26,385 Training Epoch [25/40] Iter[171/312]		Loss: 0.1151
2019-10-28 15:39:26,469 Training Epoch [25/40] Iter[172/312]		Loss: 0.1156
2019-10-28 15:39:26,547 Training Epoch [25/40] Iter[173/312]		Loss: 0.1156
2019-10-28 15:39:26,626 Training Epoch [25/40] Iter[174/312]		Loss: 0.1154
2019-10-28 15:39:26,705 Training Epoch [25/40] Iter[175/312]		Loss: 0.1152
2019-10-28 15:39:26,786 Training Epoch [25/40] Iter[176/312]		Loss: 0.1152
2019-10-28 15:39:26,865 Training Epoch [25/40] Iter[177/312]		Loss: 0.1151
2019-10-28 15:39:26,944 Training Epoch [25/40] Iter[178/312]		Loss: 0.1155
2019-10-28 15:39:27,023 Training Epoch [25/40] Iter[179/312]		Loss: 0.1155
2019-10-28 15:39:27,102 Training Epoch [25/40] Iter[180/312]		Loss: 0.1153
2019-10-28 15:39:27,181 Training Epoch [25/40] Iter[181/312]		Loss: 0.1153
2019-10-28 15:39:27,260 Training Epoch [25/40] Iter[182/312]		Loss: 0.1153
2019-10-28 15:39:27,339 Training Epoch [25/40] Iter[183/312]		Loss: 0.1161
2019-10-28 15:39:27,418 Training Epoch [25/40] Iter[184/312]		Loss: 0.1159
2019-10-28 15:39:27,496 Training Epoch [25/40] Iter[185/312]		Loss: 0.1160
2019-10-28 15:39:27,575 Training Epoch [25/40] Iter[186/312]		Loss: 0.1158
2019-10-28 15:39:27,654 Training Epoch [25/40] Iter[187/312]		Loss: 0.1160
2019-10-28 15:39:27,733 Training Epoch [25/40] Iter[188/312]		Loss: 0.1161
2019-10-28 15:39:27,812 Training Epoch [25/40] Iter[189/312]		Loss: 0.1162
2019-10-28 15:39:27,891 Training Epoch [25/40] Iter[190/312]		Loss: 0.1160
2019-10-28 15:39:27,970 Training Epoch [25/40] Iter[191/312]		Loss: 0.1158
2019-10-28 15:39:28,049 Training Epoch [25/40] Iter[192/312]		Loss: 0.1157
2019-10-28 15:39:28,128 Training Epoch [25/40] Iter[193/312]		Loss: 0.1160
2019-10-28 15:39:28,207 Training Epoch [25/40] Iter[194/312]		Loss: 0.1159
2019-10-28 15:39:28,286 Training Epoch [25/40] Iter[195/312]		Loss: 0.1157
2019-10-28 15:39:28,365 Training Epoch [25/40] Iter[196/312]		Loss: 0.1156
2019-10-28 15:39:28,444 Training Epoch [25/40] Iter[197/312]		Loss: 0.1159
2019-10-28 15:39:28,523 Training Epoch [25/40] Iter[198/312]		Loss: 0.1158
2019-10-28 15:39:28,602 Training Epoch [25/40] Iter[199/312]		Loss: 0.1159
2019-10-28 15:39:28,681 Training Epoch [25/40] Iter[200/312]		Loss: 0.1159
2019-10-28 15:39:28,760 Training Epoch [25/40] Iter[201/312]		Loss: 0.1160
2019-10-28 15:39:28,839 Training Epoch [25/40] Iter[202/312]		Loss: 0.1163
2019-10-28 15:39:28,918 Training Epoch [25/40] Iter[203/312]		Loss: 0.1161
2019-10-28 15:39:28,997 Training Epoch [25/40] Iter[204/312]		Loss: 0.1160
2019-10-28 15:39:29,077 Training Epoch [25/40] Iter[205/312]		Loss: 0.1158
2019-10-28 15:39:29,156 Training Epoch [25/40] Iter[206/312]		Loss: 0.1158
2019-10-28 15:39:29,235 Training Epoch [25/40] Iter[207/312]		Loss: 0.1160
2019-10-28 15:39:29,314 Training Epoch [25/40] Iter[208/312]		Loss: 0.1161
2019-10-28 15:39:29,393 Training Epoch [25/40] Iter[209/312]		Loss: 0.1160
2019-10-28 15:39:29,472 Training Epoch [25/40] Iter[210/312]		Loss: 0.1162
2019-10-28 15:39:29,550 Training Epoch [25/40] Iter[211/312]		Loss: 0.1161
2019-10-28 15:39:29,629 Training Epoch [25/40] Iter[212/312]		Loss: 0.1159
2019-10-28 15:39:29,708 Training Epoch [25/40] Iter[213/312]		Loss: 0.1156
2019-10-28 15:39:29,787 Training Epoch [25/40] Iter[214/312]		Loss: 0.1156
2019-10-28 15:39:29,865 Training Epoch [25/40] Iter[215/312]		Loss: 0.1155
2019-10-28 15:39:29,944 Training Epoch [25/40] Iter[216/312]		Loss: 0.1155
2019-10-28 15:39:30,023 Training Epoch [25/40] Iter[217/312]		Loss: 0.1156
2019-10-28 15:39:30,102 Training Epoch [25/40] Iter[218/312]		Loss: 0.1154
2019-10-28 15:39:30,181 Training Epoch [25/40] Iter[219/312]		Loss: 0.1156
2019-10-28 15:39:30,260 Training Epoch [25/40] Iter[220/312]		Loss: 0.1157
2019-10-28 15:39:30,339 Training Epoch [25/40] Iter[221/312]		Loss: 0.1155
2019-10-28 15:39:30,418 Training Epoch [25/40] Iter[222/312]		Loss: 0.1154
2019-10-28 15:39:30,497 Training Epoch [25/40] Iter[223/312]		Loss: 0.1153
2019-10-28 15:39:30,576 Training Epoch [25/40] Iter[224/312]		Loss: 0.1154
2019-10-28 15:39:30,655 Training Epoch [25/40] Iter[225/312]		Loss: 0.1153
2019-10-28 15:39:30,734 Training Epoch [25/40] Iter[226/312]		Loss: 0.1153
2019-10-28 15:39:30,813 Training Epoch [25/40] Iter[227/312]		Loss: 0.1152
2019-10-28 15:39:30,892 Training Epoch [25/40] Iter[228/312]		Loss: 0.1151
2019-10-28 15:39:30,971 Training Epoch [25/40] Iter[229/312]		Loss: 0.1149
2019-10-28 15:39:31,050 Training Epoch [25/40] Iter[230/312]		Loss: 0.1147
2019-10-28 15:39:31,129 Training Epoch [25/40] Iter[231/312]		Loss: 0.1147
2019-10-28 15:39:31,209 Training Epoch [25/40] Iter[232/312]		Loss: 0.1148
2019-10-28 15:39:31,288 Training Epoch [25/40] Iter[233/312]		Loss: 0.1148
2019-10-28 15:39:31,368 Training Epoch [25/40] Iter[234/312]		Loss: 0.1150
2019-10-28 15:39:31,448 Training Epoch [25/40] Iter[235/312]		Loss: 0.1150
2019-10-28 15:39:31,527 Training Epoch [25/40] Iter[236/312]		Loss: 0.1149
2019-10-28 15:39:31,607 Training Epoch [25/40] Iter[237/312]		Loss: 0.1149
2019-10-28 15:39:31,686 Training Epoch [25/40] Iter[238/312]		Loss: 0.1148
2019-10-28 15:39:31,765 Training Epoch [25/40] Iter[239/312]		Loss: 0.1151
2019-10-28 15:39:31,844 Training Epoch [25/40] Iter[240/312]		Loss: 0.1150
2019-10-28 15:39:31,923 Training Epoch [25/40] Iter[241/312]		Loss: 0.1149
2019-10-28 15:39:32,002 Training Epoch [25/40] Iter[242/312]		Loss: 0.1149
2019-10-28 15:39:32,081 Training Epoch [25/40] Iter[243/312]		Loss: 0.1151
2019-10-28 15:39:32,160 Training Epoch [25/40] Iter[244/312]		Loss: 0.1151
2019-10-28 15:39:32,240 Training Epoch [25/40] Iter[245/312]		Loss: 0.1152
2019-10-28 15:39:32,319 Training Epoch [25/40] Iter[246/312]		Loss: 0.1151
2019-10-28 15:39:32,398 Training Epoch [25/40] Iter[247/312]		Loss: 0.1151
2019-10-28 15:39:32,477 Training Epoch [25/40] Iter[248/312]		Loss: 0.1149
2019-10-28 15:39:32,556 Training Epoch [25/40] Iter[249/312]		Loss: 0.1151
2019-10-28 15:39:32,635 Training Epoch [25/40] Iter[250/312]		Loss: 0.1151
2019-10-28 15:39:32,714 Training Epoch [25/40] Iter[251/312]		Loss: 0.1152
2019-10-28 15:39:32,793 Training Epoch [25/40] Iter[252/312]		Loss: 0.1150
2019-10-28 15:39:32,872 Training Epoch [25/40] Iter[253/312]		Loss: 0.1148
2019-10-28 15:39:32,951 Training Epoch [25/40] Iter[254/312]		Loss: 0.1149
2019-10-28 15:39:33,030 Training Epoch [25/40] Iter[255/312]		Loss: 0.1148
2019-10-28 15:39:33,109 Training Epoch [25/40] Iter[256/312]		Loss: 0.1147
2019-10-28 15:39:33,188 Training Epoch [25/40] Iter[257/312]		Loss: 0.1146
2019-10-28 15:39:33,267 Training Epoch [25/40] Iter[258/312]		Loss: 0.1148
2019-10-28 15:39:33,346 Training Epoch [25/40] Iter[259/312]		Loss: 0.1149
2019-10-28 15:39:33,425 Training Epoch [25/40] Iter[260/312]		Loss: 0.1148
2019-10-28 15:39:33,504 Training Epoch [25/40] Iter[261/312]		Loss: 0.1147
2019-10-28 15:39:33,583 Training Epoch [25/40] Iter[262/312]		Loss: 0.1146
2019-10-28 15:39:33,662 Training Epoch [25/40] Iter[263/312]		Loss: 0.1144
2019-10-28 15:39:33,741 Training Epoch [25/40] Iter[264/312]		Loss: 0.1148
2019-10-28 15:39:33,820 Training Epoch [25/40] Iter[265/312]		Loss: 0.1147
2019-10-28 15:39:33,899 Training Epoch [25/40] Iter[266/312]		Loss: 0.1147
2019-10-28 15:39:33,978 Training Epoch [25/40] Iter[267/312]		Loss: 0.1147
2019-10-28 15:39:34,057 Training Epoch [25/40] Iter[268/312]		Loss: 0.1146
2019-10-28 15:39:34,136 Training Epoch [25/40] Iter[269/312]		Loss: 0.1146
2019-10-28 15:39:34,215 Training Epoch [25/40] Iter[270/312]		Loss: 0.1146
2019-10-28 15:39:34,294 Training Epoch [25/40] Iter[271/312]		Loss: 0.1145
2019-10-28 15:39:34,374 Training Epoch [25/40] Iter[272/312]		Loss: 0.1144
2019-10-28 15:39:34,453 Training Epoch [25/40] Iter[273/312]		Loss: 0.1145
2019-10-28 15:39:34,532 Training Epoch [25/40] Iter[274/312]		Loss: 0.1148
2019-10-28 15:39:34,611 Training Epoch [25/40] Iter[275/312]		Loss: 0.1147
2019-10-28 15:39:34,690 Training Epoch [25/40] Iter[276/312]		Loss: 0.1147
2019-10-28 15:39:34,769 Training Epoch [25/40] Iter[277/312]		Loss: 0.1146
2019-10-28 15:39:34,848 Training Epoch [25/40] Iter[278/312]		Loss: 0.1145
2019-10-28 15:39:34,927 Training Epoch [25/40] Iter[279/312]		Loss: 0.1147
2019-10-28 15:39:35,006 Training Epoch [25/40] Iter[280/312]		Loss: 0.1146
2019-10-28 15:39:35,085 Training Epoch [25/40] Iter[281/312]		Loss: 0.1145
2019-10-28 15:39:35,164 Training Epoch [25/40] Iter[282/312]		Loss: 0.1146
2019-10-28 15:39:35,243 Training Epoch [25/40] Iter[283/312]		Loss: 0.1146
2019-10-28 15:39:35,322 Training Epoch [25/40] Iter[284/312]		Loss: 0.1147
2019-10-28 15:39:35,401 Training Epoch [25/40] Iter[285/312]		Loss: 0.1147
2019-10-28 15:39:35,480 Training Epoch [25/40] Iter[286/312]		Loss: 0.1147
2019-10-28 15:39:35,558 Training Epoch [25/40] Iter[287/312]		Loss: 0.1147
2019-10-28 15:39:35,637 Training Epoch [25/40] Iter[288/312]		Loss: 0.1145
2019-10-28 15:39:35,716 Training Epoch [25/40] Iter[289/312]		Loss: 0.1145
2019-10-28 15:39:35,796 Training Epoch [25/40] Iter[290/312]		Loss: 0.1144
2019-10-28 15:39:35,878 Training Epoch [25/40] Iter[291/312]		Loss: 0.1145
2019-10-28 15:39:35,957 Training Epoch [25/40] Iter[292/312]		Loss: 0.1144
2019-10-28 15:39:36,036 Training Epoch [25/40] Iter[293/312]		Loss: 0.1144
2019-10-28 15:39:36,115 Training Epoch [25/40] Iter[294/312]		Loss: 0.1144
2019-10-28 15:39:36,198 Training Epoch [25/40] Iter[295/312]		Loss: 0.1143
2019-10-28 15:39:36,277 Training Epoch [25/40] Iter[296/312]		Loss: 0.1143
2019-10-28 15:39:36,356 Training Epoch [25/40] Iter[297/312]		Loss: 0.1143
2019-10-28 15:39:36,435 Training Epoch [25/40] Iter[298/312]		Loss: 0.1142
2019-10-28 15:39:36,518 Training Epoch [25/40] Iter[299/312]		Loss: 0.1142
2019-10-28 15:39:36,597 Training Epoch [25/40] Iter[300/312]		Loss: 0.1142
2019-10-28 15:39:36,676 Training Epoch [25/40] Iter[301/312]		Loss: 0.1144
2019-10-28 15:39:36,755 Training Epoch [25/40] Iter[302/312]		Loss: 0.1142
2019-10-28 15:39:36,834 Training Epoch [25/40] Iter[303/312]		Loss: 0.1142
2019-10-28 15:39:36,913 Training Epoch [25/40] Iter[304/312]		Loss: 0.1142
2019-10-28 15:39:36,991 Training Epoch [25/40] Iter[305/312]		Loss: 0.1142
2019-10-28 15:39:37,069 Training Epoch [25/40] Iter[306/312]		Loss: 0.1142
2019-10-28 15:39:37,147 Training Epoch [25/40] Iter[307/312]		Loss: 0.1141
2019-10-28 15:39:37,225 Training Epoch [25/40] Iter[308/312]		Loss: 0.1141
2019-10-28 15:39:37,304 Training Epoch [25/40] Iter[309/312]		Loss: 0.1141
2019-10-28 15:39:37,382 Training Epoch [25/40] Iter[310/312]		Loss: 0.1144
2019-10-28 15:39:37,460 Training Epoch [25/40] Iter[311/312]		Loss: 0.1144
2019-10-28 15:39:37,499 Training Epoch [25/40] Iter[312/312]		Loss: 0.1144
2019-10-28 15:39:37,922 Testing Epoch [25/40] Iter[0/62]		Loss: 0.1297
2019-10-28 15:39:37,946 Testing Epoch [25/40] Iter[1/62]		Loss: 0.1272
2019-10-28 15:39:37,985 Testing Epoch [25/40] Iter[2/62]		Loss: 0.1099
2019-10-28 15:39:38,008 Testing Epoch [25/40] Iter[3/62]		Loss: 0.1164
2019-10-28 15:39:38,024 Testing Epoch [25/40] Iter[4/62]		Loss: 0.1211
2019-10-28 15:39:38,049 Testing Epoch [25/40] Iter[5/62]		Loss: 0.1160
2019-10-28 15:39:38,065 Testing Epoch [25/40] Iter[6/62]		Loss: 0.1191
2019-10-28 15:39:38,097 Testing Epoch [25/40] Iter[7/62]		Loss: 0.1211
2019-10-28 15:39:38,113 Testing Epoch [25/40] Iter[8/62]		Loss: 0.1229
2019-10-28 15:39:38,131 Testing Epoch [25/40] Iter[9/62]		Loss: 0.1219
2019-10-28 15:39:38,158 Testing Epoch [25/40] Iter[10/62]		Loss: 0.1233
2019-10-28 15:39:38,175 Testing Epoch [25/40] Iter[11/62]		Loss: 0.1298
2019-10-28 15:39:38,192 Testing Epoch [25/40] Iter[12/62]		Loss: 0.1291
2019-10-28 15:39:38,210 Testing Epoch [25/40] Iter[13/62]		Loss: 0.1313
2019-10-28 15:39:38,241 Testing Epoch [25/40] Iter[14/62]		Loss: 0.1431
2019-10-28 15:39:38,259 Testing Epoch [25/40] Iter[15/62]		Loss: 0.1449
2019-10-28 15:39:38,277 Testing Epoch [25/40] Iter[16/62]		Loss: 0.1419
2019-10-28 15:39:38,305 Testing Epoch [25/40] Iter[17/62]		Loss: 0.1426
2019-10-28 15:39:38,323 Testing Epoch [25/40] Iter[18/62]		Loss: 0.1401
2019-10-28 15:39:38,340 Testing Epoch [25/40] Iter[19/62]		Loss: 0.1383
2019-10-28 15:39:38,370 Testing Epoch [25/40] Iter[20/62]		Loss: 0.1399
2019-10-28 15:39:38,397 Testing Epoch [25/40] Iter[21/62]		Loss: 0.1383
2019-10-28 15:39:38,417 Testing Epoch [25/40] Iter[22/62]		Loss: 0.1398
2019-10-28 15:39:38,435 Testing Epoch [25/40] Iter[23/62]		Loss: 0.1388
2019-10-28 15:39:38,461 Testing Epoch [25/40] Iter[24/62]		Loss: 0.1422
2019-10-28 15:39:38,479 Testing Epoch [25/40] Iter[25/62]		Loss: 0.1413
2019-10-28 15:39:38,505 Testing Epoch [25/40] Iter[26/62]		Loss: 0.1400
2019-10-28 15:39:38,525 Testing Epoch [25/40] Iter[27/62]		Loss: 0.1474
2019-10-28 15:39:38,549 Testing Epoch [25/40] Iter[28/62]		Loss: 0.1510
2019-10-28 15:39:38,567 Testing Epoch [25/40] Iter[29/62]		Loss: 0.1510
2019-10-28 15:39:38,594 Testing Epoch [25/40] Iter[30/62]		Loss: 0.1512
2019-10-28 15:39:38,614 Testing Epoch [25/40] Iter[31/62]		Loss: 0.1502
2019-10-28 15:39:38,641 Testing Epoch [25/40] Iter[32/62]		Loss: 0.1518
2019-10-28 15:39:38,663 Testing Epoch [25/40] Iter[33/62]		Loss: 0.1509
2019-10-28 15:39:38,689 Testing Epoch [25/40] Iter[34/62]		Loss: 0.1531
2019-10-28 15:39:38,709 Testing Epoch [25/40] Iter[35/62]		Loss: 0.1528
2019-10-28 15:39:38,727 Testing Epoch [25/40] Iter[36/62]		Loss: 0.1508
2019-10-28 15:39:38,744 Testing Epoch [25/40] Iter[37/62]		Loss: 0.1497
2019-10-28 15:39:38,774 Testing Epoch [25/40] Iter[38/62]		Loss: 0.1487
2019-10-28 15:39:38,792 Testing Epoch [25/40] Iter[39/62]		Loss: 0.1490
2019-10-28 15:39:38,810 Testing Epoch [25/40] Iter[40/62]		Loss: 0.1507
2019-10-28 15:39:38,837 Testing Epoch [25/40] Iter[41/62]		Loss: 0.1521
2019-10-28 15:39:38,858 Testing Epoch [25/40] Iter[42/62]		Loss: 0.1502
2019-10-28 15:39:38,877 Testing Epoch [25/40] Iter[43/62]		Loss: 0.1495
2019-10-28 15:39:38,895 Testing Epoch [25/40] Iter[44/62]		Loss: 0.1479
2019-10-28 15:39:38,930 Testing Epoch [25/40] Iter[45/62]		Loss: 0.1477
2019-10-28 15:39:38,947 Testing Epoch [25/40] Iter[46/62]		Loss: 0.1474
2019-10-28 15:39:38,965 Testing Epoch [25/40] Iter[47/62]		Loss: 0.1533
2019-10-28 15:39:38,983 Testing Epoch [25/40] Iter[48/62]		Loss: 0.1523
2019-10-28 15:39:39,021 Testing Epoch [25/40] Iter[49/62]		Loss: 0.1544
2019-10-28 15:39:39,042 Testing Epoch [25/40] Iter[50/62]		Loss: 0.1535
2019-10-28 15:39:39,060 Testing Epoch [25/40] Iter[51/62]		Loss: 0.1534
2019-10-28 15:39:39,077 Testing Epoch [25/40] Iter[52/62]		Loss: 0.1521
2019-10-28 15:39:39,106 Testing Epoch [25/40] Iter[53/62]		Loss: 0.1524
2019-10-28 15:39:39,130 Testing Epoch [25/40] Iter[54/62]		Loss: 0.1512
2019-10-28 15:39:39,147 Testing Epoch [25/40] Iter[55/62]		Loss: 0.1511
2019-10-28 15:39:39,164 Testing Epoch [25/40] Iter[56/62]		Loss: 0.1504
2019-10-28 15:39:39,180 Testing Epoch [25/40] Iter[57/62]		Loss: 0.1506
2019-10-28 15:39:39,197 Testing Epoch [25/40] Iter[58/62]		Loss: 0.1501
2019-10-28 15:39:39,213 Testing Epoch [25/40] Iter[59/62]		Loss: 0.1512
2019-10-28 15:39:39,230 Testing Epoch [25/40] Iter[60/62]		Loss: 0.1504
2019-10-28 15:39:39,246 Testing Epoch [25/40] Iter[61/62]		Loss: 0.1502
2019-10-28 15:39:39,256 Testing Epoch [25/40] Iter[62/62]		Loss: 0.1508
2019-10-28 15:39:39,325 Saving the Model
2019-10-28 15:39:39,757 Training Epoch [26/40] Iter[0/312]		Loss: 0.1988
2019-10-28 15:39:39,835 Training Epoch [26/40] Iter[1/312]		Loss: 0.1423
2019-10-28 15:39:39,914 Training Epoch [26/40] Iter[2/312]		Loss: 0.1226
2019-10-28 15:39:39,993 Training Epoch [26/40] Iter[3/312]		Loss: 0.1277
2019-10-28 15:39:40,074 Training Epoch [26/40] Iter[4/312]		Loss: 0.1152
2019-10-28 15:39:40,152 Training Epoch [26/40] Iter[5/312]		Loss: 0.1106
2019-10-28 15:39:40,230 Training Epoch [26/40] Iter[6/312]		Loss: 0.1068
2019-10-28 15:39:40,309 Training Epoch [26/40] Iter[7/312]		Loss: 0.1182
2019-10-28 15:39:40,388 Training Epoch [26/40] Iter[8/312]		Loss: 0.1131
2019-10-28 15:39:40,466 Training Epoch [26/40] Iter[9/312]		Loss: 0.1135
2019-10-28 15:39:40,545 Training Epoch [26/40] Iter[10/312]		Loss: 0.1129
2019-10-28 15:39:40,624 Training Epoch [26/40] Iter[11/312]		Loss: 0.1151
2019-10-28 15:39:40,703 Training Epoch [26/40] Iter[12/312]		Loss: 0.1124
2019-10-28 15:39:40,782 Training Epoch [26/40] Iter[13/312]		Loss: 0.1120
2019-10-28 15:39:40,861 Training Epoch [26/40] Iter[14/312]		Loss: 0.1109
2019-10-28 15:39:40,940 Training Epoch [26/40] Iter[15/312]		Loss: 0.1077
2019-10-28 15:39:41,018 Training Epoch [26/40] Iter[16/312]		Loss: 0.1064
2019-10-28 15:39:41,097 Training Epoch [26/40] Iter[17/312]		Loss: 0.1064
2019-10-28 15:39:41,176 Training Epoch [26/40] Iter[18/312]		Loss: 0.1056
2019-10-28 15:39:41,255 Training Epoch [26/40] Iter[19/312]		Loss: 0.1060
2019-10-28 15:39:41,334 Training Epoch [26/40] Iter[20/312]		Loss: 0.1061
2019-10-28 15:39:41,413 Training Epoch [26/40] Iter[21/312]		Loss: 0.1051
2019-10-28 15:39:41,491 Training Epoch [26/40] Iter[22/312]		Loss: 0.1074
2019-10-28 15:39:41,574 Training Epoch [26/40] Iter[23/312]		Loss: 0.1082
2019-10-28 15:39:41,653 Training Epoch [26/40] Iter[24/312]		Loss: 0.1073
2019-10-28 15:39:41,734 Training Epoch [26/40] Iter[25/312]		Loss: 0.1099
2019-10-28 15:39:41,813 Training Epoch [26/40] Iter[26/312]		Loss: 0.1091
2019-10-28 15:39:41,892 Training Epoch [26/40] Iter[27/312]		Loss: 0.1087
2019-10-28 15:39:41,971 Training Epoch [26/40] Iter[28/312]		Loss: 0.1104
2019-10-28 15:39:42,049 Training Epoch [26/40] Iter[29/312]		Loss: 0.1098
2019-10-28 15:39:42,128 Training Epoch [26/40] Iter[30/312]		Loss: 0.1109
2019-10-28 15:39:42,207 Training Epoch [26/40] Iter[31/312]		Loss: 0.1118
2019-10-28 15:39:42,286 Training Epoch [26/40] Iter[32/312]		Loss: 0.1119
2019-10-28 15:39:42,365 Training Epoch [26/40] Iter[33/312]		Loss: 0.1113
2019-10-28 15:39:42,444 Training Epoch [26/40] Iter[34/312]		Loss: 0.1106
2019-10-28 15:39:42,523 Training Epoch [26/40] Iter[35/312]		Loss: 0.1100
2019-10-28 15:39:42,602 Training Epoch [26/40] Iter[36/312]		Loss: 0.1102
2019-10-28 15:39:42,681 Training Epoch [26/40] Iter[37/312]		Loss: 0.1108
2019-10-28 15:39:42,760 Training Epoch [26/40] Iter[38/312]		Loss: 0.1098
2019-10-28 15:39:42,839 Training Epoch [26/40] Iter[39/312]		Loss: 0.1106
2019-10-28 15:39:42,918 Training Epoch [26/40] Iter[40/312]		Loss: 0.1108
2019-10-28 15:39:42,996 Training Epoch [26/40] Iter[41/312]		Loss: 0.1106
2019-10-28 15:39:43,075 Training Epoch [26/40] Iter[42/312]		Loss: 0.1124
2019-10-28 15:39:43,154 Training Epoch [26/40] Iter[43/312]		Loss: 0.1128
2019-10-28 15:39:43,233 Training Epoch [26/40] Iter[44/312]		Loss: 0.1127
2019-10-28 15:39:43,312 Training Epoch [26/40] Iter[45/312]		Loss: 0.1130
2019-10-28 15:39:43,391 Training Epoch [26/40] Iter[46/312]		Loss: 0.1131
2019-10-28 15:39:43,470 Training Epoch [26/40] Iter[47/312]		Loss: 0.1142
2019-10-28 15:39:43,549 Training Epoch [26/40] Iter[48/312]		Loss: 0.1139
2019-10-28 15:39:43,629 Training Epoch [26/40] Iter[49/312]		Loss: 0.1131
2019-10-28 15:39:43,707 Training Epoch [26/40] Iter[50/312]		Loss: 0.1126
2019-10-28 15:39:43,787 Training Epoch [26/40] Iter[51/312]		Loss: 0.1124
2019-10-28 15:39:43,865 Training Epoch [26/40] Iter[52/312]		Loss: 0.1125
2019-10-28 15:39:43,944 Training Epoch [26/40] Iter[53/312]		Loss: 0.1128
2019-10-28 15:39:44,023 Training Epoch [26/40] Iter[54/312]		Loss: 0.1122
2019-10-28 15:39:44,102 Training Epoch [26/40] Iter[55/312]		Loss: 0.1126
2019-10-28 15:39:44,180 Training Epoch [26/40] Iter[56/312]		Loss: 0.1129
2019-10-28 15:39:44,259 Training Epoch [26/40] Iter[57/312]		Loss: 0.1126
2019-10-28 15:39:44,338 Training Epoch [26/40] Iter[58/312]		Loss: 0.1124
2019-10-28 15:39:44,417 Training Epoch [26/40] Iter[59/312]		Loss: 0.1122
2019-10-28 15:39:44,496 Training Epoch [26/40] Iter[60/312]		Loss: 0.1119
2019-10-28 15:39:44,575 Training Epoch [26/40] Iter[61/312]		Loss: 0.1116
2019-10-28 15:39:44,653 Training Epoch [26/40] Iter[62/312]		Loss: 0.1115
2019-10-28 15:39:44,732 Training Epoch [26/40] Iter[63/312]		Loss: 0.1111
2019-10-28 15:39:44,811 Training Epoch [26/40] Iter[64/312]		Loss: 0.1131
2019-10-28 15:39:44,890 Training Epoch [26/40] Iter[65/312]		Loss: 0.1125
2019-10-28 15:39:44,969 Training Epoch [26/40] Iter[66/312]		Loss: 0.1117
2019-10-28 15:39:45,047 Training Epoch [26/40] Iter[67/312]		Loss: 0.1117
2019-10-28 15:39:45,126 Training Epoch [26/40] Iter[68/312]		Loss: 0.1119
2019-10-28 15:39:45,205 Training Epoch [26/40] Iter[69/312]		Loss: 0.1118
2019-10-28 15:39:45,284 Training Epoch [26/40] Iter[70/312]		Loss: 0.1117
2019-10-28 15:39:45,363 Training Epoch [26/40] Iter[71/312]		Loss: 0.1115
2019-10-28 15:39:45,442 Training Epoch [26/40] Iter[72/312]		Loss: 0.1111
2019-10-28 15:39:45,520 Training Epoch [26/40] Iter[73/312]		Loss: 0.1117
2019-10-28 15:39:45,599 Training Epoch [26/40] Iter[74/312]		Loss: 0.1113
2019-10-28 15:39:45,678 Training Epoch [26/40] Iter[75/312]		Loss: 0.1112
2019-10-28 15:39:45,757 Training Epoch [26/40] Iter[76/312]		Loss: 0.1107
2019-10-28 15:39:45,835 Training Epoch [26/40] Iter[77/312]		Loss: 0.1104
2019-10-28 15:39:45,914 Training Epoch [26/40] Iter[78/312]		Loss: 0.1100
2019-10-28 15:39:45,993 Training Epoch [26/40] Iter[79/312]		Loss: 0.1097
2019-10-28 15:39:46,072 Training Epoch [26/40] Iter[80/312]		Loss: 0.1096
2019-10-28 15:39:46,151 Training Epoch [26/40] Iter[81/312]		Loss: 0.1093
2019-10-28 15:39:46,230 Training Epoch [26/40] Iter[82/312]		Loss: 0.1094
2019-10-28 15:39:46,309 Training Epoch [26/40] Iter[83/312]		Loss: 0.1092
2019-10-28 15:39:46,388 Training Epoch [26/40] Iter[84/312]		Loss: 0.1096
2019-10-28 15:39:46,467 Training Epoch [26/40] Iter[85/312]		Loss: 0.1096
2019-10-28 15:39:46,547 Training Epoch [26/40] Iter[86/312]		Loss: 0.1093
2019-10-28 15:39:46,626 Training Epoch [26/40] Iter[87/312]		Loss: 0.1100
2019-10-28 15:39:46,705 Training Epoch [26/40] Iter[88/312]		Loss: 0.1098
2019-10-28 15:39:46,784 Training Epoch [26/40] Iter[89/312]		Loss: 0.1107
2019-10-28 15:39:46,863 Training Epoch [26/40] Iter[90/312]		Loss: 0.1108
2019-10-28 15:39:46,942 Training Epoch [26/40] Iter[91/312]		Loss: 0.1109
2019-10-28 15:39:47,021 Training Epoch [26/40] Iter[92/312]		Loss: 0.1111
2019-10-28 15:39:47,100 Training Epoch [26/40] Iter[93/312]		Loss: 0.1109
2019-10-28 15:39:47,178 Training Epoch [26/40] Iter[94/312]		Loss: 0.1109
2019-10-28 15:39:47,257 Training Epoch [26/40] Iter[95/312]		Loss: 0.1107
2019-10-28 15:39:47,336 Training Epoch [26/40] Iter[96/312]		Loss: 0.1110
2019-10-28 15:39:47,415 Training Epoch [26/40] Iter[97/312]		Loss: 0.1105
2019-10-28 15:39:47,494 Training Epoch [26/40] Iter[98/312]		Loss: 0.1106
2019-10-28 15:39:47,573 Training Epoch [26/40] Iter[99/312]		Loss: 0.1108
2019-10-28 15:39:47,652 Training Epoch [26/40] Iter[100/312]		Loss: 0.1107
2019-10-28 15:39:47,734 Training Epoch [26/40] Iter[101/312]		Loss: 0.1115
2019-10-28 15:39:47,813 Training Epoch [26/40] Iter[102/312]		Loss: 0.1116
2019-10-28 15:39:47,892 Training Epoch [26/40] Iter[103/312]		Loss: 0.1112
2019-10-28 15:39:47,971 Training Epoch [26/40] Iter[104/312]		Loss: 0.1111
2019-10-28 15:39:48,050 Training Epoch [26/40] Iter[105/312]		Loss: 0.1111
2019-10-28 15:39:48,129 Training Epoch [26/40] Iter[106/312]		Loss: 0.1109
2019-10-28 15:39:48,208 Training Epoch [26/40] Iter[107/312]		Loss: 0.1108
2019-10-28 15:39:48,287 Training Epoch [26/40] Iter[108/312]		Loss: 0.1105
2019-10-28 15:39:48,366 Training Epoch [26/40] Iter[109/312]		Loss: 0.1105
2019-10-28 15:39:48,445 Training Epoch [26/40] Iter[110/312]		Loss: 0.1103
2019-10-28 15:39:48,524 Training Epoch [26/40] Iter[111/312]		Loss: 0.1101
2019-10-28 15:39:48,603 Training Epoch [26/40] Iter[112/312]		Loss: 0.1098
2019-10-28 15:39:48,682 Training Epoch [26/40] Iter[113/312]		Loss: 0.1094
2019-10-28 15:39:48,761 Training Epoch [26/40] Iter[114/312]		Loss: 0.1095
2019-10-28 15:39:48,840 Training Epoch [26/40] Iter[115/312]		Loss: 0.1093
2019-10-28 15:39:48,924 Training Epoch [26/40] Iter[116/312]		Loss: 0.1098
2019-10-28 15:39:49,003 Training Epoch [26/40] Iter[117/312]		Loss: 0.1102
2019-10-28 15:39:49,082 Training Epoch [26/40] Iter[118/312]		Loss: 0.1099
2019-10-28 15:39:49,161 Training Epoch [26/40] Iter[119/312]		Loss: 0.1099
2019-10-28 15:39:49,243 Training Epoch [26/40] Iter[120/312]		Loss: 0.1105
2019-10-28 15:39:49,321 Training Epoch [26/40] Iter[121/312]		Loss: 0.1107
2019-10-28 15:39:49,400 Training Epoch [26/40] Iter[122/312]		Loss: 0.1109
2019-10-28 15:39:49,479 Training Epoch [26/40] Iter[123/312]		Loss: 0.1113
2019-10-28 15:39:49,564 Training Epoch [26/40] Iter[124/312]		Loss: 0.1118
2019-10-28 15:39:49,642 Training Epoch [26/40] Iter[125/312]		Loss: 0.1116
2019-10-28 15:39:49,721 Training Epoch [26/40] Iter[126/312]		Loss: 0.1118
2019-10-28 15:39:49,800 Training Epoch [26/40] Iter[127/312]		Loss: 0.1119
2019-10-28 15:39:49,879 Training Epoch [26/40] Iter[128/312]		Loss: 0.1118
2019-10-28 15:39:49,958 Training Epoch [26/40] Iter[129/312]		Loss: 0.1126
2019-10-28 15:39:50,037 Training Epoch [26/40] Iter[130/312]		Loss: 0.1125
2019-10-28 15:39:50,116 Training Epoch [26/40] Iter[131/312]		Loss: 0.1122
2019-10-28 15:39:50,194 Training Epoch [26/40] Iter[132/312]		Loss: 0.1122
2019-10-28 15:39:50,274 Training Epoch [26/40] Iter[133/312]		Loss: 0.1121
2019-10-28 15:39:50,353 Training Epoch [26/40] Iter[134/312]		Loss: 0.1120
2019-10-28 15:39:50,432 Training Epoch [26/40] Iter[135/312]		Loss: 0.1125
2019-10-28 15:39:50,510 Training Epoch [26/40] Iter[136/312]		Loss: 0.1132
2019-10-28 15:39:50,589 Training Epoch [26/40] Iter[137/312]		Loss: 0.1129
2019-10-28 15:39:50,668 Training Epoch [26/40] Iter[138/312]		Loss: 0.1136
2019-10-28 15:39:50,747 Training Epoch [26/40] Iter[139/312]		Loss: 0.1144
2019-10-28 15:39:50,826 Training Epoch [26/40] Iter[140/312]		Loss: 0.1147
2019-10-28 15:39:50,905 Training Epoch [26/40] Iter[141/312]		Loss: 0.1147
2019-10-28 15:39:50,984 Training Epoch [26/40] Iter[142/312]		Loss: 0.1146
2019-10-28 15:39:51,063 Training Epoch [26/40] Iter[143/312]		Loss: 0.1145
2019-10-28 15:39:51,142 Training Epoch [26/40] Iter[144/312]		Loss: 0.1147
2019-10-28 15:39:51,221 Training Epoch [26/40] Iter[145/312]		Loss: 0.1145
2019-10-28 15:39:51,300 Training Epoch [26/40] Iter[146/312]		Loss: 0.1147
2019-10-28 15:39:51,379 Training Epoch [26/40] Iter[147/312]		Loss: 0.1147
2019-10-28 15:39:51,458 Training Epoch [26/40] Iter[148/312]		Loss: 0.1146
2019-10-28 15:39:51,537 Training Epoch [26/40] Iter[149/312]		Loss: 0.1146
2019-10-28 15:39:51,616 Training Epoch [26/40] Iter[150/312]		Loss: 0.1148
2019-10-28 15:39:51,695 Training Epoch [26/40] Iter[151/312]		Loss: 0.1152
2019-10-28 15:39:51,774 Training Epoch [26/40] Iter[152/312]		Loss: 0.1154
2019-10-28 15:39:51,853 Training Epoch [26/40] Iter[153/312]		Loss: 0.1152
2019-10-28 15:39:51,932 Training Epoch [26/40] Iter[154/312]		Loss: 0.1149
2019-10-28 15:39:52,011 Training Epoch [26/40] Iter[155/312]		Loss: 0.1150
2019-10-28 15:39:52,090 Training Epoch [26/40] Iter[156/312]		Loss: 0.1149
2019-10-28 15:39:52,169 Training Epoch [26/40] Iter[157/312]		Loss: 0.1150
2019-10-28 15:39:52,248 Training Epoch [26/40] Iter[158/312]		Loss: 0.1152
2019-10-28 15:39:52,327 Training Epoch [26/40] Iter[159/312]		Loss: 0.1152
2019-10-28 15:39:52,406 Training Epoch [26/40] Iter[160/312]		Loss: 0.1153
2019-10-28 15:39:52,485 Training Epoch [26/40] Iter[161/312]		Loss: 0.1155
2019-10-28 15:39:52,564 Training Epoch [26/40] Iter[162/312]		Loss: 0.1155
2019-10-28 15:39:52,643 Training Epoch [26/40] Iter[163/312]		Loss: 0.1155
2019-10-28 15:39:52,722 Training Epoch [26/40] Iter[164/312]		Loss: 0.1155
2019-10-28 15:39:52,801 Training Epoch [26/40] Iter[165/312]		Loss: 0.1155
2019-10-28 15:39:52,879 Training Epoch [26/40] Iter[166/312]		Loss: 0.1154
2019-10-28 15:39:52,958 Training Epoch [26/40] Iter[167/312]		Loss: 0.1152
2019-10-28 15:39:53,037 Training Epoch [26/40] Iter[168/312]		Loss: 0.1152
2019-10-28 15:39:53,117 Training Epoch [26/40] Iter[169/312]		Loss: 0.1152
2019-10-28 15:39:53,196 Training Epoch [26/40] Iter[170/312]		Loss: 0.1155
2019-10-28 15:39:53,280 Training Epoch [26/40] Iter[171/312]		Loss: 0.1153
2019-10-28 15:39:53,359 Training Epoch [26/40] Iter[172/312]		Loss: 0.1153
2019-10-28 15:39:53,437 Training Epoch [26/40] Iter[173/312]		Loss: 0.1153
2019-10-28 15:39:53,516 Training Epoch [26/40] Iter[174/312]		Loss: 0.1150
2019-10-28 15:39:53,599 Training Epoch [26/40] Iter[175/312]		Loss: 0.1149
2019-10-28 15:39:53,678 Training Epoch [26/40] Iter[176/312]		Loss: 0.1149
2019-10-28 15:39:53,757 Training Epoch [26/40] Iter[177/312]		Loss: 0.1147
2019-10-28 15:39:53,836 Training Epoch [26/40] Iter[178/312]		Loss: 0.1146
2019-10-28 15:39:53,915 Training Epoch [26/40] Iter[179/312]		Loss: 0.1149
2019-10-28 15:39:53,994 Training Epoch [26/40] Iter[180/312]		Loss: 0.1153
2019-10-28 15:39:54,073 Training Epoch [26/40] Iter[181/312]		Loss: 0.1154
2019-10-28 15:39:54,152 Training Epoch [26/40] Iter[182/312]		Loss: 0.1154
2019-10-28 15:39:54,232 Training Epoch [26/40] Iter[183/312]		Loss: 0.1152
2019-10-28 15:39:54,311 Training Epoch [26/40] Iter[184/312]		Loss: 0.1151
2019-10-28 15:39:54,389 Training Epoch [26/40] Iter[185/312]		Loss: 0.1150
2019-10-28 15:39:54,474 Training Epoch [26/40] Iter[186/312]		Loss: 0.1155
2019-10-28 15:39:54,552 Training Epoch [26/40] Iter[187/312]		Loss: 0.1155
2019-10-28 15:39:54,631 Training Epoch [26/40] Iter[188/312]		Loss: 0.1154
2019-10-28 15:39:54,710 Training Epoch [26/40] Iter[189/312]		Loss: 0.1154
2019-10-28 15:39:54,790 Training Epoch [26/40] Iter[190/312]		Loss: 0.1152
2019-10-28 15:39:54,869 Training Epoch [26/40] Iter[191/312]		Loss: 0.1152
2019-10-28 15:39:54,948 Training Epoch [26/40] Iter[192/312]		Loss: 0.1151
2019-10-28 15:39:55,027 Training Epoch [26/40] Iter[193/312]		Loss: 0.1150
2019-10-28 15:39:55,106 Training Epoch [26/40] Iter[194/312]		Loss: 0.1150
2019-10-28 15:39:55,185 Training Epoch [26/40] Iter[195/312]		Loss: 0.1149
2019-10-28 15:39:55,264 Training Epoch [26/40] Iter[196/312]		Loss: 0.1153
2019-10-28 15:39:55,343 Training Epoch [26/40] Iter[197/312]		Loss: 0.1153
2019-10-28 15:39:55,422 Training Epoch [26/40] Iter[198/312]		Loss: 0.1153
2019-10-28 15:39:55,501 Training Epoch [26/40] Iter[199/312]		Loss: 0.1153
2019-10-28 15:39:55,579 Training Epoch [26/40] Iter[200/312]		Loss: 0.1156
2019-10-28 15:39:55,658 Training Epoch [26/40] Iter[201/312]		Loss: 0.1157
2019-10-28 15:39:55,739 Training Epoch [26/40] Iter[202/312]		Loss: 0.1157
2019-10-28 15:39:55,818 Training Epoch [26/40] Iter[203/312]		Loss: 0.1158
2019-10-28 15:39:55,896 Training Epoch [26/40] Iter[204/312]		Loss: 0.1158
2019-10-28 15:39:55,975 Training Epoch [26/40] Iter[205/312]		Loss: 0.1156
2019-10-28 15:39:56,054 Training Epoch [26/40] Iter[206/312]		Loss: 0.1158
2019-10-28 15:39:56,133 Training Epoch [26/40] Iter[207/312]		Loss: 0.1163
2019-10-28 15:39:56,212 Training Epoch [26/40] Iter[208/312]		Loss: 0.1163
2019-10-28 15:39:56,291 Training Epoch [26/40] Iter[209/312]		Loss: 0.1165
2019-10-28 15:39:56,375 Training Epoch [26/40] Iter[210/312]		Loss: 0.1163
2019-10-28 15:39:56,454 Training Epoch [26/40] Iter[211/312]		Loss: 0.1170
2019-10-28 15:39:56,533 Training Epoch [26/40] Iter[212/312]		Loss: 0.1168
2019-10-28 15:39:56,612 Training Epoch [26/40] Iter[213/312]		Loss: 0.1167
2019-10-28 15:39:56,694 Training Epoch [26/40] Iter[214/312]		Loss: 0.1166
2019-10-28 15:39:56,773 Training Epoch [26/40] Iter[215/312]		Loss: 0.1166
2019-10-28 15:39:56,852 Training Epoch [26/40] Iter[216/312]		Loss: 0.1165
2019-10-28 15:39:56,931 Training Epoch [26/40] Iter[217/312]		Loss: 0.1166
2019-10-28 15:39:57,010 Training Epoch [26/40] Iter[218/312]		Loss: 0.1165
2019-10-28 15:39:57,089 Training Epoch [26/40] Iter[219/312]		Loss: 0.1165
2019-10-28 15:39:57,168 Training Epoch [26/40] Iter[220/312]		Loss: 0.1163
2019-10-28 15:39:57,247 Training Epoch [26/40] Iter[221/312]		Loss: 0.1162
2019-10-28 15:39:57,327 Training Epoch [26/40] Iter[222/312]		Loss: 0.1162
2019-10-28 15:39:57,406 Training Epoch [26/40] Iter[223/312]		Loss: 0.1161
2019-10-28 15:39:57,485 Training Epoch [26/40] Iter[224/312]		Loss: 0.1160
2019-10-28 15:39:57,564 Training Epoch [26/40] Iter[225/312]		Loss: 0.1162
2019-10-28 15:39:57,643 Training Epoch [26/40] Iter[226/312]		Loss: 0.1160
2019-10-28 15:39:57,722 Training Epoch [26/40] Iter[227/312]		Loss: 0.1162
2019-10-28 15:39:57,801 Training Epoch [26/40] Iter[228/312]		Loss: 0.1162
2019-10-28 15:39:57,880 Training Epoch [26/40] Iter[229/312]		Loss: 0.1162
2019-10-28 15:39:57,960 Training Epoch [26/40] Iter[230/312]		Loss: 0.1162
2019-10-28 15:39:58,039 Training Epoch [26/40] Iter[231/312]		Loss: 0.1161
2019-10-28 15:39:58,118 Training Epoch [26/40] Iter[232/312]		Loss: 0.1163
2019-10-28 15:39:58,198 Training Epoch [26/40] Iter[233/312]		Loss: 0.1162
2019-10-28 15:39:58,277 Training Epoch [26/40] Iter[234/312]		Loss: 0.1160
2019-10-28 15:39:58,358 Training Epoch [26/40] Iter[235/312]		Loss: 0.1160
2019-10-28 15:39:58,437 Training Epoch [26/40] Iter[236/312]		Loss: 0.1159
2019-10-28 15:39:58,516 Training Epoch [26/40] Iter[237/312]		Loss: 0.1158
2019-10-28 15:39:58,595 Training Epoch [26/40] Iter[238/312]		Loss: 0.1156
2019-10-28 15:39:58,674 Training Epoch [26/40] Iter[239/312]		Loss: 0.1159
2019-10-28 15:39:58,753 Training Epoch [26/40] Iter[240/312]		Loss: 0.1159
2019-10-28 15:39:58,832 Training Epoch [26/40] Iter[241/312]		Loss: 0.1158
2019-10-28 15:39:58,911 Training Epoch [26/40] Iter[242/312]		Loss: 0.1156
2019-10-28 15:39:58,990 Training Epoch [26/40] Iter[243/312]		Loss: 0.1156
2019-10-28 15:39:59,074 Training Epoch [26/40] Iter[244/312]		Loss: 0.1155
2019-10-28 15:39:59,153 Training Epoch [26/40] Iter[245/312]		Loss: 0.1155
2019-10-28 15:39:59,232 Training Epoch [26/40] Iter[246/312]		Loss: 0.1156
2019-10-28 15:39:59,311 Training Epoch [26/40] Iter[247/312]		Loss: 0.1156
2019-10-28 15:39:59,390 Training Epoch [26/40] Iter[248/312]		Loss: 0.1154
2019-10-28 15:39:59,469 Training Epoch [26/40] Iter[249/312]		Loss: 0.1154
2019-10-28 15:39:59,548 Training Epoch [26/40] Iter[250/312]		Loss: 0.1152
2019-10-28 15:39:59,627 Training Epoch [26/40] Iter[251/312]		Loss: 0.1152
2019-10-28 15:39:59,706 Training Epoch [26/40] Iter[252/312]		Loss: 0.1151
2019-10-28 15:39:59,785 Training Epoch [26/40] Iter[253/312]		Loss: 0.1152
2019-10-28 15:39:59,864 Training Epoch [26/40] Iter[254/312]		Loss: 0.1153
2019-10-28 15:39:59,943 Training Epoch [26/40] Iter[255/312]		Loss: 0.1152
2019-10-28 15:40:00,022 Training Epoch [26/40] Iter[256/312]		Loss: 0.1152
2019-10-28 15:40:00,101 Training Epoch [26/40] Iter[257/312]		Loss: 0.1151
2019-10-28 15:40:00,180 Training Epoch [26/40] Iter[258/312]		Loss: 0.1150
2019-10-28 15:40:00,259 Training Epoch [26/40] Iter[259/312]		Loss: 0.1152
2019-10-28 15:40:00,338 Training Epoch [26/40] Iter[260/312]		Loss: 0.1151
2019-10-28 15:40:00,417 Training Epoch [26/40] Iter[261/312]		Loss: 0.1151
2019-10-28 15:40:00,496 Training Epoch [26/40] Iter[262/312]		Loss: 0.1151
2019-10-28 15:40:00,574 Training Epoch [26/40] Iter[263/312]		Loss: 0.1150
2019-10-28 15:40:00,653 Training Epoch [26/40] Iter[264/312]		Loss: 0.1149
2019-10-28 15:40:00,732 Training Epoch [26/40] Iter[265/312]		Loss: 0.1147
2019-10-28 15:40:00,811 Training Epoch [26/40] Iter[266/312]		Loss: 0.1146
2019-10-28 15:40:00,890 Training Epoch [26/40] Iter[267/312]		Loss: 0.1145
2019-10-28 15:40:00,969 Training Epoch [26/40] Iter[268/312]		Loss: 0.1143
2019-10-28 15:40:01,048 Training Epoch [26/40] Iter[269/312]		Loss: 0.1142
2019-10-28 15:40:01,127 Training Epoch [26/40] Iter[270/312]		Loss: 0.1141
2019-10-28 15:40:01,206 Training Epoch [26/40] Iter[271/312]		Loss: 0.1140
2019-10-28 15:40:01,285 Training Epoch [26/40] Iter[272/312]		Loss: 0.1143
2019-10-28 15:40:01,364 Training Epoch [26/40] Iter[273/312]		Loss: 0.1142
2019-10-28 15:40:01,443 Training Epoch [26/40] Iter[274/312]		Loss: 0.1141
2019-10-28 15:40:01,522 Training Epoch [26/40] Iter[275/312]		Loss: 0.1140
2019-10-28 15:40:01,601 Training Epoch [26/40] Iter[276/312]		Loss: 0.1141
2019-10-28 15:40:01,681 Training Epoch [26/40] Iter[277/312]		Loss: 0.1141
2019-10-28 15:40:01,760 Training Epoch [26/40] Iter[278/312]		Loss: 0.1141
2019-10-28 15:40:01,839 Training Epoch [26/40] Iter[279/312]		Loss: 0.1141
2019-10-28 15:40:01,918 Training Epoch [26/40] Iter[280/312]		Loss: 0.1140
2019-10-28 15:40:01,997 Training Epoch [26/40] Iter[281/312]		Loss: 0.1139
2019-10-28 15:40:02,076 Training Epoch [26/40] Iter[282/312]		Loss: 0.1141
2019-10-28 15:40:02,155 Training Epoch [26/40] Iter[283/312]		Loss: 0.1139
2019-10-28 15:40:02,234 Training Epoch [26/40] Iter[284/312]		Loss: 0.1140
2019-10-28 15:40:02,313 Training Epoch [26/40] Iter[285/312]		Loss: 0.1139
2019-10-28 15:40:02,392 Training Epoch [26/40] Iter[286/312]		Loss: 0.1139
2019-10-28 15:40:02,471 Training Epoch [26/40] Iter[287/312]		Loss: 0.1140
2019-10-28 15:40:02,550 Training Epoch [26/40] Iter[288/312]		Loss: 0.1139
2019-10-28 15:40:02,629 Training Epoch [26/40] Iter[289/312]		Loss: 0.1140
2019-10-28 15:40:02,708 Training Epoch [26/40] Iter[290/312]		Loss: 0.1142
2019-10-28 15:40:02,787 Training Epoch [26/40] Iter[291/312]		Loss: 0.1141
2019-10-28 15:40:02,872 Training Epoch [26/40] Iter[292/312]		Loss: 0.1141
2019-10-28 15:40:02,951 Training Epoch [26/40] Iter[293/312]		Loss: 0.1141
2019-10-28 15:40:03,035 Training Epoch [26/40] Iter[294/312]		Loss: 0.1139
2019-10-28 15:40:03,114 Training Epoch [26/40] Iter[295/312]		Loss: 0.1139
2019-10-28 15:40:03,194 Training Epoch [26/40] Iter[296/312]		Loss: 0.1141
2019-10-28 15:40:03,273 Training Epoch [26/40] Iter[297/312]		Loss: 0.1142
2019-10-28 15:40:03,352 Training Epoch [26/40] Iter[298/312]		Loss: 0.1141
2019-10-28 15:40:03,431 Training Epoch [26/40] Iter[299/312]		Loss: 0.1140
2019-10-28 15:40:03,510 Training Epoch [26/40] Iter[300/312]		Loss: 0.1140
2019-10-28 15:40:03,590 Training Epoch [26/40] Iter[301/312]		Loss: 0.1140
2019-10-28 15:40:03,669 Training Epoch [26/40] Iter[302/312]		Loss: 0.1139
2019-10-28 15:40:03,748 Training Epoch [26/40] Iter[303/312]		Loss: 0.1139
2019-10-28 15:40:03,827 Training Epoch [26/40] Iter[304/312]		Loss: 0.1139
2019-10-28 15:40:03,905 Training Epoch [26/40] Iter[305/312]		Loss: 0.1139
2019-10-28 15:40:03,983 Training Epoch [26/40] Iter[306/312]		Loss: 0.1138
2019-10-28 15:40:04,062 Training Epoch [26/40] Iter[307/312]		Loss: 0.1137
2019-10-28 15:40:04,140 Training Epoch [26/40] Iter[308/312]		Loss: 0.1137
2019-10-28 15:40:04,218 Training Epoch [26/40] Iter[309/312]		Loss: 0.1141
2019-10-28 15:40:04,296 Training Epoch [26/40] Iter[310/312]		Loss: 0.1140
2019-10-28 15:40:04,374 Training Epoch [26/40] Iter[311/312]		Loss: 0.1139
2019-10-28 15:40:04,413 Training Epoch [26/40] Iter[312/312]		Loss: 0.1141
2019-10-28 15:40:04,838 Testing Epoch [26/40] Iter[0/62]		Loss: 0.1277
2019-10-28 15:40:04,868 Testing Epoch [26/40] Iter[1/62]		Loss: 0.1283
2019-10-28 15:40:04,894 Testing Epoch [26/40] Iter[2/62]		Loss: 0.1120
2019-10-28 15:40:04,922 Testing Epoch [26/40] Iter[3/62]		Loss: 0.1177
2019-10-28 15:40:04,946 Testing Epoch [26/40] Iter[4/62]		Loss: 0.1219
2019-10-28 15:40:04,969 Testing Epoch [26/40] Iter[5/62]		Loss: 0.1167
2019-10-28 15:40:04,995 Testing Epoch [26/40] Iter[6/62]		Loss: 0.1186
2019-10-28 15:40:05,017 Testing Epoch [26/40] Iter[7/62]		Loss: 0.1208
2019-10-28 15:40:05,042 Testing Epoch [26/40] Iter[8/62]		Loss: 0.1231
2019-10-28 15:40:05,060 Testing Epoch [26/40] Iter[9/62]		Loss: 0.1220
2019-10-28 15:40:05,078 Testing Epoch [26/40] Iter[10/62]		Loss: 0.1228
2019-10-28 15:40:05,110 Testing Epoch [26/40] Iter[11/62]		Loss: 0.1287
2019-10-28 15:40:05,132 Testing Epoch [26/40] Iter[12/62]		Loss: 0.1283
2019-10-28 15:40:05,150 Testing Epoch [26/40] Iter[13/62]		Loss: 0.1304
2019-10-28 15:40:05,168 Testing Epoch [26/40] Iter[14/62]		Loss: 0.1431
2019-10-28 15:40:05,197 Testing Epoch [26/40] Iter[15/62]		Loss: 0.1450
2019-10-28 15:40:05,223 Testing Epoch [26/40] Iter[16/62]		Loss: 0.1419
2019-10-28 15:40:05,240 Testing Epoch [26/40] Iter[17/62]		Loss: 0.1423
2019-10-28 15:40:05,265 Testing Epoch [26/40] Iter[18/62]		Loss: 0.1400
2019-10-28 15:40:05,283 Testing Epoch [26/40] Iter[19/62]		Loss: 0.1382
2019-10-28 15:40:05,309 Testing Epoch [26/40] Iter[20/62]		Loss: 0.1399
2019-10-28 15:40:05,334 Testing Epoch [26/40] Iter[21/62]		Loss: 0.1384
2019-10-28 15:40:05,352 Testing Epoch [26/40] Iter[22/62]		Loss: 0.1401
2019-10-28 15:40:05,369 Testing Epoch [26/40] Iter[23/62]		Loss: 0.1390
2019-10-28 15:40:05,402 Testing Epoch [26/40] Iter[24/62]		Loss: 0.1424
2019-10-28 15:40:05,420 Testing Epoch [26/40] Iter[25/62]		Loss: 0.1414
2019-10-28 15:40:05,438 Testing Epoch [26/40] Iter[26/62]		Loss: 0.1401
2019-10-28 15:40:05,455 Testing Epoch [26/40] Iter[27/62]		Loss: 0.1477
2019-10-28 15:40:05,486 Testing Epoch [26/40] Iter[28/62]		Loss: 0.1511
2019-10-28 15:40:05,504 Testing Epoch [26/40] Iter[29/62]		Loss: 0.1512
2019-10-28 15:40:05,523 Testing Epoch [26/40] Iter[30/62]		Loss: 0.1515
2019-10-28 15:40:05,550 Testing Epoch [26/40] Iter[31/62]		Loss: 0.1506
2019-10-28 15:40:05,574 Testing Epoch [26/40] Iter[32/62]		Loss: 0.1522
2019-10-28 15:40:05,593 Testing Epoch [26/40] Iter[33/62]		Loss: 0.1511
2019-10-28 15:40:05,611 Testing Epoch [26/40] Iter[34/62]		Loss: 0.1533
2019-10-28 15:40:05,642 Testing Epoch [26/40] Iter[35/62]		Loss: 0.1530
2019-10-28 15:40:05,665 Testing Epoch [26/40] Iter[36/62]		Loss: 0.1511
2019-10-28 15:40:05,683 Testing Epoch [26/40] Iter[37/62]		Loss: 0.1501
2019-10-28 15:40:05,710 Testing Epoch [26/40] Iter[38/62]		Loss: 0.1490
2019-10-28 15:40:05,738 Testing Epoch [26/40] Iter[39/62]		Loss: 0.1494
2019-10-28 15:40:05,755 Testing Epoch [26/40] Iter[40/62]		Loss: 0.1511
2019-10-28 15:40:05,786 Testing Epoch [26/40] Iter[41/62]		Loss: 0.1524
2019-10-28 15:40:05,806 Testing Epoch [26/40] Iter[42/62]		Loss: 0.1506
2019-10-28 15:40:05,824 Testing Epoch [26/40] Iter[43/62]		Loss: 0.1498
2019-10-28 15:40:05,849 Testing Epoch [26/40] Iter[44/62]		Loss: 0.1482
2019-10-28 15:40:05,867 Testing Epoch [26/40] Iter[45/62]		Loss: 0.1480
2019-10-28 15:40:05,897 Testing Epoch [26/40] Iter[46/62]		Loss: 0.1477
2019-10-28 15:40:05,914 Testing Epoch [26/40] Iter[47/62]		Loss: 0.1536
2019-10-28 15:40:05,941 Testing Epoch [26/40] Iter[48/62]		Loss: 0.1526
2019-10-28 15:40:05,959 Testing Epoch [26/40] Iter[49/62]		Loss: 0.1549
2019-10-28 15:40:05,986 Testing Epoch [26/40] Iter[50/62]		Loss: 0.1540
2019-10-28 15:40:06,003 Testing Epoch [26/40] Iter[51/62]		Loss: 0.1540
2019-10-28 15:40:06,034 Testing Epoch [26/40] Iter[52/62]		Loss: 0.1528
2019-10-28 15:40:06,054 Testing Epoch [26/40] Iter[53/62]		Loss: 0.1531
2019-10-28 15:40:06,072 Testing Epoch [26/40] Iter[54/62]		Loss: 0.1518
2019-10-28 15:40:06,089 Testing Epoch [26/40] Iter[55/62]		Loss: 0.1516
2019-10-28 15:40:06,106 Testing Epoch [26/40] Iter[56/62]		Loss: 0.1509
2019-10-28 15:40:06,122 Testing Epoch [26/40] Iter[57/62]		Loss: 0.1512
2019-10-28 15:40:06,139 Testing Epoch [26/40] Iter[58/62]		Loss: 0.1506
2019-10-28 15:40:06,156 Testing Epoch [26/40] Iter[59/62]		Loss: 0.1518
2019-10-28 15:40:06,172 Testing Epoch [26/40] Iter[60/62]		Loss: 0.1510
2019-10-28 15:40:06,189 Testing Epoch [26/40] Iter[61/62]		Loss: 0.1508
2019-10-28 15:40:06,198 Testing Epoch [26/40] Iter[62/62]		Loss: 0.1516
2019-10-28 15:40:06,709 Training Epoch [27/40] Iter[0/312]		Loss: 0.1559
2019-10-28 15:40:06,787 Training Epoch [27/40] Iter[1/312]		Loss: 0.1360
2019-10-28 15:40:06,865 Training Epoch [27/40] Iter[2/312]		Loss: 0.1272
2019-10-28 15:40:06,944 Training Epoch [27/40] Iter[3/312]		Loss: 0.1328
2019-10-28 15:40:07,026 Training Epoch [27/40] Iter[4/312]		Loss: 0.1205
2019-10-28 15:40:07,103 Training Epoch [27/40] Iter[5/312]		Loss: 0.1198
2019-10-28 15:40:07,181 Training Epoch [27/40] Iter[6/312]		Loss: 0.1178
2019-10-28 15:40:07,260 Training Epoch [27/40] Iter[7/312]		Loss: 0.1120
2019-10-28 15:40:07,339 Training Epoch [27/40] Iter[8/312]		Loss: 0.1220
2019-10-28 15:40:07,418 Training Epoch [27/40] Iter[9/312]		Loss: 0.1306
2019-10-28 15:40:07,498 Training Epoch [27/40] Iter[10/312]		Loss: 0.1255
2019-10-28 15:40:07,576 Training Epoch [27/40] Iter[11/312]		Loss: 0.1258
2019-10-28 15:40:07,656 Training Epoch [27/40] Iter[12/312]		Loss: 0.1244
2019-10-28 15:40:07,735 Training Epoch [27/40] Iter[13/312]		Loss: 0.1253
2019-10-28 15:40:07,813 Training Epoch [27/40] Iter[14/312]		Loss: 0.1233
2019-10-28 15:40:07,892 Training Epoch [27/40] Iter[15/312]		Loss: 0.1219
2019-10-28 15:40:07,971 Training Epoch [27/40] Iter[16/312]		Loss: 0.1218
2019-10-28 15:40:08,050 Training Epoch [27/40] Iter[17/312]		Loss: 0.1193
2019-10-28 15:40:08,129 Training Epoch [27/40] Iter[18/312]		Loss: 0.1194
2019-10-28 15:40:08,208 Training Epoch [27/40] Iter[19/312]		Loss: 0.1174
2019-10-28 15:40:08,287 Training Epoch [27/40] Iter[20/312]		Loss: 0.1186
2019-10-28 15:40:08,366 Training Epoch [27/40] Iter[21/312]		Loss: 0.1215
2019-10-28 15:40:08,446 Training Epoch [27/40] Iter[22/312]		Loss: 0.1210
2019-10-28 15:40:08,526 Training Epoch [27/40] Iter[23/312]		Loss: 0.1202
2019-10-28 15:40:08,605 Training Epoch [27/40] Iter[24/312]		Loss: 0.1203
2019-10-28 15:40:08,685 Training Epoch [27/40] Iter[25/312]		Loss: 0.1200
2019-10-28 15:40:08,765 Training Epoch [27/40] Iter[26/312]		Loss: 0.1191
2019-10-28 15:40:08,844 Training Epoch [27/40] Iter[27/312]		Loss: 0.1178
2019-10-28 15:40:08,923 Training Epoch [27/40] Iter[28/312]		Loss: 0.1170
2019-10-28 15:40:09,002 Training Epoch [27/40] Iter[29/312]		Loss: 0.1167
2019-10-28 15:40:09,082 Training Epoch [27/40] Iter[30/312]		Loss: 0.1171
2019-10-28 15:40:09,161 Training Epoch [27/40] Iter[31/312]		Loss: 0.1189
2019-10-28 15:40:09,240 Training Epoch [27/40] Iter[32/312]		Loss: 0.1184
2019-10-28 15:40:09,319 Training Epoch [27/40] Iter[33/312]		Loss: 0.1198
2019-10-28 15:40:09,398 Training Epoch [27/40] Iter[34/312]		Loss: 0.1194
2019-10-28 15:40:09,478 Training Epoch [27/40] Iter[35/312]		Loss: 0.1190
2019-10-28 15:40:09,557 Training Epoch [27/40] Iter[36/312]		Loss: 0.1184
2019-10-28 15:40:09,636 Training Epoch [27/40] Iter[37/312]		Loss: 0.1184
2019-10-28 15:40:09,715 Training Epoch [27/40] Iter[38/312]		Loss: 0.1176
2019-10-28 15:40:09,794 Training Epoch [27/40] Iter[39/312]		Loss: 0.1175
2019-10-28 15:40:09,874 Training Epoch [27/40] Iter[40/312]		Loss: 0.1169
2019-10-28 15:40:09,954 Training Epoch [27/40] Iter[41/312]		Loss: 0.1172
2019-10-28 15:40:10,034 Training Epoch [27/40] Iter[42/312]		Loss: 0.1167
2019-10-28 15:40:10,114 Training Epoch [27/40] Iter[43/312]		Loss: 0.1162
2019-10-28 15:40:10,193 Training Epoch [27/40] Iter[44/312]		Loss: 0.1169
2019-10-28 15:40:10,272 Training Epoch [27/40] Iter[45/312]		Loss: 0.1163
2019-10-28 15:40:10,351 Training Epoch [27/40] Iter[46/312]		Loss: 0.1164
2019-10-28 15:40:10,430 Training Epoch [27/40] Iter[47/312]		Loss: 0.1159
2019-10-28 15:40:10,510 Training Epoch [27/40] Iter[48/312]		Loss: 0.1150
2019-10-28 15:40:10,589 Training Epoch [27/40] Iter[49/312]		Loss: 0.1147
2019-10-28 15:40:10,668 Training Epoch [27/40] Iter[50/312]		Loss: 0.1142
2019-10-28 15:40:10,747 Training Epoch [27/40] Iter[51/312]		Loss: 0.1141
2019-10-28 15:40:10,826 Training Epoch [27/40] Iter[52/312]		Loss: 0.1141
2019-10-28 15:40:10,905 Training Epoch [27/40] Iter[53/312]		Loss: 0.1140
2019-10-28 15:40:10,984 Training Epoch [27/40] Iter[54/312]		Loss: 0.1140
2019-10-28 15:40:11,063 Training Epoch [27/40] Iter[55/312]		Loss: 0.1143
2019-10-28 15:40:11,142 Training Epoch [27/40] Iter[56/312]		Loss: 0.1144
2019-10-28 15:40:11,221 Training Epoch [27/40] Iter[57/312]		Loss: 0.1139
2019-10-28 15:40:11,300 Training Epoch [27/40] Iter[58/312]		Loss: 0.1139
2019-10-28 15:40:11,380 Training Epoch [27/40] Iter[59/312]		Loss: 0.1156
2019-10-28 15:40:11,459 Training Epoch [27/40] Iter[60/312]		Loss: 0.1158
2019-10-28 15:40:11,538 Training Epoch [27/40] Iter[61/312]		Loss: 0.1159
2019-10-28 15:40:11,617 Training Epoch [27/40] Iter[62/312]		Loss: 0.1154
2019-10-28 15:40:11,697 Training Epoch [27/40] Iter[63/312]		Loss: 0.1146
2019-10-28 15:40:11,776 Training Epoch [27/40] Iter[64/312]		Loss: 0.1143
2019-10-28 15:40:11,855 Training Epoch [27/40] Iter[65/312]		Loss: 0.1147
2019-10-28 15:40:11,934 Training Epoch [27/40] Iter[66/312]		Loss: 0.1143
2019-10-28 15:40:12,013 Training Epoch [27/40] Iter[67/312]		Loss: 0.1144
2019-10-28 15:40:12,092 Training Epoch [27/40] Iter[68/312]		Loss: 0.1141
2019-10-28 15:40:12,172 Training Epoch [27/40] Iter[69/312]		Loss: 0.1138
2019-10-28 15:40:12,251 Training Epoch [27/40] Iter[70/312]		Loss: 0.1139
2019-10-28 15:40:12,330 Training Epoch [27/40] Iter[71/312]		Loss: 0.1134
2019-10-28 15:40:12,409 Training Epoch [27/40] Iter[72/312]		Loss: 0.1135
2019-10-28 15:40:12,488 Training Epoch [27/40] Iter[73/312]		Loss: 0.1129
2019-10-28 15:40:12,567 Training Epoch [27/40] Iter[74/312]		Loss: 0.1122
2019-10-28 15:40:12,647 Training Epoch [27/40] Iter[75/312]		Loss: 0.1122
2019-10-28 15:40:12,726 Training Epoch [27/40] Iter[76/312]		Loss: 0.1129
2019-10-28 15:40:12,805 Training Epoch [27/40] Iter[77/312]		Loss: 0.1133
2019-10-28 15:40:12,884 Training Epoch [27/40] Iter[78/312]		Loss: 0.1132
2019-10-28 15:40:12,963 Training Epoch [27/40] Iter[79/312]		Loss: 0.1133
2019-10-28 15:40:13,042 Training Epoch [27/40] Iter[80/312]		Loss: 0.1130
2019-10-28 15:40:13,121 Training Epoch [27/40] Iter[81/312]		Loss: 0.1125
2019-10-28 15:40:13,201 Training Epoch [27/40] Iter[82/312]		Loss: 0.1130
2019-10-28 15:40:13,280 Training Epoch [27/40] Iter[83/312]		Loss: 0.1127
2019-10-28 15:40:13,359 Training Epoch [27/40] Iter[84/312]		Loss: 0.1123
2019-10-28 15:40:13,444 Training Epoch [27/40] Iter[85/312]		Loss: 0.1125
2019-10-28 15:40:13,527 Training Epoch [27/40] Iter[86/312]		Loss: 0.1126
2019-10-28 15:40:13,606 Training Epoch [27/40] Iter[87/312]		Loss: 0.1126
2019-10-28 15:40:13,686 Training Epoch [27/40] Iter[88/312]		Loss: 0.1124
2019-10-28 15:40:13,765 Training Epoch [27/40] Iter[89/312]		Loss: 0.1129
2019-10-28 15:40:13,844 Training Epoch [27/40] Iter[90/312]		Loss: 0.1126
2019-10-28 15:40:13,923 Training Epoch [27/40] Iter[91/312]		Loss: 0.1124
2019-10-28 15:40:14,002 Training Epoch [27/40] Iter[92/312]		Loss: 0.1127
2019-10-28 15:40:14,081 Training Epoch [27/40] Iter[93/312]		Loss: 0.1125
2019-10-28 15:40:14,160 Training Epoch [27/40] Iter[94/312]		Loss: 0.1132
2019-10-28 15:40:14,239 Training Epoch [27/40] Iter[95/312]		Loss: 0.1133
2019-10-28 15:40:14,318 Training Epoch [27/40] Iter[96/312]		Loss: 0.1131
2019-10-28 15:40:14,398 Training Epoch [27/40] Iter[97/312]		Loss: 0.1132
2019-10-28 15:40:14,486 Training Epoch [27/40] Iter[98/312]		Loss: 0.1134
2019-10-28 15:40:14,571 Training Epoch [27/40] Iter[99/312]		Loss: 0.1140
2019-10-28 15:40:14,650 Training Epoch [27/40] Iter[100/312]		Loss: 0.1136
2019-10-28 15:40:14,734 Training Epoch [27/40] Iter[101/312]		Loss: 0.1136
2019-10-28 15:40:14,813 Training Epoch [27/40] Iter[102/312]		Loss: 0.1135
2019-10-28 15:40:14,898 Training Epoch [27/40] Iter[103/312]		Loss: 0.1134
2019-10-28 15:40:14,983 Training Epoch [27/40] Iter[104/312]		Loss: 0.1132
2019-10-28 15:40:15,067 Training Epoch [27/40] Iter[105/312]		Loss: 0.1137
2019-10-28 15:40:15,151 Training Epoch [27/40] Iter[106/312]		Loss: 0.1135
2019-10-28 15:40:15,235 Training Epoch [27/40] Iter[107/312]		Loss: 0.1137
2019-10-28 15:40:15,314 Training Epoch [27/40] Iter[108/312]		Loss: 0.1134
2019-10-28 15:40:15,394 Training Epoch [27/40] Iter[109/312]		Loss: 0.1131
2019-10-28 15:40:15,473 Training Epoch [27/40] Iter[110/312]		Loss: 0.1132
2019-10-28 15:40:15,552 Training Epoch [27/40] Iter[111/312]		Loss: 0.1131
2019-10-28 15:40:15,631 Training Epoch [27/40] Iter[112/312]		Loss: 0.1132
2019-10-28 15:40:15,710 Training Epoch [27/40] Iter[113/312]		Loss: 0.1133
2019-10-28 15:40:15,789 Training Epoch [27/40] Iter[114/312]		Loss: 0.1133
2019-10-28 15:40:15,868 Training Epoch [27/40] Iter[115/312]		Loss: 0.1132
2019-10-28 15:40:15,947 Training Epoch [27/40] Iter[116/312]		Loss: 0.1128
2019-10-28 15:40:16,026 Training Epoch [27/40] Iter[117/312]		Loss: 0.1131
2019-10-28 15:40:16,105 Training Epoch [27/40] Iter[118/312]		Loss: 0.1131
2019-10-28 15:40:16,185 Training Epoch [27/40] Iter[119/312]		Loss: 0.1133
2019-10-28 15:40:16,264 Training Epoch [27/40] Iter[120/312]		Loss: 0.1132
2019-10-28 15:40:16,343 Training Epoch [27/40] Iter[121/312]		Loss: 0.1129
2019-10-28 15:40:16,422 Training Epoch [27/40] Iter[122/312]		Loss: 0.1128
2019-10-28 15:40:16,501 Training Epoch [27/40] Iter[123/312]		Loss: 0.1135
2019-10-28 15:40:16,580 Training Epoch [27/40] Iter[124/312]		Loss: 0.1135
2019-10-28 15:40:16,659 Training Epoch [27/40] Iter[125/312]		Loss: 0.1141
2019-10-28 15:40:16,744 Training Epoch [27/40] Iter[126/312]		Loss: 0.1143
2019-10-28 15:40:16,823 Training Epoch [27/40] Iter[127/312]		Loss: 0.1143
2019-10-28 15:40:16,902 Training Epoch [27/40] Iter[128/312]		Loss: 0.1148
2019-10-28 15:40:16,981 Training Epoch [27/40] Iter[129/312]		Loss: 0.1148
2019-10-28 15:40:17,063 Training Epoch [27/40] Iter[130/312]		Loss: 0.1146
2019-10-28 15:40:17,142 Training Epoch [27/40] Iter[131/312]		Loss: 0.1144
2019-10-28 15:40:17,221 Training Epoch [27/40] Iter[132/312]		Loss: 0.1140
2019-10-28 15:40:17,300 Training Epoch [27/40] Iter[133/312]		Loss: 0.1137
2019-10-28 15:40:17,379 Training Epoch [27/40] Iter[134/312]		Loss: 0.1137
2019-10-28 15:40:17,459 Training Epoch [27/40] Iter[135/312]		Loss: 0.1140
2019-10-28 15:40:17,538 Training Epoch [27/40] Iter[136/312]		Loss: 0.1139
2019-10-28 15:40:17,616 Training Epoch [27/40] Iter[137/312]		Loss: 0.1137
2019-10-28 15:40:17,696 Training Epoch [27/40] Iter[138/312]		Loss: 0.1137
2019-10-28 15:40:17,775 Training Epoch [27/40] Iter[139/312]		Loss: 0.1135
2019-10-28 15:40:17,853 Training Epoch [27/40] Iter[140/312]		Loss: 0.1145
2019-10-28 15:40:17,932 Training Epoch [27/40] Iter[141/312]		Loss: 0.1151
2019-10-28 15:40:18,011 Training Epoch [27/40] Iter[142/312]		Loss: 0.1151
2019-10-28 15:40:18,090 Training Epoch [27/40] Iter[143/312]		Loss: 0.1155
2019-10-28 15:40:18,170 Training Epoch [27/40] Iter[144/312]		Loss: 0.1156
2019-10-28 15:40:18,249 Training Epoch [27/40] Iter[145/312]		Loss: 0.1158
2019-10-28 15:40:18,328 Training Epoch [27/40] Iter[146/312]		Loss: 0.1158
2019-10-28 15:40:18,407 Training Epoch [27/40] Iter[147/312]		Loss: 0.1156
2019-10-28 15:40:18,486 Training Epoch [27/40] Iter[148/312]		Loss: 0.1155
2019-10-28 15:40:18,565 Training Epoch [27/40] Iter[149/312]		Loss: 0.1153
2019-10-28 15:40:18,644 Training Epoch [27/40] Iter[150/312]		Loss: 0.1152
2019-10-28 15:40:18,724 Training Epoch [27/40] Iter[151/312]		Loss: 0.1151
2019-10-28 15:40:18,802 Training Epoch [27/40] Iter[152/312]		Loss: 0.1149
2019-10-28 15:40:18,881 Training Epoch [27/40] Iter[153/312]		Loss: 0.1149
2019-10-28 15:40:18,960 Training Epoch [27/40] Iter[154/312]		Loss: 0.1149
2019-10-28 15:40:19,039 Training Epoch [27/40] Iter[155/312]		Loss: 0.1155
2019-10-28 15:40:19,118 Training Epoch [27/40] Iter[156/312]		Loss: 0.1156
2019-10-28 15:40:19,198 Training Epoch [27/40] Iter[157/312]		Loss: 0.1156
2019-10-28 15:40:19,277 Training Epoch [27/40] Iter[158/312]		Loss: 0.1156
2019-10-28 15:40:19,356 Training Epoch [27/40] Iter[159/312]		Loss: 0.1155
2019-10-28 15:40:19,436 Training Epoch [27/40] Iter[160/312]		Loss: 0.1155
2019-10-28 15:40:19,515 Training Epoch [27/40] Iter[161/312]		Loss: 0.1163
2019-10-28 15:40:19,595 Training Epoch [27/40] Iter[162/312]		Loss: 0.1168
2019-10-28 15:40:19,674 Training Epoch [27/40] Iter[163/312]		Loss: 0.1172
2019-10-28 15:40:19,753 Training Epoch [27/40] Iter[164/312]		Loss: 0.1172
2019-10-28 15:40:19,832 Training Epoch [27/40] Iter[165/312]		Loss: 0.1169
2019-10-28 15:40:19,911 Training Epoch [27/40] Iter[166/312]		Loss: 0.1170
2019-10-28 15:40:19,990 Training Epoch [27/40] Iter[167/312]		Loss: 0.1167
2019-10-28 15:40:20,068 Training Epoch [27/40] Iter[168/312]		Loss: 0.1169
2019-10-28 15:40:20,148 Training Epoch [27/40] Iter[169/312]		Loss: 0.1167
2019-10-28 15:40:20,227 Training Epoch [27/40] Iter[170/312]		Loss: 0.1165
2019-10-28 15:40:20,306 Training Epoch [27/40] Iter[171/312]		Loss: 0.1166
2019-10-28 15:40:20,385 Training Epoch [27/40] Iter[172/312]		Loss: 0.1164
2019-10-28 15:40:20,464 Training Epoch [27/40] Iter[173/312]		Loss: 0.1162
2019-10-28 15:40:20,543 Training Epoch [27/40] Iter[174/312]		Loss: 0.1161
2019-10-28 15:40:20,622 Training Epoch [27/40] Iter[175/312]		Loss: 0.1160
2019-10-28 15:40:20,700 Training Epoch [27/40] Iter[176/312]		Loss: 0.1162
2019-10-28 15:40:20,779 Training Epoch [27/40] Iter[177/312]		Loss: 0.1162
2019-10-28 15:40:20,858 Training Epoch [27/40] Iter[178/312]		Loss: 0.1167
2019-10-28 15:40:20,937 Training Epoch [27/40] Iter[179/312]		Loss: 0.1167
2019-10-28 15:40:21,016 Training Epoch [27/40] Iter[180/312]		Loss: 0.1166
2019-10-28 15:40:21,095 Training Epoch [27/40] Iter[181/312]		Loss: 0.1166
2019-10-28 15:40:21,174 Training Epoch [27/40] Iter[182/312]		Loss: 0.1166
2019-10-28 15:40:21,253 Training Epoch [27/40] Iter[183/312]		Loss: 0.1167
2019-10-28 15:40:21,331 Training Epoch [27/40] Iter[184/312]		Loss: 0.1165
2019-10-28 15:40:21,410 Training Epoch [27/40] Iter[185/312]		Loss: 0.1165
2019-10-28 15:40:21,489 Training Epoch [27/40] Iter[186/312]		Loss: 0.1163
2019-10-28 15:40:21,568 Training Epoch [27/40] Iter[187/312]		Loss: 0.1162
2019-10-28 15:40:21,647 Training Epoch [27/40] Iter[188/312]		Loss: 0.1160
2019-10-28 15:40:21,726 Training Epoch [27/40] Iter[189/312]		Loss: 0.1165
2019-10-28 15:40:21,804 Training Epoch [27/40] Iter[190/312]		Loss: 0.1163
2019-10-28 15:40:21,883 Training Epoch [27/40] Iter[191/312]		Loss: 0.1162
2019-10-28 15:40:21,962 Training Epoch [27/40] Iter[192/312]		Loss: 0.1160
2019-10-28 15:40:22,041 Training Epoch [27/40] Iter[193/312]		Loss: 0.1163
2019-10-28 15:40:22,120 Training Epoch [27/40] Iter[194/312]		Loss: 0.1161
2019-10-28 15:40:22,199 Training Epoch [27/40] Iter[195/312]		Loss: 0.1160
2019-10-28 15:40:22,278 Training Epoch [27/40] Iter[196/312]		Loss: 0.1157
2019-10-28 15:40:22,358 Training Epoch [27/40] Iter[197/312]		Loss: 0.1156
2019-10-28 15:40:22,437 Training Epoch [27/40] Iter[198/312]		Loss: 0.1154
2019-10-28 15:40:22,515 Training Epoch [27/40] Iter[199/312]		Loss: 0.1155
2019-10-28 15:40:22,594 Training Epoch [27/40] Iter[200/312]		Loss: 0.1156
2019-10-28 15:40:22,673 Training Epoch [27/40] Iter[201/312]		Loss: 0.1158
2019-10-28 15:40:22,752 Training Epoch [27/40] Iter[202/312]		Loss: 0.1158
2019-10-28 15:40:22,831 Training Epoch [27/40] Iter[203/312]		Loss: 0.1159
2019-10-28 15:40:22,909 Training Epoch [27/40] Iter[204/312]		Loss: 0.1157
2019-10-28 15:40:22,988 Training Epoch [27/40] Iter[205/312]		Loss: 0.1160
2019-10-28 15:40:23,067 Training Epoch [27/40] Iter[206/312]		Loss: 0.1160
2019-10-28 15:40:23,146 Training Epoch [27/40] Iter[207/312]		Loss: 0.1162
2019-10-28 15:40:23,225 Training Epoch [27/40] Iter[208/312]		Loss: 0.1162
2019-10-28 15:40:23,304 Training Epoch [27/40] Iter[209/312]		Loss: 0.1160
2019-10-28 15:40:23,383 Training Epoch [27/40] Iter[210/312]		Loss: 0.1158
2019-10-28 15:40:23,462 Training Epoch [27/40] Iter[211/312]		Loss: 0.1156
2019-10-28 15:40:23,541 Training Epoch [27/40] Iter[212/312]		Loss: 0.1155
2019-10-28 15:40:23,620 Training Epoch [27/40] Iter[213/312]		Loss: 0.1154
2019-10-28 15:40:23,699 Training Epoch [27/40] Iter[214/312]		Loss: 0.1154
2019-10-28 15:40:23,778 Training Epoch [27/40] Iter[215/312]		Loss: 0.1158
2019-10-28 15:40:23,858 Training Epoch [27/40] Iter[216/312]		Loss: 0.1159
2019-10-28 15:40:23,936 Training Epoch [27/40] Iter[217/312]		Loss: 0.1158
2019-10-28 15:40:24,015 Training Epoch [27/40] Iter[218/312]		Loss: 0.1157
2019-10-28 15:40:24,094 Training Epoch [27/40] Iter[219/312]		Loss: 0.1154
2019-10-28 15:40:24,173 Training Epoch [27/40] Iter[220/312]		Loss: 0.1156
2019-10-28 15:40:24,252 Training Epoch [27/40] Iter[221/312]		Loss: 0.1156
2019-10-28 15:40:24,331 Training Epoch [27/40] Iter[222/312]		Loss: 0.1158
2019-10-28 15:40:24,410 Training Epoch [27/40] Iter[223/312]		Loss: 0.1160
2019-10-28 15:40:24,489 Training Epoch [27/40] Iter[224/312]		Loss: 0.1159
2019-10-28 15:40:24,568 Training Epoch [27/40] Iter[225/312]		Loss: 0.1159
2019-10-28 15:40:24,647 Training Epoch [27/40] Iter[226/312]		Loss: 0.1160
2019-10-28 15:40:24,726 Training Epoch [27/40] Iter[227/312]		Loss: 0.1158
2019-10-28 15:40:24,805 Training Epoch [27/40] Iter[228/312]		Loss: 0.1156
2019-10-28 15:40:24,884 Training Epoch [27/40] Iter[229/312]		Loss: 0.1157
2019-10-28 15:40:24,963 Training Epoch [27/40] Iter[230/312]		Loss: 0.1156
2019-10-28 15:40:25,042 Training Epoch [27/40] Iter[231/312]		Loss: 0.1154
2019-10-28 15:40:25,121 Training Epoch [27/40] Iter[232/312]		Loss: 0.1154
2019-10-28 15:40:25,200 Training Epoch [27/40] Iter[233/312]		Loss: 0.1154
2019-10-28 15:40:25,279 Training Epoch [27/40] Iter[234/312]		Loss: 0.1153
2019-10-28 15:40:25,358 Training Epoch [27/40] Iter[235/312]		Loss: 0.1153
2019-10-28 15:40:25,437 Training Epoch [27/40] Iter[236/312]		Loss: 0.1151
2019-10-28 15:40:25,516 Training Epoch [27/40] Iter[237/312]		Loss: 0.1151
2019-10-28 15:40:25,596 Training Epoch [27/40] Iter[238/312]		Loss: 0.1154
2019-10-28 15:40:25,674 Training Epoch [27/40] Iter[239/312]		Loss: 0.1155
2019-10-28 15:40:25,753 Training Epoch [27/40] Iter[240/312]		Loss: 0.1154
2019-10-28 15:40:25,832 Training Epoch [27/40] Iter[241/312]		Loss: 0.1155
2019-10-28 15:40:25,911 Training Epoch [27/40] Iter[242/312]		Loss: 0.1155
2019-10-28 15:40:25,990 Training Epoch [27/40] Iter[243/312]		Loss: 0.1154
2019-10-28 15:40:26,069 Training Epoch [27/40] Iter[244/312]		Loss: 0.1153
2019-10-28 15:40:26,147 Training Epoch [27/40] Iter[245/312]		Loss: 0.1152
2019-10-28 15:40:26,226 Training Epoch [27/40] Iter[246/312]		Loss: 0.1151
2019-10-28 15:40:26,305 Training Epoch [27/40] Iter[247/312]		Loss: 0.1150
2019-10-28 15:40:26,384 Training Epoch [27/40] Iter[248/312]		Loss: 0.1149
2019-10-28 15:40:26,463 Training Epoch [27/40] Iter[249/312]		Loss: 0.1148
2019-10-28 15:40:26,542 Training Epoch [27/40] Iter[250/312]		Loss: 0.1147
2019-10-28 15:40:26,621 Training Epoch [27/40] Iter[251/312]		Loss: 0.1147
2019-10-28 15:40:26,700 Training Epoch [27/40] Iter[252/312]		Loss: 0.1147
2019-10-28 15:40:26,779 Training Epoch [27/40] Iter[253/312]		Loss: 0.1147
2019-10-28 15:40:26,858 Training Epoch [27/40] Iter[254/312]		Loss: 0.1147
2019-10-28 15:40:26,937 Training Epoch [27/40] Iter[255/312]		Loss: 0.1149
2019-10-28 15:40:27,017 Training Epoch [27/40] Iter[256/312]		Loss: 0.1148
2019-10-28 15:40:27,096 Training Epoch [27/40] Iter[257/312]		Loss: 0.1148
2019-10-28 15:40:27,175 Training Epoch [27/40] Iter[258/312]		Loss: 0.1148
2019-10-28 15:40:27,254 Training Epoch [27/40] Iter[259/312]		Loss: 0.1147
2019-10-28 15:40:27,333 Training Epoch [27/40] Iter[260/312]		Loss: 0.1147
2019-10-28 15:40:27,413 Training Epoch [27/40] Iter[261/312]		Loss: 0.1147
2019-10-28 15:40:27,492 Training Epoch [27/40] Iter[262/312]		Loss: 0.1148
2019-10-28 15:40:27,570 Training Epoch [27/40] Iter[263/312]		Loss: 0.1147
2019-10-28 15:40:27,650 Training Epoch [27/40] Iter[264/312]		Loss: 0.1149
2019-10-28 15:40:27,728 Training Epoch [27/40] Iter[265/312]		Loss: 0.1148
2019-10-28 15:40:27,807 Training Epoch [27/40] Iter[266/312]		Loss: 0.1150
2019-10-28 15:40:27,886 Training Epoch [27/40] Iter[267/312]		Loss: 0.1150
2019-10-28 15:40:27,965 Training Epoch [27/40] Iter[268/312]		Loss: 0.1150
2019-10-28 15:40:28,044 Training Epoch [27/40] Iter[269/312]		Loss: 0.1148
2019-10-28 15:40:28,123 Training Epoch [27/40] Iter[270/312]		Loss: 0.1148
2019-10-28 15:40:28,201 Training Epoch [27/40] Iter[271/312]		Loss: 0.1147
2019-10-28 15:40:28,281 Training Epoch [27/40] Iter[272/312]		Loss: 0.1148
2019-10-28 15:40:28,360 Training Epoch [27/40] Iter[273/312]		Loss: 0.1148
2019-10-28 15:40:28,439 Training Epoch [27/40] Iter[274/312]		Loss: 0.1148
2019-10-28 15:40:28,518 Training Epoch [27/40] Iter[275/312]		Loss: 0.1147
2019-10-28 15:40:28,597 Training Epoch [27/40] Iter[276/312]		Loss: 0.1148
2019-10-28 15:40:28,676 Training Epoch [27/40] Iter[277/312]		Loss: 0.1147
2019-10-28 15:40:28,755 Training Epoch [27/40] Iter[278/312]		Loss: 0.1146
2019-10-28 15:40:28,833 Training Epoch [27/40] Iter[279/312]		Loss: 0.1145
2019-10-28 15:40:28,913 Training Epoch [27/40] Iter[280/312]		Loss: 0.1144
2019-10-28 15:40:28,992 Training Epoch [27/40] Iter[281/312]		Loss: 0.1144
2019-10-28 15:40:29,071 Training Epoch [27/40] Iter[282/312]		Loss: 0.1143
2019-10-28 15:40:29,150 Training Epoch [27/40] Iter[283/312]		Loss: 0.1144
2019-10-28 15:40:29,230 Training Epoch [27/40] Iter[284/312]		Loss: 0.1142
2019-10-28 15:40:29,309 Training Epoch [27/40] Iter[285/312]		Loss: 0.1141
2019-10-28 15:40:29,388 Training Epoch [27/40] Iter[286/312]		Loss: 0.1140
2019-10-28 15:40:29,467 Training Epoch [27/40] Iter[287/312]		Loss: 0.1139
2019-10-28 15:40:29,546 Training Epoch [27/40] Iter[288/312]		Loss: 0.1138
2019-10-28 15:40:29,625 Training Epoch [27/40] Iter[289/312]		Loss: 0.1141
2019-10-28 15:40:29,703 Training Epoch [27/40] Iter[290/312]		Loss: 0.1142
2019-10-28 15:40:29,782 Training Epoch [27/40] Iter[291/312]		Loss: 0.1142
2019-10-28 15:40:29,861 Training Epoch [27/40] Iter[292/312]		Loss: 0.1141
2019-10-28 15:40:29,940 Training Epoch [27/40] Iter[293/312]		Loss: 0.1139
2019-10-28 15:40:30,019 Training Epoch [27/40] Iter[294/312]		Loss: 0.1140
2019-10-28 15:40:30,098 Training Epoch [27/40] Iter[295/312]		Loss: 0.1138
2019-10-28 15:40:30,177 Training Epoch [27/40] Iter[296/312]		Loss: 0.1139
2019-10-28 15:40:30,256 Training Epoch [27/40] Iter[297/312]		Loss: 0.1138
2019-10-28 15:40:30,335 Training Epoch [27/40] Iter[298/312]		Loss: 0.1138
2019-10-28 15:40:30,414 Training Epoch [27/40] Iter[299/312]		Loss: 0.1137
2019-10-28 15:40:30,493 Training Epoch [27/40] Iter[300/312]		Loss: 0.1136
2019-10-28 15:40:30,572 Training Epoch [27/40] Iter[301/312]		Loss: 0.1135
2019-10-28 15:40:30,652 Training Epoch [27/40] Iter[302/312]		Loss: 0.1134
2019-10-28 15:40:30,732 Training Epoch [27/40] Iter[303/312]		Loss: 0.1134
2019-10-28 15:40:30,811 Training Epoch [27/40] Iter[304/312]		Loss: 0.1133
2019-10-28 15:40:30,891 Training Epoch [27/40] Iter[305/312]		Loss: 0.1133
2019-10-28 15:40:30,971 Training Epoch [27/40] Iter[306/312]		Loss: 0.1132
2019-10-28 15:40:31,050 Training Epoch [27/40] Iter[307/312]		Loss: 0.1132
2019-10-28 15:40:31,130 Training Epoch [27/40] Iter[308/312]		Loss: 0.1132
2019-10-28 15:40:31,209 Training Epoch [27/40] Iter[309/312]		Loss: 0.1134
2019-10-28 15:40:31,287 Training Epoch [27/40] Iter[310/312]		Loss: 0.1133
2019-10-28 15:40:31,366 Training Epoch [27/40] Iter[311/312]		Loss: 0.1132
2019-10-28 15:40:31,404 Training Epoch [27/40] Iter[312/312]		Loss: 0.1133
2019-10-28 15:40:31,843 Testing Epoch [27/40] Iter[0/62]		Loss: 0.1283
2019-10-28 15:40:31,872 Testing Epoch [27/40] Iter[1/62]		Loss: 0.1279
2019-10-28 15:40:31,902 Testing Epoch [27/40] Iter[2/62]		Loss: 0.1129
2019-10-28 15:40:31,922 Testing Epoch [27/40] Iter[3/62]		Loss: 0.1181
2019-10-28 15:40:31,942 Testing Epoch [27/40] Iter[4/62]		Loss: 0.1201
2019-10-28 15:40:31,965 Testing Epoch [27/40] Iter[5/62]		Loss: 0.1150
2019-10-28 15:40:31,993 Testing Epoch [27/40] Iter[6/62]		Loss: 0.1168
2019-10-28 15:40:32,010 Testing Epoch [27/40] Iter[7/62]		Loss: 0.1195
2019-10-28 15:40:32,037 Testing Epoch [27/40] Iter[8/62]		Loss: 0.1223
2019-10-28 15:40:32,053 Testing Epoch [27/40] Iter[9/62]		Loss: 0.1212
2019-10-28 15:40:32,070 Testing Epoch [27/40] Iter[10/62]		Loss: 0.1220
2019-10-28 15:40:32,098 Testing Epoch [27/40] Iter[11/62]		Loss: 0.1274
2019-10-28 15:40:32,116 Testing Epoch [27/40] Iter[12/62]		Loss: 0.1269
2019-10-28 15:40:32,136 Testing Epoch [27/40] Iter[13/62]		Loss: 0.1287
2019-10-28 15:40:32,162 Testing Epoch [27/40] Iter[14/62]		Loss: 0.1416
2019-10-28 15:40:32,191 Testing Epoch [27/40] Iter[15/62]		Loss: 0.1437
2019-10-28 15:40:32,213 Testing Epoch [27/40] Iter[16/62]		Loss: 0.1408
2019-10-28 15:40:32,231 Testing Epoch [27/40] Iter[17/62]		Loss: 0.1406
2019-10-28 15:40:32,250 Testing Epoch [27/40] Iter[18/62]		Loss: 0.1381
2019-10-28 15:40:32,277 Testing Epoch [27/40] Iter[19/62]		Loss: 0.1361
2019-10-28 15:40:32,296 Testing Epoch [27/40] Iter[20/62]		Loss: 0.1381
2019-10-28 15:40:32,318 Testing Epoch [27/40] Iter[21/62]		Loss: 0.1367
2019-10-28 15:40:32,336 Testing Epoch [27/40] Iter[22/62]		Loss: 0.1384
2019-10-28 15:40:32,363 Testing Epoch [27/40] Iter[23/62]		Loss: 0.1378
2019-10-28 15:40:32,386 Testing Epoch [27/40] Iter[24/62]		Loss: 0.1413
2019-10-28 15:40:32,413 Testing Epoch [27/40] Iter[25/62]		Loss: 0.1405
2019-10-28 15:40:32,437 Testing Epoch [27/40] Iter[26/62]		Loss: 0.1392
2019-10-28 15:40:32,455 Testing Epoch [27/40] Iter[27/62]		Loss: 0.1469
2019-10-28 15:40:32,473 Testing Epoch [27/40] Iter[28/62]		Loss: 0.1503
2019-10-28 15:40:32,498 Testing Epoch [27/40] Iter[29/62]		Loss: 0.1502
2019-10-28 15:40:32,523 Testing Epoch [27/40] Iter[30/62]		Loss: 0.1505
2019-10-28 15:40:32,541 Testing Epoch [27/40] Iter[31/62]		Loss: 0.1494
2019-10-28 15:40:32,558 Testing Epoch [27/40] Iter[32/62]		Loss: 0.1512
2019-10-28 15:40:32,590 Testing Epoch [27/40] Iter[33/62]		Loss: 0.1499
2019-10-28 15:40:32,612 Testing Epoch [27/40] Iter[34/62]		Loss: 0.1521
2019-10-28 15:40:32,630 Testing Epoch [27/40] Iter[35/62]		Loss: 0.1518
2019-10-28 15:40:32,661 Testing Epoch [27/40] Iter[36/62]		Loss: 0.1497
2019-10-28 15:40:32,689 Testing Epoch [27/40] Iter[37/62]		Loss: 0.1485
2019-10-28 15:40:32,707 Testing Epoch [27/40] Iter[38/62]		Loss: 0.1474
2019-10-28 15:40:32,725 Testing Epoch [27/40] Iter[39/62]		Loss: 0.1478
2019-10-28 15:40:32,742 Testing Epoch [27/40] Iter[40/62]		Loss: 0.1495
2019-10-28 15:40:32,775 Testing Epoch [27/40] Iter[41/62]		Loss: 0.1510
2019-10-28 15:40:32,794 Testing Epoch [27/40] Iter[42/62]		Loss: 0.1491
2019-10-28 15:40:32,810 Testing Epoch [27/40] Iter[43/62]		Loss: 0.1485
2019-10-28 15:40:32,829 Testing Epoch [27/40] Iter[44/62]		Loss: 0.1470
2019-10-28 15:40:32,860 Testing Epoch [27/40] Iter[45/62]		Loss: 0.1469
2019-10-28 15:40:32,878 Testing Epoch [27/40] Iter[46/62]		Loss: 0.1469
2019-10-28 15:40:32,905 Testing Epoch [27/40] Iter[47/62]		Loss: 0.1529
2019-10-28 15:40:32,922 Testing Epoch [27/40] Iter[48/62]		Loss: 0.1519
2019-10-28 15:40:32,949 Testing Epoch [27/40] Iter[49/62]		Loss: 0.1543
2019-10-28 15:40:32,967 Testing Epoch [27/40] Iter[50/62]		Loss: 0.1535
2019-10-28 15:40:32,989 Testing Epoch [27/40] Iter[51/62]		Loss: 0.1535
2019-10-28 15:40:33,007 Testing Epoch [27/40] Iter[52/62]		Loss: 0.1523
2019-10-28 15:40:33,025 Testing Epoch [27/40] Iter[53/62]		Loss: 0.1525
2019-10-28 15:40:33,050 Testing Epoch [27/40] Iter[54/62]		Loss: 0.1513
2019-10-28 15:40:33,068 Testing Epoch [27/40] Iter[55/62]		Loss: 0.1510
2019-10-28 15:40:33,084 Testing Epoch [27/40] Iter[56/62]		Loss: 0.1503
2019-10-28 15:40:33,101 Testing Epoch [27/40] Iter[57/62]		Loss: 0.1506
2019-10-28 15:40:33,117 Testing Epoch [27/40] Iter[58/62]		Loss: 0.1499
2019-10-28 15:40:33,134 Testing Epoch [27/40] Iter[59/62]		Loss: 0.1510
2019-10-28 15:40:33,151 Testing Epoch [27/40] Iter[60/62]		Loss: 0.1500
2019-10-28 15:40:33,168 Testing Epoch [27/40] Iter[61/62]		Loss: 0.1501
2019-10-28 15:40:33,176 Testing Epoch [27/40] Iter[62/62]		Loss: 0.1509
2019-10-28 15:40:33,697 Training Epoch [28/40] Iter[0/312]		Loss: 0.0832
2019-10-28 15:40:33,779 Training Epoch [28/40] Iter[1/312]		Loss: 0.0759
2019-10-28 15:40:33,858 Training Epoch [28/40] Iter[2/312]		Loss: 0.0814
2019-10-28 15:40:33,937 Training Epoch [28/40] Iter[3/312]		Loss: 0.1147
2019-10-28 15:40:34,016 Training Epoch [28/40] Iter[4/312]		Loss: 0.1127
2019-10-28 15:40:34,096 Training Epoch [28/40] Iter[5/312]		Loss: 0.1174
2019-10-28 15:40:34,175 Training Epoch [28/40] Iter[6/312]		Loss: 0.1143
2019-10-28 15:40:34,253 Training Epoch [28/40] Iter[7/312]		Loss: 0.1171
2019-10-28 15:40:34,332 Training Epoch [28/40] Iter[8/312]		Loss: 0.1246
2019-10-28 15:40:34,412 Training Epoch [28/40] Iter[9/312]		Loss: 0.1380
2019-10-28 15:40:34,491 Training Epoch [28/40] Iter[10/312]		Loss: 0.1349
2019-10-28 15:40:34,569 Training Epoch [28/40] Iter[11/312]		Loss: 0.1296
2019-10-28 15:40:34,648 Training Epoch [28/40] Iter[12/312]		Loss: 0.1258
2019-10-28 15:40:34,727 Training Epoch [28/40] Iter[13/312]		Loss: 0.1295
2019-10-28 15:40:34,806 Training Epoch [28/40] Iter[14/312]		Loss: 0.1264
2019-10-28 15:40:34,885 Training Epoch [28/40] Iter[15/312]		Loss: 0.1233
2019-10-28 15:40:34,964 Training Epoch [28/40] Iter[16/312]		Loss: 0.1227
2019-10-28 15:40:35,043 Training Epoch [28/40] Iter[17/312]		Loss: 0.1206
2019-10-28 15:40:35,122 Training Epoch [28/40] Iter[18/312]		Loss: 0.1194
2019-10-28 15:40:35,201 Training Epoch [28/40] Iter[19/312]		Loss: 0.1182
2019-10-28 15:40:35,280 Training Epoch [28/40] Iter[20/312]		Loss: 0.1172
2019-10-28 15:40:35,360 Training Epoch [28/40] Iter[21/312]		Loss: 0.1166
2019-10-28 15:40:35,439 Training Epoch [28/40] Iter[22/312]		Loss: 0.1161
2019-10-28 15:40:35,518 Training Epoch [28/40] Iter[23/312]		Loss: 0.1161
2019-10-28 15:40:35,597 Training Epoch [28/40] Iter[24/312]		Loss: 0.1172
2019-10-28 15:40:35,677 Training Epoch [28/40] Iter[25/312]		Loss: 0.1156
2019-10-28 15:40:35,756 Training Epoch [28/40] Iter[26/312]		Loss: 0.1141
2019-10-28 15:40:35,835 Training Epoch [28/40] Iter[27/312]		Loss: 0.1129
2019-10-28 15:40:35,914 Training Epoch [28/40] Iter[28/312]		Loss: 0.1126
2019-10-28 15:40:35,993 Training Epoch [28/40] Iter[29/312]		Loss: 0.1131
2019-10-28 15:40:36,072 Training Epoch [28/40] Iter[30/312]		Loss: 0.1163
2019-10-28 15:40:36,151 Training Epoch [28/40] Iter[31/312]		Loss: 0.1151
2019-10-28 15:40:36,231 Training Epoch [28/40] Iter[32/312]		Loss: 0.1149
2019-10-28 15:40:36,310 Training Epoch [28/40] Iter[33/312]		Loss: 0.1135
2019-10-28 15:40:36,390 Training Epoch [28/40] Iter[34/312]		Loss: 0.1137
2019-10-28 15:40:36,470 Training Epoch [28/40] Iter[35/312]		Loss: 0.1133
2019-10-28 15:40:36,549 Training Epoch [28/40] Iter[36/312]		Loss: 0.1135
2019-10-28 15:40:36,629 Training Epoch [28/40] Iter[37/312]		Loss: 0.1138
2019-10-28 15:40:36,709 Training Epoch [28/40] Iter[38/312]		Loss: 0.1139
2019-10-28 15:40:36,788 Training Epoch [28/40] Iter[39/312]		Loss: 0.1149
2019-10-28 15:40:36,867 Training Epoch [28/40] Iter[40/312]		Loss: 0.1144
2019-10-28 15:40:36,947 Training Epoch [28/40] Iter[41/312]		Loss: 0.1148
2019-10-28 15:40:37,026 Training Epoch [28/40] Iter[42/312]		Loss: 0.1149
2019-10-28 15:40:37,105 Training Epoch [28/40] Iter[43/312]		Loss: 0.1149
2019-10-28 15:40:37,185 Training Epoch [28/40] Iter[44/312]		Loss: 0.1143
2019-10-28 15:40:37,264 Training Epoch [28/40] Iter[45/312]		Loss: 0.1138
2019-10-28 15:40:37,344 Training Epoch [28/40] Iter[46/312]		Loss: 0.1138
2019-10-28 15:40:37,423 Training Epoch [28/40] Iter[47/312]		Loss: 0.1131
2019-10-28 15:40:37,502 Training Epoch [28/40] Iter[48/312]		Loss: 0.1133
2019-10-28 15:40:37,582 Training Epoch [28/40] Iter[49/312]		Loss: 0.1142
2019-10-28 15:40:37,662 Training Epoch [28/40] Iter[50/312]		Loss: 0.1147
2019-10-28 15:40:37,741 Training Epoch [28/40] Iter[51/312]		Loss: 0.1149
2019-10-28 15:40:37,820 Training Epoch [28/40] Iter[52/312]		Loss: 0.1147
2019-10-28 15:40:37,900 Training Epoch [28/40] Iter[53/312]		Loss: 0.1144
2019-10-28 15:40:37,979 Training Epoch [28/40] Iter[54/312]		Loss: 0.1138
2019-10-28 15:40:38,058 Training Epoch [28/40] Iter[55/312]		Loss: 0.1143
2019-10-28 15:40:38,137 Training Epoch [28/40] Iter[56/312]		Loss: 0.1145
2019-10-28 15:40:38,217 Training Epoch [28/40] Iter[57/312]		Loss: 0.1145
2019-10-28 15:40:38,296 Training Epoch [28/40] Iter[58/312]		Loss: 0.1143
2019-10-28 15:40:38,376 Training Epoch [28/40] Iter[59/312]		Loss: 0.1137
2019-10-28 15:40:38,455 Training Epoch [28/40] Iter[60/312]		Loss: 0.1134
2019-10-28 15:40:38,540 Training Epoch [28/40] Iter[61/312]		Loss: 0.1142
2019-10-28 15:40:38,623 Training Epoch [28/40] Iter[62/312]		Loss: 0.1136
2019-10-28 15:40:38,703 Training Epoch [28/40] Iter[63/312]		Loss: 0.1136
2019-10-28 15:40:38,782 Training Epoch [28/40] Iter[64/312]		Loss: 0.1131
2019-10-28 15:40:38,860 Training Epoch [28/40] Iter[65/312]		Loss: 0.1134
2019-10-28 15:40:38,939 Training Epoch [28/40] Iter[66/312]		Loss: 0.1134
2019-10-28 15:40:39,024 Training Epoch [28/40] Iter[67/312]		Loss: 0.1128
2019-10-28 15:40:39,107 Training Epoch [28/40] Iter[68/312]		Loss: 0.1121
2019-10-28 15:40:39,187 Training Epoch [28/40] Iter[69/312]		Loss: 0.1120
2019-10-28 15:40:39,266 Training Epoch [28/40] Iter[70/312]		Loss: 0.1130
2019-10-28 15:40:39,345 Training Epoch [28/40] Iter[71/312]		Loss: 0.1130
2019-10-28 15:40:39,424 Training Epoch [28/40] Iter[72/312]		Loss: 0.1129
2019-10-28 15:40:39,503 Training Epoch [28/40] Iter[73/312]		Loss: 0.1132
2019-10-28 15:40:39,582 Training Epoch [28/40] Iter[74/312]		Loss: 0.1129
2019-10-28 15:40:39,661 Training Epoch [28/40] Iter[75/312]		Loss: 0.1129
2019-10-28 15:40:39,740 Training Epoch [28/40] Iter[76/312]		Loss: 0.1128
2019-10-28 15:40:39,819 Training Epoch [28/40] Iter[77/312]		Loss: 0.1129
2019-10-28 15:40:39,898 Training Epoch [28/40] Iter[78/312]		Loss: 0.1126
2019-10-28 15:40:39,977 Training Epoch [28/40] Iter[79/312]		Loss: 0.1128
2019-10-28 15:40:40,056 Training Epoch [28/40] Iter[80/312]		Loss: 0.1123
2019-10-28 15:40:40,136 Training Epoch [28/40] Iter[81/312]		Loss: 0.1135
2019-10-28 15:40:40,215 Training Epoch [28/40] Iter[82/312]		Loss: 0.1131
2019-10-28 15:40:40,294 Training Epoch [28/40] Iter[83/312]		Loss: 0.1133
2019-10-28 15:40:40,373 Training Epoch [28/40] Iter[84/312]		Loss: 0.1142
2019-10-28 15:40:40,453 Training Epoch [28/40] Iter[85/312]		Loss: 0.1143
2019-10-28 15:40:40,532 Training Epoch [28/40] Iter[86/312]		Loss: 0.1143
2019-10-28 15:40:40,612 Training Epoch [28/40] Iter[87/312]		Loss: 0.1145
2019-10-28 15:40:40,691 Training Epoch [28/40] Iter[88/312]		Loss: 0.1140
2019-10-28 15:40:40,770 Training Epoch [28/40] Iter[89/312]		Loss: 0.1141
2019-10-28 15:40:40,849 Training Epoch [28/40] Iter[90/312]		Loss: 0.1141
2019-10-28 15:40:40,929 Training Epoch [28/40] Iter[91/312]		Loss: 0.1135
2019-10-28 15:40:41,008 Training Epoch [28/40] Iter[92/312]		Loss: 0.1131
2019-10-28 15:40:41,088 Training Epoch [28/40] Iter[93/312]		Loss: 0.1130
2019-10-28 15:40:41,167 Training Epoch [28/40] Iter[94/312]		Loss: 0.1129
2019-10-28 15:40:41,246 Training Epoch [28/40] Iter[95/312]		Loss: 0.1139
2019-10-28 15:40:41,325 Training Epoch [28/40] Iter[96/312]		Loss: 0.1140
2019-10-28 15:40:41,404 Training Epoch [28/40] Iter[97/312]		Loss: 0.1142
2019-10-28 15:40:41,484 Training Epoch [28/40] Iter[98/312]		Loss: 0.1138
2019-10-28 15:40:41,563 Training Epoch [28/40] Iter[99/312]		Loss: 0.1138
2019-10-28 15:40:41,642 Training Epoch [28/40] Iter[100/312]		Loss: 0.1133
2019-10-28 15:40:41,721 Training Epoch [28/40] Iter[101/312]		Loss: 0.1136
2019-10-28 15:40:41,800 Training Epoch [28/40] Iter[102/312]		Loss: 0.1133
2019-10-28 15:40:41,879 Training Epoch [28/40] Iter[103/312]		Loss: 0.1134
2019-10-28 15:40:41,958 Training Epoch [28/40] Iter[104/312]		Loss: 0.1132
2019-10-28 15:40:42,037 Training Epoch [28/40] Iter[105/312]		Loss: 0.1132
2019-10-28 15:40:42,117 Training Epoch [28/40] Iter[106/312]		Loss: 0.1134
2019-10-28 15:40:42,196 Training Epoch [28/40] Iter[107/312]		Loss: 0.1138
2019-10-28 15:40:42,275 Training Epoch [28/40] Iter[108/312]		Loss: 0.1137
2019-10-28 15:40:42,354 Training Epoch [28/40] Iter[109/312]		Loss: 0.1135
2019-10-28 15:40:42,433 Training Epoch [28/40] Iter[110/312]		Loss: 0.1132
2019-10-28 15:40:42,513 Training Epoch [28/40] Iter[111/312]		Loss: 0.1135
2019-10-28 15:40:42,592 Training Epoch [28/40] Iter[112/312]		Loss: 0.1134
2019-10-28 15:40:42,671 Training Epoch [28/40] Iter[113/312]		Loss: 0.1135
2019-10-28 15:40:42,750 Training Epoch [28/40] Iter[114/312]		Loss: 0.1130
2019-10-28 15:40:42,830 Training Epoch [28/40] Iter[115/312]		Loss: 0.1130
2019-10-28 15:40:42,909 Training Epoch [28/40] Iter[116/312]		Loss: 0.1127
2019-10-28 15:40:42,988 Training Epoch [28/40] Iter[117/312]		Loss: 0.1125
2019-10-28 15:40:43,068 Training Epoch [28/40] Iter[118/312]		Loss: 0.1123
2019-10-28 15:40:43,147 Training Epoch [28/40] Iter[119/312]		Loss: 0.1125
2019-10-28 15:40:43,227 Training Epoch [28/40] Iter[120/312]		Loss: 0.1126
2019-10-28 15:40:43,307 Training Epoch [28/40] Iter[121/312]		Loss: 0.1124
2019-10-28 15:40:43,386 Training Epoch [28/40] Iter[122/312]		Loss: 0.1121
2019-10-28 15:40:43,465 Training Epoch [28/40] Iter[123/312]		Loss: 0.1117
2019-10-28 15:40:43,545 Training Epoch [28/40] Iter[124/312]		Loss: 0.1115
2019-10-28 15:40:43,624 Training Epoch [28/40] Iter[125/312]		Loss: 0.1116
2019-10-28 15:40:43,704 Training Epoch [28/40] Iter[126/312]		Loss: 0.1114
2019-10-28 15:40:43,783 Training Epoch [28/40] Iter[127/312]		Loss: 0.1119
2019-10-28 15:40:43,862 Training Epoch [28/40] Iter[128/312]		Loss: 0.1119
2019-10-28 15:40:43,942 Training Epoch [28/40] Iter[129/312]		Loss: 0.1120
2019-10-28 15:40:44,022 Training Epoch [28/40] Iter[130/312]		Loss: 0.1116
2019-10-28 15:40:44,101 Training Epoch [28/40] Iter[131/312]		Loss: 0.1116
2019-10-28 15:40:44,181 Training Epoch [28/40] Iter[132/312]		Loss: 0.1123
2019-10-28 15:40:44,260 Training Epoch [28/40] Iter[133/312]		Loss: 0.1121
2019-10-28 15:40:44,340 Training Epoch [28/40] Iter[134/312]		Loss: 0.1127
2019-10-28 15:40:44,420 Training Epoch [28/40] Iter[135/312]		Loss: 0.1125
2019-10-28 15:40:44,499 Training Epoch [28/40] Iter[136/312]		Loss: 0.1123
2019-10-28 15:40:44,579 Training Epoch [28/40] Iter[137/312]		Loss: 0.1122
2019-10-28 15:40:44,659 Training Epoch [28/40] Iter[138/312]		Loss: 0.1122
2019-10-28 15:40:44,738 Training Epoch [28/40] Iter[139/312]		Loss: 0.1127
2019-10-28 15:40:44,817 Training Epoch [28/40] Iter[140/312]		Loss: 0.1126
2019-10-28 15:40:44,897 Training Epoch [28/40] Iter[141/312]		Loss: 0.1130
2019-10-28 15:40:44,976 Training Epoch [28/40] Iter[142/312]		Loss: 0.1130
2019-10-28 15:40:45,056 Training Epoch [28/40] Iter[143/312]		Loss: 0.1132
2019-10-28 15:40:45,136 Training Epoch [28/40] Iter[144/312]		Loss: 0.1131
2019-10-28 15:40:45,216 Training Epoch [28/40] Iter[145/312]		Loss: 0.1130
2019-10-28 15:40:45,295 Training Epoch [28/40] Iter[146/312]		Loss: 0.1134
2019-10-28 15:40:45,374 Training Epoch [28/40] Iter[147/312]		Loss: 0.1134
2019-10-28 15:40:45,454 Training Epoch [28/40] Iter[148/312]		Loss: 0.1132
2019-10-28 15:40:45,533 Training Epoch [28/40] Iter[149/312]		Loss: 0.1132
2019-10-28 15:40:45,612 Training Epoch [28/40] Iter[150/312]		Loss: 0.1134
2019-10-28 15:40:45,691 Training Epoch [28/40] Iter[151/312]		Loss: 0.1136
2019-10-28 15:40:45,770 Training Epoch [28/40] Iter[152/312]		Loss: 0.1140
2019-10-28 15:40:45,850 Training Epoch [28/40] Iter[153/312]		Loss: 0.1138
2019-10-28 15:40:45,929 Training Epoch [28/40] Iter[154/312]		Loss: 0.1141
2019-10-28 15:40:46,008 Training Epoch [28/40] Iter[155/312]		Loss: 0.1139
2019-10-28 15:40:46,087 Training Epoch [28/40] Iter[156/312]		Loss: 0.1138
2019-10-28 15:40:46,167 Training Epoch [28/40] Iter[157/312]		Loss: 0.1137
2019-10-28 15:40:46,246 Training Epoch [28/40] Iter[158/312]		Loss: 0.1136
2019-10-28 15:40:46,325 Training Epoch [28/40] Iter[159/312]		Loss: 0.1136
2019-10-28 15:40:46,405 Training Epoch [28/40] Iter[160/312]		Loss: 0.1138
2019-10-28 15:40:46,484 Training Epoch [28/40] Iter[161/312]		Loss: 0.1138
2019-10-28 15:40:46,564 Training Epoch [28/40] Iter[162/312]		Loss: 0.1136
2019-10-28 15:40:46,643 Training Epoch [28/40] Iter[163/312]		Loss: 0.1138
2019-10-28 15:40:46,722 Training Epoch [28/40] Iter[164/312]		Loss: 0.1142
2019-10-28 15:40:46,801 Training Epoch [28/40] Iter[165/312]		Loss: 0.1141
2019-10-28 15:40:46,880 Training Epoch [28/40] Iter[166/312]		Loss: 0.1144
2019-10-28 15:40:46,960 Training Epoch [28/40] Iter[167/312]		Loss: 0.1146
2019-10-28 15:40:47,039 Training Epoch [28/40] Iter[168/312]		Loss: 0.1148
2019-10-28 15:40:47,118 Training Epoch [28/40] Iter[169/312]		Loss: 0.1146
2019-10-28 15:40:47,197 Training Epoch [28/40] Iter[170/312]		Loss: 0.1145
2019-10-28 15:40:47,277 Training Epoch [28/40] Iter[171/312]		Loss: 0.1146
2019-10-28 15:40:47,356 Training Epoch [28/40] Iter[172/312]		Loss: 0.1146
2019-10-28 15:40:47,435 Training Epoch [28/40] Iter[173/312]		Loss: 0.1146
2019-10-28 15:40:47,514 Training Epoch [28/40] Iter[174/312]		Loss: 0.1144
2019-10-28 15:40:47,593 Training Epoch [28/40] Iter[175/312]		Loss: 0.1144
2019-10-28 15:40:47,672 Training Epoch [28/40] Iter[176/312]		Loss: 0.1142
2019-10-28 15:40:47,751 Training Epoch [28/40] Iter[177/312]		Loss: 0.1140
2019-10-28 15:40:47,830 Training Epoch [28/40] Iter[178/312]		Loss: 0.1138
2019-10-28 15:40:47,909 Training Epoch [28/40] Iter[179/312]		Loss: 0.1136
2019-10-28 15:40:47,988 Training Epoch [28/40] Iter[180/312]		Loss: 0.1134
2019-10-28 15:40:48,068 Training Epoch [28/40] Iter[181/312]		Loss: 0.1134
2019-10-28 15:40:48,147 Training Epoch [28/40] Iter[182/312]		Loss: 0.1136
2019-10-28 15:40:48,226 Training Epoch [28/40] Iter[183/312]		Loss: 0.1137
2019-10-28 15:40:48,305 Training Epoch [28/40] Iter[184/312]		Loss: 0.1139
2019-10-28 15:40:48,385 Training Epoch [28/40] Iter[185/312]		Loss: 0.1140
2019-10-28 15:40:48,464 Training Epoch [28/40] Iter[186/312]		Loss: 0.1141
2019-10-28 15:40:48,544 Training Epoch [28/40] Iter[187/312]		Loss: 0.1142
2019-10-28 15:40:48,623 Training Epoch [28/40] Iter[188/312]		Loss: 0.1143
2019-10-28 15:40:48,702 Training Epoch [28/40] Iter[189/312]		Loss: 0.1142
2019-10-28 15:40:48,782 Training Epoch [28/40] Iter[190/312]		Loss: 0.1140
2019-10-28 15:40:48,861 Training Epoch [28/40] Iter[191/312]		Loss: 0.1139
2019-10-28 15:40:48,940 Training Epoch [28/40] Iter[192/312]		Loss: 0.1139
2019-10-28 15:40:49,019 Training Epoch [28/40] Iter[193/312]		Loss: 0.1140
2019-10-28 15:40:49,098 Training Epoch [28/40] Iter[194/312]		Loss: 0.1139
2019-10-28 15:40:49,178 Training Epoch [28/40] Iter[195/312]		Loss: 0.1139
2019-10-28 15:40:49,257 Training Epoch [28/40] Iter[196/312]		Loss: 0.1139
2019-10-28 15:40:49,336 Training Epoch [28/40] Iter[197/312]		Loss: 0.1143
2019-10-28 15:40:49,415 Training Epoch [28/40] Iter[198/312]		Loss: 0.1144
2019-10-28 15:40:49,500 Training Epoch [28/40] Iter[199/312]		Loss: 0.1142
2019-10-28 15:40:49,579 Training Epoch [28/40] Iter[200/312]		Loss: 0.1141
2019-10-28 15:40:49,658 Training Epoch [28/40] Iter[201/312]		Loss: 0.1140
2019-10-28 15:40:49,737 Training Epoch [28/40] Iter[202/312]		Loss: 0.1140
2019-10-28 15:40:49,822 Training Epoch [28/40] Iter[203/312]		Loss: 0.1139
2019-10-28 15:40:49,901 Training Epoch [28/40] Iter[204/312]		Loss: 0.1138
2019-10-28 15:40:49,980 Training Epoch [28/40] Iter[205/312]		Loss: 0.1137
2019-10-28 15:40:50,059 Training Epoch [28/40] Iter[206/312]		Loss: 0.1137
2019-10-28 15:40:50,138 Training Epoch [28/40] Iter[207/312]		Loss: 0.1135
2019-10-28 15:40:50,218 Training Epoch [28/40] Iter[208/312]		Loss: 0.1133
2019-10-28 15:40:50,298 Training Epoch [28/40] Iter[209/312]		Loss: 0.1132
2019-10-28 15:40:50,377 Training Epoch [28/40] Iter[210/312]		Loss: 0.1132
2019-10-28 15:40:50,457 Training Epoch [28/40] Iter[211/312]		Loss: 0.1135
2019-10-28 15:40:50,537 Training Epoch [28/40] Iter[212/312]		Loss: 0.1134
2019-10-28 15:40:50,617 Training Epoch [28/40] Iter[213/312]		Loss: 0.1134
2019-10-28 15:40:50,696 Training Epoch [28/40] Iter[214/312]		Loss: 0.1131
2019-10-28 15:40:50,775 Training Epoch [28/40] Iter[215/312]		Loss: 0.1131
2019-10-28 15:40:50,855 Training Epoch [28/40] Iter[216/312]		Loss: 0.1130
2019-10-28 15:40:50,934 Training Epoch [28/40] Iter[217/312]		Loss: 0.1129
2019-10-28 15:40:51,013 Training Epoch [28/40] Iter[218/312]		Loss: 0.1129
2019-10-28 15:40:51,092 Training Epoch [28/40] Iter[219/312]		Loss: 0.1132
2019-10-28 15:40:51,172 Training Epoch [28/40] Iter[220/312]		Loss: 0.1132
2019-10-28 15:40:51,251 Training Epoch [28/40] Iter[221/312]		Loss: 0.1131
2019-10-28 15:40:51,330 Training Epoch [28/40] Iter[222/312]		Loss: 0.1130
2019-10-28 15:40:51,410 Training Epoch [28/40] Iter[223/312]		Loss: 0.1130
2019-10-28 15:40:51,489 Training Epoch [28/40] Iter[224/312]		Loss: 0.1128
2019-10-28 15:40:51,569 Training Epoch [28/40] Iter[225/312]		Loss: 0.1128
2019-10-28 15:40:51,648 Training Epoch [28/40] Iter[226/312]		Loss: 0.1128
2019-10-28 15:40:51,727 Training Epoch [28/40] Iter[227/312]		Loss: 0.1130
2019-10-28 15:40:51,807 Training Epoch [28/40] Iter[228/312]		Loss: 0.1127
2019-10-28 15:40:51,886 Training Epoch [28/40] Iter[229/312]		Loss: 0.1126
2019-10-28 15:40:51,965 Training Epoch [28/40] Iter[230/312]		Loss: 0.1128
2019-10-28 15:40:52,044 Training Epoch [28/40] Iter[231/312]		Loss: 0.1128
2019-10-28 15:40:52,123 Training Epoch [28/40] Iter[232/312]		Loss: 0.1128
2019-10-28 15:40:52,202 Training Epoch [28/40] Iter[233/312]		Loss: 0.1129
2019-10-28 15:40:52,282 Training Epoch [28/40] Iter[234/312]		Loss: 0.1128
2019-10-28 15:40:52,361 Training Epoch [28/40] Iter[235/312]		Loss: 0.1127
2019-10-28 15:40:52,441 Training Epoch [28/40] Iter[236/312]		Loss: 0.1126
2019-10-28 15:40:52,520 Training Epoch [28/40] Iter[237/312]		Loss: 0.1126
2019-10-28 15:40:52,599 Training Epoch [28/40] Iter[238/312]		Loss: 0.1130
2019-10-28 15:40:52,679 Training Epoch [28/40] Iter[239/312]		Loss: 0.1132
2019-10-28 15:40:52,758 Training Epoch [28/40] Iter[240/312]		Loss: 0.1135
2019-10-28 15:40:52,838 Training Epoch [28/40] Iter[241/312]		Loss: 0.1133
2019-10-28 15:40:52,917 Training Epoch [28/40] Iter[242/312]		Loss: 0.1132
2019-10-28 15:40:52,997 Training Epoch [28/40] Iter[243/312]		Loss: 0.1131
2019-10-28 15:40:53,076 Training Epoch [28/40] Iter[244/312]		Loss: 0.1131
2019-10-28 15:40:53,156 Training Epoch [28/40] Iter[245/312]		Loss: 0.1131
2019-10-28 15:40:53,235 Training Epoch [28/40] Iter[246/312]		Loss: 0.1130
2019-10-28 15:40:53,315 Training Epoch [28/40] Iter[247/312]		Loss: 0.1129
2019-10-28 15:40:53,394 Training Epoch [28/40] Iter[248/312]		Loss: 0.1129
2019-10-28 15:40:53,474 Training Epoch [28/40] Iter[249/312]		Loss: 0.1128
2019-10-28 15:40:53,553 Training Epoch [28/40] Iter[250/312]		Loss: 0.1127
2019-10-28 15:40:53,633 Training Epoch [28/40] Iter[251/312]		Loss: 0.1126
2019-10-28 15:40:53,712 Training Epoch [28/40] Iter[252/312]		Loss: 0.1125
2019-10-28 15:40:53,791 Training Epoch [28/40] Iter[253/312]		Loss: 0.1128
2019-10-28 15:40:53,871 Training Epoch [28/40] Iter[254/312]		Loss: 0.1130
2019-10-28 15:40:53,950 Training Epoch [28/40] Iter[255/312]		Loss: 0.1130
2019-10-28 15:40:54,029 Training Epoch [28/40] Iter[256/312]		Loss: 0.1129
2019-10-28 15:40:54,109 Training Epoch [28/40] Iter[257/312]		Loss: 0.1129
2019-10-28 15:40:54,188 Training Epoch [28/40] Iter[258/312]		Loss: 0.1128
2019-10-28 15:40:54,267 Training Epoch [28/40] Iter[259/312]		Loss: 0.1128
2019-10-28 15:40:54,346 Training Epoch [28/40] Iter[260/312]		Loss: 0.1127
2019-10-28 15:40:54,425 Training Epoch [28/40] Iter[261/312]		Loss: 0.1130
2019-10-28 15:40:54,504 Training Epoch [28/40] Iter[262/312]		Loss: 0.1129
2019-10-28 15:40:54,583 Training Epoch [28/40] Iter[263/312]		Loss: 0.1131
2019-10-28 15:40:54,662 Training Epoch [28/40] Iter[264/312]		Loss: 0.1130
2019-10-28 15:40:54,741 Training Epoch [28/40] Iter[265/312]		Loss: 0.1129
2019-10-28 15:40:54,821 Training Epoch [28/40] Iter[266/312]		Loss: 0.1137
2019-10-28 15:40:54,900 Training Epoch [28/40] Iter[267/312]		Loss: 0.1135
2019-10-28 15:40:54,980 Training Epoch [28/40] Iter[268/312]		Loss: 0.1137
2019-10-28 15:40:55,060 Training Epoch [28/40] Iter[269/312]		Loss: 0.1141
2019-10-28 15:40:55,140 Training Epoch [28/40] Iter[270/312]		Loss: 0.1142
2019-10-28 15:40:55,220 Training Epoch [28/40] Iter[271/312]		Loss: 0.1142
2019-10-28 15:40:55,299 Training Epoch [28/40] Iter[272/312]		Loss: 0.1140
2019-10-28 15:40:55,379 Training Epoch [28/40] Iter[273/312]		Loss: 0.1140
2019-10-28 15:40:55,458 Training Epoch [28/40] Iter[274/312]		Loss: 0.1140
2019-10-28 15:40:55,538 Training Epoch [28/40] Iter[275/312]		Loss: 0.1142
2019-10-28 15:40:55,617 Training Epoch [28/40] Iter[276/312]		Loss: 0.1140
2019-10-28 15:40:55,696 Training Epoch [28/40] Iter[277/312]		Loss: 0.1140
2019-10-28 15:40:55,776 Training Epoch [28/40] Iter[278/312]		Loss: 0.1139
2019-10-28 15:40:55,855 Training Epoch [28/40] Iter[279/312]		Loss: 0.1139
2019-10-28 15:40:55,934 Training Epoch [28/40] Iter[280/312]		Loss: 0.1140
2019-10-28 15:40:56,014 Training Epoch [28/40] Iter[281/312]		Loss: 0.1143
2019-10-28 15:40:56,094 Training Epoch [28/40] Iter[282/312]		Loss: 0.1144
2019-10-28 15:40:56,173 Training Epoch [28/40] Iter[283/312]		Loss: 0.1146
2019-10-28 15:40:56,253 Training Epoch [28/40] Iter[284/312]		Loss: 0.1145
2019-10-28 15:40:56,333 Training Epoch [28/40] Iter[285/312]		Loss: 0.1145
2019-10-28 15:40:56,413 Training Epoch [28/40] Iter[286/312]		Loss: 0.1143
2019-10-28 15:40:56,493 Training Epoch [28/40] Iter[287/312]		Loss: 0.1142
2019-10-28 15:40:56,573 Training Epoch [28/40] Iter[288/312]		Loss: 0.1142
2019-10-28 15:40:56,652 Training Epoch [28/40] Iter[289/312]		Loss: 0.1142
2019-10-28 15:40:56,732 Training Epoch [28/40] Iter[290/312]		Loss: 0.1141
2019-10-28 15:40:56,812 Training Epoch [28/40] Iter[291/312]		Loss: 0.1141
2019-10-28 15:40:56,892 Training Epoch [28/40] Iter[292/312]		Loss: 0.1141
2019-10-28 15:40:56,972 Training Epoch [28/40] Iter[293/312]		Loss: 0.1139
2019-10-28 15:40:57,051 Training Epoch [28/40] Iter[294/312]		Loss: 0.1139
2019-10-28 15:40:57,131 Training Epoch [28/40] Iter[295/312]		Loss: 0.1139
2019-10-28 15:40:57,211 Training Epoch [28/40] Iter[296/312]		Loss: 0.1140
2019-10-28 15:40:57,291 Training Epoch [28/40] Iter[297/312]		Loss: 0.1140
2019-10-28 15:40:57,371 Training Epoch [28/40] Iter[298/312]		Loss: 0.1140
2019-10-28 15:40:57,451 Training Epoch [28/40] Iter[299/312]		Loss: 0.1140
2019-10-28 15:40:57,530 Training Epoch [28/40] Iter[300/312]		Loss: 0.1139
2019-10-28 15:40:57,610 Training Epoch [28/40] Iter[301/312]		Loss: 0.1138
2019-10-28 15:40:57,690 Training Epoch [28/40] Iter[302/312]		Loss: 0.1137
2019-10-28 15:40:57,769 Training Epoch [28/40] Iter[303/312]		Loss: 0.1135
2019-10-28 15:40:57,849 Training Epoch [28/40] Iter[304/312]		Loss: 0.1137
2019-10-28 15:40:57,928 Training Epoch [28/40] Iter[305/312]		Loss: 0.1140
2019-10-28 15:40:58,006 Training Epoch [28/40] Iter[306/312]		Loss: 0.1139
2019-10-28 15:40:58,085 Training Epoch [28/40] Iter[307/312]		Loss: 0.1138
2019-10-28 15:40:58,164 Training Epoch [28/40] Iter[308/312]		Loss: 0.1143
2019-10-28 15:40:58,243 Training Epoch [28/40] Iter[309/312]		Loss: 0.1143
2019-10-28 15:40:58,322 Training Epoch [28/40] Iter[310/312]		Loss: 0.1142
2019-10-28 15:40:58,402 Training Epoch [28/40] Iter[311/312]		Loss: 0.1142
2019-10-28 15:40:58,441 Training Epoch [28/40] Iter[312/312]		Loss: 0.1142
2019-10-28 15:40:58,882 Testing Epoch [28/40] Iter[0/62]		Loss: 0.1312
2019-10-28 15:40:58,918 Testing Epoch [28/40] Iter[1/62]		Loss: 0.1295
2019-10-28 15:40:58,946 Testing Epoch [28/40] Iter[2/62]		Loss: 0.1120
2019-10-28 15:40:58,973 Testing Epoch [28/40] Iter[3/62]		Loss: 0.1163
2019-10-28 15:40:58,992 Testing Epoch [28/40] Iter[4/62]		Loss: 0.1202
2019-10-28 15:40:59,018 Testing Epoch [28/40] Iter[5/62]		Loss: 0.1156
2019-10-28 15:40:59,036 Testing Epoch [28/40] Iter[6/62]		Loss: 0.1170
2019-10-28 15:40:59,065 Testing Epoch [28/40] Iter[7/62]		Loss: 0.1195
2019-10-28 15:40:59,083 Testing Epoch [28/40] Iter[8/62]		Loss: 0.1220
2019-10-28 15:40:59,110 Testing Epoch [28/40] Iter[9/62]		Loss: 0.1212
2019-10-28 15:40:59,133 Testing Epoch [28/40] Iter[10/62]		Loss: 0.1221
2019-10-28 15:40:59,162 Testing Epoch [28/40] Iter[11/62]		Loss: 0.1282
2019-10-28 15:40:59,180 Testing Epoch [28/40] Iter[12/62]		Loss: 0.1283
2019-10-28 15:40:59,199 Testing Epoch [28/40] Iter[13/62]		Loss: 0.1305
2019-10-28 15:40:59,226 Testing Epoch [28/40] Iter[14/62]		Loss: 0.1435
2019-10-28 15:40:59,258 Testing Epoch [28/40] Iter[15/62]		Loss: 0.1455
2019-10-28 15:40:59,280 Testing Epoch [28/40] Iter[16/62]		Loss: 0.1424
2019-10-28 15:40:59,306 Testing Epoch [28/40] Iter[17/62]		Loss: 0.1427
2019-10-28 15:40:59,325 Testing Epoch [28/40] Iter[18/62]		Loss: 0.1402
2019-10-28 15:40:59,344 Testing Epoch [28/40] Iter[19/62]		Loss: 0.1383
2019-10-28 15:40:59,373 Testing Epoch [28/40] Iter[20/62]		Loss: 0.1401
2019-10-28 15:40:59,399 Testing Epoch [28/40] Iter[21/62]		Loss: 0.1386
2019-10-28 15:40:59,417 Testing Epoch [28/40] Iter[22/62]		Loss: 0.1401
2019-10-28 15:40:59,442 Testing Epoch [28/40] Iter[23/62]		Loss: 0.1390
2019-10-28 15:40:59,466 Testing Epoch [28/40] Iter[24/62]		Loss: 0.1422
2019-10-28 15:40:59,486 Testing Epoch [28/40] Iter[25/62]		Loss: 0.1413
2019-10-28 15:40:59,503 Testing Epoch [28/40] Iter[26/62]		Loss: 0.1401
2019-10-28 15:40:59,534 Testing Epoch [28/40] Iter[27/62]		Loss: 0.1477
2019-10-28 15:40:59,552 Testing Epoch [28/40] Iter[28/62]		Loss: 0.1515
2019-10-28 15:40:59,571 Testing Epoch [28/40] Iter[29/62]		Loss: 0.1515
2019-10-28 15:40:59,588 Testing Epoch [28/40] Iter[30/62]		Loss: 0.1518
2019-10-28 15:40:59,618 Testing Epoch [28/40] Iter[31/62]		Loss: 0.1506
2019-10-28 15:40:59,639 Testing Epoch [28/40] Iter[32/62]		Loss: 0.1523
2019-10-28 15:40:59,657 Testing Epoch [28/40] Iter[33/62]		Loss: 0.1512
2019-10-28 15:40:59,682 Testing Epoch [28/40] Iter[34/62]		Loss: 0.1535
2019-10-28 15:40:59,707 Testing Epoch [28/40] Iter[35/62]		Loss: 0.1530
2019-10-28 15:40:59,726 Testing Epoch [28/40] Iter[36/62]		Loss: 0.1511
2019-10-28 15:40:59,744 Testing Epoch [28/40] Iter[37/62]		Loss: 0.1500
2019-10-28 15:40:59,778 Testing Epoch [28/40] Iter[38/62]		Loss: 0.1489
2019-10-28 15:40:59,803 Testing Epoch [28/40] Iter[39/62]		Loss: 0.1492
2019-10-28 15:40:59,822 Testing Epoch [28/40] Iter[40/62]		Loss: 0.1508
2019-10-28 15:40:59,840 Testing Epoch [28/40] Iter[41/62]		Loss: 0.1524
2019-10-28 15:40:59,873 Testing Epoch [28/40] Iter[42/62]		Loss: 0.1504
2019-10-28 15:40:59,891 Testing Epoch [28/40] Iter[43/62]		Loss: 0.1498
2019-10-28 15:40:59,909 Testing Epoch [28/40] Iter[44/62]		Loss: 0.1482
2019-10-28 15:40:59,938 Testing Epoch [28/40] Iter[45/62]		Loss: 0.1480
2019-10-28 15:40:59,956 Testing Epoch [28/40] Iter[46/62]		Loss: 0.1478
2019-10-28 15:40:59,985 Testing Epoch [28/40] Iter[47/62]		Loss: 0.1537
2019-10-28 15:41:00,005 Testing Epoch [28/40] Iter[48/62]		Loss: 0.1527
2019-10-28 15:41:00,030 Testing Epoch [28/40] Iter[49/62]		Loss: 0.1549
2019-10-28 15:41:00,048 Testing Epoch [28/40] Iter[50/62]		Loss: 0.1541
2019-10-28 15:41:00,077 Testing Epoch [28/40] Iter[51/62]		Loss: 0.1541
2019-10-28 15:41:00,096 Testing Epoch [28/40] Iter[52/62]		Loss: 0.1528
2019-10-28 15:41:00,122 Testing Epoch [28/40] Iter[53/62]		Loss: 0.1532
2019-10-28 15:41:00,140 Testing Epoch [28/40] Iter[54/62]		Loss: 0.1519
2019-10-28 15:41:00,158 Testing Epoch [28/40] Iter[55/62]		Loss: 0.1516
2019-10-28 15:41:00,175 Testing Epoch [28/40] Iter[56/62]		Loss: 0.1509
2019-10-28 15:41:00,192 Testing Epoch [28/40] Iter[57/62]		Loss: 0.1511
2019-10-28 15:41:00,209 Testing Epoch [28/40] Iter[58/62]		Loss: 0.1505
2019-10-28 15:41:00,226 Testing Epoch [28/40] Iter[59/62]		Loss: 0.1517
2019-10-28 15:41:00,243 Testing Epoch [28/40] Iter[60/62]		Loss: 0.1508
2019-10-28 15:41:00,261 Testing Epoch [28/40] Iter[61/62]		Loss: 0.1508
2019-10-28 15:41:00,270 Testing Epoch [28/40] Iter[62/62]		Loss: 0.1516
2019-10-28 15:41:00,781 Training Epoch [29/40] Iter[0/312]		Loss: 0.1268
2019-10-28 15:41:00,863 Training Epoch [29/40] Iter[1/312]		Loss: 0.1080
2019-10-28 15:41:00,943 Training Epoch [29/40] Iter[2/312]		Loss: 0.1342
2019-10-28 15:41:01,024 Training Epoch [29/40] Iter[3/312]		Loss: 0.1216
2019-10-28 15:41:01,106 Training Epoch [29/40] Iter[4/312]		Loss: 0.1127
2019-10-28 15:41:01,184 Training Epoch [29/40] Iter[5/312]		Loss: 0.1195
2019-10-28 15:41:01,263 Training Epoch [29/40] Iter[6/312]		Loss: 0.1140
2019-10-28 15:41:01,341 Training Epoch [29/40] Iter[7/312]		Loss: 0.1167
2019-10-28 15:41:01,421 Training Epoch [29/40] Iter[8/312]		Loss: 0.1121
2019-10-28 15:41:01,501 Training Epoch [29/40] Iter[9/312]		Loss: 0.1089
2019-10-28 15:41:01,580 Training Epoch [29/40] Iter[10/312]		Loss: 0.1117
2019-10-28 15:41:01,660 Training Epoch [29/40] Iter[11/312]		Loss: 0.1103
2019-10-28 15:41:01,740 Training Epoch [29/40] Iter[12/312]		Loss: 0.1106
2019-10-28 15:41:01,819 Training Epoch [29/40] Iter[13/312]		Loss: 0.1075
2019-10-28 15:41:01,899 Training Epoch [29/40] Iter[14/312]		Loss: 0.1068
2019-10-28 15:41:01,978 Training Epoch [29/40] Iter[15/312]		Loss: 0.1063
2019-10-28 15:41:02,058 Training Epoch [29/40] Iter[16/312]		Loss: 0.1082
2019-10-28 15:41:02,138 Training Epoch [29/40] Iter[17/312]		Loss: 0.1056
2019-10-28 15:41:02,217 Training Epoch [29/40] Iter[18/312]		Loss: 0.1045
2019-10-28 15:41:02,297 Training Epoch [29/40] Iter[19/312]		Loss: 0.1062
2019-10-28 15:41:02,377 Training Epoch [29/40] Iter[20/312]		Loss: 0.1051
2019-10-28 15:41:02,457 Training Epoch [29/40] Iter[21/312]		Loss: 0.1042
2019-10-28 15:41:02,536 Training Epoch [29/40] Iter[22/312]		Loss: 0.1048
2019-10-28 15:41:02,616 Training Epoch [29/40] Iter[23/312]		Loss: 0.1045
2019-10-28 15:41:02,696 Training Epoch [29/40] Iter[24/312]		Loss: 0.1031
2019-10-28 15:41:02,776 Training Epoch [29/40] Iter[25/312]		Loss: 0.1035
2019-10-28 15:41:02,856 Training Epoch [29/40] Iter[26/312]		Loss: 0.1036
2019-10-28 15:41:02,936 Training Epoch [29/40] Iter[27/312]		Loss: 0.1060
2019-10-28 15:41:03,016 Training Epoch [29/40] Iter[28/312]		Loss: 0.1055
2019-10-28 15:41:03,095 Training Epoch [29/40] Iter[29/312]		Loss: 0.1057
2019-10-28 15:41:03,175 Training Epoch [29/40] Iter[30/312]		Loss: 0.1050
2019-10-28 15:41:03,254 Training Epoch [29/40] Iter[31/312]		Loss: 0.1041
2019-10-28 15:41:03,334 Training Epoch [29/40] Iter[32/312]		Loss: 0.1040
2019-10-28 15:41:03,414 Training Epoch [29/40] Iter[33/312]		Loss: 0.1046
2019-10-28 15:41:03,493 Training Epoch [29/40] Iter[34/312]		Loss: 0.1039
2019-10-28 15:41:03,573 Training Epoch [29/40] Iter[35/312]		Loss: 0.1035
2019-10-28 15:41:03,653 Training Epoch [29/40] Iter[36/312]		Loss: 0.1036
2019-10-28 15:41:03,732 Training Epoch [29/40] Iter[37/312]		Loss: 0.1036
2019-10-28 15:41:03,812 Training Epoch [29/40] Iter[38/312]		Loss: 0.1037
2019-10-28 15:41:03,891 Training Epoch [29/40] Iter[39/312]		Loss: 0.1035
2019-10-28 15:41:03,970 Training Epoch [29/40] Iter[40/312]		Loss: 0.1029
2019-10-28 15:41:04,050 Training Epoch [29/40] Iter[41/312]		Loss: 0.1029
2019-10-28 15:41:04,129 Training Epoch [29/40] Iter[42/312]		Loss: 0.1051
2019-10-28 15:41:04,209 Training Epoch [29/40] Iter[43/312]		Loss: 0.1047
2019-10-28 15:41:04,289 Training Epoch [29/40] Iter[44/312]		Loss: 0.1049
2019-10-28 15:41:04,368 Training Epoch [29/40] Iter[45/312]		Loss: 0.1050
2019-10-28 15:41:04,448 Training Epoch [29/40] Iter[46/312]		Loss: 0.1043
2019-10-28 15:41:04,527 Training Epoch [29/40] Iter[47/312]		Loss: 0.1038
2019-10-28 15:41:04,606 Training Epoch [29/40] Iter[48/312]		Loss: 0.1030
2019-10-28 15:41:04,686 Training Epoch [29/40] Iter[49/312]		Loss: 0.1052
2019-10-28 15:41:04,765 Training Epoch [29/40] Iter[50/312]		Loss: 0.1049
2019-10-28 15:41:04,845 Training Epoch [29/40] Iter[51/312]		Loss: 0.1051
2019-10-28 15:41:04,924 Training Epoch [29/40] Iter[52/312]		Loss: 0.1057
2019-10-28 15:41:05,004 Training Epoch [29/40] Iter[53/312]		Loss: 0.1053
2019-10-28 15:41:05,083 Training Epoch [29/40] Iter[54/312]		Loss: 0.1050
2019-10-28 15:41:05,163 Training Epoch [29/40] Iter[55/312]		Loss: 0.1046
2019-10-28 15:41:05,242 Training Epoch [29/40] Iter[56/312]		Loss: 0.1067
2019-10-28 15:41:05,322 Training Epoch [29/40] Iter[57/312]		Loss: 0.1072
2019-10-28 15:41:05,402 Training Epoch [29/40] Iter[58/312]		Loss: 0.1071
2019-10-28 15:41:05,482 Training Epoch [29/40] Iter[59/312]		Loss: 0.1071
2019-10-28 15:41:05,562 Training Epoch [29/40] Iter[60/312]		Loss: 0.1072
2019-10-28 15:41:05,641 Training Epoch [29/40] Iter[61/312]		Loss: 0.1075
2019-10-28 15:41:05,721 Training Epoch [29/40] Iter[62/312]		Loss: 0.1073
2019-10-28 15:41:05,800 Training Epoch [29/40] Iter[63/312]		Loss: 0.1068
2019-10-28 15:41:05,880 Training Epoch [29/40] Iter[64/312]		Loss: 0.1073
2019-10-28 15:41:05,959 Training Epoch [29/40] Iter[65/312]		Loss: 0.1073
2019-10-28 15:41:06,039 Training Epoch [29/40] Iter[66/312]		Loss: 0.1077
2019-10-28 15:41:06,119 Training Epoch [29/40] Iter[67/312]		Loss: 0.1076
2019-10-28 15:41:06,199 Training Epoch [29/40] Iter[68/312]		Loss: 0.1085
2019-10-28 15:41:06,278 Training Epoch [29/40] Iter[69/312]		Loss: 0.1084
2019-10-28 15:41:06,358 Training Epoch [29/40] Iter[70/312]		Loss: 0.1079
2019-10-28 15:41:06,438 Training Epoch [29/40] Iter[71/312]		Loss: 0.1079
2019-10-28 15:41:06,519 Training Epoch [29/40] Iter[72/312]		Loss: 0.1078
2019-10-28 15:41:06,599 Training Epoch [29/40] Iter[73/312]		Loss: 0.1084
2019-10-28 15:41:06,678 Training Epoch [29/40] Iter[74/312]		Loss: 0.1079
2019-10-28 15:41:06,758 Training Epoch [29/40] Iter[75/312]		Loss: 0.1087
2019-10-28 15:41:06,837 Training Epoch [29/40] Iter[76/312]		Loss: 0.1092
2019-10-28 15:41:06,917 Training Epoch [29/40] Iter[77/312]		Loss: 0.1093
2019-10-28 15:41:06,997 Training Epoch [29/40] Iter[78/312]		Loss: 0.1093
2019-10-28 15:41:07,076 Training Epoch [29/40] Iter[79/312]		Loss: 0.1095
2019-10-28 15:41:07,156 Training Epoch [29/40] Iter[80/312]		Loss: 0.1102
2019-10-28 15:41:07,236 Training Epoch [29/40] Iter[81/312]		Loss: 0.1108
2019-10-28 15:41:07,315 Training Epoch [29/40] Iter[82/312]		Loss: 0.1106
2019-10-28 15:41:07,394 Training Epoch [29/40] Iter[83/312]		Loss: 0.1109
2019-10-28 15:41:07,474 Training Epoch [29/40] Iter[84/312]		Loss: 0.1115
2019-10-28 15:41:07,554 Training Epoch [29/40] Iter[85/312]		Loss: 0.1116
2019-10-28 15:41:07,633 Training Epoch [29/40] Iter[86/312]		Loss: 0.1113
2019-10-28 15:41:07,713 Training Epoch [29/40] Iter[87/312]		Loss: 0.1116
2019-10-28 15:41:07,792 Training Epoch [29/40] Iter[88/312]		Loss: 0.1111
2019-10-28 15:41:07,872 Training Epoch [29/40] Iter[89/312]		Loss: 0.1109
2019-10-28 15:41:07,951 Training Epoch [29/40] Iter[90/312]		Loss: 0.1108
2019-10-28 15:41:08,031 Training Epoch [29/40] Iter[91/312]		Loss: 0.1110
2019-10-28 15:41:08,111 Training Epoch [29/40] Iter[92/312]		Loss: 0.1116
2019-10-28 15:41:08,195 Training Epoch [29/40] Iter[93/312]		Loss: 0.1113
2019-10-28 15:41:08,279 Training Epoch [29/40] Iter[94/312]		Loss: 0.1111
2019-10-28 15:41:08,359 Training Epoch [29/40] Iter[95/312]		Loss: 0.1112
2019-10-28 15:41:08,438 Training Epoch [29/40] Iter[96/312]		Loss: 0.1112
2019-10-28 15:41:08,518 Training Epoch [29/40] Iter[97/312]		Loss: 0.1110
2019-10-28 15:41:08,598 Training Epoch [29/40] Iter[98/312]		Loss: 0.1107
2019-10-28 15:41:08,678 Training Epoch [29/40] Iter[99/312]		Loss: 0.1105
2019-10-28 15:41:08,757 Training Epoch [29/40] Iter[100/312]		Loss: 0.1109
2019-10-28 15:41:08,837 Training Epoch [29/40] Iter[101/312]		Loss: 0.1112
2019-10-28 15:41:08,916 Training Epoch [29/40] Iter[102/312]		Loss: 0.1107
2019-10-28 15:41:08,996 Training Epoch [29/40] Iter[103/312]		Loss: 0.1105
2019-10-28 15:41:09,075 Training Epoch [29/40] Iter[104/312]		Loss: 0.1103
2019-10-28 15:41:09,155 Training Epoch [29/40] Iter[105/312]		Loss: 0.1102
2019-10-28 15:41:09,235 Training Epoch [29/40] Iter[106/312]		Loss: 0.1106
2019-10-28 15:41:09,315 Training Epoch [29/40] Iter[107/312]		Loss: 0.1106
2019-10-28 15:41:09,394 Training Epoch [29/40] Iter[108/312]		Loss: 0.1107
2019-10-28 15:41:09,474 Training Epoch [29/40] Iter[109/312]		Loss: 0.1107
2019-10-28 15:41:09,554 Training Epoch [29/40] Iter[110/312]		Loss: 0.1104
2019-10-28 15:41:09,633 Training Epoch [29/40] Iter[111/312]		Loss: 0.1102
2019-10-28 15:41:09,713 Training Epoch [29/40] Iter[112/312]		Loss: 0.1098
2019-10-28 15:41:09,793 Training Epoch [29/40] Iter[113/312]		Loss: 0.1103
2019-10-28 15:41:09,872 Training Epoch [29/40] Iter[114/312]		Loss: 0.1101
2019-10-28 15:41:09,952 Training Epoch [29/40] Iter[115/312]		Loss: 0.1099
2019-10-28 15:41:10,032 Training Epoch [29/40] Iter[116/312]		Loss: 0.1101
2019-10-28 15:41:10,112 Training Epoch [29/40] Iter[117/312]		Loss: 0.1106
2019-10-28 15:41:10,191 Training Epoch [29/40] Iter[118/312]		Loss: 0.1110
2019-10-28 15:41:10,271 Training Epoch [29/40] Iter[119/312]		Loss: 0.1109
2019-10-28 15:41:10,350 Training Epoch [29/40] Iter[120/312]		Loss: 0.1106
2019-10-28 15:41:10,430 Training Epoch [29/40] Iter[121/312]		Loss: 0.1103
2019-10-28 15:41:10,509 Training Epoch [29/40] Iter[122/312]		Loss: 0.1105
2019-10-28 15:41:10,589 Training Epoch [29/40] Iter[123/312]		Loss: 0.1103
2019-10-28 15:41:10,668 Training Epoch [29/40] Iter[124/312]		Loss: 0.1099
2019-10-28 15:41:10,748 Training Epoch [29/40] Iter[125/312]		Loss: 0.1103
2019-10-28 15:41:10,828 Training Epoch [29/40] Iter[126/312]		Loss: 0.1099
2019-10-28 15:41:10,907 Training Epoch [29/40] Iter[127/312]		Loss: 0.1106
2019-10-28 15:41:10,987 Training Epoch [29/40] Iter[128/312]		Loss: 0.1106
2019-10-28 15:41:11,067 Training Epoch [29/40] Iter[129/312]		Loss: 0.1103
2019-10-28 15:41:11,147 Training Epoch [29/40] Iter[130/312]		Loss: 0.1101
2019-10-28 15:41:11,226 Training Epoch [29/40] Iter[131/312]		Loss: 0.1100
2019-10-28 15:41:11,306 Training Epoch [29/40] Iter[132/312]		Loss: 0.1098
2019-10-28 15:41:11,386 Training Epoch [29/40] Iter[133/312]		Loss: 0.1099
2019-10-28 15:41:11,466 Training Epoch [29/40] Iter[134/312]		Loss: 0.1102
2019-10-28 15:41:11,546 Training Epoch [29/40] Iter[135/312]		Loss: 0.1102
2019-10-28 15:41:11,626 Training Epoch [29/40] Iter[136/312]		Loss: 0.1101
2019-10-28 15:41:11,706 Training Epoch [29/40] Iter[137/312]		Loss: 0.1102
2019-10-28 15:41:11,786 Training Epoch [29/40] Iter[138/312]		Loss: 0.1100
2019-10-28 15:41:11,865 Training Epoch [29/40] Iter[139/312]		Loss: 0.1098
2019-10-28 15:41:11,945 Training Epoch [29/40] Iter[140/312]		Loss: 0.1101
2019-10-28 15:41:12,026 Training Epoch [29/40] Iter[141/312]		Loss: 0.1100
2019-10-28 15:41:12,105 Training Epoch [29/40] Iter[142/312]		Loss: 0.1099
2019-10-28 15:41:12,185 Training Epoch [29/40] Iter[143/312]		Loss: 0.1099
2019-10-28 15:41:12,265 Training Epoch [29/40] Iter[144/312]		Loss: 0.1099
2019-10-28 15:41:12,345 Training Epoch [29/40] Iter[145/312]		Loss: 0.1097
2019-10-28 15:41:12,425 Training Epoch [29/40] Iter[146/312]		Loss: 0.1097
2019-10-28 15:41:12,505 Training Epoch [29/40] Iter[147/312]		Loss: 0.1099
2019-10-28 15:41:12,585 Training Epoch [29/40] Iter[148/312]		Loss: 0.1099
2019-10-28 15:41:12,664 Training Epoch [29/40] Iter[149/312]		Loss: 0.1098
2019-10-28 15:41:12,744 Training Epoch [29/40] Iter[150/312]		Loss: 0.1103
2019-10-28 15:41:12,824 Training Epoch [29/40] Iter[151/312]		Loss: 0.1104
2019-10-28 15:41:12,904 Training Epoch [29/40] Iter[152/312]		Loss: 0.1102
2019-10-28 15:41:12,984 Training Epoch [29/40] Iter[153/312]		Loss: 0.1101
2019-10-28 15:41:13,064 Training Epoch [29/40] Iter[154/312]		Loss: 0.1097
2019-10-28 15:41:13,143 Training Epoch [29/40] Iter[155/312]		Loss: 0.1096
2019-10-28 15:41:13,223 Training Epoch [29/40] Iter[156/312]		Loss: 0.1100
2019-10-28 15:41:13,303 Training Epoch [29/40] Iter[157/312]		Loss: 0.1098
2019-10-28 15:41:13,383 Training Epoch [29/40] Iter[158/312]		Loss: 0.1097
2019-10-28 15:41:13,468 Training Epoch [29/40] Iter[159/312]		Loss: 0.1096
2019-10-28 15:41:13,548 Training Epoch [29/40] Iter[160/312]		Loss: 0.1095
2019-10-28 15:41:13,628 Training Epoch [29/40] Iter[161/312]		Loss: 0.1094
2019-10-28 15:41:13,708 Training Epoch [29/40] Iter[162/312]		Loss: 0.1094
2019-10-28 15:41:13,788 Training Epoch [29/40] Iter[163/312]		Loss: 0.1094
2019-10-28 15:41:13,867 Training Epoch [29/40] Iter[164/312]		Loss: 0.1093
2019-10-28 15:41:13,947 Training Epoch [29/40] Iter[165/312]		Loss: 0.1092
2019-10-28 15:41:14,027 Training Epoch [29/40] Iter[166/312]		Loss: 0.1091
2019-10-28 15:41:14,107 Training Epoch [29/40] Iter[167/312]		Loss: 0.1088
2019-10-28 15:41:14,187 Training Epoch [29/40] Iter[168/312]		Loss: 0.1091
2019-10-28 15:41:14,267 Training Epoch [29/40] Iter[169/312]		Loss: 0.1090
2019-10-28 15:41:14,346 Training Epoch [29/40] Iter[170/312]		Loss: 0.1088
2019-10-28 15:41:14,426 Training Epoch [29/40] Iter[171/312]		Loss: 0.1089
2019-10-28 15:41:14,506 Training Epoch [29/40] Iter[172/312]		Loss: 0.1089
2019-10-28 15:41:14,586 Training Epoch [29/40] Iter[173/312]		Loss: 0.1088
2019-10-28 15:41:14,666 Training Epoch [29/40] Iter[174/312]		Loss: 0.1087
2019-10-28 15:41:14,745 Training Epoch [29/40] Iter[175/312]		Loss: 0.1089
2019-10-28 15:41:14,825 Training Epoch [29/40] Iter[176/312]		Loss: 0.1087
2019-10-28 15:41:14,905 Training Epoch [29/40] Iter[177/312]		Loss: 0.1091
2019-10-28 15:41:14,985 Training Epoch [29/40] Iter[178/312]		Loss: 0.1089
2019-10-28 15:41:15,065 Training Epoch [29/40] Iter[179/312]		Loss: 0.1088
2019-10-28 15:41:15,144 Training Epoch [29/40] Iter[180/312]		Loss: 0.1086
2019-10-28 15:41:15,225 Training Epoch [29/40] Iter[181/312]		Loss: 0.1086
2019-10-28 15:41:15,304 Training Epoch [29/40] Iter[182/312]		Loss: 0.1088
2019-10-28 15:41:15,384 Training Epoch [29/40] Iter[183/312]		Loss: 0.1090
2019-10-28 15:41:15,464 Training Epoch [29/40] Iter[184/312]		Loss: 0.1088
2019-10-28 15:41:15,544 Training Epoch [29/40] Iter[185/312]		Loss: 0.1088
2019-10-28 15:41:15,623 Training Epoch [29/40] Iter[186/312]		Loss: 0.1088
2019-10-28 15:41:15,703 Training Epoch [29/40] Iter[187/312]		Loss: 0.1086
2019-10-28 15:41:15,783 Training Epoch [29/40] Iter[188/312]		Loss: 0.1085
2019-10-28 15:41:15,862 Training Epoch [29/40] Iter[189/312]		Loss: 0.1087
2019-10-28 15:41:15,942 Training Epoch [29/40] Iter[190/312]		Loss: 0.1094
2019-10-28 15:41:16,021 Training Epoch [29/40] Iter[191/312]		Loss: 0.1094
2019-10-28 15:41:16,101 Training Epoch [29/40] Iter[192/312]		Loss: 0.1093
2019-10-28 15:41:16,181 Training Epoch [29/40] Iter[193/312]		Loss: 0.1093
2019-10-28 15:41:16,260 Training Epoch [29/40] Iter[194/312]		Loss: 0.1093
2019-10-28 15:41:16,340 Training Epoch [29/40] Iter[195/312]		Loss: 0.1093
2019-10-28 15:41:16,419 Training Epoch [29/40] Iter[196/312]		Loss: 0.1093
2019-10-28 15:41:16,499 Training Epoch [29/40] Iter[197/312]		Loss: 0.1101
2019-10-28 15:41:16,578 Training Epoch [29/40] Iter[198/312]		Loss: 0.1104
2019-10-28 15:41:16,658 Training Epoch [29/40] Iter[199/312]		Loss: 0.1102
2019-10-28 15:41:16,737 Training Epoch [29/40] Iter[200/312]		Loss: 0.1102
2019-10-28 15:41:16,816 Training Epoch [29/40] Iter[201/312]		Loss: 0.1100
2019-10-28 15:41:16,896 Training Epoch [29/40] Iter[202/312]		Loss: 0.1099
2019-10-28 15:41:16,975 Training Epoch [29/40] Iter[203/312]		Loss: 0.1098
2019-10-28 15:41:17,055 Training Epoch [29/40] Iter[204/312]		Loss: 0.1096
2019-10-28 15:41:17,134 Training Epoch [29/40] Iter[205/312]		Loss: 0.1096
2019-10-28 15:41:17,215 Training Epoch [29/40] Iter[206/312]		Loss: 0.1095
2019-10-28 15:41:17,295 Training Epoch [29/40] Iter[207/312]		Loss: 0.1095
2019-10-28 15:41:17,375 Training Epoch [29/40] Iter[208/312]		Loss: 0.1094
2019-10-28 15:41:17,455 Training Epoch [29/40] Iter[209/312]		Loss: 0.1095
2019-10-28 15:41:17,535 Training Epoch [29/40] Iter[210/312]		Loss: 0.1095
2019-10-28 15:41:17,615 Training Epoch [29/40] Iter[211/312]		Loss: 0.1094
2019-10-28 15:41:17,695 Training Epoch [29/40] Iter[212/312]		Loss: 0.1097
2019-10-28 15:41:17,776 Training Epoch [29/40] Iter[213/312]		Loss: 0.1095
2019-10-28 15:41:17,856 Training Epoch [29/40] Iter[214/312]		Loss: 0.1095
2019-10-28 15:41:17,936 Training Epoch [29/40] Iter[215/312]		Loss: 0.1095
2019-10-28 15:41:18,016 Training Epoch [29/40] Iter[216/312]		Loss: 0.1096
2019-10-28 15:41:18,097 Training Epoch [29/40] Iter[217/312]		Loss: 0.1096
2019-10-28 15:41:18,177 Training Epoch [29/40] Iter[218/312]		Loss: 0.1097
2019-10-28 15:41:18,257 Training Epoch [29/40] Iter[219/312]		Loss: 0.1096
2019-10-28 15:41:18,337 Training Epoch [29/40] Iter[220/312]		Loss: 0.1093
2019-10-28 15:41:18,417 Training Epoch [29/40] Iter[221/312]		Loss: 0.1091
2019-10-28 15:41:18,497 Training Epoch [29/40] Iter[222/312]		Loss: 0.1091
2019-10-28 15:41:18,577 Training Epoch [29/40] Iter[223/312]		Loss: 0.1090
2019-10-28 15:41:18,657 Training Epoch [29/40] Iter[224/312]		Loss: 0.1091
2019-10-28 15:41:18,737 Training Epoch [29/40] Iter[225/312]		Loss: 0.1092
2019-10-28 15:41:18,817 Training Epoch [29/40] Iter[226/312]		Loss: 0.1092
2019-10-28 15:41:18,896 Training Epoch [29/40] Iter[227/312]		Loss: 0.1093
2019-10-28 15:41:18,976 Training Epoch [29/40] Iter[228/312]		Loss: 0.1094
2019-10-28 15:41:19,055 Training Epoch [29/40] Iter[229/312]		Loss: 0.1095
2019-10-28 15:41:19,135 Training Epoch [29/40] Iter[230/312]		Loss: 0.1098
2019-10-28 15:41:19,214 Training Epoch [29/40] Iter[231/312]		Loss: 0.1098
2019-10-28 15:41:19,294 Training Epoch [29/40] Iter[232/312]		Loss: 0.1097
2019-10-28 15:41:19,373 Training Epoch [29/40] Iter[233/312]		Loss: 0.1096
2019-10-28 15:41:19,453 Training Epoch [29/40] Iter[234/312]		Loss: 0.1095
2019-10-28 15:41:19,532 Training Epoch [29/40] Iter[235/312]		Loss: 0.1097
2019-10-28 15:41:19,612 Training Epoch [29/40] Iter[236/312]		Loss: 0.1096
2019-10-28 15:41:19,691 Training Epoch [29/40] Iter[237/312]		Loss: 0.1096
2019-10-28 15:41:19,771 Training Epoch [29/40] Iter[238/312]		Loss: 0.1095
2019-10-28 15:41:19,850 Training Epoch [29/40] Iter[239/312]		Loss: 0.1098
2019-10-28 15:41:19,929 Training Epoch [29/40] Iter[240/312]		Loss: 0.1100
2019-10-28 15:41:20,008 Training Epoch [29/40] Iter[241/312]		Loss: 0.1100
2019-10-28 15:41:20,088 Training Epoch [29/40] Iter[242/312]		Loss: 0.1099
2019-10-28 15:41:20,167 Training Epoch [29/40] Iter[243/312]		Loss: 0.1102
2019-10-28 15:41:20,247 Training Epoch [29/40] Iter[244/312]		Loss: 0.1108
2019-10-28 15:41:20,326 Training Epoch [29/40] Iter[245/312]		Loss: 0.1112
2019-10-28 15:41:20,405 Training Epoch [29/40] Iter[246/312]		Loss: 0.1114
2019-10-28 15:41:20,484 Training Epoch [29/40] Iter[247/312]		Loss: 0.1114
2019-10-28 15:41:20,564 Training Epoch [29/40] Iter[248/312]		Loss: 0.1115
2019-10-28 15:41:20,643 Training Epoch [29/40] Iter[249/312]		Loss: 0.1113
2019-10-28 15:41:20,722 Training Epoch [29/40] Iter[250/312]		Loss: 0.1116
2019-10-28 15:41:20,802 Training Epoch [29/40] Iter[251/312]		Loss: 0.1117
2019-10-28 15:41:20,881 Training Epoch [29/40] Iter[252/312]		Loss: 0.1120
2019-10-28 15:41:20,960 Training Epoch [29/40] Iter[253/312]		Loss: 0.1119
2019-10-28 15:41:21,039 Training Epoch [29/40] Iter[254/312]		Loss: 0.1119
2019-10-28 15:41:21,123 Training Epoch [29/40] Iter[255/312]		Loss: 0.1120
2019-10-28 15:41:21,202 Training Epoch [29/40] Iter[256/312]		Loss: 0.1118
2019-10-28 15:41:21,282 Training Epoch [29/40] Iter[257/312]		Loss: 0.1121
2019-10-28 15:41:21,361 Training Epoch [29/40] Iter[258/312]		Loss: 0.1121
2019-10-28 15:41:21,441 Training Epoch [29/40] Iter[259/312]		Loss: 0.1121
2019-10-28 15:41:21,520 Training Epoch [29/40] Iter[260/312]		Loss: 0.1121
2019-10-28 15:41:21,599 Training Epoch [29/40] Iter[261/312]		Loss: 0.1120
2019-10-28 15:41:21,678 Training Epoch [29/40] Iter[262/312]		Loss: 0.1120
2019-10-28 15:41:21,758 Training Epoch [29/40] Iter[263/312]		Loss: 0.1119
2019-10-28 15:41:21,837 Training Epoch [29/40] Iter[264/312]		Loss: 0.1119
2019-10-28 15:41:21,917 Training Epoch [29/40] Iter[265/312]		Loss: 0.1118
2019-10-28 15:41:21,996 Training Epoch [29/40] Iter[266/312]		Loss: 0.1117
2019-10-28 15:41:22,076 Training Epoch [29/40] Iter[267/312]		Loss: 0.1116
2019-10-28 15:41:22,155 Training Epoch [29/40] Iter[268/312]		Loss: 0.1116
2019-10-28 15:41:22,235 Training Epoch [29/40] Iter[269/312]		Loss: 0.1116
2019-10-28 15:41:22,314 Training Epoch [29/40] Iter[270/312]		Loss: 0.1116
2019-10-28 15:41:22,394 Training Epoch [29/40] Iter[271/312]		Loss: 0.1116
2019-10-28 15:41:22,474 Training Epoch [29/40] Iter[272/312]		Loss: 0.1115
2019-10-28 15:41:22,554 Training Epoch [29/40] Iter[273/312]		Loss: 0.1114
2019-10-28 15:41:22,633 Training Epoch [29/40] Iter[274/312]		Loss: 0.1113
2019-10-28 15:41:22,712 Training Epoch [29/40] Iter[275/312]		Loss: 0.1115
2019-10-28 15:41:22,792 Training Epoch [29/40] Iter[276/312]		Loss: 0.1117
2019-10-28 15:41:22,871 Training Epoch [29/40] Iter[277/312]		Loss: 0.1119
2019-10-28 15:41:22,950 Training Epoch [29/40] Iter[278/312]		Loss: 0.1119
2019-10-28 15:41:23,029 Training Epoch [29/40] Iter[279/312]		Loss: 0.1118
2019-10-28 15:41:23,109 Training Epoch [29/40] Iter[280/312]		Loss: 0.1117
2019-10-28 15:41:23,188 Training Epoch [29/40] Iter[281/312]		Loss: 0.1117
2019-10-28 15:41:23,268 Training Epoch [29/40] Iter[282/312]		Loss: 0.1118
2019-10-28 15:41:23,347 Training Epoch [29/40] Iter[283/312]		Loss: 0.1119
2019-10-28 15:41:23,426 Training Epoch [29/40] Iter[284/312]		Loss: 0.1118
2019-10-28 15:41:23,506 Training Epoch [29/40] Iter[285/312]		Loss: 0.1119
2019-10-28 15:41:23,585 Training Epoch [29/40] Iter[286/312]		Loss: 0.1119
2019-10-28 15:41:23,665 Training Epoch [29/40] Iter[287/312]		Loss: 0.1120
2019-10-28 15:41:23,745 Training Epoch [29/40] Iter[288/312]		Loss: 0.1121
2019-10-28 15:41:23,824 Training Epoch [29/40] Iter[289/312]		Loss: 0.1120
2019-10-28 15:41:23,903 Training Epoch [29/40] Iter[290/312]		Loss: 0.1121
2019-10-28 15:41:23,982 Training Epoch [29/40] Iter[291/312]		Loss: 0.1123
2019-10-28 15:41:24,062 Training Epoch [29/40] Iter[292/312]		Loss: 0.1122
2019-10-28 15:41:24,141 Training Epoch [29/40] Iter[293/312]		Loss: 0.1125
2019-10-28 15:41:24,221 Training Epoch [29/40] Iter[294/312]		Loss: 0.1124
2019-10-28 15:41:24,300 Training Epoch [29/40] Iter[295/312]		Loss: 0.1127
2019-10-28 15:41:24,379 Training Epoch [29/40] Iter[296/312]		Loss: 0.1126
2019-10-28 15:41:24,458 Training Epoch [29/40] Iter[297/312]		Loss: 0.1126
2019-10-28 15:41:24,537 Training Epoch [29/40] Iter[298/312]		Loss: 0.1127
2019-10-28 15:41:24,616 Training Epoch [29/40] Iter[299/312]		Loss: 0.1127
2019-10-28 15:41:24,696 Training Epoch [29/40] Iter[300/312]		Loss: 0.1127
2019-10-28 15:41:24,775 Training Epoch [29/40] Iter[301/312]		Loss: 0.1127
2019-10-28 15:41:24,854 Training Epoch [29/40] Iter[302/312]		Loss: 0.1126
2019-10-28 15:41:24,933 Training Epoch [29/40] Iter[303/312]		Loss: 0.1128
2019-10-28 15:41:25,012 Training Epoch [29/40] Iter[304/312]		Loss: 0.1129
2019-10-28 15:41:25,090 Training Epoch [29/40] Iter[305/312]		Loss: 0.1130
2019-10-28 15:41:25,169 Training Epoch [29/40] Iter[306/312]		Loss: 0.1130
2019-10-28 15:41:25,248 Training Epoch [29/40] Iter[307/312]		Loss: 0.1129
2019-10-28 15:41:25,326 Training Epoch [29/40] Iter[308/312]		Loss: 0.1128
2019-10-28 15:41:25,405 Training Epoch [29/40] Iter[309/312]		Loss: 0.1127
2019-10-28 15:41:25,483 Training Epoch [29/40] Iter[310/312]		Loss: 0.1129
2019-10-28 15:41:25,562 Training Epoch [29/40] Iter[311/312]		Loss: 0.1130
2019-10-28 15:41:25,601 Training Epoch [29/40] Iter[312/312]		Loss: 0.1130
2019-10-28 15:41:26,034 Testing Epoch [29/40] Iter[0/62]		Loss: 0.1301
2019-10-28 15:41:26,070 Testing Epoch [29/40] Iter[1/62]		Loss: 0.1273
2019-10-28 15:41:26,106 Testing Epoch [29/40] Iter[2/62]		Loss: 0.1116
2019-10-28 15:41:26,126 Testing Epoch [29/40] Iter[3/62]		Loss: 0.1148
2019-10-28 15:41:26,149 Testing Epoch [29/40] Iter[4/62]		Loss: 0.1222
2019-10-28 15:41:26,173 Testing Epoch [29/40] Iter[5/62]		Loss: 0.1177
2019-10-28 15:41:26,190 Testing Epoch [29/40] Iter[6/62]		Loss: 0.1203
2019-10-28 15:41:26,207 Testing Epoch [29/40] Iter[7/62]		Loss: 0.1218
2019-10-28 15:41:26,238 Testing Epoch [29/40] Iter[8/62]		Loss: 0.1236
2019-10-28 15:41:26,255 Testing Epoch [29/40] Iter[9/62]		Loss: 0.1228
2019-10-28 15:41:26,273 Testing Epoch [29/40] Iter[10/62]		Loss: 0.1242
2019-10-28 15:41:26,291 Testing Epoch [29/40] Iter[11/62]		Loss: 0.1313
2019-10-28 15:41:26,318 Testing Epoch [29/40] Iter[12/62]		Loss: 0.1313
2019-10-28 15:41:26,337 Testing Epoch [29/40] Iter[13/62]		Loss: 0.1335
2019-10-28 15:41:26,359 Testing Epoch [29/40] Iter[14/62]		Loss: 0.1457
2019-10-28 15:41:26,377 Testing Epoch [29/40] Iter[15/62]		Loss: 0.1474
2019-10-28 15:41:26,414 Testing Epoch [29/40] Iter[16/62]		Loss: 0.1440
2019-10-28 15:41:26,433 Testing Epoch [29/40] Iter[17/62]		Loss: 0.1451
2019-10-28 15:41:26,451 Testing Epoch [29/40] Iter[18/62]		Loss: 0.1428
2019-10-28 15:41:26,469 Testing Epoch [29/40] Iter[19/62]		Loss: 0.1408
2019-10-28 15:41:26,499 Testing Epoch [29/40] Iter[20/62]		Loss: 0.1425
2019-10-28 15:41:26,518 Testing Epoch [29/40] Iter[21/62]		Loss: 0.1406
2019-10-28 15:41:26,540 Testing Epoch [29/40] Iter[22/62]		Loss: 0.1418
2019-10-28 15:41:26,569 Testing Epoch [29/40] Iter[23/62]		Loss: 0.1404
2019-10-28 15:41:26,585 Testing Epoch [29/40] Iter[24/62]		Loss: 0.1435
2019-10-28 15:41:26,603 Testing Epoch [29/40] Iter[25/62]		Loss: 0.1427
2019-10-28 15:41:26,630 Testing Epoch [29/40] Iter[26/62]		Loss: 0.1418
2019-10-28 15:41:26,658 Testing Epoch [29/40] Iter[27/62]		Loss: 0.1495
2019-10-28 15:41:26,679 Testing Epoch [29/40] Iter[28/62]		Loss: 0.1533
2019-10-28 15:41:26,697 Testing Epoch [29/40] Iter[29/62]		Loss: 0.1535
2019-10-28 15:41:26,715 Testing Epoch [29/40] Iter[30/62]		Loss: 0.1537
2019-10-28 15:41:26,742 Testing Epoch [29/40] Iter[31/62]		Loss: 0.1525
2019-10-28 15:41:26,760 Testing Epoch [29/40] Iter[32/62]		Loss: 0.1541
2019-10-28 15:41:26,782 Testing Epoch [29/40] Iter[33/62]		Loss: 0.1531
2019-10-28 15:41:26,809 Testing Epoch [29/40] Iter[34/62]		Loss: 0.1553
2019-10-28 15:41:26,825 Testing Epoch [29/40] Iter[35/62]		Loss: 0.1548
2019-10-28 15:41:26,847 Testing Epoch [29/40] Iter[36/62]		Loss: 0.1529
2019-10-28 15:41:26,869 Testing Epoch [29/40] Iter[37/62]		Loss: 0.1516
2019-10-28 15:41:26,894 Testing Epoch [29/40] Iter[38/62]		Loss: 0.1506
2019-10-28 15:41:26,917 Testing Epoch [29/40] Iter[39/62]		Loss: 0.1509
2019-10-28 15:41:26,945 Testing Epoch [29/40] Iter[40/62]		Loss: 0.1525
2019-10-28 15:41:26,963 Testing Epoch [29/40] Iter[41/62]		Loss: 0.1541
2019-10-28 15:41:26,982 Testing Epoch [29/40] Iter[42/62]		Loss: 0.1520
2019-10-28 15:41:27,010 Testing Epoch [29/40] Iter[43/62]		Loss: 0.1514
2019-10-28 15:41:27,034 Testing Epoch [29/40] Iter[44/62]		Loss: 0.1496
2019-10-28 15:41:27,052 Testing Epoch [29/40] Iter[45/62]		Loss: 0.1493
2019-10-28 15:41:27,070 Testing Epoch [29/40] Iter[46/62]		Loss: 0.1490
2019-10-28 15:41:27,102 Testing Epoch [29/40] Iter[47/62]		Loss: 0.1548
2019-10-28 15:41:27,129 Testing Epoch [29/40] Iter[48/62]		Loss: 0.1538
2019-10-28 15:41:27,147 Testing Epoch [29/40] Iter[49/62]		Loss: 0.1559
2019-10-28 15:41:27,166 Testing Epoch [29/40] Iter[50/62]		Loss: 0.1549
2019-10-28 15:41:27,193 Testing Epoch [29/40] Iter[51/62]		Loss: 0.1549
2019-10-28 15:41:27,211 Testing Epoch [29/40] Iter[52/62]		Loss: 0.1537
2019-10-28 15:41:27,229 Testing Epoch [29/40] Iter[53/62]		Loss: 0.1539
2019-10-28 15:41:27,258 Testing Epoch [29/40] Iter[54/62]		Loss: 0.1528
2019-10-28 15:41:27,276 Testing Epoch [29/40] Iter[55/62]		Loss: 0.1524
2019-10-28 15:41:27,293 Testing Epoch [29/40] Iter[56/62]		Loss: 0.1517
2019-10-28 15:41:27,310 Testing Epoch [29/40] Iter[57/62]		Loss: 0.1519
2019-10-28 15:41:27,326 Testing Epoch [29/40] Iter[58/62]		Loss: 0.1514
2019-10-28 15:41:27,343 Testing Epoch [29/40] Iter[59/62]		Loss: 0.1524
2019-10-28 15:41:27,359 Testing Epoch [29/40] Iter[60/62]		Loss: 0.1516
2019-10-28 15:41:27,377 Testing Epoch [29/40] Iter[61/62]		Loss: 0.1515
2019-10-28 15:41:27,386 Testing Epoch [29/40] Iter[62/62]		Loss: 0.1521
2019-10-28 15:41:27,889 Training Epoch [30/40] Iter[0/312]		Loss: 0.0774
2019-10-28 15:41:27,968 Training Epoch [30/40] Iter[1/312]		Loss: 0.1100
2019-10-28 15:41:28,051 Training Epoch [30/40] Iter[2/312]		Loss: 0.1049
2019-10-28 15:41:28,129 Training Epoch [30/40] Iter[3/312]		Loss: 0.0920
2019-10-28 15:41:28,211 Training Epoch [30/40] Iter[4/312]		Loss: 0.0931
2019-10-28 15:41:28,289 Training Epoch [30/40] Iter[5/312]		Loss: 0.0878
2019-10-28 15:41:28,367 Training Epoch [30/40] Iter[6/312]		Loss: 0.0849
2019-10-28 15:41:28,447 Training Epoch [30/40] Iter[7/312]		Loss: 0.0849
2019-10-28 15:41:28,526 Training Epoch [30/40] Iter[8/312]		Loss: 0.0855
2019-10-28 15:41:28,606 Training Epoch [30/40] Iter[9/312]		Loss: 0.0891
2019-10-28 15:41:28,686 Training Epoch [30/40] Iter[10/312]		Loss: 0.0891
2019-10-28 15:41:28,765 Training Epoch [30/40] Iter[11/312]		Loss: 0.0901
2019-10-28 15:41:28,845 Training Epoch [30/40] Iter[12/312]		Loss: 0.0912
2019-10-28 15:41:28,925 Training Epoch [30/40] Iter[13/312]		Loss: 0.0932
2019-10-28 15:41:29,004 Training Epoch [30/40] Iter[14/312]		Loss: 0.0940
2019-10-28 15:41:29,084 Training Epoch [30/40] Iter[15/312]		Loss: 0.0954
2019-10-28 15:41:29,163 Training Epoch [30/40] Iter[16/312]		Loss: 0.0959
2019-10-28 15:41:29,243 Training Epoch [30/40] Iter[17/312]		Loss: 0.0964
2019-10-28 15:41:29,322 Training Epoch [30/40] Iter[18/312]		Loss: 0.0966
2019-10-28 15:41:29,402 Training Epoch [30/40] Iter[19/312]		Loss: 0.0985
2019-10-28 15:41:29,481 Training Epoch [30/40] Iter[20/312]		Loss: 0.0987
2019-10-28 15:41:29,561 Training Epoch [30/40] Iter[21/312]		Loss: 0.0975
2019-10-28 15:41:29,640 Training Epoch [30/40] Iter[22/312]		Loss: 0.0988
2019-10-28 15:41:29,720 Training Epoch [30/40] Iter[23/312]		Loss: 0.0986
2019-10-28 15:41:29,799 Training Epoch [30/40] Iter[24/312]		Loss: 0.0983
2019-10-28 15:41:29,879 Training Epoch [30/40] Iter[25/312]		Loss: 0.0984
2019-10-28 15:41:29,958 Training Epoch [30/40] Iter[26/312]		Loss: 0.0994
2019-10-28 15:41:30,038 Training Epoch [30/40] Iter[27/312]		Loss: 0.0985
2019-10-28 15:41:30,117 Training Epoch [30/40] Iter[28/312]		Loss: 0.1011
2019-10-28 15:41:30,197 Training Epoch [30/40] Iter[29/312]		Loss: 0.1015
2019-10-28 15:41:30,276 Training Epoch [30/40] Iter[30/312]		Loss: 0.1016
2019-10-28 15:41:30,357 Training Epoch [30/40] Iter[31/312]		Loss: 0.1013
2019-10-28 15:41:30,436 Training Epoch [30/40] Iter[32/312]		Loss: 0.1013
2019-10-28 15:41:30,516 Training Epoch [30/40] Iter[33/312]		Loss: 0.1017
2019-10-28 15:41:30,596 Training Epoch [30/40] Iter[34/312]		Loss: 0.1008
2019-10-28 15:41:30,676 Training Epoch [30/40] Iter[35/312]		Loss: 0.1031
2019-10-28 15:41:30,755 Training Epoch [30/40] Iter[36/312]		Loss: 0.1037
2019-10-28 15:41:30,835 Training Epoch [30/40] Iter[37/312]		Loss: 0.1034
2019-10-28 15:41:30,914 Training Epoch [30/40] Iter[38/312]		Loss: 0.1058
2019-10-28 15:41:30,994 Training Epoch [30/40] Iter[39/312]		Loss: 0.1048
2019-10-28 15:41:31,074 Training Epoch [30/40] Iter[40/312]		Loss: 0.1045
2019-10-28 15:41:31,154 Training Epoch [30/40] Iter[41/312]		Loss: 0.1049
2019-10-28 15:41:31,234 Training Epoch [30/40] Iter[42/312]		Loss: 0.1066
2019-10-28 15:41:31,314 Training Epoch [30/40] Iter[43/312]		Loss: 0.1070
2019-10-28 15:41:31,394 Training Epoch [30/40] Iter[44/312]		Loss: 0.1069
2019-10-28 15:41:31,473 Training Epoch [30/40] Iter[45/312]		Loss: 0.1065
2019-10-28 15:41:31,553 Training Epoch [30/40] Iter[46/312]		Loss: 0.1061
2019-10-28 15:41:31,633 Training Epoch [30/40] Iter[47/312]		Loss: 0.1056
2019-10-28 15:41:31,713 Training Epoch [30/40] Iter[48/312]		Loss: 0.1063
2019-10-28 15:41:31,792 Training Epoch [30/40] Iter[49/312]		Loss: 0.1061
2019-10-28 15:41:31,872 Training Epoch [30/40] Iter[50/312]		Loss: 0.1054
2019-10-28 15:41:31,952 Training Epoch [30/40] Iter[51/312]		Loss: 0.1057
2019-10-28 15:41:32,032 Training Epoch [30/40] Iter[52/312]		Loss: 0.1068
2019-10-28 15:41:32,111 Training Epoch [30/40] Iter[53/312]		Loss: 0.1066
2019-10-28 15:41:32,191 Training Epoch [30/40] Iter[54/312]		Loss: 0.1065
2019-10-28 15:41:32,271 Training Epoch [30/40] Iter[55/312]		Loss: 0.1085
2019-10-28 15:41:32,351 Training Epoch [30/40] Iter[56/312]		Loss: 0.1096
2019-10-28 15:41:32,431 Training Epoch [30/40] Iter[57/312]		Loss: 0.1096
2019-10-28 15:41:32,511 Training Epoch [30/40] Iter[58/312]		Loss: 0.1101
2019-10-28 15:41:32,591 Training Epoch [30/40] Iter[59/312]		Loss: 0.1109
2019-10-28 15:41:32,671 Training Epoch [30/40] Iter[60/312]		Loss: 0.1111
2019-10-28 15:41:32,751 Training Epoch [30/40] Iter[61/312]		Loss: 0.1104
2019-10-28 15:41:32,830 Training Epoch [30/40] Iter[62/312]		Loss: 0.1098
2019-10-28 15:41:32,910 Training Epoch [30/40] Iter[63/312]		Loss: 0.1094
2019-10-28 15:41:32,990 Training Epoch [30/40] Iter[64/312]		Loss: 0.1100
2019-10-28 15:41:33,070 Training Epoch [30/40] Iter[65/312]		Loss: 0.1099
2019-10-28 15:41:33,150 Training Epoch [30/40] Iter[66/312]		Loss: 0.1096
2019-10-28 15:41:33,230 Training Epoch [30/40] Iter[67/312]		Loss: 0.1089
2019-10-28 15:41:33,310 Training Epoch [30/40] Iter[68/312]		Loss: 0.1087
2019-10-28 15:41:33,390 Training Epoch [30/40] Iter[69/312]		Loss: 0.1083
2019-10-28 15:41:33,470 Training Epoch [30/40] Iter[70/312]		Loss: 0.1078
2019-10-28 15:41:33,550 Training Epoch [30/40] Iter[71/312]		Loss: 0.1073
2019-10-28 15:41:33,630 Training Epoch [30/40] Iter[72/312]		Loss: 0.1072
2019-10-28 15:41:33,710 Training Epoch [30/40] Iter[73/312]		Loss: 0.1077
2019-10-28 15:41:33,790 Training Epoch [30/40] Iter[74/312]		Loss: 0.1083
2019-10-28 15:41:33,870 Training Epoch [30/40] Iter[75/312]		Loss: 0.1082
2019-10-28 15:41:33,950 Training Epoch [30/40] Iter[76/312]		Loss: 0.1079
2019-10-28 15:41:34,030 Training Epoch [30/40] Iter[77/312]		Loss: 0.1075
2019-10-28 15:41:34,110 Training Epoch [30/40] Iter[78/312]		Loss: 0.1077
2019-10-28 15:41:34,190 Training Epoch [30/40] Iter[79/312]		Loss: 0.1077
2019-10-28 15:41:34,270 Training Epoch [30/40] Iter[80/312]		Loss: 0.1076
2019-10-28 15:41:34,350 Training Epoch [30/40] Iter[81/312]		Loss: 0.1082
2019-10-28 15:41:34,430 Training Epoch [30/40] Iter[82/312]		Loss: 0.1082
2019-10-28 15:41:34,510 Training Epoch [30/40] Iter[83/312]		Loss: 0.1080
2019-10-28 15:41:34,590 Training Epoch [30/40] Iter[84/312]		Loss: 0.1079
2019-10-28 15:41:34,670 Training Epoch [30/40] Iter[85/312]		Loss: 0.1079
2019-10-28 15:41:34,750 Training Epoch [30/40] Iter[86/312]		Loss: 0.1076
2019-10-28 15:41:34,830 Training Epoch [30/40] Iter[87/312]		Loss: 0.1082
2019-10-28 15:41:34,910 Training Epoch [30/40] Iter[88/312]		Loss: 0.1084
2019-10-28 15:41:34,990 Training Epoch [30/40] Iter[89/312]		Loss: 0.1083
2019-10-28 15:41:35,070 Training Epoch [30/40] Iter[90/312]		Loss: 0.1086
2019-10-28 15:41:35,150 Training Epoch [30/40] Iter[91/312]		Loss: 0.1092
2019-10-28 15:41:35,230 Training Epoch [30/40] Iter[92/312]		Loss: 0.1090
2019-10-28 15:41:35,310 Training Epoch [30/40] Iter[93/312]		Loss: 0.1087
2019-10-28 15:41:35,390 Training Epoch [30/40] Iter[94/312]		Loss: 0.1087
2019-10-28 15:41:35,471 Training Epoch [30/40] Iter[95/312]		Loss: 0.1094
2019-10-28 15:41:35,551 Training Epoch [30/40] Iter[96/312]		Loss: 0.1090
2019-10-28 15:41:35,631 Training Epoch [30/40] Iter[97/312]		Loss: 0.1091
2019-10-28 15:41:35,710 Training Epoch [30/40] Iter[98/312]		Loss: 0.1092
2019-10-28 15:41:35,790 Training Epoch [30/40] Iter[99/312]		Loss: 0.1091
2019-10-28 15:41:35,870 Training Epoch [30/40] Iter[100/312]		Loss: 0.1096
2019-10-28 15:41:35,950 Training Epoch [30/40] Iter[101/312]		Loss: 0.1091
2019-10-28 15:41:36,030 Training Epoch [30/40] Iter[102/312]		Loss: 0.1087
2019-10-28 15:41:36,111 Training Epoch [30/40] Iter[103/312]		Loss: 0.1089
2019-10-28 15:41:36,191 Training Epoch [30/40] Iter[104/312]		Loss: 0.1086
2019-10-28 15:41:36,271 Training Epoch [30/40] Iter[105/312]		Loss: 0.1094
2019-10-28 15:41:36,351 Training Epoch [30/40] Iter[106/312]		Loss: 0.1098
2019-10-28 15:41:36,431 Training Epoch [30/40] Iter[107/312]		Loss: 0.1096
2019-10-28 15:41:36,510 Training Epoch [30/40] Iter[108/312]		Loss: 0.1098
2019-10-28 15:41:36,590 Training Epoch [30/40] Iter[109/312]		Loss: 0.1099
2019-10-28 15:41:36,670 Training Epoch [30/40] Iter[110/312]		Loss: 0.1098
2019-10-28 15:41:36,750 Training Epoch [30/40] Iter[111/312]		Loss: 0.1097
2019-10-28 15:41:36,829 Training Epoch [30/40] Iter[112/312]		Loss: 0.1101
2019-10-28 15:41:36,909 Training Epoch [30/40] Iter[113/312]		Loss: 0.1105
2019-10-28 15:41:36,989 Training Epoch [30/40] Iter[114/312]		Loss: 0.1101
2019-10-28 15:41:37,069 Training Epoch [30/40] Iter[115/312]		Loss: 0.1101
2019-10-28 15:41:37,149 Training Epoch [30/40] Iter[116/312]		Loss: 0.1099
2019-10-28 15:41:37,229 Training Epoch [30/40] Iter[117/312]		Loss: 0.1106
2019-10-28 15:41:37,309 Training Epoch [30/40] Iter[118/312]		Loss: 0.1105
2019-10-28 15:41:37,389 Training Epoch [30/40] Iter[119/312]		Loss: 0.1105
2019-10-28 15:41:37,469 Training Epoch [30/40] Iter[120/312]		Loss: 0.1109
2019-10-28 15:41:37,549 Training Epoch [30/40] Iter[121/312]		Loss: 0.1110
2019-10-28 15:41:37,629 Training Epoch [30/40] Iter[122/312]		Loss: 0.1116
2019-10-28 15:41:37,709 Training Epoch [30/40] Iter[123/312]		Loss: 0.1117
2019-10-28 15:41:37,789 Training Epoch [30/40] Iter[124/312]		Loss: 0.1117
2019-10-28 15:41:37,869 Training Epoch [30/40] Iter[125/312]		Loss: 0.1117
2019-10-28 15:41:37,949 Training Epoch [30/40] Iter[126/312]		Loss: 0.1114
2019-10-28 15:41:38,029 Training Epoch [30/40] Iter[127/312]		Loss: 0.1113
2019-10-28 15:41:38,108 Training Epoch [30/40] Iter[128/312]		Loss: 0.1114
2019-10-28 15:41:38,188 Training Epoch [30/40] Iter[129/312]		Loss: 0.1114
2019-10-28 15:41:38,268 Training Epoch [30/40] Iter[130/312]		Loss: 0.1113
2019-10-28 15:41:38,347 Training Epoch [30/40] Iter[131/312]		Loss: 0.1111
2019-10-28 15:41:38,426 Training Epoch [30/40] Iter[132/312]		Loss: 0.1108
2019-10-28 15:41:38,505 Training Epoch [30/40] Iter[133/312]		Loss: 0.1108
2019-10-28 15:41:38,585 Training Epoch [30/40] Iter[134/312]		Loss: 0.1117
2019-10-28 15:41:38,664 Training Epoch [30/40] Iter[135/312]		Loss: 0.1114
2019-10-28 15:41:38,744 Training Epoch [30/40] Iter[136/312]		Loss: 0.1117
2019-10-28 15:41:38,823 Training Epoch [30/40] Iter[137/312]		Loss: 0.1117
2019-10-28 15:41:38,903 Training Epoch [30/40] Iter[138/312]		Loss: 0.1115
2019-10-28 15:41:38,982 Training Epoch [30/40] Iter[139/312]		Loss: 0.1114
2019-10-28 15:41:39,062 Training Epoch [30/40] Iter[140/312]		Loss: 0.1116
2019-10-28 15:41:39,142 Training Epoch [30/40] Iter[141/312]		Loss: 0.1121
2019-10-28 15:41:39,221 Training Epoch [30/40] Iter[142/312]		Loss: 0.1121
2019-10-28 15:41:39,301 Training Epoch [30/40] Iter[143/312]		Loss: 0.1125
2019-10-28 15:41:39,380 Training Epoch [30/40] Iter[144/312]		Loss: 0.1128
2019-10-28 15:41:39,460 Training Epoch [30/40] Iter[145/312]		Loss: 0.1128
2019-10-28 15:41:39,539 Training Epoch [30/40] Iter[146/312]		Loss: 0.1128
2019-10-28 15:41:39,619 Training Epoch [30/40] Iter[147/312]		Loss: 0.1126
2019-10-28 15:41:39,698 Training Epoch [30/40] Iter[148/312]		Loss: 0.1124
2019-10-28 15:41:39,778 Training Epoch [30/40] Iter[149/312]		Loss: 0.1126
2019-10-28 15:41:39,858 Training Epoch [30/40] Iter[150/312]		Loss: 0.1129
2019-10-28 15:41:39,937 Training Epoch [30/40] Iter[151/312]		Loss: 0.1129
2019-10-28 15:41:40,017 Training Epoch [30/40] Iter[152/312]		Loss: 0.1131
2019-10-28 15:41:40,097 Training Epoch [30/40] Iter[153/312]		Loss: 0.1130
2019-10-28 15:41:40,177 Training Epoch [30/40] Iter[154/312]		Loss: 0.1129
2019-10-28 15:41:40,256 Training Epoch [30/40] Iter[155/312]		Loss: 0.1127
2019-10-28 15:41:40,336 Training Epoch [30/40] Iter[156/312]		Loss: 0.1137
2019-10-28 15:41:40,415 Training Epoch [30/40] Iter[157/312]		Loss: 0.1137
2019-10-28 15:41:40,495 Training Epoch [30/40] Iter[158/312]		Loss: 0.1135
2019-10-28 15:41:40,575 Training Epoch [30/40] Iter[159/312]		Loss: 0.1132
2019-10-28 15:41:40,654 Training Epoch [30/40] Iter[160/312]		Loss: 0.1129
2019-10-28 15:41:40,733 Training Epoch [30/40] Iter[161/312]		Loss: 0.1131
2019-10-28 15:41:40,813 Training Epoch [30/40] Iter[162/312]		Loss: 0.1130
2019-10-28 15:41:40,892 Training Epoch [30/40] Iter[163/312]		Loss: 0.1127
2019-10-28 15:41:40,972 Training Epoch [30/40] Iter[164/312]		Loss: 0.1128
2019-10-28 15:41:41,051 Training Epoch [30/40] Iter[165/312]		Loss: 0.1132
2019-10-28 15:41:41,131 Training Epoch [30/40] Iter[166/312]		Loss: 0.1131
2019-10-28 15:41:41,210 Training Epoch [30/40] Iter[167/312]		Loss: 0.1129
2019-10-28 15:41:41,290 Training Epoch [30/40] Iter[168/312]		Loss: 0.1135
2019-10-28 15:41:41,370 Training Epoch [30/40] Iter[169/312]		Loss: 0.1134
2019-10-28 15:41:41,449 Training Epoch [30/40] Iter[170/312]		Loss: 0.1133
2019-10-28 15:41:41,529 Training Epoch [30/40] Iter[171/312]		Loss: 0.1133
2019-10-28 15:41:41,609 Training Epoch [30/40] Iter[172/312]		Loss: 0.1132
2019-10-28 15:41:41,688 Training Epoch [30/40] Iter[173/312]		Loss: 0.1135
2019-10-28 15:41:41,768 Training Epoch [30/40] Iter[174/312]		Loss: 0.1133
2019-10-28 15:41:41,847 Training Epoch [30/40] Iter[175/312]		Loss: 0.1131
2019-10-28 15:41:41,931 Training Epoch [30/40] Iter[176/312]		Loss: 0.1129
2019-10-28 15:41:42,010 Training Epoch [30/40] Iter[177/312]		Loss: 0.1126
2019-10-28 15:41:42,090 Training Epoch [30/40] Iter[178/312]		Loss: 0.1128
2019-10-28 15:41:42,169 Training Epoch [30/40] Iter[179/312]		Loss: 0.1126
2019-10-28 15:41:42,249 Training Epoch [30/40] Iter[180/312]		Loss: 0.1131
2019-10-28 15:41:42,329 Training Epoch [30/40] Iter[181/312]		Loss: 0.1131
2019-10-28 15:41:42,408 Training Epoch [30/40] Iter[182/312]		Loss: 0.1132
2019-10-28 15:41:42,488 Training Epoch [30/40] Iter[183/312]		Loss: 0.1129
2019-10-28 15:41:42,567 Training Epoch [30/40] Iter[184/312]		Loss: 0.1129
2019-10-28 15:41:42,647 Training Epoch [30/40] Iter[185/312]		Loss: 0.1129
2019-10-28 15:41:42,727 Training Epoch [30/40] Iter[186/312]		Loss: 0.1127
2019-10-28 15:41:42,806 Training Epoch [30/40] Iter[187/312]		Loss: 0.1128
2019-10-28 15:41:42,886 Training Epoch [30/40] Iter[188/312]		Loss: 0.1129
2019-10-28 15:41:42,966 Training Epoch [30/40] Iter[189/312]		Loss: 0.1128
2019-10-28 15:41:43,045 Training Epoch [30/40] Iter[190/312]		Loss: 0.1128
2019-10-28 15:41:43,125 Training Epoch [30/40] Iter[191/312]		Loss: 0.1129
2019-10-28 15:41:43,205 Training Epoch [30/40] Iter[192/312]		Loss: 0.1131
2019-10-28 15:41:43,285 Training Epoch [30/40] Iter[193/312]		Loss: 0.1135
2019-10-28 15:41:43,364 Training Epoch [30/40] Iter[194/312]		Loss: 0.1134
2019-10-28 15:41:43,444 Training Epoch [30/40] Iter[195/312]		Loss: 0.1135
2019-10-28 15:41:43,524 Training Epoch [30/40] Iter[196/312]		Loss: 0.1135
2019-10-28 15:41:43,604 Training Epoch [30/40] Iter[197/312]		Loss: 0.1132
2019-10-28 15:41:43,683 Training Epoch [30/40] Iter[198/312]		Loss: 0.1131
2019-10-28 15:41:43,762 Training Epoch [30/40] Iter[199/312]		Loss: 0.1129
2019-10-28 15:41:43,842 Training Epoch [30/40] Iter[200/312]		Loss: 0.1129
2019-10-28 15:41:43,922 Training Epoch [30/40] Iter[201/312]		Loss: 0.1128
2019-10-28 15:41:44,001 Training Epoch [30/40] Iter[202/312]		Loss: 0.1127
2019-10-28 15:41:44,081 Training Epoch [30/40] Iter[203/312]		Loss: 0.1125
2019-10-28 15:41:44,161 Training Epoch [30/40] Iter[204/312]		Loss: 0.1124
2019-10-28 15:41:44,241 Training Epoch [30/40] Iter[205/312]		Loss: 0.1125
2019-10-28 15:41:44,321 Training Epoch [30/40] Iter[206/312]		Loss: 0.1123
2019-10-28 15:41:44,400 Training Epoch [30/40] Iter[207/312]		Loss: 0.1123
2019-10-28 15:41:44,480 Training Epoch [30/40] Iter[208/312]		Loss: 0.1123
2019-10-28 15:41:44,559 Training Epoch [30/40] Iter[209/312]		Loss: 0.1122
2019-10-28 15:41:44,639 Training Epoch [30/40] Iter[210/312]		Loss: 0.1123
2019-10-28 15:41:44,718 Training Epoch [30/40] Iter[211/312]		Loss: 0.1126
2019-10-28 15:41:44,798 Training Epoch [30/40] Iter[212/312]		Loss: 0.1126
2019-10-28 15:41:44,877 Training Epoch [30/40] Iter[213/312]		Loss: 0.1124
2019-10-28 15:41:44,957 Training Epoch [30/40] Iter[214/312]		Loss: 0.1126
2019-10-28 15:41:45,036 Training Epoch [30/40] Iter[215/312]		Loss: 0.1126
2019-10-28 15:41:45,116 Training Epoch [30/40] Iter[216/312]		Loss: 0.1125
2019-10-28 15:41:45,196 Training Epoch [30/40] Iter[217/312]		Loss: 0.1124
2019-10-28 15:41:45,275 Training Epoch [30/40] Iter[218/312]		Loss: 0.1121
2019-10-28 15:41:45,355 Training Epoch [30/40] Iter[219/312]		Loss: 0.1123
2019-10-28 15:41:45,434 Training Epoch [30/40] Iter[220/312]		Loss: 0.1121
2019-10-28 15:41:45,514 Training Epoch [30/40] Iter[221/312]		Loss: 0.1120
2019-10-28 15:41:45,594 Training Epoch [30/40] Iter[222/312]		Loss: 0.1126
2019-10-28 15:41:45,673 Training Epoch [30/40] Iter[223/312]		Loss: 0.1125
2019-10-28 15:41:45,753 Training Epoch [30/40] Iter[224/312]		Loss: 0.1124
2019-10-28 15:41:45,832 Training Epoch [30/40] Iter[225/312]		Loss: 0.1123
2019-10-28 15:41:45,912 Training Epoch [30/40] Iter[226/312]		Loss: 0.1122
2019-10-28 15:41:45,991 Training Epoch [30/40] Iter[227/312]		Loss: 0.1121
2019-10-28 15:41:46,070 Training Epoch [30/40] Iter[228/312]		Loss: 0.1126
2019-10-28 15:41:46,150 Training Epoch [30/40] Iter[229/312]		Loss: 0.1125
2019-10-28 15:41:46,230 Training Epoch [30/40] Iter[230/312]		Loss: 0.1126
2019-10-28 15:41:46,309 Training Epoch [30/40] Iter[231/312]		Loss: 0.1125
2019-10-28 15:41:46,389 Training Epoch [30/40] Iter[232/312]		Loss: 0.1124
2019-10-28 15:41:46,469 Training Epoch [30/40] Iter[233/312]		Loss: 0.1122
2019-10-28 15:41:46,549 Training Epoch [30/40] Iter[234/312]		Loss: 0.1121
2019-10-28 15:41:46,628 Training Epoch [30/40] Iter[235/312]		Loss: 0.1122
2019-10-28 15:41:46,708 Training Epoch [30/40] Iter[236/312]		Loss: 0.1124
2019-10-28 15:41:46,787 Training Epoch [30/40] Iter[237/312]		Loss: 0.1123
2019-10-28 15:41:46,867 Training Epoch [30/40] Iter[238/312]		Loss: 0.1125
2019-10-28 15:41:46,946 Training Epoch [30/40] Iter[239/312]		Loss: 0.1124
2019-10-28 15:41:47,026 Training Epoch [30/40] Iter[240/312]		Loss: 0.1123
2019-10-28 15:41:47,105 Training Epoch [30/40] Iter[241/312]		Loss: 0.1122
2019-10-28 15:41:47,185 Training Epoch [30/40] Iter[242/312]		Loss: 0.1122
2019-10-28 15:41:47,264 Training Epoch [30/40] Iter[243/312]		Loss: 0.1124
2019-10-28 15:41:47,344 Training Epoch [30/40] Iter[244/312]		Loss: 0.1123
2019-10-28 15:41:47,423 Training Epoch [30/40] Iter[245/312]		Loss: 0.1130
2019-10-28 15:41:47,503 Training Epoch [30/40] Iter[246/312]		Loss: 0.1130
2019-10-28 15:41:47,583 Training Epoch [30/40] Iter[247/312]		Loss: 0.1132
2019-10-28 15:41:47,662 Training Epoch [30/40] Iter[248/312]		Loss: 0.1130
2019-10-28 15:41:47,741 Training Epoch [30/40] Iter[249/312]		Loss: 0.1129
2019-10-28 15:41:47,820 Training Epoch [30/40] Iter[250/312]		Loss: 0.1129
2019-10-28 15:41:47,900 Training Epoch [30/40] Iter[251/312]		Loss: 0.1128
2019-10-28 15:41:47,979 Training Epoch [30/40] Iter[252/312]		Loss: 0.1128
2019-10-28 15:41:48,059 Training Epoch [30/40] Iter[253/312]		Loss: 0.1127
2019-10-28 15:41:48,139 Training Epoch [30/40] Iter[254/312]		Loss: 0.1127
2019-10-28 15:41:48,218 Training Epoch [30/40] Iter[255/312]		Loss: 0.1127
2019-10-28 15:41:48,298 Training Epoch [30/40] Iter[256/312]		Loss: 0.1128
2019-10-28 15:41:48,377 Training Epoch [30/40] Iter[257/312]		Loss: 0.1127
2019-10-28 15:41:48,457 Training Epoch [30/40] Iter[258/312]		Loss: 0.1126
2019-10-28 15:41:48,537 Training Epoch [30/40] Iter[259/312]		Loss: 0.1124
2019-10-28 15:41:48,616 Training Epoch [30/40] Iter[260/312]		Loss: 0.1124
2019-10-28 15:41:48,695 Training Epoch [30/40] Iter[261/312]		Loss: 0.1126
2019-10-28 15:41:48,775 Training Epoch [30/40] Iter[262/312]		Loss: 0.1124
2019-10-28 15:41:48,854 Training Epoch [30/40] Iter[263/312]		Loss: 0.1126
2019-10-28 15:41:48,933 Training Epoch [30/40] Iter[264/312]		Loss: 0.1128
2019-10-28 15:41:49,012 Training Epoch [30/40] Iter[265/312]		Loss: 0.1128
2019-10-28 15:41:49,092 Training Epoch [30/40] Iter[266/312]		Loss: 0.1128
2019-10-28 15:41:49,171 Training Epoch [30/40] Iter[267/312]		Loss: 0.1126
2019-10-28 15:41:49,251 Training Epoch [30/40] Iter[268/312]		Loss: 0.1130
2019-10-28 15:41:49,330 Training Epoch [30/40] Iter[269/312]		Loss: 0.1129
2019-10-28 15:41:49,410 Training Epoch [30/40] Iter[270/312]		Loss: 0.1129
2019-10-28 15:41:49,490 Training Epoch [30/40] Iter[271/312]		Loss: 0.1127
2019-10-28 15:41:49,569 Training Epoch [30/40] Iter[272/312]		Loss: 0.1127
2019-10-28 15:41:49,648 Training Epoch [30/40] Iter[273/312]		Loss: 0.1129
2019-10-28 15:41:49,727 Training Epoch [30/40] Iter[274/312]		Loss: 0.1131
2019-10-28 15:41:49,812 Training Epoch [30/40] Iter[275/312]		Loss: 0.1131
2019-10-28 15:41:49,891 Training Epoch [30/40] Iter[276/312]		Loss: 0.1131
2019-10-28 15:41:49,970 Training Epoch [30/40] Iter[277/312]		Loss: 0.1130
2019-10-28 15:41:50,049 Training Epoch [30/40] Iter[278/312]		Loss: 0.1129
2019-10-28 15:41:50,135 Training Epoch [30/40] Iter[279/312]		Loss: 0.1128
2019-10-28 15:41:50,214 Training Epoch [30/40] Iter[280/312]		Loss: 0.1128
2019-10-28 15:41:50,294 Training Epoch [30/40] Iter[281/312]		Loss: 0.1132
2019-10-28 15:41:50,374 Training Epoch [30/40] Iter[282/312]		Loss: 0.1131
2019-10-28 15:41:50,453 Training Epoch [30/40] Iter[283/312]		Loss: 0.1130
2019-10-28 15:41:50,533 Training Epoch [30/40] Iter[284/312]		Loss: 0.1129
2019-10-28 15:41:50,612 Training Epoch [30/40] Iter[285/312]		Loss: 0.1129
2019-10-28 15:41:50,692 Training Epoch [30/40] Iter[286/312]		Loss: 0.1128
2019-10-28 15:41:50,772 Training Epoch [30/40] Iter[287/312]		Loss: 0.1128
2019-10-28 15:41:50,851 Training Epoch [30/40] Iter[288/312]		Loss: 0.1130
2019-10-28 15:41:50,931 Training Epoch [30/40] Iter[289/312]		Loss: 0.1131
2019-10-28 15:41:51,010 Training Epoch [30/40] Iter[290/312]		Loss: 0.1130
2019-10-28 15:41:51,090 Training Epoch [30/40] Iter[291/312]		Loss: 0.1129
2019-10-28 15:41:51,169 Training Epoch [30/40] Iter[292/312]		Loss: 0.1130
2019-10-28 15:41:51,249 Training Epoch [30/40] Iter[293/312]		Loss: 0.1129
2019-10-28 15:41:51,328 Training Epoch [30/40] Iter[294/312]		Loss: 0.1128
2019-10-28 15:41:51,408 Training Epoch [30/40] Iter[295/312]		Loss: 0.1129
2019-10-28 15:41:51,488 Training Epoch [30/40] Iter[296/312]		Loss: 0.1128
2019-10-28 15:41:51,567 Training Epoch [30/40] Iter[297/312]		Loss: 0.1128
2019-10-28 15:41:51,647 Training Epoch [30/40] Iter[298/312]		Loss: 0.1126
2019-10-28 15:41:51,726 Training Epoch [30/40] Iter[299/312]		Loss: 0.1127
2019-10-28 15:41:51,806 Training Epoch [30/40] Iter[300/312]		Loss: 0.1126
2019-10-28 15:41:51,885 Training Epoch [30/40] Iter[301/312]		Loss: 0.1125
2019-10-28 15:41:51,965 Training Epoch [30/40] Iter[302/312]		Loss: 0.1125
2019-10-28 15:41:52,044 Training Epoch [30/40] Iter[303/312]		Loss: 0.1125
2019-10-28 15:41:52,123 Training Epoch [30/40] Iter[304/312]		Loss: 0.1124
2019-10-28 15:41:52,202 Training Epoch [30/40] Iter[305/312]		Loss: 0.1123
2019-10-28 15:41:52,280 Training Epoch [30/40] Iter[306/312]		Loss: 0.1123
2019-10-28 15:41:52,359 Training Epoch [30/40] Iter[307/312]		Loss: 0.1122
2019-10-28 15:41:52,437 Training Epoch [30/40] Iter[308/312]		Loss: 0.1122
2019-10-28 15:41:52,516 Training Epoch [30/40] Iter[309/312]		Loss: 0.1122
2019-10-28 15:41:52,595 Training Epoch [30/40] Iter[310/312]		Loss: 0.1122
2019-10-28 15:41:52,674 Training Epoch [30/40] Iter[311/312]		Loss: 0.1122
2019-10-28 15:41:52,713 Training Epoch [30/40] Iter[312/312]		Loss: 0.1122
2019-10-28 15:41:53,151 Testing Epoch [30/40] Iter[0/62]		Loss: 0.1299
2019-10-28 15:41:53,181 Testing Epoch [30/40] Iter[1/62]		Loss: 0.1275
2019-10-28 15:41:53,211 Testing Epoch [30/40] Iter[2/62]		Loss: 0.1119
2019-10-28 15:41:53,237 Testing Epoch [30/40] Iter[3/62]		Loss: 0.1159
2019-10-28 15:41:53,255 Testing Epoch [30/40] Iter[4/62]		Loss: 0.1227
2019-10-28 15:41:53,282 Testing Epoch [30/40] Iter[5/62]		Loss: 0.1180
2019-10-28 15:41:53,300 Testing Epoch [30/40] Iter[6/62]		Loss: 0.1202
2019-10-28 15:41:53,326 Testing Epoch [30/40] Iter[7/62]		Loss: 0.1218
2019-10-28 15:41:53,344 Testing Epoch [30/40] Iter[8/62]		Loss: 0.1239
2019-10-28 15:41:53,373 Testing Epoch [30/40] Iter[9/62]		Loss: 0.1228
2019-10-28 15:41:53,391 Testing Epoch [30/40] Iter[10/62]		Loss: 0.1239
2019-10-28 15:41:53,418 Testing Epoch [30/40] Iter[11/62]		Loss: 0.1303
2019-10-28 15:41:53,436 Testing Epoch [30/40] Iter[12/62]		Loss: 0.1298
2019-10-28 15:41:53,462 Testing Epoch [30/40] Iter[13/62]		Loss: 0.1322
2019-10-28 15:41:53,480 Testing Epoch [30/40] Iter[14/62]		Loss: 0.1439
2019-10-28 15:41:53,509 Testing Epoch [30/40] Iter[15/62]		Loss: 0.1456
2019-10-28 15:41:53,527 Testing Epoch [30/40] Iter[16/62]		Loss: 0.1424
2019-10-28 15:41:53,554 Testing Epoch [30/40] Iter[17/62]		Loss: 0.1437
2019-10-28 15:41:53,572 Testing Epoch [30/40] Iter[18/62]		Loss: 0.1414
2019-10-28 15:41:53,597 Testing Epoch [30/40] Iter[19/62]		Loss: 0.1396
2019-10-28 15:41:53,615 Testing Epoch [30/40] Iter[20/62]		Loss: 0.1412
2019-10-28 15:41:53,642 Testing Epoch [30/40] Iter[21/62]		Loss: 0.1395
2019-10-28 15:41:53,660 Testing Epoch [30/40] Iter[22/62]		Loss: 0.1406
2019-10-28 15:41:53,686 Testing Epoch [30/40] Iter[23/62]		Loss: 0.1393
2019-10-28 15:41:53,704 Testing Epoch [30/40] Iter[24/62]		Loss: 0.1425
2019-10-28 15:41:53,734 Testing Epoch [30/40] Iter[25/62]		Loss: 0.1417
2019-10-28 15:41:53,752 Testing Epoch [30/40] Iter[26/62]		Loss: 0.1406
2019-10-28 15:41:53,777 Testing Epoch [30/40] Iter[27/62]		Loss: 0.1481
2019-10-28 15:41:53,795 Testing Epoch [30/40] Iter[28/62]		Loss: 0.1518
2019-10-28 15:41:53,822 Testing Epoch [30/40] Iter[29/62]		Loss: 0.1520
2019-10-28 15:41:53,840 Testing Epoch [30/40] Iter[30/62]		Loss: 0.1522
2019-10-28 15:41:53,866 Testing Epoch [30/40] Iter[31/62]		Loss: 0.1513
2019-10-28 15:41:53,884 Testing Epoch [30/40] Iter[32/62]		Loss: 0.1529
2019-10-28 15:41:53,909 Testing Epoch [30/40] Iter[33/62]		Loss: 0.1519
2019-10-28 15:41:53,928 Testing Epoch [30/40] Iter[34/62]		Loss: 0.1542
2019-10-28 15:41:53,954 Testing Epoch [30/40] Iter[35/62]		Loss: 0.1538
2019-10-28 15:41:53,972 Testing Epoch [30/40] Iter[36/62]		Loss: 0.1519
2019-10-28 15:41:53,998 Testing Epoch [30/40] Iter[37/62]		Loss: 0.1508
2019-10-28 15:41:54,017 Testing Epoch [30/40] Iter[38/62]		Loss: 0.1498
2019-10-28 15:41:54,042 Testing Epoch [30/40] Iter[39/62]		Loss: 0.1501
2019-10-28 15:41:54,060 Testing Epoch [30/40] Iter[40/62]		Loss: 0.1518
2019-10-28 15:41:54,085 Testing Epoch [30/40] Iter[41/62]		Loss: 0.1532
2019-10-28 15:41:54,104 Testing Epoch [30/40] Iter[42/62]		Loss: 0.1512
2019-10-28 15:41:54,133 Testing Epoch [30/40] Iter[43/62]		Loss: 0.1505
2019-10-28 15:41:54,151 Testing Epoch [30/40] Iter[44/62]		Loss: 0.1489
2019-10-28 15:41:54,178 Testing Epoch [30/40] Iter[45/62]		Loss: 0.1485
2019-10-28 15:41:54,196 Testing Epoch [30/40] Iter[46/62]		Loss: 0.1482
2019-10-28 15:41:54,221 Testing Epoch [30/40] Iter[47/62]		Loss: 0.1540
2019-10-28 15:41:54,240 Testing Epoch [30/40] Iter[48/62]		Loss: 0.1530
2019-10-28 15:41:54,270 Testing Epoch [30/40] Iter[49/62]		Loss: 0.1550
2019-10-28 15:41:54,288 Testing Epoch [30/40] Iter[50/62]		Loss: 0.1541
2019-10-28 15:41:54,318 Testing Epoch [30/40] Iter[51/62]		Loss: 0.1541
2019-10-28 15:41:54,343 Testing Epoch [30/40] Iter[52/62]		Loss: 0.1528
2019-10-28 15:41:54,362 Testing Epoch [30/40] Iter[53/62]		Loss: 0.1531
2019-10-28 15:41:54,380 Testing Epoch [30/40] Iter[54/62]		Loss: 0.1519
2019-10-28 15:41:54,398 Testing Epoch [30/40] Iter[55/62]		Loss: 0.1516
2019-10-28 15:41:54,415 Testing Epoch [30/40] Iter[56/62]		Loss: 0.1509
2019-10-28 15:41:54,431 Testing Epoch [30/40] Iter[57/62]		Loss: 0.1510
2019-10-28 15:41:54,448 Testing Epoch [30/40] Iter[58/62]		Loss: 0.1505
2019-10-28 15:41:54,465 Testing Epoch [30/40] Iter[59/62]		Loss: 0.1516
2019-10-28 15:41:54,482 Testing Epoch [30/40] Iter[60/62]		Loss: 0.1509
2019-10-28 15:41:54,500 Testing Epoch [30/40] Iter[61/62]		Loss: 0.1507
2019-10-28 15:41:54,509 Testing Epoch [30/40] Iter[62/62]		Loss: 0.1513
2019-10-28 15:41:55,013 Training Epoch [31/40] Iter[0/312]		Loss: 0.0977
2019-10-28 15:41:55,094 Training Epoch [31/40] Iter[1/312]		Loss: 0.0884
2019-10-28 15:41:55,172 Training Epoch [31/40] Iter[2/312]		Loss: 0.1294
2019-10-28 15:41:55,255 Training Epoch [31/40] Iter[3/312]		Loss: 0.1199
2019-10-28 15:41:55,337 Training Epoch [31/40] Iter[4/312]		Loss: 0.1140
2019-10-28 15:41:55,419 Training Epoch [31/40] Iter[5/312]		Loss: 0.1178
2019-10-28 15:41:55,497 Training Epoch [31/40] Iter[6/312]		Loss: 0.1149
2019-10-28 15:41:55,577 Training Epoch [31/40] Iter[7/312]		Loss: 0.1120
2019-10-28 15:41:55,656 Training Epoch [31/40] Iter[8/312]		Loss: 0.1241
2019-10-28 15:41:55,736 Training Epoch [31/40] Iter[9/312]		Loss: 0.1171
2019-10-28 15:41:55,815 Training Epoch [31/40] Iter[10/312]		Loss: 0.1145
2019-10-28 15:41:55,895 Training Epoch [31/40] Iter[11/312]		Loss: 0.1137
2019-10-28 15:41:55,974 Training Epoch [31/40] Iter[12/312]		Loss: 0.1127
2019-10-28 15:41:56,054 Training Epoch [31/40] Iter[13/312]		Loss: 0.1145
2019-10-28 15:41:56,133 Training Epoch [31/40] Iter[14/312]		Loss: 0.1173
2019-10-28 15:41:56,212 Training Epoch [31/40] Iter[15/312]		Loss: 0.1143
2019-10-28 15:41:56,291 Training Epoch [31/40] Iter[16/312]		Loss: 0.1171
2019-10-28 15:41:56,371 Training Epoch [31/40] Iter[17/312]		Loss: 0.1160
2019-10-28 15:41:56,450 Training Epoch [31/40] Iter[18/312]		Loss: 0.1159
2019-10-28 15:41:56,529 Training Epoch [31/40] Iter[19/312]		Loss: 0.1145
2019-10-28 15:41:56,609 Training Epoch [31/40] Iter[20/312]		Loss: 0.1137
2019-10-28 15:41:56,688 Training Epoch [31/40] Iter[21/312]		Loss: 0.1123
2019-10-28 15:41:56,767 Training Epoch [31/40] Iter[22/312]		Loss: 0.1111
2019-10-28 15:41:56,847 Training Epoch [31/40] Iter[23/312]		Loss: 0.1107
2019-10-28 15:41:56,926 Training Epoch [31/40] Iter[24/312]		Loss: 0.1096
2019-10-28 15:41:57,005 Training Epoch [31/40] Iter[25/312]		Loss: 0.1083
2019-10-28 15:41:57,085 Training Epoch [31/40] Iter[26/312]		Loss: 0.1079
2019-10-28 15:41:57,164 Training Epoch [31/40] Iter[27/312]		Loss: 0.1068
2019-10-28 15:41:57,243 Training Epoch [31/40] Iter[28/312]		Loss: 0.1063
2019-10-28 15:41:57,323 Training Epoch [31/40] Iter[29/312]		Loss: 0.1055
2019-10-28 15:41:57,402 Training Epoch [31/40] Iter[30/312]		Loss: 0.1062
2019-10-28 15:41:57,481 Training Epoch [31/40] Iter[31/312]		Loss: 0.1067
2019-10-28 15:41:57,560 Training Epoch [31/40] Iter[32/312]		Loss: 0.1068
2019-10-28 15:41:57,640 Training Epoch [31/40] Iter[33/312]		Loss: 0.1065
2019-10-28 15:41:57,719 Training Epoch [31/40] Iter[34/312]		Loss: 0.1058
2019-10-28 15:41:57,798 Training Epoch [31/40] Iter[35/312]		Loss: 0.1051
2019-10-28 15:41:57,878 Training Epoch [31/40] Iter[36/312]		Loss: 0.1041
2019-10-28 15:41:57,957 Training Epoch [31/40] Iter[37/312]		Loss: 0.1034
2019-10-28 15:41:58,036 Training Epoch [31/40] Iter[38/312]		Loss: 0.1025
2019-10-28 15:41:58,115 Training Epoch [31/40] Iter[39/312]		Loss: 0.1020
2019-10-28 15:41:58,200 Training Epoch [31/40] Iter[40/312]		Loss: 0.1014
2019-10-28 15:41:58,279 Training Epoch [31/40] Iter[41/312]		Loss: 0.1011
2019-10-28 15:41:58,359 Training Epoch [31/40] Iter[42/312]		Loss: 0.1013
2019-10-28 15:41:58,438 Training Epoch [31/40] Iter[43/312]		Loss: 0.1012
2019-10-28 15:41:58,517 Training Epoch [31/40] Iter[44/312]		Loss: 0.1003
2019-10-28 15:41:58,597 Training Epoch [31/40] Iter[45/312]		Loss: 0.1006
2019-10-28 15:41:58,676 Training Epoch [31/40] Iter[46/312]		Loss: 0.1009
2019-10-28 15:41:58,755 Training Epoch [31/40] Iter[47/312]		Loss: 0.1013
2019-10-28 15:41:58,834 Training Epoch [31/40] Iter[48/312]		Loss: 0.1017
2019-10-28 15:41:58,913 Training Epoch [31/40] Iter[49/312]		Loss: 0.1014
2019-10-28 15:41:58,993 Training Epoch [31/40] Iter[50/312]		Loss: 0.1025
2019-10-28 15:41:59,072 Training Epoch [31/40] Iter[51/312]		Loss: 0.1022
2019-10-28 15:41:59,152 Training Epoch [31/40] Iter[52/312]		Loss: 0.1017
2019-10-28 15:41:59,231 Training Epoch [31/40] Iter[53/312]		Loss: 0.1021
2019-10-28 15:41:59,310 Training Epoch [31/40] Iter[54/312]		Loss: 0.1058
2019-10-28 15:41:59,389 Training Epoch [31/40] Iter[55/312]		Loss: 0.1060
2019-10-28 15:41:59,468 Training Epoch [31/40] Iter[56/312]		Loss: 0.1063
2019-10-28 15:41:59,547 Training Epoch [31/40] Iter[57/312]		Loss: 0.1062
2019-10-28 15:41:59,626 Training Epoch [31/40] Iter[58/312]		Loss: 0.1060
2019-10-28 15:41:59,705 Training Epoch [31/40] Iter[59/312]		Loss: 0.1061
2019-10-28 15:41:59,784 Training Epoch [31/40] Iter[60/312]		Loss: 0.1057
2019-10-28 15:41:59,863 Training Epoch [31/40] Iter[61/312]		Loss: 0.1066
2019-10-28 15:41:59,942 Training Epoch [31/40] Iter[62/312]		Loss: 0.1077
2019-10-28 15:42:00,021 Training Epoch [31/40] Iter[63/312]		Loss: 0.1079
2019-10-28 15:42:00,100 Training Epoch [31/40] Iter[64/312]		Loss: 0.1084
2019-10-28 15:42:00,180 Training Epoch [31/40] Iter[65/312]		Loss: 0.1100
2019-10-28 15:42:00,259 Training Epoch [31/40] Iter[66/312]		Loss: 0.1095
2019-10-28 15:42:00,339 Training Epoch [31/40] Iter[67/312]		Loss: 0.1090
2019-10-28 15:42:00,418 Training Epoch [31/40] Iter[68/312]		Loss: 0.1086
2019-10-28 15:42:00,506 Training Epoch [31/40] Iter[69/312]		Loss: 0.1082
2019-10-28 15:42:00,586 Training Epoch [31/40] Iter[70/312]		Loss: 0.1081
2019-10-28 15:42:00,667 Training Epoch [31/40] Iter[71/312]		Loss: 0.1081
2019-10-28 15:42:00,746 Training Epoch [31/40] Iter[72/312]		Loss: 0.1081
2019-10-28 15:42:00,827 Training Epoch [31/40] Iter[73/312]		Loss: 0.1080
2019-10-28 15:42:00,906 Training Epoch [31/40] Iter[74/312]		Loss: 0.1076
2019-10-28 15:42:00,987 Training Epoch [31/40] Iter[75/312]		Loss: 0.1082
2019-10-28 15:42:01,066 Training Epoch [31/40] Iter[76/312]		Loss: 0.1080
2019-10-28 15:42:01,145 Training Epoch [31/40] Iter[77/312]		Loss: 0.1088
2019-10-28 15:42:01,225 Training Epoch [31/40] Iter[78/312]		Loss: 0.1090
2019-10-28 15:42:01,304 Training Epoch [31/40] Iter[79/312]		Loss: 0.1096
2019-10-28 15:42:01,387 Training Epoch [31/40] Iter[80/312]		Loss: 0.1098
2019-10-28 15:42:01,467 Training Epoch [31/40] Iter[81/312]		Loss: 0.1095
2019-10-28 15:42:01,546 Training Epoch [31/40] Iter[82/312]		Loss: 0.1101
2019-10-28 15:42:01,627 Training Epoch [31/40] Iter[83/312]		Loss: 0.1097
2019-10-28 15:42:01,711 Training Epoch [31/40] Iter[84/312]		Loss: 0.1093
2019-10-28 15:42:01,791 Training Epoch [31/40] Iter[85/312]		Loss: 0.1093
2019-10-28 15:42:01,870 Training Epoch [31/40] Iter[86/312]		Loss: 0.1095
2019-10-28 15:42:01,951 Training Epoch [31/40] Iter[87/312]		Loss: 0.1101
2019-10-28 15:42:02,031 Training Epoch [31/40] Iter[88/312]		Loss: 0.1101
2019-10-28 15:42:02,110 Training Epoch [31/40] Iter[89/312]		Loss: 0.1100
2019-10-28 15:42:02,190 Training Epoch [31/40] Iter[90/312]		Loss: 0.1097
2019-10-28 15:42:02,271 Training Epoch [31/40] Iter[91/312]		Loss: 0.1099
2019-10-28 15:42:02,351 Training Epoch [31/40] Iter[92/312]		Loss: 0.1100
2019-10-28 15:42:02,430 Training Epoch [31/40] Iter[93/312]		Loss: 0.1098
2019-10-28 15:42:02,511 Training Epoch [31/40] Iter[94/312]		Loss: 0.1102
2019-10-28 15:42:02,591 Training Epoch [31/40] Iter[95/312]		Loss: 0.1123
2019-10-28 15:42:02,671 Training Epoch [31/40] Iter[96/312]		Loss: 0.1118
2019-10-28 15:42:02,750 Training Epoch [31/40] Iter[97/312]		Loss: 0.1119
2019-10-28 15:42:02,830 Training Epoch [31/40] Iter[98/312]		Loss: 0.1119
2019-10-28 15:42:02,909 Training Epoch [31/40] Iter[99/312]		Loss: 0.1120
2019-10-28 15:42:02,988 Training Epoch [31/40] Iter[100/312]		Loss: 0.1121
2019-10-28 15:42:03,067 Training Epoch [31/40] Iter[101/312]		Loss: 0.1122
2019-10-28 15:42:03,147 Training Epoch [31/40] Iter[102/312]		Loss: 0.1121
2019-10-28 15:42:03,226 Training Epoch [31/40] Iter[103/312]		Loss: 0.1122
2019-10-28 15:42:03,306 Training Epoch [31/40] Iter[104/312]		Loss: 0.1122
2019-10-28 15:42:03,385 Training Epoch [31/40] Iter[105/312]		Loss: 0.1120
2019-10-28 15:42:03,465 Training Epoch [31/40] Iter[106/312]		Loss: 0.1120
2019-10-28 15:42:03,545 Training Epoch [31/40] Iter[107/312]		Loss: 0.1123
2019-10-28 15:42:03,624 Training Epoch [31/40] Iter[108/312]		Loss: 0.1124
2019-10-28 15:42:03,703 Training Epoch [31/40] Iter[109/312]		Loss: 0.1124
2019-10-28 15:42:03,787 Training Epoch [31/40] Iter[110/312]		Loss: 0.1133
2019-10-28 15:42:03,866 Training Epoch [31/40] Iter[111/312]		Loss: 0.1130
2019-10-28 15:42:03,947 Training Epoch [31/40] Iter[112/312]		Loss: 0.1128
2019-10-28 15:42:04,026 Training Epoch [31/40] Iter[113/312]		Loss: 0.1128
2019-10-28 15:42:04,106 Training Epoch [31/40] Iter[114/312]		Loss: 0.1127
2019-10-28 15:42:04,185 Training Epoch [31/40] Iter[115/312]		Loss: 0.1130
2019-10-28 15:42:04,264 Training Epoch [31/40] Iter[116/312]		Loss: 0.1128
2019-10-28 15:42:04,344 Training Epoch [31/40] Iter[117/312]		Loss: 0.1131
2019-10-28 15:42:04,423 Training Epoch [31/40] Iter[118/312]		Loss: 0.1128
2019-10-28 15:42:04,503 Training Epoch [31/40] Iter[119/312]		Loss: 0.1129
2019-10-28 15:42:04,582 Training Epoch [31/40] Iter[120/312]		Loss: 0.1128
2019-10-28 15:42:04,661 Training Epoch [31/40] Iter[121/312]		Loss: 0.1127
2019-10-28 15:42:04,741 Training Epoch [31/40] Iter[122/312]		Loss: 0.1126
2019-10-28 15:42:04,820 Training Epoch [31/40] Iter[123/312]		Loss: 0.1127
2019-10-28 15:42:04,899 Training Epoch [31/40] Iter[124/312]		Loss: 0.1126
2019-10-28 15:42:04,979 Training Epoch [31/40] Iter[125/312]		Loss: 0.1129
2019-10-28 15:42:05,058 Training Epoch [31/40] Iter[126/312]		Loss: 0.1129
2019-10-28 15:42:05,138 Training Epoch [31/40] Iter[127/312]		Loss: 0.1131
2019-10-28 15:42:05,217 Training Epoch [31/40] Iter[128/312]		Loss: 0.1129
2019-10-28 15:42:05,297 Training Epoch [31/40] Iter[129/312]		Loss: 0.1127
2019-10-28 15:42:05,377 Training Epoch [31/40] Iter[130/312]		Loss: 0.1127
2019-10-28 15:42:05,456 Training Epoch [31/40] Iter[131/312]		Loss: 0.1127
2019-10-28 15:42:05,536 Training Epoch [31/40] Iter[132/312]		Loss: 0.1126
2019-10-28 15:42:05,616 Training Epoch [31/40] Iter[133/312]		Loss: 0.1124
2019-10-28 15:42:05,695 Training Epoch [31/40] Iter[134/312]		Loss: 0.1121
2019-10-28 15:42:05,775 Training Epoch [31/40] Iter[135/312]		Loss: 0.1122
2019-10-28 15:42:05,855 Training Epoch [31/40] Iter[136/312]		Loss: 0.1122
2019-10-28 15:42:05,935 Training Epoch [31/40] Iter[137/312]		Loss: 0.1119
2019-10-28 15:42:06,014 Training Epoch [31/40] Iter[138/312]		Loss: 0.1127
2019-10-28 15:42:06,094 Training Epoch [31/40] Iter[139/312]		Loss: 0.1124
2019-10-28 15:42:06,173 Training Epoch [31/40] Iter[140/312]		Loss: 0.1124
2019-10-28 15:42:06,253 Training Epoch [31/40] Iter[141/312]		Loss: 0.1122
2019-10-28 15:42:06,333 Training Epoch [31/40] Iter[142/312]		Loss: 0.1120
2019-10-28 15:42:06,412 Training Epoch [31/40] Iter[143/312]		Loss: 0.1122
2019-10-28 15:42:06,492 Training Epoch [31/40] Iter[144/312]		Loss: 0.1120
2019-10-28 15:42:06,572 Training Epoch [31/40] Iter[145/312]		Loss: 0.1119
2019-10-28 15:42:06,652 Training Epoch [31/40] Iter[146/312]		Loss: 0.1119
2019-10-28 15:42:06,731 Training Epoch [31/40] Iter[147/312]		Loss: 0.1118
2019-10-28 15:42:06,811 Training Epoch [31/40] Iter[148/312]		Loss: 0.1121
2019-10-28 15:42:06,890 Training Epoch [31/40] Iter[149/312]		Loss: 0.1119
2019-10-28 15:42:06,970 Training Epoch [31/40] Iter[150/312]		Loss: 0.1119
2019-10-28 15:42:07,050 Training Epoch [31/40] Iter[151/312]		Loss: 0.1120
2019-10-28 15:42:07,129 Training Epoch [31/40] Iter[152/312]		Loss: 0.1120
2019-10-28 15:42:07,209 Training Epoch [31/40] Iter[153/312]		Loss: 0.1120
2019-10-28 15:42:07,289 Training Epoch [31/40] Iter[154/312]		Loss: 0.1117
2019-10-28 15:42:07,369 Training Epoch [31/40] Iter[155/312]		Loss: 0.1126
2019-10-28 15:42:07,449 Training Epoch [31/40] Iter[156/312]		Loss: 0.1126
2019-10-28 15:42:07,528 Training Epoch [31/40] Iter[157/312]		Loss: 0.1123
2019-10-28 15:42:07,608 Training Epoch [31/40] Iter[158/312]		Loss: 0.1129
2019-10-28 15:42:07,688 Training Epoch [31/40] Iter[159/312]		Loss: 0.1130
2019-10-28 15:42:07,767 Training Epoch [31/40] Iter[160/312]		Loss: 0.1130
2019-10-28 15:42:07,847 Training Epoch [31/40] Iter[161/312]		Loss: 0.1128
2019-10-28 15:42:07,927 Training Epoch [31/40] Iter[162/312]		Loss: 0.1129
2019-10-28 15:42:08,007 Training Epoch [31/40] Iter[163/312]		Loss: 0.1128
2019-10-28 15:42:08,087 Training Epoch [31/40] Iter[164/312]		Loss: 0.1128
2019-10-28 15:42:08,166 Training Epoch [31/40] Iter[165/312]		Loss: 0.1130
2019-10-28 15:42:08,246 Training Epoch [31/40] Iter[166/312]		Loss: 0.1128
2019-10-28 15:42:08,326 Training Epoch [31/40] Iter[167/312]		Loss: 0.1127
2019-10-28 15:42:08,406 Training Epoch [31/40] Iter[168/312]		Loss: 0.1131
2019-10-28 15:42:08,486 Training Epoch [31/40] Iter[169/312]		Loss: 0.1128
2019-10-28 15:42:08,565 Training Epoch [31/40] Iter[170/312]		Loss: 0.1127
2019-10-28 15:42:08,645 Training Epoch [31/40] Iter[171/312]		Loss: 0.1126
2019-10-28 15:42:08,725 Training Epoch [31/40] Iter[172/312]		Loss: 0.1124
2019-10-28 15:42:08,805 Training Epoch [31/40] Iter[173/312]		Loss: 0.1122
2019-10-28 15:42:08,885 Training Epoch [31/40] Iter[174/312]		Loss: 0.1122
2019-10-28 15:42:08,964 Training Epoch [31/40] Iter[175/312]		Loss: 0.1124
2019-10-28 15:42:09,044 Training Epoch [31/40] Iter[176/312]		Loss: 0.1124
2019-10-28 15:42:09,124 Training Epoch [31/40] Iter[177/312]		Loss: 0.1125
2019-10-28 15:42:09,204 Training Epoch [31/40] Iter[178/312]		Loss: 0.1124
2019-10-28 15:42:09,283 Training Epoch [31/40] Iter[179/312]		Loss: 0.1124
2019-10-28 15:42:09,363 Training Epoch [31/40] Iter[180/312]		Loss: 0.1124
2019-10-28 15:42:09,443 Training Epoch [31/40] Iter[181/312]		Loss: 0.1125
2019-10-28 15:42:09,522 Training Epoch [31/40] Iter[182/312]		Loss: 0.1125
2019-10-28 15:42:09,602 Training Epoch [31/40] Iter[183/312]		Loss: 0.1122
2019-10-28 15:42:09,682 Training Epoch [31/40] Iter[184/312]		Loss: 0.1121
2019-10-28 15:42:09,761 Training Epoch [31/40] Iter[185/312]		Loss: 0.1120
2019-10-28 15:42:09,840 Training Epoch [31/40] Iter[186/312]		Loss: 0.1119
2019-10-28 15:42:09,920 Training Epoch [31/40] Iter[187/312]		Loss: 0.1121
2019-10-28 15:42:10,000 Training Epoch [31/40] Iter[188/312]		Loss: 0.1123
2019-10-28 15:42:10,080 Training Epoch [31/40] Iter[189/312]		Loss: 0.1120
2019-10-28 15:42:10,160 Training Epoch [31/40] Iter[190/312]		Loss: 0.1120
2019-10-28 15:42:10,239 Training Epoch [31/40] Iter[191/312]		Loss: 0.1118
2019-10-28 15:42:10,319 Training Epoch [31/40] Iter[192/312]		Loss: 0.1124
2019-10-28 15:42:10,398 Training Epoch [31/40] Iter[193/312]		Loss: 0.1123
2019-10-28 15:42:10,478 Training Epoch [31/40] Iter[194/312]		Loss: 0.1124
2019-10-28 15:42:10,558 Training Epoch [31/40] Iter[195/312]		Loss: 0.1125
2019-10-28 15:42:10,637 Training Epoch [31/40] Iter[196/312]		Loss: 0.1124
2019-10-28 15:42:10,716 Training Epoch [31/40] Iter[197/312]		Loss: 0.1125
2019-10-28 15:42:10,796 Training Epoch [31/40] Iter[198/312]		Loss: 0.1125
2019-10-28 15:42:10,875 Training Epoch [31/40] Iter[199/312]		Loss: 0.1126
2019-10-28 15:42:10,955 Training Epoch [31/40] Iter[200/312]		Loss: 0.1124
2019-10-28 15:42:11,034 Training Epoch [31/40] Iter[201/312]		Loss: 0.1124
2019-10-28 15:42:11,114 Training Epoch [31/40] Iter[202/312]		Loss: 0.1123
2019-10-28 15:42:11,194 Training Epoch [31/40] Iter[203/312]		Loss: 0.1121
2019-10-28 15:42:11,274 Training Epoch [31/40] Iter[204/312]		Loss: 0.1121
2019-10-28 15:42:11,354 Training Epoch [31/40] Iter[205/312]		Loss: 0.1125
2019-10-28 15:42:11,433 Training Epoch [31/40] Iter[206/312]		Loss: 0.1124
2019-10-28 15:42:11,513 Training Epoch [31/40] Iter[207/312]		Loss: 0.1124
2019-10-28 15:42:11,593 Training Epoch [31/40] Iter[208/312]		Loss: 0.1123
2019-10-28 15:42:11,672 Training Epoch [31/40] Iter[209/312]		Loss: 0.1121
2019-10-28 15:42:11,752 Training Epoch [31/40] Iter[210/312]		Loss: 0.1122
2019-10-28 15:42:11,832 Training Epoch [31/40] Iter[211/312]		Loss: 0.1121
2019-10-28 15:42:11,912 Training Epoch [31/40] Iter[212/312]		Loss: 0.1121
2019-10-28 15:42:11,992 Training Epoch [31/40] Iter[213/312]		Loss: 0.1120
2019-10-28 15:42:12,072 Training Epoch [31/40] Iter[214/312]		Loss: 0.1119
2019-10-28 15:42:12,152 Training Epoch [31/40] Iter[215/312]		Loss: 0.1119
2019-10-28 15:42:12,232 Training Epoch [31/40] Iter[216/312]		Loss: 0.1117
2019-10-28 15:42:12,312 Training Epoch [31/40] Iter[217/312]		Loss: 0.1116
2019-10-28 15:42:12,391 Training Epoch [31/40] Iter[218/312]		Loss: 0.1114
2019-10-28 15:42:12,471 Training Epoch [31/40] Iter[219/312]		Loss: 0.1114
2019-10-28 15:42:12,551 Training Epoch [31/40] Iter[220/312]		Loss: 0.1114
2019-10-28 15:42:12,630 Training Epoch [31/40] Iter[221/312]		Loss: 0.1113
2019-10-28 15:42:12,710 Training Epoch [31/40] Iter[222/312]		Loss: 0.1112
2019-10-28 15:42:12,789 Training Epoch [31/40] Iter[223/312]		Loss: 0.1113
2019-10-28 15:42:12,869 Training Epoch [31/40] Iter[224/312]		Loss: 0.1114
2019-10-28 15:42:12,949 Training Epoch [31/40] Iter[225/312]		Loss: 0.1113
2019-10-28 15:42:13,028 Training Epoch [31/40] Iter[226/312]		Loss: 0.1114
2019-10-28 15:42:13,108 Training Epoch [31/40] Iter[227/312]		Loss: 0.1117
2019-10-28 15:42:13,187 Training Epoch [31/40] Iter[228/312]		Loss: 0.1118
2019-10-28 15:42:13,266 Training Epoch [31/40] Iter[229/312]		Loss: 0.1117
2019-10-28 15:42:13,346 Training Epoch [31/40] Iter[230/312]		Loss: 0.1117
2019-10-28 15:42:13,425 Training Epoch [31/40] Iter[231/312]		Loss: 0.1118
2019-10-28 15:42:13,505 Training Epoch [31/40] Iter[232/312]		Loss: 0.1119
2019-10-28 15:42:13,584 Training Epoch [31/40] Iter[233/312]		Loss: 0.1118
2019-10-28 15:42:13,664 Training Epoch [31/40] Iter[234/312]		Loss: 0.1119
2019-10-28 15:42:13,743 Training Epoch [31/40] Iter[235/312]		Loss: 0.1118
2019-10-28 15:42:13,823 Training Epoch [31/40] Iter[236/312]		Loss: 0.1120
2019-10-28 15:42:13,903 Training Epoch [31/40] Iter[237/312]		Loss: 0.1119
2019-10-28 15:42:13,983 Training Epoch [31/40] Iter[238/312]		Loss: 0.1118
2019-10-28 15:42:14,063 Training Epoch [31/40] Iter[239/312]		Loss: 0.1118
2019-10-28 15:42:14,143 Training Epoch [31/40] Iter[240/312]		Loss: 0.1116
2019-10-28 15:42:14,222 Training Epoch [31/40] Iter[241/312]		Loss: 0.1115
2019-10-28 15:42:14,302 Training Epoch [31/40] Iter[242/312]		Loss: 0.1113
2019-10-28 15:42:14,382 Training Epoch [31/40] Iter[243/312]		Loss: 0.1112
2019-10-28 15:42:14,462 Training Epoch [31/40] Iter[244/312]		Loss: 0.1115
2019-10-28 15:42:14,541 Training Epoch [31/40] Iter[245/312]		Loss: 0.1114
2019-10-28 15:42:14,621 Training Epoch [31/40] Iter[246/312]		Loss: 0.1116
2019-10-28 15:42:14,700 Training Epoch [31/40] Iter[247/312]		Loss: 0.1119
2019-10-28 15:42:14,780 Training Epoch [31/40] Iter[248/312]		Loss: 0.1119
2019-10-28 15:42:14,859 Training Epoch [31/40] Iter[249/312]		Loss: 0.1119
2019-10-28 15:42:14,939 Training Epoch [31/40] Iter[250/312]		Loss: 0.1118
2019-10-28 15:42:15,018 Training Epoch [31/40] Iter[251/312]		Loss: 0.1122
2019-10-28 15:42:15,098 Training Epoch [31/40] Iter[252/312]		Loss: 0.1122
2019-10-28 15:42:15,178 Training Epoch [31/40] Iter[253/312]		Loss: 0.1122
2019-10-28 15:42:15,258 Training Epoch [31/40] Iter[254/312]		Loss: 0.1121
2019-10-28 15:42:15,337 Training Epoch [31/40] Iter[255/312]		Loss: 0.1119
2019-10-28 15:42:15,418 Training Epoch [31/40] Iter[256/312]		Loss: 0.1119
2019-10-28 15:42:15,497 Training Epoch [31/40] Iter[257/312]		Loss: 0.1121
2019-10-28 15:42:15,577 Training Epoch [31/40] Iter[258/312]		Loss: 0.1121
2019-10-28 15:42:15,656 Training Epoch [31/40] Iter[259/312]		Loss: 0.1121
2019-10-28 15:42:15,736 Training Epoch [31/40] Iter[260/312]		Loss: 0.1120
2019-10-28 15:42:15,815 Training Epoch [31/40] Iter[261/312]		Loss: 0.1120
2019-10-28 15:42:15,895 Training Epoch [31/40] Iter[262/312]		Loss: 0.1124
2019-10-28 15:42:15,975 Training Epoch [31/40] Iter[263/312]		Loss: 0.1123
2019-10-28 15:42:16,054 Training Epoch [31/40] Iter[264/312]		Loss: 0.1123
2019-10-28 15:42:16,134 Training Epoch [31/40] Iter[265/312]		Loss: 0.1122
2019-10-28 15:42:16,213 Training Epoch [31/40] Iter[266/312]		Loss: 0.1122
2019-10-28 15:42:16,294 Training Epoch [31/40] Iter[267/312]		Loss: 0.1123
2019-10-28 15:42:16,373 Training Epoch [31/40] Iter[268/312]		Loss: 0.1122
2019-10-28 15:42:16,453 Training Epoch [31/40] Iter[269/312]		Loss: 0.1123
2019-10-28 15:42:16,533 Training Epoch [31/40] Iter[270/312]		Loss: 0.1125
2019-10-28 15:42:16,612 Training Epoch [31/40] Iter[271/312]		Loss: 0.1125
2019-10-28 15:42:16,692 Training Epoch [31/40] Iter[272/312]		Loss: 0.1124
2019-10-28 15:42:16,772 Training Epoch [31/40] Iter[273/312]		Loss: 0.1123
2019-10-28 15:42:16,852 Training Epoch [31/40] Iter[274/312]		Loss: 0.1122
2019-10-28 15:42:16,931 Training Epoch [31/40] Iter[275/312]		Loss: 0.1122
2019-10-28 15:42:17,011 Training Epoch [31/40] Iter[276/312]		Loss: 0.1123
2019-10-28 15:42:17,091 Training Epoch [31/40] Iter[277/312]		Loss: 0.1122
2019-10-28 15:42:17,170 Training Epoch [31/40] Iter[278/312]		Loss: 0.1121
2019-10-28 15:42:17,250 Training Epoch [31/40] Iter[279/312]		Loss: 0.1122
2019-10-28 15:42:17,329 Training Epoch [31/40] Iter[280/312]		Loss: 0.1125
2019-10-28 15:42:17,409 Training Epoch [31/40] Iter[281/312]		Loss: 0.1123
2019-10-28 15:42:17,489 Training Epoch [31/40] Iter[282/312]		Loss: 0.1123
2019-10-28 15:42:17,569 Training Epoch [31/40] Iter[283/312]		Loss: 0.1122
2019-10-28 15:42:17,649 Training Epoch [31/40] Iter[284/312]		Loss: 0.1124
2019-10-28 15:42:17,728 Training Epoch [31/40] Iter[285/312]		Loss: 0.1126
2019-10-28 15:42:17,808 Training Epoch [31/40] Iter[286/312]		Loss: 0.1127
2019-10-28 15:42:17,888 Training Epoch [31/40] Iter[287/312]		Loss: 0.1127
2019-10-28 15:42:17,968 Training Epoch [31/40] Iter[288/312]		Loss: 0.1127
2019-10-28 15:42:18,047 Training Epoch [31/40] Iter[289/312]		Loss: 0.1127
2019-10-28 15:42:18,127 Training Epoch [31/40] Iter[290/312]		Loss: 0.1127
2019-10-28 15:42:18,207 Training Epoch [31/40] Iter[291/312]		Loss: 0.1128
2019-10-28 15:42:18,286 Training Epoch [31/40] Iter[292/312]		Loss: 0.1130
2019-10-28 15:42:18,366 Training Epoch [31/40] Iter[293/312]		Loss: 0.1129
2019-10-28 15:42:18,446 Training Epoch [31/40] Iter[294/312]		Loss: 0.1129
2019-10-28 15:42:18,526 Training Epoch [31/40] Iter[295/312]		Loss: 0.1130
2019-10-28 15:42:18,605 Training Epoch [31/40] Iter[296/312]		Loss: 0.1132
2019-10-28 15:42:18,685 Training Epoch [31/40] Iter[297/312]		Loss: 0.1132
2019-10-28 15:42:18,764 Training Epoch [31/40] Iter[298/312]		Loss: 0.1131
2019-10-28 15:42:18,844 Training Epoch [31/40] Iter[299/312]		Loss: 0.1131
2019-10-28 15:42:18,923 Training Epoch [31/40] Iter[300/312]		Loss: 0.1131
2019-10-28 15:42:19,002 Training Epoch [31/40] Iter[301/312]		Loss: 0.1131
2019-10-28 15:42:19,082 Training Epoch [31/40] Iter[302/312]		Loss: 0.1132
2019-10-28 15:42:19,162 Training Epoch [31/40] Iter[303/312]		Loss: 0.1131
2019-10-28 15:42:19,241 Training Epoch [31/40] Iter[304/312]		Loss: 0.1130
2019-10-28 15:42:19,320 Training Epoch [31/40] Iter[305/312]		Loss: 0.1131
2019-10-28 15:42:19,399 Training Epoch [31/40] Iter[306/312]		Loss: 0.1130
2019-10-28 15:42:19,478 Training Epoch [31/40] Iter[307/312]		Loss: 0.1130
2019-10-28 15:42:19,556 Training Epoch [31/40] Iter[308/312]		Loss: 0.1128
2019-10-28 15:42:19,635 Training Epoch [31/40] Iter[309/312]		Loss: 0.1127
2019-10-28 15:42:19,714 Training Epoch [31/40] Iter[310/312]		Loss: 0.1129
2019-10-28 15:42:19,792 Training Epoch [31/40] Iter[311/312]		Loss: 0.1131
2019-10-28 15:42:19,831 Training Epoch [31/40] Iter[312/312]		Loss: 0.1131
2019-10-28 15:42:20,251 Testing Epoch [31/40] Iter[0/62]		Loss: 0.1289
2019-10-28 15:42:20,298 Testing Epoch [31/40] Iter[1/62]		Loss: 0.1290
2019-10-28 15:42:20,315 Testing Epoch [31/40] Iter[2/62]		Loss: 0.1117
2019-10-28 15:42:20,350 Testing Epoch [31/40] Iter[3/62]		Loss: 0.1160
2019-10-28 15:42:20,381 Testing Epoch [31/40] Iter[4/62]		Loss: 0.1196
2019-10-28 15:42:20,410 Testing Epoch [31/40] Iter[5/62]		Loss: 0.1147
2019-10-28 15:42:20,441 Testing Epoch [31/40] Iter[6/62]		Loss: 0.1160
2019-10-28 15:42:20,459 Testing Epoch [31/40] Iter[7/62]		Loss: 0.1186
2019-10-28 15:42:20,476 Testing Epoch [31/40] Iter[8/62]		Loss: 0.1211
2019-10-28 15:42:20,505 Testing Epoch [31/40] Iter[9/62]		Loss: 0.1199
2019-10-28 15:42:20,522 Testing Epoch [31/40] Iter[10/62]		Loss: 0.1208
2019-10-28 15:42:20,549 Testing Epoch [31/40] Iter[11/62]		Loss: 0.1267
2019-10-28 15:42:20,567 Testing Epoch [31/40] Iter[12/62]		Loss: 0.1266
2019-10-28 15:42:20,593 Testing Epoch [31/40] Iter[13/62]		Loss: 0.1286
2019-10-28 15:42:20,611 Testing Epoch [31/40] Iter[14/62]		Loss: 0.1419
2019-10-28 15:42:20,641 Testing Epoch [31/40] Iter[15/62]		Loss: 0.1439
2019-10-28 15:42:20,660 Testing Epoch [31/40] Iter[16/62]		Loss: 0.1410
2019-10-28 15:42:20,685 Testing Epoch [31/40] Iter[17/62]		Loss: 0.1411
2019-10-28 15:42:20,702 Testing Epoch [31/40] Iter[18/62]		Loss: 0.1386
2019-10-28 15:42:20,733 Testing Epoch [31/40] Iter[19/62]		Loss: 0.1369
2019-10-28 15:42:20,752 Testing Epoch [31/40] Iter[20/62]		Loss: 0.1388
2019-10-28 15:42:20,781 Testing Epoch [31/40] Iter[21/62]		Loss: 0.1372
2019-10-28 15:42:20,802 Testing Epoch [31/40] Iter[22/62]		Loss: 0.1388
2019-10-28 15:42:20,829 Testing Epoch [31/40] Iter[23/62]		Loss: 0.1378
2019-10-28 15:42:20,847 Testing Epoch [31/40] Iter[24/62]		Loss: 0.1411
2019-10-28 15:42:20,866 Testing Epoch [31/40] Iter[25/62]		Loss: 0.1402
2019-10-28 15:42:20,897 Testing Epoch [31/40] Iter[26/62]		Loss: 0.1390
2019-10-28 15:42:20,919 Testing Epoch [31/40] Iter[27/62]		Loss: 0.1467
2019-10-28 15:42:20,937 Testing Epoch [31/40] Iter[28/62]		Loss: 0.1502
2019-10-28 15:42:20,955 Testing Epoch [31/40] Iter[29/62]		Loss: 0.1502
2019-10-28 15:42:20,986 Testing Epoch [31/40] Iter[30/62]		Loss: 0.1504
2019-10-28 15:42:21,004 Testing Epoch [31/40] Iter[31/62]		Loss: 0.1492
2019-10-28 15:42:21,023 Testing Epoch [31/40] Iter[32/62]		Loss: 0.1509
2019-10-28 15:42:21,050 Testing Epoch [31/40] Iter[33/62]		Loss: 0.1499
2019-10-28 15:42:21,077 Testing Epoch [31/40] Iter[34/62]		Loss: 0.1521
2019-10-28 15:42:21,095 Testing Epoch [31/40] Iter[35/62]		Loss: 0.1516
2019-10-28 15:42:21,114 Testing Epoch [31/40] Iter[36/62]		Loss: 0.1495
2019-10-28 15:42:21,141 Testing Epoch [31/40] Iter[37/62]		Loss: 0.1484
2019-10-28 15:42:21,169 Testing Epoch [31/40] Iter[38/62]		Loss: 0.1473
2019-10-28 15:42:21,194 Testing Epoch [31/40] Iter[39/62]		Loss: 0.1475
2019-10-28 15:42:21,213 Testing Epoch [31/40] Iter[40/62]		Loss: 0.1492
2019-10-28 15:42:21,237 Testing Epoch [31/40] Iter[41/62]		Loss: 0.1508
2019-10-28 15:42:21,255 Testing Epoch [31/40] Iter[42/62]		Loss: 0.1488
2019-10-28 15:42:21,286 Testing Epoch [31/40] Iter[43/62]		Loss: 0.1482
2019-10-28 15:42:21,302 Testing Epoch [31/40] Iter[44/62]		Loss: 0.1467
2019-10-28 15:42:21,329 Testing Epoch [31/40] Iter[45/62]		Loss: 0.1465
2019-10-28 15:42:21,347 Testing Epoch [31/40] Iter[46/62]		Loss: 0.1463
2019-10-28 15:42:21,377 Testing Epoch [31/40] Iter[47/62]		Loss: 0.1522
2019-10-28 15:42:21,400 Testing Epoch [31/40] Iter[48/62]		Loss: 0.1512
2019-10-28 15:42:21,425 Testing Epoch [31/40] Iter[49/62]		Loss: 0.1535
2019-10-28 15:42:21,443 Testing Epoch [31/40] Iter[50/62]		Loss: 0.1527
2019-10-28 15:42:21,473 Testing Epoch [31/40] Iter[51/62]		Loss: 0.1526
2019-10-28 15:42:21,491 Testing Epoch [31/40] Iter[52/62]		Loss: 0.1515
2019-10-28 15:42:21,521 Testing Epoch [31/40] Iter[53/62]		Loss: 0.1518
2019-10-28 15:42:21,539 Testing Epoch [31/40] Iter[54/62]		Loss: 0.1506
2019-10-28 15:42:21,557 Testing Epoch [31/40] Iter[55/62]		Loss: 0.1503
2019-10-28 15:42:21,573 Testing Epoch [31/40] Iter[56/62]		Loss: 0.1495
2019-10-28 15:42:21,590 Testing Epoch [31/40] Iter[57/62]		Loss: 0.1498
2019-10-28 15:42:21,607 Testing Epoch [31/40] Iter[58/62]		Loss: 0.1492
2019-10-28 15:42:21,624 Testing Epoch [31/40] Iter[59/62]		Loss: 0.1503
2019-10-28 15:42:21,641 Testing Epoch [31/40] Iter[60/62]		Loss: 0.1494
2019-10-28 15:42:21,658 Testing Epoch [31/40] Iter[61/62]		Loss: 0.1494
2019-10-28 15:42:21,667 Testing Epoch [31/40] Iter[62/62]		Loss: 0.1502
2019-10-28 15:42:21,740 Saving the Model
2019-10-28 15:42:22,155 Training Epoch [32/40] Iter[0/312]		Loss: 0.0848
2019-10-28 15:42:22,246 Training Epoch [32/40] Iter[1/312]		Loss: 0.1011
2019-10-28 15:42:22,327 Training Epoch [32/40] Iter[2/312]		Loss: 0.0988
2019-10-28 15:42:22,407 Training Epoch [32/40] Iter[3/312]		Loss: 0.1041
2019-10-28 15:42:22,486 Training Epoch [32/40] Iter[4/312]		Loss: 0.0996
2019-10-28 15:42:22,567 Training Epoch [32/40] Iter[5/312]		Loss: 0.0998
2019-10-28 15:42:22,648 Training Epoch [32/40] Iter[6/312]		Loss: 0.0992
2019-10-28 15:42:22,731 Training Epoch [32/40] Iter[7/312]		Loss: 0.1020
2019-10-28 15:42:22,809 Training Epoch [32/40] Iter[8/312]		Loss: 0.0973
2019-10-28 15:42:22,889 Training Epoch [32/40] Iter[9/312]		Loss: 0.1015
2019-10-28 15:42:22,968 Training Epoch [32/40] Iter[10/312]		Loss: 0.1055
2019-10-28 15:42:23,048 Training Epoch [32/40] Iter[11/312]		Loss: 0.1053
2019-10-28 15:42:23,127 Training Epoch [32/40] Iter[12/312]		Loss: 0.1102
2019-10-28 15:42:23,207 Training Epoch [32/40] Iter[13/312]		Loss: 0.1115
2019-10-28 15:42:23,286 Training Epoch [32/40] Iter[14/312]		Loss: 0.1098
2019-10-28 15:42:23,366 Training Epoch [32/40] Iter[15/312]		Loss: 0.1080
2019-10-28 15:42:23,445 Training Epoch [32/40] Iter[16/312]		Loss: 0.1063
2019-10-28 15:42:23,525 Training Epoch [32/40] Iter[17/312]		Loss: 0.1045
2019-10-28 15:42:23,604 Training Epoch [32/40] Iter[18/312]		Loss: 0.1052
2019-10-28 15:42:23,684 Training Epoch [32/40] Iter[19/312]		Loss: 0.1058
2019-10-28 15:42:23,763 Training Epoch [32/40] Iter[20/312]		Loss: 0.1070
2019-10-28 15:42:23,843 Training Epoch [32/40] Iter[21/312]		Loss: 0.1062
2019-10-28 15:42:23,922 Training Epoch [32/40] Iter[22/312]		Loss: 0.1074
2019-10-28 15:42:24,001 Training Epoch [32/40] Iter[23/312]		Loss: 0.1076
2019-10-28 15:42:24,081 Training Epoch [32/40] Iter[24/312]		Loss: 0.1059
2019-10-28 15:42:24,160 Training Epoch [32/40] Iter[25/312]		Loss: 0.1052
2019-10-28 15:42:24,240 Training Epoch [32/40] Iter[26/312]		Loss: 0.1042
2019-10-28 15:42:24,320 Training Epoch [32/40] Iter[27/312]		Loss: 0.1065
2019-10-28 15:42:24,400 Training Epoch [32/40] Iter[28/312]		Loss: 0.1078
2019-10-28 15:42:24,480 Training Epoch [32/40] Iter[29/312]		Loss: 0.1072
2019-10-28 15:42:24,559 Training Epoch [32/40] Iter[30/312]		Loss: 0.1061
2019-10-28 15:42:24,644 Training Epoch [32/40] Iter[31/312]		Loss: 0.1060
2019-10-28 15:42:24,724 Training Epoch [32/40] Iter[32/312]		Loss: 0.1055
2019-10-28 15:42:24,803 Training Epoch [32/40] Iter[33/312]		Loss: 0.1053
2019-10-28 15:42:24,883 Training Epoch [32/40] Iter[34/312]		Loss: 0.1048
2019-10-28 15:42:24,962 Training Epoch [32/40] Iter[35/312]		Loss: 0.1059
2019-10-28 15:42:25,041 Training Epoch [32/40] Iter[36/312]		Loss: 0.1050
2019-10-28 15:42:25,121 Training Epoch [32/40] Iter[37/312]		Loss: 0.1070
2019-10-28 15:42:25,203 Training Epoch [32/40] Iter[38/312]		Loss: 0.1067
2019-10-28 15:42:25,282 Training Epoch [32/40] Iter[39/312]		Loss: 0.1073
2019-10-28 15:42:25,362 Training Epoch [32/40] Iter[40/312]		Loss: 0.1068
2019-10-28 15:42:25,441 Training Epoch [32/40] Iter[41/312]		Loss: 0.1058
2019-10-28 15:42:25,521 Training Epoch [32/40] Iter[42/312]		Loss: 0.1057
2019-10-28 15:42:25,600 Training Epoch [32/40] Iter[43/312]		Loss: 0.1057
2019-10-28 15:42:25,680 Training Epoch [32/40] Iter[44/312]		Loss: 0.1067
2019-10-28 15:42:25,759 Training Epoch [32/40] Iter[45/312]		Loss: 0.1071
2019-10-28 15:42:25,839 Training Epoch [32/40] Iter[46/312]		Loss: 0.1071
2019-10-28 15:42:25,918 Training Epoch [32/40] Iter[47/312]		Loss: 0.1071
2019-10-28 15:42:25,998 Training Epoch [32/40] Iter[48/312]		Loss: 0.1073
2019-10-28 15:42:26,078 Training Epoch [32/40] Iter[49/312]		Loss: 0.1068
2019-10-28 15:42:26,157 Training Epoch [32/40] Iter[50/312]		Loss: 0.1059
2019-10-28 15:42:26,237 Training Epoch [32/40] Iter[51/312]		Loss: 0.1069
2019-10-28 15:42:26,317 Training Epoch [32/40] Iter[52/312]		Loss: 0.1067
2019-10-28 15:42:26,397 Training Epoch [32/40] Iter[53/312]		Loss: 0.1079
2019-10-28 15:42:26,476 Training Epoch [32/40] Iter[54/312]		Loss: 0.1081
2019-10-28 15:42:26,556 Training Epoch [32/40] Iter[55/312]		Loss: 0.1079
2019-10-28 15:42:26,636 Training Epoch [32/40] Iter[56/312]		Loss: 0.1074
2019-10-28 15:42:26,715 Training Epoch [32/40] Iter[57/312]		Loss: 0.1084
2019-10-28 15:42:26,795 Training Epoch [32/40] Iter[58/312]		Loss: 0.1078
2019-10-28 15:42:26,874 Training Epoch [32/40] Iter[59/312]		Loss: 0.1079
2019-10-28 15:42:26,954 Training Epoch [32/40] Iter[60/312]		Loss: 0.1081
2019-10-28 15:42:27,034 Training Epoch [32/40] Iter[61/312]		Loss: 0.1079
2019-10-28 15:42:27,114 Training Epoch [32/40] Iter[62/312]		Loss: 0.1078
2019-10-28 15:42:27,193 Training Epoch [32/40] Iter[63/312]		Loss: 0.1077
2019-10-28 15:42:27,273 Training Epoch [32/40] Iter[64/312]		Loss: 0.1079
2019-10-28 15:42:27,353 Training Epoch [32/40] Iter[65/312]		Loss: 0.1073
2019-10-28 15:42:27,432 Training Epoch [32/40] Iter[66/312]		Loss: 0.1078
2019-10-28 15:42:27,512 Training Epoch [32/40] Iter[67/312]		Loss: 0.1076
2019-10-28 15:42:27,592 Training Epoch [32/40] Iter[68/312]		Loss: 0.1075
2019-10-28 15:42:27,671 Training Epoch [32/40] Iter[69/312]		Loss: 0.1076
2019-10-28 15:42:27,751 Training Epoch [32/40] Iter[70/312]		Loss: 0.1076
2019-10-28 15:42:27,831 Training Epoch [32/40] Iter[71/312]		Loss: 0.1071
2019-10-28 15:42:27,911 Training Epoch [32/40] Iter[72/312]		Loss: 0.1068
2019-10-28 15:42:27,990 Training Epoch [32/40] Iter[73/312]		Loss: 0.1069
2019-10-28 15:42:28,070 Training Epoch [32/40] Iter[74/312]		Loss: 0.1070
2019-10-28 15:42:28,149 Training Epoch [32/40] Iter[75/312]		Loss: 0.1074
2019-10-28 15:42:28,229 Training Epoch [32/40] Iter[76/312]		Loss: 0.1082
2019-10-28 15:42:28,309 Training Epoch [32/40] Iter[77/312]		Loss: 0.1080
2019-10-28 15:42:28,388 Training Epoch [32/40] Iter[78/312]		Loss: 0.1084
2019-10-28 15:42:28,468 Training Epoch [32/40] Iter[79/312]		Loss: 0.1086
2019-10-28 15:42:28,548 Training Epoch [32/40] Iter[80/312]		Loss: 0.1081
2019-10-28 15:42:28,627 Training Epoch [32/40] Iter[81/312]		Loss: 0.1083
2019-10-28 15:42:28,707 Training Epoch [32/40] Iter[82/312]		Loss: 0.1082
2019-10-28 15:42:28,786 Training Epoch [32/40] Iter[83/312]		Loss: 0.1078
2019-10-28 15:42:28,866 Training Epoch [32/40] Iter[84/312]		Loss: 0.1081
2019-10-28 15:42:28,945 Training Epoch [32/40] Iter[85/312]		Loss: 0.1078
2019-10-28 15:42:29,025 Training Epoch [32/40] Iter[86/312]		Loss: 0.1076
2019-10-28 15:42:29,104 Training Epoch [32/40] Iter[87/312]		Loss: 0.1074
2019-10-28 15:42:29,184 Training Epoch [32/40] Iter[88/312]		Loss: 0.1071
2019-10-28 15:42:29,263 Training Epoch [32/40] Iter[89/312]		Loss: 0.1069
2019-10-28 15:42:29,343 Training Epoch [32/40] Iter[90/312]		Loss: 0.1068
2019-10-28 15:42:29,422 Training Epoch [32/40] Iter[91/312]		Loss: 0.1072
2019-10-28 15:42:29,502 Training Epoch [32/40] Iter[92/312]		Loss: 0.1077
2019-10-28 15:42:29,581 Training Epoch [32/40] Iter[93/312]		Loss: 0.1076
2019-10-28 15:42:29,660 Training Epoch [32/40] Iter[94/312]		Loss: 0.1083
2019-10-28 15:42:29,739 Training Epoch [32/40] Iter[95/312]		Loss: 0.1089
2019-10-28 15:42:29,819 Training Epoch [32/40] Iter[96/312]		Loss: 0.1087
2019-10-28 15:42:29,898 Training Epoch [32/40] Iter[97/312]		Loss: 0.1090
2019-10-28 15:42:29,977 Training Epoch [32/40] Iter[98/312]		Loss: 0.1088
2019-10-28 15:42:30,056 Training Epoch [32/40] Iter[99/312]		Loss: 0.1093
2019-10-28 15:42:30,135 Training Epoch [32/40] Iter[100/312]		Loss: 0.1088
2019-10-28 15:42:30,214 Training Epoch [32/40] Iter[101/312]		Loss: 0.1087
2019-10-28 15:42:30,294 Training Epoch [32/40] Iter[102/312]		Loss: 0.1089
2019-10-28 15:42:30,373 Training Epoch [32/40] Iter[103/312]		Loss: 0.1092
2019-10-28 15:42:30,453 Training Epoch [32/40] Iter[104/312]		Loss: 0.1093
2019-10-28 15:42:30,532 Training Epoch [32/40] Iter[105/312]		Loss: 0.1091
2019-10-28 15:42:30,611 Training Epoch [32/40] Iter[106/312]		Loss: 0.1093
2019-10-28 15:42:30,691 Training Epoch [32/40] Iter[107/312]		Loss: 0.1091
2019-10-28 15:42:30,770 Training Epoch [32/40] Iter[108/312]		Loss: 0.1088
2019-10-28 15:42:30,849 Training Epoch [32/40] Iter[109/312]		Loss: 0.1090
2019-10-28 15:42:30,928 Training Epoch [32/40] Iter[110/312]		Loss: 0.1088
2019-10-28 15:42:31,007 Training Epoch [32/40] Iter[111/312]		Loss: 0.1085
2019-10-28 15:42:31,086 Training Epoch [32/40] Iter[112/312]		Loss: 0.1085
2019-10-28 15:42:31,166 Training Epoch [32/40] Iter[113/312]		Loss: 0.1090
2019-10-28 15:42:31,245 Training Epoch [32/40] Iter[114/312]		Loss: 0.1094
2019-10-28 15:42:31,324 Training Epoch [32/40] Iter[115/312]		Loss: 0.1094
2019-10-28 15:42:31,404 Training Epoch [32/40] Iter[116/312]		Loss: 0.1095
2019-10-28 15:42:31,484 Training Epoch [32/40] Iter[117/312]		Loss: 0.1094
2019-10-28 15:42:31,563 Training Epoch [32/40] Iter[118/312]		Loss: 0.1092
2019-10-28 15:42:31,642 Training Epoch [32/40] Iter[119/312]		Loss: 0.1091
2019-10-28 15:42:31,722 Training Epoch [32/40] Iter[120/312]		Loss: 0.1092
2019-10-28 15:42:31,801 Training Epoch [32/40] Iter[121/312]		Loss: 0.1101
2019-10-28 15:42:31,881 Training Epoch [32/40] Iter[122/312]		Loss: 0.1100
2019-10-28 15:42:31,960 Training Epoch [32/40] Iter[123/312]		Loss: 0.1099
2019-10-28 15:42:32,039 Training Epoch [32/40] Iter[124/312]		Loss: 0.1096
2019-10-28 15:42:32,118 Training Epoch [32/40] Iter[125/312]		Loss: 0.1099
2019-10-28 15:42:32,198 Training Epoch [32/40] Iter[126/312]		Loss: 0.1095
2019-10-28 15:42:32,277 Training Epoch [32/40] Iter[127/312]		Loss: 0.1095
2019-10-28 15:42:32,357 Training Epoch [32/40] Iter[128/312]		Loss: 0.1092
2019-10-28 15:42:32,436 Training Epoch [32/40] Iter[129/312]		Loss: 0.1098
2019-10-28 15:42:32,516 Training Epoch [32/40] Iter[130/312]		Loss: 0.1100
2019-10-28 15:42:32,596 Training Epoch [32/40] Iter[131/312]		Loss: 0.1101
2019-10-28 15:42:32,675 Training Epoch [32/40] Iter[132/312]		Loss: 0.1102
2019-10-28 15:42:32,760 Training Epoch [32/40] Iter[133/312]		Loss: 0.1106
2019-10-28 15:42:32,839 Training Epoch [32/40] Iter[134/312]		Loss: 0.1109
2019-10-28 15:42:32,918 Training Epoch [32/40] Iter[135/312]		Loss: 0.1109
2019-10-28 15:42:32,997 Training Epoch [32/40] Iter[136/312]		Loss: 0.1110
2019-10-28 15:42:33,076 Training Epoch [32/40] Iter[137/312]		Loss: 0.1108
2019-10-28 15:42:33,156 Training Epoch [32/40] Iter[138/312]		Loss: 0.1105
2019-10-28 15:42:33,235 Training Epoch [32/40] Iter[139/312]		Loss: 0.1104
2019-10-28 15:42:33,314 Training Epoch [32/40] Iter[140/312]		Loss: 0.1103
2019-10-28 15:42:33,394 Training Epoch [32/40] Iter[141/312]		Loss: 0.1100
2019-10-28 15:42:33,473 Training Epoch [32/40] Iter[142/312]		Loss: 0.1099
2019-10-28 15:42:33,553 Training Epoch [32/40] Iter[143/312]		Loss: 0.1097
2019-10-28 15:42:33,633 Training Epoch [32/40] Iter[144/312]		Loss: 0.1096
2019-10-28 15:42:33,712 Training Epoch [32/40] Iter[145/312]		Loss: 0.1094
2019-10-28 15:42:33,792 Training Epoch [32/40] Iter[146/312]		Loss: 0.1093
2019-10-28 15:42:33,871 Training Epoch [32/40] Iter[147/312]		Loss: 0.1091
2019-10-28 15:42:33,951 Training Epoch [32/40] Iter[148/312]		Loss: 0.1093
2019-10-28 15:42:34,030 Training Epoch [32/40] Iter[149/312]		Loss: 0.1094
2019-10-28 15:42:34,110 Training Epoch [32/40] Iter[150/312]		Loss: 0.1099
2019-10-28 15:42:34,189 Training Epoch [32/40] Iter[151/312]		Loss: 0.1103
2019-10-28 15:42:34,269 Training Epoch [32/40] Iter[152/312]		Loss: 0.1101
2019-10-28 15:42:34,348 Training Epoch [32/40] Iter[153/312]		Loss: 0.1099
2019-10-28 15:42:34,428 Training Epoch [32/40] Iter[154/312]		Loss: 0.1101
2019-10-28 15:42:34,513 Training Epoch [32/40] Iter[155/312]		Loss: 0.1102
2019-10-28 15:42:34,592 Training Epoch [32/40] Iter[156/312]		Loss: 0.1102
2019-10-28 15:42:34,672 Training Epoch [32/40] Iter[157/312]		Loss: 0.1101
2019-10-28 15:42:34,751 Training Epoch [32/40] Iter[158/312]		Loss: 0.1103
2019-10-28 15:42:34,831 Training Epoch [32/40] Iter[159/312]		Loss: 0.1106
2019-10-28 15:42:34,911 Training Epoch [32/40] Iter[160/312]		Loss: 0.1109
2019-10-28 15:42:34,990 Training Epoch [32/40] Iter[161/312]		Loss: 0.1113
2019-10-28 15:42:35,070 Training Epoch [32/40] Iter[162/312]		Loss: 0.1114
2019-10-28 15:42:35,149 Training Epoch [32/40] Iter[163/312]		Loss: 0.1115
2019-10-28 15:42:35,229 Training Epoch [32/40] Iter[164/312]		Loss: 0.1116
2019-10-28 15:42:35,309 Training Epoch [32/40] Iter[165/312]		Loss: 0.1122
2019-10-28 15:42:35,388 Training Epoch [32/40] Iter[166/312]		Loss: 0.1121
2019-10-28 15:42:35,468 Training Epoch [32/40] Iter[167/312]		Loss: 0.1119
2019-10-28 15:42:35,547 Training Epoch [32/40] Iter[168/312]		Loss: 0.1123
2019-10-28 15:42:35,627 Training Epoch [32/40] Iter[169/312]		Loss: 0.1120
2019-10-28 15:42:35,706 Training Epoch [32/40] Iter[170/312]		Loss: 0.1119
2019-10-28 15:42:35,786 Training Epoch [32/40] Iter[171/312]		Loss: 0.1127
2019-10-28 15:42:35,865 Training Epoch [32/40] Iter[172/312]		Loss: 0.1126
2019-10-28 15:42:35,944 Training Epoch [32/40] Iter[173/312]		Loss: 0.1126
2019-10-28 15:42:36,024 Training Epoch [32/40] Iter[174/312]		Loss: 0.1127
2019-10-28 15:42:36,103 Training Epoch [32/40] Iter[175/312]		Loss: 0.1125
2019-10-28 15:42:36,183 Training Epoch [32/40] Iter[176/312]		Loss: 0.1124
2019-10-28 15:42:36,262 Training Epoch [32/40] Iter[177/312]		Loss: 0.1123
2019-10-28 15:42:36,342 Training Epoch [32/40] Iter[178/312]		Loss: 0.1121
2019-10-28 15:42:36,422 Training Epoch [32/40] Iter[179/312]		Loss: 0.1119
2019-10-28 15:42:36,502 Training Epoch [32/40] Iter[180/312]		Loss: 0.1124
2019-10-28 15:42:36,582 Training Epoch [32/40] Iter[181/312]		Loss: 0.1124
2019-10-28 15:42:36,661 Training Epoch [32/40] Iter[182/312]		Loss: 0.1124
2019-10-28 15:42:36,741 Training Epoch [32/40] Iter[183/312]		Loss: 0.1122
2019-10-28 15:42:36,820 Training Epoch [32/40] Iter[184/312]		Loss: 0.1125
2019-10-28 15:42:36,900 Training Epoch [32/40] Iter[185/312]		Loss: 0.1125
2019-10-28 15:42:36,979 Training Epoch [32/40] Iter[186/312]		Loss: 0.1123
2019-10-28 15:42:37,059 Training Epoch [32/40] Iter[187/312]		Loss: 0.1121
2019-10-28 15:42:37,139 Training Epoch [32/40] Iter[188/312]		Loss: 0.1119
2019-10-28 15:42:37,218 Training Epoch [32/40] Iter[189/312]		Loss: 0.1120
2019-10-28 15:42:37,298 Training Epoch [32/40] Iter[190/312]		Loss: 0.1118
2019-10-28 15:42:37,378 Training Epoch [32/40] Iter[191/312]		Loss: 0.1116
2019-10-28 15:42:37,458 Training Epoch [32/40] Iter[192/312]		Loss: 0.1115
2019-10-28 15:42:37,537 Training Epoch [32/40] Iter[193/312]		Loss: 0.1113
2019-10-28 15:42:37,617 Training Epoch [32/40] Iter[194/312]		Loss: 0.1114
2019-10-28 15:42:37,697 Training Epoch [32/40] Iter[195/312]		Loss: 0.1112
2019-10-28 15:42:37,776 Training Epoch [32/40] Iter[196/312]		Loss: 0.1114
2019-10-28 15:42:37,856 Training Epoch [32/40] Iter[197/312]		Loss: 0.1113
2019-10-28 15:42:37,935 Training Epoch [32/40] Iter[198/312]		Loss: 0.1113
2019-10-28 15:42:38,015 Training Epoch [32/40] Iter[199/312]		Loss: 0.1113
2019-10-28 15:42:38,095 Training Epoch [32/40] Iter[200/312]		Loss: 0.1113
2019-10-28 15:42:38,174 Training Epoch [32/40] Iter[201/312]		Loss: 0.1113
2019-10-28 15:42:38,254 Training Epoch [32/40] Iter[202/312]		Loss: 0.1116
2019-10-28 15:42:38,334 Training Epoch [32/40] Iter[203/312]		Loss: 0.1113
2019-10-28 15:42:38,414 Training Epoch [32/40] Iter[204/312]		Loss: 0.1113
2019-10-28 15:42:38,494 Training Epoch [32/40] Iter[205/312]		Loss: 0.1114
2019-10-28 15:42:38,574 Training Epoch [32/40] Iter[206/312]		Loss: 0.1116
2019-10-28 15:42:38,653 Training Epoch [32/40] Iter[207/312]		Loss: 0.1118
2019-10-28 15:42:38,733 Training Epoch [32/40] Iter[208/312]		Loss: 0.1116
2019-10-28 15:42:38,813 Training Epoch [32/40] Iter[209/312]		Loss: 0.1115
2019-10-28 15:42:38,893 Training Epoch [32/40] Iter[210/312]		Loss: 0.1116
2019-10-28 15:42:38,972 Training Epoch [32/40] Iter[211/312]		Loss: 0.1114
2019-10-28 15:42:39,052 Training Epoch [32/40] Iter[212/312]		Loss: 0.1116
2019-10-28 15:42:39,132 Training Epoch [32/40] Iter[213/312]		Loss: 0.1115
2019-10-28 15:42:39,211 Training Epoch [32/40] Iter[214/312]		Loss: 0.1114
2019-10-28 15:42:39,291 Training Epoch [32/40] Iter[215/312]		Loss: 0.1112
2019-10-28 15:42:39,371 Training Epoch [32/40] Iter[216/312]		Loss: 0.1112
2019-10-28 15:42:39,451 Training Epoch [32/40] Iter[217/312]		Loss: 0.1111
2019-10-28 15:42:39,530 Training Epoch [32/40] Iter[218/312]		Loss: 0.1110
2019-10-28 15:42:39,610 Training Epoch [32/40] Iter[219/312]		Loss: 0.1113
2019-10-28 15:42:39,690 Training Epoch [32/40] Iter[220/312]		Loss: 0.1111
2019-10-28 15:42:39,769 Training Epoch [32/40] Iter[221/312]		Loss: 0.1112
2019-10-28 15:42:39,848 Training Epoch [32/40] Iter[222/312]		Loss: 0.1112
2019-10-28 15:42:39,928 Training Epoch [32/40] Iter[223/312]		Loss: 0.1113
2019-10-28 15:42:40,007 Training Epoch [32/40] Iter[224/312]		Loss: 0.1112
2019-10-28 15:42:40,086 Training Epoch [32/40] Iter[225/312]		Loss: 0.1112
2019-10-28 15:42:40,166 Training Epoch [32/40] Iter[226/312]		Loss: 0.1112
2019-10-28 15:42:40,246 Training Epoch [32/40] Iter[227/312]		Loss: 0.1114
2019-10-28 15:42:40,325 Training Epoch [32/40] Iter[228/312]		Loss: 0.1113
2019-10-28 15:42:40,404 Training Epoch [32/40] Iter[229/312]		Loss: 0.1116
2019-10-28 15:42:40,484 Training Epoch [32/40] Iter[230/312]		Loss: 0.1120
2019-10-28 15:42:40,564 Training Epoch [32/40] Iter[231/312]		Loss: 0.1121
2019-10-28 15:42:40,644 Training Epoch [32/40] Iter[232/312]		Loss: 0.1118
2019-10-28 15:42:40,723 Training Epoch [32/40] Iter[233/312]		Loss: 0.1117
2019-10-28 15:42:40,803 Training Epoch [32/40] Iter[234/312]		Loss: 0.1116
2019-10-28 15:42:40,882 Training Epoch [32/40] Iter[235/312]		Loss: 0.1116
2019-10-28 15:42:40,962 Training Epoch [32/40] Iter[236/312]		Loss: 0.1116
2019-10-28 15:42:41,041 Training Epoch [32/40] Iter[237/312]		Loss: 0.1115
2019-10-28 15:42:41,121 Training Epoch [32/40] Iter[238/312]		Loss: 0.1114
2019-10-28 15:42:41,200 Training Epoch [32/40] Iter[239/312]		Loss: 0.1116
2019-10-28 15:42:41,280 Training Epoch [32/40] Iter[240/312]		Loss: 0.1115
2019-10-28 15:42:41,360 Training Epoch [32/40] Iter[241/312]		Loss: 0.1114
2019-10-28 15:42:41,440 Training Epoch [32/40] Iter[242/312]		Loss: 0.1114
2019-10-28 15:42:41,519 Training Epoch [32/40] Iter[243/312]		Loss: 0.1115
2019-10-28 15:42:41,599 Training Epoch [32/40] Iter[244/312]		Loss: 0.1115
2019-10-28 15:42:41,678 Training Epoch [32/40] Iter[245/312]		Loss: 0.1114
2019-10-28 15:42:41,758 Training Epoch [32/40] Iter[246/312]		Loss: 0.1114
2019-10-28 15:42:41,837 Training Epoch [32/40] Iter[247/312]		Loss: 0.1114
2019-10-28 15:42:41,916 Training Epoch [32/40] Iter[248/312]		Loss: 0.1114
2019-10-28 15:42:41,996 Training Epoch [32/40] Iter[249/312]		Loss: 0.1113
2019-10-28 15:42:42,075 Training Epoch [32/40] Iter[250/312]		Loss: 0.1114
2019-10-28 15:42:42,156 Training Epoch [32/40] Iter[251/312]		Loss: 0.1116
2019-10-28 15:42:42,235 Training Epoch [32/40] Iter[252/312]		Loss: 0.1115
2019-10-28 15:42:42,314 Training Epoch [32/40] Iter[253/312]		Loss: 0.1114
2019-10-28 15:42:42,394 Training Epoch [32/40] Iter[254/312]		Loss: 0.1114
2019-10-28 15:42:42,473 Training Epoch [32/40] Iter[255/312]		Loss: 0.1114
2019-10-28 15:42:42,553 Training Epoch [32/40] Iter[256/312]		Loss: 0.1113
2019-10-28 15:42:42,632 Training Epoch [32/40] Iter[257/312]		Loss: 0.1112
2019-10-28 15:42:42,712 Training Epoch [32/40] Iter[258/312]		Loss: 0.1112
2019-10-28 15:42:42,791 Training Epoch [32/40] Iter[259/312]		Loss: 0.1111
2019-10-28 15:42:42,870 Training Epoch [32/40] Iter[260/312]		Loss: 0.1110
2019-10-28 15:42:42,949 Training Epoch [32/40] Iter[261/312]		Loss: 0.1109
2019-10-28 15:42:43,029 Training Epoch [32/40] Iter[262/312]		Loss: 0.1110
2019-10-28 15:42:43,108 Training Epoch [32/40] Iter[263/312]		Loss: 0.1108
2019-10-28 15:42:43,187 Training Epoch [32/40] Iter[264/312]		Loss: 0.1110
2019-10-28 15:42:43,266 Training Epoch [32/40] Iter[265/312]		Loss: 0.1111
2019-10-28 15:42:43,346 Training Epoch [32/40] Iter[266/312]		Loss: 0.1112
2019-10-28 15:42:43,425 Training Epoch [32/40] Iter[267/312]		Loss: 0.1115
2019-10-28 15:42:43,505 Training Epoch [32/40] Iter[268/312]		Loss: 0.1116
2019-10-28 15:42:43,584 Training Epoch [32/40] Iter[269/312]		Loss: 0.1116
2019-10-28 15:42:43,663 Training Epoch [32/40] Iter[270/312]		Loss: 0.1115
2019-10-28 15:42:43,743 Training Epoch [32/40] Iter[271/312]		Loss: 0.1115
2019-10-28 15:42:43,822 Training Epoch [32/40] Iter[272/312]		Loss: 0.1114
2019-10-28 15:42:43,901 Training Epoch [32/40] Iter[273/312]		Loss: 0.1112
2019-10-28 15:42:43,980 Training Epoch [32/40] Iter[274/312]		Loss: 0.1112
2019-10-28 15:42:44,059 Training Epoch [32/40] Iter[275/312]		Loss: 0.1110
2019-10-28 15:42:44,138 Training Epoch [32/40] Iter[276/312]		Loss: 0.1110
2019-10-28 15:42:44,218 Training Epoch [32/40] Iter[277/312]		Loss: 0.1109
2019-10-28 15:42:44,297 Training Epoch [32/40] Iter[278/312]		Loss: 0.1108
2019-10-28 15:42:44,376 Training Epoch [32/40] Iter[279/312]		Loss: 0.1110
2019-10-28 15:42:44,455 Training Epoch [32/40] Iter[280/312]		Loss: 0.1110
2019-10-28 15:42:44,535 Training Epoch [32/40] Iter[281/312]		Loss: 0.1110
2019-10-28 15:42:44,614 Training Epoch [32/40] Iter[282/312]		Loss: 0.1116
2019-10-28 15:42:44,694 Training Epoch [32/40] Iter[283/312]		Loss: 0.1115
2019-10-28 15:42:44,773 Training Epoch [32/40] Iter[284/312]		Loss: 0.1114
2019-10-28 15:42:44,852 Training Epoch [32/40] Iter[285/312]		Loss: 0.1113
2019-10-28 15:42:44,932 Training Epoch [32/40] Iter[286/312]		Loss: 0.1115
2019-10-28 15:42:45,011 Training Epoch [32/40] Iter[287/312]		Loss: 0.1114
2019-10-28 15:42:45,090 Training Epoch [32/40] Iter[288/312]		Loss: 0.1118
2019-10-28 15:42:45,170 Training Epoch [32/40] Iter[289/312]		Loss: 0.1117
2019-10-28 15:42:45,250 Training Epoch [32/40] Iter[290/312]		Loss: 0.1116
2019-10-28 15:42:45,330 Training Epoch [32/40] Iter[291/312]		Loss: 0.1117
2019-10-28 15:42:45,410 Training Epoch [32/40] Iter[292/312]		Loss: 0.1117
2019-10-28 15:42:45,489 Training Epoch [32/40] Iter[293/312]		Loss: 0.1117
2019-10-28 15:42:45,569 Training Epoch [32/40] Iter[294/312]		Loss: 0.1118
2019-10-28 15:42:45,649 Training Epoch [32/40] Iter[295/312]		Loss: 0.1118
2019-10-28 15:42:45,729 Training Epoch [32/40] Iter[296/312]		Loss: 0.1117
2019-10-28 15:42:45,808 Training Epoch [32/40] Iter[297/312]		Loss: 0.1117
2019-10-28 15:42:45,888 Training Epoch [32/40] Iter[298/312]		Loss: 0.1119
2019-10-28 15:42:45,968 Training Epoch [32/40] Iter[299/312]		Loss: 0.1120
2019-10-28 15:42:46,047 Training Epoch [32/40] Iter[300/312]		Loss: 0.1119
2019-10-28 15:42:46,127 Training Epoch [32/40] Iter[301/312]		Loss: 0.1119
2019-10-28 15:42:46,206 Training Epoch [32/40] Iter[302/312]		Loss: 0.1123
2019-10-28 15:42:46,286 Training Epoch [32/40] Iter[303/312]		Loss: 0.1122
2019-10-28 15:42:46,366 Training Epoch [32/40] Iter[304/312]		Loss: 0.1122
2019-10-28 15:42:46,445 Training Epoch [32/40] Iter[305/312]		Loss: 0.1121
2019-10-28 15:42:46,524 Training Epoch [32/40] Iter[306/312]		Loss: 0.1122
2019-10-28 15:42:46,603 Training Epoch [32/40] Iter[307/312]		Loss: 0.1123
2019-10-28 15:42:46,682 Training Epoch [32/40] Iter[308/312]		Loss: 0.1123
2019-10-28 15:42:46,761 Training Epoch [32/40] Iter[309/312]		Loss: 0.1123
2019-10-28 15:42:46,840 Training Epoch [32/40] Iter[310/312]		Loss: 0.1122
2019-10-28 15:42:46,919 Training Epoch [32/40] Iter[311/312]		Loss: 0.1123
2019-10-28 15:42:46,958 Training Epoch [32/40] Iter[312/312]		Loss: 0.1122
2019-10-28 15:42:47,401 Testing Epoch [32/40] Iter[0/62]		Loss: 0.1297
2019-10-28 15:42:47,434 Testing Epoch [32/40] Iter[1/62]		Loss: 0.1291
2019-10-28 15:42:47,470 Testing Epoch [32/40] Iter[2/62]		Loss: 0.1115
2019-10-28 15:42:47,497 Testing Epoch [32/40] Iter[3/62]		Loss: 0.1157
2019-10-28 15:42:47,519 Testing Epoch [32/40] Iter[4/62]		Loss: 0.1197
2019-10-28 15:42:47,536 Testing Epoch [32/40] Iter[5/62]		Loss: 0.1152
2019-10-28 15:42:47,555 Testing Epoch [32/40] Iter[6/62]		Loss: 0.1166
2019-10-28 15:42:47,585 Testing Epoch [32/40] Iter[7/62]		Loss: 0.1191
2019-10-28 15:42:47,614 Testing Epoch [32/40] Iter[8/62]		Loss: 0.1216
2019-10-28 15:42:47,634 Testing Epoch [32/40] Iter[9/62]		Loss: 0.1205
2019-10-28 15:42:47,650 Testing Epoch [32/40] Iter[10/62]		Loss: 0.1210
2019-10-28 15:42:47,668 Testing Epoch [32/40] Iter[11/62]		Loss: 0.1272
2019-10-28 15:42:47,698 Testing Epoch [32/40] Iter[12/62]		Loss: 0.1271
2019-10-28 15:42:47,722 Testing Epoch [32/40] Iter[13/62]		Loss: 0.1291
2019-10-28 15:42:47,741 Testing Epoch [32/40] Iter[14/62]		Loss: 0.1424
2019-10-28 15:42:47,769 Testing Epoch [32/40] Iter[15/62]		Loss: 0.1446
2019-10-28 15:42:47,787 Testing Epoch [32/40] Iter[16/62]		Loss: 0.1416
2019-10-28 15:42:47,805 Testing Epoch [32/40] Iter[17/62]		Loss: 0.1418
2019-10-28 15:42:47,834 Testing Epoch [32/40] Iter[18/62]		Loss: 0.1395
2019-10-28 15:42:47,856 Testing Epoch [32/40] Iter[19/62]		Loss: 0.1375
2019-10-28 15:42:47,874 Testing Epoch [32/40] Iter[20/62]		Loss: 0.1395
2019-10-28 15:42:47,892 Testing Epoch [32/40] Iter[21/62]		Loss: 0.1377
2019-10-28 15:42:47,910 Testing Epoch [32/40] Iter[22/62]		Loss: 0.1392
2019-10-28 15:42:47,935 Testing Epoch [32/40] Iter[23/62]		Loss: 0.1382
2019-10-28 15:42:47,970 Testing Epoch [32/40] Iter[24/62]		Loss: 0.1413
2019-10-28 15:42:47,989 Testing Epoch [32/40] Iter[25/62]		Loss: 0.1404
2019-10-28 15:42:48,006 Testing Epoch [32/40] Iter[26/62]		Loss: 0.1393
2019-10-28 15:42:48,034 Testing Epoch [32/40] Iter[27/62]		Loss: 0.1472
2019-10-28 15:42:48,050 Testing Epoch [32/40] Iter[28/62]		Loss: 0.1507
2019-10-28 15:42:48,068 Testing Epoch [32/40] Iter[29/62]		Loss: 0.1508
2019-10-28 15:42:48,086 Testing Epoch [32/40] Iter[30/62]		Loss: 0.1509
2019-10-28 15:42:48,107 Testing Epoch [32/40] Iter[31/62]		Loss: 0.1497
2019-10-28 15:42:48,137 Testing Epoch [32/40] Iter[32/62]		Loss: 0.1514
2019-10-28 15:42:48,165 Testing Epoch [32/40] Iter[33/62]		Loss: 0.1503
2019-10-28 15:42:48,185 Testing Epoch [32/40] Iter[34/62]		Loss: 0.1526
2019-10-28 15:42:48,201 Testing Epoch [32/40] Iter[35/62]		Loss: 0.1520
2019-10-28 15:42:48,229 Testing Epoch [32/40] Iter[36/62]		Loss: 0.1500
2019-10-28 15:42:48,251 Testing Epoch [32/40] Iter[37/62]		Loss: 0.1489
2019-10-28 15:42:48,269 Testing Epoch [32/40] Iter[38/62]		Loss: 0.1477
2019-10-28 15:42:48,287 Testing Epoch [32/40] Iter[39/62]		Loss: 0.1480
2019-10-28 15:42:48,314 Testing Epoch [32/40] Iter[40/62]		Loss: 0.1497
2019-10-28 15:42:48,332 Testing Epoch [32/40] Iter[41/62]		Loss: 0.1512
2019-10-28 15:42:48,358 Testing Epoch [32/40] Iter[42/62]		Loss: 0.1493
2019-10-28 15:42:48,375 Testing Epoch [32/40] Iter[43/62]		Loss: 0.1487
2019-10-28 15:42:48,393 Testing Epoch [32/40] Iter[44/62]		Loss: 0.1471
2019-10-28 15:42:48,421 Testing Epoch [32/40] Iter[45/62]		Loss: 0.1469
2019-10-28 15:42:48,443 Testing Epoch [32/40] Iter[46/62]		Loss: 0.1467
2019-10-28 15:42:48,461 Testing Epoch [32/40] Iter[47/62]		Loss: 0.1526
2019-10-28 15:42:48,484 Testing Epoch [32/40] Iter[48/62]		Loss: 0.1516
2019-10-28 15:42:48,503 Testing Epoch [32/40] Iter[49/62]		Loss: 0.1539
2019-10-28 15:42:48,530 Testing Epoch [32/40] Iter[50/62]		Loss: 0.1530
2019-10-28 15:42:48,547 Testing Epoch [32/40] Iter[51/62]		Loss: 0.1529
2019-10-28 15:42:48,565 Testing Epoch [32/40] Iter[52/62]		Loss: 0.1517
2019-10-28 15:42:48,594 Testing Epoch [32/40] Iter[53/62]		Loss: 0.1521
2019-10-28 15:42:48,612 Testing Epoch [32/40] Iter[54/62]		Loss: 0.1509
2019-10-28 15:42:48,629 Testing Epoch [32/40] Iter[55/62]		Loss: 0.1505
2019-10-28 15:42:48,646 Testing Epoch [32/40] Iter[56/62]		Loss: 0.1498
2019-10-28 15:42:48,663 Testing Epoch [32/40] Iter[57/62]		Loss: 0.1501
2019-10-28 15:42:48,679 Testing Epoch [32/40] Iter[58/62]		Loss: 0.1495
2019-10-28 15:42:48,696 Testing Epoch [32/40] Iter[59/62]		Loss: 0.1505
2019-10-28 15:42:48,712 Testing Epoch [32/40] Iter[60/62]		Loss: 0.1496
2019-10-28 15:42:48,729 Testing Epoch [32/40] Iter[61/62]		Loss: 0.1495
2019-10-28 15:42:48,739 Testing Epoch [32/40] Iter[62/62]		Loss: 0.1504
2019-10-28 15:42:49,234 Training Epoch [33/40] Iter[0/312]		Loss: 0.0869
2019-10-28 15:42:49,316 Training Epoch [33/40] Iter[1/312]		Loss: 0.1121
2019-10-28 15:42:49,394 Training Epoch [33/40] Iter[2/312]		Loss: 0.1047
2019-10-28 15:42:49,472 Training Epoch [33/40] Iter[3/312]		Loss: 0.0954
2019-10-28 15:42:49,550 Training Epoch [33/40] Iter[4/312]		Loss: 0.0921
2019-10-28 15:42:49,629 Training Epoch [33/40] Iter[5/312]		Loss: 0.1052
2019-10-28 15:42:49,709 Training Epoch [33/40] Iter[6/312]		Loss: 0.1003
2019-10-28 15:42:49,786 Training Epoch [33/40] Iter[7/312]		Loss: 0.1090
2019-10-28 15:42:49,866 Training Epoch [33/40] Iter[8/312]		Loss: 0.1108
2019-10-28 15:42:49,945 Training Epoch [33/40] Iter[9/312]		Loss: 0.1102
2019-10-28 15:42:50,024 Training Epoch [33/40] Iter[10/312]		Loss: 0.1092
2019-10-28 15:42:50,103 Training Epoch [33/40] Iter[11/312]		Loss: 0.1080
2019-10-28 15:42:50,183 Training Epoch [33/40] Iter[12/312]		Loss: 0.1087
2019-10-28 15:42:50,262 Training Epoch [33/40] Iter[13/312]		Loss: 0.1129
2019-10-28 15:42:50,341 Training Epoch [33/40] Iter[14/312]		Loss: 0.1101
2019-10-28 15:42:50,420 Training Epoch [33/40] Iter[15/312]		Loss: 0.1078
2019-10-28 15:42:50,500 Training Epoch [33/40] Iter[16/312]		Loss: 0.1108
2019-10-28 15:42:50,579 Training Epoch [33/40] Iter[17/312]		Loss: 0.1129
2019-10-28 15:42:50,658 Training Epoch [33/40] Iter[18/312]		Loss: 0.1118
2019-10-28 15:42:50,737 Training Epoch [33/40] Iter[19/312]		Loss: 0.1112
2019-10-28 15:42:50,816 Training Epoch [33/40] Iter[20/312]		Loss: 0.1131
2019-10-28 15:42:50,895 Training Epoch [33/40] Iter[21/312]		Loss: 0.1127
2019-10-28 15:42:50,974 Training Epoch [33/40] Iter[22/312]		Loss: 0.1128
2019-10-28 15:42:51,053 Training Epoch [33/40] Iter[23/312]		Loss: 0.1121
2019-10-28 15:42:51,133 Training Epoch [33/40] Iter[24/312]		Loss: 0.1143
2019-10-28 15:42:51,212 Training Epoch [33/40] Iter[25/312]		Loss: 0.1126
2019-10-28 15:42:51,292 Training Epoch [33/40] Iter[26/312]		Loss: 0.1127
2019-10-28 15:42:51,371 Training Epoch [33/40] Iter[27/312]		Loss: 0.1147
2019-10-28 15:42:51,451 Training Epoch [33/40] Iter[28/312]		Loss: 0.1140
2019-10-28 15:42:51,531 Training Epoch [33/40] Iter[29/312]		Loss: 0.1136
2019-10-28 15:42:51,610 Training Epoch [33/40] Iter[30/312]		Loss: 0.1140
2019-10-28 15:42:51,690 Training Epoch [33/40] Iter[31/312]		Loss: 0.1122
2019-10-28 15:42:51,769 Training Epoch [33/40] Iter[32/312]		Loss: 0.1113
2019-10-28 15:42:51,848 Training Epoch [33/40] Iter[33/312]		Loss: 0.1112
2019-10-28 15:42:51,928 Training Epoch [33/40] Iter[34/312]		Loss: 0.1107
2019-10-28 15:42:52,007 Training Epoch [33/40] Iter[35/312]		Loss: 0.1110
2019-10-28 15:42:52,087 Training Epoch [33/40] Iter[36/312]		Loss: 0.1096
2019-10-28 15:42:52,166 Training Epoch [33/40] Iter[37/312]		Loss: 0.1088
2019-10-28 15:42:52,245 Training Epoch [33/40] Iter[38/312]		Loss: 0.1088
2019-10-28 15:42:52,325 Training Epoch [33/40] Iter[39/312]		Loss: 0.1081
2019-10-28 15:42:52,404 Training Epoch [33/40] Iter[40/312]		Loss: 0.1076
2019-10-28 15:42:52,483 Training Epoch [33/40] Iter[41/312]		Loss: 0.1085
2019-10-28 15:42:52,562 Training Epoch [33/40] Iter[42/312]		Loss: 0.1081
2019-10-28 15:42:52,641 Training Epoch [33/40] Iter[43/312]		Loss: 0.1083
2019-10-28 15:42:52,720 Training Epoch [33/40] Iter[44/312]		Loss: 0.1083
2019-10-28 15:42:52,799 Training Epoch [33/40] Iter[45/312]		Loss: 0.1081
2019-10-28 15:42:52,878 Training Epoch [33/40] Iter[46/312]		Loss: 0.1072
2019-10-28 15:42:52,957 Training Epoch [33/40] Iter[47/312]		Loss: 0.1071
2019-10-28 15:42:53,036 Training Epoch [33/40] Iter[48/312]		Loss: 0.1083
2019-10-28 15:42:53,116 Training Epoch [33/40] Iter[49/312]		Loss: 0.1099
2019-10-28 15:42:53,195 Training Epoch [33/40] Iter[50/312]		Loss: 0.1109
2019-10-28 15:42:53,274 Training Epoch [33/40] Iter[51/312]		Loss: 0.1114
2019-10-28 15:42:53,354 Training Epoch [33/40] Iter[52/312]		Loss: 0.1112
2019-10-28 15:42:53,433 Training Epoch [33/40] Iter[53/312]		Loss: 0.1108
2019-10-28 15:42:53,512 Training Epoch [33/40] Iter[54/312]		Loss: 0.1110
2019-10-28 15:42:53,592 Training Epoch [33/40] Iter[55/312]		Loss: 0.1115
2019-10-28 15:42:53,671 Training Epoch [33/40] Iter[56/312]		Loss: 0.1112
2019-10-28 15:42:53,750 Training Epoch [33/40] Iter[57/312]		Loss: 0.1110
2019-10-28 15:42:53,830 Training Epoch [33/40] Iter[58/312]		Loss: 0.1107
2019-10-28 15:42:53,909 Training Epoch [33/40] Iter[59/312]		Loss: 0.1119
2019-10-28 15:42:53,988 Training Epoch [33/40] Iter[60/312]		Loss: 0.1120
2019-10-28 15:42:54,068 Training Epoch [33/40] Iter[61/312]		Loss: 0.1114
2019-10-28 15:42:54,147 Training Epoch [33/40] Iter[62/312]		Loss: 0.1117
2019-10-28 15:42:54,226 Training Epoch [33/40] Iter[63/312]		Loss: 0.1113
2019-10-28 15:42:54,305 Training Epoch [33/40] Iter[64/312]		Loss: 0.1110
2019-10-28 15:42:54,385 Training Epoch [33/40] Iter[65/312]		Loss: 0.1119
2019-10-28 15:42:54,464 Training Epoch [33/40] Iter[66/312]		Loss: 0.1117
2019-10-28 15:42:54,543 Training Epoch [33/40] Iter[67/312]		Loss: 0.1121
2019-10-28 15:42:54,623 Training Epoch [33/40] Iter[68/312]		Loss: 0.1136
2019-10-28 15:42:54,702 Training Epoch [33/40] Iter[69/312]		Loss: 0.1134
2019-10-28 15:42:54,781 Training Epoch [33/40] Iter[70/312]		Loss: 0.1131
2019-10-28 15:42:54,860 Training Epoch [33/40] Iter[71/312]		Loss: 0.1134
2019-10-28 15:42:54,939 Training Epoch [33/40] Iter[72/312]		Loss: 0.1130
2019-10-28 15:42:55,019 Training Epoch [33/40] Iter[73/312]		Loss: 0.1125
2019-10-28 15:42:55,098 Training Epoch [33/40] Iter[74/312]		Loss: 0.1124
2019-10-28 15:42:55,177 Training Epoch [33/40] Iter[75/312]		Loss: 0.1124
2019-10-28 15:42:55,256 Training Epoch [33/40] Iter[76/312]		Loss: 0.1126
2019-10-28 15:42:55,335 Training Epoch [33/40] Iter[77/312]		Loss: 0.1137
2019-10-28 15:42:55,419 Training Epoch [33/40] Iter[78/312]		Loss: 0.1135
2019-10-28 15:42:55,498 Training Epoch [33/40] Iter[79/312]		Loss: 0.1133
2019-10-28 15:42:55,582 Training Epoch [33/40] Iter[80/312]		Loss: 0.1132
2019-10-28 15:42:55,662 Training Epoch [33/40] Iter[81/312]		Loss: 0.1134
2019-10-28 15:42:55,747 Training Epoch [33/40] Iter[82/312]		Loss: 0.1135
2019-10-28 15:42:55,831 Training Epoch [33/40] Iter[83/312]		Loss: 0.1128
2019-10-28 15:42:55,915 Training Epoch [33/40] Iter[84/312]		Loss: 0.1125
2019-10-28 15:42:55,995 Training Epoch [33/40] Iter[85/312]		Loss: 0.1124
2019-10-28 15:42:56,074 Training Epoch [33/40] Iter[86/312]		Loss: 0.1124
2019-10-28 15:42:56,153 Training Epoch [33/40] Iter[87/312]		Loss: 0.1127
2019-10-28 15:42:56,232 Training Epoch [33/40] Iter[88/312]		Loss: 0.1125
2019-10-28 15:42:56,311 Training Epoch [33/40] Iter[89/312]		Loss: 0.1123
2019-10-28 15:42:56,391 Training Epoch [33/40] Iter[90/312]		Loss: 0.1121
2019-10-28 15:42:56,470 Training Epoch [33/40] Iter[91/312]		Loss: 0.1121
2019-10-28 15:42:56,549 Training Epoch [33/40] Iter[92/312]		Loss: 0.1119
2019-10-28 15:42:56,628 Training Epoch [33/40] Iter[93/312]		Loss: 0.1120
2019-10-28 15:42:56,707 Training Epoch [33/40] Iter[94/312]		Loss: 0.1125
2019-10-28 15:42:56,786 Training Epoch [33/40] Iter[95/312]		Loss: 0.1128
2019-10-28 15:42:56,865 Training Epoch [33/40] Iter[96/312]		Loss: 0.1131
2019-10-28 15:42:56,945 Training Epoch [33/40] Iter[97/312]		Loss: 0.1128
2019-10-28 15:42:57,024 Training Epoch [33/40] Iter[98/312]		Loss: 0.1125
2019-10-28 15:42:57,103 Training Epoch [33/40] Iter[99/312]		Loss: 0.1123
2019-10-28 15:42:57,182 Training Epoch [33/40] Iter[100/312]		Loss: 0.1120
2019-10-28 15:42:57,261 Training Epoch [33/40] Iter[101/312]		Loss: 0.1123
2019-10-28 15:42:57,340 Training Epoch [33/40] Iter[102/312]		Loss: 0.1123
2019-10-28 15:42:57,420 Training Epoch [33/40] Iter[103/312]		Loss: 0.1126
2019-10-28 15:42:57,500 Training Epoch [33/40] Iter[104/312]		Loss: 0.1123
2019-10-28 15:42:57,579 Training Epoch [33/40] Iter[105/312]		Loss: 0.1120
2019-10-28 15:42:57,658 Training Epoch [33/40] Iter[106/312]		Loss: 0.1117
2019-10-28 15:42:57,737 Training Epoch [33/40] Iter[107/312]		Loss: 0.1113
2019-10-28 15:42:57,816 Training Epoch [33/40] Iter[108/312]		Loss: 0.1110
2019-10-28 15:42:57,896 Training Epoch [33/40] Iter[109/312]		Loss: 0.1107
2019-10-28 15:42:57,975 Training Epoch [33/40] Iter[110/312]		Loss: 0.1113
2019-10-28 15:42:58,054 Training Epoch [33/40] Iter[111/312]		Loss: 0.1111
2019-10-28 15:42:58,133 Training Epoch [33/40] Iter[112/312]		Loss: 0.1115
2019-10-28 15:42:58,213 Training Epoch [33/40] Iter[113/312]		Loss: 0.1113
2019-10-28 15:42:58,292 Training Epoch [33/40] Iter[114/312]		Loss: 0.1113
2019-10-28 15:42:58,371 Training Epoch [33/40] Iter[115/312]		Loss: 0.1113
2019-10-28 15:42:58,451 Training Epoch [33/40] Iter[116/312]		Loss: 0.1110
2019-10-28 15:42:58,530 Training Epoch [33/40] Iter[117/312]		Loss: 0.1106
2019-10-28 15:42:58,609 Training Epoch [33/40] Iter[118/312]		Loss: 0.1106
2019-10-28 15:42:58,689 Training Epoch [33/40] Iter[119/312]		Loss: 0.1105
2019-10-28 15:42:58,768 Training Epoch [33/40] Iter[120/312]		Loss: 0.1105
2019-10-28 15:42:58,847 Training Epoch [33/40] Iter[121/312]		Loss: 0.1108
2019-10-28 15:42:58,926 Training Epoch [33/40] Iter[122/312]		Loss: 0.1106
2019-10-28 15:42:59,005 Training Epoch [33/40] Iter[123/312]		Loss: 0.1108
2019-10-28 15:42:59,085 Training Epoch [33/40] Iter[124/312]		Loss: 0.1107
2019-10-28 15:42:59,164 Training Epoch [33/40] Iter[125/312]		Loss: 0.1103
2019-10-28 15:42:59,243 Training Epoch [33/40] Iter[126/312]		Loss: 0.1099
2019-10-28 15:42:59,323 Training Epoch [33/40] Iter[127/312]		Loss: 0.1096
2019-10-28 15:42:59,402 Training Epoch [33/40] Iter[128/312]		Loss: 0.1093
2019-10-28 15:42:59,481 Training Epoch [33/40] Iter[129/312]		Loss: 0.1094
2019-10-28 15:42:59,560 Training Epoch [33/40] Iter[130/312]		Loss: 0.1094
2019-10-28 15:42:59,639 Training Epoch [33/40] Iter[131/312]		Loss: 0.1093
2019-10-28 15:42:59,719 Training Epoch [33/40] Iter[132/312]		Loss: 0.1100
2019-10-28 15:42:59,797 Training Epoch [33/40] Iter[133/312]		Loss: 0.1097
2019-10-28 15:42:59,876 Training Epoch [33/40] Iter[134/312]		Loss: 0.1107
2019-10-28 15:42:59,956 Training Epoch [33/40] Iter[135/312]		Loss: 0.1107
2019-10-28 15:43:00,035 Training Epoch [33/40] Iter[136/312]		Loss: 0.1108
2019-10-28 15:43:00,114 Training Epoch [33/40] Iter[137/312]		Loss: 0.1111
2019-10-28 15:43:00,193 Training Epoch [33/40] Iter[138/312]		Loss: 0.1111
2019-10-28 15:43:00,272 Training Epoch [33/40] Iter[139/312]		Loss: 0.1109
2019-10-28 15:43:00,351 Training Epoch [33/40] Iter[140/312]		Loss: 0.1112
2019-10-28 15:43:00,430 Training Epoch [33/40] Iter[141/312]		Loss: 0.1113
2019-10-28 15:43:00,509 Training Epoch [33/40] Iter[142/312]		Loss: 0.1114
2019-10-28 15:43:00,588 Training Epoch [33/40] Iter[143/312]		Loss: 0.1119
2019-10-28 15:43:00,667 Training Epoch [33/40] Iter[144/312]		Loss: 0.1118
2019-10-28 15:43:00,746 Training Epoch [33/40] Iter[145/312]		Loss: 0.1119
2019-10-28 15:43:00,825 Training Epoch [33/40] Iter[146/312]		Loss: 0.1120
2019-10-28 15:43:00,904 Training Epoch [33/40] Iter[147/312]		Loss: 0.1119
2019-10-28 15:43:00,983 Training Epoch [33/40] Iter[148/312]		Loss: 0.1117
2019-10-28 15:43:01,062 Training Epoch [33/40] Iter[149/312]		Loss: 0.1116
2019-10-28 15:43:01,142 Training Epoch [33/40] Iter[150/312]		Loss: 0.1114
2019-10-28 15:43:01,221 Training Epoch [33/40] Iter[151/312]		Loss: 0.1117
2019-10-28 15:43:01,300 Training Epoch [33/40] Iter[152/312]		Loss: 0.1117
2019-10-28 15:43:01,379 Training Epoch [33/40] Iter[153/312]		Loss: 0.1118
2019-10-28 15:43:01,458 Training Epoch [33/40] Iter[154/312]		Loss: 0.1117
2019-10-28 15:43:01,537 Training Epoch [33/40] Iter[155/312]		Loss: 0.1117
2019-10-28 15:43:01,616 Training Epoch [33/40] Iter[156/312]		Loss: 0.1115
2019-10-28 15:43:01,696 Training Epoch [33/40] Iter[157/312]		Loss: 0.1113
2019-10-28 15:43:01,775 Training Epoch [33/40] Iter[158/312]		Loss: 0.1118
2019-10-28 15:43:01,854 Training Epoch [33/40] Iter[159/312]		Loss: 0.1117
2019-10-28 15:43:01,933 Training Epoch [33/40] Iter[160/312]		Loss: 0.1120
2019-10-28 15:43:02,012 Training Epoch [33/40] Iter[161/312]		Loss: 0.1119
2019-10-28 15:43:02,092 Training Epoch [33/40] Iter[162/312]		Loss: 0.1120
2019-10-28 15:43:02,171 Training Epoch [33/40] Iter[163/312]		Loss: 0.1119
2019-10-28 15:43:02,249 Training Epoch [33/40] Iter[164/312]		Loss: 0.1122
2019-10-28 15:43:02,329 Training Epoch [33/40] Iter[165/312]		Loss: 0.1120
2019-10-28 15:43:02,408 Training Epoch [33/40] Iter[166/312]		Loss: 0.1122
2019-10-28 15:43:02,487 Training Epoch [33/40] Iter[167/312]		Loss: 0.1127
2019-10-28 15:43:02,566 Training Epoch [33/40] Iter[168/312]		Loss: 0.1125
2019-10-28 15:43:02,646 Training Epoch [33/40] Iter[169/312]		Loss: 0.1123
2019-10-28 15:43:02,725 Training Epoch [33/40] Iter[170/312]		Loss: 0.1122
2019-10-28 15:43:02,804 Training Epoch [33/40] Iter[171/312]		Loss: 0.1121
2019-10-28 15:43:02,883 Training Epoch [33/40] Iter[172/312]		Loss: 0.1121
2019-10-28 15:43:02,962 Training Epoch [33/40] Iter[173/312]		Loss: 0.1119
2019-10-28 15:43:03,041 Training Epoch [33/40] Iter[174/312]		Loss: 0.1118
2019-10-28 15:43:03,121 Training Epoch [33/40] Iter[175/312]		Loss: 0.1118
2019-10-28 15:43:03,200 Training Epoch [33/40] Iter[176/312]		Loss: 0.1120
2019-10-28 15:43:03,280 Training Epoch [33/40] Iter[177/312]		Loss: 0.1119
2019-10-28 15:43:03,359 Training Epoch [33/40] Iter[178/312]		Loss: 0.1117
2019-10-28 15:43:03,439 Training Epoch [33/40] Iter[179/312]		Loss: 0.1117
2019-10-28 15:43:03,518 Training Epoch [33/40] Iter[180/312]		Loss: 0.1118
2019-10-28 15:43:03,597 Training Epoch [33/40] Iter[181/312]		Loss: 0.1116
2019-10-28 15:43:03,677 Training Epoch [33/40] Iter[182/312]		Loss: 0.1117
2019-10-28 15:43:03,756 Training Epoch [33/40] Iter[183/312]		Loss: 0.1116
2019-10-28 15:43:03,835 Training Epoch [33/40] Iter[184/312]		Loss: 0.1115
2019-10-28 15:43:03,914 Training Epoch [33/40] Iter[185/312]		Loss: 0.1116
2019-10-28 15:43:03,994 Training Epoch [33/40] Iter[186/312]		Loss: 0.1120
2019-10-28 15:43:04,073 Training Epoch [33/40] Iter[187/312]		Loss: 0.1123
2019-10-28 15:43:04,152 Training Epoch [33/40] Iter[188/312]		Loss: 0.1120
2019-10-28 15:43:04,231 Training Epoch [33/40] Iter[189/312]		Loss: 0.1119
2019-10-28 15:43:04,310 Training Epoch [33/40] Iter[190/312]		Loss: 0.1117
2019-10-28 15:43:04,390 Training Epoch [33/40] Iter[191/312]		Loss: 0.1117
2019-10-28 15:43:04,469 Training Epoch [33/40] Iter[192/312]		Loss: 0.1116
2019-10-28 15:43:04,548 Training Epoch [33/40] Iter[193/312]		Loss: 0.1117
2019-10-28 15:43:04,627 Training Epoch [33/40] Iter[194/312]		Loss: 0.1114
2019-10-28 15:43:04,707 Training Epoch [33/40] Iter[195/312]		Loss: 0.1113
2019-10-28 15:43:04,786 Training Epoch [33/40] Iter[196/312]		Loss: 0.1113
2019-10-28 15:43:04,865 Training Epoch [33/40] Iter[197/312]		Loss: 0.1112
2019-10-28 15:43:04,944 Training Epoch [33/40] Iter[198/312]		Loss: 0.1112
2019-10-28 15:43:05,024 Training Epoch [33/40] Iter[199/312]		Loss: 0.1118
2019-10-28 15:43:05,103 Training Epoch [33/40] Iter[200/312]		Loss: 0.1121
2019-10-28 15:43:05,182 Training Epoch [33/40] Iter[201/312]		Loss: 0.1126
2019-10-28 15:43:05,262 Training Epoch [33/40] Iter[202/312]		Loss: 0.1125
2019-10-28 15:43:05,341 Training Epoch [33/40] Iter[203/312]		Loss: 0.1126
2019-10-28 15:43:05,421 Training Epoch [33/40] Iter[204/312]		Loss: 0.1125
2019-10-28 15:43:05,500 Training Epoch [33/40] Iter[205/312]		Loss: 0.1125
2019-10-28 15:43:05,580 Training Epoch [33/40] Iter[206/312]		Loss: 0.1126
2019-10-28 15:43:05,659 Training Epoch [33/40] Iter[207/312]		Loss: 0.1124
2019-10-28 15:43:05,739 Training Epoch [33/40] Iter[208/312]		Loss: 0.1124
2019-10-28 15:43:05,818 Training Epoch [33/40] Iter[209/312]		Loss: 0.1125
2019-10-28 15:43:05,898 Training Epoch [33/40] Iter[210/312]		Loss: 0.1126
2019-10-28 15:43:05,977 Training Epoch [33/40] Iter[211/312]		Loss: 0.1124
2019-10-28 15:43:06,056 Training Epoch [33/40] Iter[212/312]		Loss: 0.1124
2019-10-28 15:43:06,136 Training Epoch [33/40] Iter[213/312]		Loss: 0.1122
2019-10-28 15:43:06,215 Training Epoch [33/40] Iter[214/312]		Loss: 0.1122
2019-10-28 15:43:06,295 Training Epoch [33/40] Iter[215/312]		Loss: 0.1120
2019-10-28 15:43:06,374 Training Epoch [33/40] Iter[216/312]		Loss: 0.1118
2019-10-28 15:43:06,453 Training Epoch [33/40] Iter[217/312]		Loss: 0.1123
2019-10-28 15:43:06,533 Training Epoch [33/40] Iter[218/312]		Loss: 0.1126
2019-10-28 15:43:06,612 Training Epoch [33/40] Iter[219/312]		Loss: 0.1125
2019-10-28 15:43:06,691 Training Epoch [33/40] Iter[220/312]		Loss: 0.1123
2019-10-28 15:43:06,771 Training Epoch [33/40] Iter[221/312]		Loss: 0.1122
2019-10-28 15:43:06,850 Training Epoch [33/40] Iter[222/312]		Loss: 0.1123
2019-10-28 15:43:06,929 Training Epoch [33/40] Iter[223/312]		Loss: 0.1125
2019-10-28 15:43:07,008 Training Epoch [33/40] Iter[224/312]		Loss: 0.1127
2019-10-28 15:43:07,088 Training Epoch [33/40] Iter[225/312]		Loss: 0.1129
2019-10-28 15:43:07,167 Training Epoch [33/40] Iter[226/312]		Loss: 0.1130
2019-10-28 15:43:07,246 Training Epoch [33/40] Iter[227/312]		Loss: 0.1129
2019-10-28 15:43:07,326 Training Epoch [33/40] Iter[228/312]		Loss: 0.1129
2019-10-28 15:43:07,405 Training Epoch [33/40] Iter[229/312]		Loss: 0.1128
2019-10-28 15:43:07,484 Training Epoch [33/40] Iter[230/312]		Loss: 0.1128
2019-10-28 15:43:07,563 Training Epoch [33/40] Iter[231/312]		Loss: 0.1126
2019-10-28 15:43:07,643 Training Epoch [33/40] Iter[232/312]		Loss: 0.1124
2019-10-28 15:43:07,722 Training Epoch [33/40] Iter[233/312]		Loss: 0.1123
2019-10-28 15:43:07,801 Training Epoch [33/40] Iter[234/312]		Loss: 0.1122
2019-10-28 15:43:07,881 Training Epoch [33/40] Iter[235/312]		Loss: 0.1123
2019-10-28 15:43:07,960 Training Epoch [33/40] Iter[236/312]		Loss: 0.1123
2019-10-28 15:43:08,039 Training Epoch [33/40] Iter[237/312]		Loss: 0.1123
2019-10-28 15:43:08,118 Training Epoch [33/40] Iter[238/312]		Loss: 0.1122
2019-10-28 15:43:08,197 Training Epoch [33/40] Iter[239/312]		Loss: 0.1121
2019-10-28 15:43:08,277 Training Epoch [33/40] Iter[240/312]		Loss: 0.1120
2019-10-28 15:43:08,356 Training Epoch [33/40] Iter[241/312]		Loss: 0.1119
2019-10-28 15:43:08,436 Training Epoch [33/40] Iter[242/312]		Loss: 0.1122
2019-10-28 15:43:08,515 Training Epoch [33/40] Iter[243/312]		Loss: 0.1123
2019-10-28 15:43:08,595 Training Epoch [33/40] Iter[244/312]		Loss: 0.1122
2019-10-28 15:43:08,674 Training Epoch [33/40] Iter[245/312]		Loss: 0.1121
2019-10-28 15:43:08,753 Training Epoch [33/40] Iter[246/312]		Loss: 0.1120
2019-10-28 15:43:08,832 Training Epoch [33/40] Iter[247/312]		Loss: 0.1119
2019-10-28 15:43:08,912 Training Epoch [33/40] Iter[248/312]		Loss: 0.1119
2019-10-28 15:43:08,991 Training Epoch [33/40] Iter[249/312]		Loss: 0.1122
2019-10-28 15:43:09,070 Training Epoch [33/40] Iter[250/312]		Loss: 0.1121
2019-10-28 15:43:09,150 Training Epoch [33/40] Iter[251/312]		Loss: 0.1121
2019-10-28 15:43:09,229 Training Epoch [33/40] Iter[252/312]		Loss: 0.1122
2019-10-28 15:43:09,309 Training Epoch [33/40] Iter[253/312]		Loss: 0.1124
2019-10-28 15:43:09,389 Training Epoch [33/40] Iter[254/312]		Loss: 0.1123
2019-10-28 15:43:09,469 Training Epoch [33/40] Iter[255/312]		Loss: 0.1122
2019-10-28 15:43:09,549 Training Epoch [33/40] Iter[256/312]		Loss: 0.1121
2019-10-28 15:43:09,628 Training Epoch [33/40] Iter[257/312]		Loss: 0.1119
2019-10-28 15:43:09,708 Training Epoch [33/40] Iter[258/312]		Loss: 0.1121
2019-10-28 15:43:09,787 Training Epoch [33/40] Iter[259/312]		Loss: 0.1119
2019-10-28 15:43:09,867 Training Epoch [33/40] Iter[260/312]		Loss: 0.1120
2019-10-28 15:43:09,946 Training Epoch [33/40] Iter[261/312]		Loss: 0.1122
2019-10-28 15:43:10,025 Training Epoch [33/40] Iter[262/312]		Loss: 0.1123
2019-10-28 15:43:10,104 Training Epoch [33/40] Iter[263/312]		Loss: 0.1123
2019-10-28 15:43:10,183 Training Epoch [33/40] Iter[264/312]		Loss: 0.1122
2019-10-28 15:43:10,262 Training Epoch [33/40] Iter[265/312]		Loss: 0.1125
2019-10-28 15:43:10,342 Training Epoch [33/40] Iter[266/312]		Loss: 0.1124
2019-10-28 15:43:10,421 Training Epoch [33/40] Iter[267/312]		Loss: 0.1123
2019-10-28 15:43:10,500 Training Epoch [33/40] Iter[268/312]		Loss: 0.1122
2019-10-28 15:43:10,579 Training Epoch [33/40] Iter[269/312]		Loss: 0.1121
2019-10-28 15:43:10,663 Training Epoch [33/40] Iter[270/312]		Loss: 0.1120
2019-10-28 15:43:10,742 Training Epoch [33/40] Iter[271/312]		Loss: 0.1120
2019-10-28 15:43:10,821 Training Epoch [33/40] Iter[272/312]		Loss: 0.1119
2019-10-28 15:43:10,901 Training Epoch [33/40] Iter[273/312]		Loss: 0.1121
2019-10-28 15:43:10,983 Training Epoch [33/40] Iter[274/312]		Loss: 0.1121
2019-10-28 15:43:11,062 Training Epoch [33/40] Iter[275/312]		Loss: 0.1120
2019-10-28 15:43:11,141 Training Epoch [33/40] Iter[276/312]		Loss: 0.1119
2019-10-28 15:43:11,221 Training Epoch [33/40] Iter[277/312]		Loss: 0.1118
2019-10-28 15:43:11,300 Training Epoch [33/40] Iter[278/312]		Loss: 0.1119
2019-10-28 15:43:11,379 Training Epoch [33/40] Iter[279/312]		Loss: 0.1118
2019-10-28 15:43:11,459 Training Epoch [33/40] Iter[280/312]		Loss: 0.1117
2019-10-28 15:43:11,538 Training Epoch [33/40] Iter[281/312]		Loss: 0.1117
2019-10-28 15:43:11,617 Training Epoch [33/40] Iter[282/312]		Loss: 0.1118
2019-10-28 15:43:11,697 Training Epoch [33/40] Iter[283/312]		Loss: 0.1118
2019-10-28 15:43:11,776 Training Epoch [33/40] Iter[284/312]		Loss: 0.1119
2019-10-28 15:43:11,856 Training Epoch [33/40] Iter[285/312]		Loss: 0.1120
2019-10-28 15:43:11,935 Training Epoch [33/40] Iter[286/312]		Loss: 0.1119
2019-10-28 15:43:12,014 Training Epoch [33/40] Iter[287/312]		Loss: 0.1118
2019-10-28 15:43:12,094 Training Epoch [33/40] Iter[288/312]		Loss: 0.1117
2019-10-28 15:43:12,173 Training Epoch [33/40] Iter[289/312]		Loss: 0.1119
2019-10-28 15:43:12,253 Training Epoch [33/40] Iter[290/312]		Loss: 0.1121
2019-10-28 15:43:12,332 Training Epoch [33/40] Iter[291/312]		Loss: 0.1122
2019-10-28 15:43:12,412 Training Epoch [33/40] Iter[292/312]		Loss: 0.1122
2019-10-28 15:43:12,491 Training Epoch [33/40] Iter[293/312]		Loss: 0.1120
2019-10-28 15:43:12,570 Training Epoch [33/40] Iter[294/312]		Loss: 0.1120
2019-10-28 15:43:12,649 Training Epoch [33/40] Iter[295/312]		Loss: 0.1120
2019-10-28 15:43:12,729 Training Epoch [33/40] Iter[296/312]		Loss: 0.1119
2019-10-28 15:43:12,808 Training Epoch [33/40] Iter[297/312]		Loss: 0.1120
2019-10-28 15:43:12,887 Training Epoch [33/40] Iter[298/312]		Loss: 0.1119
2019-10-28 15:43:12,966 Training Epoch [33/40] Iter[299/312]		Loss: 0.1118
2019-10-28 15:43:13,045 Training Epoch [33/40] Iter[300/312]		Loss: 0.1117
2019-10-28 15:43:13,124 Training Epoch [33/40] Iter[301/312]		Loss: 0.1116
2019-10-28 15:43:13,203 Training Epoch [33/40] Iter[302/312]		Loss: 0.1119
2019-10-28 15:43:13,283 Training Epoch [33/40] Iter[303/312]		Loss: 0.1117
2019-10-28 15:43:13,362 Training Epoch [33/40] Iter[304/312]		Loss: 0.1115
2019-10-28 15:43:13,441 Training Epoch [33/40] Iter[305/312]		Loss: 0.1115
2019-10-28 15:43:13,519 Training Epoch [33/40] Iter[306/312]		Loss: 0.1114
2019-10-28 15:43:13,598 Training Epoch [33/40] Iter[307/312]		Loss: 0.1113
2019-10-28 15:43:13,677 Training Epoch [33/40] Iter[308/312]		Loss: 0.1113
2019-10-28 15:43:13,755 Training Epoch [33/40] Iter[309/312]		Loss: 0.1111
2019-10-28 15:43:13,834 Training Epoch [33/40] Iter[310/312]		Loss: 0.1111
2019-10-28 15:43:13,912 Training Epoch [33/40] Iter[311/312]		Loss: 0.1112
2019-10-28 15:43:13,951 Training Epoch [33/40] Iter[312/312]		Loss: 0.1114
2019-10-28 15:43:14,379 Testing Epoch [33/40] Iter[0/62]		Loss: 0.1303
2019-10-28 15:43:14,412 Testing Epoch [33/40] Iter[1/62]		Loss: 0.1303
2019-10-28 15:43:14,443 Testing Epoch [33/40] Iter[2/62]		Loss: 0.1158
2019-10-28 15:43:14,469 Testing Epoch [33/40] Iter[3/62]		Loss: 0.1200
2019-10-28 15:43:14,487 Testing Epoch [33/40] Iter[4/62]		Loss: 0.1214
2019-10-28 15:43:14,513 Testing Epoch [33/40] Iter[5/62]		Loss: 0.1169
2019-10-28 15:43:14,538 Testing Epoch [33/40] Iter[6/62]		Loss: 0.1185
2019-10-28 15:43:14,563 Testing Epoch [33/40] Iter[7/62]		Loss: 0.1208
2019-10-28 15:43:14,589 Testing Epoch [33/40] Iter[8/62]		Loss: 0.1228
2019-10-28 15:43:14,612 Testing Epoch [33/40] Iter[9/62]		Loss: 0.1220
2019-10-28 15:43:14,629 Testing Epoch [33/40] Iter[10/62]		Loss: 0.1229
2019-10-28 15:43:14,657 Testing Epoch [33/40] Iter[11/62]		Loss: 0.1284
2019-10-28 15:43:14,675 Testing Epoch [33/40] Iter[12/62]		Loss: 0.1276
2019-10-28 15:43:14,693 Testing Epoch [33/40] Iter[13/62]		Loss: 0.1293
2019-10-28 15:43:14,722 Testing Epoch [33/40] Iter[14/62]		Loss: 0.1418
2019-10-28 15:43:14,748 Testing Epoch [33/40] Iter[15/62]		Loss: 0.1437
2019-10-28 15:43:14,770 Testing Epoch [33/40] Iter[16/62]		Loss: 0.1410
2019-10-28 15:43:14,796 Testing Epoch [33/40] Iter[17/62]		Loss: 0.1409
2019-10-28 15:43:14,814 Testing Epoch [33/40] Iter[18/62]		Loss: 0.1384
2019-10-28 15:43:14,832 Testing Epoch [33/40] Iter[19/62]		Loss: 0.1365
2019-10-28 15:43:14,857 Testing Epoch [33/40] Iter[20/62]		Loss: 0.1385
2019-10-28 15:43:14,881 Testing Epoch [33/40] Iter[21/62]		Loss: 0.1368
2019-10-28 15:43:14,899 Testing Epoch [33/40] Iter[22/62]		Loss: 0.1383
2019-10-28 15:43:14,926 Testing Epoch [33/40] Iter[23/62]		Loss: 0.1379
2019-10-28 15:43:14,947 Testing Epoch [33/40] Iter[24/62]		Loss: 0.1414
2019-10-28 15:43:14,973 Testing Epoch [33/40] Iter[25/62]		Loss: 0.1409
2019-10-28 15:43:14,997 Testing Epoch [33/40] Iter[26/62]		Loss: 0.1397
2019-10-28 15:43:15,021 Testing Epoch [33/40] Iter[27/62]		Loss: 0.1467
2019-10-28 15:43:15,045 Testing Epoch [33/40] Iter[28/62]		Loss: 0.1499
2019-10-28 15:43:15,071 Testing Epoch [33/40] Iter[29/62]		Loss: 0.1498
2019-10-28 15:43:15,094 Testing Epoch [33/40] Iter[30/62]		Loss: 0.1500
2019-10-28 15:43:15,112 Testing Epoch [33/40] Iter[31/62]		Loss: 0.1489
2019-10-28 15:43:15,130 Testing Epoch [33/40] Iter[32/62]		Loss: 0.1507
2019-10-28 15:43:15,161 Testing Epoch [33/40] Iter[33/62]		Loss: 0.1494
2019-10-28 15:43:15,178 Testing Epoch [33/40] Iter[34/62]		Loss: 0.1515
2019-10-28 15:43:15,196 Testing Epoch [33/40] Iter[35/62]		Loss: 0.1510
2019-10-28 15:43:15,214 Testing Epoch [33/40] Iter[36/62]		Loss: 0.1490
2019-10-28 15:43:15,246 Testing Epoch [33/40] Iter[37/62]		Loss: 0.1477
2019-10-28 15:43:15,264 Testing Epoch [33/40] Iter[38/62]		Loss: 0.1466
2019-10-28 15:43:15,296 Testing Epoch [33/40] Iter[39/62]		Loss: 0.1469
2019-10-28 15:43:15,313 Testing Epoch [33/40] Iter[40/62]		Loss: 0.1486
2019-10-28 15:43:15,331 Testing Epoch [33/40] Iter[41/62]		Loss: 0.1502
2019-10-28 15:43:15,359 Testing Epoch [33/40] Iter[42/62]		Loss: 0.1485
2019-10-28 15:43:15,389 Testing Epoch [33/40] Iter[43/62]		Loss: 0.1478
2019-10-28 15:43:15,406 Testing Epoch [33/40] Iter[44/62]		Loss: 0.1464
2019-10-28 15:43:15,437 Testing Epoch [33/40] Iter[45/62]		Loss: 0.1463
2019-10-28 15:43:15,454 Testing Epoch [33/40] Iter[46/62]		Loss: 0.1459
2019-10-28 15:43:15,481 Testing Epoch [33/40] Iter[47/62]		Loss: 0.1519
2019-10-28 15:43:15,499 Testing Epoch [33/40] Iter[48/62]		Loss: 0.1510
2019-10-28 15:43:15,529 Testing Epoch [33/40] Iter[49/62]		Loss: 0.1533
2019-10-28 15:43:15,547 Testing Epoch [33/40] Iter[50/62]		Loss: 0.1525
2019-10-28 15:43:15,573 Testing Epoch [33/40] Iter[51/62]		Loss: 0.1524
2019-10-28 15:43:15,591 Testing Epoch [33/40] Iter[52/62]		Loss: 0.1512
2019-10-28 15:43:15,618 Testing Epoch [33/40] Iter[53/62]		Loss: 0.1514
2019-10-28 15:43:15,635 Testing Epoch [33/40] Iter[54/62]		Loss: 0.1503
2019-10-28 15:43:15,653 Testing Epoch [33/40] Iter[55/62]		Loss: 0.1500
2019-10-28 15:43:15,670 Testing Epoch [33/40] Iter[56/62]		Loss: 0.1494
2019-10-28 15:43:15,686 Testing Epoch [33/40] Iter[57/62]		Loss: 0.1497
2019-10-28 15:43:15,703 Testing Epoch [33/40] Iter[58/62]		Loss: 0.1492
2019-10-28 15:43:15,719 Testing Epoch [33/40] Iter[59/62]		Loss: 0.1502
2019-10-28 15:43:15,736 Testing Epoch [33/40] Iter[60/62]		Loss: 0.1493
2019-10-28 15:43:15,753 Testing Epoch [33/40] Iter[61/62]		Loss: 0.1494
2019-10-28 15:43:15,762 Testing Epoch [33/40] Iter[62/62]		Loss: 0.1503
2019-10-28 15:43:16,250 Training Epoch [34/40] Iter[0/312]		Loss: 0.1385
2019-10-28 15:43:16,330 Training Epoch [34/40] Iter[1/312]		Loss: 0.1161
2019-10-28 15:43:16,409 Training Epoch [34/40] Iter[2/312]		Loss: 0.0980
2019-10-28 15:43:16,490 Training Epoch [34/40] Iter[3/312]		Loss: 0.1090
2019-10-28 15:43:16,571 Training Epoch [34/40] Iter[4/312]		Loss: 0.1042
2019-10-28 15:43:16,648 Training Epoch [34/40] Iter[5/312]		Loss: 0.0992
2019-10-28 15:43:16,726 Training Epoch [34/40] Iter[6/312]		Loss: 0.1044
2019-10-28 15:43:16,806 Training Epoch [34/40] Iter[7/312]		Loss: 0.1036
2019-10-28 15:43:16,885 Training Epoch [34/40] Iter[8/312]		Loss: 0.1056
2019-10-28 15:43:16,964 Training Epoch [34/40] Iter[9/312]		Loss: 0.1057
2019-10-28 15:43:17,043 Training Epoch [34/40] Iter[10/312]		Loss: 0.1087
2019-10-28 15:43:17,122 Training Epoch [34/40] Iter[11/312]		Loss: 0.1091
2019-10-28 15:43:17,201 Training Epoch [34/40] Iter[12/312]		Loss: 0.1075
2019-10-28 15:43:17,280 Training Epoch [34/40] Iter[13/312]		Loss: 0.1079
2019-10-28 15:43:17,360 Training Epoch [34/40] Iter[14/312]		Loss: 0.1077
2019-10-28 15:43:17,439 Training Epoch [34/40] Iter[15/312]		Loss: 0.1084
2019-10-28 15:43:17,518 Training Epoch [34/40] Iter[16/312]		Loss: 0.1063
2019-10-28 15:43:17,597 Training Epoch [34/40] Iter[17/312]		Loss: 0.1073
2019-10-28 15:43:17,676 Training Epoch [34/40] Iter[18/312]		Loss: 0.1089
2019-10-28 15:43:17,755 Training Epoch [34/40] Iter[19/312]		Loss: 0.1071
2019-10-28 15:43:17,834 Training Epoch [34/40] Iter[20/312]		Loss: 0.1056
2019-10-28 15:43:17,913 Training Epoch [34/40] Iter[21/312]		Loss: 0.1055
2019-10-28 15:43:17,992 Training Epoch [34/40] Iter[22/312]		Loss: 0.1040
2019-10-28 15:43:18,071 Training Epoch [34/40] Iter[23/312]		Loss: 0.1049
2019-10-28 15:43:18,150 Training Epoch [34/40] Iter[24/312]		Loss: 0.1055
2019-10-28 15:43:18,229 Training Epoch [34/40] Iter[25/312]		Loss: 0.1044
2019-10-28 15:43:18,308 Training Epoch [34/40] Iter[26/312]		Loss: 0.1042
2019-10-28 15:43:18,388 Training Epoch [34/40] Iter[27/312]		Loss: 0.1049
2019-10-28 15:43:18,466 Training Epoch [34/40] Iter[28/312]		Loss: 0.1051
2019-10-28 15:43:18,546 Training Epoch [34/40] Iter[29/312]		Loss: 0.1072
2019-10-28 15:43:18,625 Training Epoch [34/40] Iter[30/312]		Loss: 0.1071
2019-10-28 15:43:18,704 Training Epoch [34/40] Iter[31/312]		Loss: 0.1096
2019-10-28 15:43:18,783 Training Epoch [34/40] Iter[32/312]		Loss: 0.1107
2019-10-28 15:43:18,862 Training Epoch [34/40] Iter[33/312]		Loss: 0.1097
2019-10-28 15:43:18,941 Training Epoch [34/40] Iter[34/312]		Loss: 0.1099
2019-10-28 15:43:19,020 Training Epoch [34/40] Iter[35/312]		Loss: 0.1092
2019-10-28 15:43:19,099 Training Epoch [34/40] Iter[36/312]		Loss: 0.1092
2019-10-28 15:43:19,178 Training Epoch [34/40] Iter[37/312]		Loss: 0.1090
2019-10-28 15:43:19,257 Training Epoch [34/40] Iter[38/312]		Loss: 0.1087
2019-10-28 15:43:19,336 Training Epoch [34/40] Iter[39/312]		Loss: 0.1077
2019-10-28 15:43:19,416 Training Epoch [34/40] Iter[40/312]		Loss: 0.1080
2019-10-28 15:43:19,495 Training Epoch [34/40] Iter[41/312]		Loss: 0.1071
2019-10-28 15:43:19,574 Training Epoch [34/40] Iter[42/312]		Loss: 0.1084
2019-10-28 15:43:19,653 Training Epoch [34/40] Iter[43/312]		Loss: 0.1095
2019-10-28 15:43:19,732 Training Epoch [34/40] Iter[44/312]		Loss: 0.1095
2019-10-28 15:43:19,812 Training Epoch [34/40] Iter[45/312]		Loss: 0.1098
2019-10-28 15:43:19,891 Training Epoch [34/40] Iter[46/312]		Loss: 0.1099
2019-10-28 15:43:19,971 Training Epoch [34/40] Iter[47/312]		Loss: 0.1099
2019-10-28 15:43:20,050 Training Epoch [34/40] Iter[48/312]		Loss: 0.1098
2019-10-28 15:43:20,129 Training Epoch [34/40] Iter[49/312]		Loss: 0.1106
2019-10-28 15:43:20,209 Training Epoch [34/40] Iter[50/312]		Loss: 0.1102
2019-10-28 15:43:20,288 Training Epoch [34/40] Iter[51/312]		Loss: 0.1092
2019-10-28 15:43:20,367 Training Epoch [34/40] Iter[52/312]		Loss: 0.1107
2019-10-28 15:43:20,446 Training Epoch [34/40] Iter[53/312]		Loss: 0.1102
2019-10-28 15:43:20,525 Training Epoch [34/40] Iter[54/312]		Loss: 0.1104
2019-10-28 15:43:20,604 Training Epoch [34/40] Iter[55/312]		Loss: 0.1113
2019-10-28 15:43:20,683 Training Epoch [34/40] Iter[56/312]		Loss: 0.1105
2019-10-28 15:43:20,762 Training Epoch [34/40] Iter[57/312]		Loss: 0.1097
2019-10-28 15:43:20,841 Training Epoch [34/40] Iter[58/312]		Loss: 0.1096
2019-10-28 15:43:20,920 Training Epoch [34/40] Iter[59/312]		Loss: 0.1102
2019-10-28 15:43:20,999 Training Epoch [34/40] Iter[60/312]		Loss: 0.1100
2019-10-28 15:43:21,078 Training Epoch [34/40] Iter[61/312]		Loss: 0.1096
2019-10-28 15:43:21,157 Training Epoch [34/40] Iter[62/312]		Loss: 0.1094
2019-10-28 15:43:21,236 Training Epoch [34/40] Iter[63/312]		Loss: 0.1094
2019-10-28 15:43:21,315 Training Epoch [34/40] Iter[64/312]		Loss: 0.1094
2019-10-28 15:43:21,394 Training Epoch [34/40] Iter[65/312]		Loss: 0.1090
2019-10-28 15:43:21,473 Training Epoch [34/40] Iter[66/312]		Loss: 0.1086
2019-10-28 15:43:21,552 Training Epoch [34/40] Iter[67/312]		Loss: 0.1086
2019-10-28 15:43:21,631 Training Epoch [34/40] Iter[68/312]		Loss: 0.1090
2019-10-28 15:43:21,710 Training Epoch [34/40] Iter[69/312]		Loss: 0.1091
2019-10-28 15:43:21,789 Training Epoch [34/40] Iter[70/312]		Loss: 0.1086
2019-10-28 15:43:21,869 Training Epoch [34/40] Iter[71/312]		Loss: 0.1086
2019-10-28 15:43:21,948 Training Epoch [34/40] Iter[72/312]		Loss: 0.1086
2019-10-28 15:43:22,027 Training Epoch [34/40] Iter[73/312]		Loss: 0.1089
2019-10-28 15:43:22,106 Training Epoch [34/40] Iter[74/312]		Loss: 0.1085
2019-10-28 15:43:22,185 Training Epoch [34/40] Iter[75/312]		Loss: 0.1102
2019-10-28 15:43:22,264 Training Epoch [34/40] Iter[76/312]		Loss: 0.1097
2019-10-28 15:43:22,343 Training Epoch [34/40] Iter[77/312]		Loss: 0.1096
2019-10-28 15:43:22,422 Training Epoch [34/40] Iter[78/312]		Loss: 0.1101
2019-10-28 15:43:22,501 Training Epoch [34/40] Iter[79/312]		Loss: 0.1099
2019-10-28 15:43:22,580 Training Epoch [34/40] Iter[80/312]		Loss: 0.1102
2019-10-28 15:43:22,659 Training Epoch [34/40] Iter[81/312]		Loss: 0.1107
2019-10-28 15:43:22,738 Training Epoch [34/40] Iter[82/312]		Loss: 0.1113
2019-10-28 15:43:22,818 Training Epoch [34/40] Iter[83/312]		Loss: 0.1116
2019-10-28 15:43:22,897 Training Epoch [34/40] Iter[84/312]		Loss: 0.1114
2019-10-28 15:43:22,977 Training Epoch [34/40] Iter[85/312]		Loss: 0.1107
2019-10-28 15:43:23,056 Training Epoch [34/40] Iter[86/312]		Loss: 0.1112
2019-10-28 15:43:23,136 Training Epoch [34/40] Iter[87/312]		Loss: 0.1108
2019-10-28 15:43:23,215 Training Epoch [34/40] Iter[88/312]		Loss: 0.1110
2019-10-28 15:43:23,294 Training Epoch [34/40] Iter[89/312]		Loss: 0.1110
2019-10-28 15:43:23,373 Training Epoch [34/40] Iter[90/312]		Loss: 0.1109
2019-10-28 15:43:23,452 Training Epoch [34/40] Iter[91/312]		Loss: 0.1105
2019-10-28 15:43:23,531 Training Epoch [34/40] Iter[92/312]		Loss: 0.1100
2019-10-28 15:43:23,610 Training Epoch [34/40] Iter[93/312]		Loss: 0.1100
2019-10-28 15:43:23,689 Training Epoch [34/40] Iter[94/312]		Loss: 0.1104
2019-10-28 15:43:23,769 Training Epoch [34/40] Iter[95/312]		Loss: 0.1103
2019-10-28 15:43:23,848 Training Epoch [34/40] Iter[96/312]		Loss: 0.1101
2019-10-28 15:43:23,927 Training Epoch [34/40] Iter[97/312]		Loss: 0.1108
2019-10-28 15:43:24,005 Training Epoch [34/40] Iter[98/312]		Loss: 0.1103
2019-10-28 15:43:24,085 Training Epoch [34/40] Iter[99/312]		Loss: 0.1102
2019-10-28 15:43:24,163 Training Epoch [34/40] Iter[100/312]		Loss: 0.1099
2019-10-28 15:43:24,243 Training Epoch [34/40] Iter[101/312]		Loss: 0.1096
2019-10-28 15:43:24,322 Training Epoch [34/40] Iter[102/312]		Loss: 0.1094
2019-10-28 15:43:24,401 Training Epoch [34/40] Iter[103/312]		Loss: 0.1092
2019-10-28 15:43:24,480 Training Epoch [34/40] Iter[104/312]		Loss: 0.1091
2019-10-28 15:43:24,559 Training Epoch [34/40] Iter[105/312]		Loss: 0.1096
2019-10-28 15:43:24,638 Training Epoch [34/40] Iter[106/312]		Loss: 0.1094
2019-10-28 15:43:24,717 Training Epoch [34/40] Iter[107/312]		Loss: 0.1093
2019-10-28 15:43:24,796 Training Epoch [34/40] Iter[108/312]		Loss: 0.1094
2019-10-28 15:43:24,876 Training Epoch [34/40] Iter[109/312]		Loss: 0.1098
2019-10-28 15:43:24,955 Training Epoch [34/40] Iter[110/312]		Loss: 0.1096
2019-10-28 15:43:25,034 Training Epoch [34/40] Iter[111/312]		Loss: 0.1093
2019-10-28 15:43:25,113 Training Epoch [34/40] Iter[112/312]		Loss: 0.1095
2019-10-28 15:43:25,193 Training Epoch [34/40] Iter[113/312]		Loss: 0.1096
2019-10-28 15:43:25,272 Training Epoch [34/40] Iter[114/312]		Loss: 0.1096
2019-10-28 15:43:25,351 Training Epoch [34/40] Iter[115/312]		Loss: 0.1095
2019-10-28 15:43:25,430 Training Epoch [34/40] Iter[116/312]		Loss: 0.1093
2019-10-28 15:43:25,510 Training Epoch [34/40] Iter[117/312]		Loss: 0.1092
2019-10-28 15:43:25,589 Training Epoch [34/40] Iter[118/312]		Loss: 0.1093
2019-10-28 15:43:25,668 Training Epoch [34/40] Iter[119/312]		Loss: 0.1091
2019-10-28 15:43:25,747 Training Epoch [34/40] Iter[120/312]		Loss: 0.1093
2019-10-28 15:43:25,826 Training Epoch [34/40] Iter[121/312]		Loss: 0.1094
2019-10-28 15:43:25,905 Training Epoch [34/40] Iter[122/312]		Loss: 0.1099
2019-10-28 15:43:25,984 Training Epoch [34/40] Iter[123/312]		Loss: 0.1109
2019-10-28 15:43:26,063 Training Epoch [34/40] Iter[124/312]		Loss: 0.1106
2019-10-28 15:43:26,142 Training Epoch [34/40] Iter[125/312]		Loss: 0.1105
2019-10-28 15:43:26,221 Training Epoch [34/40] Iter[126/312]		Loss: 0.1105
2019-10-28 15:43:26,300 Training Epoch [34/40] Iter[127/312]		Loss: 0.1105
2019-10-28 15:43:26,379 Training Epoch [34/40] Iter[128/312]		Loss: 0.1103
2019-10-28 15:43:26,458 Training Epoch [34/40] Iter[129/312]		Loss: 0.1104
2019-10-28 15:43:26,537 Training Epoch [34/40] Iter[130/312]		Loss: 0.1108
2019-10-28 15:43:26,616 Training Epoch [34/40] Iter[131/312]		Loss: 0.1113
2019-10-28 15:43:26,695 Training Epoch [34/40] Iter[132/312]		Loss: 0.1112
2019-10-28 15:43:26,774 Training Epoch [34/40] Iter[133/312]		Loss: 0.1112
2019-10-28 15:43:26,853 Training Epoch [34/40] Iter[134/312]		Loss: 0.1112
2019-10-28 15:43:26,932 Training Epoch [34/40] Iter[135/312]		Loss: 0.1116
2019-10-28 15:43:27,011 Training Epoch [34/40] Iter[136/312]		Loss: 0.1117
2019-10-28 15:43:27,090 Training Epoch [34/40] Iter[137/312]		Loss: 0.1114
2019-10-28 15:43:27,169 Training Epoch [34/40] Iter[138/312]		Loss: 0.1113
2019-10-28 15:43:27,248 Training Epoch [34/40] Iter[139/312]		Loss: 0.1112
2019-10-28 15:43:27,327 Training Epoch [34/40] Iter[140/312]		Loss: 0.1115
2019-10-28 15:43:27,406 Training Epoch [34/40] Iter[141/312]		Loss: 0.1112
2019-10-28 15:43:27,485 Training Epoch [34/40] Iter[142/312]		Loss: 0.1113
2019-10-28 15:43:27,564 Training Epoch [34/40] Iter[143/312]		Loss: 0.1111
2019-10-28 15:43:27,643 Training Epoch [34/40] Iter[144/312]		Loss: 0.1109
2019-10-28 15:43:27,722 Training Epoch [34/40] Iter[145/312]		Loss: 0.1106
2019-10-28 15:43:27,801 Training Epoch [34/40] Iter[146/312]		Loss: 0.1105
2019-10-28 15:43:27,880 Training Epoch [34/40] Iter[147/312]		Loss: 0.1102
2019-10-28 15:43:27,959 Training Epoch [34/40] Iter[148/312]		Loss: 0.1102
2019-10-28 15:43:28,038 Training Epoch [34/40] Iter[149/312]		Loss: 0.1100
2019-10-28 15:43:28,117 Training Epoch [34/40] Iter[150/312]		Loss: 0.1097
2019-10-28 15:43:28,196 Training Epoch [34/40] Iter[151/312]		Loss: 0.1094
2019-10-28 15:43:28,276 Training Epoch [34/40] Iter[152/312]		Loss: 0.1092
2019-10-28 15:43:28,355 Training Epoch [34/40] Iter[153/312]		Loss: 0.1094
2019-10-28 15:43:28,434 Training Epoch [34/40] Iter[154/312]		Loss: 0.1094
2019-10-28 15:43:28,513 Training Epoch [34/40] Iter[155/312]		Loss: 0.1094
2019-10-28 15:43:28,593 Training Epoch [34/40] Iter[156/312]		Loss: 0.1095
2019-10-28 15:43:28,672 Training Epoch [34/40] Iter[157/312]		Loss: 0.1100
2019-10-28 15:43:28,751 Training Epoch [34/40] Iter[158/312]		Loss: 0.1097
2019-10-28 15:43:28,830 Training Epoch [34/40] Iter[159/312]		Loss: 0.1099
2019-10-28 15:43:28,909 Training Epoch [34/40] Iter[160/312]		Loss: 0.1103
2019-10-28 15:43:28,988 Training Epoch [34/40] Iter[161/312]		Loss: 0.1101
2019-10-28 15:43:29,067 Training Epoch [34/40] Iter[162/312]		Loss: 0.1099
2019-10-28 15:43:29,146 Training Epoch [34/40] Iter[163/312]		Loss: 0.1096
2019-10-28 15:43:29,225 Training Epoch [34/40] Iter[164/312]		Loss: 0.1102
2019-10-28 15:43:29,304 Training Epoch [34/40] Iter[165/312]		Loss: 0.1102
2019-10-28 15:43:29,383 Training Epoch [34/40] Iter[166/312]		Loss: 0.1100
2019-10-28 15:43:29,462 Training Epoch [34/40] Iter[167/312]		Loss: 0.1099
2019-10-28 15:43:29,541 Training Epoch [34/40] Iter[168/312]		Loss: 0.1096
2019-10-28 15:43:29,620 Training Epoch [34/40] Iter[169/312]		Loss: 0.1093
2019-10-28 15:43:29,699 Training Epoch [34/40] Iter[170/312]		Loss: 0.1091
2019-10-28 15:43:29,778 Training Epoch [34/40] Iter[171/312]		Loss: 0.1088
2019-10-28 15:43:29,857 Training Epoch [34/40] Iter[172/312]		Loss: 0.1088
2019-10-28 15:43:29,936 Training Epoch [34/40] Iter[173/312]		Loss: 0.1090
2019-10-28 15:43:30,015 Training Epoch [34/40] Iter[174/312]		Loss: 0.1095
2019-10-28 15:43:30,094 Training Epoch [34/40] Iter[175/312]		Loss: 0.1094
2019-10-28 15:43:30,174 Training Epoch [34/40] Iter[176/312]		Loss: 0.1098
2019-10-28 15:43:30,253 Training Epoch [34/40] Iter[177/312]		Loss: 0.1099
2019-10-28 15:43:30,332 Training Epoch [34/40] Iter[178/312]		Loss: 0.1099
2019-10-28 15:43:30,411 Training Epoch [34/40] Iter[179/312]		Loss: 0.1097
2019-10-28 15:43:30,490 Training Epoch [34/40] Iter[180/312]		Loss: 0.1097
2019-10-28 15:43:30,569 Training Epoch [34/40] Iter[181/312]		Loss: 0.1096
2019-10-28 15:43:30,648 Training Epoch [34/40] Iter[182/312]		Loss: 0.1095
2019-10-28 15:43:30,727 Training Epoch [34/40] Iter[183/312]		Loss: 0.1094
2019-10-28 15:43:30,806 Training Epoch [34/40] Iter[184/312]		Loss: 0.1093
2019-10-28 15:43:30,885 Training Epoch [34/40] Iter[185/312]		Loss: 0.1094
2019-10-28 15:43:30,964 Training Epoch [34/40] Iter[186/312]		Loss: 0.1096
2019-10-28 15:43:31,043 Training Epoch [34/40] Iter[187/312]		Loss: 0.1097
2019-10-28 15:43:31,122 Training Epoch [34/40] Iter[188/312]		Loss: 0.1098
2019-10-28 15:43:31,201 Training Epoch [34/40] Iter[189/312]		Loss: 0.1099
2019-10-28 15:43:31,280 Training Epoch [34/40] Iter[190/312]		Loss: 0.1100
2019-10-28 15:43:31,359 Training Epoch [34/40] Iter[191/312]		Loss: 0.1099
2019-10-28 15:43:31,438 Training Epoch [34/40] Iter[192/312]		Loss: 0.1098
2019-10-28 15:43:31,517 Training Epoch [34/40] Iter[193/312]		Loss: 0.1099
2019-10-28 15:43:31,596 Training Epoch [34/40] Iter[194/312]		Loss: 0.1098
2019-10-28 15:43:31,676 Training Epoch [34/40] Iter[195/312]		Loss: 0.1101
2019-10-28 15:43:31,755 Training Epoch [34/40] Iter[196/312]		Loss: 0.1102
2019-10-28 15:43:31,834 Training Epoch [34/40] Iter[197/312]		Loss: 0.1102
2019-10-28 15:43:31,913 Training Epoch [34/40] Iter[198/312]		Loss: 0.1100
2019-10-28 15:43:31,992 Training Epoch [34/40] Iter[199/312]		Loss: 0.1100
2019-10-28 15:43:32,071 Training Epoch [34/40] Iter[200/312]		Loss: 0.1102
2019-10-28 15:43:32,150 Training Epoch [34/40] Iter[201/312]		Loss: 0.1105
2019-10-28 15:43:32,229 Training Epoch [34/40] Iter[202/312]		Loss: 0.1104
2019-10-28 15:43:32,308 Training Epoch [34/40] Iter[203/312]		Loss: 0.1104
2019-10-28 15:43:32,387 Training Epoch [34/40] Iter[204/312]		Loss: 0.1105
2019-10-28 15:43:32,466 Training Epoch [34/40] Iter[205/312]		Loss: 0.1104
2019-10-28 15:43:32,545 Training Epoch [34/40] Iter[206/312]		Loss: 0.1103
2019-10-28 15:43:32,624 Training Epoch [34/40] Iter[207/312]		Loss: 0.1101
2019-10-28 15:43:32,703 Training Epoch [34/40] Iter[208/312]		Loss: 0.1101
2019-10-28 15:43:32,782 Training Epoch [34/40] Iter[209/312]		Loss: 0.1100
2019-10-28 15:43:32,861 Training Epoch [34/40] Iter[210/312]		Loss: 0.1100
2019-10-28 15:43:32,940 Training Epoch [34/40] Iter[211/312]		Loss: 0.1099
2019-10-28 15:43:33,019 Training Epoch [34/40] Iter[212/312]		Loss: 0.1102
2019-10-28 15:43:33,098 Training Epoch [34/40] Iter[213/312]		Loss: 0.1104
2019-10-28 15:43:33,177 Training Epoch [34/40] Iter[214/312]		Loss: 0.1102
2019-10-28 15:43:33,256 Training Epoch [34/40] Iter[215/312]		Loss: 0.1102
2019-10-28 15:43:33,335 Training Epoch [34/40] Iter[216/312]		Loss: 0.1101
2019-10-28 15:43:33,414 Training Epoch [34/40] Iter[217/312]		Loss: 0.1100
2019-10-28 15:43:33,494 Training Epoch [34/40] Iter[218/312]		Loss: 0.1099
2019-10-28 15:43:33,573 Training Epoch [34/40] Iter[219/312]		Loss: 0.1098
2019-10-28 15:43:33,652 Training Epoch [34/40] Iter[220/312]		Loss: 0.1099
2019-10-28 15:43:33,732 Training Epoch [34/40] Iter[221/312]		Loss: 0.1101
2019-10-28 15:43:33,811 Training Epoch [34/40] Iter[222/312]		Loss: 0.1100
2019-10-28 15:43:33,890 Training Epoch [34/40] Iter[223/312]		Loss: 0.1100
2019-10-28 15:43:33,969 Training Epoch [34/40] Iter[224/312]		Loss: 0.1100
2019-10-28 15:43:34,048 Training Epoch [34/40] Iter[225/312]		Loss: 0.1100
2019-10-28 15:43:34,127 Training Epoch [34/40] Iter[226/312]		Loss: 0.1099
2019-10-28 15:43:34,206 Training Epoch [34/40] Iter[227/312]		Loss: 0.1099
2019-10-28 15:43:34,285 Training Epoch [34/40] Iter[228/312]		Loss: 0.1099
2019-10-28 15:43:34,365 Training Epoch [34/40] Iter[229/312]		Loss: 0.1097
2019-10-28 15:43:34,444 Training Epoch [34/40] Iter[230/312]		Loss: 0.1095
2019-10-28 15:43:34,523 Training Epoch [34/40] Iter[231/312]		Loss: 0.1095
2019-10-28 15:43:34,602 Training Epoch [34/40] Iter[232/312]		Loss: 0.1093
2019-10-28 15:43:34,682 Training Epoch [34/40] Iter[233/312]		Loss: 0.1093
2019-10-28 15:43:34,761 Training Epoch [34/40] Iter[234/312]		Loss: 0.1094
2019-10-28 15:43:34,839 Training Epoch [34/40] Iter[235/312]		Loss: 0.1095
2019-10-28 15:43:34,918 Training Epoch [34/40] Iter[236/312]		Loss: 0.1097
2019-10-28 15:43:34,997 Training Epoch [34/40] Iter[237/312]		Loss: 0.1098
2019-10-28 15:43:35,076 Training Epoch [34/40] Iter[238/312]		Loss: 0.1099
2019-10-28 15:43:35,155 Training Epoch [34/40] Iter[239/312]		Loss: 0.1100
2019-10-28 15:43:35,234 Training Epoch [34/40] Iter[240/312]		Loss: 0.1100
2019-10-28 15:43:35,314 Training Epoch [34/40] Iter[241/312]		Loss: 0.1098
2019-10-28 15:43:35,393 Training Epoch [34/40] Iter[242/312]		Loss: 0.1100
2019-10-28 15:43:35,472 Training Epoch [34/40] Iter[243/312]		Loss: 0.1100
2019-10-28 15:43:35,551 Training Epoch [34/40] Iter[244/312]		Loss: 0.1101
2019-10-28 15:43:35,631 Training Epoch [34/40] Iter[245/312]		Loss: 0.1100
2019-10-28 15:43:35,710 Training Epoch [34/40] Iter[246/312]		Loss: 0.1098
2019-10-28 15:43:35,789 Training Epoch [34/40] Iter[247/312]		Loss: 0.1099
2019-10-28 15:43:35,868 Training Epoch [34/40] Iter[248/312]		Loss: 0.1099
2019-10-28 15:43:35,947 Training Epoch [34/40] Iter[249/312]		Loss: 0.1100
2019-10-28 15:43:36,026 Training Epoch [34/40] Iter[250/312]		Loss: 0.1100
2019-10-28 15:43:36,105 Training Epoch [34/40] Iter[251/312]		Loss: 0.1101
2019-10-28 15:43:36,184 Training Epoch [34/40] Iter[252/312]		Loss: 0.1100
2019-10-28 15:43:36,263 Training Epoch [34/40] Iter[253/312]		Loss: 0.1101
2019-10-28 15:43:36,343 Training Epoch [34/40] Iter[254/312]		Loss: 0.1101
2019-10-28 15:43:36,421 Training Epoch [34/40] Iter[255/312]		Loss: 0.1099
2019-10-28 15:43:36,500 Training Epoch [34/40] Iter[256/312]		Loss: 0.1100
2019-10-28 15:43:36,579 Training Epoch [34/40] Iter[257/312]		Loss: 0.1101
2019-10-28 15:43:36,658 Training Epoch [34/40] Iter[258/312]		Loss: 0.1101
2019-10-28 15:43:36,737 Training Epoch [34/40] Iter[259/312]		Loss: 0.1099
2019-10-28 15:43:36,816 Training Epoch [34/40] Iter[260/312]		Loss: 0.1100
2019-10-28 15:43:36,895 Training Epoch [34/40] Iter[261/312]		Loss: 0.1099
2019-10-28 15:43:36,974 Training Epoch [34/40] Iter[262/312]		Loss: 0.1098
2019-10-28 15:43:37,053 Training Epoch [34/40] Iter[263/312]		Loss: 0.1097
2019-10-28 15:43:37,132 Training Epoch [34/40] Iter[264/312]		Loss: 0.1097
2019-10-28 15:43:37,211 Training Epoch [34/40] Iter[265/312]		Loss: 0.1096
2019-10-28 15:43:37,290 Training Epoch [34/40] Iter[266/312]		Loss: 0.1097
2019-10-28 15:43:37,369 Training Epoch [34/40] Iter[267/312]		Loss: 0.1096
2019-10-28 15:43:37,448 Training Epoch [34/40] Iter[268/312]		Loss: 0.1095
2019-10-28 15:43:37,527 Training Epoch [34/40] Iter[269/312]		Loss: 0.1095
2019-10-28 15:43:37,606 Training Epoch [34/40] Iter[270/312]		Loss: 0.1094
2019-10-28 15:43:37,685 Training Epoch [34/40] Iter[271/312]		Loss: 0.1094
2019-10-28 15:43:37,764 Training Epoch [34/40] Iter[272/312]		Loss: 0.1093
2019-10-28 15:43:37,842 Training Epoch [34/40] Iter[273/312]		Loss: 0.1095
2019-10-28 15:43:37,921 Training Epoch [34/40] Iter[274/312]		Loss: 0.1095
2019-10-28 15:43:38,000 Training Epoch [34/40] Iter[275/312]		Loss: 0.1096
2019-10-28 15:43:38,079 Training Epoch [34/40] Iter[276/312]		Loss: 0.1095
2019-10-28 15:43:38,158 Training Epoch [34/40] Iter[277/312]		Loss: 0.1094
2019-10-28 15:43:38,237 Training Epoch [34/40] Iter[278/312]		Loss: 0.1093
2019-10-28 15:43:38,316 Training Epoch [34/40] Iter[279/312]		Loss: 0.1092
2019-10-28 15:43:38,395 Training Epoch [34/40] Iter[280/312]		Loss: 0.1093
2019-10-28 15:43:38,475 Training Epoch [34/40] Iter[281/312]		Loss: 0.1095
2019-10-28 15:43:38,554 Training Epoch [34/40] Iter[282/312]		Loss: 0.1096
2019-10-28 15:43:38,633 Training Epoch [34/40] Iter[283/312]		Loss: 0.1097
2019-10-28 15:43:38,712 Training Epoch [34/40] Iter[284/312]		Loss: 0.1096
2019-10-28 15:43:38,791 Training Epoch [34/40] Iter[285/312]		Loss: 0.1097
2019-10-28 15:43:38,870 Training Epoch [34/40] Iter[286/312]		Loss: 0.1102
2019-10-28 15:43:38,949 Training Epoch [34/40] Iter[287/312]		Loss: 0.1105
2019-10-28 15:43:39,028 Training Epoch [34/40] Iter[288/312]		Loss: 0.1105
2019-10-28 15:43:39,107 Training Epoch [34/40] Iter[289/312]		Loss: 0.1104
2019-10-28 15:43:39,186 Training Epoch [34/40] Iter[290/312]		Loss: 0.1106
2019-10-28 15:43:39,265 Training Epoch [34/40] Iter[291/312]		Loss: 0.1105
2019-10-28 15:43:39,345 Training Epoch [34/40] Iter[292/312]		Loss: 0.1108
2019-10-28 15:43:39,424 Training Epoch [34/40] Iter[293/312]		Loss: 0.1110
2019-10-28 15:43:39,503 Training Epoch [34/40] Iter[294/312]		Loss: 0.1109
2019-10-28 15:43:39,582 Training Epoch [34/40] Iter[295/312]		Loss: 0.1110
2019-10-28 15:43:39,661 Training Epoch [34/40] Iter[296/312]		Loss: 0.1111
2019-10-28 15:43:39,740 Training Epoch [34/40] Iter[297/312]		Loss: 0.1111
2019-10-28 15:43:39,819 Training Epoch [34/40] Iter[298/312]		Loss: 0.1111
2019-10-28 15:43:39,898 Training Epoch [34/40] Iter[299/312]		Loss: 0.1110
2019-10-28 15:43:39,977 Training Epoch [34/40] Iter[300/312]		Loss: 0.1109
2019-10-28 15:43:40,056 Training Epoch [34/40] Iter[301/312]		Loss: 0.1110
2019-10-28 15:43:40,135 Training Epoch [34/40] Iter[302/312]		Loss: 0.1109
2019-10-28 15:43:40,214 Training Epoch [34/40] Iter[303/312]		Loss: 0.1108
2019-10-28 15:43:40,293 Training Epoch [34/40] Iter[304/312]		Loss: 0.1109
2019-10-28 15:43:40,372 Training Epoch [34/40] Iter[305/312]		Loss: 0.1108
2019-10-28 15:43:40,450 Training Epoch [34/40] Iter[306/312]		Loss: 0.1109
2019-10-28 15:43:40,528 Training Epoch [34/40] Iter[307/312]		Loss: 0.1109
2019-10-28 15:43:40,607 Training Epoch [34/40] Iter[308/312]		Loss: 0.1109
2019-10-28 15:43:40,685 Training Epoch [34/40] Iter[309/312]		Loss: 0.1109
2019-10-28 15:43:40,764 Training Epoch [34/40] Iter[310/312]		Loss: 0.1108
2019-10-28 15:43:40,842 Training Epoch [34/40] Iter[311/312]		Loss: 0.1109
2019-10-28 15:43:40,880 Training Epoch [34/40] Iter[312/312]		Loss: 0.1113
2019-10-28 15:43:41,314 Testing Epoch [34/40] Iter[0/62]		Loss: 0.1286
2019-10-28 15:43:41,338 Testing Epoch [34/40] Iter[1/62]		Loss: 0.1293
2019-10-28 15:43:41,362 Testing Epoch [34/40] Iter[2/62]		Loss: 0.1126
2019-10-28 15:43:41,394 Testing Epoch [34/40] Iter[3/62]		Loss: 0.1174
2019-10-28 15:43:41,421 Testing Epoch [34/40] Iter[4/62]		Loss: 0.1206
2019-10-28 15:43:41,445 Testing Epoch [34/40] Iter[5/62]		Loss: 0.1159
2019-10-28 15:43:41,469 Testing Epoch [34/40] Iter[6/62]		Loss: 0.1174
2019-10-28 15:43:41,486 Testing Epoch [34/40] Iter[7/62]		Loss: 0.1201
2019-10-28 15:43:41,507 Testing Epoch [34/40] Iter[8/62]		Loss: 0.1226
2019-10-28 15:43:41,524 Testing Epoch [34/40] Iter[9/62]		Loss: 0.1216
2019-10-28 15:43:41,554 Testing Epoch [34/40] Iter[10/62]		Loss: 0.1219
2019-10-28 15:43:41,574 Testing Epoch [34/40] Iter[11/62]		Loss: 0.1274
2019-10-28 15:43:41,593 Testing Epoch [34/40] Iter[12/62]		Loss: 0.1270
2019-10-28 15:43:41,611 Testing Epoch [34/40] Iter[13/62]		Loss: 0.1289
2019-10-28 15:43:41,643 Testing Epoch [34/40] Iter[14/62]		Loss: 0.1415
2019-10-28 15:43:41,665 Testing Epoch [34/40] Iter[15/62]		Loss: 0.1435
2019-10-28 15:43:41,684 Testing Epoch [34/40] Iter[16/62]		Loss: 0.1404
2019-10-28 15:43:41,710 Testing Epoch [34/40] Iter[17/62]		Loss: 0.1408
2019-10-28 15:43:41,737 Testing Epoch [34/40] Iter[18/62]		Loss: 0.1385
2019-10-28 15:43:41,760 Testing Epoch [34/40] Iter[19/62]		Loss: 0.1367
2019-10-28 15:43:41,785 Testing Epoch [34/40] Iter[20/62]		Loss: 0.1385
2019-10-28 15:43:41,809 Testing Epoch [34/40] Iter[21/62]		Loss: 0.1372
2019-10-28 15:43:41,827 Testing Epoch [34/40] Iter[22/62]		Loss: 0.1388
2019-10-28 15:43:41,857 Testing Epoch [34/40] Iter[23/62]		Loss: 0.1377
2019-10-28 15:43:41,877 Testing Epoch [34/40] Iter[24/62]		Loss: 0.1408
2019-10-28 15:43:41,901 Testing Epoch [34/40] Iter[25/62]		Loss: 0.1399
2019-10-28 15:43:41,925 Testing Epoch [34/40] Iter[26/62]		Loss: 0.1386
2019-10-28 15:43:41,949 Testing Epoch [34/40] Iter[27/62]		Loss: 0.1461
2019-10-28 15:43:41,973 Testing Epoch [34/40] Iter[28/62]		Loss: 0.1496
2019-10-28 15:43:42,000 Testing Epoch [34/40] Iter[29/62]		Loss: 0.1497
2019-10-28 15:43:42,018 Testing Epoch [34/40] Iter[30/62]		Loss: 0.1500
2019-10-28 15:43:42,045 Testing Epoch [34/40] Iter[31/62]		Loss: 0.1490
2019-10-28 15:43:42,063 Testing Epoch [34/40] Iter[32/62]		Loss: 0.1506
2019-10-28 15:43:42,093 Testing Epoch [34/40] Iter[33/62]		Loss: 0.1496
2019-10-28 15:43:42,115 Testing Epoch [34/40] Iter[34/62]		Loss: 0.1518
2019-10-28 15:43:42,141 Testing Epoch [34/40] Iter[35/62]		Loss: 0.1515
2019-10-28 15:43:42,158 Testing Epoch [34/40] Iter[36/62]		Loss: 0.1494
2019-10-28 15:43:42,186 Testing Epoch [34/40] Iter[37/62]		Loss: 0.1484
2019-10-28 15:43:42,204 Testing Epoch [34/40] Iter[38/62]		Loss: 0.1472
2019-10-28 15:43:42,222 Testing Epoch [34/40] Iter[39/62]		Loss: 0.1476
2019-10-28 15:43:42,239 Testing Epoch [34/40] Iter[40/62]		Loss: 0.1492
2019-10-28 15:43:42,270 Testing Epoch [34/40] Iter[41/62]		Loss: 0.1506
2019-10-28 15:43:42,293 Testing Epoch [34/40] Iter[42/62]		Loss: 0.1488
2019-10-28 15:43:42,317 Testing Epoch [34/40] Iter[43/62]		Loss: 0.1482
2019-10-28 15:43:42,345 Testing Epoch [34/40] Iter[44/62]		Loss: 0.1467
2019-10-28 15:43:42,362 Testing Epoch [34/40] Iter[45/62]		Loss: 0.1465
2019-10-28 15:43:42,381 Testing Epoch [34/40] Iter[46/62]		Loss: 0.1462
2019-10-28 15:43:42,405 Testing Epoch [34/40] Iter[47/62]		Loss: 0.1522
2019-10-28 15:43:42,433 Testing Epoch [34/40] Iter[48/62]		Loss: 0.1511
2019-10-28 15:43:42,457 Testing Epoch [34/40] Iter[49/62]		Loss: 0.1534
2019-10-28 15:43:42,481 Testing Epoch [34/40] Iter[50/62]		Loss: 0.1525
2019-10-28 15:43:42,499 Testing Epoch [34/40] Iter[51/62]		Loss: 0.1525
2019-10-28 15:43:42,517 Testing Epoch [34/40] Iter[52/62]		Loss: 0.1513
2019-10-28 15:43:42,535 Testing Epoch [34/40] Iter[53/62]		Loss: 0.1516
2019-10-28 15:43:42,554 Testing Epoch [34/40] Iter[54/62]		Loss: 0.1503
2019-10-28 15:43:42,577 Testing Epoch [34/40] Iter[55/62]		Loss: 0.1500
2019-10-28 15:43:42,594 Testing Epoch [34/40] Iter[56/62]		Loss: 0.1493
2019-10-28 15:43:42,610 Testing Epoch [34/40] Iter[57/62]		Loss: 0.1495
2019-10-28 15:43:42,627 Testing Epoch [34/40] Iter[58/62]		Loss: 0.1489
2019-10-28 15:43:42,645 Testing Epoch [34/40] Iter[59/62]		Loss: 0.1501
2019-10-28 15:43:42,662 Testing Epoch [34/40] Iter[60/62]		Loss: 0.1492
2019-10-28 15:43:42,677 Testing Epoch [34/40] Iter[61/62]		Loss: 0.1492
2019-10-28 15:43:42,686 Testing Epoch [34/40] Iter[62/62]		Loss: 0.1500
2019-10-28 15:43:42,757 Saving the Model
2019-10-28 15:43:43,163 Training Epoch [35/40] Iter[0/312]		Loss: 0.1096
2019-10-28 15:43:43,256 Training Epoch [35/40] Iter[1/312]		Loss: 0.0901
2019-10-28 15:43:43,335 Training Epoch [35/40] Iter[2/312]		Loss: 0.1035
2019-10-28 15:43:43,412 Training Epoch [35/40] Iter[3/312]		Loss: 0.0994
2019-10-28 15:43:43,490 Training Epoch [35/40] Iter[4/312]		Loss: 0.0971
2019-10-28 15:43:43,575 Training Epoch [35/40] Iter[5/312]		Loss: 0.1006
2019-10-28 15:43:43,655 Training Epoch [35/40] Iter[6/312]		Loss: 0.0965
2019-10-28 15:43:43,733 Training Epoch [35/40] Iter[7/312]		Loss: 0.0938
2019-10-28 15:43:43,811 Training Epoch [35/40] Iter[8/312]		Loss: 0.0971
2019-10-28 15:43:43,890 Training Epoch [35/40] Iter[9/312]		Loss: 0.0964
2019-10-28 15:43:43,969 Training Epoch [35/40] Iter[10/312]		Loss: 0.1062
2019-10-28 15:43:44,048 Training Epoch [35/40] Iter[11/312]		Loss: 0.1107
2019-10-28 15:43:44,127 Training Epoch [35/40] Iter[12/312]		Loss: 0.1146
2019-10-28 15:43:44,207 Training Epoch [35/40] Iter[13/312]		Loss: 0.1153
2019-10-28 15:43:44,287 Training Epoch [35/40] Iter[14/312]		Loss: 0.1148
2019-10-28 15:43:44,366 Training Epoch [35/40] Iter[15/312]		Loss: 0.1144
2019-10-28 15:43:44,445 Training Epoch [35/40] Iter[16/312]		Loss: 0.1127
2019-10-28 15:43:44,525 Training Epoch [35/40] Iter[17/312]		Loss: 0.1140
2019-10-28 15:43:44,604 Training Epoch [35/40] Iter[18/312]		Loss: 0.1131
2019-10-28 15:43:44,684 Training Epoch [35/40] Iter[19/312]		Loss: 0.1109
2019-10-28 15:43:44,763 Training Epoch [35/40] Iter[20/312]		Loss: 0.1118
2019-10-28 15:43:44,842 Training Epoch [35/40] Iter[21/312]		Loss: 0.1113
2019-10-28 15:43:44,922 Training Epoch [35/40] Iter[22/312]		Loss: 0.1127
2019-10-28 15:43:45,001 Training Epoch [35/40] Iter[23/312]		Loss: 0.1117
2019-10-28 15:43:45,081 Training Epoch [35/40] Iter[24/312]		Loss: 0.1133
2019-10-28 15:43:45,161 Training Epoch [35/40] Iter[25/312]		Loss: 0.1127
2019-10-28 15:43:45,240 Training Epoch [35/40] Iter[26/312]		Loss: 0.1124
2019-10-28 15:43:45,319 Training Epoch [35/40] Iter[27/312]		Loss: 0.1118
2019-10-28 15:43:45,398 Training Epoch [35/40] Iter[28/312]		Loss: 0.1147
2019-10-28 15:43:45,477 Training Epoch [35/40] Iter[29/312]		Loss: 0.1136
2019-10-28 15:43:45,556 Training Epoch [35/40] Iter[30/312]		Loss: 0.1125
2019-10-28 15:43:45,636 Training Epoch [35/40] Iter[31/312]		Loss: 0.1122
2019-10-28 15:43:45,715 Training Epoch [35/40] Iter[32/312]		Loss: 0.1111
2019-10-28 15:43:45,794 Training Epoch [35/40] Iter[33/312]		Loss: 0.1127
2019-10-28 15:43:45,873 Training Epoch [35/40] Iter[34/312]		Loss: 0.1124
2019-10-28 15:43:45,952 Training Epoch [35/40] Iter[35/312]		Loss: 0.1128
2019-10-28 15:43:46,031 Training Epoch [35/40] Iter[36/312]		Loss: 0.1133
2019-10-28 15:43:46,111 Training Epoch [35/40] Iter[37/312]		Loss: 0.1128
2019-10-28 15:43:46,190 Training Epoch [35/40] Iter[38/312]		Loss: 0.1124
2019-10-28 15:43:46,271 Training Epoch [35/40] Iter[39/312]		Loss: 0.1123
2019-10-28 15:43:46,349 Training Epoch [35/40] Iter[40/312]		Loss: 0.1121
2019-10-28 15:43:46,429 Training Epoch [35/40] Iter[41/312]		Loss: 0.1117
2019-10-28 15:43:46,508 Training Epoch [35/40] Iter[42/312]		Loss: 0.1112
2019-10-28 15:43:46,588 Training Epoch [35/40] Iter[43/312]		Loss: 0.1116
2019-10-28 15:43:46,667 Training Epoch [35/40] Iter[44/312]		Loss: 0.1127
2019-10-28 15:43:46,746 Training Epoch [35/40] Iter[45/312]		Loss: 0.1137
2019-10-28 15:43:46,825 Training Epoch [35/40] Iter[46/312]		Loss: 0.1134
2019-10-28 15:43:46,904 Training Epoch [35/40] Iter[47/312]		Loss: 0.1132
2019-10-28 15:43:46,984 Training Epoch [35/40] Iter[48/312]		Loss: 0.1136
2019-10-28 15:43:47,063 Training Epoch [35/40] Iter[49/312]		Loss: 0.1138
2019-10-28 15:43:47,143 Training Epoch [35/40] Iter[50/312]		Loss: 0.1137
2019-10-28 15:43:47,222 Training Epoch [35/40] Iter[51/312]		Loss: 0.1147
2019-10-28 15:43:47,301 Training Epoch [35/40] Iter[52/312]		Loss: 0.1147
2019-10-28 15:43:47,383 Training Epoch [35/40] Iter[53/312]		Loss: 0.1173
2019-10-28 15:43:47,462 Training Epoch [35/40] Iter[54/312]		Loss: 0.1163
2019-10-28 15:43:47,541 Training Epoch [35/40] Iter[55/312]		Loss: 0.1159
2019-10-28 15:43:47,620 Training Epoch [35/40] Iter[56/312]		Loss: 0.1154
2019-10-28 15:43:47,699 Training Epoch [35/40] Iter[57/312]		Loss: 0.1148
2019-10-28 15:43:47,779 Training Epoch [35/40] Iter[58/312]		Loss: 0.1147
2019-10-28 15:43:47,858 Training Epoch [35/40] Iter[59/312]		Loss: 0.1146
2019-10-28 15:43:47,937 Training Epoch [35/40] Iter[60/312]		Loss: 0.1148
2019-10-28 15:43:48,016 Training Epoch [35/40] Iter[61/312]		Loss: 0.1158
2019-10-28 15:43:48,095 Training Epoch [35/40] Iter[62/312]		Loss: 0.1156
2019-10-28 15:43:48,174 Training Epoch [35/40] Iter[63/312]		Loss: 0.1154
2019-10-28 15:43:48,254 Training Epoch [35/40] Iter[64/312]		Loss: 0.1158
2019-10-28 15:43:48,333 Training Epoch [35/40] Iter[65/312]		Loss: 0.1163
2019-10-28 15:43:48,412 Training Epoch [35/40] Iter[66/312]		Loss: 0.1161
2019-10-28 15:43:48,491 Training Epoch [35/40] Iter[67/312]		Loss: 0.1154
2019-10-28 15:43:48,571 Training Epoch [35/40] Iter[68/312]		Loss: 0.1149
2019-10-28 15:43:48,650 Training Epoch [35/40] Iter[69/312]		Loss: 0.1148
2019-10-28 15:43:48,729 Training Epoch [35/40] Iter[70/312]		Loss: 0.1160
2019-10-28 15:43:48,809 Training Epoch [35/40] Iter[71/312]		Loss: 0.1160
2019-10-28 15:43:48,888 Training Epoch [35/40] Iter[72/312]		Loss: 0.1156
2019-10-28 15:43:48,971 Training Epoch [35/40] Iter[73/312]		Loss: 0.1157
2019-10-28 15:43:49,050 Training Epoch [35/40] Iter[74/312]		Loss: 0.1159
2019-10-28 15:43:49,129 Training Epoch [35/40] Iter[75/312]		Loss: 0.1153
2019-10-28 15:43:49,208 Training Epoch [35/40] Iter[76/312]		Loss: 0.1152
2019-10-28 15:43:49,287 Training Epoch [35/40] Iter[77/312]		Loss: 0.1149
2019-10-28 15:43:49,366 Training Epoch [35/40] Iter[78/312]		Loss: 0.1152
2019-10-28 15:43:49,445 Training Epoch [35/40] Iter[79/312]		Loss: 0.1148
2019-10-28 15:43:49,524 Training Epoch [35/40] Iter[80/312]		Loss: 0.1143
2019-10-28 15:43:49,603 Training Epoch [35/40] Iter[81/312]		Loss: 0.1141
2019-10-28 15:43:49,682 Training Epoch [35/40] Iter[82/312]		Loss: 0.1141
2019-10-28 15:43:49,761 Training Epoch [35/40] Iter[83/312]		Loss: 0.1139
2019-10-28 15:43:49,840 Training Epoch [35/40] Iter[84/312]		Loss: 0.1140
2019-10-28 15:43:49,919 Training Epoch [35/40] Iter[85/312]		Loss: 0.1141
2019-10-28 15:43:49,998 Training Epoch [35/40] Iter[86/312]		Loss: 0.1139
2019-10-28 15:43:50,078 Training Epoch [35/40] Iter[87/312]		Loss: 0.1143
2019-10-28 15:43:50,157 Training Epoch [35/40] Iter[88/312]		Loss: 0.1139
2019-10-28 15:43:50,239 Training Epoch [35/40] Iter[89/312]		Loss: 0.1138
2019-10-28 15:43:50,318 Training Epoch [35/40] Iter[90/312]		Loss: 0.1136
2019-10-28 15:43:50,397 Training Epoch [35/40] Iter[91/312]		Loss: 0.1133
2019-10-28 15:43:50,476 Training Epoch [35/40] Iter[92/312]		Loss: 0.1141
2019-10-28 15:43:50,555 Training Epoch [35/40] Iter[93/312]		Loss: 0.1135
2019-10-28 15:43:50,639 Training Epoch [35/40] Iter[94/312]		Loss: 0.1138
2019-10-28 15:43:50,718 Training Epoch [35/40] Iter[95/312]		Loss: 0.1140
2019-10-28 15:43:50,797 Training Epoch [35/40] Iter[96/312]		Loss: 0.1139
2019-10-28 15:43:50,876 Training Epoch [35/40] Iter[97/312]		Loss: 0.1138
2019-10-28 15:43:50,955 Training Epoch [35/40] Iter[98/312]		Loss: 0.1135
2019-10-28 15:43:51,034 Training Epoch [35/40] Iter[99/312]		Loss: 0.1136
2019-10-28 15:43:51,113 Training Epoch [35/40] Iter[100/312]		Loss: 0.1134
2019-10-28 15:43:51,192 Training Epoch [35/40] Iter[101/312]		Loss: 0.1135
2019-10-28 15:43:51,271 Training Epoch [35/40] Iter[102/312]		Loss: 0.1134
2019-10-28 15:43:51,350 Training Epoch [35/40] Iter[103/312]		Loss: 0.1133
2019-10-28 15:43:51,429 Training Epoch [35/40] Iter[104/312]		Loss: 0.1131
2019-10-28 15:43:51,508 Training Epoch [35/40] Iter[105/312]		Loss: 0.1126
2019-10-28 15:43:51,587 Training Epoch [35/40] Iter[106/312]		Loss: 0.1124
2019-10-28 15:43:51,666 Training Epoch [35/40] Iter[107/312]		Loss: 0.1123
2019-10-28 15:43:51,745 Training Epoch [35/40] Iter[108/312]		Loss: 0.1119
2019-10-28 15:43:51,824 Training Epoch [35/40] Iter[109/312]		Loss: 0.1119
2019-10-28 15:43:51,903 Training Epoch [35/40] Iter[110/312]		Loss: 0.1116
2019-10-28 15:43:51,982 Training Epoch [35/40] Iter[111/312]		Loss: 0.1114
2019-10-28 15:43:52,061 Training Epoch [35/40] Iter[112/312]		Loss: 0.1116
2019-10-28 15:43:52,140 Training Epoch [35/40] Iter[113/312]		Loss: 0.1113
2019-10-28 15:43:52,219 Training Epoch [35/40] Iter[114/312]		Loss: 0.1109
2019-10-28 15:43:52,298 Training Epoch [35/40] Iter[115/312]		Loss: 0.1107
2019-10-28 15:43:52,378 Training Epoch [35/40] Iter[116/312]		Loss: 0.1103
2019-10-28 15:43:52,457 Training Epoch [35/40] Iter[117/312]		Loss: 0.1105
2019-10-28 15:43:52,536 Training Epoch [35/40] Iter[118/312]		Loss: 0.1108
2019-10-28 15:43:52,615 Training Epoch [35/40] Iter[119/312]		Loss: 0.1104
2019-10-28 15:43:52,694 Training Epoch [35/40] Iter[120/312]		Loss: 0.1100
2019-10-28 15:43:52,773 Training Epoch [35/40] Iter[121/312]		Loss: 0.1099
2019-10-28 15:43:52,852 Training Epoch [35/40] Iter[122/312]		Loss: 0.1096
2019-10-28 15:43:52,931 Training Epoch [35/40] Iter[123/312]		Loss: 0.1093
2019-10-28 15:43:53,010 Training Epoch [35/40] Iter[124/312]		Loss: 0.1092
2019-10-28 15:43:53,089 Training Epoch [35/40] Iter[125/312]		Loss: 0.1091
2019-10-28 15:43:53,168 Training Epoch [35/40] Iter[126/312]		Loss: 0.1094
2019-10-28 15:43:53,247 Training Epoch [35/40] Iter[127/312]		Loss: 0.1093
2019-10-28 15:43:53,326 Training Epoch [35/40] Iter[128/312]		Loss: 0.1092
2019-10-28 15:43:53,405 Training Epoch [35/40] Iter[129/312]		Loss: 0.1095
2019-10-28 15:43:53,484 Training Epoch [35/40] Iter[130/312]		Loss: 0.1094
2019-10-28 15:43:53,563 Training Epoch [35/40] Iter[131/312]		Loss: 0.1093
2019-10-28 15:43:53,643 Training Epoch [35/40] Iter[132/312]		Loss: 0.1093
2019-10-28 15:43:53,722 Training Epoch [35/40] Iter[133/312]		Loss: 0.1099
2019-10-28 15:43:53,800 Training Epoch [35/40] Iter[134/312]		Loss: 0.1100
2019-10-28 15:43:53,880 Training Epoch [35/40] Iter[135/312]		Loss: 0.1098
2019-10-28 15:43:53,959 Training Epoch [35/40] Iter[136/312]		Loss: 0.1094
2019-10-28 15:43:54,038 Training Epoch [35/40] Iter[137/312]		Loss: 0.1091
2019-10-28 15:43:54,117 Training Epoch [35/40] Iter[138/312]		Loss: 0.1093
2019-10-28 15:43:54,196 Training Epoch [35/40] Iter[139/312]		Loss: 0.1093
2019-10-28 15:43:54,275 Training Epoch [35/40] Iter[140/312]		Loss: 0.1092
2019-10-28 15:43:54,354 Training Epoch [35/40] Iter[141/312]		Loss: 0.1096
2019-10-28 15:43:54,433 Training Epoch [35/40] Iter[142/312]		Loss: 0.1095
2019-10-28 15:43:54,512 Training Epoch [35/40] Iter[143/312]		Loss: 0.1094
2019-10-28 15:43:54,591 Training Epoch [35/40] Iter[144/312]		Loss: 0.1096
2019-10-28 15:43:54,670 Training Epoch [35/40] Iter[145/312]		Loss: 0.1096
2019-10-28 15:43:54,749 Training Epoch [35/40] Iter[146/312]		Loss: 0.1098
2019-10-28 15:43:54,828 Training Epoch [35/40] Iter[147/312]		Loss: 0.1098
2019-10-28 15:43:54,907 Training Epoch [35/40] Iter[148/312]		Loss: 0.1098
2019-10-28 15:43:54,986 Training Epoch [35/40] Iter[149/312]		Loss: 0.1099
2019-10-28 15:43:55,065 Training Epoch [35/40] Iter[150/312]		Loss: 0.1099
2019-10-28 15:43:55,144 Training Epoch [35/40] Iter[151/312]		Loss: 0.1099
2019-10-28 15:43:55,223 Training Epoch [35/40] Iter[152/312]		Loss: 0.1100
2019-10-28 15:43:55,303 Training Epoch [35/40] Iter[153/312]		Loss: 0.1100
2019-10-28 15:43:55,381 Training Epoch [35/40] Iter[154/312]		Loss: 0.1099
2019-10-28 15:43:55,460 Training Epoch [35/40] Iter[155/312]		Loss: 0.1099
2019-10-28 15:43:55,540 Training Epoch [35/40] Iter[156/312]		Loss: 0.1098
2019-10-28 15:43:55,619 Training Epoch [35/40] Iter[157/312]		Loss: 0.1106
2019-10-28 15:43:55,698 Training Epoch [35/40] Iter[158/312]		Loss: 0.1104
2019-10-28 15:43:55,777 Training Epoch [35/40] Iter[159/312]		Loss: 0.1108
2019-10-28 15:43:55,856 Training Epoch [35/40] Iter[160/312]		Loss: 0.1107
2019-10-28 15:43:55,935 Training Epoch [35/40] Iter[161/312]		Loss: 0.1106
2019-10-28 15:43:56,014 Training Epoch [35/40] Iter[162/312]		Loss: 0.1106
2019-10-28 15:43:56,093 Training Epoch [35/40] Iter[163/312]		Loss: 0.1106
2019-10-28 15:43:56,172 Training Epoch [35/40] Iter[164/312]		Loss: 0.1104
2019-10-28 15:43:56,252 Training Epoch [35/40] Iter[165/312]		Loss: 0.1106
2019-10-28 15:43:56,331 Training Epoch [35/40] Iter[166/312]		Loss: 0.1109
2019-10-28 15:43:56,410 Training Epoch [35/40] Iter[167/312]		Loss: 0.1109
2019-10-28 15:43:56,489 Training Epoch [35/40] Iter[168/312]		Loss: 0.1111
2019-10-28 15:43:56,568 Training Epoch [35/40] Iter[169/312]		Loss: 0.1108
2019-10-28 15:43:56,646 Training Epoch [35/40] Iter[170/312]		Loss: 0.1111
2019-10-28 15:43:56,725 Training Epoch [35/40] Iter[171/312]		Loss: 0.1109
2019-10-28 15:43:56,805 Training Epoch [35/40] Iter[172/312]		Loss: 0.1109
2019-10-28 15:43:56,884 Training Epoch [35/40] Iter[173/312]		Loss: 0.1107
2019-10-28 15:43:56,963 Training Epoch [35/40] Iter[174/312]		Loss: 0.1106
2019-10-28 15:43:57,042 Training Epoch [35/40] Iter[175/312]		Loss: 0.1112
2019-10-28 15:43:57,121 Training Epoch [35/40] Iter[176/312]		Loss: 0.1113
2019-10-28 15:43:57,201 Training Epoch [35/40] Iter[177/312]		Loss: 0.1114
2019-10-28 15:43:57,280 Training Epoch [35/40] Iter[178/312]		Loss: 0.1115
2019-10-28 15:43:57,359 Training Epoch [35/40] Iter[179/312]		Loss: 0.1113
2019-10-28 15:43:57,438 Training Epoch [35/40] Iter[180/312]		Loss: 0.1114
2019-10-28 15:43:57,517 Training Epoch [35/40] Iter[181/312]		Loss: 0.1110
2019-10-28 15:43:57,596 Training Epoch [35/40] Iter[182/312]		Loss: 0.1109
2019-10-28 15:43:57,675 Training Epoch [35/40] Iter[183/312]		Loss: 0.1108
2019-10-28 15:43:57,754 Training Epoch [35/40] Iter[184/312]		Loss: 0.1112
2019-10-28 15:43:57,833 Training Epoch [35/40] Iter[185/312]		Loss: 0.1114
2019-10-28 15:43:57,912 Training Epoch [35/40] Iter[186/312]		Loss: 0.1112
2019-10-28 15:43:57,991 Training Epoch [35/40] Iter[187/312]		Loss: 0.1111
2019-10-28 15:43:58,070 Training Epoch [35/40] Iter[188/312]		Loss: 0.1112
2019-10-28 15:43:58,149 Training Epoch [35/40] Iter[189/312]		Loss: 0.1112
2019-10-28 15:43:58,228 Training Epoch [35/40] Iter[190/312]		Loss: 0.1111
2019-10-28 15:43:58,307 Training Epoch [35/40] Iter[191/312]		Loss: 0.1111
2019-10-28 15:43:58,386 Training Epoch [35/40] Iter[192/312]		Loss: 0.1111
2019-10-28 15:43:58,465 Training Epoch [35/40] Iter[193/312]		Loss: 0.1109
2019-10-28 15:43:58,544 Training Epoch [35/40] Iter[194/312]		Loss: 0.1108
2019-10-28 15:43:58,624 Training Epoch [35/40] Iter[195/312]		Loss: 0.1110
2019-10-28 15:43:58,703 Training Epoch [35/40] Iter[196/312]		Loss: 0.1108
2019-10-28 15:43:58,782 Training Epoch [35/40] Iter[197/312]		Loss: 0.1108
2019-10-28 15:43:58,861 Training Epoch [35/40] Iter[198/312]		Loss: 0.1107
2019-10-28 15:43:58,940 Training Epoch [35/40] Iter[199/312]		Loss: 0.1106
2019-10-28 15:43:59,019 Training Epoch [35/40] Iter[200/312]		Loss: 0.1105
2019-10-28 15:43:59,099 Training Epoch [35/40] Iter[201/312]		Loss: 0.1104
2019-10-28 15:43:59,179 Training Epoch [35/40] Iter[202/312]		Loss: 0.1103
2019-10-28 15:43:59,258 Training Epoch [35/40] Iter[203/312]		Loss: 0.1103
2019-10-28 15:43:59,338 Training Epoch [35/40] Iter[204/312]		Loss: 0.1102
2019-10-28 15:43:59,417 Training Epoch [35/40] Iter[205/312]		Loss: 0.1100
2019-10-28 15:43:59,496 Training Epoch [35/40] Iter[206/312]		Loss: 0.1099
2019-10-28 15:43:59,576 Training Epoch [35/40] Iter[207/312]		Loss: 0.1099
2019-10-28 15:43:59,655 Training Epoch [35/40] Iter[208/312]		Loss: 0.1105
2019-10-28 15:43:59,734 Training Epoch [35/40] Iter[209/312]		Loss: 0.1102
2019-10-28 15:43:59,813 Training Epoch [35/40] Iter[210/312]		Loss: 0.1102
2019-10-28 15:43:59,893 Training Epoch [35/40] Iter[211/312]		Loss: 0.1101
2019-10-28 15:43:59,972 Training Epoch [35/40] Iter[212/312]		Loss: 0.1102
2019-10-28 15:44:00,052 Training Epoch [35/40] Iter[213/312]		Loss: 0.1104
2019-10-28 15:44:00,131 Training Epoch [35/40] Iter[214/312]		Loss: 0.1105
2019-10-28 15:44:00,211 Training Epoch [35/40] Iter[215/312]		Loss: 0.1104
2019-10-28 15:44:00,290 Training Epoch [35/40] Iter[216/312]		Loss: 0.1104
2019-10-28 15:44:00,369 Training Epoch [35/40] Iter[217/312]		Loss: 0.1103
2019-10-28 15:44:00,448 Training Epoch [35/40] Iter[218/312]		Loss: 0.1103
2019-10-28 15:44:00,528 Training Epoch [35/40] Iter[219/312]		Loss: 0.1103
2019-10-28 15:44:00,607 Training Epoch [35/40] Iter[220/312]		Loss: 0.1104
2019-10-28 15:44:00,686 Training Epoch [35/40] Iter[221/312]		Loss: 0.1103
2019-10-28 15:44:00,765 Training Epoch [35/40] Iter[222/312]		Loss: 0.1102
2019-10-28 15:44:00,844 Training Epoch [35/40] Iter[223/312]		Loss: 0.1104
2019-10-28 15:44:00,923 Training Epoch [35/40] Iter[224/312]		Loss: 0.1105
2019-10-28 15:44:01,003 Training Epoch [35/40] Iter[225/312]		Loss: 0.1104
2019-10-28 15:44:01,082 Training Epoch [35/40] Iter[226/312]		Loss: 0.1102
2019-10-28 15:44:01,161 Training Epoch [35/40] Iter[227/312]		Loss: 0.1107
2019-10-28 15:44:01,241 Training Epoch [35/40] Iter[228/312]		Loss: 0.1108
2019-10-28 15:44:01,320 Training Epoch [35/40] Iter[229/312]		Loss: 0.1109
2019-10-28 15:44:01,399 Training Epoch [35/40] Iter[230/312]		Loss: 0.1109
2019-10-28 15:44:01,479 Training Epoch [35/40] Iter[231/312]		Loss: 0.1108
2019-10-28 15:44:01,558 Training Epoch [35/40] Iter[232/312]		Loss: 0.1113
2019-10-28 15:44:01,637 Training Epoch [35/40] Iter[233/312]		Loss: 0.1114
2019-10-28 15:44:01,716 Training Epoch [35/40] Iter[234/312]		Loss: 0.1112
2019-10-28 15:44:01,795 Training Epoch [35/40] Iter[235/312]		Loss: 0.1112
2019-10-28 15:44:01,874 Training Epoch [35/40] Iter[236/312]		Loss: 0.1111
2019-10-28 15:44:01,953 Training Epoch [35/40] Iter[237/312]		Loss: 0.1110
2019-10-28 15:44:02,032 Training Epoch [35/40] Iter[238/312]		Loss: 0.1110
2019-10-28 15:44:02,111 Training Epoch [35/40] Iter[239/312]		Loss: 0.1108
2019-10-28 15:44:02,191 Training Epoch [35/40] Iter[240/312]		Loss: 0.1107
2019-10-28 15:44:02,270 Training Epoch [35/40] Iter[241/312]		Loss: 0.1110
2019-10-28 15:44:02,349 Training Epoch [35/40] Iter[242/312]		Loss: 0.1110
2019-10-28 15:44:02,428 Training Epoch [35/40] Iter[243/312]		Loss: 0.1112
2019-10-28 15:44:02,510 Training Epoch [35/40] Iter[244/312]		Loss: 0.1113
2019-10-28 15:44:02,589 Training Epoch [35/40] Iter[245/312]		Loss: 0.1113
2019-10-28 15:44:02,668 Training Epoch [35/40] Iter[246/312]		Loss: 0.1115
2019-10-28 15:44:02,748 Training Epoch [35/40] Iter[247/312]		Loss: 0.1113
2019-10-28 15:44:02,827 Training Epoch [35/40] Iter[248/312]		Loss: 0.1112
2019-10-28 15:44:02,906 Training Epoch [35/40] Iter[249/312]		Loss: 0.1112
2019-10-28 15:44:02,986 Training Epoch [35/40] Iter[250/312]		Loss: 0.1113
2019-10-28 15:44:03,065 Training Epoch [35/40] Iter[251/312]		Loss: 0.1113
2019-10-28 15:44:03,144 Training Epoch [35/40] Iter[252/312]		Loss: 0.1112
2019-10-28 15:44:03,223 Training Epoch [35/40] Iter[253/312]		Loss: 0.1113
2019-10-28 15:44:03,302 Training Epoch [35/40] Iter[254/312]		Loss: 0.1112
2019-10-28 15:44:03,381 Training Epoch [35/40] Iter[255/312]		Loss: 0.1111
2019-10-28 15:44:03,461 Training Epoch [35/40] Iter[256/312]		Loss: 0.1109
2019-10-28 15:44:03,540 Training Epoch [35/40] Iter[257/312]		Loss: 0.1111
2019-10-28 15:44:03,619 Training Epoch [35/40] Iter[258/312]		Loss: 0.1111
2019-10-28 15:44:03,699 Training Epoch [35/40] Iter[259/312]		Loss: 0.1113
2019-10-28 15:44:03,778 Training Epoch [35/40] Iter[260/312]		Loss: 0.1115
2019-10-28 15:44:03,858 Training Epoch [35/40] Iter[261/312]		Loss: 0.1115
2019-10-28 15:44:03,937 Training Epoch [35/40] Iter[262/312]		Loss: 0.1114
2019-10-28 15:44:04,016 Training Epoch [35/40] Iter[263/312]		Loss: 0.1112
2019-10-28 15:44:04,096 Training Epoch [35/40] Iter[264/312]		Loss: 0.1111
2019-10-28 15:44:04,176 Training Epoch [35/40] Iter[265/312]		Loss: 0.1112
2019-10-28 15:44:04,256 Training Epoch [35/40] Iter[266/312]		Loss: 0.1114
2019-10-28 15:44:04,335 Training Epoch [35/40] Iter[267/312]		Loss: 0.1116
2019-10-28 15:44:04,415 Training Epoch [35/40] Iter[268/312]		Loss: 0.1116
2019-10-28 15:44:04,494 Training Epoch [35/40] Iter[269/312]		Loss: 0.1116
2019-10-28 15:44:04,574 Training Epoch [35/40] Iter[270/312]		Loss: 0.1116
2019-10-28 15:44:04,654 Training Epoch [35/40] Iter[271/312]		Loss: 0.1116
2019-10-28 15:44:04,733 Training Epoch [35/40] Iter[272/312]		Loss: 0.1116
2019-10-28 15:44:04,813 Training Epoch [35/40] Iter[273/312]		Loss: 0.1115
2019-10-28 15:44:04,892 Training Epoch [35/40] Iter[274/312]		Loss: 0.1115
2019-10-28 15:44:04,972 Training Epoch [35/40] Iter[275/312]		Loss: 0.1115
2019-10-28 15:44:05,051 Training Epoch [35/40] Iter[276/312]		Loss: 0.1115
2019-10-28 15:44:05,131 Training Epoch [35/40] Iter[277/312]		Loss: 0.1113
2019-10-28 15:44:05,210 Training Epoch [35/40] Iter[278/312]		Loss: 0.1112
2019-10-28 15:44:05,290 Training Epoch [35/40] Iter[279/312]		Loss: 0.1111
2019-10-28 15:44:05,369 Training Epoch [35/40] Iter[280/312]		Loss: 0.1111
2019-10-28 15:44:05,449 Training Epoch [35/40] Iter[281/312]		Loss: 0.1111
2019-10-28 15:44:05,528 Training Epoch [35/40] Iter[282/312]		Loss: 0.1111
2019-10-28 15:44:05,607 Training Epoch [35/40] Iter[283/312]		Loss: 0.1110
2019-10-28 15:44:05,687 Training Epoch [35/40] Iter[284/312]		Loss: 0.1110
2019-10-28 15:44:05,766 Training Epoch [35/40] Iter[285/312]		Loss: 0.1109
2019-10-28 15:44:05,846 Training Epoch [35/40] Iter[286/312]		Loss: 0.1108
2019-10-28 15:44:05,925 Training Epoch [35/40] Iter[287/312]		Loss: 0.1109
2019-10-28 15:44:06,005 Training Epoch [35/40] Iter[288/312]		Loss: 0.1108
2019-10-28 15:44:06,084 Training Epoch [35/40] Iter[289/312]		Loss: 0.1107
2019-10-28 15:44:06,163 Training Epoch [35/40] Iter[290/312]		Loss: 0.1107
2019-10-28 15:44:06,243 Training Epoch [35/40] Iter[291/312]		Loss: 0.1106
2019-10-28 15:44:06,322 Training Epoch [35/40] Iter[292/312]		Loss: 0.1106
2019-10-28 15:44:06,402 Training Epoch [35/40] Iter[293/312]		Loss: 0.1106
2019-10-28 15:44:06,482 Training Epoch [35/40] Iter[294/312]		Loss: 0.1105
2019-10-28 15:44:06,562 Training Epoch [35/40] Iter[295/312]		Loss: 0.1105
2019-10-28 15:44:06,641 Training Epoch [35/40] Iter[296/312]		Loss: 0.1105
2019-10-28 15:44:06,721 Training Epoch [35/40] Iter[297/312]		Loss: 0.1105
2019-10-28 15:44:06,800 Training Epoch [35/40] Iter[298/312]		Loss: 0.1104
2019-10-28 15:44:06,880 Training Epoch [35/40] Iter[299/312]		Loss: 0.1103
2019-10-28 15:44:06,960 Training Epoch [35/40] Iter[300/312]		Loss: 0.1104
2019-10-28 15:44:07,040 Training Epoch [35/40] Iter[301/312]		Loss: 0.1103
2019-10-28 15:44:07,119 Training Epoch [35/40] Iter[302/312]		Loss: 0.1103
2019-10-28 15:44:07,199 Training Epoch [35/40] Iter[303/312]		Loss: 0.1106
2019-10-28 15:44:07,278 Training Epoch [35/40] Iter[304/312]		Loss: 0.1108
2019-10-28 15:44:07,357 Training Epoch [35/40] Iter[305/312]		Loss: 0.1108
2019-10-28 15:44:07,436 Training Epoch [35/40] Iter[306/312]		Loss: 0.1107
2019-10-28 15:44:07,515 Training Epoch [35/40] Iter[307/312]		Loss: 0.1107
2019-10-28 15:44:07,594 Training Epoch [35/40] Iter[308/312]		Loss: 0.1107
2019-10-28 15:44:07,673 Training Epoch [35/40] Iter[309/312]		Loss: 0.1106
2019-10-28 15:44:07,752 Training Epoch [35/40] Iter[310/312]		Loss: 0.1108
2019-10-28 15:44:07,830 Training Epoch [35/40] Iter[311/312]		Loss: 0.1108
2019-10-28 15:44:07,869 Training Epoch [35/40] Iter[312/312]		Loss: 0.1108
2019-10-28 15:44:08,305 Testing Epoch [35/40] Iter[0/62]		Loss: 0.1322
2019-10-28 15:44:08,324 Testing Epoch [35/40] Iter[1/62]		Loss: 0.1292
2019-10-28 15:44:08,350 Testing Epoch [35/40] Iter[2/62]		Loss: 0.1129
2019-10-28 15:44:08,374 Testing Epoch [35/40] Iter[3/62]		Loss: 0.1166
2019-10-28 15:44:08,406 Testing Epoch [35/40] Iter[4/62]		Loss: 0.1208
2019-10-28 15:44:08,433 Testing Epoch [35/40] Iter[5/62]		Loss: 0.1158
2019-10-28 15:44:08,457 Testing Epoch [35/40] Iter[6/62]		Loss: 0.1182
2019-10-28 15:44:08,473 Testing Epoch [35/40] Iter[7/62]		Loss: 0.1200
2019-10-28 15:44:08,505 Testing Epoch [35/40] Iter[8/62]		Loss: 0.1226
2019-10-28 15:44:08,524 Testing Epoch [35/40] Iter[9/62]		Loss: 0.1214
2019-10-28 15:44:08,542 Testing Epoch [35/40] Iter[10/62]		Loss: 0.1225
2019-10-28 15:44:08,569 Testing Epoch [35/40] Iter[11/62]		Loss: 0.1286
2019-10-28 15:44:08,587 Testing Epoch [35/40] Iter[12/62]		Loss: 0.1282
2019-10-28 15:44:08,611 Testing Epoch [35/40] Iter[13/62]		Loss: 0.1299
2019-10-28 15:44:08,629 Testing Epoch [35/40] Iter[14/62]		Loss: 0.1421
2019-10-28 15:44:08,658 Testing Epoch [35/40] Iter[15/62]		Loss: 0.1436
2019-10-28 15:44:08,676 Testing Epoch [35/40] Iter[16/62]		Loss: 0.1406
2019-10-28 15:44:08,695 Testing Epoch [35/40] Iter[17/62]		Loss: 0.1413
2019-10-28 15:44:08,713 Testing Epoch [35/40] Iter[18/62]		Loss: 0.1389
2019-10-28 15:44:08,746 Testing Epoch [35/40] Iter[19/62]		Loss: 0.1369
2019-10-28 15:44:08,764 Testing Epoch [35/40] Iter[20/62]		Loss: 0.1388
2019-10-28 15:44:08,782 Testing Epoch [35/40] Iter[21/62]		Loss: 0.1372
2019-10-28 15:44:08,811 Testing Epoch [35/40] Iter[22/62]		Loss: 0.1385
2019-10-28 15:44:08,829 Testing Epoch [35/40] Iter[23/62]		Loss: 0.1376
2019-10-28 15:44:08,854 Testing Epoch [35/40] Iter[24/62]		Loss: 0.1409
2019-10-28 15:44:08,877 Testing Epoch [35/40] Iter[25/62]		Loss: 0.1401
2019-10-28 15:44:08,900 Testing Epoch [35/40] Iter[26/62]		Loss: 0.1390
2019-10-28 15:44:08,925 Testing Epoch [35/40] Iter[27/62]		Loss: 0.1462
2019-10-28 15:44:08,947 Testing Epoch [35/40] Iter[28/62]		Loss: 0.1500
2019-10-28 15:44:08,977 Testing Epoch [35/40] Iter[29/62]		Loss: 0.1501
2019-10-28 15:44:08,995 Testing Epoch [35/40] Iter[30/62]		Loss: 0.1502
2019-10-28 15:44:09,021 Testing Epoch [35/40] Iter[31/62]		Loss: 0.1492
2019-10-28 15:44:09,038 Testing Epoch [35/40] Iter[32/62]		Loss: 0.1510
2019-10-28 15:44:09,065 Testing Epoch [35/40] Iter[33/62]		Loss: 0.1500
2019-10-28 15:44:09,097 Testing Epoch [35/40] Iter[34/62]		Loss: 0.1522
2019-10-28 15:44:09,121 Testing Epoch [35/40] Iter[35/62]		Loss: 0.1518
2019-10-28 15:44:09,139 Testing Epoch [35/40] Iter[36/62]		Loss: 0.1497
2019-10-28 15:44:09,165 Testing Epoch [35/40] Iter[37/62]		Loss: 0.1486
2019-10-28 15:44:09,184 Testing Epoch [35/40] Iter[38/62]		Loss: 0.1475
2019-10-28 15:44:09,202 Testing Epoch [35/40] Iter[39/62]		Loss: 0.1478
2019-10-28 15:44:09,238 Testing Epoch [35/40] Iter[40/62]		Loss: 0.1495
2019-10-28 15:44:09,265 Testing Epoch [35/40] Iter[41/62]		Loss: 0.1510
2019-10-28 15:44:09,284 Testing Epoch [35/40] Iter[42/62]		Loss: 0.1491
2019-10-28 15:44:09,309 Testing Epoch [35/40] Iter[43/62]		Loss: 0.1484
2019-10-28 15:44:09,327 Testing Epoch [35/40] Iter[44/62]		Loss: 0.1469
2019-10-28 15:44:09,357 Testing Epoch [35/40] Iter[45/62]		Loss: 0.1466
2019-10-28 15:44:09,385 Testing Epoch [35/40] Iter[46/62]		Loss: 0.1461
2019-10-28 15:44:09,401 Testing Epoch [35/40] Iter[47/62]		Loss: 0.1521
2019-10-28 15:44:09,429 Testing Epoch [35/40] Iter[48/62]		Loss: 0.1512
2019-10-28 15:44:09,458 Testing Epoch [35/40] Iter[49/62]		Loss: 0.1534
2019-10-28 15:44:09,475 Testing Epoch [35/40] Iter[50/62]		Loss: 0.1526
2019-10-28 15:44:09,493 Testing Epoch [35/40] Iter[51/62]		Loss: 0.1525
2019-10-28 15:44:09,519 Testing Epoch [35/40] Iter[52/62]		Loss: 0.1513
2019-10-28 15:44:09,545 Testing Epoch [35/40] Iter[53/62]		Loss: 0.1515
2019-10-28 15:44:09,569 Testing Epoch [35/40] Iter[54/62]		Loss: 0.1503
2019-10-28 15:44:09,586 Testing Epoch [35/40] Iter[55/62]		Loss: 0.1499
2019-10-28 15:44:09,603 Testing Epoch [35/40] Iter[56/62]		Loss: 0.1493
2019-10-28 15:44:09,619 Testing Epoch [35/40] Iter[57/62]		Loss: 0.1495
2019-10-28 15:44:09,636 Testing Epoch [35/40] Iter[58/62]		Loss: 0.1490
2019-10-28 15:44:09,653 Testing Epoch [35/40] Iter[59/62]		Loss: 0.1501
2019-10-28 15:44:09,670 Testing Epoch [35/40] Iter[60/62]		Loss: 0.1493
2019-10-28 15:44:09,686 Testing Epoch [35/40] Iter[61/62]		Loss: 0.1492
2019-10-28 15:44:09,696 Testing Epoch [35/40] Iter[62/62]		Loss: 0.1498
2019-10-28 15:44:09,768 Saving the Model
2019-10-28 15:44:10,101 Training Epoch [36/40] Iter[0/312]		Loss: 0.0833
2019-10-28 15:44:10,198 Training Epoch [36/40] Iter[1/312]		Loss: 0.0882
2019-10-28 15:44:10,293 Training Epoch [36/40] Iter[2/312]		Loss: 0.1215
2019-10-28 15:44:10,371 Training Epoch [36/40] Iter[3/312]		Loss: 0.1200
2019-10-28 15:44:10,450 Training Epoch [36/40] Iter[4/312]		Loss: 0.1115
2019-10-28 15:44:10,528 Training Epoch [36/40] Iter[5/312]		Loss: 0.1120
2019-10-28 15:44:10,609 Training Epoch [36/40] Iter[6/312]		Loss: 0.1163
2019-10-28 15:44:10,689 Training Epoch [36/40] Iter[7/312]		Loss: 0.1277
2019-10-28 15:44:10,767 Training Epoch [36/40] Iter[8/312]		Loss: 0.1277
2019-10-28 15:44:10,845 Training Epoch [36/40] Iter[9/312]		Loss: 0.1237
2019-10-28 15:44:10,925 Training Epoch [36/40] Iter[10/312]		Loss: 0.1259
2019-10-28 15:44:11,004 Training Epoch [36/40] Iter[11/312]		Loss: 0.1244
2019-10-28 15:44:11,087 Training Epoch [36/40] Iter[12/312]		Loss: 0.1219
2019-10-28 15:44:11,166 Training Epoch [36/40] Iter[13/312]		Loss: 0.1212
2019-10-28 15:44:11,246 Training Epoch [36/40] Iter[14/312]		Loss: 0.1183
2019-10-28 15:44:11,325 Training Epoch [36/40] Iter[15/312]		Loss: 0.1166
2019-10-28 15:44:11,405 Training Epoch [36/40] Iter[16/312]		Loss: 0.1165
2019-10-28 15:44:11,484 Training Epoch [36/40] Iter[17/312]		Loss: 0.1150
2019-10-28 15:44:11,564 Training Epoch [36/40] Iter[18/312]		Loss: 0.1184
2019-10-28 15:44:11,643 Training Epoch [36/40] Iter[19/312]		Loss: 0.1249
2019-10-28 15:44:11,722 Training Epoch [36/40] Iter[20/312]		Loss: 0.1234
2019-10-28 15:44:11,802 Training Epoch [36/40] Iter[21/312]		Loss: 0.1221
2019-10-28 15:44:11,881 Training Epoch [36/40] Iter[22/312]		Loss: 0.1208
2019-10-28 15:44:11,961 Training Epoch [36/40] Iter[23/312]		Loss: 0.1198
2019-10-28 15:44:12,040 Training Epoch [36/40] Iter[24/312]		Loss: 0.1189
2019-10-28 15:44:12,119 Training Epoch [36/40] Iter[25/312]		Loss: 0.1191
2019-10-28 15:44:12,199 Training Epoch [36/40] Iter[26/312]		Loss: 0.1170
2019-10-28 15:44:12,278 Training Epoch [36/40] Iter[27/312]		Loss: 0.1171
2019-10-28 15:44:12,358 Training Epoch [36/40] Iter[28/312]		Loss: 0.1162
2019-10-28 15:44:12,438 Training Epoch [36/40] Iter[29/312]		Loss: 0.1150
2019-10-28 15:44:12,517 Training Epoch [36/40] Iter[30/312]		Loss: 0.1161
2019-10-28 15:44:12,596 Training Epoch [36/40] Iter[31/312]		Loss: 0.1151
2019-10-28 15:44:12,676 Training Epoch [36/40] Iter[32/312]		Loss: 0.1145
2019-10-28 15:44:12,755 Training Epoch [36/40] Iter[33/312]		Loss: 0.1155
2019-10-28 15:44:12,834 Training Epoch [36/40] Iter[34/312]		Loss: 0.1147
2019-10-28 15:44:12,914 Training Epoch [36/40] Iter[35/312]		Loss: 0.1141
2019-10-28 15:44:12,993 Training Epoch [36/40] Iter[36/312]		Loss: 0.1140
2019-10-28 15:44:13,072 Training Epoch [36/40] Iter[37/312]		Loss: 0.1140
2019-10-28 15:44:13,151 Training Epoch [36/40] Iter[38/312]		Loss: 0.1132
2019-10-28 15:44:13,231 Training Epoch [36/40] Iter[39/312]		Loss: 0.1131
2019-10-28 15:44:13,310 Training Epoch [36/40] Iter[40/312]		Loss: 0.1124
2019-10-28 15:44:13,390 Training Epoch [36/40] Iter[41/312]		Loss: 0.1138
2019-10-28 15:44:13,470 Training Epoch [36/40] Iter[42/312]		Loss: 0.1136
2019-10-28 15:44:13,550 Training Epoch [36/40] Iter[43/312]		Loss: 0.1136
2019-10-28 15:44:13,629 Training Epoch [36/40] Iter[44/312]		Loss: 0.1133
2019-10-28 15:44:13,709 Training Epoch [36/40] Iter[45/312]		Loss: 0.1123
2019-10-28 15:44:13,788 Training Epoch [36/40] Iter[46/312]		Loss: 0.1129
2019-10-28 15:44:13,867 Training Epoch [36/40] Iter[47/312]		Loss: 0.1132
2019-10-28 15:44:13,946 Training Epoch [36/40] Iter[48/312]		Loss: 0.1144
2019-10-28 15:44:14,025 Training Epoch [36/40] Iter[49/312]		Loss: 0.1166
2019-10-28 15:44:14,104 Training Epoch [36/40] Iter[50/312]		Loss: 0.1165
2019-10-28 15:44:14,184 Training Epoch [36/40] Iter[51/312]		Loss: 0.1161
2019-10-28 15:44:14,263 Training Epoch [36/40] Iter[52/312]		Loss: 0.1161
2019-10-28 15:44:14,342 Training Epoch [36/40] Iter[53/312]		Loss: 0.1165
2019-10-28 15:44:14,421 Training Epoch [36/40] Iter[54/312]		Loss: 0.1161
2019-10-28 15:44:14,500 Training Epoch [36/40] Iter[55/312]		Loss: 0.1155
2019-10-28 15:44:14,579 Training Epoch [36/40] Iter[56/312]		Loss: 0.1157
2019-10-28 15:44:14,658 Training Epoch [36/40] Iter[57/312]		Loss: 0.1158
2019-10-28 15:44:14,743 Training Epoch [36/40] Iter[58/312]		Loss: 0.1150
2019-10-28 15:44:14,827 Training Epoch [36/40] Iter[59/312]		Loss: 0.1143
2019-10-28 15:44:14,906 Training Epoch [36/40] Iter[60/312]		Loss: 0.1153
2019-10-28 15:44:14,985 Training Epoch [36/40] Iter[61/312]		Loss: 0.1156
2019-10-28 15:44:15,067 Training Epoch [36/40] Iter[62/312]		Loss: 0.1150
2019-10-28 15:44:15,147 Training Epoch [36/40] Iter[63/312]		Loss: 0.1147
2019-10-28 15:44:15,231 Training Epoch [36/40] Iter[64/312]		Loss: 0.1150
2019-10-28 15:44:15,311 Training Epoch [36/40] Iter[65/312]		Loss: 0.1146
2019-10-28 15:44:15,395 Training Epoch [36/40] Iter[66/312]		Loss: 0.1142
2019-10-28 15:44:15,479 Training Epoch [36/40] Iter[67/312]		Loss: 0.1140
2019-10-28 15:44:15,558 Training Epoch [36/40] Iter[68/312]		Loss: 0.1148
2019-10-28 15:44:15,638 Training Epoch [36/40] Iter[69/312]		Loss: 0.1143
2019-10-28 15:44:15,719 Training Epoch [36/40] Iter[70/312]		Loss: 0.1147
2019-10-28 15:44:15,798 Training Epoch [36/40] Iter[71/312]		Loss: 0.1146
2019-10-28 15:44:15,879 Training Epoch [36/40] Iter[72/312]		Loss: 0.1149
2019-10-28 15:44:15,958 Training Epoch [36/40] Iter[73/312]		Loss: 0.1147
2019-10-28 15:44:16,039 Training Epoch [36/40] Iter[74/312]		Loss: 0.1145
2019-10-28 15:44:16,119 Training Epoch [36/40] Iter[75/312]		Loss: 0.1142
2019-10-28 15:44:16,203 Training Epoch [36/40] Iter[76/312]		Loss: 0.1139
2019-10-28 15:44:16,283 Training Epoch [36/40] Iter[77/312]		Loss: 0.1140
2019-10-28 15:44:16,363 Training Epoch [36/40] Iter[78/312]		Loss: 0.1138
2019-10-28 15:44:16,443 Training Epoch [36/40] Iter[79/312]		Loss: 0.1139
2019-10-28 15:44:16,527 Training Epoch [36/40] Iter[80/312]		Loss: 0.1139
2019-10-28 15:44:16,606 Training Epoch [36/40] Iter[81/312]		Loss: 0.1134
2019-10-28 15:44:16,687 Training Epoch [36/40] Iter[82/312]		Loss: 0.1130
2019-10-28 15:44:16,767 Training Epoch [36/40] Iter[83/312]		Loss: 0.1130
2019-10-28 15:44:16,851 Training Epoch [36/40] Iter[84/312]		Loss: 0.1127
2019-10-28 15:44:16,930 Training Epoch [36/40] Iter[85/312]		Loss: 0.1126
2019-10-28 15:44:17,015 Training Epoch [36/40] Iter[86/312]		Loss: 0.1126
2019-10-28 15:44:17,099 Training Epoch [36/40] Iter[87/312]		Loss: 0.1123
2019-10-28 15:44:17,183 Training Epoch [36/40] Iter[88/312]		Loss: 0.1120
2019-10-28 15:44:17,262 Training Epoch [36/40] Iter[89/312]		Loss: 0.1122
2019-10-28 15:44:17,343 Training Epoch [36/40] Iter[90/312]		Loss: 0.1122
2019-10-28 15:44:17,423 Training Epoch [36/40] Iter[91/312]		Loss: 0.1120
2019-10-28 15:44:17,503 Training Epoch [36/40] Iter[92/312]		Loss: 0.1120
2019-10-28 15:44:17,587 Training Epoch [36/40] Iter[93/312]		Loss: 0.1119
2019-10-28 15:44:17,671 Training Epoch [36/40] Iter[94/312]		Loss: 0.1115
2019-10-28 15:44:17,751 Training Epoch [36/40] Iter[95/312]		Loss: 0.1113
2019-10-28 15:44:17,830 Training Epoch [36/40] Iter[96/312]		Loss: 0.1114
2019-10-28 15:44:17,911 Training Epoch [36/40] Iter[97/312]		Loss: 0.1113
2019-10-28 15:44:17,995 Training Epoch [36/40] Iter[98/312]		Loss: 0.1113
2019-10-28 15:44:18,079 Training Epoch [36/40] Iter[99/312]		Loss: 0.1115
2019-10-28 15:44:18,163 Training Epoch [36/40] Iter[100/312]		Loss: 0.1111
2019-10-28 15:44:18,242 Training Epoch [36/40] Iter[101/312]		Loss: 0.1109
2019-10-28 15:44:18,327 Training Epoch [36/40] Iter[102/312]		Loss: 0.1115
2019-10-28 15:44:18,411 Training Epoch [36/40] Iter[103/312]		Loss: 0.1114
2019-10-28 15:44:18,495 Training Epoch [36/40] Iter[104/312]		Loss: 0.1111
2019-10-28 15:44:18,574 Training Epoch [36/40] Iter[105/312]		Loss: 0.1110
2019-10-28 15:44:18,654 Training Epoch [36/40] Iter[106/312]		Loss: 0.1107
2019-10-28 15:44:18,733 Training Epoch [36/40] Iter[107/312]		Loss: 0.1107
2019-10-28 15:44:18,812 Training Epoch [36/40] Iter[108/312]		Loss: 0.1112
2019-10-28 15:44:18,891 Training Epoch [36/40] Iter[109/312]		Loss: 0.1110
2019-10-28 15:44:18,970 Training Epoch [36/40] Iter[110/312]		Loss: 0.1107
2019-10-28 15:44:19,049 Training Epoch [36/40] Iter[111/312]		Loss: 0.1105
2019-10-28 15:44:19,128 Training Epoch [36/40] Iter[112/312]		Loss: 0.1105
2019-10-28 15:44:19,207 Training Epoch [36/40] Iter[113/312]		Loss: 0.1106
2019-10-28 15:44:19,286 Training Epoch [36/40] Iter[114/312]		Loss: 0.1107
2019-10-28 15:44:19,366 Training Epoch [36/40] Iter[115/312]		Loss: 0.1110
2019-10-28 15:44:19,445 Training Epoch [36/40] Iter[116/312]		Loss: 0.1107
2019-10-28 15:44:19,524 Training Epoch [36/40] Iter[117/312]		Loss: 0.1110
2019-10-28 15:44:19,603 Training Epoch [36/40] Iter[118/312]		Loss: 0.1109
2019-10-28 15:44:19,682 Training Epoch [36/40] Iter[119/312]		Loss: 0.1105
2019-10-28 15:44:19,761 Training Epoch [36/40] Iter[120/312]		Loss: 0.1106
2019-10-28 15:44:19,840 Training Epoch [36/40] Iter[121/312]		Loss: 0.1107
2019-10-28 15:44:19,919 Training Epoch [36/40] Iter[122/312]		Loss: 0.1106
2019-10-28 15:44:19,998 Training Epoch [36/40] Iter[123/312]		Loss: 0.1103
2019-10-28 15:44:20,077 Training Epoch [36/40] Iter[124/312]		Loss: 0.1102
2019-10-28 15:44:20,156 Training Epoch [36/40] Iter[125/312]		Loss: 0.1106
2019-10-28 15:44:20,236 Training Epoch [36/40] Iter[126/312]		Loss: 0.1106
2019-10-28 15:44:20,315 Training Epoch [36/40] Iter[127/312]		Loss: 0.1111
2019-10-28 15:44:20,394 Training Epoch [36/40] Iter[128/312]		Loss: 0.1109
2019-10-28 15:44:20,473 Training Epoch [36/40] Iter[129/312]		Loss: 0.1107
2019-10-28 15:44:20,553 Training Epoch [36/40] Iter[130/312]		Loss: 0.1108
2019-10-28 15:44:20,632 Training Epoch [36/40] Iter[131/312]		Loss: 0.1107
2019-10-28 15:44:20,711 Training Epoch [36/40] Iter[132/312]		Loss: 0.1105
2019-10-28 15:44:20,790 Training Epoch [36/40] Iter[133/312]		Loss: 0.1105
2019-10-28 15:44:20,870 Training Epoch [36/40] Iter[134/312]		Loss: 0.1103
2019-10-28 15:44:20,949 Training Epoch [36/40] Iter[135/312]		Loss: 0.1103
2019-10-28 15:44:21,027 Training Epoch [36/40] Iter[136/312]		Loss: 0.1104
2019-10-28 15:44:21,112 Training Epoch [36/40] Iter[137/312]		Loss: 0.1103
2019-10-28 15:44:21,191 Training Epoch [36/40] Iter[138/312]		Loss: 0.1103
2019-10-28 15:44:21,270 Training Epoch [36/40] Iter[139/312]		Loss: 0.1110
2019-10-28 15:44:21,349 Training Epoch [36/40] Iter[140/312]		Loss: 0.1116
2019-10-28 15:44:21,428 Training Epoch [36/40] Iter[141/312]		Loss: 0.1120
2019-10-28 15:44:21,507 Training Epoch [36/40] Iter[142/312]		Loss: 0.1124
2019-10-28 15:44:21,586 Training Epoch [36/40] Iter[143/312]		Loss: 0.1123
2019-10-28 15:44:21,665 Training Epoch [36/40] Iter[144/312]		Loss: 0.1121
2019-10-28 15:44:21,744 Training Epoch [36/40] Iter[145/312]		Loss: 0.1120
2019-10-28 15:44:21,823 Training Epoch [36/40] Iter[146/312]		Loss: 0.1118
2019-10-28 15:44:21,902 Training Epoch [36/40] Iter[147/312]		Loss: 0.1117
2019-10-28 15:44:21,981 Training Epoch [36/40] Iter[148/312]		Loss: 0.1120
2019-10-28 15:44:22,060 Training Epoch [36/40] Iter[149/312]		Loss: 0.1118
2019-10-28 15:44:22,139 Training Epoch [36/40] Iter[150/312]		Loss: 0.1116
2019-10-28 15:44:22,218 Training Epoch [36/40] Iter[151/312]		Loss: 0.1118
2019-10-28 15:44:22,297 Training Epoch [36/40] Iter[152/312]		Loss: 0.1116
2019-10-28 15:44:22,376 Training Epoch [36/40] Iter[153/312]		Loss: 0.1117
2019-10-28 15:44:22,455 Training Epoch [36/40] Iter[154/312]		Loss: 0.1118
2019-10-28 15:44:22,534 Training Epoch [36/40] Iter[155/312]		Loss: 0.1118
2019-10-28 15:44:22,613 Training Epoch [36/40] Iter[156/312]		Loss: 0.1116
2019-10-28 15:44:22,692 Training Epoch [36/40] Iter[157/312]		Loss: 0.1115
2019-10-28 15:44:22,771 Training Epoch [36/40] Iter[158/312]		Loss: 0.1112
2019-10-28 15:44:22,850 Training Epoch [36/40] Iter[159/312]		Loss: 0.1111
2019-10-28 15:44:22,929 Training Epoch [36/40] Iter[160/312]		Loss: 0.1109
2019-10-28 15:44:23,008 Training Epoch [36/40] Iter[161/312]		Loss: 0.1111
2019-10-28 15:44:23,087 Training Epoch [36/40] Iter[162/312]		Loss: 0.1109
2019-10-28 15:44:23,166 Training Epoch [36/40] Iter[163/312]		Loss: 0.1108
2019-10-28 15:44:23,245 Training Epoch [36/40] Iter[164/312]		Loss: 0.1109
2019-10-28 15:44:23,325 Training Epoch [36/40] Iter[165/312]		Loss: 0.1111
2019-10-28 15:44:23,404 Training Epoch [36/40] Iter[166/312]		Loss: 0.1108
2019-10-28 15:44:23,483 Training Epoch [36/40] Iter[167/312]		Loss: 0.1107
2019-10-28 15:44:23,568 Training Epoch [36/40] Iter[168/312]		Loss: 0.1109
2019-10-28 15:44:23,647 Training Epoch [36/40] Iter[169/312]		Loss: 0.1113
2019-10-28 15:44:23,727 Training Epoch [36/40] Iter[170/312]		Loss: 0.1112
2019-10-28 15:44:23,806 Training Epoch [36/40] Iter[171/312]		Loss: 0.1113
2019-10-28 15:44:23,887 Training Epoch [36/40] Iter[172/312]		Loss: 0.1113
2019-10-28 15:44:23,966 Training Epoch [36/40] Iter[173/312]		Loss: 0.1116
2019-10-28 15:44:24,045 Training Epoch [36/40] Iter[174/312]		Loss: 0.1124
2019-10-28 15:44:24,124 Training Epoch [36/40] Iter[175/312]		Loss: 0.1123
2019-10-28 15:44:24,203 Training Epoch [36/40] Iter[176/312]		Loss: 0.1124
2019-10-28 15:44:24,282 Training Epoch [36/40] Iter[177/312]		Loss: 0.1125
2019-10-28 15:44:24,361 Training Epoch [36/40] Iter[178/312]		Loss: 0.1124
2019-10-28 15:44:24,441 Training Epoch [36/40] Iter[179/312]		Loss: 0.1123
2019-10-28 15:44:24,520 Training Epoch [36/40] Iter[180/312]		Loss: 0.1126
2019-10-28 15:44:24,599 Training Epoch [36/40] Iter[181/312]		Loss: 0.1126
2019-10-28 15:44:24,678 Training Epoch [36/40] Iter[182/312]		Loss: 0.1126
2019-10-28 15:44:24,757 Training Epoch [36/40] Iter[183/312]		Loss: 0.1125
2019-10-28 15:44:24,836 Training Epoch [36/40] Iter[184/312]		Loss: 0.1124
2019-10-28 15:44:24,915 Training Epoch [36/40] Iter[185/312]		Loss: 0.1124
2019-10-28 15:44:24,994 Training Epoch [36/40] Iter[186/312]		Loss: 0.1125
2019-10-28 15:44:25,074 Training Epoch [36/40] Iter[187/312]		Loss: 0.1126
2019-10-28 15:44:25,153 Training Epoch [36/40] Iter[188/312]		Loss: 0.1125
2019-10-28 15:44:25,232 Training Epoch [36/40] Iter[189/312]		Loss: 0.1125
2019-10-28 15:44:25,311 Training Epoch [36/40] Iter[190/312]		Loss: 0.1125
2019-10-28 15:44:25,391 Training Epoch [36/40] Iter[191/312]		Loss: 0.1125
2019-10-28 15:44:25,470 Training Epoch [36/40] Iter[192/312]		Loss: 0.1122
2019-10-28 15:44:25,549 Training Epoch [36/40] Iter[193/312]		Loss: 0.1121
2019-10-28 15:44:25,628 Training Epoch [36/40] Iter[194/312]		Loss: 0.1120
2019-10-28 15:44:25,707 Training Epoch [36/40] Iter[195/312]		Loss: 0.1117
2019-10-28 15:44:25,786 Training Epoch [36/40] Iter[196/312]		Loss: 0.1117
2019-10-28 15:44:25,865 Training Epoch [36/40] Iter[197/312]		Loss: 0.1118
2019-10-28 15:44:25,944 Training Epoch [36/40] Iter[198/312]		Loss: 0.1117
2019-10-28 15:44:26,023 Training Epoch [36/40] Iter[199/312]		Loss: 0.1116
2019-10-28 15:44:26,102 Training Epoch [36/40] Iter[200/312]		Loss: 0.1115
2019-10-28 15:44:26,181 Training Epoch [36/40] Iter[201/312]		Loss: 0.1114
2019-10-28 15:44:26,260 Training Epoch [36/40] Iter[202/312]		Loss: 0.1113
2019-10-28 15:44:26,340 Training Epoch [36/40] Iter[203/312]		Loss: 0.1112
2019-10-28 15:44:26,419 Training Epoch [36/40] Iter[204/312]		Loss: 0.1112
2019-10-28 15:44:26,498 Training Epoch [36/40] Iter[205/312]		Loss: 0.1114
2019-10-28 15:44:26,578 Training Epoch [36/40] Iter[206/312]		Loss: 0.1112
2019-10-28 15:44:26,657 Training Epoch [36/40] Iter[207/312]		Loss: 0.1114
2019-10-28 15:44:26,736 Training Epoch [36/40] Iter[208/312]		Loss: 0.1116
2019-10-28 15:44:26,815 Training Epoch [36/40] Iter[209/312]		Loss: 0.1117
2019-10-28 15:44:26,894 Training Epoch [36/40] Iter[210/312]		Loss: 0.1115
2019-10-28 15:44:26,973 Training Epoch [36/40] Iter[211/312]		Loss: 0.1114
2019-10-28 15:44:27,052 Training Epoch [36/40] Iter[212/312]		Loss: 0.1113
2019-10-28 15:44:27,131 Training Epoch [36/40] Iter[213/312]		Loss: 0.1112
2019-10-28 15:44:27,210 Training Epoch [36/40] Iter[214/312]		Loss: 0.1113
2019-10-28 15:44:27,289 Training Epoch [36/40] Iter[215/312]		Loss: 0.1111
2019-10-28 15:44:27,368 Training Epoch [36/40] Iter[216/312]		Loss: 0.1114
2019-10-28 15:44:27,448 Training Epoch [36/40] Iter[217/312]		Loss: 0.1117
2019-10-28 15:44:27,527 Training Epoch [36/40] Iter[218/312]		Loss: 0.1118
2019-10-28 15:44:27,606 Training Epoch [36/40] Iter[219/312]		Loss: 0.1118
2019-10-28 15:44:27,685 Training Epoch [36/40] Iter[220/312]		Loss: 0.1120
2019-10-28 15:44:27,764 Training Epoch [36/40] Iter[221/312]		Loss: 0.1121
2019-10-28 15:44:27,843 Training Epoch [36/40] Iter[222/312]		Loss: 0.1120
2019-10-28 15:44:27,922 Training Epoch [36/40] Iter[223/312]		Loss: 0.1121
2019-10-28 15:44:28,001 Training Epoch [36/40] Iter[224/312]		Loss: 0.1124
2019-10-28 15:44:28,080 Training Epoch [36/40] Iter[225/312]		Loss: 0.1124
2019-10-28 15:44:28,159 Training Epoch [36/40] Iter[226/312]		Loss: 0.1123
2019-10-28 15:44:28,238 Training Epoch [36/40] Iter[227/312]		Loss: 0.1124
2019-10-28 15:44:28,317 Training Epoch [36/40] Iter[228/312]		Loss: 0.1123
2019-10-28 15:44:28,396 Training Epoch [36/40] Iter[229/312]		Loss: 0.1122
2019-10-28 15:44:28,475 Training Epoch [36/40] Iter[230/312]		Loss: 0.1122
2019-10-28 15:44:28,554 Training Epoch [36/40] Iter[231/312]		Loss: 0.1122
2019-10-28 15:44:28,633 Training Epoch [36/40] Iter[232/312]		Loss: 0.1120
2019-10-28 15:44:28,713 Training Epoch [36/40] Iter[233/312]		Loss: 0.1119
2019-10-28 15:44:28,792 Training Epoch [36/40] Iter[234/312]		Loss: 0.1118
2019-10-28 15:44:28,871 Training Epoch [36/40] Iter[235/312]		Loss: 0.1118
2019-10-28 15:44:28,950 Training Epoch [36/40] Iter[236/312]		Loss: 0.1118
2019-10-28 15:44:29,029 Training Epoch [36/40] Iter[237/312]		Loss: 0.1116
2019-10-28 15:44:29,108 Training Epoch [36/40] Iter[238/312]		Loss: 0.1115
2019-10-28 15:44:29,192 Training Epoch [36/40] Iter[239/312]		Loss: 0.1117
2019-10-28 15:44:29,271 Training Epoch [36/40] Iter[240/312]		Loss: 0.1118
2019-10-28 15:44:29,350 Training Epoch [36/40] Iter[241/312]		Loss: 0.1120
2019-10-28 15:44:29,429 Training Epoch [36/40] Iter[242/312]		Loss: 0.1118
2019-10-28 15:44:29,511 Training Epoch [36/40] Iter[243/312]		Loss: 0.1119
2019-10-28 15:44:29,590 Training Epoch [36/40] Iter[244/312]		Loss: 0.1119
2019-10-28 15:44:29,670 Training Epoch [36/40] Iter[245/312]		Loss: 0.1119
2019-10-28 15:44:29,750 Training Epoch [36/40] Iter[246/312]		Loss: 0.1119
2019-10-28 15:44:29,829 Training Epoch [36/40] Iter[247/312]		Loss: 0.1119
2019-10-28 15:44:29,910 Training Epoch [36/40] Iter[248/312]		Loss: 0.1117
2019-10-28 15:44:29,990 Training Epoch [36/40] Iter[249/312]		Loss: 0.1121
2019-10-28 15:44:30,069 Training Epoch [36/40] Iter[250/312]		Loss: 0.1120
2019-10-28 15:44:30,148 Training Epoch [36/40] Iter[251/312]		Loss: 0.1118
2019-10-28 15:44:30,227 Training Epoch [36/40] Iter[252/312]		Loss: 0.1117
2019-10-28 15:44:30,306 Training Epoch [36/40] Iter[253/312]		Loss: 0.1118
2019-10-28 15:44:30,385 Training Epoch [36/40] Iter[254/312]		Loss: 0.1118
2019-10-28 15:44:30,465 Training Epoch [36/40] Iter[255/312]		Loss: 0.1117
2019-10-28 15:44:30,544 Training Epoch [36/40] Iter[256/312]		Loss: 0.1116
2019-10-28 15:44:30,623 Training Epoch [36/40] Iter[257/312]		Loss: 0.1115
2019-10-28 15:44:30,702 Training Epoch [36/40] Iter[258/312]		Loss: 0.1114
2019-10-28 15:44:30,781 Training Epoch [36/40] Iter[259/312]		Loss: 0.1114
2019-10-28 15:44:30,860 Training Epoch [36/40] Iter[260/312]		Loss: 0.1114
2019-10-28 15:44:30,939 Training Epoch [36/40] Iter[261/312]		Loss: 0.1112
2019-10-28 15:44:31,018 Training Epoch [36/40] Iter[262/312]		Loss: 0.1115
2019-10-28 15:44:31,097 Training Epoch [36/40] Iter[263/312]		Loss: 0.1114
2019-10-28 15:44:31,176 Training Epoch [36/40] Iter[264/312]		Loss: 0.1119
2019-10-28 15:44:31,255 Training Epoch [36/40] Iter[265/312]		Loss: 0.1118
2019-10-28 15:44:31,334 Training Epoch [36/40] Iter[266/312]		Loss: 0.1117
2019-10-28 15:44:31,414 Training Epoch [36/40] Iter[267/312]		Loss: 0.1116
2019-10-28 15:44:31,493 Training Epoch [36/40] Iter[268/312]		Loss: 0.1115
2019-10-28 15:44:31,572 Training Epoch [36/40] Iter[269/312]		Loss: 0.1115
2019-10-28 15:44:31,652 Training Epoch [36/40] Iter[270/312]		Loss: 0.1114
2019-10-28 15:44:31,731 Training Epoch [36/40] Iter[271/312]		Loss: 0.1112
2019-10-28 15:44:31,810 Training Epoch [36/40] Iter[272/312]		Loss: 0.1112
2019-10-28 15:44:31,890 Training Epoch [36/40] Iter[273/312]		Loss: 0.1110
2019-10-28 15:44:31,969 Training Epoch [36/40] Iter[274/312]		Loss: 0.1110
2019-10-28 15:44:32,049 Training Epoch [36/40] Iter[275/312]		Loss: 0.1109
2019-10-28 15:44:32,128 Training Epoch [36/40] Iter[276/312]		Loss: 0.1109
2019-10-28 15:44:32,207 Training Epoch [36/40] Iter[277/312]		Loss: 0.1107
2019-10-28 15:44:32,286 Training Epoch [36/40] Iter[278/312]		Loss: 0.1106
2019-10-28 15:44:32,365 Training Epoch [36/40] Iter[279/312]		Loss: 0.1105
2019-10-28 15:44:32,445 Training Epoch [36/40] Iter[280/312]		Loss: 0.1108
2019-10-28 15:44:32,524 Training Epoch [36/40] Iter[281/312]		Loss: 0.1107
2019-10-28 15:44:32,603 Training Epoch [36/40] Iter[282/312]		Loss: 0.1108
2019-10-28 15:44:32,682 Training Epoch [36/40] Iter[283/312]		Loss: 0.1108
2019-10-28 15:44:32,761 Training Epoch [36/40] Iter[284/312]		Loss: 0.1108
2019-10-28 15:44:32,840 Training Epoch [36/40] Iter[285/312]		Loss: 0.1108
2019-10-28 15:44:32,919 Training Epoch [36/40] Iter[286/312]		Loss: 0.1107
2019-10-28 15:44:32,998 Training Epoch [36/40] Iter[287/312]		Loss: 0.1110
2019-10-28 15:44:33,077 Training Epoch [36/40] Iter[288/312]		Loss: 0.1109
2019-10-28 15:44:33,156 Training Epoch [36/40] Iter[289/312]		Loss: 0.1109
2019-10-28 15:44:33,235 Training Epoch [36/40] Iter[290/312]		Loss: 0.1109
2019-10-28 15:44:33,314 Training Epoch [36/40] Iter[291/312]		Loss: 0.1110
2019-10-28 15:44:33,393 Training Epoch [36/40] Iter[292/312]		Loss: 0.1109
2019-10-28 15:44:33,472 Training Epoch [36/40] Iter[293/312]		Loss: 0.1108
2019-10-28 15:44:33,552 Training Epoch [36/40] Iter[294/312]		Loss: 0.1108
2019-10-28 15:44:33,631 Training Epoch [36/40] Iter[295/312]		Loss: 0.1108
2019-10-28 15:44:33,710 Training Epoch [36/40] Iter[296/312]		Loss: 0.1107
2019-10-28 15:44:33,789 Training Epoch [36/40] Iter[297/312]		Loss: 0.1111
2019-10-28 15:44:33,868 Training Epoch [36/40] Iter[298/312]		Loss: 0.1111
2019-10-28 15:44:33,947 Training Epoch [36/40] Iter[299/312]		Loss: 0.1112
2019-10-28 15:44:34,026 Training Epoch [36/40] Iter[300/312]		Loss: 0.1111
2019-10-28 15:44:34,105 Training Epoch [36/40] Iter[301/312]		Loss: 0.1109
2019-10-28 15:44:34,184 Training Epoch [36/40] Iter[302/312]		Loss: 0.1110
2019-10-28 15:44:34,263 Training Epoch [36/40] Iter[303/312]		Loss: 0.1110
2019-10-28 15:44:34,342 Training Epoch [36/40] Iter[304/312]		Loss: 0.1111
2019-10-28 15:44:34,421 Training Epoch [36/40] Iter[305/312]		Loss: 0.1111
2019-10-28 15:44:34,504 Training Epoch [36/40] Iter[306/312]		Loss: 0.1110
2019-10-28 15:44:34,582 Training Epoch [36/40] Iter[307/312]		Loss: 0.1112
2019-10-28 15:44:34,660 Training Epoch [36/40] Iter[308/312]		Loss: 0.1113
2019-10-28 15:44:34,738 Training Epoch [36/40] Iter[309/312]		Loss: 0.1112
2019-10-28 15:44:34,817 Training Epoch [36/40] Iter[310/312]		Loss: 0.1112
2019-10-28 15:44:34,895 Training Epoch [36/40] Iter[311/312]		Loss: 0.1111
2019-10-28 15:44:34,933 Training Epoch [36/40] Iter[312/312]		Loss: 0.1113
2019-10-28 15:44:35,374 Testing Epoch [36/40] Iter[0/62]		Loss: 0.1273
2019-10-28 15:44:35,400 Testing Epoch [36/40] Iter[1/62]		Loss: 0.1281
2019-10-28 15:44:35,422 Testing Epoch [36/40] Iter[2/62]		Loss: 0.1112
2019-10-28 15:44:35,439 Testing Epoch [36/40] Iter[3/62]		Loss: 0.1171
2019-10-28 15:44:35,462 Testing Epoch [36/40] Iter[4/62]		Loss: 0.1208
2019-10-28 15:44:35,478 Testing Epoch [36/40] Iter[5/62]		Loss: 0.1153
2019-10-28 15:44:35,506 Testing Epoch [36/40] Iter[6/62]		Loss: 0.1171
2019-10-28 15:44:35,523 Testing Epoch [36/40] Iter[7/62]		Loss: 0.1190
2019-10-28 15:44:35,545 Testing Epoch [36/40] Iter[8/62]		Loss: 0.1215
2019-10-28 15:44:35,570 Testing Epoch [36/40] Iter[9/62]		Loss: 0.1206
2019-10-28 15:44:35,589 Testing Epoch [36/40] Iter[10/62]		Loss: 0.1212
2019-10-28 15:44:35,606 Testing Epoch [36/40] Iter[11/62]		Loss: 0.1271
2019-10-28 15:44:35,641 Testing Epoch [36/40] Iter[12/62]		Loss: 0.1266
2019-10-28 15:44:35,658 Testing Epoch [36/40] Iter[13/62]		Loss: 0.1287
2019-10-28 15:44:35,679 Testing Epoch [36/40] Iter[14/62]		Loss: 0.1404
2019-10-28 15:44:35,706 Testing Epoch [36/40] Iter[15/62]		Loss: 0.1425
2019-10-28 15:44:35,733 Testing Epoch [36/40] Iter[16/62]		Loss: 0.1395
2019-10-28 15:44:35,757 Testing Epoch [36/40] Iter[17/62]		Loss: 0.1400
2019-10-28 15:44:35,775 Testing Epoch [36/40] Iter[18/62]		Loss: 0.1378
2019-10-28 15:44:35,800 Testing Epoch [36/40] Iter[19/62]		Loss: 0.1360
2019-10-28 15:44:35,818 Testing Epoch [36/40] Iter[20/62]		Loss: 0.1378
2019-10-28 15:44:35,845 Testing Epoch [36/40] Iter[21/62]		Loss: 0.1362
2019-10-28 15:44:35,869 Testing Epoch [36/40] Iter[22/62]		Loss: 0.1375
2019-10-28 15:44:35,893 Testing Epoch [36/40] Iter[23/62]		Loss: 0.1366
2019-10-28 15:44:35,917 Testing Epoch [36/40] Iter[24/62]		Loss: 0.1398
2019-10-28 15:44:35,941 Testing Epoch [36/40] Iter[25/62]		Loss: 0.1390
2019-10-28 15:44:35,965 Testing Epoch [36/40] Iter[26/62]		Loss: 0.1377
2019-10-28 15:44:35,983 Testing Epoch [36/40] Iter[27/62]		Loss: 0.1450
2019-10-28 15:44:36,009 Testing Epoch [36/40] Iter[28/62]		Loss: 0.1486
2019-10-28 15:44:36,026 Testing Epoch [36/40] Iter[29/62]		Loss: 0.1486
2019-10-28 15:44:36,044 Testing Epoch [36/40] Iter[30/62]		Loss: 0.1488
2019-10-28 15:44:36,073 Testing Epoch [36/40] Iter[31/62]		Loss: 0.1478
2019-10-28 15:44:36,101 Testing Epoch [36/40] Iter[32/62]		Loss: 0.1495
2019-10-28 15:44:36,119 Testing Epoch [36/40] Iter[33/62]		Loss: 0.1484
2019-10-28 15:44:36,137 Testing Epoch [36/40] Iter[34/62]		Loss: 0.1506
2019-10-28 15:44:36,161 Testing Epoch [36/40] Iter[35/62]		Loss: 0.1503
2019-10-28 15:44:36,183 Testing Epoch [36/40] Iter[36/62]		Loss: 0.1482
2019-10-28 15:44:36,203 Testing Epoch [36/40] Iter[37/62]		Loss: 0.1472
2019-10-28 15:44:36,221 Testing Epoch [36/40] Iter[38/62]		Loss: 0.1461
2019-10-28 15:44:36,249 Testing Epoch [36/40] Iter[39/62]		Loss: 0.1464
2019-10-28 15:44:36,274 Testing Epoch [36/40] Iter[40/62]		Loss: 0.1482
2019-10-28 15:44:36,292 Testing Epoch [36/40] Iter[41/62]		Loss: 0.1496
2019-10-28 15:44:36,310 Testing Epoch [36/40] Iter[42/62]		Loss: 0.1477
2019-10-28 15:44:36,338 Testing Epoch [36/40] Iter[43/62]		Loss: 0.1470
2019-10-28 15:44:36,363 Testing Epoch [36/40] Iter[44/62]		Loss: 0.1454
2019-10-28 15:44:36,389 Testing Epoch [36/40] Iter[45/62]		Loss: 0.1452
2019-10-28 15:44:36,413 Testing Epoch [36/40] Iter[46/62]		Loss: 0.1449
2019-10-28 15:44:36,430 Testing Epoch [36/40] Iter[47/62]		Loss: 0.1508
2019-10-28 15:44:36,448 Testing Epoch [36/40] Iter[48/62]		Loss: 0.1498
2019-10-28 15:44:36,473 Testing Epoch [36/40] Iter[49/62]		Loss: 0.1520
2019-10-28 15:44:36,503 Testing Epoch [36/40] Iter[50/62]		Loss: 0.1512
2019-10-28 15:44:36,521 Testing Epoch [36/40] Iter[51/62]		Loss: 0.1511
2019-10-28 15:44:36,545 Testing Epoch [36/40] Iter[52/62]		Loss: 0.1499
2019-10-28 15:44:36,569 Testing Epoch [36/40] Iter[53/62]		Loss: 0.1502
2019-10-28 15:44:36,587 Testing Epoch [36/40] Iter[54/62]		Loss: 0.1490
2019-10-28 15:44:36,604 Testing Epoch [36/40] Iter[55/62]		Loss: 0.1487
2019-10-28 15:44:36,620 Testing Epoch [36/40] Iter[56/62]		Loss: 0.1480
2019-10-28 15:44:36,637 Testing Epoch [36/40] Iter[57/62]		Loss: 0.1482
2019-10-28 15:44:36,654 Testing Epoch [36/40] Iter[58/62]		Loss: 0.1478
2019-10-28 15:44:36,670 Testing Epoch [36/40] Iter[59/62]		Loss: 0.1488
2019-10-28 15:44:36,687 Testing Epoch [36/40] Iter[60/62]		Loss: 0.1480
2019-10-28 15:44:36,704 Testing Epoch [36/40] Iter[61/62]		Loss: 0.1478
2019-10-28 15:44:36,713 Testing Epoch [36/40] Iter[62/62]		Loss: 0.1485
2019-10-28 15:44:36,784 Saving the Model
2019-10-28 15:44:37,210 Training Epoch [37/40] Iter[0/312]		Loss: 0.1308
2019-10-28 15:44:37,289 Training Epoch [37/40] Iter[1/312]		Loss: 0.1381
2019-10-28 15:44:37,371 Training Epoch [37/40] Iter[2/312]		Loss: 0.1346
2019-10-28 15:44:37,450 Training Epoch [37/40] Iter[3/312]		Loss: 0.1587
2019-10-28 15:44:37,535 Training Epoch [37/40] Iter[4/312]		Loss: 0.1471
2019-10-28 15:44:37,613 Training Epoch [37/40] Iter[5/312]		Loss: 0.1353
2019-10-28 15:44:37,695 Training Epoch [37/40] Iter[6/312]		Loss: 0.1273
2019-10-28 15:44:37,774 Training Epoch [37/40] Iter[7/312]		Loss: 0.1302
2019-10-28 15:44:37,852 Training Epoch [37/40] Iter[8/312]		Loss: 0.1316
2019-10-28 15:44:37,931 Training Epoch [37/40] Iter[9/312]		Loss: 0.1259
2019-10-28 15:44:38,010 Training Epoch [37/40] Iter[10/312]		Loss: 0.1233
2019-10-28 15:44:38,089 Training Epoch [37/40] Iter[11/312]		Loss: 0.1189
2019-10-28 15:44:38,168 Training Epoch [37/40] Iter[12/312]		Loss: 0.1162
2019-10-28 15:44:38,247 Training Epoch [37/40] Iter[13/312]		Loss: 0.1144
2019-10-28 15:44:38,326 Training Epoch [37/40] Iter[14/312]		Loss: 0.1131
2019-10-28 15:44:38,405 Training Epoch [37/40] Iter[15/312]		Loss: 0.1130
2019-10-28 15:44:38,484 Training Epoch [37/40] Iter[16/312]		Loss: 0.1139
2019-10-28 15:44:38,563 Training Epoch [37/40] Iter[17/312]		Loss: 0.1169
2019-10-28 15:44:38,642 Training Epoch [37/40] Iter[18/312]		Loss: 0.1186
2019-10-28 15:44:38,722 Training Epoch [37/40] Iter[19/312]		Loss: 0.1185
2019-10-28 15:44:38,801 Training Epoch [37/40] Iter[20/312]		Loss: 0.1214
2019-10-28 15:44:38,880 Training Epoch [37/40] Iter[21/312]		Loss: 0.1194
2019-10-28 15:44:38,958 Training Epoch [37/40] Iter[22/312]		Loss: 0.1193
2019-10-28 15:44:39,037 Training Epoch [37/40] Iter[23/312]		Loss: 0.1190
2019-10-28 15:44:39,116 Training Epoch [37/40] Iter[24/312]		Loss: 0.1184
2019-10-28 15:44:39,195 Training Epoch [37/40] Iter[25/312]		Loss: 0.1207
2019-10-28 15:44:39,274 Training Epoch [37/40] Iter[26/312]		Loss: 0.1195
2019-10-28 15:44:39,353 Training Epoch [37/40] Iter[27/312]		Loss: 0.1199
2019-10-28 15:44:39,432 Training Epoch [37/40] Iter[28/312]		Loss: 0.1197
2019-10-28 15:44:39,512 Training Epoch [37/40] Iter[29/312]		Loss: 0.1214
2019-10-28 15:44:39,591 Training Epoch [37/40] Iter[30/312]		Loss: 0.1202
2019-10-28 15:44:39,669 Training Epoch [37/40] Iter[31/312]		Loss: 0.1193
2019-10-28 15:44:39,748 Training Epoch [37/40] Iter[32/312]		Loss: 0.1184
2019-10-28 15:44:39,828 Training Epoch [37/40] Iter[33/312]		Loss: 0.1180
2019-10-28 15:44:39,907 Training Epoch [37/40] Iter[34/312]		Loss: 0.1170
2019-10-28 15:44:39,986 Training Epoch [37/40] Iter[35/312]		Loss: 0.1159
2019-10-28 15:44:40,065 Training Epoch [37/40] Iter[36/312]		Loss: 0.1147
2019-10-28 15:44:40,144 Training Epoch [37/40] Iter[37/312]		Loss: 0.1153
2019-10-28 15:44:40,223 Training Epoch [37/40] Iter[38/312]		Loss: 0.1149
2019-10-28 15:44:40,302 Training Epoch [37/40] Iter[39/312]		Loss: 0.1152
2019-10-28 15:44:40,381 Training Epoch [37/40] Iter[40/312]		Loss: 0.1158
2019-10-28 15:44:40,461 Training Epoch [37/40] Iter[41/312]		Loss: 0.1160
2019-10-28 15:44:40,540 Training Epoch [37/40] Iter[42/312]		Loss: 0.1156
2019-10-28 15:44:40,619 Training Epoch [37/40] Iter[43/312]		Loss: 0.1162
2019-10-28 15:44:40,698 Training Epoch [37/40] Iter[44/312]		Loss: 0.1164
2019-10-28 15:44:40,777 Training Epoch [37/40] Iter[45/312]		Loss: 0.1164
2019-10-28 15:44:40,856 Training Epoch [37/40] Iter[46/312]		Loss: 0.1153
2019-10-28 15:44:40,935 Training Epoch [37/40] Iter[47/312]		Loss: 0.1148
2019-10-28 15:44:41,013 Training Epoch [37/40] Iter[48/312]		Loss: 0.1142
2019-10-28 15:44:41,092 Training Epoch [37/40] Iter[49/312]		Loss: 0.1154
2019-10-28 15:44:41,171 Training Epoch [37/40] Iter[50/312]		Loss: 0.1151
2019-10-28 15:44:41,250 Training Epoch [37/40] Iter[51/312]		Loss: 0.1150
2019-10-28 15:44:41,329 Training Epoch [37/40] Iter[52/312]		Loss: 0.1144
2019-10-28 15:44:41,408 Training Epoch [37/40] Iter[53/312]		Loss: 0.1137
2019-10-28 15:44:41,487 Training Epoch [37/40] Iter[54/312]		Loss: 0.1136
2019-10-28 15:44:41,566 Training Epoch [37/40] Iter[55/312]		Loss: 0.1129
2019-10-28 15:44:41,646 Training Epoch [37/40] Iter[56/312]		Loss: 0.1123
2019-10-28 15:44:41,725 Training Epoch [37/40] Iter[57/312]		Loss: 0.1125
2019-10-28 15:44:41,804 Training Epoch [37/40] Iter[58/312]		Loss: 0.1129
2019-10-28 15:44:41,883 Training Epoch [37/40] Iter[59/312]		Loss: 0.1123
2019-10-28 15:44:41,962 Training Epoch [37/40] Iter[60/312]		Loss: 0.1130
2019-10-28 15:44:42,041 Training Epoch [37/40] Iter[61/312]		Loss: 0.1122
2019-10-28 15:44:42,120 Training Epoch [37/40] Iter[62/312]		Loss: 0.1124
2019-10-28 15:44:42,199 Training Epoch [37/40] Iter[63/312]		Loss: 0.1124
2019-10-28 15:44:42,278 Training Epoch [37/40] Iter[64/312]		Loss: 0.1122
2019-10-28 15:44:42,357 Training Epoch [37/40] Iter[65/312]		Loss: 0.1115
2019-10-28 15:44:42,436 Training Epoch [37/40] Iter[66/312]		Loss: 0.1118
2019-10-28 15:44:42,516 Training Epoch [37/40] Iter[67/312]		Loss: 0.1121
2019-10-28 15:44:42,594 Training Epoch [37/40] Iter[68/312]		Loss: 0.1121
2019-10-28 15:44:42,673 Training Epoch [37/40] Iter[69/312]		Loss: 0.1116
2019-10-28 15:44:42,752 Training Epoch [37/40] Iter[70/312]		Loss: 0.1116
2019-10-28 15:44:42,831 Training Epoch [37/40] Iter[71/312]		Loss: 0.1113
2019-10-28 15:44:42,910 Training Epoch [37/40] Iter[72/312]		Loss: 0.1111
2019-10-28 15:44:42,989 Training Epoch [37/40] Iter[73/312]		Loss: 0.1116
2019-10-28 15:44:43,068 Training Epoch [37/40] Iter[74/312]		Loss: 0.1117
2019-10-28 15:44:43,147 Training Epoch [37/40] Iter[75/312]		Loss: 0.1117
2019-10-28 15:44:43,225 Training Epoch [37/40] Iter[76/312]		Loss: 0.1115
2019-10-28 15:44:43,304 Training Epoch [37/40] Iter[77/312]		Loss: 0.1116
2019-10-28 15:44:43,384 Training Epoch [37/40] Iter[78/312]		Loss: 0.1120
2019-10-28 15:44:43,463 Training Epoch [37/40] Iter[79/312]		Loss: 0.1119
2019-10-28 15:44:43,542 Training Epoch [37/40] Iter[80/312]		Loss: 0.1121
2019-10-28 15:44:43,621 Training Epoch [37/40] Iter[81/312]		Loss: 0.1126
2019-10-28 15:44:43,700 Training Epoch [37/40] Iter[82/312]		Loss: 0.1120
2019-10-28 15:44:43,779 Training Epoch [37/40] Iter[83/312]		Loss: 0.1115
2019-10-28 15:44:43,858 Training Epoch [37/40] Iter[84/312]		Loss: 0.1115
2019-10-28 15:44:43,937 Training Epoch [37/40] Iter[85/312]		Loss: 0.1117
2019-10-28 15:44:44,016 Training Epoch [37/40] Iter[86/312]		Loss: 0.1112
2019-10-28 15:44:44,095 Training Epoch [37/40] Iter[87/312]		Loss: 0.1112
2019-10-28 15:44:44,174 Training Epoch [37/40] Iter[88/312]		Loss: 0.1115
2019-10-28 15:44:44,253 Training Epoch [37/40] Iter[89/312]		Loss: 0.1111
2019-10-28 15:44:44,332 Training Epoch [37/40] Iter[90/312]		Loss: 0.1114
2019-10-28 15:44:44,411 Training Epoch [37/40] Iter[91/312]		Loss: 0.1111
2019-10-28 15:44:44,490 Training Epoch [37/40] Iter[92/312]		Loss: 0.1107
2019-10-28 15:44:44,569 Training Epoch [37/40] Iter[93/312]		Loss: 0.1102
2019-10-28 15:44:44,648 Training Epoch [37/40] Iter[94/312]		Loss: 0.1102
2019-10-28 15:44:44,727 Training Epoch [37/40] Iter[95/312]		Loss: 0.1110
2019-10-28 15:44:44,806 Training Epoch [37/40] Iter[96/312]		Loss: 0.1107
2019-10-28 15:44:44,885 Training Epoch [37/40] Iter[97/312]		Loss: 0.1107
2019-10-28 15:44:44,964 Training Epoch [37/40] Iter[98/312]		Loss: 0.1110
2019-10-28 15:44:45,043 Training Epoch [37/40] Iter[99/312]		Loss: 0.1112
2019-10-28 15:44:45,122 Training Epoch [37/40] Iter[100/312]		Loss: 0.1115
2019-10-28 15:44:45,201 Training Epoch [37/40] Iter[101/312]		Loss: 0.1113
2019-10-28 15:44:45,280 Training Epoch [37/40] Iter[102/312]		Loss: 0.1109
2019-10-28 15:44:45,359 Training Epoch [37/40] Iter[103/312]		Loss: 0.1120
2019-10-28 15:44:45,438 Training Epoch [37/40] Iter[104/312]		Loss: 0.1118
2019-10-28 15:44:45,517 Training Epoch [37/40] Iter[105/312]		Loss: 0.1119
2019-10-28 15:44:45,596 Training Epoch [37/40] Iter[106/312]		Loss: 0.1115
2019-10-28 15:44:45,675 Training Epoch [37/40] Iter[107/312]		Loss: 0.1113
2019-10-28 15:44:45,754 Training Epoch [37/40] Iter[108/312]		Loss: 0.1110
2019-10-28 15:44:45,833 Training Epoch [37/40] Iter[109/312]		Loss: 0.1108
2019-10-28 15:44:45,912 Training Epoch [37/40] Iter[110/312]		Loss: 0.1106
2019-10-28 15:44:45,992 Training Epoch [37/40] Iter[111/312]		Loss: 0.1105
2019-10-28 15:44:46,071 Training Epoch [37/40] Iter[112/312]		Loss: 0.1102
2019-10-28 15:44:46,150 Training Epoch [37/40] Iter[113/312]		Loss: 0.1102
2019-10-28 15:44:46,230 Training Epoch [37/40] Iter[114/312]		Loss: 0.1106
2019-10-28 15:44:46,309 Training Epoch [37/40] Iter[115/312]		Loss: 0.1106
2019-10-28 15:44:46,388 Training Epoch [37/40] Iter[116/312]		Loss: 0.1105
2019-10-28 15:44:46,467 Training Epoch [37/40] Iter[117/312]		Loss: 0.1103
2019-10-28 15:44:46,547 Training Epoch [37/40] Iter[118/312]		Loss: 0.1101
2019-10-28 15:44:46,626 Training Epoch [37/40] Iter[119/312]		Loss: 0.1099
2019-10-28 15:44:46,706 Training Epoch [37/40] Iter[120/312]		Loss: 0.1097
2019-10-28 15:44:46,785 Training Epoch [37/40] Iter[121/312]		Loss: 0.1096
2019-10-28 15:44:46,864 Training Epoch [37/40] Iter[122/312]		Loss: 0.1094
2019-10-28 15:44:46,943 Training Epoch [37/40] Iter[123/312]		Loss: 0.1095
2019-10-28 15:44:47,022 Training Epoch [37/40] Iter[124/312]		Loss: 0.1093
2019-10-28 15:44:47,101 Training Epoch [37/40] Iter[125/312]		Loss: 0.1090
2019-10-28 15:44:47,180 Training Epoch [37/40] Iter[126/312]		Loss: 0.1091
2019-10-28 15:44:47,259 Training Epoch [37/40] Iter[127/312]		Loss: 0.1088
2019-10-28 15:44:47,339 Training Epoch [37/40] Iter[128/312]		Loss: 0.1086
2019-10-28 15:44:47,419 Training Epoch [37/40] Iter[129/312]		Loss: 0.1083
2019-10-28 15:44:47,498 Training Epoch [37/40] Iter[130/312]		Loss: 0.1084
2019-10-28 15:44:47,577 Training Epoch [37/40] Iter[131/312]		Loss: 0.1080
2019-10-28 15:44:47,656 Training Epoch [37/40] Iter[132/312]		Loss: 0.1085
2019-10-28 15:44:47,735 Training Epoch [37/40] Iter[133/312]		Loss: 0.1086
2019-10-28 15:44:47,814 Training Epoch [37/40] Iter[134/312]		Loss: 0.1084
2019-10-28 15:44:47,893 Training Epoch [37/40] Iter[135/312]		Loss: 0.1082
2019-10-28 15:44:47,973 Training Epoch [37/40] Iter[136/312]		Loss: 0.1079
2019-10-28 15:44:48,052 Training Epoch [37/40] Iter[137/312]		Loss: 0.1079
2019-10-28 15:44:48,131 Training Epoch [37/40] Iter[138/312]		Loss: 0.1082
2019-10-28 15:44:48,210 Training Epoch [37/40] Iter[139/312]		Loss: 0.1081
2019-10-28 15:44:48,290 Training Epoch [37/40] Iter[140/312]		Loss: 0.1080
2019-10-28 15:44:48,369 Training Epoch [37/40] Iter[141/312]		Loss: 0.1084
2019-10-28 15:44:48,448 Training Epoch [37/40] Iter[142/312]		Loss: 0.1083
2019-10-28 15:44:48,528 Training Epoch [37/40] Iter[143/312]		Loss: 0.1081
2019-10-28 15:44:48,607 Training Epoch [37/40] Iter[144/312]		Loss: 0.1079
2019-10-28 15:44:48,686 Training Epoch [37/40] Iter[145/312]		Loss: 0.1077
2019-10-28 15:44:48,766 Training Epoch [37/40] Iter[146/312]		Loss: 0.1078
2019-10-28 15:44:48,845 Training Epoch [37/40] Iter[147/312]		Loss: 0.1078
2019-10-28 15:44:48,924 Training Epoch [37/40] Iter[148/312]		Loss: 0.1075
2019-10-28 15:44:49,003 Training Epoch [37/40] Iter[149/312]		Loss: 0.1080
2019-10-28 15:44:49,082 Training Epoch [37/40] Iter[150/312]		Loss: 0.1078
2019-10-28 15:44:49,161 Training Epoch [37/40] Iter[151/312]		Loss: 0.1079
2019-10-28 15:44:49,240 Training Epoch [37/40] Iter[152/312]		Loss: 0.1076
2019-10-28 15:44:49,320 Training Epoch [37/40] Iter[153/312]		Loss: 0.1079
2019-10-28 15:44:49,399 Training Epoch [37/40] Iter[154/312]		Loss: 0.1082
2019-10-28 15:44:49,479 Training Epoch [37/40] Iter[155/312]		Loss: 0.1081
2019-10-28 15:44:49,558 Training Epoch [37/40] Iter[156/312]		Loss: 0.1080
2019-10-28 15:44:49,637 Training Epoch [37/40] Iter[157/312]		Loss: 0.1080
2019-10-28 15:44:49,716 Training Epoch [37/40] Iter[158/312]		Loss: 0.1081
2019-10-28 15:44:49,795 Training Epoch [37/40] Iter[159/312]		Loss: 0.1082
2019-10-28 15:44:49,874 Training Epoch [37/40] Iter[160/312]		Loss: 0.1081
2019-10-28 15:44:49,953 Training Epoch [37/40] Iter[161/312]		Loss: 0.1085
2019-10-28 15:44:50,032 Training Epoch [37/40] Iter[162/312]		Loss: 0.1084
2019-10-28 15:44:50,112 Training Epoch [37/40] Iter[163/312]		Loss: 0.1086
2019-10-28 15:44:50,191 Training Epoch [37/40] Iter[164/312]		Loss: 0.1084
2019-10-28 15:44:50,271 Training Epoch [37/40] Iter[165/312]		Loss: 0.1085
2019-10-28 15:44:50,350 Training Epoch [37/40] Iter[166/312]		Loss: 0.1083
2019-10-28 15:44:50,429 Training Epoch [37/40] Iter[167/312]		Loss: 0.1081
2019-10-28 15:44:50,509 Training Epoch [37/40] Iter[168/312]		Loss: 0.1080
2019-10-28 15:44:50,588 Training Epoch [37/40] Iter[169/312]		Loss: 0.1077
2019-10-28 15:44:50,667 Training Epoch [37/40] Iter[170/312]		Loss: 0.1077
2019-10-28 15:44:50,746 Training Epoch [37/40] Iter[171/312]		Loss: 0.1078
2019-10-28 15:44:50,825 Training Epoch [37/40] Iter[172/312]		Loss: 0.1076
2019-10-28 15:44:50,904 Training Epoch [37/40] Iter[173/312]		Loss: 0.1083
2019-10-28 15:44:50,984 Training Epoch [37/40] Iter[174/312]		Loss: 0.1084
2019-10-28 15:44:51,063 Training Epoch [37/40] Iter[175/312]		Loss: 0.1084
2019-10-28 15:44:51,142 Training Epoch [37/40] Iter[176/312]		Loss: 0.1083
2019-10-28 15:44:51,221 Training Epoch [37/40] Iter[177/312]		Loss: 0.1081
2019-10-28 15:44:51,300 Training Epoch [37/40] Iter[178/312]		Loss: 0.1080
2019-10-28 15:44:51,380 Training Epoch [37/40] Iter[179/312]		Loss: 0.1079
2019-10-28 15:44:51,459 Training Epoch [37/40] Iter[180/312]		Loss: 0.1078
2019-10-28 15:44:51,538 Training Epoch [37/40] Iter[181/312]		Loss: 0.1077
2019-10-28 15:44:51,617 Training Epoch [37/40] Iter[182/312]		Loss: 0.1077
2019-10-28 15:44:51,696 Training Epoch [37/40] Iter[183/312]		Loss: 0.1077
2019-10-28 15:44:51,775 Training Epoch [37/40] Iter[184/312]		Loss: 0.1076
2019-10-28 15:44:51,854 Training Epoch [37/40] Iter[185/312]		Loss: 0.1077
2019-10-28 15:44:51,934 Training Epoch [37/40] Iter[186/312]		Loss: 0.1080
2019-10-28 15:44:52,013 Training Epoch [37/40] Iter[187/312]		Loss: 0.1080
2019-10-28 15:44:52,093 Training Epoch [37/40] Iter[188/312]		Loss: 0.1078
2019-10-28 15:44:52,172 Training Epoch [37/40] Iter[189/312]		Loss: 0.1079
2019-10-28 15:44:52,251 Training Epoch [37/40] Iter[190/312]		Loss: 0.1079
2019-10-28 15:44:52,331 Training Epoch [37/40] Iter[191/312]		Loss: 0.1080
2019-10-28 15:44:52,410 Training Epoch [37/40] Iter[192/312]		Loss: 0.1084
2019-10-28 15:44:52,489 Training Epoch [37/40] Iter[193/312]		Loss: 0.1085
2019-10-28 15:44:52,568 Training Epoch [37/40] Iter[194/312]		Loss: 0.1086
2019-10-28 15:44:52,647 Training Epoch [37/40] Iter[195/312]		Loss: 0.1085
2019-10-28 15:44:52,726 Training Epoch [37/40] Iter[196/312]		Loss: 0.1085
2019-10-28 15:44:52,805 Training Epoch [37/40] Iter[197/312]		Loss: 0.1086
2019-10-28 15:44:52,884 Training Epoch [37/40] Iter[198/312]		Loss: 0.1087
2019-10-28 15:44:52,963 Training Epoch [37/40] Iter[199/312]		Loss: 0.1086
2019-10-28 15:44:53,042 Training Epoch [37/40] Iter[200/312]		Loss: 0.1085
2019-10-28 15:44:53,121 Training Epoch [37/40] Iter[201/312]		Loss: 0.1085
2019-10-28 15:44:53,200 Training Epoch [37/40] Iter[202/312]		Loss: 0.1084
2019-10-28 15:44:53,279 Training Epoch [37/40] Iter[203/312]		Loss: 0.1083
2019-10-28 15:44:53,358 Training Epoch [37/40] Iter[204/312]		Loss: 0.1083
2019-10-28 15:44:53,437 Training Epoch [37/40] Iter[205/312]		Loss: 0.1084
2019-10-28 15:44:53,517 Training Epoch [37/40] Iter[206/312]		Loss: 0.1085
2019-10-28 15:44:53,596 Training Epoch [37/40] Iter[207/312]		Loss: 0.1085
2019-10-28 15:44:53,675 Training Epoch [37/40] Iter[208/312]		Loss: 0.1086
2019-10-28 15:44:53,754 Training Epoch [37/40] Iter[209/312]		Loss: 0.1085
2019-10-28 15:44:53,833 Training Epoch [37/40] Iter[210/312]		Loss: 0.1087
2019-10-28 15:44:53,912 Training Epoch [37/40] Iter[211/312]		Loss: 0.1086
2019-10-28 15:44:53,991 Training Epoch [37/40] Iter[212/312]		Loss: 0.1087
2019-10-28 15:44:54,070 Training Epoch [37/40] Iter[213/312]		Loss: 0.1088
2019-10-28 15:44:54,149 Training Epoch [37/40] Iter[214/312]		Loss: 0.1088
2019-10-28 15:44:54,229 Training Epoch [37/40] Iter[215/312]		Loss: 0.1086
2019-10-28 15:44:54,308 Training Epoch [37/40] Iter[216/312]		Loss: 0.1086
2019-10-28 15:44:54,387 Training Epoch [37/40] Iter[217/312]		Loss: 0.1086
2019-10-28 15:44:54,466 Training Epoch [37/40] Iter[218/312]		Loss: 0.1087
2019-10-28 15:44:54,545 Training Epoch [37/40] Iter[219/312]		Loss: 0.1086
2019-10-28 15:44:54,624 Training Epoch [37/40] Iter[220/312]		Loss: 0.1086
2019-10-28 15:44:54,703 Training Epoch [37/40] Iter[221/312]		Loss: 0.1084
2019-10-28 15:44:54,782 Training Epoch [37/40] Iter[222/312]		Loss: 0.1085
2019-10-28 15:44:54,861 Training Epoch [37/40] Iter[223/312]		Loss: 0.1084
2019-10-28 15:44:54,939 Training Epoch [37/40] Iter[224/312]		Loss: 0.1085
2019-10-28 15:44:55,018 Training Epoch [37/40] Iter[225/312]		Loss: 0.1083
2019-10-28 15:44:55,098 Training Epoch [37/40] Iter[226/312]		Loss: 0.1086
2019-10-28 15:44:55,177 Training Epoch [37/40] Iter[227/312]		Loss: 0.1087
2019-10-28 15:44:55,256 Training Epoch [37/40] Iter[228/312]		Loss: 0.1086
2019-10-28 15:44:55,335 Training Epoch [37/40] Iter[229/312]		Loss: 0.1089
2019-10-28 15:44:55,414 Training Epoch [37/40] Iter[230/312]		Loss: 0.1088
2019-10-28 15:44:55,494 Training Epoch [37/40] Iter[231/312]		Loss: 0.1091
2019-10-28 15:44:55,573 Training Epoch [37/40] Iter[232/312]		Loss: 0.1092
2019-10-28 15:44:55,652 Training Epoch [37/40] Iter[233/312]		Loss: 0.1091
2019-10-28 15:44:55,732 Training Epoch [37/40] Iter[234/312]		Loss: 0.1091
2019-10-28 15:44:55,811 Training Epoch [37/40] Iter[235/312]		Loss: 0.1090
2019-10-28 15:44:55,890 Training Epoch [37/40] Iter[236/312]		Loss: 0.1089
2019-10-28 15:44:55,970 Training Epoch [37/40] Iter[237/312]		Loss: 0.1090
2019-10-28 15:44:56,048 Training Epoch [37/40] Iter[238/312]		Loss: 0.1094
2019-10-28 15:44:56,127 Training Epoch [37/40] Iter[239/312]		Loss: 0.1094
2019-10-28 15:44:56,207 Training Epoch [37/40] Iter[240/312]		Loss: 0.1093
2019-10-28 15:44:56,286 Training Epoch [37/40] Iter[241/312]		Loss: 0.1094
2019-10-28 15:44:56,365 Training Epoch [37/40] Iter[242/312]		Loss: 0.1094
2019-10-28 15:44:56,444 Training Epoch [37/40] Iter[243/312]		Loss: 0.1094
2019-10-28 15:44:56,523 Training Epoch [37/40] Iter[244/312]		Loss: 0.1098
2019-10-28 15:44:56,602 Training Epoch [37/40] Iter[245/312]		Loss: 0.1098
2019-10-28 15:44:56,681 Training Epoch [37/40] Iter[246/312]		Loss: 0.1098
2019-10-28 15:44:56,760 Training Epoch [37/40] Iter[247/312]		Loss: 0.1097
2019-10-28 15:44:56,839 Training Epoch [37/40] Iter[248/312]		Loss: 0.1097
2019-10-28 15:44:56,918 Training Epoch [37/40] Iter[249/312]		Loss: 0.1096
2019-10-28 15:44:56,997 Training Epoch [37/40] Iter[250/312]		Loss: 0.1095
2019-10-28 15:44:57,076 Training Epoch [37/40] Iter[251/312]		Loss: 0.1096
2019-10-28 15:44:57,155 Training Epoch [37/40] Iter[252/312]		Loss: 0.1096
2019-10-28 15:44:57,235 Training Epoch [37/40] Iter[253/312]		Loss: 0.1095
2019-10-28 15:44:57,314 Training Epoch [37/40] Iter[254/312]		Loss: 0.1095
2019-10-28 15:44:57,394 Training Epoch [37/40] Iter[255/312]		Loss: 0.1096
2019-10-28 15:44:57,473 Training Epoch [37/40] Iter[256/312]		Loss: 0.1101
2019-10-28 15:44:57,552 Training Epoch [37/40] Iter[257/312]		Loss: 0.1103
2019-10-28 15:44:57,631 Training Epoch [37/40] Iter[258/312]		Loss: 0.1102
2019-10-28 15:44:57,710 Training Epoch [37/40] Iter[259/312]		Loss: 0.1103
2019-10-28 15:44:57,789 Training Epoch [37/40] Iter[260/312]		Loss: 0.1103
2019-10-28 15:44:57,869 Training Epoch [37/40] Iter[261/312]		Loss: 0.1102
2019-10-28 15:44:57,948 Training Epoch [37/40] Iter[262/312]		Loss: 0.1104
2019-10-28 15:44:58,027 Training Epoch [37/40] Iter[263/312]		Loss: 0.1106
2019-10-28 15:44:58,106 Training Epoch [37/40] Iter[264/312]		Loss: 0.1110
2019-10-28 15:44:58,185 Training Epoch [37/40] Iter[265/312]		Loss: 0.1109
2019-10-28 15:44:58,265 Training Epoch [37/40] Iter[266/312]		Loss: 0.1109
2019-10-28 15:44:58,344 Training Epoch [37/40] Iter[267/312]		Loss: 0.1109
2019-10-28 15:44:58,423 Training Epoch [37/40] Iter[268/312]		Loss: 0.1107
2019-10-28 15:44:58,502 Training Epoch [37/40] Iter[269/312]		Loss: 0.1107
2019-10-28 15:44:58,581 Training Epoch [37/40] Iter[270/312]		Loss: 0.1105
2019-10-28 15:44:58,660 Training Epoch [37/40] Iter[271/312]		Loss: 0.1105
2019-10-28 15:44:58,739 Training Epoch [37/40] Iter[272/312]		Loss: 0.1105
2019-10-28 15:44:58,818 Training Epoch [37/40] Iter[273/312]		Loss: 0.1104
2019-10-28 15:44:58,897 Training Epoch [37/40] Iter[274/312]		Loss: 0.1102
2019-10-28 15:44:58,976 Training Epoch [37/40] Iter[275/312]		Loss: 0.1103
2019-10-28 15:44:59,055 Training Epoch [37/40] Iter[276/312]		Loss: 0.1107
2019-10-28 15:44:59,134 Training Epoch [37/40] Iter[277/312]		Loss: 0.1109
2019-10-28 15:44:59,214 Training Epoch [37/40] Iter[278/312]		Loss: 0.1109
2019-10-28 15:44:59,293 Training Epoch [37/40] Iter[279/312]		Loss: 0.1109
2019-10-28 15:44:59,373 Training Epoch [37/40] Iter[280/312]		Loss: 0.1108
2019-10-28 15:44:59,452 Training Epoch [37/40] Iter[281/312]		Loss: 0.1108
2019-10-28 15:44:59,531 Training Epoch [37/40] Iter[282/312]		Loss: 0.1108
2019-10-28 15:44:59,610 Training Epoch [37/40] Iter[283/312]		Loss: 0.1107
2019-10-28 15:44:59,689 Training Epoch [37/40] Iter[284/312]		Loss: 0.1107
2019-10-28 15:44:59,768 Training Epoch [37/40] Iter[285/312]		Loss: 0.1107
2019-10-28 15:44:59,847 Training Epoch [37/40] Iter[286/312]		Loss: 0.1108
2019-10-28 15:44:59,926 Training Epoch [37/40] Iter[287/312]		Loss: 0.1108
2019-10-28 15:45:00,005 Training Epoch [37/40] Iter[288/312]		Loss: 0.1107
2019-10-28 15:45:00,084 Training Epoch [37/40] Iter[289/312]		Loss: 0.1105
2019-10-28 15:45:00,163 Training Epoch [37/40] Iter[290/312]		Loss: 0.1105
2019-10-28 15:45:00,243 Training Epoch [37/40] Iter[291/312]		Loss: 0.1105
2019-10-28 15:45:00,322 Training Epoch [37/40] Iter[292/312]		Loss: 0.1104
2019-10-28 15:45:00,402 Training Epoch [37/40] Iter[293/312]		Loss: 0.1106
2019-10-28 15:45:00,482 Training Epoch [37/40] Iter[294/312]		Loss: 0.1107
2019-10-28 15:45:00,561 Training Epoch [37/40] Iter[295/312]		Loss: 0.1107
2019-10-28 15:45:00,640 Training Epoch [37/40] Iter[296/312]		Loss: 0.1106
2019-10-28 15:45:00,719 Training Epoch [37/40] Iter[297/312]		Loss: 0.1106
2019-10-28 15:45:00,798 Training Epoch [37/40] Iter[298/312]		Loss: 0.1105
2019-10-28 15:45:00,877 Training Epoch [37/40] Iter[299/312]		Loss: 0.1106
2019-10-28 15:45:00,956 Training Epoch [37/40] Iter[300/312]		Loss: 0.1105
2019-10-28 15:45:01,035 Training Epoch [37/40] Iter[301/312]		Loss: 0.1107
2019-10-28 15:45:01,114 Training Epoch [37/40] Iter[302/312]		Loss: 0.1106
2019-10-28 15:45:01,194 Training Epoch [37/40] Iter[303/312]		Loss: 0.1106
2019-10-28 15:45:01,273 Training Epoch [37/40] Iter[304/312]		Loss: 0.1105
2019-10-28 15:45:01,352 Training Epoch [37/40] Iter[305/312]		Loss: 0.1107
2019-10-28 15:45:01,431 Training Epoch [37/40] Iter[306/312]		Loss: 0.1107
2019-10-28 15:45:01,510 Training Epoch [37/40] Iter[307/312]		Loss: 0.1106
2019-10-28 15:45:01,588 Training Epoch [37/40] Iter[308/312]		Loss: 0.1107
2019-10-28 15:45:01,667 Training Epoch [37/40] Iter[309/312]		Loss: 0.1107
2019-10-28 15:45:01,745 Training Epoch [37/40] Iter[310/312]		Loss: 0.1107
2019-10-28 15:45:01,824 Training Epoch [37/40] Iter[311/312]		Loss: 0.1106
2019-10-28 15:45:01,863 Training Epoch [37/40] Iter[312/312]		Loss: 0.1107
2019-10-28 15:45:02,320 Testing Epoch [37/40] Iter[0/62]		Loss: 0.1257
2019-10-28 15:45:02,350 Testing Epoch [37/40] Iter[1/62]		Loss: 0.1264
2019-10-28 15:45:02,371 Testing Epoch [37/40] Iter[2/62]		Loss: 0.1101
2019-10-28 15:45:02,393 Testing Epoch [37/40] Iter[3/62]		Loss: 0.1160
2019-10-28 15:45:02,413 Testing Epoch [37/40] Iter[4/62]		Loss: 0.1198
2019-10-28 15:45:02,430 Testing Epoch [37/40] Iter[5/62]		Loss: 0.1144
2019-10-28 15:45:02,464 Testing Epoch [37/40] Iter[6/62]		Loss: 0.1162
2019-10-28 15:45:02,480 Testing Epoch [37/40] Iter[7/62]		Loss: 0.1182
2019-10-28 15:45:02,497 Testing Epoch [37/40] Iter[8/62]		Loss: 0.1206
2019-10-28 15:45:02,515 Testing Epoch [37/40] Iter[9/62]		Loss: 0.1195
2019-10-28 15:45:02,542 Testing Epoch [37/40] Iter[10/62]		Loss: 0.1205
2019-10-28 15:45:02,564 Testing Epoch [37/40] Iter[11/62]		Loss: 0.1267
2019-10-28 15:45:02,590 Testing Epoch [37/40] Iter[12/62]		Loss: 0.1263
2019-10-28 15:45:02,616 Testing Epoch [37/40] Iter[13/62]		Loss: 0.1285
2019-10-28 15:45:02,637 Testing Epoch [37/40] Iter[14/62]		Loss: 0.1403
2019-10-28 15:45:02,655 Testing Epoch [37/40] Iter[15/62]		Loss: 0.1423
2019-10-28 15:45:02,673 Testing Epoch [37/40] Iter[16/62]		Loss: 0.1392
2019-10-28 15:45:02,704 Testing Epoch [37/40] Iter[17/62]		Loss: 0.1397
2019-10-28 15:45:02,729 Testing Epoch [37/40] Iter[18/62]		Loss: 0.1373
2019-10-28 15:45:02,747 Testing Epoch [37/40] Iter[19/62]		Loss: 0.1357
2019-10-28 15:45:02,765 Testing Epoch [37/40] Iter[20/62]		Loss: 0.1375
2019-10-28 15:45:02,797 Testing Epoch [37/40] Iter[21/62]		Loss: 0.1359
2019-10-28 15:45:02,815 Testing Epoch [37/40] Iter[22/62]		Loss: 0.1373
2019-10-28 15:45:02,833 Testing Epoch [37/40] Iter[23/62]		Loss: 0.1362
2019-10-28 15:45:02,854 Testing Epoch [37/40] Iter[24/62]		Loss: 0.1395
2019-10-28 15:45:02,882 Testing Epoch [37/40] Iter[25/62]		Loss: 0.1386
2019-10-28 15:45:02,899 Testing Epoch [37/40] Iter[26/62]		Loss: 0.1374
2019-10-28 15:45:02,917 Testing Epoch [37/40] Iter[27/62]		Loss: 0.1447
2019-10-28 15:45:02,935 Testing Epoch [37/40] Iter[28/62]		Loss: 0.1483
2019-10-28 15:45:02,966 Testing Epoch [37/40] Iter[29/62]		Loss: 0.1481
2019-10-28 15:45:02,983 Testing Epoch [37/40] Iter[30/62]		Loss: 0.1483
2019-10-28 15:45:03,001 Testing Epoch [37/40] Iter[31/62]		Loss: 0.1473
2019-10-28 15:45:03,026 Testing Epoch [37/40] Iter[32/62]		Loss: 0.1490
2019-10-28 15:45:03,043 Testing Epoch [37/40] Iter[33/62]		Loss: 0.1480
2019-10-28 15:45:03,070 Testing Epoch [37/40] Iter[34/62]		Loss: 0.1502
2019-10-28 15:45:03,087 Testing Epoch [37/40] Iter[35/62]		Loss: 0.1499
2019-10-28 15:45:03,104 Testing Epoch [37/40] Iter[36/62]		Loss: 0.1479
2019-10-28 15:45:03,122 Testing Epoch [37/40] Iter[37/62]		Loss: 0.1468
2019-10-28 15:45:03,152 Testing Epoch [37/40] Iter[38/62]		Loss: 0.1457
2019-10-28 15:45:03,169 Testing Epoch [37/40] Iter[39/62]		Loss: 0.1460
2019-10-28 15:45:03,198 Testing Epoch [37/40] Iter[40/62]		Loss: 0.1478
2019-10-28 15:45:03,228 Testing Epoch [37/40] Iter[41/62]		Loss: 0.1491
2019-10-28 15:45:03,246 Testing Epoch [37/40] Iter[42/62]		Loss: 0.1472
2019-10-28 15:45:03,263 Testing Epoch [37/40] Iter[43/62]		Loss: 0.1466
2019-10-28 15:45:03,290 Testing Epoch [37/40] Iter[44/62]		Loss: 0.1450
2019-10-28 15:45:03,306 Testing Epoch [37/40] Iter[45/62]		Loss: 0.1448
2019-10-28 15:45:03,330 Testing Epoch [37/40] Iter[46/62]		Loss: 0.1445
2019-10-28 15:45:03,346 Testing Epoch [37/40] Iter[47/62]		Loss: 0.1504
2019-10-28 15:45:03,374 Testing Epoch [37/40] Iter[48/62]		Loss: 0.1495
2019-10-28 15:45:03,402 Testing Epoch [37/40] Iter[49/62]		Loss: 0.1516
2019-10-28 15:45:03,420 Testing Epoch [37/40] Iter[50/62]		Loss: 0.1508
2019-10-28 15:45:03,438 Testing Epoch [37/40] Iter[51/62]		Loss: 0.1507
2019-10-28 15:45:03,465 Testing Epoch [37/40] Iter[52/62]		Loss: 0.1495
2019-10-28 15:45:03,484 Testing Epoch [37/40] Iter[53/62]		Loss: 0.1498
2019-10-28 15:45:03,501 Testing Epoch [37/40] Iter[54/62]		Loss: 0.1486
2019-10-28 15:45:03,519 Testing Epoch [37/40] Iter[55/62]		Loss: 0.1483
2019-10-28 15:45:03,538 Testing Epoch [37/40] Iter[56/62]		Loss: 0.1477
2019-10-28 15:45:03,554 Testing Epoch [37/40] Iter[57/62]		Loss: 0.1479
2019-10-28 15:45:03,572 Testing Epoch [37/40] Iter[58/62]		Loss: 0.1474
2019-10-28 15:45:03,587 Testing Epoch [37/40] Iter[59/62]		Loss: 0.1485
2019-10-28 15:45:03,604 Testing Epoch [37/40] Iter[60/62]		Loss: 0.1477
2019-10-28 15:45:03,621 Testing Epoch [37/40] Iter[61/62]		Loss: 0.1476
2019-10-28 15:45:03,630 Testing Epoch [37/40] Iter[62/62]		Loss: 0.1482
2019-10-28 15:45:03,700 Saving the Model
2019-10-28 15:45:04,123 Training Epoch [38/40] Iter[0/312]		Loss: 0.0814
2019-10-28 15:45:04,202 Training Epoch [38/40] Iter[1/312]		Loss: 0.0942
2019-10-28 15:45:04,283 Training Epoch [38/40] Iter[2/312]		Loss: 0.0917
2019-10-28 15:45:04,362 Training Epoch [38/40] Iter[3/312]		Loss: 0.0929
2019-10-28 15:45:04,446 Training Epoch [38/40] Iter[4/312]		Loss: 0.0931
2019-10-28 15:45:04,524 Training Epoch [38/40] Iter[5/312]		Loss: 0.0892
2019-10-28 15:45:04,602 Training Epoch [38/40] Iter[6/312]		Loss: 0.0937
2019-10-28 15:45:04,681 Training Epoch [38/40] Iter[7/312]		Loss: 0.0929
2019-10-28 15:45:04,760 Training Epoch [38/40] Iter[8/312]		Loss: 0.0990
2019-10-28 15:45:04,839 Training Epoch [38/40] Iter[9/312]		Loss: 0.0970
2019-10-28 15:45:04,918 Training Epoch [38/40] Iter[10/312]		Loss: 0.0977
2019-10-28 15:45:04,997 Training Epoch [38/40] Iter[11/312]		Loss: 0.0964
2019-10-28 15:45:05,076 Training Epoch [38/40] Iter[12/312]		Loss: 0.0992
2019-10-28 15:45:05,155 Training Epoch [38/40] Iter[13/312]		Loss: 0.0993
2019-10-28 15:45:05,234 Training Epoch [38/40] Iter[14/312]		Loss: 0.0986
2019-10-28 15:45:05,313 Training Epoch [38/40] Iter[15/312]		Loss: 0.0986
2019-10-28 15:45:05,392 Training Epoch [38/40] Iter[16/312]		Loss: 0.1003
2019-10-28 15:45:05,472 Training Epoch [38/40] Iter[17/312]		Loss: 0.1025
2019-10-28 15:45:05,551 Training Epoch [38/40] Iter[18/312]		Loss: 0.1024
2019-10-28 15:45:05,630 Training Epoch [38/40] Iter[19/312]		Loss: 0.1023
2019-10-28 15:45:05,709 Training Epoch [38/40] Iter[20/312]		Loss: 0.1032
2019-10-28 15:45:05,788 Training Epoch [38/40] Iter[21/312]		Loss: 0.1056
2019-10-28 15:45:05,866 Training Epoch [38/40] Iter[22/312]		Loss: 0.1049
2019-10-28 15:45:05,945 Training Epoch [38/40] Iter[23/312]		Loss: 0.1043
2019-10-28 15:45:06,024 Training Epoch [38/40] Iter[24/312]		Loss: 0.1054
2019-10-28 15:45:06,103 Training Epoch [38/40] Iter[25/312]		Loss: 0.1044
2019-10-28 15:45:06,182 Training Epoch [38/40] Iter[26/312]		Loss: 0.1055
2019-10-28 15:45:06,261 Training Epoch [38/40] Iter[27/312]		Loss: 0.1056
2019-10-28 15:45:06,340 Training Epoch [38/40] Iter[28/312]		Loss: 0.1051
2019-10-28 15:45:06,419 Training Epoch [38/40] Iter[29/312]		Loss: 0.1042
2019-10-28 15:45:06,498 Training Epoch [38/40] Iter[30/312]		Loss: 0.1054
2019-10-28 15:45:06,577 Training Epoch [38/40] Iter[31/312]		Loss: 0.1055
2019-10-28 15:45:06,655 Training Epoch [38/40] Iter[32/312]		Loss: 0.1079
2019-10-28 15:45:06,734 Training Epoch [38/40] Iter[33/312]		Loss: 0.1066
2019-10-28 15:45:06,813 Training Epoch [38/40] Iter[34/312]		Loss: 0.1058
2019-10-28 15:45:06,892 Training Epoch [38/40] Iter[35/312]		Loss: 0.1054
2019-10-28 15:45:06,971 Training Epoch [38/40] Iter[36/312]		Loss: 0.1049
2019-10-28 15:45:07,049 Training Epoch [38/40] Iter[37/312]		Loss: 0.1054
2019-10-28 15:45:07,128 Training Epoch [38/40] Iter[38/312]		Loss: 0.1048
2019-10-28 15:45:07,207 Training Epoch [38/40] Iter[39/312]		Loss: 0.1045
2019-10-28 15:45:07,286 Training Epoch [38/40] Iter[40/312]		Loss: 0.1054
2019-10-28 15:45:07,365 Training Epoch [38/40] Iter[41/312]		Loss: 0.1046
2019-10-28 15:45:07,444 Training Epoch [38/40] Iter[42/312]		Loss: 0.1042
2019-10-28 15:45:07,523 Training Epoch [38/40] Iter[43/312]		Loss: 0.1048
2019-10-28 15:45:07,602 Training Epoch [38/40] Iter[44/312]		Loss: 0.1054
2019-10-28 15:45:07,681 Training Epoch [38/40] Iter[45/312]		Loss: 0.1067
2019-10-28 15:45:07,760 Training Epoch [38/40] Iter[46/312]		Loss: 0.1063
2019-10-28 15:45:07,839 Training Epoch [38/40] Iter[47/312]		Loss: 0.1056
2019-10-28 15:45:07,918 Training Epoch [38/40] Iter[48/312]		Loss: 0.1059
2019-10-28 15:45:07,997 Training Epoch [38/40] Iter[49/312]		Loss: 0.1067
2019-10-28 15:45:08,076 Training Epoch [38/40] Iter[50/312]		Loss: 0.1081
2019-10-28 15:45:08,155 Training Epoch [38/40] Iter[51/312]		Loss: 0.1075
2019-10-28 15:45:08,234 Training Epoch [38/40] Iter[52/312]		Loss: 0.1080
2019-10-28 15:45:08,313 Training Epoch [38/40] Iter[53/312]		Loss: 0.1075
2019-10-28 15:45:08,393 Training Epoch [38/40] Iter[54/312]		Loss: 0.1070
2019-10-28 15:45:08,472 Training Epoch [38/40] Iter[55/312]		Loss: 0.1070
2019-10-28 15:45:08,551 Training Epoch [38/40] Iter[56/312]		Loss: 0.1073
2019-10-28 15:45:08,630 Training Epoch [38/40] Iter[57/312]		Loss: 0.1069
2019-10-28 15:45:08,710 Training Epoch [38/40] Iter[58/312]		Loss: 0.1066
2019-10-28 15:45:08,789 Training Epoch [38/40] Iter[59/312]		Loss: 0.1072
2019-10-28 15:45:08,868 Training Epoch [38/40] Iter[60/312]		Loss: 0.1071
2019-10-28 15:45:08,947 Training Epoch [38/40] Iter[61/312]		Loss: 0.1066
2019-10-28 15:45:09,026 Training Epoch [38/40] Iter[62/312]		Loss: 0.1074
2019-10-28 15:45:09,105 Training Epoch [38/40] Iter[63/312]		Loss: 0.1079
2019-10-28 15:45:09,185 Training Epoch [38/40] Iter[64/312]		Loss: 0.1083
2019-10-28 15:45:09,264 Training Epoch [38/40] Iter[65/312]		Loss: 0.1078
2019-10-28 15:45:09,343 Training Epoch [38/40] Iter[66/312]		Loss: 0.1078
2019-10-28 15:45:09,422 Training Epoch [38/40] Iter[67/312]		Loss: 0.1078
2019-10-28 15:45:09,501 Training Epoch [38/40] Iter[68/312]		Loss: 0.1080
2019-10-28 15:45:09,580 Training Epoch [38/40] Iter[69/312]		Loss: 0.1079
2019-10-28 15:45:09,659 Training Epoch [38/40] Iter[70/312]		Loss: 0.1080
2019-10-28 15:45:09,738 Training Epoch [38/40] Iter[71/312]		Loss: 0.1080
2019-10-28 15:45:09,817 Training Epoch [38/40] Iter[72/312]		Loss: 0.1086
2019-10-28 15:45:09,896 Training Epoch [38/40] Iter[73/312]		Loss: 0.1086
2019-10-28 15:45:09,975 Training Epoch [38/40] Iter[74/312]		Loss: 0.1081
2019-10-28 15:45:10,055 Training Epoch [38/40] Iter[75/312]		Loss: 0.1085
2019-10-28 15:45:10,134 Training Epoch [38/40] Iter[76/312]		Loss: 0.1085
2019-10-28 15:45:10,213 Training Epoch [38/40] Iter[77/312]		Loss: 0.1090
2019-10-28 15:45:10,292 Training Epoch [38/40] Iter[78/312]		Loss: 0.1086
2019-10-28 15:45:10,371 Training Epoch [38/40] Iter[79/312]		Loss: 0.1093
2019-10-28 15:45:10,450 Training Epoch [38/40] Iter[80/312]		Loss: 0.1091
2019-10-28 15:45:10,529 Training Epoch [38/40] Iter[81/312]		Loss: 0.1087
2019-10-28 15:45:10,608 Training Epoch [38/40] Iter[82/312]		Loss: 0.1087
2019-10-28 15:45:10,688 Training Epoch [38/40] Iter[83/312]		Loss: 0.1095
2019-10-28 15:45:10,767 Training Epoch [38/40] Iter[84/312]		Loss: 0.1097
2019-10-28 15:45:10,846 Training Epoch [38/40] Iter[85/312]		Loss: 0.1094
2019-10-28 15:45:10,925 Training Epoch [38/40] Iter[86/312]		Loss: 0.1094
2019-10-28 15:45:11,004 Training Epoch [38/40] Iter[87/312]		Loss: 0.1094
2019-10-28 15:45:11,083 Training Epoch [38/40] Iter[88/312]		Loss: 0.1089
2019-10-28 15:45:11,162 Training Epoch [38/40] Iter[89/312]		Loss: 0.1084
2019-10-28 15:45:11,241 Training Epoch [38/40] Iter[90/312]		Loss: 0.1081
2019-10-28 15:45:11,320 Training Epoch [38/40] Iter[91/312]		Loss: 0.1082
2019-10-28 15:45:11,399 Training Epoch [38/40] Iter[92/312]		Loss: 0.1079
2019-10-28 15:45:11,478 Training Epoch [38/40] Iter[93/312]		Loss: 0.1077
2019-10-28 15:45:11,557 Training Epoch [38/40] Iter[94/312]		Loss: 0.1076
2019-10-28 15:45:11,636 Training Epoch [38/40] Iter[95/312]		Loss: 0.1073
2019-10-28 15:45:11,715 Training Epoch [38/40] Iter[96/312]		Loss: 0.1071
2019-10-28 15:45:11,794 Training Epoch [38/40] Iter[97/312]		Loss: 0.1068
2019-10-28 15:45:11,873 Training Epoch [38/40] Iter[98/312]		Loss: 0.1065
2019-10-28 15:45:11,952 Training Epoch [38/40] Iter[99/312]		Loss: 0.1062
2019-10-28 15:45:12,031 Training Epoch [38/40] Iter[100/312]		Loss: 0.1061
2019-10-28 15:45:12,110 Training Epoch [38/40] Iter[101/312]		Loss: 0.1064
2019-10-28 15:45:12,189 Training Epoch [38/40] Iter[102/312]		Loss: 0.1061
2019-10-28 15:45:12,268 Training Epoch [38/40] Iter[103/312]		Loss: 0.1060
2019-10-28 15:45:12,347 Training Epoch [38/40] Iter[104/312]		Loss: 0.1064
2019-10-28 15:45:12,426 Training Epoch [38/40] Iter[105/312]		Loss: 0.1063
2019-10-28 15:45:12,505 Training Epoch [38/40] Iter[106/312]		Loss: 0.1063
2019-10-28 15:45:12,584 Training Epoch [38/40] Iter[107/312]		Loss: 0.1061
2019-10-28 15:45:12,663 Training Epoch [38/40] Iter[108/312]		Loss: 0.1059
2019-10-28 15:45:12,741 Training Epoch [38/40] Iter[109/312]		Loss: 0.1058
2019-10-28 15:45:12,820 Training Epoch [38/40] Iter[110/312]		Loss: 0.1064
2019-10-28 15:45:12,899 Training Epoch [38/40] Iter[111/312]		Loss: 0.1061
2019-10-28 15:45:12,978 Training Epoch [38/40] Iter[112/312]		Loss: 0.1057
2019-10-28 15:45:13,057 Training Epoch [38/40] Iter[113/312]		Loss: 0.1056
2019-10-28 15:45:13,136 Training Epoch [38/40] Iter[114/312]		Loss: 0.1054
2019-10-28 15:45:13,215 Training Epoch [38/40] Iter[115/312]		Loss: 0.1056
2019-10-28 15:45:13,294 Training Epoch [38/40] Iter[116/312]		Loss: 0.1057
2019-10-28 15:45:13,373 Training Epoch [38/40] Iter[117/312]		Loss: 0.1058
2019-10-28 15:45:13,453 Training Epoch [38/40] Iter[118/312]		Loss: 0.1058
2019-10-28 15:45:13,532 Training Epoch [38/40] Iter[119/312]		Loss: 0.1056
2019-10-28 15:45:13,611 Training Epoch [38/40] Iter[120/312]		Loss: 0.1056
2019-10-28 15:45:13,690 Training Epoch [38/40] Iter[121/312]		Loss: 0.1056
2019-10-28 15:45:13,769 Training Epoch [38/40] Iter[122/312]		Loss: 0.1054
2019-10-28 15:45:13,848 Training Epoch [38/40] Iter[123/312]		Loss: 0.1055
2019-10-28 15:45:13,927 Training Epoch [38/40] Iter[124/312]		Loss: 0.1056
2019-10-28 15:45:14,006 Training Epoch [38/40] Iter[125/312]		Loss: 0.1053
2019-10-28 15:45:14,085 Training Epoch [38/40] Iter[126/312]		Loss: 0.1051
2019-10-28 15:45:14,165 Training Epoch [38/40] Iter[127/312]		Loss: 0.1050
2019-10-28 15:45:14,244 Training Epoch [38/40] Iter[128/312]		Loss: 0.1049
2019-10-28 15:45:14,323 Training Epoch [38/40] Iter[129/312]		Loss: 0.1049
2019-10-28 15:45:14,402 Training Epoch [38/40] Iter[130/312]		Loss: 0.1049
2019-10-28 15:45:14,481 Training Epoch [38/40] Iter[131/312]		Loss: 0.1050
2019-10-28 15:45:14,560 Training Epoch [38/40] Iter[132/312]		Loss: 0.1047
2019-10-28 15:45:14,639 Training Epoch [38/40] Iter[133/312]		Loss: 0.1048
2019-10-28 15:45:14,718 Training Epoch [38/40] Iter[134/312]		Loss: 0.1050
2019-10-28 15:45:14,797 Training Epoch [38/40] Iter[135/312]		Loss: 0.1050
2019-10-28 15:45:14,876 Training Epoch [38/40] Iter[136/312]		Loss: 0.1046
2019-10-28 15:45:14,955 Training Epoch [38/40] Iter[137/312]		Loss: 0.1044
2019-10-28 15:45:15,035 Training Epoch [38/40] Iter[138/312]		Loss: 0.1043
2019-10-28 15:45:15,114 Training Epoch [38/40] Iter[139/312]		Loss: 0.1042
2019-10-28 15:45:15,193 Training Epoch [38/40] Iter[140/312]		Loss: 0.1045
2019-10-28 15:45:15,272 Training Epoch [38/40] Iter[141/312]		Loss: 0.1046
2019-10-28 15:45:15,351 Training Epoch [38/40] Iter[142/312]		Loss: 0.1048
2019-10-28 15:45:15,431 Training Epoch [38/40] Iter[143/312]		Loss: 0.1048
2019-10-28 15:45:15,510 Training Epoch [38/40] Iter[144/312]		Loss: 0.1051
2019-10-28 15:45:15,589 Training Epoch [38/40] Iter[145/312]		Loss: 0.1051
2019-10-28 15:45:15,668 Training Epoch [38/40] Iter[146/312]		Loss: 0.1052
2019-10-28 15:45:15,747 Training Epoch [38/40] Iter[147/312]		Loss: 0.1053
2019-10-28 15:45:15,826 Training Epoch [38/40] Iter[148/312]		Loss: 0.1060
2019-10-28 15:45:15,905 Training Epoch [38/40] Iter[149/312]		Loss: 0.1059
2019-10-28 15:45:15,984 Training Epoch [38/40] Iter[150/312]		Loss: 0.1062
2019-10-28 15:45:16,063 Training Epoch [38/40] Iter[151/312]		Loss: 0.1060
2019-10-28 15:45:16,143 Training Epoch [38/40] Iter[152/312]		Loss: 0.1059
2019-10-28 15:45:16,222 Training Epoch [38/40] Iter[153/312]		Loss: 0.1063
2019-10-28 15:45:16,301 Training Epoch [38/40] Iter[154/312]		Loss: 0.1061
2019-10-28 15:45:16,380 Training Epoch [38/40] Iter[155/312]		Loss: 0.1059
2019-10-28 15:45:16,459 Training Epoch [38/40] Iter[156/312]		Loss: 0.1064
2019-10-28 15:45:16,538 Training Epoch [38/40] Iter[157/312]		Loss: 0.1066
2019-10-28 15:45:16,617 Training Epoch [38/40] Iter[158/312]		Loss: 0.1069
2019-10-28 15:45:16,696 Training Epoch [38/40] Iter[159/312]		Loss: 0.1069
2019-10-28 15:45:16,775 Training Epoch [38/40] Iter[160/312]		Loss: 0.1070
2019-10-28 15:45:16,855 Training Epoch [38/40] Iter[161/312]		Loss: 0.1068
2019-10-28 15:45:16,934 Training Epoch [38/40] Iter[162/312]		Loss: 0.1068
2019-10-28 15:45:17,013 Training Epoch [38/40] Iter[163/312]		Loss: 0.1070
2019-10-28 15:45:17,092 Training Epoch [38/40] Iter[164/312]		Loss: 0.1071
2019-10-28 15:45:17,170 Training Epoch [38/40] Iter[165/312]		Loss: 0.1073
2019-10-28 15:45:17,250 Training Epoch [38/40] Iter[166/312]		Loss: 0.1072
2019-10-28 15:45:17,329 Training Epoch [38/40] Iter[167/312]		Loss: 0.1069
2019-10-28 15:45:17,408 Training Epoch [38/40] Iter[168/312]		Loss: 0.1067
2019-10-28 15:45:17,488 Training Epoch [38/40] Iter[169/312]		Loss: 0.1065
2019-10-28 15:45:17,567 Training Epoch [38/40] Iter[170/312]		Loss: 0.1071
2019-10-28 15:45:17,652 Training Epoch [38/40] Iter[171/312]		Loss: 0.1075
2019-10-28 15:45:17,731 Training Epoch [38/40] Iter[172/312]		Loss: 0.1075
2019-10-28 15:45:17,810 Training Epoch [38/40] Iter[173/312]		Loss: 0.1076
2019-10-28 15:45:17,889 Training Epoch [38/40] Iter[174/312]		Loss: 0.1076
2019-10-28 15:45:17,968 Training Epoch [38/40] Iter[175/312]		Loss: 0.1078
2019-10-28 15:45:18,047 Training Epoch [38/40] Iter[176/312]		Loss: 0.1078
2019-10-28 15:45:18,126 Training Epoch [38/40] Iter[177/312]		Loss: 0.1078
2019-10-28 15:45:18,206 Training Epoch [38/40] Iter[178/312]		Loss: 0.1078
2019-10-28 15:45:18,285 Training Epoch [38/40] Iter[179/312]		Loss: 0.1076
2019-10-28 15:45:18,364 Training Epoch [38/40] Iter[180/312]		Loss: 0.1076
2019-10-28 15:45:18,443 Training Epoch [38/40] Iter[181/312]		Loss: 0.1075
2019-10-28 15:45:18,522 Training Epoch [38/40] Iter[182/312]		Loss: 0.1075
2019-10-28 15:45:18,601 Training Epoch [38/40] Iter[183/312]		Loss: 0.1076
2019-10-28 15:45:18,680 Training Epoch [38/40] Iter[184/312]		Loss: 0.1075
2019-10-28 15:45:18,759 Training Epoch [38/40] Iter[185/312]		Loss: 0.1074
2019-10-28 15:45:18,838 Training Epoch [38/40] Iter[186/312]		Loss: 0.1072
2019-10-28 15:45:18,917 Training Epoch [38/40] Iter[187/312]		Loss: 0.1074
2019-10-28 15:45:18,996 Training Epoch [38/40] Iter[188/312]		Loss: 0.1072
2019-10-28 15:45:19,075 Training Epoch [38/40] Iter[189/312]		Loss: 0.1076
2019-10-28 15:45:19,154 Training Epoch [38/40] Iter[190/312]		Loss: 0.1074
2019-10-28 15:45:19,233 Training Epoch [38/40] Iter[191/312]		Loss: 0.1083
2019-10-28 15:45:19,312 Training Epoch [38/40] Iter[192/312]		Loss: 0.1090
2019-10-28 15:45:19,391 Training Epoch [38/40] Iter[193/312]		Loss: 0.1091
2019-10-28 15:45:19,470 Training Epoch [38/40] Iter[194/312]		Loss: 0.1090
2019-10-28 15:45:19,549 Training Epoch [38/40] Iter[195/312]		Loss: 0.1090
2019-10-28 15:45:19,627 Training Epoch [38/40] Iter[196/312]		Loss: 0.1089
2019-10-28 15:45:19,706 Training Epoch [38/40] Iter[197/312]		Loss: 0.1090
2019-10-28 15:45:19,785 Training Epoch [38/40] Iter[198/312]		Loss: 0.1090
2019-10-28 15:45:19,864 Training Epoch [38/40] Iter[199/312]		Loss: 0.1090
2019-10-28 15:45:19,943 Training Epoch [38/40] Iter[200/312]		Loss: 0.1089
2019-10-28 15:45:20,022 Training Epoch [38/40] Iter[201/312]		Loss: 0.1089
2019-10-28 15:45:20,101 Training Epoch [38/40] Iter[202/312]		Loss: 0.1086
2019-10-28 15:45:20,180 Training Epoch [38/40] Iter[203/312]		Loss: 0.1083
2019-10-28 15:45:20,259 Training Epoch [38/40] Iter[204/312]		Loss: 0.1082
2019-10-28 15:45:20,338 Training Epoch [38/40] Iter[205/312]		Loss: 0.1082
2019-10-28 15:45:20,417 Training Epoch [38/40] Iter[206/312]		Loss: 0.1082
2019-10-28 15:45:20,496 Training Epoch [38/40] Iter[207/312]		Loss: 0.1082
2019-10-28 15:45:20,575 Training Epoch [38/40] Iter[208/312]		Loss: 0.1081
2019-10-28 15:45:20,654 Training Epoch [38/40] Iter[209/312]		Loss: 0.1081
2019-10-28 15:45:20,733 Training Epoch [38/40] Iter[210/312]		Loss: 0.1083
2019-10-28 15:45:20,812 Training Epoch [38/40] Iter[211/312]		Loss: 0.1084
2019-10-28 15:45:20,891 Training Epoch [38/40] Iter[212/312]		Loss: 0.1083
2019-10-28 15:45:20,970 Training Epoch [38/40] Iter[213/312]		Loss: 0.1082
2019-10-28 15:45:21,049 Training Epoch [38/40] Iter[214/312]		Loss: 0.1082
2019-10-28 15:45:21,128 Training Epoch [38/40] Iter[215/312]		Loss: 0.1080
2019-10-28 15:45:21,207 Training Epoch [38/40] Iter[216/312]		Loss: 0.1080
2019-10-28 15:45:21,286 Training Epoch [38/40] Iter[217/312]		Loss: 0.1080
2019-10-28 15:45:21,365 Training Epoch [38/40] Iter[218/312]		Loss: 0.1081
2019-10-28 15:45:21,444 Training Epoch [38/40] Iter[219/312]		Loss: 0.1081
2019-10-28 15:45:21,524 Training Epoch [38/40] Iter[220/312]		Loss: 0.1082
2019-10-28 15:45:21,603 Training Epoch [38/40] Iter[221/312]		Loss: 0.1084
2019-10-28 15:45:21,682 Training Epoch [38/40] Iter[222/312]		Loss: 0.1083
2019-10-28 15:45:21,761 Training Epoch [38/40] Iter[223/312]		Loss: 0.1082
2019-10-28 15:45:21,840 Training Epoch [38/40] Iter[224/312]		Loss: 0.1081
2019-10-28 15:45:21,919 Training Epoch [38/40] Iter[225/312]		Loss: 0.1083
2019-10-28 15:45:21,998 Training Epoch [38/40] Iter[226/312]		Loss: 0.1082
2019-10-28 15:45:22,077 Training Epoch [38/40] Iter[227/312]		Loss: 0.1084
2019-10-28 15:45:22,156 Training Epoch [38/40] Iter[228/312]		Loss: 0.1083
2019-10-28 15:45:22,236 Training Epoch [38/40] Iter[229/312]		Loss: 0.1083
2019-10-28 15:45:22,315 Training Epoch [38/40] Iter[230/312]		Loss: 0.1082
2019-10-28 15:45:22,394 Training Epoch [38/40] Iter[231/312]		Loss: 0.1083
2019-10-28 15:45:22,474 Training Epoch [38/40] Iter[232/312]		Loss: 0.1082
2019-10-28 15:45:22,553 Training Epoch [38/40] Iter[233/312]		Loss: 0.1081
2019-10-28 15:45:22,632 Training Epoch [38/40] Iter[234/312]		Loss: 0.1080
2019-10-28 15:45:22,711 Training Epoch [38/40] Iter[235/312]		Loss: 0.1079
2019-10-28 15:45:22,790 Training Epoch [38/40] Iter[236/312]		Loss: 0.1077
2019-10-28 15:45:22,869 Training Epoch [38/40] Iter[237/312]		Loss: 0.1078
2019-10-28 15:45:22,948 Training Epoch [38/40] Iter[238/312]		Loss: 0.1078
2019-10-28 15:45:23,027 Training Epoch [38/40] Iter[239/312]		Loss: 0.1078
2019-10-28 15:45:23,106 Training Epoch [38/40] Iter[240/312]		Loss: 0.1078
2019-10-28 15:45:23,185 Training Epoch [38/40] Iter[241/312]		Loss: 0.1084
2019-10-28 15:45:23,264 Training Epoch [38/40] Iter[242/312]		Loss: 0.1083
2019-10-28 15:45:23,343 Training Epoch [38/40] Iter[243/312]		Loss: 0.1083
2019-10-28 15:45:23,423 Training Epoch [38/40] Iter[244/312]		Loss: 0.1083
2019-10-28 15:45:23,502 Training Epoch [38/40] Iter[245/312]		Loss: 0.1082
2019-10-28 15:45:23,581 Training Epoch [38/40] Iter[246/312]		Loss: 0.1081
2019-10-28 15:45:23,661 Training Epoch [38/40] Iter[247/312]		Loss: 0.1083
2019-10-28 15:45:23,740 Training Epoch [38/40] Iter[248/312]		Loss: 0.1085
2019-10-28 15:45:23,819 Training Epoch [38/40] Iter[249/312]		Loss: 0.1084
2019-10-28 15:45:23,898 Training Epoch [38/40] Iter[250/312]		Loss: 0.1087
2019-10-28 15:45:23,978 Training Epoch [38/40] Iter[251/312]		Loss: 0.1087
2019-10-28 15:45:24,057 Training Epoch [38/40] Iter[252/312]		Loss: 0.1088
2019-10-28 15:45:24,136 Training Epoch [38/40] Iter[253/312]		Loss: 0.1087
2019-10-28 15:45:24,215 Training Epoch [38/40] Iter[254/312]		Loss: 0.1087
2019-10-28 15:45:24,294 Training Epoch [38/40] Iter[255/312]		Loss: 0.1095
2019-10-28 15:45:24,375 Training Epoch [38/40] Iter[256/312]		Loss: 0.1096
2019-10-28 15:45:24,454 Training Epoch [38/40] Iter[257/312]		Loss: 0.1095
2019-10-28 15:45:24,533 Training Epoch [38/40] Iter[258/312]		Loss: 0.1094
2019-10-28 15:45:24,612 Training Epoch [38/40] Iter[259/312]		Loss: 0.1093
2019-10-28 15:45:24,691 Training Epoch [38/40] Iter[260/312]		Loss: 0.1093
2019-10-28 15:45:24,770 Training Epoch [38/40] Iter[261/312]		Loss: 0.1093
2019-10-28 15:45:24,850 Training Epoch [38/40] Iter[262/312]		Loss: 0.1092
2019-10-28 15:45:24,929 Training Epoch [38/40] Iter[263/312]		Loss: 0.1092
2019-10-28 15:45:25,008 Training Epoch [38/40] Iter[264/312]		Loss: 0.1091
2019-10-28 15:45:25,087 Training Epoch [38/40] Iter[265/312]		Loss: 0.1091
2019-10-28 15:45:25,166 Training Epoch [38/40] Iter[266/312]		Loss: 0.1090
2019-10-28 15:45:25,246 Training Epoch [38/40] Iter[267/312]		Loss: 0.1095
2019-10-28 15:45:25,325 Training Epoch [38/40] Iter[268/312]		Loss: 0.1095
2019-10-28 15:45:25,403 Training Epoch [38/40] Iter[269/312]		Loss: 0.1095
2019-10-28 15:45:25,483 Training Epoch [38/40] Iter[270/312]		Loss: 0.1094
2019-10-28 15:45:25,562 Training Epoch [38/40] Iter[271/312]		Loss: 0.1093
2019-10-28 15:45:25,641 Training Epoch [38/40] Iter[272/312]		Loss: 0.1094
2019-10-28 15:45:25,720 Training Epoch [38/40] Iter[273/312]		Loss: 0.1095
2019-10-28 15:45:25,799 Training Epoch [38/40] Iter[274/312]		Loss: 0.1096
2019-10-28 15:45:25,878 Training Epoch [38/40] Iter[275/312]		Loss: 0.1095
2019-10-28 15:45:25,957 Training Epoch [38/40] Iter[276/312]		Loss: 0.1096
2019-10-28 15:45:26,036 Training Epoch [38/40] Iter[277/312]		Loss: 0.1095
2019-10-28 15:45:26,115 Training Epoch [38/40] Iter[278/312]		Loss: 0.1094
2019-10-28 15:45:26,194 Training Epoch [38/40] Iter[279/312]		Loss: 0.1095
2019-10-28 15:45:26,273 Training Epoch [38/40] Iter[280/312]		Loss: 0.1093
2019-10-28 15:45:26,352 Training Epoch [38/40] Iter[281/312]		Loss: 0.1093
2019-10-28 15:45:26,431 Training Epoch [38/40] Iter[282/312]		Loss: 0.1091
2019-10-28 15:45:26,510 Training Epoch [38/40] Iter[283/312]		Loss: 0.1091
2019-10-28 15:45:26,590 Training Epoch [38/40] Iter[284/312]		Loss: 0.1091
2019-10-28 15:45:26,669 Training Epoch [38/40] Iter[285/312]		Loss: 0.1090
2019-10-28 15:45:26,748 Training Epoch [38/40] Iter[286/312]		Loss: 0.1089
2019-10-28 15:45:26,827 Training Epoch [38/40] Iter[287/312]		Loss: 0.1088
2019-10-28 15:45:26,906 Training Epoch [38/40] Iter[288/312]		Loss: 0.1089
2019-10-28 15:45:26,985 Training Epoch [38/40] Iter[289/312]		Loss: 0.1089
2019-10-28 15:45:27,064 Training Epoch [38/40] Iter[290/312]		Loss: 0.1088
2019-10-28 15:45:27,143 Training Epoch [38/40] Iter[291/312]		Loss: 0.1088
2019-10-28 15:45:27,222 Training Epoch [38/40] Iter[292/312]		Loss: 0.1089
2019-10-28 15:45:27,301 Training Epoch [38/40] Iter[293/312]		Loss: 0.1090
2019-10-28 15:45:27,381 Training Epoch [38/40] Iter[294/312]		Loss: 0.1091
2019-10-28 15:45:27,460 Training Epoch [38/40] Iter[295/312]		Loss: 0.1091
2019-10-28 15:45:27,539 Training Epoch [38/40] Iter[296/312]		Loss: 0.1091
2019-10-28 15:45:27,618 Training Epoch [38/40] Iter[297/312]		Loss: 0.1089
2019-10-28 15:45:27,697 Training Epoch [38/40] Iter[298/312]		Loss: 0.1089
2019-10-28 15:45:27,776 Training Epoch [38/40] Iter[299/312]		Loss: 0.1091
2019-10-28 15:45:27,856 Training Epoch [38/40] Iter[300/312]		Loss: 0.1091
2019-10-28 15:45:27,935 Training Epoch [38/40] Iter[301/312]		Loss: 0.1092
2019-10-28 15:45:28,013 Training Epoch [38/40] Iter[302/312]		Loss: 0.1092
2019-10-28 15:45:28,093 Training Epoch [38/40] Iter[303/312]		Loss: 0.1092
2019-10-28 15:45:28,172 Training Epoch [38/40] Iter[304/312]		Loss: 0.1091
2019-10-28 15:45:28,250 Training Epoch [38/40] Iter[305/312]		Loss: 0.1090
2019-10-28 15:45:28,328 Training Epoch [38/40] Iter[306/312]		Loss: 0.1090
2019-10-28 15:45:28,407 Training Epoch [38/40] Iter[307/312]		Loss: 0.1092
2019-10-28 15:45:28,485 Training Epoch [38/40] Iter[308/312]		Loss: 0.1093
2019-10-28 15:45:28,564 Training Epoch [38/40] Iter[309/312]		Loss: 0.1093
2019-10-28 15:45:28,643 Training Epoch [38/40] Iter[310/312]		Loss: 0.1091
2019-10-28 15:45:28,721 Training Epoch [38/40] Iter[311/312]		Loss: 0.1091
2019-10-28 15:45:28,759 Training Epoch [38/40] Iter[312/312]		Loss: 0.1090
2019-10-28 15:45:29,187 Testing Epoch [38/40] Iter[0/62]		Loss: 0.1294
2019-10-28 15:45:29,217 Testing Epoch [38/40] Iter[1/62]		Loss: 0.1289
2019-10-28 15:45:29,242 Testing Epoch [38/40] Iter[2/62]		Loss: 0.1117
2019-10-28 15:45:29,274 Testing Epoch [38/40] Iter[3/62]		Loss: 0.1169
2019-10-28 15:45:29,301 Testing Epoch [38/40] Iter[4/62]		Loss: 0.1202
2019-10-28 15:45:29,329 Testing Epoch [38/40] Iter[5/62]		Loss: 0.1149
2019-10-28 15:45:29,348 Testing Epoch [38/40] Iter[6/62]		Loss: 0.1170
2019-10-28 15:45:29,365 Testing Epoch [38/40] Iter[7/62]		Loss: 0.1192
2019-10-28 15:45:29,393 Testing Epoch [38/40] Iter[8/62]		Loss: 0.1220
2019-10-28 15:45:29,417 Testing Epoch [38/40] Iter[9/62]		Loss: 0.1210
2019-10-28 15:45:29,442 Testing Epoch [38/40] Iter[10/62]		Loss: 0.1218
2019-10-28 15:45:29,459 Testing Epoch [38/40] Iter[11/62]		Loss: 0.1274
2019-10-28 15:45:29,489 Testing Epoch [38/40] Iter[12/62]		Loss: 0.1269
2019-10-28 15:45:29,507 Testing Epoch [38/40] Iter[13/62]		Loss: 0.1284
2019-10-28 15:45:29,537 Testing Epoch [38/40] Iter[14/62]		Loss: 0.1411
2019-10-28 15:45:29,557 Testing Epoch [38/40] Iter[15/62]		Loss: 0.1428
2019-10-28 15:45:29,582 Testing Epoch [38/40] Iter[16/62]		Loss: 0.1397
2019-10-28 15:45:29,599 Testing Epoch [38/40] Iter[17/62]		Loss: 0.1400
2019-10-28 15:45:29,617 Testing Epoch [38/40] Iter[18/62]		Loss: 0.1377
2019-10-28 15:45:29,648 Testing Epoch [38/40] Iter[19/62]		Loss: 0.1358
2019-10-28 15:45:29,673 Testing Epoch [38/40] Iter[20/62]		Loss: 0.1378
2019-10-28 15:45:29,691 Testing Epoch [38/40] Iter[21/62]		Loss: 0.1364
2019-10-28 15:45:29,717 Testing Epoch [38/40] Iter[22/62]		Loss: 0.1379
2019-10-28 15:45:29,745 Testing Epoch [38/40] Iter[23/62]		Loss: 0.1370
2019-10-28 15:45:29,763 Testing Epoch [38/40] Iter[24/62]		Loss: 0.1401
2019-10-28 15:45:29,781 Testing Epoch [38/40] Iter[25/62]		Loss: 0.1393
2019-10-28 15:45:29,806 Testing Epoch [38/40] Iter[26/62]		Loss: 0.1381
2019-10-28 15:45:29,833 Testing Epoch [38/40] Iter[27/62]		Loss: 0.1456
2019-10-28 15:45:29,851 Testing Epoch [38/40] Iter[28/62]		Loss: 0.1491
2019-10-28 15:45:29,870 Testing Epoch [38/40] Iter[29/62]		Loss: 0.1492
2019-10-28 15:45:29,890 Testing Epoch [38/40] Iter[30/62]		Loss: 0.1493
2019-10-28 15:45:29,914 Testing Epoch [38/40] Iter[31/62]		Loss: 0.1483
2019-10-28 15:45:29,945 Testing Epoch [38/40] Iter[32/62]		Loss: 0.1498
2019-10-28 15:45:29,963 Testing Epoch [38/40] Iter[33/62]		Loss: 0.1487
2019-10-28 15:45:29,981 Testing Epoch [38/40] Iter[34/62]		Loss: 0.1508
2019-10-28 15:45:29,999 Testing Epoch [38/40] Iter[35/62]		Loss: 0.1505
2019-10-28 15:45:30,026 Testing Epoch [38/40] Iter[36/62]		Loss: 0.1485
2019-10-28 15:45:30,057 Testing Epoch [38/40] Iter[37/62]		Loss: 0.1474
2019-10-28 15:45:30,073 Testing Epoch [38/40] Iter[38/62]		Loss: 0.1462
2019-10-28 15:45:30,090 Testing Epoch [38/40] Iter[39/62]		Loss: 0.1466
2019-10-28 15:45:30,123 Testing Epoch [38/40] Iter[40/62]		Loss: 0.1482
2019-10-28 15:45:30,142 Testing Epoch [38/40] Iter[41/62]		Loss: 0.1496
2019-10-28 15:45:30,162 Testing Epoch [38/40] Iter[42/62]		Loss: 0.1478
2019-10-28 15:45:30,178 Testing Epoch [38/40] Iter[43/62]		Loss: 0.1472
2019-10-28 15:45:30,206 Testing Epoch [38/40] Iter[44/62]		Loss: 0.1456
2019-10-28 15:45:30,224 Testing Epoch [38/40] Iter[45/62]		Loss: 0.1454
2019-10-28 15:45:30,241 Testing Epoch [38/40] Iter[46/62]		Loss: 0.1451
2019-10-28 15:45:30,259 Testing Epoch [38/40] Iter[47/62]		Loss: 0.1512
2019-10-28 15:45:30,287 Testing Epoch [38/40] Iter[48/62]		Loss: 0.1502
2019-10-28 15:45:30,305 Testing Epoch [38/40] Iter[49/62]		Loss: 0.1525
2019-10-28 15:45:30,332 Testing Epoch [38/40] Iter[50/62]		Loss: 0.1516
2019-10-28 15:45:30,348 Testing Epoch [38/40] Iter[51/62]		Loss: 0.1517
2019-10-28 15:45:30,366 Testing Epoch [38/40] Iter[52/62]		Loss: 0.1505
2019-10-28 15:45:30,386 Testing Epoch [38/40] Iter[53/62]		Loss: 0.1507
2019-10-28 15:45:30,404 Testing Epoch [38/40] Iter[54/62]		Loss: 0.1495
2019-10-28 15:45:30,430 Testing Epoch [38/40] Iter[55/62]		Loss: 0.1492
2019-10-28 15:45:30,447 Testing Epoch [38/40] Iter[56/62]		Loss: 0.1485
2019-10-28 15:45:30,463 Testing Epoch [38/40] Iter[57/62]		Loss: 0.1488
2019-10-28 15:45:30,481 Testing Epoch [38/40] Iter[58/62]		Loss: 0.1483
2019-10-28 15:45:30,496 Testing Epoch [38/40] Iter[59/62]		Loss: 0.1494
2019-10-28 15:45:30,513 Testing Epoch [38/40] Iter[60/62]		Loss: 0.1484
2019-10-28 15:45:30,530 Testing Epoch [38/40] Iter[61/62]		Loss: 0.1483
2019-10-28 15:45:30,539 Testing Epoch [38/40] Iter[62/62]		Loss: 0.1491
2019-10-28 15:45:31,013 Training Epoch [39/40] Iter[0/312]		Loss: 0.1355
2019-10-28 15:45:31,103 Training Epoch [39/40] Iter[1/312]		Loss: 0.1128
2019-10-28 15:45:31,182 Training Epoch [39/40] Iter[2/312]		Loss: 0.1251
2019-10-28 15:45:31,267 Training Epoch [39/40] Iter[3/312]		Loss: 0.1226
2019-10-28 15:45:31,345 Training Epoch [39/40] Iter[4/312]		Loss: 0.1322
2019-10-28 15:45:31,422 Training Epoch [39/40] Iter[5/312]		Loss: 0.1215
2019-10-28 15:45:31,500 Training Epoch [39/40] Iter[6/312]		Loss: 0.1152
2019-10-28 15:45:31,579 Training Epoch [39/40] Iter[7/312]		Loss: 0.1212
2019-10-28 15:45:31,658 Training Epoch [39/40] Iter[8/312]		Loss: 0.1178
2019-10-28 15:45:31,737 Training Epoch [39/40] Iter[9/312]		Loss: 0.1153
2019-10-28 15:45:31,816 Training Epoch [39/40] Iter[10/312]		Loss: 0.1133
2019-10-28 15:45:31,895 Training Epoch [39/40] Iter[11/312]		Loss: 0.1128
2019-10-28 15:45:31,974 Training Epoch [39/40] Iter[12/312]		Loss: 0.1111
2019-10-28 15:45:32,052 Training Epoch [39/40] Iter[13/312]		Loss: 0.1119
2019-10-28 15:45:32,131 Training Epoch [39/40] Iter[14/312]		Loss: 0.1131
2019-10-28 15:45:32,211 Training Epoch [39/40] Iter[15/312]		Loss: 0.1149
2019-10-28 15:45:32,290 Training Epoch [39/40] Iter[16/312]		Loss: 0.1127
2019-10-28 15:45:32,369 Training Epoch [39/40] Iter[17/312]		Loss: 0.1098
2019-10-28 15:45:32,448 Training Epoch [39/40] Iter[18/312]		Loss: 0.1078
2019-10-28 15:45:32,531 Training Epoch [39/40] Iter[19/312]		Loss: 0.1070
2019-10-28 15:45:32,609 Training Epoch [39/40] Iter[20/312]		Loss: 0.1082
2019-10-28 15:45:32,688 Training Epoch [39/40] Iter[21/312]		Loss: 0.1087
2019-10-28 15:45:32,767 Training Epoch [39/40] Iter[22/312]		Loss: 0.1088
2019-10-28 15:45:32,846 Training Epoch [39/40] Iter[23/312]		Loss: 0.1087
2019-10-28 15:45:32,925 Training Epoch [39/40] Iter[24/312]		Loss: 0.1080
2019-10-28 15:45:33,004 Training Epoch [39/40] Iter[25/312]		Loss: 0.1065
2019-10-28 15:45:33,083 Training Epoch [39/40] Iter[26/312]		Loss: 0.1052
2019-10-28 15:45:33,162 Training Epoch [39/40] Iter[27/312]		Loss: 0.1053
2019-10-28 15:45:33,241 Training Epoch [39/40] Iter[28/312]		Loss: 0.1044
2019-10-28 15:45:33,321 Training Epoch [39/40] Iter[29/312]		Loss: 0.1035
2019-10-28 15:45:33,400 Training Epoch [39/40] Iter[30/312]		Loss: 0.1024
2019-10-28 15:45:33,480 Training Epoch [39/40] Iter[31/312]		Loss: 0.1035
2019-10-28 15:45:33,559 Training Epoch [39/40] Iter[32/312]		Loss: 0.1045
2019-10-28 15:45:33,638 Training Epoch [39/40] Iter[33/312]		Loss: 0.1040
2019-10-28 15:45:33,718 Training Epoch [39/40] Iter[34/312]		Loss: 0.1032
2019-10-28 15:45:33,797 Training Epoch [39/40] Iter[35/312]		Loss: 0.1042
2019-10-28 15:45:33,876 Training Epoch [39/40] Iter[36/312]		Loss: 0.1056
2019-10-28 15:45:33,955 Training Epoch [39/40] Iter[37/312]		Loss: 0.1055
2019-10-28 15:45:34,034 Training Epoch [39/40] Iter[38/312]		Loss: 0.1062
2019-10-28 15:45:34,113 Training Epoch [39/40] Iter[39/312]		Loss: 0.1058
2019-10-28 15:45:34,193 Training Epoch [39/40] Iter[40/312]		Loss: 0.1058
2019-10-28 15:45:34,272 Training Epoch [39/40] Iter[41/312]		Loss: 0.1050
2019-10-28 15:45:34,351 Training Epoch [39/40] Iter[42/312]		Loss: 0.1048
2019-10-28 15:45:34,430 Training Epoch [39/40] Iter[43/312]		Loss: 0.1046
2019-10-28 15:45:34,509 Training Epoch [39/40] Iter[44/312]		Loss: 0.1042
2019-10-28 15:45:34,589 Training Epoch [39/40] Iter[45/312]		Loss: 0.1045
2019-10-28 15:45:34,668 Training Epoch [39/40] Iter[46/312]		Loss: 0.1047
2019-10-28 15:45:34,746 Training Epoch [39/40] Iter[47/312]		Loss: 0.1048
2019-10-28 15:45:34,826 Training Epoch [39/40] Iter[48/312]		Loss: 0.1044
2019-10-28 15:45:34,905 Training Epoch [39/40] Iter[49/312]		Loss: 0.1044
2019-10-28 15:45:34,984 Training Epoch [39/40] Iter[50/312]		Loss: 0.1056
2019-10-28 15:45:35,063 Training Epoch [39/40] Iter[51/312]		Loss: 0.1059
2019-10-28 15:45:35,142 Training Epoch [39/40] Iter[52/312]		Loss: 0.1058
2019-10-28 15:45:35,221 Training Epoch [39/40] Iter[53/312]		Loss: 0.1063
2019-10-28 15:45:35,300 Training Epoch [39/40] Iter[54/312]		Loss: 0.1062
2019-10-28 15:45:35,379 Training Epoch [39/40] Iter[55/312]		Loss: 0.1059
2019-10-28 15:45:35,464 Training Epoch [39/40] Iter[56/312]		Loss: 0.1082
2019-10-28 15:45:35,543 Training Epoch [39/40] Iter[57/312]		Loss: 0.1086
2019-10-28 15:45:35,622 Training Epoch [39/40] Iter[58/312]		Loss: 0.1084
2019-10-28 15:45:35,701 Training Epoch [39/40] Iter[59/312]		Loss: 0.1091
2019-10-28 15:45:35,780 Training Epoch [39/40] Iter[60/312]		Loss: 0.1092
2019-10-28 15:45:35,860 Training Epoch [39/40] Iter[61/312]		Loss: 0.1090
2019-10-28 15:45:35,938 Training Epoch [39/40] Iter[62/312]		Loss: 0.1088
2019-10-28 15:45:36,017 Training Epoch [39/40] Iter[63/312]		Loss: 0.1083
2019-10-28 15:45:36,096 Training Epoch [39/40] Iter[64/312]		Loss: 0.1090
2019-10-28 15:45:36,175 Training Epoch [39/40] Iter[65/312]		Loss: 0.1085
2019-10-28 15:45:36,255 Training Epoch [39/40] Iter[66/312]		Loss: 0.1101
2019-10-28 15:45:36,334 Training Epoch [39/40] Iter[67/312]		Loss: 0.1109
2019-10-28 15:45:36,413 Training Epoch [39/40] Iter[68/312]		Loss: 0.1104
2019-10-28 15:45:36,492 Training Epoch [39/40] Iter[69/312]		Loss: 0.1103
2019-10-28 15:45:36,571 Training Epoch [39/40] Iter[70/312]		Loss: 0.1096
2019-10-28 15:45:36,650 Training Epoch [39/40] Iter[71/312]		Loss: 0.1100
2019-10-28 15:45:36,729 Training Epoch [39/40] Iter[72/312]		Loss: 0.1105
2019-10-28 15:45:36,808 Training Epoch [39/40] Iter[73/312]		Loss: 0.1106
2019-10-28 15:45:36,888 Training Epoch [39/40] Iter[74/312]		Loss: 0.1107
2019-10-28 15:45:36,967 Training Epoch [39/40] Iter[75/312]		Loss: 0.1107
2019-10-28 15:45:37,046 Training Epoch [39/40] Iter[76/312]		Loss: 0.1106
2019-10-28 15:45:37,125 Training Epoch [39/40] Iter[77/312]		Loss: 0.1108
2019-10-28 15:45:37,205 Training Epoch [39/40] Iter[78/312]		Loss: 0.1105
2019-10-28 15:45:37,284 Training Epoch [39/40] Iter[79/312]		Loss: 0.1107
2019-10-28 15:45:37,363 Training Epoch [39/40] Iter[80/312]		Loss: 0.1111
2019-10-28 15:45:37,442 Training Epoch [39/40] Iter[81/312]		Loss: 0.1108
2019-10-28 15:45:37,521 Training Epoch [39/40] Iter[82/312]		Loss: 0.1117
2019-10-28 15:45:37,600 Training Epoch [39/40] Iter[83/312]		Loss: 0.1111
2019-10-28 15:45:37,679 Training Epoch [39/40] Iter[84/312]		Loss: 0.1111
2019-10-28 15:45:37,758 Training Epoch [39/40] Iter[85/312]		Loss: 0.1109
2019-10-28 15:45:37,837 Training Epoch [39/40] Iter[86/312]		Loss: 0.1104
2019-10-28 15:45:37,916 Training Epoch [39/40] Iter[87/312]		Loss: 0.1100
2019-10-28 15:45:37,996 Training Epoch [39/40] Iter[88/312]		Loss: 0.1096
2019-10-28 15:45:38,075 Training Epoch [39/40] Iter[89/312]		Loss: 0.1096
2019-10-28 15:45:38,154 Training Epoch [39/40] Iter[90/312]		Loss: 0.1098
2019-10-28 15:45:38,233 Training Epoch [39/40] Iter[91/312]		Loss: 0.1102
2019-10-28 15:45:38,312 Training Epoch [39/40] Iter[92/312]		Loss: 0.1100
2019-10-28 15:45:38,391 Training Epoch [39/40] Iter[93/312]		Loss: 0.1099
2019-10-28 15:45:38,470 Training Epoch [39/40] Iter[94/312]		Loss: 0.1101
2019-10-28 15:45:38,550 Training Epoch [39/40] Iter[95/312]		Loss: 0.1096
2019-10-28 15:45:38,629 Training Epoch [39/40] Iter[96/312]		Loss: 0.1093
2019-10-28 15:45:38,708 Training Epoch [39/40] Iter[97/312]		Loss: 0.1090
2019-10-28 15:45:38,787 Training Epoch [39/40] Iter[98/312]		Loss: 0.1094
2019-10-28 15:45:38,866 Training Epoch [39/40] Iter[99/312]		Loss: 0.1099
2019-10-28 15:45:38,945 Training Epoch [39/40] Iter[100/312]		Loss: 0.1094
2019-10-28 15:45:39,025 Training Epoch [39/40] Iter[101/312]		Loss: 0.1100
2019-10-28 15:45:39,104 Training Epoch [39/40] Iter[102/312]		Loss: 0.1102
2019-10-28 15:45:39,183 Training Epoch [39/40] Iter[103/312]		Loss: 0.1102
2019-10-28 15:45:39,263 Training Epoch [39/40] Iter[104/312]		Loss: 0.1100
2019-10-28 15:45:39,342 Training Epoch [39/40] Iter[105/312]		Loss: 0.1096
2019-10-28 15:45:39,421 Training Epoch [39/40] Iter[106/312]		Loss: 0.1094
2019-10-28 15:45:39,500 Training Epoch [39/40] Iter[107/312]		Loss: 0.1094
2019-10-28 15:45:39,579 Training Epoch [39/40] Iter[108/312]		Loss: 0.1092
2019-10-28 15:45:39,658 Training Epoch [39/40] Iter[109/312]		Loss: 0.1094
2019-10-28 15:45:39,736 Training Epoch [39/40] Iter[110/312]		Loss: 0.1102
2019-10-28 15:45:39,815 Training Epoch [39/40] Iter[111/312]		Loss: 0.1102
2019-10-28 15:45:39,894 Training Epoch [39/40] Iter[112/312]		Loss: 0.1099
2019-10-28 15:45:39,974 Training Epoch [39/40] Iter[113/312]		Loss: 0.1115
2019-10-28 15:45:40,053 Training Epoch [39/40] Iter[114/312]		Loss: 0.1123
2019-10-28 15:45:40,132 Training Epoch [39/40] Iter[115/312]		Loss: 0.1120
2019-10-28 15:45:40,212 Training Epoch [39/40] Iter[116/312]		Loss: 0.1120
2019-10-28 15:45:40,291 Training Epoch [39/40] Iter[117/312]		Loss: 0.1118
2019-10-28 15:45:40,370 Training Epoch [39/40] Iter[118/312]		Loss: 0.1118
2019-10-28 15:45:40,449 Training Epoch [39/40] Iter[119/312]		Loss: 0.1121
2019-10-28 15:45:40,528 Training Epoch [39/40] Iter[120/312]		Loss: 0.1122
2019-10-28 15:45:40,607 Training Epoch [39/40] Iter[121/312]		Loss: 0.1121
2019-10-28 15:45:40,686 Training Epoch [39/40] Iter[122/312]		Loss: 0.1121
2019-10-28 15:45:40,765 Training Epoch [39/40] Iter[123/312]		Loss: 0.1119
2019-10-28 15:45:40,844 Training Epoch [39/40] Iter[124/312]		Loss: 0.1119
2019-10-28 15:45:40,923 Training Epoch [39/40] Iter[125/312]		Loss: 0.1117
2019-10-28 15:45:41,002 Training Epoch [39/40] Iter[126/312]		Loss: 0.1117
2019-10-28 15:45:41,081 Training Epoch [39/40] Iter[127/312]		Loss: 0.1114
2019-10-28 15:45:41,160 Training Epoch [39/40] Iter[128/312]		Loss: 0.1112
2019-10-28 15:45:41,239 Training Epoch [39/40] Iter[129/312]		Loss: 0.1111
2019-10-28 15:45:41,318 Training Epoch [39/40] Iter[130/312]		Loss: 0.1110
2019-10-28 15:45:41,398 Training Epoch [39/40] Iter[131/312]		Loss: 0.1108
2019-10-28 15:45:41,477 Training Epoch [39/40] Iter[132/312]		Loss: 0.1109
2019-10-28 15:45:41,556 Training Epoch [39/40] Iter[133/312]		Loss: 0.1127
2019-10-28 15:45:41,635 Training Epoch [39/40] Iter[134/312]		Loss: 0.1124
2019-10-28 15:45:41,714 Training Epoch [39/40] Iter[135/312]		Loss: 0.1122
2019-10-28 15:45:41,793 Training Epoch [39/40] Iter[136/312]		Loss: 0.1118
2019-10-28 15:45:41,872 Training Epoch [39/40] Iter[137/312]		Loss: 0.1120
2019-10-28 15:45:41,951 Training Epoch [39/40] Iter[138/312]		Loss: 0.1120
2019-10-28 15:45:42,030 Training Epoch [39/40] Iter[139/312]		Loss: 0.1123
2019-10-28 15:45:42,109 Training Epoch [39/40] Iter[140/312]		Loss: 0.1122
2019-10-28 15:45:42,188 Training Epoch [39/40] Iter[141/312]		Loss: 0.1119
2019-10-28 15:45:42,267 Training Epoch [39/40] Iter[142/312]		Loss: 0.1118
2019-10-28 15:45:42,346 Training Epoch [39/40] Iter[143/312]		Loss: 0.1116
2019-10-28 15:45:42,426 Training Epoch [39/40] Iter[144/312]		Loss: 0.1116
2019-10-28 15:45:42,505 Training Epoch [39/40] Iter[145/312]		Loss: 0.1115
2019-10-28 15:45:42,584 Training Epoch [39/40] Iter[146/312]		Loss: 0.1114
2019-10-28 15:45:42,662 Training Epoch [39/40] Iter[147/312]		Loss: 0.1113
2019-10-28 15:45:42,741 Training Epoch [39/40] Iter[148/312]		Loss: 0.1111
2019-10-28 15:45:42,820 Training Epoch [39/40] Iter[149/312]		Loss: 0.1109
2019-10-28 15:45:42,899 Training Epoch [39/40] Iter[150/312]		Loss: 0.1109
2019-10-28 15:45:42,978 Training Epoch [39/40] Iter[151/312]		Loss: 0.1106
2019-10-28 15:45:43,057 Training Epoch [39/40] Iter[152/312]		Loss: 0.1106
2019-10-28 15:45:43,136 Training Epoch [39/40] Iter[153/312]		Loss: 0.1105
2019-10-28 15:45:43,214 Training Epoch [39/40] Iter[154/312]		Loss: 0.1103
2019-10-28 15:45:43,294 Training Epoch [39/40] Iter[155/312]		Loss: 0.1102
2019-10-28 15:45:43,373 Training Epoch [39/40] Iter[156/312]		Loss: 0.1102
2019-10-28 15:45:43,452 Training Epoch [39/40] Iter[157/312]		Loss: 0.1100
2019-10-28 15:45:43,531 Training Epoch [39/40] Iter[158/312]		Loss: 0.1097
2019-10-28 15:45:43,610 Training Epoch [39/40] Iter[159/312]		Loss: 0.1098
2019-10-28 15:45:43,689 Training Epoch [39/40] Iter[160/312]		Loss: 0.1099
2019-10-28 15:45:43,768 Training Epoch [39/40] Iter[161/312]		Loss: 0.1099
2019-10-28 15:45:43,847 Training Epoch [39/40] Iter[162/312]		Loss: 0.1097
2019-10-28 15:45:43,926 Training Epoch [39/40] Iter[163/312]		Loss: 0.1100
2019-10-28 15:45:44,005 Training Epoch [39/40] Iter[164/312]		Loss: 0.1098
2019-10-28 15:45:44,084 Training Epoch [39/40] Iter[165/312]		Loss: 0.1099
2019-10-28 15:45:44,163 Training Epoch [39/40] Iter[166/312]		Loss: 0.1097
2019-10-28 15:45:44,242 Training Epoch [39/40] Iter[167/312]		Loss: 0.1101
2019-10-28 15:45:44,321 Training Epoch [39/40] Iter[168/312]		Loss: 0.1101
2019-10-28 15:45:44,400 Training Epoch [39/40] Iter[169/312]		Loss: 0.1099
2019-10-28 15:45:44,479 Training Epoch [39/40] Iter[170/312]		Loss: 0.1098
2019-10-28 15:45:44,558 Training Epoch [39/40] Iter[171/312]		Loss: 0.1097
2019-10-28 15:45:44,637 Training Epoch [39/40] Iter[172/312]		Loss: 0.1096
2019-10-28 15:45:44,716 Training Epoch [39/40] Iter[173/312]		Loss: 0.1094
2019-10-28 15:45:44,794 Training Epoch [39/40] Iter[174/312]		Loss: 0.1092
2019-10-28 15:45:44,873 Training Epoch [39/40] Iter[175/312]		Loss: 0.1091
2019-10-28 15:45:44,952 Training Epoch [39/40] Iter[176/312]		Loss: 0.1092
2019-10-28 15:45:45,031 Training Epoch [39/40] Iter[177/312]		Loss: 0.1090
2019-10-28 15:45:45,110 Training Epoch [39/40] Iter[178/312]		Loss: 0.1088
2019-10-28 15:45:45,189 Training Epoch [39/40] Iter[179/312]		Loss: 0.1086
2019-10-28 15:45:45,268 Training Epoch [39/40] Iter[180/312]		Loss: 0.1084
2019-10-28 15:45:45,347 Training Epoch [39/40] Iter[181/312]		Loss: 0.1085
2019-10-28 15:45:45,426 Training Epoch [39/40] Iter[182/312]		Loss: 0.1084
2019-10-28 15:45:45,505 Training Epoch [39/40] Iter[183/312]		Loss: 0.1082
2019-10-28 15:45:45,584 Training Epoch [39/40] Iter[184/312]		Loss: 0.1080
2019-10-28 15:45:45,663 Training Epoch [39/40] Iter[185/312]		Loss: 0.1080
2019-10-28 15:45:45,742 Training Epoch [39/40] Iter[186/312]		Loss: 0.1083
2019-10-28 15:45:45,821 Training Epoch [39/40] Iter[187/312]		Loss: 0.1082
2019-10-28 15:45:45,900 Training Epoch [39/40] Iter[188/312]		Loss: 0.1081
2019-10-28 15:45:45,980 Training Epoch [39/40] Iter[189/312]		Loss: 0.1079
2019-10-28 15:45:46,059 Training Epoch [39/40] Iter[190/312]		Loss: 0.1080
2019-10-28 15:45:46,138 Training Epoch [39/40] Iter[191/312]		Loss: 0.1079
2019-10-28 15:45:46,217 Training Epoch [39/40] Iter[192/312]		Loss: 0.1079
2019-10-28 15:45:46,297 Training Epoch [39/40] Iter[193/312]		Loss: 0.1079
2019-10-28 15:45:46,376 Training Epoch [39/40] Iter[194/312]		Loss: 0.1079
2019-10-28 15:45:46,455 Training Epoch [39/40] Iter[195/312]		Loss: 0.1078
2019-10-28 15:45:46,535 Training Epoch [39/40] Iter[196/312]		Loss: 0.1078
2019-10-28 15:45:46,614 Training Epoch [39/40] Iter[197/312]		Loss: 0.1076
2019-10-28 15:45:46,693 Training Epoch [39/40] Iter[198/312]		Loss: 0.1076
2019-10-28 15:45:46,772 Training Epoch [39/40] Iter[199/312]		Loss: 0.1075
2019-10-28 15:45:46,851 Training Epoch [39/40] Iter[200/312]		Loss: 0.1075
2019-10-28 15:45:46,930 Training Epoch [39/40] Iter[201/312]		Loss: 0.1075
2019-10-28 15:45:47,009 Training Epoch [39/40] Iter[202/312]		Loss: 0.1075
2019-10-28 15:45:47,088 Training Epoch [39/40] Iter[203/312]		Loss: 0.1075
2019-10-28 15:45:47,167 Training Epoch [39/40] Iter[204/312]		Loss: 0.1075
2019-10-28 15:45:47,246 Training Epoch [39/40] Iter[205/312]		Loss: 0.1075
2019-10-28 15:45:47,325 Training Epoch [39/40] Iter[206/312]		Loss: 0.1074
2019-10-28 15:45:47,404 Training Epoch [39/40] Iter[207/312]		Loss: 0.1074
2019-10-28 15:45:47,483 Training Epoch [39/40] Iter[208/312]		Loss: 0.1072
2019-10-28 15:45:47,562 Training Epoch [39/40] Iter[209/312]		Loss: 0.1071
2019-10-28 15:45:47,641 Training Epoch [39/40] Iter[210/312]		Loss: 0.1071
2019-10-28 15:45:47,720 Training Epoch [39/40] Iter[211/312]		Loss: 0.1069
2019-10-28 15:45:47,799 Training Epoch [39/40] Iter[212/312]		Loss: 0.1067
2019-10-28 15:45:47,878 Training Epoch [39/40] Iter[213/312]		Loss: 0.1065
2019-10-28 15:45:47,957 Training Epoch [39/40] Iter[214/312]		Loss: 0.1065
2019-10-28 15:45:48,036 Training Epoch [39/40] Iter[215/312]		Loss: 0.1064
2019-10-28 15:45:48,115 Training Epoch [39/40] Iter[216/312]		Loss: 0.1063
2019-10-28 15:45:48,194 Training Epoch [39/40] Iter[217/312]		Loss: 0.1064
2019-10-28 15:45:48,273 Training Epoch [39/40] Iter[218/312]		Loss: 0.1063
2019-10-28 15:45:48,352 Training Epoch [39/40] Iter[219/312]		Loss: 0.1063
2019-10-28 15:45:48,431 Training Epoch [39/40] Iter[220/312]		Loss: 0.1061
2019-10-28 15:45:48,510 Training Epoch [39/40] Iter[221/312]		Loss: 0.1067
2019-10-28 15:45:48,590 Training Epoch [39/40] Iter[222/312]		Loss: 0.1070
2019-10-28 15:45:48,669 Training Epoch [39/40] Iter[223/312]		Loss: 0.1071
2019-10-28 15:45:48,748 Training Epoch [39/40] Iter[224/312]		Loss: 0.1071
2019-10-28 15:45:48,827 Training Epoch [39/40] Iter[225/312]		Loss: 0.1069
2019-10-28 15:45:48,906 Training Epoch [39/40] Iter[226/312]		Loss: 0.1073
2019-10-28 15:45:48,986 Training Epoch [39/40] Iter[227/312]		Loss: 0.1073
2019-10-28 15:45:49,065 Training Epoch [39/40] Iter[228/312]		Loss: 0.1072
2019-10-28 15:45:49,144 Training Epoch [39/40] Iter[229/312]		Loss: 0.1071
2019-10-28 15:45:49,223 Training Epoch [39/40] Iter[230/312]		Loss: 0.1070
2019-10-28 15:45:49,302 Training Epoch [39/40] Iter[231/312]		Loss: 0.1071
2019-10-28 15:45:49,382 Training Epoch [39/40] Iter[232/312]		Loss: 0.1073
2019-10-28 15:45:49,462 Training Epoch [39/40] Iter[233/312]		Loss: 0.1073
2019-10-28 15:45:49,541 Training Epoch [39/40] Iter[234/312]		Loss: 0.1072
2019-10-28 15:45:49,621 Training Epoch [39/40] Iter[235/312]		Loss: 0.1073
2019-10-28 15:45:49,700 Training Epoch [39/40] Iter[236/312]		Loss: 0.1073
2019-10-28 15:45:49,780 Training Epoch [39/40] Iter[237/312]		Loss: 0.1075
2019-10-28 15:45:49,859 Training Epoch [39/40] Iter[238/312]		Loss: 0.1075
2019-10-28 15:45:49,938 Training Epoch [39/40] Iter[239/312]		Loss: 0.1080
2019-10-28 15:45:50,018 Training Epoch [39/40] Iter[240/312]		Loss: 0.1078
2019-10-28 15:45:50,097 Training Epoch [39/40] Iter[241/312]		Loss: 0.1079
2019-10-28 15:45:50,177 Training Epoch [39/40] Iter[242/312]		Loss: 0.1078
2019-10-28 15:45:50,256 Training Epoch [39/40] Iter[243/312]		Loss: 0.1081
2019-10-28 15:45:50,336 Training Epoch [39/40] Iter[244/312]		Loss: 0.1081
2019-10-28 15:45:50,415 Training Epoch [39/40] Iter[245/312]		Loss: 0.1082
2019-10-28 15:45:50,494 Training Epoch [39/40] Iter[246/312]		Loss: 0.1080
2019-10-28 15:45:50,573 Training Epoch [39/40] Iter[247/312]		Loss: 0.1080
2019-10-28 15:45:50,652 Training Epoch [39/40] Iter[248/312]		Loss: 0.1079
2019-10-28 15:45:50,731 Training Epoch [39/40] Iter[249/312]		Loss: 0.1080
2019-10-28 15:45:50,810 Training Epoch [39/40] Iter[250/312]		Loss: 0.1085
2019-10-28 15:45:50,889 Training Epoch [39/40] Iter[251/312]		Loss: 0.1084
2019-10-28 15:45:50,968 Training Epoch [39/40] Iter[252/312]		Loss: 0.1084
2019-10-28 15:45:51,047 Training Epoch [39/40] Iter[253/312]		Loss: 0.1086
2019-10-28 15:45:51,127 Training Epoch [39/40] Iter[254/312]		Loss: 0.1085
2019-10-28 15:45:51,206 Training Epoch [39/40] Iter[255/312]		Loss: 0.1084
2019-10-28 15:45:51,286 Training Epoch [39/40] Iter[256/312]		Loss: 0.1085
2019-10-28 15:45:51,365 Training Epoch [39/40] Iter[257/312]		Loss: 0.1084
2019-10-28 15:45:51,445 Training Epoch [39/40] Iter[258/312]		Loss: 0.1083
2019-10-28 15:45:51,524 Training Epoch [39/40] Iter[259/312]		Loss: 0.1083
2019-10-28 15:45:51,603 Training Epoch [39/40] Iter[260/312]		Loss: 0.1082
2019-10-28 15:45:51,682 Training Epoch [39/40] Iter[261/312]		Loss: 0.1082
2019-10-28 15:45:51,761 Training Epoch [39/40] Iter[262/312]		Loss: 0.1081
2019-10-28 15:45:51,840 Training Epoch [39/40] Iter[263/312]		Loss: 0.1080
2019-10-28 15:45:51,919 Training Epoch [39/40] Iter[264/312]		Loss: 0.1081
2019-10-28 15:45:52,004 Training Epoch [39/40] Iter[265/312]		Loss: 0.1080
2019-10-28 15:45:52,084 Training Epoch [39/40] Iter[266/312]		Loss: 0.1079
2019-10-28 15:45:52,163 Training Epoch [39/40] Iter[267/312]		Loss: 0.1079
2019-10-28 15:45:52,242 Training Epoch [39/40] Iter[268/312]		Loss: 0.1079
2019-10-28 15:45:52,323 Training Epoch [39/40] Iter[269/312]		Loss: 0.1078
2019-10-28 15:45:52,402 Training Epoch [39/40] Iter[270/312]		Loss: 0.1079
2019-10-28 15:45:52,481 Training Epoch [39/40] Iter[271/312]		Loss: 0.1079
2019-10-28 15:45:52,560 Training Epoch [39/40] Iter[272/312]		Loss: 0.1087
2019-10-28 15:45:52,642 Training Epoch [39/40] Iter[273/312]		Loss: 0.1088
2019-10-28 15:45:52,722 Training Epoch [39/40] Iter[274/312]		Loss: 0.1088
2019-10-28 15:45:52,801 Training Epoch [39/40] Iter[275/312]		Loss: 0.1087
2019-10-28 15:45:52,880 Training Epoch [39/40] Iter[276/312]		Loss: 0.1087
2019-10-28 15:45:52,959 Training Epoch [39/40] Iter[277/312]		Loss: 0.1087
2019-10-28 15:45:53,038 Training Epoch [39/40] Iter[278/312]		Loss: 0.1086
2019-10-28 15:45:53,117 Training Epoch [39/40] Iter[279/312]		Loss: 0.1084
2019-10-28 15:45:53,196 Training Epoch [39/40] Iter[280/312]		Loss: 0.1084
2019-10-28 15:45:53,275 Training Epoch [39/40] Iter[281/312]		Loss: 0.1086
2019-10-28 15:45:53,354 Training Epoch [39/40] Iter[282/312]		Loss: 0.1091
2019-10-28 15:45:53,433 Training Epoch [39/40] Iter[283/312]		Loss: 0.1089
2019-10-28 15:45:53,512 Training Epoch [39/40] Iter[284/312]		Loss: 0.1088
2019-10-28 15:45:53,592 Training Epoch [39/40] Iter[285/312]		Loss: 0.1088
2019-10-28 15:45:53,671 Training Epoch [39/40] Iter[286/312]		Loss: 0.1087
2019-10-28 15:45:53,750 Training Epoch [39/40] Iter[287/312]		Loss: 0.1087
2019-10-28 15:45:53,829 Training Epoch [39/40] Iter[288/312]		Loss: 0.1087
2019-10-28 15:45:53,908 Training Epoch [39/40] Iter[289/312]		Loss: 0.1087
2019-10-28 15:45:53,987 Training Epoch [39/40] Iter[290/312]		Loss: 0.1089
2019-10-28 15:45:54,066 Training Epoch [39/40] Iter[291/312]		Loss: 0.1089
2019-10-28 15:45:54,146 Training Epoch [39/40] Iter[292/312]		Loss: 0.1089
2019-10-28 15:45:54,225 Training Epoch [39/40] Iter[293/312]		Loss: 0.1091
2019-10-28 15:45:54,304 Training Epoch [39/40] Iter[294/312]		Loss: 0.1090
2019-10-28 15:45:54,384 Training Epoch [39/40] Iter[295/312]		Loss: 0.1089
2019-10-28 15:45:54,462 Training Epoch [39/40] Iter[296/312]		Loss: 0.1090
2019-10-28 15:45:54,542 Training Epoch [39/40] Iter[297/312]		Loss: 0.1089
2019-10-28 15:45:54,621 Training Epoch [39/40] Iter[298/312]		Loss: 0.1093
2019-10-28 15:45:54,700 Training Epoch [39/40] Iter[299/312]		Loss: 0.1093
2019-10-28 15:45:54,779 Training Epoch [39/40] Iter[300/312]		Loss: 0.1094
2019-10-28 15:45:54,858 Training Epoch [39/40] Iter[301/312]		Loss: 0.1093
2019-10-28 15:45:54,937 Training Epoch [39/40] Iter[302/312]		Loss: 0.1094
2019-10-28 15:45:55,016 Training Epoch [39/40] Iter[303/312]		Loss: 0.1094
2019-10-28 15:45:55,095 Training Epoch [39/40] Iter[304/312]		Loss: 0.1093
2019-10-28 15:45:55,173 Training Epoch [39/40] Iter[305/312]		Loss: 0.1094
2019-10-28 15:45:55,252 Training Epoch [39/40] Iter[306/312]		Loss: 0.1094
2019-10-28 15:45:55,330 Training Epoch [39/40] Iter[307/312]		Loss: 0.1093
2019-10-28 15:45:55,409 Training Epoch [39/40] Iter[308/312]		Loss: 0.1095
2019-10-28 15:45:55,488 Training Epoch [39/40] Iter[309/312]		Loss: 0.1096
2019-10-28 15:45:55,566 Training Epoch [39/40] Iter[310/312]		Loss: 0.1096
2019-10-28 15:45:55,644 Training Epoch [39/40] Iter[311/312]		Loss: 0.1098
2019-10-28 15:45:55,683 Training Epoch [39/40] Iter[312/312]		Loss: 0.1098
2019-10-28 15:45:56,102 Testing Epoch [39/40] Iter[0/62]		Loss: 0.1267
2019-10-28 15:45:56,142 Testing Epoch [39/40] Iter[1/62]		Loss: 0.1276
2019-10-28 15:45:56,168 Testing Epoch [39/40] Iter[2/62]		Loss: 0.1116
2019-10-28 15:45:56,194 Testing Epoch [39/40] Iter[3/62]		Loss: 0.1180
2019-10-28 15:45:56,210 Testing Epoch [39/40] Iter[4/62]		Loss: 0.1191
2019-10-28 15:45:56,237 Testing Epoch [39/40] Iter[5/62]		Loss: 0.1134
2019-10-28 15:45:56,254 Testing Epoch [39/40] Iter[6/62]		Loss: 0.1148
2019-10-28 15:45:56,282 Testing Epoch [39/40] Iter[7/62]		Loss: 0.1173
2019-10-28 15:45:56,305 Testing Epoch [39/40] Iter[8/62]		Loss: 0.1200
2019-10-28 15:45:56,329 Testing Epoch [39/40] Iter[9/62]		Loss: 0.1190
2019-10-28 15:45:56,353 Testing Epoch [39/40] Iter[10/62]		Loss: 0.1200
2019-10-28 15:45:56,377 Testing Epoch [39/40] Iter[11/62]		Loss: 0.1255
2019-10-28 15:45:56,403 Testing Epoch [39/40] Iter[12/62]		Loss: 0.1248
2019-10-28 15:45:56,420 Testing Epoch [39/40] Iter[13/62]		Loss: 0.1265
2019-10-28 15:45:56,438 Testing Epoch [39/40] Iter[14/62]		Loss: 0.1392
2019-10-28 15:45:56,467 Testing Epoch [39/40] Iter[15/62]		Loss: 0.1412
2019-10-28 15:45:56,494 Testing Epoch [39/40] Iter[16/62]		Loss: 0.1384
2019-10-28 15:45:56,517 Testing Epoch [39/40] Iter[17/62]		Loss: 0.1381
2019-10-28 15:45:56,541 Testing Epoch [39/40] Iter[18/62]		Loss: 0.1356
2019-10-28 15:45:56,565 Testing Epoch [39/40] Iter[19/62]		Loss: 0.1341
2019-10-28 15:45:56,583 Testing Epoch [39/40] Iter[20/62]		Loss: 0.1361
2019-10-28 15:45:56,614 Testing Epoch [39/40] Iter[21/62]		Loss: 0.1346
2019-10-28 15:45:56,633 Testing Epoch [39/40] Iter[22/62]		Loss: 0.1362
2019-10-28 15:45:56,651 Testing Epoch [39/40] Iter[23/62]		Loss: 0.1355
2019-10-28 15:45:56,669 Testing Epoch [39/40] Iter[24/62]		Loss: 0.1389
2019-10-28 15:45:56,693 Testing Epoch [39/40] Iter[25/62]		Loss: 0.1380
2019-10-28 15:45:56,714 Testing Epoch [39/40] Iter[26/62]		Loss: 0.1365
2019-10-28 15:45:56,735 Testing Epoch [39/40] Iter[27/62]		Loss: 0.1438
2019-10-28 15:45:56,753 Testing Epoch [39/40] Iter[28/62]		Loss: 0.1471
2019-10-28 15:45:56,777 Testing Epoch [39/40] Iter[29/62]		Loss: 0.1470
2019-10-28 15:45:56,798 Testing Epoch [39/40] Iter[30/62]		Loss: 0.1472
2019-10-28 15:45:56,822 Testing Epoch [39/40] Iter[31/62]		Loss: 0.1461
2019-10-28 15:45:56,840 Testing Epoch [39/40] Iter[32/62]		Loss: 0.1479
2019-10-28 15:45:56,869 Testing Epoch [39/40] Iter[33/62]		Loss: 0.1467
2019-10-28 15:45:56,891 Testing Epoch [39/40] Iter[34/62]		Loss: 0.1489
2019-10-28 15:45:56,909 Testing Epoch [39/40] Iter[35/62]		Loss: 0.1486
2019-10-28 15:45:56,927 Testing Epoch [39/40] Iter[36/62]		Loss: 0.1466
2019-10-28 15:45:56,959 Testing Epoch [39/40] Iter[37/62]		Loss: 0.1456
2019-10-28 15:45:56,982 Testing Epoch [39/40] Iter[38/62]		Loss: 0.1444
2019-10-28 15:45:57,000 Testing Epoch [39/40] Iter[39/62]		Loss: 0.1447
2019-10-28 15:45:57,018 Testing Epoch [39/40] Iter[40/62]		Loss: 0.1464
2019-10-28 15:45:57,036 Testing Epoch [39/40] Iter[41/62]		Loss: 0.1477
2019-10-28 15:45:57,054 Testing Epoch [39/40] Iter[42/62]		Loss: 0.1460
2019-10-28 15:45:57,082 Testing Epoch [39/40] Iter[43/62]		Loss: 0.1453
2019-10-28 15:45:57,099 Testing Epoch [39/40] Iter[44/62]		Loss: 0.1438
2019-10-28 15:45:57,121 Testing Epoch [39/40] Iter[45/62]		Loss: 0.1437
2019-10-28 15:45:57,138 Testing Epoch [39/40] Iter[46/62]		Loss: 0.1435
2019-10-28 15:45:57,170 Testing Epoch [39/40] Iter[47/62]		Loss: 0.1495
2019-10-28 15:45:57,192 Testing Epoch [39/40] Iter[48/62]		Loss: 0.1486
2019-10-28 15:45:57,217 Testing Epoch [39/40] Iter[49/62]		Loss: 0.1509
2019-10-28 15:45:57,235 Testing Epoch [39/40] Iter[50/62]		Loss: 0.1501
2019-10-28 15:45:57,253 Testing Epoch [39/40] Iter[51/62]		Loss: 0.1501
2019-10-28 15:45:57,281 Testing Epoch [39/40] Iter[52/62]		Loss: 0.1489
2019-10-28 15:45:57,299 Testing Epoch [39/40] Iter[53/62]		Loss: 0.1492
2019-10-28 15:45:57,328 Testing Epoch [39/40] Iter[54/62]		Loss: 0.1480
2019-10-28 15:45:57,345 Testing Epoch [39/40] Iter[55/62]		Loss: 0.1477
2019-10-28 15:45:57,362 Testing Epoch [39/40] Iter[56/62]		Loss: 0.1471
2019-10-28 15:45:57,378 Testing Epoch [39/40] Iter[57/62]		Loss: 0.1475
2019-10-28 15:45:57,396 Testing Epoch [39/40] Iter[58/62]		Loss: 0.1469
2019-10-28 15:45:57,412 Testing Epoch [39/40] Iter[59/62]		Loss: 0.1480
2019-10-28 15:45:57,429 Testing Epoch [39/40] Iter[60/62]		Loss: 0.1471
2019-10-28 15:45:57,446 Testing Epoch [39/40] Iter[61/62]		Loss: 0.1471
2019-10-28 15:45:57,454 Testing Epoch [39/40] Iter[62/62]		Loss: 0.1479
2019-10-28 15:45:57,528 Saving the Model
2019-10-28 15:45:57,956 Training Epoch [40/40] Iter[0/312]		Loss: 0.0651
2019-10-28 15:45:58,039 Training Epoch [40/40] Iter[1/312]		Loss: 0.1020
2019-10-28 15:45:58,118 Training Epoch [40/40] Iter[2/312]		Loss: 0.0924
2019-10-28 15:45:58,200 Training Epoch [40/40] Iter[3/312]		Loss: 0.0888
2019-10-28 15:45:58,283 Training Epoch [40/40] Iter[4/312]		Loss: 0.0981
2019-10-28 15:45:58,361 Training Epoch [40/40] Iter[5/312]		Loss: 0.0961
2019-10-28 15:45:58,438 Training Epoch [40/40] Iter[6/312]		Loss: 0.0948
2019-10-28 15:45:58,518 Training Epoch [40/40] Iter[7/312]		Loss: 0.1004
2019-10-28 15:45:58,596 Training Epoch [40/40] Iter[8/312]		Loss: 0.1015
2019-10-28 15:45:58,675 Training Epoch [40/40] Iter[9/312]		Loss: 0.1092
2019-10-28 15:45:58,759 Training Epoch [40/40] Iter[10/312]		Loss: 0.1117
2019-10-28 15:45:58,839 Training Epoch [40/40] Iter[11/312]		Loss: 0.1136
2019-10-28 15:45:58,918 Training Epoch [40/40] Iter[12/312]		Loss: 0.1129
2019-10-28 15:45:58,997 Training Epoch [40/40] Iter[13/312]		Loss: 0.1122
2019-10-28 15:45:59,076 Training Epoch [40/40] Iter[14/312]		Loss: 0.1105
2019-10-28 15:45:59,155 Training Epoch [40/40] Iter[15/312]		Loss: 0.1079
2019-10-28 15:45:59,234 Training Epoch [40/40] Iter[16/312]		Loss: 0.1069
2019-10-28 15:45:59,313 Training Epoch [40/40] Iter[17/312]		Loss: 0.1084
2019-10-28 15:45:59,392 Training Epoch [40/40] Iter[18/312]		Loss: 0.1093
2019-10-28 15:45:59,471 Training Epoch [40/40] Iter[19/312]		Loss: 0.1096
2019-10-28 15:45:59,550 Training Epoch [40/40] Iter[20/312]		Loss: 0.1098
2019-10-28 15:45:59,629 Training Epoch [40/40] Iter[21/312]		Loss: 0.1084
2019-10-28 15:45:59,708 Training Epoch [40/40] Iter[22/312]		Loss: 0.1089
2019-10-28 15:45:59,787 Training Epoch [40/40] Iter[23/312]		Loss: 0.1087
2019-10-28 15:45:59,865 Training Epoch [40/40] Iter[24/312]		Loss: 0.1076
2019-10-28 15:45:59,944 Training Epoch [40/40] Iter[25/312]		Loss: 0.1065
2019-10-28 15:46:00,023 Training Epoch [40/40] Iter[26/312]		Loss: 0.1050
2019-10-28 15:46:00,102 Training Epoch [40/40] Iter[27/312]		Loss: 0.1058
2019-10-28 15:46:00,181 Training Epoch [40/40] Iter[28/312]		Loss: 0.1053
2019-10-28 15:46:00,260 Training Epoch [40/40] Iter[29/312]		Loss: 0.1061
2019-10-28 15:46:00,339 Training Epoch [40/40] Iter[30/312]		Loss: 0.1054
2019-10-28 15:46:00,419 Training Epoch [40/40] Iter[31/312]		Loss: 0.1051
2019-10-28 15:46:00,498 Training Epoch [40/40] Iter[32/312]		Loss: 0.1047
2019-10-28 15:46:00,577 Training Epoch [40/40] Iter[33/312]		Loss: 0.1035
2019-10-28 15:46:00,656 Training Epoch [40/40] Iter[34/312]		Loss: 0.1034
2019-10-28 15:46:00,734 Training Epoch [40/40] Iter[35/312]		Loss: 0.1024
2019-10-28 15:46:00,814 Training Epoch [40/40] Iter[36/312]		Loss: 0.1033
2019-10-28 15:46:00,893 Training Epoch [40/40] Iter[37/312]		Loss: 0.1032
2019-10-28 15:46:00,972 Training Epoch [40/40] Iter[38/312]		Loss: 0.1037
2019-10-28 15:46:01,051 Training Epoch [40/40] Iter[39/312]		Loss: 0.1037
2019-10-28 15:46:01,130 Training Epoch [40/40] Iter[40/312]		Loss: 0.1029
2019-10-28 15:46:01,209 Training Epoch [40/40] Iter[41/312]		Loss: 0.1035
2019-10-28 15:46:01,288 Training Epoch [40/40] Iter[42/312]		Loss: 0.1032
2019-10-28 15:46:01,367 Training Epoch [40/40] Iter[43/312]		Loss: 0.1031
2019-10-28 15:46:01,446 Training Epoch [40/40] Iter[44/312]		Loss: 0.1021
2019-10-28 15:46:01,525 Training Epoch [40/40] Iter[45/312]		Loss: 0.1029
2019-10-28 15:46:01,604 Training Epoch [40/40] Iter[46/312]		Loss: 0.1028
2019-10-28 15:46:01,683 Training Epoch [40/40] Iter[47/312]		Loss: 0.1025
2019-10-28 15:46:01,762 Training Epoch [40/40] Iter[48/312]		Loss: 0.1019
2019-10-28 15:46:01,841 Training Epoch [40/40] Iter[49/312]		Loss: 0.1020
2019-10-28 15:46:01,920 Training Epoch [40/40] Iter[50/312]		Loss: 0.1020
2019-10-28 15:46:01,999 Training Epoch [40/40] Iter[51/312]		Loss: 0.1020
2019-10-28 15:46:02,078 Training Epoch [40/40] Iter[52/312]		Loss: 0.1018
2019-10-28 15:46:02,157 Training Epoch [40/40] Iter[53/312]		Loss: 0.1016
2019-10-28 15:46:02,236 Training Epoch [40/40] Iter[54/312]		Loss: 0.1015
2019-10-28 15:46:02,315 Training Epoch [40/40] Iter[55/312]		Loss: 0.1019
2019-10-28 15:46:02,394 Training Epoch [40/40] Iter[56/312]		Loss: 0.1018
2019-10-28 15:46:02,473 Training Epoch [40/40] Iter[57/312]		Loss: 0.1034
2019-10-28 15:46:02,552 Training Epoch [40/40] Iter[58/312]		Loss: 0.1033
2019-10-28 15:46:02,631 Training Epoch [40/40] Iter[59/312]		Loss: 0.1034
2019-10-28 15:46:02,710 Training Epoch [40/40] Iter[60/312]		Loss: 0.1029
2019-10-28 15:46:02,788 Training Epoch [40/40] Iter[61/312]		Loss: 0.1026
2019-10-28 15:46:02,867 Training Epoch [40/40] Iter[62/312]		Loss: 0.1028
2019-10-28 15:46:02,946 Training Epoch [40/40] Iter[63/312]		Loss: 0.1028
2019-10-28 15:46:03,025 Training Epoch [40/40] Iter[64/312]		Loss: 0.1025
2019-10-28 15:46:03,105 Training Epoch [40/40] Iter[65/312]		Loss: 0.1025
2019-10-28 15:46:03,184 Training Epoch [40/40] Iter[66/312]		Loss: 0.1024
2019-10-28 15:46:03,264 Training Epoch [40/40] Iter[67/312]		Loss: 0.1021
2019-10-28 15:46:03,343 Training Epoch [40/40] Iter[68/312]		Loss: 0.1023
2019-10-28 15:46:03,422 Training Epoch [40/40] Iter[69/312]		Loss: 0.1021
2019-10-28 15:46:03,501 Training Epoch [40/40] Iter[70/312]		Loss: 0.1026
2019-10-28 15:46:03,580 Training Epoch [40/40] Iter[71/312]		Loss: 0.1021
2019-10-28 15:46:03,659 Training Epoch [40/40] Iter[72/312]		Loss: 0.1018
2019-10-28 15:46:03,738 Training Epoch [40/40] Iter[73/312]		Loss: 0.1019
2019-10-28 15:46:03,817 Training Epoch [40/40] Iter[74/312]		Loss: 0.1037
2019-10-28 15:46:03,896 Training Epoch [40/40] Iter[75/312]		Loss: 0.1037
2019-10-28 15:46:03,976 Training Epoch [40/40] Iter[76/312]		Loss: 0.1037
2019-10-28 15:46:04,055 Training Epoch [40/40] Iter[77/312]		Loss: 0.1032
2019-10-28 15:46:04,134 Training Epoch [40/40] Iter[78/312]		Loss: 0.1029
2019-10-28 15:46:04,214 Training Epoch [40/40] Iter[79/312]		Loss: 0.1026
2019-10-28 15:46:04,293 Training Epoch [40/40] Iter[80/312]		Loss: 0.1033
2019-10-28 15:46:04,371 Training Epoch [40/40] Iter[81/312]		Loss: 0.1036
2019-10-28 15:46:04,450 Training Epoch [40/40] Iter[82/312]		Loss: 0.1036
2019-10-28 15:46:04,529 Training Epoch [40/40] Iter[83/312]		Loss: 0.1031
2019-10-28 15:46:04,608 Training Epoch [40/40] Iter[84/312]		Loss: 0.1030
2019-10-28 15:46:04,687 Training Epoch [40/40] Iter[85/312]		Loss: 0.1027
2019-10-28 15:46:04,766 Training Epoch [40/40] Iter[86/312]		Loss: 0.1026
2019-10-28 15:46:04,845 Training Epoch [40/40] Iter[87/312]		Loss: 0.1025
2019-10-28 15:46:04,924 Training Epoch [40/40] Iter[88/312]		Loss: 0.1029
2019-10-28 15:46:05,003 Training Epoch [40/40] Iter[89/312]		Loss: 0.1026
2019-10-28 15:46:05,082 Training Epoch [40/40] Iter[90/312]		Loss: 0.1026
2019-10-28 15:46:05,162 Training Epoch [40/40] Iter[91/312]		Loss: 0.1022
2019-10-28 15:46:05,241 Training Epoch [40/40] Iter[92/312]		Loss: 0.1029
2019-10-28 15:46:05,320 Training Epoch [40/40] Iter[93/312]		Loss: 0.1033
2019-10-28 15:46:05,399 Training Epoch [40/40] Iter[94/312]		Loss: 0.1035
2019-10-28 15:46:05,478 Training Epoch [40/40] Iter[95/312]		Loss: 0.1033
2019-10-28 15:46:05,557 Training Epoch [40/40] Iter[96/312]		Loss: 0.1033
2019-10-28 15:46:05,636 Training Epoch [40/40] Iter[97/312]		Loss: 0.1038
2019-10-28 15:46:05,715 Training Epoch [40/40] Iter[98/312]		Loss: 0.1036
2019-10-28 15:46:05,794 Training Epoch [40/40] Iter[99/312]		Loss: 0.1033
2019-10-28 15:46:05,873 Training Epoch [40/40] Iter[100/312]		Loss: 0.1037
2019-10-28 15:46:05,952 Training Epoch [40/40] Iter[101/312]		Loss: 0.1039
2019-10-28 15:46:06,031 Training Epoch [40/40] Iter[102/312]		Loss: 0.1050
2019-10-28 15:46:06,118 Training Epoch [40/40] Iter[103/312]		Loss: 0.1054
2019-10-28 15:46:06,199 Training Epoch [40/40] Iter[104/312]		Loss: 0.1052
2019-10-28 15:46:06,278 Training Epoch [40/40] Iter[105/312]		Loss: 0.1051
2019-10-28 15:46:06,357 Training Epoch [40/40] Iter[106/312]		Loss: 0.1048
2019-10-28 15:46:06,437 Training Epoch [40/40] Iter[107/312]		Loss: 0.1052
2019-10-28 15:46:06,516 Training Epoch [40/40] Iter[108/312]		Loss: 0.1062
2019-10-28 15:46:06,594 Training Epoch [40/40] Iter[109/312]		Loss: 0.1065
2019-10-28 15:46:06,673 Training Epoch [40/40] Iter[110/312]		Loss: 0.1062
2019-10-28 15:46:06,752 Training Epoch [40/40] Iter[111/312]		Loss: 0.1057
2019-10-28 15:46:06,831 Training Epoch [40/40] Iter[112/312]		Loss: 0.1063
2019-10-28 15:46:06,910 Training Epoch [40/40] Iter[113/312]		Loss: 0.1066
2019-10-28 15:46:06,989 Training Epoch [40/40] Iter[114/312]		Loss: 0.1072
2019-10-28 15:46:07,068 Training Epoch [40/40] Iter[115/312]		Loss: 0.1069
2019-10-28 15:46:07,147 Training Epoch [40/40] Iter[116/312]		Loss: 0.1068
2019-10-28 15:46:07,226 Training Epoch [40/40] Iter[117/312]		Loss: 0.1068
2019-10-28 15:46:07,305 Training Epoch [40/40] Iter[118/312]		Loss: 0.1068
2019-10-28 15:46:07,384 Training Epoch [40/40] Iter[119/312]		Loss: 0.1067
2019-10-28 15:46:07,464 Training Epoch [40/40] Iter[120/312]		Loss: 0.1064
2019-10-28 15:46:07,543 Training Epoch [40/40] Iter[121/312]		Loss: 0.1063
2019-10-28 15:46:07,621 Training Epoch [40/40] Iter[122/312]		Loss: 0.1064
2019-10-28 15:46:07,700 Training Epoch [40/40] Iter[123/312]		Loss: 0.1062
2019-10-28 15:46:07,780 Training Epoch [40/40] Iter[124/312]		Loss: 0.1067
2019-10-28 15:46:07,858 Training Epoch [40/40] Iter[125/312]		Loss: 0.1066
2019-10-28 15:46:07,937 Training Epoch [40/40] Iter[126/312]		Loss: 0.1069
2019-10-28 15:46:08,016 Training Epoch [40/40] Iter[127/312]		Loss: 0.1068
2019-10-28 15:46:08,095 Training Epoch [40/40] Iter[128/312]		Loss: 0.1067
2019-10-28 15:46:08,174 Training Epoch [40/40] Iter[129/312]		Loss: 0.1065
2019-10-28 15:46:08,254 Training Epoch [40/40] Iter[130/312]		Loss: 0.1063
2019-10-28 15:46:08,333 Training Epoch [40/40] Iter[131/312]		Loss: 0.1061
2019-10-28 15:46:08,412 Training Epoch [40/40] Iter[132/312]		Loss: 0.1061
2019-10-28 15:46:08,491 Training Epoch [40/40] Iter[133/312]		Loss: 0.1065
2019-10-28 15:46:08,571 Training Epoch [40/40] Iter[134/312]		Loss: 0.1066
2019-10-28 15:46:08,650 Training Epoch [40/40] Iter[135/312]		Loss: 0.1069
2019-10-28 15:46:08,729 Training Epoch [40/40] Iter[136/312]		Loss: 0.1070
2019-10-28 15:46:08,808 Training Epoch [40/40] Iter[137/312]		Loss: 0.1072
2019-10-28 15:46:08,887 Training Epoch [40/40] Iter[138/312]		Loss: 0.1077
2019-10-28 15:46:08,966 Training Epoch [40/40] Iter[139/312]		Loss: 0.1080
2019-10-28 15:46:09,045 Training Epoch [40/40] Iter[140/312]		Loss: 0.1078
2019-10-28 15:46:09,125 Training Epoch [40/40] Iter[141/312]		Loss: 0.1079
2019-10-28 15:46:09,204 Training Epoch [40/40] Iter[142/312]		Loss: 0.1078
2019-10-28 15:46:09,283 Training Epoch [40/40] Iter[143/312]		Loss: 0.1080
2019-10-28 15:46:09,362 Training Epoch [40/40] Iter[144/312]		Loss: 0.1079
2019-10-28 15:46:09,441 Training Epoch [40/40] Iter[145/312]		Loss: 0.1083
2019-10-28 15:46:09,520 Training Epoch [40/40] Iter[146/312]		Loss: 0.1081
2019-10-28 15:46:09,599 Training Epoch [40/40] Iter[147/312]		Loss: 0.1083
2019-10-28 15:46:09,678 Training Epoch [40/40] Iter[148/312]		Loss: 0.1081
2019-10-28 15:46:09,757 Training Epoch [40/40] Iter[149/312]		Loss: 0.1081
2019-10-28 15:46:09,836 Training Epoch [40/40] Iter[150/312]		Loss: 0.1079
2019-10-28 15:46:09,915 Training Epoch [40/40] Iter[151/312]		Loss: 0.1079
2019-10-28 15:46:09,994 Training Epoch [40/40] Iter[152/312]		Loss: 0.1078
2019-10-28 15:46:10,073 Training Epoch [40/40] Iter[153/312]		Loss: 0.1081
2019-10-28 15:46:10,152 Training Epoch [40/40] Iter[154/312]		Loss: 0.1083
2019-10-28 15:46:10,231 Training Epoch [40/40] Iter[155/312]		Loss: 0.1081
2019-10-28 15:46:10,311 Training Epoch [40/40] Iter[156/312]		Loss: 0.1082
2019-10-28 15:46:10,390 Training Epoch [40/40] Iter[157/312]		Loss: 0.1086
2019-10-28 15:46:10,469 Training Epoch [40/40] Iter[158/312]		Loss: 0.1085
2019-10-28 15:46:10,548 Training Epoch [40/40] Iter[159/312]		Loss: 0.1083
2019-10-28 15:46:10,627 Training Epoch [40/40] Iter[160/312]		Loss: 0.1082
2019-10-28 15:46:10,706 Training Epoch [40/40] Iter[161/312]		Loss: 0.1081
2019-10-28 15:46:10,785 Training Epoch [40/40] Iter[162/312]		Loss: 0.1081
2019-10-28 15:46:10,864 Training Epoch [40/40] Iter[163/312]		Loss: 0.1084
2019-10-28 15:46:10,943 Training Epoch [40/40] Iter[164/312]		Loss: 0.1083
2019-10-28 15:46:11,022 Training Epoch [40/40] Iter[165/312]		Loss: 0.1082
2019-10-28 15:46:11,101 Training Epoch [40/40] Iter[166/312]		Loss: 0.1082
2019-10-28 15:46:11,180 Training Epoch [40/40] Iter[167/312]		Loss: 0.1082
2019-10-28 15:46:11,260 Training Epoch [40/40] Iter[168/312]		Loss: 0.1085
2019-10-28 15:46:11,339 Training Epoch [40/40] Iter[169/312]		Loss: 0.1087
2019-10-28 15:46:11,418 Training Epoch [40/40] Iter[170/312]		Loss: 0.1087
2019-10-28 15:46:11,497 Training Epoch [40/40] Iter[171/312]		Loss: 0.1087
2019-10-28 15:46:11,576 Training Epoch [40/40] Iter[172/312]		Loss: 0.1088
2019-10-28 15:46:11,656 Training Epoch [40/40] Iter[173/312]		Loss: 0.1092
2019-10-28 15:46:11,735 Training Epoch [40/40] Iter[174/312]		Loss: 0.1091
2019-10-28 15:46:11,814 Training Epoch [40/40] Iter[175/312]		Loss: 0.1089
2019-10-28 15:46:11,893 Training Epoch [40/40] Iter[176/312]		Loss: 0.1086
2019-10-28 15:46:11,972 Training Epoch [40/40] Iter[177/312]		Loss: 0.1089
2019-10-28 15:46:12,051 Training Epoch [40/40] Iter[178/312]		Loss: 0.1090
2019-10-28 15:46:12,130 Training Epoch [40/40] Iter[179/312]		Loss: 0.1089
2019-10-28 15:46:12,210 Training Epoch [40/40] Iter[180/312]		Loss: 0.1088
2019-10-28 15:46:12,289 Training Epoch [40/40] Iter[181/312]		Loss: 0.1093
2019-10-28 15:46:12,368 Training Epoch [40/40] Iter[182/312]		Loss: 0.1098
2019-10-28 15:46:12,447 Training Epoch [40/40] Iter[183/312]		Loss: 0.1096
2019-10-28 15:46:12,526 Training Epoch [40/40] Iter[184/312]		Loss: 0.1095
2019-10-28 15:46:12,605 Training Epoch [40/40] Iter[185/312]		Loss: 0.1097
2019-10-28 15:46:12,684 Training Epoch [40/40] Iter[186/312]		Loss: 0.1102
2019-10-28 15:46:12,763 Training Epoch [40/40] Iter[187/312]		Loss: 0.1103
2019-10-28 15:46:12,842 Training Epoch [40/40] Iter[188/312]		Loss: 0.1102
2019-10-28 15:46:12,921 Training Epoch [40/40] Iter[189/312]		Loss: 0.1103
2019-10-28 15:46:13,000 Training Epoch [40/40] Iter[190/312]		Loss: 0.1102
2019-10-28 15:46:13,079 Training Epoch [40/40] Iter[191/312]		Loss: 0.1102
2019-10-28 15:46:13,159 Training Epoch [40/40] Iter[192/312]		Loss: 0.1102
2019-10-28 15:46:13,238 Training Epoch [40/40] Iter[193/312]		Loss: 0.1102
2019-10-28 15:46:13,317 Training Epoch [40/40] Iter[194/312]		Loss: 0.1101
2019-10-28 15:46:13,396 Training Epoch [40/40] Iter[195/312]		Loss: 0.1101
2019-10-28 15:46:13,475 Training Epoch [40/40] Iter[196/312]		Loss: 0.1102
2019-10-28 15:46:13,554 Training Epoch [40/40] Iter[197/312]		Loss: 0.1102
2019-10-28 15:46:13,633 Training Epoch [40/40] Iter[198/312]		Loss: 0.1104
2019-10-28 15:46:13,713 Training Epoch [40/40] Iter[199/312]		Loss: 0.1105
2019-10-28 15:46:13,792 Training Epoch [40/40] Iter[200/312]		Loss: 0.1106
2019-10-28 15:46:13,871 Training Epoch [40/40] Iter[201/312]		Loss: 0.1104
2019-10-28 15:46:13,950 Training Epoch [40/40] Iter[202/312]		Loss: 0.1105
2019-10-28 15:46:14,029 Training Epoch [40/40] Iter[203/312]		Loss: 0.1105
2019-10-28 15:46:14,108 Training Epoch [40/40] Iter[204/312]		Loss: 0.1104
2019-10-28 15:46:14,187 Training Epoch [40/40] Iter[205/312]		Loss: 0.1102
2019-10-28 15:46:14,267 Training Epoch [40/40] Iter[206/312]		Loss: 0.1105
2019-10-28 15:46:14,346 Training Epoch [40/40] Iter[207/312]		Loss: 0.1103
2019-10-28 15:46:14,426 Training Epoch [40/40] Iter[208/312]		Loss: 0.1102
2019-10-28 15:46:14,505 Training Epoch [40/40] Iter[209/312]		Loss: 0.1104
2019-10-28 15:46:14,584 Training Epoch [40/40] Iter[210/312]		Loss: 0.1103
2019-10-28 15:46:14,663 Training Epoch [40/40] Iter[211/312]		Loss: 0.1101
2019-10-28 15:46:14,742 Training Epoch [40/40] Iter[212/312]		Loss: 0.1102
2019-10-28 15:46:14,821 Training Epoch [40/40] Iter[213/312]		Loss: 0.1101
2019-10-28 15:46:14,900 Training Epoch [40/40] Iter[214/312]		Loss: 0.1101
2019-10-28 15:46:14,979 Training Epoch [40/40] Iter[215/312]		Loss: 0.1100
2019-10-28 15:46:15,058 Training Epoch [40/40] Iter[216/312]		Loss: 0.1099
2019-10-28 15:46:15,138 Training Epoch [40/40] Iter[217/312]		Loss: 0.1097
2019-10-28 15:46:15,217 Training Epoch [40/40] Iter[218/312]		Loss: 0.1097
2019-10-28 15:46:15,296 Training Epoch [40/40] Iter[219/312]		Loss: 0.1096
2019-10-28 15:46:15,375 Training Epoch [40/40] Iter[220/312]		Loss: 0.1095
2019-10-28 15:46:15,454 Training Epoch [40/40] Iter[221/312]		Loss: 0.1095
2019-10-28 15:46:15,533 Training Epoch [40/40] Iter[222/312]		Loss: 0.1094
2019-10-28 15:46:15,612 Training Epoch [40/40] Iter[223/312]		Loss: 0.1095
2019-10-28 15:46:15,691 Training Epoch [40/40] Iter[224/312]		Loss: 0.1094
2019-10-28 15:46:15,771 Training Epoch [40/40] Iter[225/312]		Loss: 0.1094
2019-10-28 15:46:15,850 Training Epoch [40/40] Iter[226/312]		Loss: 0.1093
2019-10-28 15:46:15,929 Training Epoch [40/40] Iter[227/312]		Loss: 0.1094
2019-10-28 15:46:16,008 Training Epoch [40/40] Iter[228/312]		Loss: 0.1095
2019-10-28 15:46:16,088 Training Epoch [40/40] Iter[229/312]		Loss: 0.1095
2019-10-28 15:46:16,167 Training Epoch [40/40] Iter[230/312]		Loss: 0.1094
2019-10-28 15:46:16,247 Training Epoch [40/40] Iter[231/312]		Loss: 0.1093
2019-10-28 15:46:16,326 Training Epoch [40/40] Iter[232/312]		Loss: 0.1096
2019-10-28 15:46:16,405 Training Epoch [40/40] Iter[233/312]		Loss: 0.1094
2019-10-28 15:46:16,484 Training Epoch [40/40] Iter[234/312]		Loss: 0.1094
2019-10-28 15:46:16,563 Training Epoch [40/40] Iter[235/312]		Loss: 0.1093
2019-10-28 15:46:16,642 Training Epoch [40/40] Iter[236/312]		Loss: 0.1091
2019-10-28 15:46:16,722 Training Epoch [40/40] Iter[237/312]		Loss: 0.1091
2019-10-28 15:46:16,801 Training Epoch [40/40] Iter[238/312]		Loss: 0.1090
2019-10-28 15:46:16,880 Training Epoch [40/40] Iter[239/312]		Loss: 0.1090
2019-10-28 15:46:16,959 Training Epoch [40/40] Iter[240/312]		Loss: 0.1090
2019-10-28 15:46:17,038 Training Epoch [40/40] Iter[241/312]		Loss: 0.1089
2019-10-28 15:46:17,118 Training Epoch [40/40] Iter[242/312]		Loss: 0.1087
2019-10-28 15:46:17,197 Training Epoch [40/40] Iter[243/312]		Loss: 0.1087
2019-10-28 15:46:17,276 Training Epoch [40/40] Iter[244/312]		Loss: 0.1085
2019-10-28 15:46:17,355 Training Epoch [40/40] Iter[245/312]		Loss: 0.1084
2019-10-28 15:46:17,440 Training Epoch [40/40] Iter[246/312]		Loss: 0.1087
2019-10-28 15:46:17,519 Training Epoch [40/40] Iter[247/312]		Loss: 0.1089
2019-10-28 15:46:17,603 Training Epoch [40/40] Iter[248/312]		Loss: 0.1087
2019-10-28 15:46:17,682 Training Epoch [40/40] Iter[249/312]		Loss: 0.1086
2019-10-28 15:46:17,763 Training Epoch [40/40] Iter[250/312]		Loss: 0.1086
2019-10-28 15:46:17,841 Training Epoch [40/40] Iter[251/312]		Loss: 0.1084
2019-10-28 15:46:17,921 Training Epoch [40/40] Iter[252/312]		Loss: 0.1086
2019-10-28 15:46:18,000 Training Epoch [40/40] Iter[253/312]		Loss: 0.1086
2019-10-28 15:46:18,079 Training Epoch [40/40] Iter[254/312]		Loss: 0.1089
2019-10-28 15:46:18,159 Training Epoch [40/40] Iter[255/312]		Loss: 0.1088
2019-10-28 15:46:18,238 Training Epoch [40/40] Iter[256/312]		Loss: 0.1087
2019-10-28 15:46:18,317 Training Epoch [40/40] Iter[257/312]		Loss: 0.1087
2019-10-28 15:46:18,396 Training Epoch [40/40] Iter[258/312]		Loss: 0.1087
2019-10-28 15:46:18,476 Training Epoch [40/40] Iter[259/312]		Loss: 0.1086
2019-10-28 15:46:18,555 Training Epoch [40/40] Iter[260/312]		Loss: 0.1088
2019-10-28 15:46:18,634 Training Epoch [40/40] Iter[261/312]		Loss: 0.1087
2019-10-28 15:46:18,713 Training Epoch [40/40] Iter[262/312]		Loss: 0.1088
2019-10-28 15:46:18,792 Training Epoch [40/40] Iter[263/312]		Loss: 0.1089
2019-10-28 15:46:18,871 Training Epoch [40/40] Iter[264/312]		Loss: 0.1090
2019-10-28 15:46:18,950 Training Epoch [40/40] Iter[265/312]		Loss: 0.1092
2019-10-28 15:46:19,029 Training Epoch [40/40] Iter[266/312]		Loss: 0.1093
2019-10-28 15:46:19,108 Training Epoch [40/40] Iter[267/312]		Loss: 0.1092
2019-10-28 15:46:19,188 Training Epoch [40/40] Iter[268/312]		Loss: 0.1091
2019-10-28 15:46:19,267 Training Epoch [40/40] Iter[269/312]		Loss: 0.1092
2019-10-28 15:46:19,346 Training Epoch [40/40] Iter[270/312]		Loss: 0.1092
2019-10-28 15:46:19,426 Training Epoch [40/40] Iter[271/312]		Loss: 0.1091
2019-10-28 15:46:19,505 Training Epoch [40/40] Iter[272/312]		Loss: 0.1093
2019-10-28 15:46:19,584 Training Epoch [40/40] Iter[273/312]		Loss: 0.1092
2019-10-28 15:46:19,664 Training Epoch [40/40] Iter[274/312]		Loss: 0.1091
2019-10-28 15:46:19,743 Training Epoch [40/40] Iter[275/312]		Loss: 0.1090
2019-10-28 15:46:19,822 Training Epoch [40/40] Iter[276/312]		Loss: 0.1088
2019-10-28 15:46:19,901 Training Epoch [40/40] Iter[277/312]		Loss: 0.1087
2019-10-28 15:46:19,981 Training Epoch [40/40] Iter[278/312]		Loss: 0.1087
2019-10-28 15:46:20,060 Training Epoch [40/40] Iter[279/312]		Loss: 0.1087
2019-10-28 15:46:20,140 Training Epoch [40/40] Iter[280/312]		Loss: 0.1086
2019-10-28 15:46:20,219 Training Epoch [40/40] Iter[281/312]		Loss: 0.1086
2019-10-28 15:46:20,304 Training Epoch [40/40] Iter[282/312]		Loss: 0.1086
2019-10-28 15:46:20,383 Training Epoch [40/40] Iter[283/312]		Loss: 0.1086
2019-10-28 15:46:20,463 Training Epoch [40/40] Iter[284/312]		Loss: 0.1087
2019-10-28 15:46:20,542 Training Epoch [40/40] Iter[285/312]		Loss: 0.1086
2019-10-28 15:46:20,623 Training Epoch [40/40] Iter[286/312]		Loss: 0.1088
2019-10-28 15:46:20,702 Training Epoch [40/40] Iter[287/312]		Loss: 0.1090
2019-10-28 15:46:20,781 Training Epoch [40/40] Iter[288/312]		Loss: 0.1090
2019-10-28 15:46:20,860 Training Epoch [40/40] Iter[289/312]		Loss: 0.1090
2019-10-28 15:46:20,939 Training Epoch [40/40] Iter[290/312]		Loss: 0.1088
2019-10-28 15:46:21,018 Training Epoch [40/40] Iter[291/312]		Loss: 0.1088
2019-10-28 15:46:21,097 Training Epoch [40/40] Iter[292/312]		Loss: 0.1091
2019-10-28 15:46:21,176 Training Epoch [40/40] Iter[293/312]		Loss: 0.1091
2019-10-28 15:46:21,256 Training Epoch [40/40] Iter[294/312]		Loss: 0.1093
2019-10-28 15:46:21,335 Training Epoch [40/40] Iter[295/312]		Loss: 0.1094
2019-10-28 15:46:21,415 Training Epoch [40/40] Iter[296/312]		Loss: 0.1095
2019-10-28 15:46:21,494 Training Epoch [40/40] Iter[297/312]		Loss: 0.1096
2019-10-28 15:46:21,573 Training Epoch [40/40] Iter[298/312]		Loss: 0.1098
2019-10-28 15:46:21,652 Training Epoch [40/40] Iter[299/312]		Loss: 0.1100
2019-10-28 15:46:21,731 Training Epoch [40/40] Iter[300/312]		Loss: 0.1100
2019-10-28 15:46:21,810 Training Epoch [40/40] Iter[301/312]		Loss: 0.1099
2019-10-28 15:46:21,889 Training Epoch [40/40] Iter[302/312]		Loss: 0.1101
2019-10-28 15:46:21,968 Training Epoch [40/40] Iter[303/312]		Loss: 0.1100
2019-10-28 15:46:22,048 Training Epoch [40/40] Iter[304/312]		Loss: 0.1099
2019-10-28 15:46:22,126 Training Epoch [40/40] Iter[305/312]		Loss: 0.1099
2019-10-28 15:46:22,205 Training Epoch [40/40] Iter[306/312]		Loss: 0.1099
2019-10-28 15:46:22,284 Training Epoch [40/40] Iter[307/312]		Loss: 0.1098
2019-10-28 15:46:22,363 Training Epoch [40/40] Iter[308/312]		Loss: 0.1100
2019-10-28 15:46:22,442 Training Epoch [40/40] Iter[309/312]		Loss: 0.1100
2019-10-28 15:46:22,521 Training Epoch [40/40] Iter[310/312]		Loss: 0.1100
2019-10-28 15:46:22,599 Training Epoch [40/40] Iter[311/312]		Loss: 0.1099
2019-10-28 15:46:22,638 Training Epoch [40/40] Iter[312/312]		Loss: 0.1098
2019-10-28 15:46:23,070 Testing Epoch [40/40] Iter[0/62]		Loss: 0.1236
2019-10-28 15:46:23,100 Testing Epoch [40/40] Iter[1/62]		Loss: 0.1269
2019-10-28 15:46:23,122 Testing Epoch [40/40] Iter[2/62]		Loss: 0.1108
2019-10-28 15:46:23,149 Testing Epoch [40/40] Iter[3/62]		Loss: 0.1172
2019-10-28 15:46:23,170 Testing Epoch [40/40] Iter[4/62]		Loss: 0.1191
2019-10-28 15:46:23,193 Testing Epoch [40/40] Iter[5/62]		Loss: 0.1135
2019-10-28 15:46:23,209 Testing Epoch [40/40] Iter[6/62]		Loss: 0.1152
2019-10-28 15:46:23,238 Testing Epoch [40/40] Iter[7/62]		Loss: 0.1179
2019-10-28 15:46:23,261 Testing Epoch [40/40] Iter[8/62]		Loss: 0.1204
2019-10-28 15:46:23,287 Testing Epoch [40/40] Iter[9/62]		Loss: 0.1192
2019-10-28 15:46:23,303 Testing Epoch [40/40] Iter[10/62]		Loss: 0.1196
2019-10-28 15:46:23,322 Testing Epoch [40/40] Iter[11/62]		Loss: 0.1249
2019-10-28 15:46:23,349 Testing Epoch [40/40] Iter[12/62]		Loss: 0.1245
2019-10-28 15:46:23,381 Testing Epoch [40/40] Iter[13/62]		Loss: 0.1264
2019-10-28 15:46:23,399 Testing Epoch [40/40] Iter[14/62]		Loss: 0.1385
2019-10-28 15:46:23,416 Testing Epoch [40/40] Iter[15/62]		Loss: 0.1406
2019-10-28 15:46:23,442 Testing Epoch [40/40] Iter[16/62]		Loss: 0.1378
2019-10-28 15:46:23,473 Testing Epoch [40/40] Iter[17/62]		Loss: 0.1378
2019-10-28 15:46:23,490 Testing Epoch [40/40] Iter[18/62]		Loss: 0.1355
2019-10-28 15:46:23,508 Testing Epoch [40/40] Iter[19/62]		Loss: 0.1338
2019-10-28 15:46:23,537 Testing Epoch [40/40] Iter[20/62]		Loss: 0.1357
2019-10-28 15:46:23,561 Testing Epoch [40/40] Iter[21/62]		Loss: 0.1342
2019-10-28 15:46:23,583 Testing Epoch [40/40] Iter[22/62]		Loss: 0.1359
2019-10-28 15:46:23,601 Testing Epoch [40/40] Iter[23/62]		Loss: 0.1352
2019-10-28 15:46:23,625 Testing Epoch [40/40] Iter[24/62]		Loss: 0.1383
2019-10-28 15:46:23,643 Testing Epoch [40/40] Iter[25/62]		Loss: 0.1377
2019-10-28 15:46:23,669 Testing Epoch [40/40] Iter[26/62]		Loss: 0.1364
2019-10-28 15:46:23,687 Testing Epoch [40/40] Iter[27/62]		Loss: 0.1436
2019-10-28 15:46:23,713 Testing Epoch [40/40] Iter[28/62]		Loss: 0.1469
2019-10-28 15:46:23,731 Testing Epoch [40/40] Iter[29/62]		Loss: 0.1468
2019-10-28 15:46:23,757 Testing Epoch [40/40] Iter[30/62]		Loss: 0.1469
2019-10-28 15:46:23,775 Testing Epoch [40/40] Iter[31/62]		Loss: 0.1460
2019-10-28 15:46:23,801 Testing Epoch [40/40] Iter[32/62]		Loss: 0.1477
2019-10-28 15:46:23,819 Testing Epoch [40/40] Iter[33/62]		Loss: 0.1465
2019-10-28 15:46:23,845 Testing Epoch [40/40] Iter[34/62]		Loss: 0.1485
2019-10-28 15:46:23,863 Testing Epoch [40/40] Iter[35/62]		Loss: 0.1482
2019-10-28 15:46:23,889 Testing Epoch [40/40] Iter[36/62]		Loss: 0.1462
2019-10-28 15:46:23,907 Testing Epoch [40/40] Iter[37/62]		Loss: 0.1452
2019-10-28 15:46:23,933 Testing Epoch [40/40] Iter[38/62]		Loss: 0.1441
2019-10-28 15:46:23,951 Testing Epoch [40/40] Iter[39/62]		Loss: 0.1446
2019-10-28 15:46:23,977 Testing Epoch [40/40] Iter[40/62]		Loss: 0.1463
2019-10-28 15:46:23,995 Testing Epoch [40/40] Iter[41/62]		Loss: 0.1476
2019-10-28 15:46:24,021 Testing Epoch [40/40] Iter[42/62]		Loss: 0.1459
2019-10-28 15:46:24,039 Testing Epoch [40/40] Iter[43/62]		Loss: 0.1452
2019-10-28 15:46:24,065 Testing Epoch [40/40] Iter[44/62]		Loss: 0.1436
2019-10-28 15:46:24,083 Testing Epoch [40/40] Iter[45/62]		Loss: 0.1435
2019-10-28 15:46:24,109 Testing Epoch [40/40] Iter[46/62]		Loss: 0.1432
2019-10-28 15:46:24,127 Testing Epoch [40/40] Iter[47/62]		Loss: 0.1493
2019-10-28 15:46:24,157 Testing Epoch [40/40] Iter[48/62]		Loss: 0.1484
2019-10-28 15:46:24,179 Testing Epoch [40/40] Iter[49/62]		Loss: 0.1507
2019-10-28 15:46:24,204 Testing Epoch [40/40] Iter[50/62]		Loss: 0.1499
2019-10-28 15:46:24,222 Testing Epoch [40/40] Iter[51/62]		Loss: 0.1499
2019-10-28 15:46:24,240 Testing Epoch [40/40] Iter[52/62]		Loss: 0.1488
2019-10-28 15:46:24,270 Testing Epoch [40/40] Iter[53/62]		Loss: 0.1490
2019-10-28 15:46:24,287 Testing Epoch [40/40] Iter[54/62]		Loss: 0.1479
2019-10-28 15:46:24,305 Testing Epoch [40/40] Iter[55/62]		Loss: 0.1475
2019-10-28 15:46:24,321 Testing Epoch [40/40] Iter[56/62]		Loss: 0.1469
2019-10-28 15:46:24,338 Testing Epoch [40/40] Iter[57/62]		Loss: 0.1472
2019-10-28 15:46:24,355 Testing Epoch [40/40] Iter[58/62]		Loss: 0.1467
2019-10-28 15:46:24,371 Testing Epoch [40/40] Iter[59/62]		Loss: 0.1478
2019-10-28 15:46:24,389 Testing Epoch [40/40] Iter[60/62]		Loss: 0.1469
2019-10-28 15:46:24,405 Testing Epoch [40/40] Iter[61/62]		Loss: 0.1469
2019-10-28 15:46:24,414 Testing Epoch [40/40] Iter[62/62]		Loss: 0.1477
2019-10-28 15:46:24,483 Saving the Model
2019-10-28 15:46:24,484 Min Loss@1: 0.1489
